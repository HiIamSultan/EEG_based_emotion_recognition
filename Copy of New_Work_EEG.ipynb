{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of New_Work_EEG.ipynb","provenance":[{"file_id":"1lSsTpCnZc7NP67Cj2D0MN2HxalsmnXce","timestamp":1638718545258}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"mJl4myg42Jt-","executionInfo":{"status":"ok","timestamp":1639125321551,"user_tz":-360,"elapsed":3389,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from scipy.signal import butter, lfilter, freqz, filtfilt\n","from pywt import swt, cwt\n","import scipy.misc\n","from scipy.signal import welch\n","import tensorflow as tf\n","import keras\n","from tensorflow import keras\n","import tensorflow.keras.backend as K\n","from keras.models import Sequential,Model\n","from keras.models import Sequential \n","from keras.layers import Dense, Dropout, Flatten, Conv3D, Conv2D, MaxPool3D, MaxPool2D, Input, AvgPool3D, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM, Multiply\n","from keras.layers import Activation, GlobalMaxPool3D, GlobalMaxPool2D, SpatialDropout3D, SpatialDropout2D, GlobalAvgPool3D, GlobalAvgPool2D, SeparableConv1D\n","from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate, LeakyReLU\n","from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D, MaxPooling3D\n","from tensorflow.keras.optimizers import Adam\n","from keras.utils import np_utils\n","from sklearn.preprocessing import StandardScaler                                                      \n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import confusion_matrix \n","from scipy import signal\n","import pickle as pkl\n","from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n","from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n","from sklearn.utils.class_weight import compute_class_weight\n","import gc"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"_ns3s5JN97fU","executionInfo":{"status":"error","timestamp":1639125327876,"user_tz":-360,"elapsed":4270,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"3ad0531c-2a88-444e-94b1-bbfaa53fdc26"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","gc.collect()"],"execution_count":2,"outputs":[{"output_type":"error","ename":"MessageError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-dc819c935966>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    111\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m       \u001b[0muse_metadata_server\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_metadata_server\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m       ephemeral=ephemeral)\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server, ephemeral)\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 136\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    173\u001b[0m   request_id = send_request(\n\u001b[1;32m    174\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 175\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}]},{"cell_type":"code","metadata":{"id":"ugvNZGZX-DO7"},"source":["input_path='/content/drive/MyDrive/data_preprocessed_python/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GHPHG2H5lmju","executionInfo":{"status":"ok","timestamp":1638896913981,"user_tz":-360,"elapsed":49390,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"a1c2d41b-81bc-4853-ebbb-2615c2c8c243"},"source":["eeg_signal = []\n","valence = []\n","arousal = []\n","dominance = []\n","signal_freq = []\n","window_size = 32\n","skip = 32\n","gc.collect()\n","\n","for person in range(1,33):\n","  print('Person No.' + str(person))\n","  \n","  # EEG files address\n","  if person < 10 :\n","    address = input_path+'s0'+str(person)+'.dat'\n","  else :\n","    address = input_path+'s'+str(person)+'.dat'\n","\n","  with open(address, 'rb') as file:\n","    data = pkl.load(file, encoding = 'latin1')\n","\n","  eeg = data['data']\n","  label = data['labels']\n","  \n","  # Assigning classes\n","  label[label<4] = 0\n","  label[(label>=4) & (label<6)] = 1\n","  label[label>=6] = 2\n","\n","  val = label.T[0] # Valence label\n","  aro = label.T[1] # Arousal label\n","  #dom = label.T[2] # Dominance label\n","\n","  del data, label\n","  # Iterating through 40 vidoes/trials\n","  for i in range(40):\n","    valence.append(val[i])\n","    arousal.append(aro[i])\n","    sig = eeg[i]\n","    sig = sig[:32, 384:]\n","    eeg_signal.append(sig)\n","  del eeg, val, aro\n","eeg_signal = np.reshape(eeg_signal,[-1,32,7680,1])\n","data = np.asarray(eeg_signal, dtype = np.float32) # Using 32 bit floating point value to save memory\n","del eeg_signal, sig\n","valence = np.asarray(valence, dtype = np.int8)\n","arousal = np.asarray(arousal, dtype = np.int8)\n","#dominance = np.asarray(dominance, dtype = np.int8)\n","\n","print(data.shape)\n","print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence == 2].shape)\n","print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal == 2].shape)\n","#print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape)\n","\n","valence = np_utils.to_categorical(valence)\n","arousal = np_utils.to_categorical(arousal)\n","#dominance = np_utils.to_categorical(dominance)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Person No.1\n","Person No.2\n","Person No.3\n","Person No.4\n","Person No.5\n","Person No.6\n","Person No.7\n","Person No.8\n","Person No.9\n","Person No.10\n","Person No.11\n","Person No.12\n","Person No.13\n","Person No.14\n","Person No.15\n","Person No.16\n","Person No.17\n","Person No.18\n","Person No.19\n","Person No.20\n","Person No.21\n","Person No.22\n","Person No.23\n","Person No.24\n","Person No.25\n","Person No.26\n","Person No.27\n","Person No.28\n","Person No.29\n","Person No.30\n","Person No.31\n","Person No.32\n","(1280, 32, 7680, 1)\n","(1280,) (356,) (378,) (546,)\n","(1280,) (368,) (380,) (532,)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fbCNIFVD3V2L","executionInfo":{"status":"ok","timestamp":1638897101176,"user_tz":-360,"elapsed":650,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"bff23aae-fecd-4152-eb4f-704df0ace302"},"source":["#valence\n","X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n","print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(1024, 32, 7680, 1) (256, 32, 7680, 1) (1024, 3) (256, 3)\n"]}]},{"cell_type":"markdown","metadata":{"id":"-VMwwMiur8kW"},"source":["# **Proposed Architecture**"]},{"cell_type":"code","metadata":{"id":"v74dY50RoH3a"},"source":["def CNN1D(x): #power of each window\n","  x = BatchNormalization(name='BatchNormalization_1')(x)\n","  x1 = Conv1D(filters = 10, kernel_size = 32, strides = 1, padding = 'same', name = 'Conv1D_1')(x)\n","  x1 = LeakyReLU(alpha=0.3, name='LeakyReLU-activation_1')(x1)\n","  x1 = AvgPool1D(pool_size=256, name='AvgPool1D_1')(x1)\n","  x2 = Conv1D(filters = 10, kernel_size = 16, strides = 1, padding = 'same', name = 'Conv1D_2')(x)\n","  x2 = LeakyReLU(alpha=0.3, name='LeakyReLU-activation_2')(x2)\n","  x2 = AvgPool1D(pool_size=256, name='AvgPool1D_2')(x2)\n","  x3 = Conv1D(filters = 10, kernel_size = 8, strides = 1, padding = 'same', name = 'Conv1D_3')(x)\n","  x3 = LeakyReLU(alpha=0.3, name='LeakyReLU-activation_3')(x3)\n","  x3 = AvgPool1D(pool_size=256, name='AvgPool1D_3')(x3)\n","  x4 = Conv1D(filters = 10, kernel_size = 4, strides = 1, padding = 'same', name = 'Conv1D_4')(x)\n","  x4 = LeakyReLU(alpha=0.3, name='LeakyReLU-activation_4')(x4)\n","  x4 = AvgPool1D(pool_size=256, name='AvgPool1D_4')(x4)\n","  x = Concatenate(axis = 1, name = 'Concatenate_1')([x1, x2, x3, x4])\n","  x = BatchNormalization(name = 'BatchNormalization_2')(x)\n","  x = Flatten(name = 'Flatten_1')(x)\n","  x = Dense(512, activation='tanh', name='Dense_1') (x)\n","  x = Dropout(0.4, name='Dropout_1')(x)\n","  x = Dense(32, activation='relu', name='Dense_2') (x)\n","  x = Dropout(0.4, name='Dropout_2')(x)\n","  x = Dense(3, activation='softmax', name='Dense_3') (x)\n","  return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XllS2B_DbGH3","executionInfo":{"status":"ok","timestamp":1638898283240,"user_tz":-360,"elapsed":5,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"d3f605dd-18bf-4687-e29c-14266a0f0400"},"source":["def CNN1D_get_model() :\n","  input_shape = (data.shape[2],1)\n","  a = Input(input_shape, name='Input')\n","  out = CNN1D(a)\n","  model = Model(a, out)\n","  opt = keras.optimizers.Adam(learning_rate=0.001)\n","  model.compile(loss=keras.losses.categorical_crossentropy, metrics=[tf.keras.metrics.CategoricalAccuracy(),\n","                                                                     tf.keras.metrics.CategoricalCrossentropy(), \n","                                                                     tf.keras.metrics.AUC(),\n","                                                                     tf.keras.metrics.Precision(),\n","                                                                     tf.keras.metrics.Recall()], optimizer=opt)\n","  return model\n","model = CNN1D_get_model()\n","print(model.summary())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_14\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," Input (InputLayer)             [(None, 7680, 1)]    0           []                               \n","                                                                                                  \n"," BatchNormalization_1 (BatchNor  (None, 7680, 1)     4           ['Input[0][0]']                  \n"," malization)                                                                                      \n","                                                                                                  \n"," Conv1D_1 (Conv1D)              (None, 7680, 10)     330         ['BatchNormalization_1[0][0]']   \n","                                                                                                  \n"," Conv1D_2 (Conv1D)              (None, 7680, 10)     170         ['BatchNormalization_1[0][0]']   \n","                                                                                                  \n"," Conv1D_3 (Conv1D)              (None, 7680, 10)     90          ['BatchNormalization_1[0][0]']   \n","                                                                                                  \n"," Conv1D_4 (Conv1D)              (None, 7680, 10)     50          ['BatchNormalization_1[0][0]']   \n","                                                                                                  \n"," LeakyReLU-activation_1 (LeakyR  (None, 7680, 10)    0           ['Conv1D_1[0][0]']               \n"," eLU)                                                                                             \n","                                                                                                  \n"," LeakyReLU-activation_2 (LeakyR  (None, 7680, 10)    0           ['Conv1D_2[0][0]']               \n"," eLU)                                                                                             \n","                                                                                                  \n"," LeakyReLU-activation_3 (LeakyR  (None, 7680, 10)    0           ['Conv1D_3[0][0]']               \n"," eLU)                                                                                             \n","                                                                                                  \n"," LeakyReLU-activation_4 (LeakyR  (None, 7680, 10)    0           ['Conv1D_4[0][0]']               \n"," eLU)                                                                                             \n","                                                                                                  \n"," AvgPool1D_1 (AveragePooling1D)  (None, 30, 10)      0           ['LeakyReLU-activation_1[0][0]'] \n","                                                                                                  \n"," AvgPool1D_2 (AveragePooling1D)  (None, 30, 10)      0           ['LeakyReLU-activation_2[0][0]'] \n","                                                                                                  \n"," AvgPool1D_3 (AveragePooling1D)  (None, 30, 10)      0           ['LeakyReLU-activation_3[0][0]'] \n","                                                                                                  \n"," AvgPool1D_4 (AveragePooling1D)  (None, 30, 10)      0           ['LeakyReLU-activation_4[0][0]'] \n","                                                                                                  \n"," Concatenate_1 (Concatenate)    (None, 120, 10)      0           ['AvgPool1D_1[0][0]',            \n","                                                                  'AvgPool1D_2[0][0]',            \n","                                                                  'AvgPool1D_3[0][0]',            \n","                                                                  'AvgPool1D_4[0][0]']            \n","                                                                                                  \n"," BatchNormalization_2 (BatchNor  (None, 120, 10)     40          ['Concatenate_1[0][0]']          \n"," malization)                                                                                      \n","                                                                                                  \n"," Flatten_1 (Flatten)            (None, 1200)         0           ['BatchNormalization_2[0][0]']   \n","                                                                                                  \n"," Dense_1 (Dense)                (None, 512)          614912      ['Flatten_1[0][0]']              \n","                                                                                                  \n"," Dropout_1 (Dropout)            (None, 512)          0           ['Dense_1[0][0]']                \n","                                                                                                  \n"," Dense_2 (Dense)                (None, 32)           16416       ['Dropout_1[0][0]']              \n","                                                                                                  \n"," Dropout_2 (Dropout)            (None, 32)           0           ['Dense_2[0][0]']                \n","                                                                                                  \n"," Dense_3 (Dense)                (None, 3)            99          ['Dropout_2[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 632,111\n","Trainable params: 632,089\n","Non-trainable params: 22\n","__________________________________________________________________________________________________\n","None\n"]}]},{"cell_type":"code","metadata":{"id":"ZC6fgR_XrOSw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638897140383,"user_tz":-360,"elapsed":771,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"8990e509-23df-477d-cbcb-2c917a60dfb3"},"source":["batch_size = 64\n","epochs = 30\n","kfold = KFold(n_splits=10, random_state=1, shuffle=True)\n","gc.collect()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2463"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"le6AXdqO3A0E"},"source":["def call_class_weights(yt):\n","  y_integers = np.argmax(yt, axis=1)\n","  class_weights = compute_class_weight(class_weight = 'balanced', classes = np.unique(y_integers), y = y_integers)\n","  d_class_weights = dict(enumerate(class_weights))\n","  return d_class_weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0itaylBXqWmO","outputId":"45cfcada-06b3-41ea-df97-ef149f7e6055"},"source":["xf_test = []\n","Xf_train = []\n","for i in range(32):\n","  print(\"Channel No.\",i+1)\n","  foldNum=0\n","  model = CNN1D_get_model()\n","  for train_index, val_index in kfold.split(X_train[:,i,:,:], Y_train):\n","    foldNum = foldNum + 1\n","    print(\"Results for fold\",foldNum)\n","    x_train, x_val = X_train[:,i,:,:][train_index], X_train[:,i,:,:][val_index]\n","    y_train, y_val = Y_train[train_index], Y_train[val_index]\n","    d_class_weights = call_class_weights(y_train)\n","    model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, class_weight=d_class_weights, verbose=0, validation_data=(x_val, y_val),shuffle=True)\n","    model.evaluate(x_test[:,i,:,:], y_test)\n","    gc.collect() # Garbage collecter\n","    del x_train, x_val, y_train, y_val\n","  layer_name = 'Dense_1'\n","  intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n","  xf_test.append(intermediate_layer_model.predict(x_test[:,i,:,:]))\n","  Xf_train.append(intermediate_layer_model.predict(X_train[:,i,:,:]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Channel No. 1\n","Results for fold 1\n","8/8 [==============================] - 1s 21ms/step - loss: 1.0931 - categorical_accuracy: 0.3398 - categorical_crossentropy: 1.0931 - auc_8: 0.5474 - precision_8: 0.4000 - recall_8: 0.0078\n","Results for fold 2\n","8/8 [==============================] - 0s 16ms/step - loss: 1.1430 - categorical_accuracy: 0.3320 - categorical_crossentropy: 1.1430 - auc_8: 0.5020 - precision_8: 0.3333 - recall_8: 0.0430\n","Results for fold 3\n","8/8 [==============================] - 0s 17ms/step - loss: 1.2552 - categorical_accuracy: 0.3203 - categorical_crossentropy: 1.2552 - auc_8: 0.4883 - precision_8: 0.2800 - recall_8: 0.0820\n","Results for fold 4\n","8/8 [==============================] - 0s 21ms/step - loss: 1.3027 - categorical_accuracy: 0.3047 - categorical_crossentropy: 1.3027 - auc_8: 0.4946 - precision_8: 0.2778 - recall_8: 0.0977\n","Results for fold 5\n","8/8 [==============================] - 0s 18ms/step - loss: 1.3809 - categorical_accuracy: 0.3125 - categorical_crossentropy: 1.3809 - auc_8: 0.4971 - precision_8: 0.3393 - recall_8: 0.1484\n","Results for fold 6\n","8/8 [==============================] - 0s 16ms/step - loss: 1.4660 - categorical_accuracy: 0.3359 - categorical_crossentropy: 1.4660 - auc_8: 0.5153 - precision_8: 0.3285 - recall_8: 0.1758\n","Results for fold 7\n","8/8 [==============================] - 0s 17ms/step - loss: 1.6252 - categorical_accuracy: 0.3320 - categorical_crossentropy: 1.6252 - auc_8: 0.5007 - precision_8: 0.3448 - recall_8: 0.1953\n","Results for fold 8\n","8/8 [==============================] - 0s 16ms/step - loss: 1.7191 - categorical_accuracy: 0.3086 - categorical_crossentropy: 1.7191 - auc_8: 0.4845 - precision_8: 0.3230 - recall_8: 0.2031\n","Results for fold 9\n","8/8 [==============================] - 0s 16ms/step - loss: 1.7818 - categorical_accuracy: 0.3359 - categorical_crossentropy: 1.7818 - auc_8: 0.5242 - precision_8: 0.3815 - recall_8: 0.2578\n","Results for fold 10\n","8/8 [==============================] - 0s 21ms/step - loss: 1.9734 - categorical_accuracy: 0.3203 - categorical_crossentropy: 1.9734 - auc_8: 0.5062 - precision_8: 0.3370 - recall_8: 0.2383\n","Channel No. 2\n","Results for fold 1\n","8/8 [==============================] - 1s 22ms/step - loss: 1.1087 - categorical_accuracy: 0.3320 - categorical_crossentropy: 1.1087 - auc_9: 0.4865 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n","Results for fold 2\n","8/8 [==============================] - 0s 22ms/step - loss: 1.1295 - categorical_accuracy: 0.3047 - categorical_crossentropy: 1.1295 - auc_9: 0.5066 - precision_9: 0.2000 - recall_9: 0.0195\n","Results for fold 3\n","8/8 [==============================] - 0s 22ms/step - loss: 1.1556 - categorical_accuracy: 0.3359 - categorical_crossentropy: 1.1556 - auc_9: 0.5019 - precision_9: 0.2593 - recall_9: 0.0273\n","Results for fold 4\n","8/8 [==============================] - 0s 16ms/step - loss: 1.1919 - categorical_accuracy: 0.3477 - categorical_crossentropy: 1.1919 - auc_9: 0.5255 - precision_9: 0.2553 - recall_9: 0.0469\n","Results for fold 5\n","8/8 [==============================] - 0s 17ms/step - loss: 1.1968 - categorical_accuracy: 0.3516 - categorical_crossentropy: 1.1968 - auc_9: 0.5409 - precision_9: 0.3971 - recall_9: 0.1055\n","Results for fold 6\n","8/8 [==============================] - 0s 22ms/step - loss: 1.2692 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.2692 - auc_9: 0.5481 - precision_9: 0.4070 - recall_9: 0.1367\n","Results for fold 7\n","8/8 [==============================] - 0s 17ms/step - loss: 1.3291 - categorical_accuracy: 0.3438 - categorical_crossentropy: 1.3291 - auc_9: 0.5259 - precision_9: 0.3095 - recall_9: 0.1016\n","Results for fold 8\n","8/8 [==============================] - 0s 21ms/step - loss: 1.3302 - categorical_accuracy: 0.3906 - categorical_crossentropy: 1.3302 - auc_9: 0.5658 - precision_9: 0.4554 - recall_9: 0.1797\n","Results for fold 9\n","8/8 [==============================] - 0s 21ms/step - loss: 1.4239 - categorical_accuracy: 0.3867 - categorical_crossentropy: 1.4239 - auc_9: 0.5375 - precision_9: 0.3717 - recall_9: 0.1641\n","Results for fold 10\n","8/8 [==============================] - 0s 21ms/step - loss: 1.5270 - categorical_accuracy: 0.3477 - categorical_crossentropy: 1.5270 - auc_9: 0.5368 - precision_9: 0.3458 - recall_9: 0.1445\n","Channel No. 3\n","Results for fold 1\n","8/8 [==============================] - 1s 16ms/step - loss: 1.0955 - categorical_accuracy: 0.3555 - categorical_crossentropy: 1.0955 - auc_10: 0.5447 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00\n","Results for fold 2\n","8/8 [==============================] - 0s 22ms/step - loss: 1.0984 - categorical_accuracy: 0.3477 - categorical_crossentropy: 1.0984 - auc_10: 0.5231 - precision_10: 0.7273 - recall_10: 0.0312\n","Results for fold 3\n","8/8 [==============================] - 0s 20ms/step - loss: 1.1005 - categorical_accuracy: 0.3633 - categorical_crossentropy: 1.1005 - auc_10: 0.5486 - precision_10: 0.5263 - recall_10: 0.0391\n","Results for fold 4\n","8/8 [==============================] - 0s 21ms/step - loss: 1.1414 - categorical_accuracy: 0.3359 - categorical_crossentropy: 1.1414 - auc_10: 0.5164 - precision_10: 0.3673 - recall_10: 0.0703\n","Results for fold 5\n","8/8 [==============================] - 0s 21ms/step - loss: 1.1674 - categorical_accuracy: 0.3164 - categorical_crossentropy: 1.1674 - auc_10: 0.5035 - precision_10: 0.2917 - recall_10: 0.0547\n","Results for fold 6\n","8/8 [==============================] - 0s 17ms/step - loss: 1.2106 - categorical_accuracy: 0.3672 - categorical_crossentropy: 1.2106 - auc_10: 0.5432 - precision_10: 0.3382 - recall_10: 0.0898\n","Results for fold 7\n","8/8 [==============================] - 0s 21ms/step - loss: 1.2897 - categorical_accuracy: 0.3867 - categorical_crossentropy: 1.2897 - auc_10: 0.5349 - precision_10: 0.4000 - recall_10: 0.1328\n","Results for fold 8\n","8/8 [==============================] - 0s 21ms/step - loss: 1.3408 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.3408 - auc_10: 0.5382 - precision_10: 0.3592 - recall_10: 0.1445\n","Results for fold 9\n","8/8 [==============================] - 0s 21ms/step - loss: 1.4530 - categorical_accuracy: 0.3945 - categorical_crossentropy: 1.4530 - auc_10: 0.5271 - precision_10: 0.3739 - recall_10: 0.1680\n","Results for fold 10\n","8/8 [==============================] - 0s 22ms/step - loss: 1.6252 - categorical_accuracy: 0.3711 - categorical_crossentropy: 1.6252 - auc_10: 0.5136 - precision_10: 0.3529 - recall_10: 0.1875\n","Channel No. 4\n","Results for fold 1\n","8/8 [==============================] - 1s 22ms/step - loss: 1.1011 - categorical_accuracy: 0.3672 - categorical_crossentropy: 1.1011 - auc_11: 0.5096 - precision_11: 0.0000e+00 - recall_11: 0.0000e+00\n","Results for fold 2\n","8/8 [==============================] - 0s 17ms/step - loss: 1.0989 - categorical_accuracy: 0.2695 - categorical_crossentropy: 1.0989 - auc_11: 0.4632 - precision_11: 1.0000 - recall_11: 0.0039\n","Results for fold 3\n","8/8 [==============================] - 0s 22ms/step - loss: 1.0961 - categorical_accuracy: 0.3633 - categorical_crossentropy: 1.0961 - auc_11: 0.5427 - precision_11: 0.6250 - recall_11: 0.0195\n","Results for fold 4\n","8/8 [==============================] - 0s 21ms/step - loss: 1.1093 - categorical_accuracy: 0.3516 - categorical_crossentropy: 1.1093 - auc_11: 0.5395 - precision_11: 0.4348 - recall_11: 0.0391\n","Results for fold 5\n","8/8 [==============================] - 0s 21ms/step - loss: 1.1135 - categorical_accuracy: 0.3984 - categorical_crossentropy: 1.1135 - auc_11: 0.5528 - precision_11: 0.4600 - recall_11: 0.0898\n","Results for fold 6\n","8/8 [==============================] - 0s 22ms/step - loss: 1.1933 - categorical_accuracy: 0.3867 - categorical_crossentropy: 1.1933 - auc_11: 0.5323 - precision_11: 0.4124 - recall_11: 0.1562\n","Results for fold 7\n","8/8 [==============================] - 0s 18ms/step - loss: 1.2264 - categorical_accuracy: 0.3633 - categorical_crossentropy: 1.2264 - auc_11: 0.5232 - precision_11: 0.3467 - recall_11: 0.1016\n","Results for fold 8\n","8/8 [==============================] - 0s 21ms/step - loss: 1.2787 - categorical_accuracy: 0.3438 - categorical_crossentropy: 1.2787 - auc_11: 0.5163 - precision_11: 0.3786 - recall_11: 0.1523\n","Results for fold 9\n","8/8 [==============================] - 0s 21ms/step - loss: 1.3305 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.3305 - auc_11: 0.5061 - precision_11: 0.3448 - recall_11: 0.1562\n","Results for fold 10\n","8/8 [==============================] - 0s 21ms/step - loss: 1.3815 - categorical_accuracy: 0.3594 - categorical_crossentropy: 1.3815 - auc_11: 0.5129 - precision_11: 0.3600 - recall_11: 0.1758\n","Channel No. 5\n","Results for fold 1\n","8/8 [==============================] - 1s 16ms/step - loss: 1.1128 - categorical_accuracy: 0.3320 - categorical_crossentropy: 1.1128 - auc_12: 0.5029 - precision_12: 0.2000 - recall_12: 0.0039\n","Results for fold 2\n","8/8 [==============================] - 0s 21ms/step - loss: 1.1132 - categorical_accuracy: 0.3945 - categorical_crossentropy: 1.1132 - auc_12: 0.5372 - precision_12: 0.3600 - recall_12: 0.0352\n","Results for fold 3\n","8/8 [==============================] - 0s 21ms/step - loss: 1.1371 - categorical_accuracy: 0.3203 - categorical_crossentropy: 1.1371 - auc_12: 0.4888 - precision_12: 0.2083 - recall_12: 0.0195\n","Results for fold 4\n","8/8 [==============================] - 0s 17ms/step - loss: 1.2201 - categorical_accuracy: 0.3359 - categorical_crossentropy: 1.2201 - auc_12: 0.4894 - precision_12: 0.2143 - recall_12: 0.0469\n","Results for fold 5\n","8/8 [==============================] - 0s 17ms/step - loss: 1.2561 - categorical_accuracy: 0.3594 - categorical_crossentropy: 1.2561 - auc_12: 0.5199 - precision_12: 0.3924 - recall_12: 0.1211\n","Results for fold 6\n","8/8 [==============================] - 0s 21ms/step - loss: 1.2739 - categorical_accuracy: 0.3555 - categorical_crossentropy: 1.2739 - auc_12: 0.5237 - precision_12: 0.3721 - recall_12: 0.1250\n","Results for fold 7\n","8/8 [==============================] - 0s 16ms/step - loss: 1.3360 - categorical_accuracy: 0.3828 - categorical_crossentropy: 1.3360 - auc_12: 0.5278 - precision_12: 0.3684 - recall_12: 0.1367\n","Results for fold 8\n","8/8 [==============================] - 0s 22ms/step - loss: 1.3729 - categorical_accuracy: 0.3711 - categorical_crossentropy: 1.3729 - auc_12: 0.5326 - precision_12: 0.3333 - recall_12: 0.1562\n","Results for fold 9\n","8/8 [==============================] - 0s 22ms/step - loss: 1.4716 - categorical_accuracy: 0.3555 - categorical_crossentropy: 1.4716 - auc_12: 0.5292 - precision_12: 0.3492 - recall_12: 0.1719\n","Results for fold 10\n","8/8 [==============================] - 0s 18ms/step - loss: 1.5880 - categorical_accuracy: 0.3633 - categorical_crossentropy: 1.5880 - auc_12: 0.5186 - precision_12: 0.3103 - recall_12: 0.1758\n","Channel No. 6\n","Results for fold 1\n","8/8 [==============================] - 1s 21ms/step - loss: 1.0970 - categorical_accuracy: 0.3633 - categorical_crossentropy: 1.0970 - auc_13: 0.5440 - precision_13: 0.2000 - recall_13: 0.0039\n","Results for fold 2\n","8/8 [==============================] - 0s 22ms/step - loss: 1.1155 - categorical_accuracy: 0.3828 - categorical_crossentropy: 1.1155 - auc_13: 0.5543 - precision_13: 0.3429 - recall_13: 0.0469\n","Results for fold 3\n","8/8 [==============================] - 0s 17ms/step - loss: 1.1074 - categorical_accuracy: 0.3633 - categorical_crossentropy: 1.1074 - auc_13: 0.5609 - precision_13: 0.4314 - recall_13: 0.0859\n","Results for fold 4\n","8/8 [==============================] - 0s 16ms/step - loss: 1.2144 - categorical_accuracy: 0.3633 - categorical_crossentropy: 1.2144 - auc_13: 0.5471 - precision_13: 0.3895 - recall_13: 0.1445\n","Results for fold 5\n","8/8 [==============================] - 0s 21ms/step - loss: 1.2827 - categorical_accuracy: 0.3633 - categorical_crossentropy: 1.2827 - auc_13: 0.5537 - precision_13: 0.3535 - recall_13: 0.1367\n","Results for fold 6\n","8/8 [==============================] - 0s 16ms/step - loss: 1.2214 - categorical_accuracy: 0.3867 - categorical_crossentropy: 1.2214 - auc_13: 0.5813 - precision_13: 0.4242 - recall_13: 0.1641\n","Results for fold 7\n","8/8 [==============================] - 0s 22ms/step - loss: 1.3583 - categorical_accuracy: 0.3633 - categorical_crossentropy: 1.3583 - auc_13: 0.5552 - precision_13: 0.3826 - recall_13: 0.1719\n","Results for fold 8\n","8/8 [==============================] - 0s 16ms/step - loss: 1.3082 - categorical_accuracy: 0.3867 - categorical_crossentropy: 1.3082 - auc_13: 0.5649 - precision_13: 0.4095 - recall_13: 0.1680\n","Results for fold 9\n","8/8 [==============================] - 0s 21ms/step - loss: 1.3981 - categorical_accuracy: 0.3633 - categorical_crossentropy: 1.3981 - auc_13: 0.5466 - precision_13: 0.3860 - recall_13: 0.1719\n","Results for fold 10\n","8/8 [==============================] - 0s 21ms/step - loss: 1.5072 - categorical_accuracy: 0.3594 - categorical_crossentropy: 1.5072 - auc_13: 0.5300 - precision_13: 0.3659 - recall_13: 0.1758\n","Channel No. 7\n","Results for fold 1\n","8/8 [==============================] - 1s 18ms/step - loss: 1.1483 - categorical_accuracy: 0.3398 - categorical_crossentropy: 1.1483 - auc_14: 0.5127 - precision_14: 0.2581 - recall_14: 0.0312\n","Results for fold 2\n","8/8 [==============================] - 0s 22ms/step - loss: 1.2284 - categorical_accuracy: 0.3438 - categorical_crossentropy: 1.2284 - auc_14: 0.5227 - precision_14: 0.3571 - recall_14: 0.0977\n","Results for fold 3\n","8/8 [==============================] - 0s 22ms/step - loss: 1.2649 - categorical_accuracy: 0.3867 - categorical_crossentropy: 1.2649 - auc_14: 0.5398 - precision_14: 0.3778 - recall_14: 0.1328\n","Results for fold 4\n","8/8 [==============================] - 0s 21ms/step - loss: 1.2894 - categorical_accuracy: 0.3828 - categorical_crossentropy: 1.2894 - auc_14: 0.5460 - precision_14: 0.4423 - recall_14: 0.1797\n","Results for fold 5\n","8/8 [==============================] - 0s 21ms/step - loss: 1.4002 - categorical_accuracy: 0.3711 - categorical_crossentropy: 1.4002 - auc_14: 0.5441 - precision_14: 0.4035 - recall_14: 0.1797\n","Results for fold 6\n","8/8 [==============================] - 0s 21ms/step - loss: 1.5833 - categorical_accuracy: 0.3359 - categorical_crossentropy: 1.5833 - auc_14: 0.4923 - precision_14: 0.3621 - recall_14: 0.1641\n","Results for fold 7\n","8/8 [==============================] - 0s 17ms/step - loss: 1.4715 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.4715 - auc_14: 0.5484 - precision_14: 0.4000 - recall_14: 0.1875\n","Results for fold 8\n","8/8 [==============================] - 0s 23ms/step - loss: 1.4922 - categorical_accuracy: 0.3555 - categorical_crossentropy: 1.4922 - auc_14: 0.5395 - precision_14: 0.3643 - recall_14: 0.1992\n","Results for fold 9\n","8/8 [==============================] - 0s 22ms/step - loss: 1.6241 - categorical_accuracy: 0.3555 - categorical_crossentropy: 1.6241 - auc_14: 0.5379 - precision_14: 0.3857 - recall_14: 0.2109\n","Results for fold 10\n","8/8 [==============================] - 0s 21ms/step - loss: 1.6400 - categorical_accuracy: 0.3516 - categorical_crossentropy: 1.6400 - auc_14: 0.5404 - precision_14: 0.3642 - recall_14: 0.2148\n","Channel No. 8\n","Results for fold 1\n","8/8 [==============================] - 1s 17ms/step - loss: 1.1216 - categorical_accuracy: 0.3398 - categorical_crossentropy: 1.1216 - auc_15: 0.5170 - precision_15: 0.3000 - recall_15: 0.0234\n","Results for fold 2\n","8/8 [==============================] - 0s 21ms/step - loss: 1.1786 - categorical_accuracy: 0.3320 - categorical_crossentropy: 1.1786 - auc_15: 0.5154 - precision_15: 0.3750 - recall_15: 0.0703\n","Results for fold 3\n","8/8 [==============================] - 0s 16ms/step - loss: 1.1898 - categorical_accuracy: 0.2852 - categorical_crossentropy: 1.1898 - auc_15: 0.4984 - precision_15: 0.3651 - recall_15: 0.0898\n","Results for fold 4\n","8/8 [==============================] - 0s 22ms/step - loss: 1.3941 - categorical_accuracy: 0.3242 - categorical_crossentropy: 1.3941 - auc_15: 0.5032 - precision_15: 0.3359 - recall_15: 0.1680\n","Results for fold 5\n","8/8 [==============================] - 0s 18ms/step - loss: 1.3234 - categorical_accuracy: 0.3086 - categorical_crossentropy: 1.3234 - auc_15: 0.5076 - precision_15: 0.3304 - recall_15: 0.1445\n","Results for fold 6\n","8/8 [==============================] - 0s 17ms/step - loss: 1.4919 - categorical_accuracy: 0.3164 - categorical_crossentropy: 1.4919 - auc_15: 0.4948 - precision_15: 0.3121 - recall_15: 0.1719\n","Results for fold 7\n","8/8 [==============================] - 0s 21ms/step - loss: 1.6232 - categorical_accuracy: 0.3086 - categorical_crossentropy: 1.6232 - auc_15: 0.5068 - precision_15: 0.3377 - recall_15: 0.1992\n","Results for fold 8\n","8/8 [==============================] - 0s 16ms/step - loss: 1.6184 - categorical_accuracy: 0.3242 - categorical_crossentropy: 1.6184 - auc_15: 0.5118 - precision_15: 0.3557 - recall_15: 0.2070\n","Results for fold 9\n","8/8 [==============================] - 0s 21ms/step - loss: 1.7352 - categorical_accuracy: 0.3281 - categorical_crossentropy: 1.7352 - auc_15: 0.5077 - precision_15: 0.3392 - recall_15: 0.2266\n","Results for fold 10\n","8/8 [==============================] - 0s 21ms/step - loss: 1.7086 - categorical_accuracy: 0.3047 - categorical_crossentropy: 1.7086 - auc_15: 0.4906 - precision_15: 0.3234 - recall_15: 0.2109\n","Channel No. 9\n","Results for fold 1\n","8/8 [==============================] - 1s 21ms/step - loss: 1.0987 - categorical_accuracy: 0.3594 - categorical_crossentropy: 1.0987 - auc_16: 0.5422 - precision_16: 0.5000 - recall_16: 0.0547\n","Results for fold 2\n","8/8 [==============================] - 0s 20ms/step - loss: 1.1445 - categorical_accuracy: 0.3516 - categorical_crossentropy: 1.1445 - auc_16: 0.5243 - precision_16: 0.2692 - recall_16: 0.0547\n","Results for fold 3\n","8/8 [==============================] - 0s 21ms/step - loss: 1.1797 - categorical_accuracy: 0.3516 - categorical_crossentropy: 1.1797 - auc_16: 0.5315 - precision_16: 0.3382 - recall_16: 0.0898\n","Results for fold 4\n","8/8 [==============================] - 0s 16ms/step - loss: 1.2453 - categorical_accuracy: 0.3711 - categorical_crossentropy: 1.2453 - auc_16: 0.5374 - precision_16: 0.3605 - recall_16: 0.1211\n","Results for fold 5\n","8/8 [==============================] - 0s 21ms/step - loss: 1.3375 - categorical_accuracy: 0.3594 - categorical_crossentropy: 1.3375 - auc_16: 0.5293 - precision_16: 0.3500 - recall_16: 0.1367\n","Results for fold 6\n","8/8 [==============================] - 0s 16ms/step - loss: 1.3628 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.3628 - auc_16: 0.5339 - precision_16: 0.3793 - recall_16: 0.1719\n","Results for fold 7\n","8/8 [==============================] - 0s 22ms/step - loss: 1.4255 - categorical_accuracy: 0.3438 - categorical_crossentropy: 1.4255 - auc_16: 0.5110 - precision_16: 0.3583 - recall_16: 0.1680\n","Results for fold 8\n","8/8 [==============================] - 0s 22ms/step - loss: 1.4932 - categorical_accuracy: 0.3633 - categorical_crossentropy: 1.4932 - auc_16: 0.5328 - precision_16: 0.3588 - recall_16: 0.1836\n","Results for fold 9\n","8/8 [==============================] - 0s 21ms/step - loss: 1.5907 - categorical_accuracy: 0.3477 - categorical_crossentropy: 1.5907 - auc_16: 0.5188 - precision_16: 0.3333 - recall_16: 0.1758\n","Results for fold 10\n","8/8 [==============================] - 0s 22ms/step - loss: 1.4910 - categorical_accuracy: 0.3672 - categorical_crossentropy: 1.4910 - auc_16: 0.5315 - precision_16: 0.3846 - recall_16: 0.1953\n","Channel No. 10\n","Results for fold 1\n","8/8 [==============================] - 1s 17ms/step - loss: 1.1197 - categorical_accuracy: 0.3359 - categorical_crossentropy: 1.1197 - auc_17: 0.5066 - precision_17: 0.2143 - recall_17: 0.0117\n","Results for fold 2\n","8/8 [==============================] - 0s 18ms/step - loss: 1.2274 - categorical_accuracy: 0.3828 - categorical_crossentropy: 1.2274 - auc_17: 0.5391 - precision_17: 0.3803 - recall_17: 0.1055\n","Results for fold 3\n","8/8 [==============================] - 0s 21ms/step - loss: 1.3402 - categorical_accuracy: 0.3672 - categorical_crossentropy: 1.3402 - auc_17: 0.5166 - precision_17: 0.3191 - recall_17: 0.1172\n","Results for fold 4\n","8/8 [==============================] - 0s 17ms/step - loss: 1.3809 - categorical_accuracy: 0.3945 - categorical_crossentropy: 1.3809 - auc_17: 0.5309 - precision_17: 0.3545 - recall_17: 0.1523\n","Results for fold 5\n","8/8 [==============================] - 0s 16ms/step - loss: 1.4259 - categorical_accuracy: 0.3945 - categorical_crossentropy: 1.4259 - auc_17: 0.5412 - precision_17: 0.3438 - recall_17: 0.1719\n","Results for fold 6\n","8/8 [==============================] - 0s 17ms/step - loss: 1.5296 - categorical_accuracy: 0.3594 - categorical_crossentropy: 1.5296 - auc_17: 0.5392 - precision_17: 0.3731 - recall_17: 0.1953\n","Results for fold 7\n","8/8 [==============================] - 0s 21ms/step - loss: 1.5659 - categorical_accuracy: 0.3906 - categorical_crossentropy: 1.5659 - auc_17: 0.5571 - precision_17: 0.4178 - recall_17: 0.2383\n","Results for fold 8\n","8/8 [==============================] - 0s 22ms/step - loss: 1.6563 - categorical_accuracy: 0.4141 - categorical_crossentropy: 1.6563 - auc_17: 0.5687 - precision_17: 0.4464 - recall_17: 0.2930\n","Results for fold 9\n","8/8 [==============================] - 0s 22ms/step - loss: 1.6870 - categorical_accuracy: 0.3828 - categorical_crossentropy: 1.6870 - auc_17: 0.5682 - precision_17: 0.4202 - recall_17: 0.3086\n","Results for fold 10\n","8/8 [==============================] - 0s 21ms/step - loss: 1.7131 - categorical_accuracy: 0.3945 - categorical_crossentropy: 1.7131 - auc_17: 0.5705 - precision_17: 0.4301 - recall_17: 0.3242\n","Channel No. 11\n","Results for fold 1\n","8/8 [==============================] - 1s 18ms/step - loss: 1.0913 - categorical_accuracy: 0.3438 - categorical_crossentropy: 1.0913 - auc_18: 0.5385 - precision_18: 0.5000 - recall_18: 0.0117\n","Results for fold 2\n","8/8 [==============================] - 0s 17ms/step - loss: 1.0992 - categorical_accuracy: 0.3359 - categorical_crossentropy: 1.0992 - auc_18: 0.5433 - precision_18: 0.5294 - recall_18: 0.0703\n","Results for fold 3\n","8/8 [==============================] - 0s 22ms/step - loss: 1.1493 - categorical_accuracy: 0.3320 - categorical_crossentropy: 1.1493 - auc_18: 0.5255 - precision_18: 0.4474 - recall_18: 0.1328\n","Results for fold 4\n","8/8 [==============================] - 0s 17ms/step - loss: 1.2152 - categorical_accuracy: 0.3711 - categorical_crossentropy: 1.2152 - auc_18: 0.5512 - precision_18: 0.4144 - recall_18: 0.1797\n","Results for fold 5\n","8/8 [==============================] - 0s 21ms/step - loss: 1.3267 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.3267 - auc_18: 0.5688 - precision_18: 0.4696 - recall_18: 0.2109\n","Results for fold 6\n","8/8 [==============================] - 0s 21ms/step - loss: 1.3635 - categorical_accuracy: 0.3594 - categorical_crossentropy: 1.3635 - auc_18: 0.5477 - precision_18: 0.4030 - recall_18: 0.2109\n","Results for fold 7\n","8/8 [==============================] - 0s 19ms/step - loss: 1.5011 - categorical_accuracy: 0.3594 - categorical_crossentropy: 1.5011 - auc_18: 0.5396 - precision_18: 0.3835 - recall_18: 0.1992\n","Results for fold 8\n","8/8 [==============================] - 0s 22ms/step - loss: 1.5478 - categorical_accuracy: 0.3555 - categorical_crossentropy: 1.5478 - auc_18: 0.5377 - precision_18: 0.3907 - recall_18: 0.2305\n","Results for fold 9\n","8/8 [==============================] - 0s 22ms/step - loss: 1.6302 - categorical_accuracy: 0.3242 - categorical_crossentropy: 1.6302 - auc_18: 0.5287 - precision_18: 0.3704 - recall_18: 0.2344\n","Results for fold 10\n","8/8 [==============================] - 0s 22ms/step - loss: 1.8209 - categorical_accuracy: 0.3672 - categorical_crossentropy: 1.8209 - auc_18: 0.5535 - precision_18: 0.4078 - recall_18: 0.2852\n","Channel No. 12\n","Results for fold 1\n","8/8 [==============================] - 1s 17ms/step - loss: 1.0803 - categorical_accuracy: 0.3633 - categorical_crossentropy: 1.0803 - auc_19: 0.5445 - precision_19: 0.5000 - recall_19: 0.0352\n","Results for fold 2\n","8/8 [==============================] - 0s 22ms/step - loss: 1.0876 - categorical_accuracy: 0.3906 - categorical_crossentropy: 1.0876 - auc_19: 0.5695 - precision_19: 0.4286 - recall_19: 0.0586\n","Results for fold 3\n","8/8 [==============================] - 0s 22ms/step - loss: 1.1864 - categorical_accuracy: 0.3125 - categorical_crossentropy: 1.1864 - auc_19: 0.5137 - precision_19: 0.3692 - recall_19: 0.0938\n","Results for fold 4\n","8/8 [==============================] - 0s 22ms/step - loss: 1.2939 - categorical_accuracy: 0.3398 - categorical_crossentropy: 1.2939 - auc_19: 0.5381 - precision_19: 0.3765 - recall_19: 0.1250\n","Results for fold 5\n","8/8 [==============================] - 0s 18ms/step - loss: 1.2518 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.2518 - auc_19: 0.5607 - precision_19: 0.4416 - recall_19: 0.1328\n","Results for fold 6\n","8/8 [==============================] - 0s 22ms/step - loss: 1.3699 - categorical_accuracy: 0.3477 - categorical_crossentropy: 1.3699 - auc_19: 0.5201 - precision_19: 0.3827 - recall_19: 0.1211\n","Results for fold 7\n","8/8 [==============================] - 0s 22ms/step - loss: 1.4543 - categorical_accuracy: 0.3672 - categorical_crossentropy: 1.4543 - auc_19: 0.5266 - precision_19: 0.4222 - recall_19: 0.1484\n","Results for fold 8\n","8/8 [==============================] - 0s 17ms/step - loss: 1.4499 - categorical_accuracy: 0.3398 - categorical_crossentropy: 1.4499 - auc_19: 0.5261 - precision_19: 0.3214 - recall_19: 0.1406\n","Results for fold 9\n","8/8 [==============================] - 0s 22ms/step - loss: 1.5763 - categorical_accuracy: 0.3438 - categorical_crossentropy: 1.5763 - auc_19: 0.5164 - precision_19: 0.3130 - recall_19: 0.1406\n","Results for fold 10\n","8/8 [==============================] - 0s 17ms/step - loss: 1.5014 - categorical_accuracy: 0.3594 - categorical_crossentropy: 1.5014 - auc_19: 0.5299 - precision_19: 0.3774 - recall_19: 0.1562\n","Channel No. 13\n","Results for fold 1\n","8/8 [==============================] - 1s 22ms/step - loss: 1.1069 - categorical_accuracy: 0.3555 - categorical_crossentropy: 1.1069 - auc_20: 0.5292 - precision_20: 0.3333 - recall_20: 0.0039\n","Results for fold 2\n","8/8 [==============================] - 0s 18ms/step - loss: 1.1615 - categorical_accuracy: 0.3398 - categorical_crossentropy: 1.1615 - auc_20: 0.5129 - precision_20: 0.1923 - recall_20: 0.0195\n","Results for fold 3\n","8/8 [==============================] - 0s 22ms/step - loss: 1.2148 - categorical_accuracy: 0.3398 - categorical_crossentropy: 1.2148 - auc_20: 0.5359 - precision_20: 0.2963 - recall_20: 0.0625\n","Results for fold 4\n","8/8 [==============================] - 0s 18ms/step - loss: 1.2516 - categorical_accuracy: 0.3555 - categorical_crossentropy: 1.2516 - auc_20: 0.5362 - precision_20: 0.3380 - recall_20: 0.0938\n","Results for fold 5\n","8/8 [==============================] - 0s 22ms/step - loss: 1.3067 - categorical_accuracy: 0.3672 - categorical_crossentropy: 1.3067 - auc_20: 0.5430 - precision_20: 0.3646 - recall_20: 0.1367\n","Results for fold 6\n","8/8 [==============================] - 0s 18ms/step - loss: 1.4377 - categorical_accuracy: 0.3516 - categorical_crossentropy: 1.4377 - auc_20: 0.5159 - precision_20: 0.3529 - recall_20: 0.1406\n","Results for fold 7\n","8/8 [==============================] - 0s 18ms/step - loss: 1.4648 - categorical_accuracy: 0.3477 - categorical_crossentropy: 1.4648 - auc_20: 0.5273 - precision_20: 0.3396 - recall_20: 0.1406\n","Results for fold 8\n","8/8 [==============================] - 0s 22ms/step - loss: 1.5446 - categorical_accuracy: 0.3633 - categorical_crossentropy: 1.5446 - auc_20: 0.5378 - precision_20: 0.3884 - recall_20: 0.1836\n","Results for fold 9\n","8/8 [==============================] - 0s 22ms/step - loss: 1.6631 - categorical_accuracy: 0.3711 - categorical_crossentropy: 1.6631 - auc_20: 0.5391 - precision_20: 0.3788 - recall_20: 0.1953\n","Results for fold 10\n","8/8 [==============================] - 0s 22ms/step - loss: 1.7197 - categorical_accuracy: 0.4180 - categorical_crossentropy: 1.7197 - auc_20: 0.5699 - precision_20: 0.4345 - recall_20: 0.2461\n","Channel No. 14\n","Results for fold 1\n","8/8 [==============================] - 1s 19ms/step - loss: 1.1097 - categorical_accuracy: 0.3086 - categorical_crossentropy: 1.1097 - auc_21: 0.4864 - precision_21: 0.6000 - recall_21: 0.0117\n","Results for fold 2\n","8/8 [==============================] - 0s 22ms/step - loss: 1.1509 - categorical_accuracy: 0.3281 - categorical_crossentropy: 1.1509 - auc_21: 0.5067 - precision_21: 0.2333 - recall_21: 0.0273\n","Results for fold 3\n","8/8 [==============================] - 0s 22ms/step - loss: 1.1637 - categorical_accuracy: 0.3359 - categorical_crossentropy: 1.1637 - auc_21: 0.5164 - precision_21: 0.3556 - recall_21: 0.0625\n","Results for fold 4\n","8/8 [==============================] - 0s 21ms/step - loss: 1.1879 - categorical_accuracy: 0.3438 - categorical_crossentropy: 1.1879 - auc_21: 0.5166 - precision_21: 0.2593 - recall_21: 0.0547\n","Results for fold 5\n","8/8 [==============================] - 0s 22ms/step - loss: 1.2634 - categorical_accuracy: 0.3359 - categorical_crossentropy: 1.2634 - auc_21: 0.5156 - precision_21: 0.3088 - recall_21: 0.0820\n","Results for fold 6\n","8/8 [==============================] - 0s 17ms/step - loss: 1.2672 - categorical_accuracy: 0.3398 - categorical_crossentropy: 1.2672 - auc_21: 0.5161 - precision_21: 0.3038 - recall_21: 0.0938\n","Results for fold 7\n","8/8 [==============================] - 0s 17ms/step - loss: 1.2809 - categorical_accuracy: 0.3438 - categorical_crossentropy: 1.2809 - auc_21: 0.5255 - precision_21: 0.3614 - recall_21: 0.1172\n","Results for fold 8\n","8/8 [==============================] - 0s 18ms/step - loss: 1.3450 - categorical_accuracy: 0.3320 - categorical_crossentropy: 1.3450 - auc_21: 0.5153 - precision_21: 0.3333 - recall_21: 0.1250\n","Results for fold 9\n","8/8 [==============================] - 0s 18ms/step - loss: 1.3266 - categorical_accuracy: 0.3359 - categorical_crossentropy: 1.3266 - auc_21: 0.5188 - precision_21: 0.3667 - recall_21: 0.1289\n","Results for fold 10\n","8/8 [==============================] - 0s 19ms/step - loss: 1.3634 - categorical_accuracy: 0.3281 - categorical_crossentropy: 1.3634 - auc_21: 0.5148 - precision_21: 0.3679 - recall_21: 0.1523\n","Channel No. 15\n","Results for fold 1\n","8/8 [==============================] - 1s 17ms/step - loss: 1.1121 - categorical_accuracy: 0.3008 - categorical_crossentropy: 1.1121 - auc_22: 0.4810 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n","Results for fold 2\n","8/8 [==============================] - 0s 19ms/step - loss: 1.1336 - categorical_accuracy: 0.3242 - categorical_crossentropy: 1.1336 - auc_22: 0.4929 - precision_22: 0.2963 - recall_22: 0.0312\n","Results for fold 3\n","8/8 [==============================] - 0s 16ms/step - loss: 1.1629 - categorical_accuracy: 0.3281 - categorical_crossentropy: 1.1629 - auc_22: 0.5128 - precision_22: 0.2889 - recall_22: 0.0508\n","Results for fold 4\n","8/8 [==============================] - 0s 18ms/step - loss: 1.2931 - categorical_accuracy: 0.3477 - categorical_crossentropy: 1.2931 - auc_22: 0.5110 - precision_22: 0.2424 - recall_22: 0.0625\n","Results for fold 5\n","8/8 [==============================] - 0s 22ms/step - loss: 1.2532 - categorical_accuracy: 0.3438 - categorical_crossentropy: 1.2532 - auc_22: 0.5058 - precision_22: 0.3115 - recall_22: 0.0742\n","Results for fold 6\n","8/8 [==============================] - 0s 21ms/step - loss: 1.3671 - categorical_accuracy: 0.3242 - categorical_crossentropy: 1.3671 - auc_22: 0.4866 - precision_22: 0.3034 - recall_22: 0.1055\n","Results for fold 7\n","8/8 [==============================] - 0s 18ms/step - loss: 1.4726 - categorical_accuracy: 0.3281 - categorical_crossentropy: 1.4726 - auc_22: 0.4866 - precision_22: 0.2778 - recall_22: 0.0977\n","Results for fold 8\n","8/8 [==============================] - 0s 23ms/step - loss: 1.5243 - categorical_accuracy: 0.3164 - categorical_crossentropy: 1.5243 - auc_22: 0.4850 - precision_22: 0.2982 - recall_22: 0.1328\n","Results for fold 9\n","8/8 [==============================] - 0s 18ms/step - loss: 1.5908 - categorical_accuracy: 0.3359 - categorical_crossentropy: 1.5908 - auc_22: 0.4970 - precision_22: 0.3307 - recall_22: 0.1641\n","Results for fold 10\n","8/8 [==============================] - 0s 18ms/step - loss: 1.6358 - categorical_accuracy: 0.3398 - categorical_crossentropy: 1.6358 - auc_22: 0.4876 - precision_22: 0.3077 - recall_22: 0.1562\n","Channel No. 16\n","Results for fold 1\n","8/8 [==============================] - 1s 18ms/step - loss: 1.1021 - categorical_accuracy: 0.3398 - categorical_crossentropy: 1.1021 - auc_23: 0.5063 - precision_23: 0.3333 - recall_23: 0.0234\n","Results for fold 2\n","8/8 [==============================] - 0s 22ms/step - loss: 1.1435 - categorical_accuracy: 0.3555 - categorical_crossentropy: 1.1435 - auc_23: 0.5177 - precision_23: 0.4286 - recall_23: 0.0586\n","Results for fold 3\n","8/8 [==============================] - 0s 18ms/step - loss: 1.1597 - categorical_accuracy: 0.3945 - categorical_crossentropy: 1.1597 - auc_23: 0.5441 - precision_23: 0.4364 - recall_23: 0.0938\n","Results for fold 4\n","8/8 [==============================] - 0s 19ms/step - loss: 1.2245 - categorical_accuracy: 0.3594 - categorical_crossentropy: 1.2245 - auc_23: 0.5363 - precision_23: 0.4409 - recall_23: 0.1602\n","Results for fold 5\n","8/8 [==============================] - 0s 23ms/step - loss: 1.3276 - categorical_accuracy: 0.3516 - categorical_crossentropy: 1.3276 - auc_23: 0.5309 - precision_23: 0.3909 - recall_23: 0.1680\n","Results for fold 6\n","8/8 [==============================] - 0s 22ms/step - loss: 1.5084 - categorical_accuracy: 0.3711 - categorical_crossentropy: 1.5084 - auc_23: 0.5392 - precision_23: 0.4080 - recall_23: 0.1992\n","Results for fold 7\n","8/8 [==============================] - 0s 23ms/step - loss: 1.5098 - categorical_accuracy: 0.3945 - categorical_crossentropy: 1.5098 - auc_23: 0.5580 - precision_23: 0.4161 - recall_23: 0.2422\n","Results for fold 8\n","8/8 [==============================] - 0s 21ms/step - loss: 1.6949 - categorical_accuracy: 0.3984 - categorical_crossentropy: 1.6949 - auc_23: 0.5503 - precision_23: 0.4194 - recall_23: 0.2539\n","Results for fold 9\n","8/8 [==============================] - 0s 22ms/step - loss: 1.6580 - categorical_accuracy: 0.3594 - categorical_crossentropy: 1.6580 - auc_23: 0.5388 - precision_23: 0.3949 - recall_23: 0.2422\n","Results for fold 10\n","8/8 [==============================] - 0s 19ms/step - loss: 1.8091 - categorical_accuracy: 0.3828 - categorical_crossentropy: 1.8091 - auc_23: 0.5437 - precision_23: 0.3855 - recall_23: 0.2695\n","Channel No. 17\n","Results for fold 1\n","8/8 [==============================] - 1s 22ms/step - loss: 1.1217 - categorical_accuracy: 0.3359 - categorical_crossentropy: 1.1217 - auc_24: 0.4817 - precision_24: 0.2963 - recall_24: 0.0312\n","Results for fold 2\n","8/8 [==============================] - 0s 23ms/step - loss: 1.1734 - categorical_accuracy: 0.3555 - categorical_crossentropy: 1.1734 - auc_24: 0.5148 - precision_24: 0.3585 - recall_24: 0.0742\n","Results for fold 3\n","8/8 [==============================] - 0s 23ms/step - loss: 1.2906 - categorical_accuracy: 0.3594 - categorical_crossentropy: 1.2906 - auc_24: 0.5160 - precision_24: 0.3333 - recall_24: 0.1016\n","Results for fold 4\n","8/8 [==============================] - 0s 19ms/step - loss: 1.2819 - categorical_accuracy: 0.3633 - categorical_crossentropy: 1.2819 - auc_24: 0.5398 - precision_24: 0.4235 - recall_24: 0.1406\n","Results for fold 5\n","8/8 [==============================] - 0s 23ms/step - loss: 1.4444 - categorical_accuracy: 0.3828 - categorical_crossentropy: 1.4444 - auc_24: 0.5498 - precision_24: 0.4000 - recall_24: 0.1484\n","Results for fold 6\n","8/8 [==============================] - 0s 23ms/step - loss: 1.3299 - categorical_accuracy: 0.3672 - categorical_crossentropy: 1.3299 - auc_24: 0.5403 - precision_24: 0.4000 - recall_24: 0.1406\n","Results for fold 7\n","8/8 [==============================] - 0s 17ms/step - loss: 1.4756 - categorical_accuracy: 0.3945 - categorical_crossentropy: 1.4756 - auc_24: 0.5380 - precision_24: 0.4535 - recall_24: 0.1523\n","Results for fold 8\n","8/8 [==============================] - 0s 18ms/step - loss: 1.4917 - categorical_accuracy: 0.3555 - categorical_crossentropy: 1.4917 - auc_24: 0.5180 - precision_24: 0.4245 - recall_24: 0.1758\n","Results for fold 9\n","8/8 [==============================] - 0s 22ms/step - loss: 1.4727 - categorical_accuracy: 0.3906 - categorical_crossentropy: 1.4727 - auc_24: 0.5375 - precision_24: 0.4466 - recall_24: 0.1797\n","Results for fold 10\n","8/8 [==============================] - 0s 23ms/step - loss: 1.4301 - categorical_accuracy: 0.3867 - categorical_crossentropy: 1.4301 - auc_24: 0.5563 - precision_24: 0.4483 - recall_24: 0.2031\n","Channel No. 18\n","Results for fold 1\n","8/8 [==============================] - 1s 23ms/step - loss: 1.1449 - categorical_accuracy: 0.3203 - categorical_crossentropy: 1.1449 - auc_25: 0.4934 - precision_25: 0.2174 - recall_25: 0.0195\n","Results for fold 2\n","8/8 [==============================] - 0s 20ms/step - loss: 1.1772 - categorical_accuracy: 0.3281 - categorical_crossentropy: 1.1772 - auc_25: 0.5078 - precision_25: 0.1667 - recall_25: 0.0234\n","Results for fold 3\n","8/8 [==============================] - 0s 18ms/step - loss: 1.2696 - categorical_accuracy: 0.3672 - categorical_crossentropy: 1.2696 - auc_25: 0.4963 - precision_25: 0.2857 - recall_25: 0.0625\n","Results for fold 4\n","8/8 [==============================] - 0s 22ms/step - loss: 1.3225 - categorical_accuracy: 0.3477 - categorical_crossentropy: 1.3225 - auc_25: 0.4818 - precision_25: 0.2949 - recall_25: 0.0898\n","Results for fold 5\n","8/8 [==============================] - 0s 23ms/step - loss: 1.3675 - categorical_accuracy: 0.3633 - categorical_crossentropy: 1.3675 - auc_25: 0.4944 - precision_25: 0.3068 - recall_25: 0.1055\n","Results for fold 6\n","8/8 [==============================] - 0s 23ms/step - loss: 1.4356 - categorical_accuracy: 0.3672 - categorical_crossentropy: 1.4356 - auc_25: 0.4952 - precision_25: 0.3558 - recall_25: 0.1445\n","Results for fold 7\n","8/8 [==============================] - 0s 19ms/step - loss: 1.4309 - categorical_accuracy: 0.3516 - categorical_crossentropy: 1.4309 - auc_25: 0.5012 - precision_25: 0.3304 - recall_25: 0.1445\n","Results for fold 8\n","8/8 [==============================] - 0s 19ms/step - loss: 1.6767 - categorical_accuracy: 0.3477 - categorical_crossentropy: 1.6767 - auc_25: 0.4964 - precision_25: 0.3492 - recall_25: 0.1719\n","Results for fold 9\n","8/8 [==============================] - 0s 22ms/step - loss: 1.6223 - categorical_accuracy: 0.3789 - categorical_crossentropy: 1.6223 - auc_25: 0.5081 - precision_25: 0.3431 - recall_25: 0.1836\n","Results for fold 10\n","8/8 [==============================] - 0s 19ms/step - loss: 1.6835 - categorical_accuracy: 0.3828 - categorical_crossentropy: 1.6835 - auc_25: 0.5132 - precision_25: 0.3542 - recall_25: 0.1992\n","Channel No. 19\n","Results for fold 1\n","8/8 [==============================] - 1s 18ms/step - loss: 1.1157 - categorical_accuracy: 0.3320 - categorical_crossentropy: 1.1157 - auc_26: 0.4940 - precision_26: 0.2000 - recall_26: 0.0039\n","Results for fold 2\n","8/8 [==============================] - 0s 19ms/step - loss: 1.1511 - categorical_accuracy: 0.2891 - categorical_crossentropy: 1.1511 - auc_26: 0.4444 - precision_26: 0.3810 - recall_26: 0.0312\n","Results for fold 3\n","8/8 [==============================] - 0s 22ms/step - loss: 1.1760 - categorical_accuracy: 0.3477 - categorical_crossentropy: 1.1760 - auc_26: 0.4813 - precision_26: 0.3514 - recall_26: 0.0508\n","Results for fold 4\n","8/8 [==============================] - 0s 18ms/step - loss: 1.2615 - categorical_accuracy: 0.3516 - categorical_crossentropy: 1.2615 - auc_26: 0.5037 - precision_26: 0.3250 - recall_26: 0.1016\n","Results for fold 5\n","8/8 [==============================] - 0s 22ms/step - loss: 1.2836 - categorical_accuracy: 0.3516 - categorical_crossentropy: 1.2836 - auc_26: 0.5044 - precision_26: 0.3556 - recall_26: 0.1250\n","Results for fold 6\n","8/8 [==============================] - 0s 23ms/step - loss: 1.3276 - categorical_accuracy: 0.3320 - categorical_crossentropy: 1.3276 - auc_26: 0.4876 - precision_26: 0.3400 - recall_26: 0.1328\n","Results for fold 7\n","8/8 [==============================] - 0s 23ms/step - loss: 1.4527 - categorical_accuracy: 0.3828 - categorical_crossentropy: 1.4527 - auc_26: 0.5080 - precision_26: 0.3594 - recall_26: 0.1797\n","Results for fold 8\n","8/8 [==============================] - 0s 23ms/step - loss: 1.4385 - categorical_accuracy: 0.3516 - categorical_crossentropy: 1.4385 - auc_26: 0.5205 - precision_26: 0.3939 - recall_26: 0.2031\n","Results for fold 9\n","8/8 [==============================] - 0s 18ms/step - loss: 1.6420 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.6420 - auc_26: 0.5174 - precision_26: 0.3571 - recall_26: 0.1953\n","Results for fold 10\n","8/8 [==============================] - 0s 22ms/step - loss: 1.5368 - categorical_accuracy: 0.3828 - categorical_crossentropy: 1.5368 - auc_26: 0.5401 - precision_26: 0.4027 - recall_26: 0.2344\n","Channel No. 20\n","Results for fold 1\n","8/8 [==============================] - 1s 20ms/step - loss: 1.1154 - categorical_accuracy: 0.3359 - categorical_crossentropy: 1.1154 - auc_27: 0.5016 - precision_27: 0.2500 - recall_27: 0.0156\n","Results for fold 2\n","8/8 [==============================] - 0s 17ms/step - loss: 1.1098 - categorical_accuracy: 0.3633 - categorical_crossentropy: 1.1098 - auc_27: 0.5168 - precision_27: 0.4138 - recall_27: 0.0469\n","Results for fold 3\n","8/8 [==============================] - 0s 16ms/step - loss: 1.1323 - categorical_accuracy: 0.3516 - categorical_crossentropy: 1.1323 - auc_27: 0.5224 - precision_27: 0.5000 - recall_27: 0.0859\n","Results for fold 4\n","8/8 [==============================] - 0s 19ms/step - loss: 1.2598 - categorical_accuracy: 0.3398 - categorical_crossentropy: 1.2598 - auc_27: 0.5136 - precision_27: 0.3088 - recall_27: 0.0820\n","Results for fold 5\n","8/8 [==============================] - 0s 22ms/step - loss: 1.2693 - categorical_accuracy: 0.3359 - categorical_crossentropy: 1.2693 - auc_27: 0.5282 - precision_27: 0.3718 - recall_27: 0.1133\n","Results for fold 6\n","8/8 [==============================] - 0s 23ms/step - loss: 1.2650 - categorical_accuracy: 0.3633 - categorical_crossentropy: 1.2650 - auc_27: 0.5313 - precision_27: 0.3929 - recall_27: 0.1289\n","Results for fold 7\n","8/8 [==============================] - 0s 23ms/step - loss: 1.3265 - categorical_accuracy: 0.3125 - categorical_crossentropy: 1.3265 - auc_27: 0.4952 - precision_27: 0.3636 - recall_27: 0.1406\n","Results for fold 8\n","8/8 [==============================] - 0s 19ms/step - loss: 1.4428 - categorical_accuracy: 0.3320 - categorical_crossentropy: 1.4428 - auc_27: 0.5196 - precision_27: 0.3895 - recall_27: 0.1445\n","Results for fold 9\n","8/8 [==============================] - 0s 19ms/step - loss: 1.3243 - categorical_accuracy: 0.3594 - categorical_crossentropy: 1.3243 - auc_27: 0.5390 - precision_27: 0.4239 - recall_27: 0.1523\n","Results for fold 10\n","8/8 [==============================] - 0s 22ms/step - loss: 1.4232 - categorical_accuracy: 0.3672 - categorical_crossentropy: 1.4232 - auc_27: 0.5432 - precision_27: 0.4245 - recall_27: 0.1758\n","Channel No. 21\n","Results for fold 1\n","8/8 [==============================] - 1s 24ms/step - loss: 1.1060 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.1060 - auc_28: 0.5108 - precision_28: 0.4545 - recall_28: 0.0195\n","Results for fold 2\n","8/8 [==============================] - 0s 23ms/step - loss: 1.1337 - categorical_accuracy: 0.3242 - categorical_crossentropy: 1.1337 - auc_28: 0.5159 - precision_28: 0.2857 - recall_28: 0.0391\n","Results for fold 3\n","8/8 [==============================] - 0s 18ms/step - loss: 1.1880 - categorical_accuracy: 0.3516 - categorical_crossentropy: 1.1880 - auc_28: 0.5315 - precision_28: 0.4474 - recall_28: 0.1328\n","Results for fold 4\n","8/8 [==============================] - 0s 19ms/step - loss: 1.2250 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.2250 - auc_28: 0.5445 - precision_28: 0.3824 - recall_28: 0.1523\n","Results for fold 5\n","8/8 [==============================] - 0s 23ms/step - loss: 1.2371 - categorical_accuracy: 0.3867 - categorical_crossentropy: 1.2371 - auc_28: 0.5589 - precision_28: 0.4426 - recall_28: 0.2109\n","Results for fold 6\n","8/8 [==============================] - 0s 24ms/step - loss: 1.2966 - categorical_accuracy: 0.3945 - categorical_crossentropy: 1.2966 - auc_28: 0.5720 - precision_28: 0.4191 - recall_28: 0.2227\n","Results for fold 7\n","8/8 [==============================] - 0s 17ms/step - loss: 1.3342 - categorical_accuracy: 0.4023 - categorical_crossentropy: 1.3342 - auc_28: 0.5743 - precision_28: 0.4295 - recall_28: 0.2500\n","Results for fold 8\n","8/8 [==============================] - 0s 19ms/step - loss: 1.4304 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.4304 - auc_28: 0.5963 - precision_28: 0.5091 - recall_28: 0.3281\n","Results for fold 9\n","8/8 [==============================] - 0s 23ms/step - loss: 1.5641 - categorical_accuracy: 0.4258 - categorical_crossentropy: 1.5641 - auc_28: 0.5866 - precision_28: 0.4310 - recall_28: 0.2930\n","Results for fold 10\n","8/8 [==============================] - 0s 25ms/step - loss: 1.5790 - categorical_accuracy: 0.3945 - categorical_crossentropy: 1.5790 - auc_28: 0.5896 - precision_28: 0.4525 - recall_28: 0.3164\n","Channel No. 22\n","Results for fold 1\n","8/8 [==============================] - 1s 22ms/step - loss: 1.1348 - categorical_accuracy: 0.3594 - categorical_crossentropy: 1.1348 - auc_29: 0.5158 - precision_29: 0.3571 - recall_29: 0.0391\n","Results for fold 2\n","8/8 [==============================] - 0s 23ms/step - loss: 1.1430 - categorical_accuracy: 0.3672 - categorical_crossentropy: 1.1430 - auc_29: 0.5269 - precision_29: 0.5278 - recall_29: 0.0742\n","Results for fold 3\n","8/8 [==============================] - 0s 23ms/step - loss: 1.2510 - categorical_accuracy: 0.3359 - categorical_crossentropy: 1.2510 - auc_29: 0.5265 - precision_29: 0.4000 - recall_29: 0.1094\n","Results for fold 4\n","8/8 [==============================] - 0s 19ms/step - loss: 1.2910 - categorical_accuracy: 0.3477 - categorical_crossentropy: 1.2910 - auc_29: 0.5149 - precision_29: 0.3902 - recall_29: 0.1250\n","Results for fold 5\n","8/8 [==============================] - 0s 19ms/step - loss: 1.3255 - categorical_accuracy: 0.3867 - categorical_crossentropy: 1.3255 - auc_29: 0.5488 - precision_29: 0.4070 - recall_29: 0.1367\n","Results for fold 6\n","8/8 [==============================] - 0s 23ms/step - loss: 1.3979 - categorical_accuracy: 0.3945 - categorical_crossentropy: 1.3979 - auc_29: 0.5589 - precision_29: 0.4215 - recall_29: 0.1992\n","Results for fold 7\n","8/8 [==============================] - 0s 24ms/step - loss: 1.4330 - categorical_accuracy: 0.3672 - categorical_crossentropy: 1.4330 - auc_29: 0.5294 - precision_29: 0.4016 - recall_29: 0.1914\n","Results for fold 8\n","8/8 [==============================] - 0s 23ms/step - loss: 1.4122 - categorical_accuracy: 0.3789 - categorical_crossentropy: 1.4122 - auc_29: 0.5632 - precision_29: 0.4571 - recall_29: 0.2500\n","Results for fold 9\n","8/8 [==============================] - 0s 24ms/step - loss: 1.6105 - categorical_accuracy: 0.3789 - categorical_crossentropy: 1.6105 - auc_29: 0.5458 - precision_29: 0.4133 - recall_29: 0.2422\n","Results for fold 10\n","8/8 [==============================] - 0s 19ms/step - loss: 1.6553 - categorical_accuracy: 0.4023 - categorical_crossentropy: 1.6553 - auc_29: 0.5642 - precision_29: 0.4452 - recall_29: 0.2695\n","Channel No. 23\n","Results for fold 1\n","8/8 [==============================] - 1s 23ms/step - loss: 1.1058 - categorical_accuracy: 0.3945 - categorical_crossentropy: 1.1058 - auc_30: 0.4799 - precision_30: 0.0000e+00 - recall_30: 0.0000e+00\n","Results for fold 2\n","8/8 [==============================] - 0s 23ms/step - loss: 1.1211 - categorical_accuracy: 0.3555 - categorical_crossentropy: 1.1211 - auc_30: 0.4874 - precision_30: 0.3077 - recall_30: 0.0156\n","Results for fold 3\n","8/8 [==============================] - 0s 22ms/step - loss: 1.1641 - categorical_accuracy: 0.3711 - categorical_crossentropy: 1.1641 - auc_30: 0.5111 - precision_30: 0.4000 - recall_30: 0.0625\n","Results for fold 4\n","8/8 [==============================] - 0s 23ms/step - loss: 1.1667 - categorical_accuracy: 0.3398 - categorical_crossentropy: 1.1667 - auc_30: 0.4820 - precision_30: 0.3939 - recall_30: 0.0508\n","Results for fold 5\n","8/8 [==============================] - 0s 20ms/step - loss: 1.2570 - categorical_accuracy: 0.3281 - categorical_crossentropy: 1.2570 - auc_30: 0.4747 - precision_30: 0.2982 - recall_30: 0.0664\n","Results for fold 6\n","8/8 [==============================] - 0s 18ms/step - loss: 1.3070 - categorical_accuracy: 0.3398 - categorical_crossentropy: 1.3070 - auc_30: 0.4869 - precision_30: 0.3462 - recall_30: 0.1055\n","Results for fold 7\n","8/8 [==============================] - 0s 24ms/step - loss: 1.2947 - categorical_accuracy: 0.3242 - categorical_crossentropy: 1.2947 - auc_30: 0.4902 - precision_30: 0.3256 - recall_30: 0.1094\n","Results for fold 8\n","8/8 [==============================] - 0s 20ms/step - loss: 1.4002 - categorical_accuracy: 0.3242 - categorical_crossentropy: 1.4002 - auc_30: 0.5047 - precision_30: 0.3130 - recall_30: 0.1406\n","Results for fold 9\n","8/8 [==============================] - 0s 19ms/step - loss: 1.3444 - categorical_accuracy: 0.3867 - categorical_crossentropy: 1.3444 - auc_30: 0.5406 - precision_30: 0.3774 - recall_30: 0.1562\n","Results for fold 10\n","8/8 [==============================] - 0s 24ms/step - loss: 1.5163 - categorical_accuracy: 0.3789 - categorical_crossentropy: 1.5163 - auc_30: 0.5275 - precision_30: 0.3780 - recall_30: 0.1875\n","Channel No. 24\n","Results for fold 1\n","8/8 [==============================] - 1s 23ms/step - loss: 1.1070 - categorical_accuracy: 0.3281 - categorical_crossentropy: 1.1070 - auc_31: 0.5032 - precision_31: 0.2000 - recall_31: 0.0039\n","Results for fold 2\n","8/8 [==============================] - 0s 22ms/step - loss: 1.1629 - categorical_accuracy: 0.3281 - categorical_crossentropy: 1.1629 - auc_31: 0.4848 - precision_31: 0.3721 - recall_31: 0.0625\n","Results for fold 3\n","8/8 [==============================] - 0s 23ms/step - loss: 1.1772 - categorical_accuracy: 0.3711 - categorical_crossentropy: 1.1772 - auc_31: 0.5216 - precision_31: 0.3226 - recall_31: 0.0781\n","Results for fold 4\n","8/8 [==============================] - 0s 23ms/step - loss: 1.2109 - categorical_accuracy: 0.3320 - categorical_crossentropy: 1.2109 - auc_31: 0.5204 - precision_31: 0.3676 - recall_31: 0.0977\n","Results for fold 5\n","8/8 [==============================] - 0s 19ms/step - loss: 1.3080 - categorical_accuracy: 0.3438 - categorical_crossentropy: 1.3080 - auc_31: 0.5168 - precision_31: 0.3871 - recall_31: 0.1406\n","Results for fold 6\n","8/8 [==============================] - 0s 20ms/step - loss: 1.2743 - categorical_accuracy: 0.3828 - categorical_crossentropy: 1.2743 - auc_31: 0.5379 - precision_31: 0.4086 - recall_31: 0.1484\n","Results for fold 7\n","8/8 [==============================] - 0s 22ms/step - loss: 1.4254 - categorical_accuracy: 0.3477 - categorical_crossentropy: 1.4254 - auc_31: 0.5223 - precision_31: 0.3596 - recall_31: 0.1602\n","Results for fold 8\n","8/8 [==============================] - 0s 23ms/step - loss: 1.4320 - categorical_accuracy: 0.3359 - categorical_crossentropy: 1.4320 - auc_31: 0.5149 - precision_31: 0.3304 - recall_31: 0.1445\n","Results for fold 9\n","8/8 [==============================] - 0s 19ms/step - loss: 1.3152 - categorical_accuracy: 0.3789 - categorical_crossentropy: 1.3152 - auc_31: 0.5452 - precision_31: 0.4153 - recall_31: 0.1914\n","Results for fold 10\n","8/8 [==============================] - 0s 23ms/step - loss: 1.3966 - categorical_accuracy: 0.3516 - categorical_crossentropy: 1.3966 - auc_31: 0.5341 - precision_31: 0.3760 - recall_31: 0.1836\n","Channel No. 25\n","Results for fold 1\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zlez-VyLj-MX","executionInfo":{"status":"ok","timestamp":1638892061436,"user_tz":-360,"elapsed":517,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"53e20d6c-d416-4354-dedf-69d147bb743c"},"source":["xf_test = np.asarray(xf_test, dtype = np.float32)\n","Xf_train = np.asarray(Xf_train, dtype = np.float32)\n","df = []\n","for i in range(X_train.shape[0]):\n","  df.append(Xf_train[:,i,:])\n","X_train = np.reshape(df,[-1,32,512,1])\n","df = []\n","for i in range(x_test.shape[0]):\n","  df.append(xf_test[:,i,:])\n","x_test = np.reshape(df,[-1,32,512,1])\n","del df, Xf_train, xf_test\n","print(X_train.shape, x_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(1024, 32, 512, 1) (256, 32, 512, 1)\n"]}]},{"cell_type":"code","metadata":{"id":"ZMIgYspBlikO"},"source":["def get_channel_attention(x):\n","  y = AvgPool2D(pool_size=(1,512), name='AvgPool2D_1')(x)\n","  y = Flatten(name='Flatten_1')(y)\n","  y = Dense(8,activation='tanh', name='Dense_1') (y)\n","  y = BatchNormalization(name='BatchNormalization_1')(y)\n","  y = Dropout(0.3, name='Dropout_1')(y)\n","  y = Dense(32,activation='sigmoid', name='Dense_2') (y)\n","  z = []\n","  for i in range(x.shape[2]):\n","    z.append(y)\n","  y = Concatenate(name='Concatenate_1')(z)\n","  y = Reshape((32, 512, 1), name='Reshape_1')(y)\n","  x = Multiply(name='Multiply_1')([x,y])\n","  #x = Reshape((32, 512, 1), name='Reshape_2')(x)\n","  return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"arJXucz2niy9","executionInfo":{"status":"ok","timestamp":1638896259235,"user_tz":-360,"elapsed":548,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"953565e0-77a1-48d3-a5c6-5ffffdf84c70"},"source":["def get_model() :\n","  input_shape = (X_train.shape[1],X_train.shape[2],1)\n","  a = Input(input_shape, name='Input')\n","  x = get_channel_attention(a)\n","  x = Conv2D(filters=16, kernel_size=(3,3), strides=(1,1), padding='same', name='Conv2D_1')(x)\n","  x = BatchNormalization(name='BatchNormalization_2')(x)\n","  x = Dropout(0.2, name='Dropout_2')(x)\n","  x = MaxPooling2D(pool_size=(2,4), name='MaxPooling2D_1')(x)\n","  x = Conv2D(filters=32, kernel_size=(5,5), strides=(1,1), padding='same', name='Conv2D_2')(x)\n","  x = BatchNormalization(name='BatchNormalization_3')(x)\n","  x = Dropout(0.2, name='Dropout_3')(x)\n","  x = MaxPooling2D(pool_size=(2,4), name='MaxPooling2D_2')(x)\n","  x = Conv2D(filters=64, kernel_size=(7,7), strides=(1,1), padding='same', name='Conv2D_3')(x)\n","  x = BatchNormalization(name='BatchNormalization_4')(x)\n","  x = Dropout(0.2, name='Dropout_4')(x)\n","  x = MaxPooling2D(pool_size=(2,4), name='MaxPooling2D_3')(x)\n","  x = Flatten(name='Flatten_2')(x)\n","  x = Dense(512,activation='tanh', name='Dense_3')(x)\n","  x = Dropout(0.4, name='Dropout_5')(x)\n","  x = Dense(32,activation='relu', name='Dense_4')(x)\n","  x = Dropout(0.4, name='Dropout_6')(x)\n","  x = Dense(3,activation='softmax', name='Dense_5')(x)\n","  model = Model(a, x)\n","  opt = keras.optimizers.Adam(learning_rate=0.01)\n","  model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n","  return model\n","model = get_model()\n","print(model.summary())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_81\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," Input (InputLayer)             [(None, 32, 512, 1)  0           []                               \n","                                ]                                                                 \n","                                                                                                  \n"," AvgPool2D_1 (AveragePooling2D)  (None, 32, 1, 1)    0           ['Input[0][0]']                  \n","                                                                                                  \n"," Flatten_1 (Flatten)            (None, 32)           0           ['AvgPool2D_1[0][0]']            \n","                                                                                                  \n"," Dense_1 (Dense)                (None, 8)            264         ['Flatten_1[0][0]']              \n","                                                                                                  \n"," BatchNormalization_1 (BatchNor  (None, 8)           32          ['Dense_1[0][0]']                \n"," malization)                                                                                      \n","                                                                                                  \n"," Dropout_1 (Dropout)            (None, 8)            0           ['BatchNormalization_1[0][0]']   \n","                                                                                                  \n"," Dense_2 (Dense)                (None, 32)           288         ['Dropout_1[0][0]']              \n","                                                                                                  \n"," Concatenate_1 (Concatenate)    (None, 16384)        0           ['Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]']                \n","                                                                                                  \n"," Reshape_1 (Reshape)            (None, 32, 512, 1)   0           ['Concatenate_1[0][0]']          \n","                                                                                                  \n"," Multiply_1 (Multiply)          (None, 32, 512, 1)   0           ['Input[0][0]',                  \n","                                                                  'Reshape_1[0][0]']              \n","                                                                                                  \n"," Conv2D_1 (Conv2D)              (None, 32, 512, 16)  160         ['Multiply_1[0][0]']             \n","                                                                                                  \n"," BatchNormalization_2 (BatchNor  (None, 32, 512, 16)  64         ['Conv2D_1[0][0]']               \n"," malization)                                                                                      \n","                                                                                                  \n"," Dropout_2 (Dropout)            (None, 32, 512, 16)  0           ['BatchNormalization_2[0][0]']   \n","                                                                                                  \n"," MaxPooling2D_1 (MaxPooling2D)  (None, 16, 128, 16)  0           ['Dropout_2[0][0]']              \n","                                                                                                  \n"," Conv2D_2 (Conv2D)              (None, 16, 128, 32)  12832       ['MaxPooling2D_1[0][0]']         \n","                                                                                                  \n"," BatchNormalization_3 (BatchNor  (None, 16, 128, 32)  128        ['Conv2D_2[0][0]']               \n"," malization)                                                                                      \n","                                                                                                  \n"," Dropout_3 (Dropout)            (None, 16, 128, 32)  0           ['BatchNormalization_3[0][0]']   \n","                                                                                                  \n"," MaxPooling2D_2 (MaxPooling2D)  (None, 8, 32, 32)    0           ['Dropout_3[0][0]']              \n","                                                                                                  \n"," Conv2D_3 (Conv2D)              (None, 8, 32, 64)    100416      ['MaxPooling2D_2[0][0]']         \n","                                                                                                  \n"," BatchNormalization_4 (BatchNor  (None, 8, 32, 64)   256         ['Conv2D_3[0][0]']               \n"," malization)                                                                                      \n","                                                                                                  \n"," Dropout_4 (Dropout)            (None, 8, 32, 64)    0           ['BatchNormalization_4[0][0]']   \n","                                                                                                  \n"," MaxPooling2D_3 (MaxPooling2D)  (None, 4, 8, 64)     0           ['Dropout_4[0][0]']              \n","                                                                                                  \n"," Flatten_2 (Flatten)            (None, 2048)         0           ['MaxPooling2D_3[0][0]']         \n","                                                                                                  \n"," Dense_3 (Dense)                (None, 512)          1049088     ['Flatten_2[0][0]']              \n","                                                                                                  \n"," Dropout_5 (Dropout)            (None, 512)          0           ['Dense_3[0][0]']                \n","                                                                                                  \n"," Dense_4 (Dense)                (None, 32)           16416       ['Dropout_5[0][0]']              \n","                                                                                                  \n"," Dropout_6 (Dropout)            (None, 32)           0           ['Dense_4[0][0]']                \n","                                                                                                  \n"," Dense_5 (Dense)                (None, 3)            99          ['Dropout_6[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 1,180,043\n","Trainable params: 1,179,803\n","Non-trainable params: 240\n","__________________________________________________________________________________________________\n","None\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jQLmeppEysrM","executionInfo":{"status":"ok","timestamp":1638896634350,"user_tz":-360,"elapsed":368918,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"c85b3482-4466-4bec-efd9-6a2bb72b4824"},"source":["foldNum=0\n","model = get_model()\n","for train_index, val_index in kfold.split(X_train, Y_train):\n","  foldNum = foldNum + 1\n","  print(\"Results for fold\",foldNum)\n","  x_train, x_val = X_train[train_index], X_train[val_index]\n","  y_train, y_val = Y_train[train_index], Y_train[val_index]\n","  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n","  del x_train, x_val, y_train, y_val\n","  gc.collect()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Results for fold 1\n","Epoch 1/30\n","15/15 [==============================] - 4s 103ms/step - loss: 1.3236 - accuracy: 0.3355 - val_loss: 1.1002 - val_accuracy: 0.4369\n","Epoch 2/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0879 - accuracy: 0.4343 - val_loss: 1.0914 - val_accuracy: 0.4369\n","Epoch 3/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0794 - accuracy: 0.4343 - val_loss: 1.0855 - val_accuracy: 0.4369\n","Epoch 4/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0769 - accuracy: 0.4343 - val_loss: 1.0838 - val_accuracy: 0.4369\n","Epoch 5/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0767 - accuracy: 0.4343 - val_loss: 1.0830 - val_accuracy: 0.4369\n","Epoch 6/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0766 - accuracy: 0.4343 - val_loss: 1.0800 - val_accuracy: 0.4369\n","Epoch 7/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0766 - accuracy: 0.4343 - val_loss: 1.0812 - val_accuracy: 0.4369\n","Epoch 8/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0767 - accuracy: 0.4343 - val_loss: 1.0818 - val_accuracy: 0.4369\n","Epoch 9/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0767 - accuracy: 0.4343 - val_loss: 1.0787 - val_accuracy: 0.4369\n","Epoch 10/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0766 - accuracy: 0.4343 - val_loss: 1.0809 - val_accuracy: 0.4369\n","Epoch 11/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0766 - accuracy: 0.4343 - val_loss: 1.0807 - val_accuracy: 0.4369\n","Epoch 12/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0772 - accuracy: 0.4343 - val_loss: 1.0818 - val_accuracy: 0.4369\n","Epoch 13/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0767 - accuracy: 0.4343 - val_loss: 1.0796 - val_accuracy: 0.4369\n","Epoch 14/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0767 - accuracy: 0.4343 - val_loss: 1.0780 - val_accuracy: 0.4369\n","Epoch 15/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0766 - accuracy: 0.4343 - val_loss: 1.0801 - val_accuracy: 0.4369\n","Epoch 16/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0766 - accuracy: 0.4343 - val_loss: 1.0809 - val_accuracy: 0.4369\n","Epoch 17/30\n","15/15 [==============================] - 1s 57ms/step - loss: 1.0766 - accuracy: 0.4343 - val_loss: 1.0803 - val_accuracy: 0.4369\n","Epoch 18/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0770 - accuracy: 0.4343 - val_loss: 1.0761 - val_accuracy: 0.4369\n","Epoch 19/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0766 - accuracy: 0.4343 - val_loss: 1.0792 - val_accuracy: 0.4369\n","Epoch 20/30\n","15/15 [==============================] - 1s 52ms/step - loss: 1.0768 - accuracy: 0.4343 - val_loss: 1.0819 - val_accuracy: 0.4369\n","Epoch 21/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0766 - accuracy: 0.4343 - val_loss: 1.0806 - val_accuracy: 0.4369\n","Epoch 22/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0768 - accuracy: 0.4343 - val_loss: 1.0786 - val_accuracy: 0.4369\n","Epoch 23/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0767 - accuracy: 0.4343 - val_loss: 1.0820 - val_accuracy: 0.4369\n","Epoch 24/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0766 - accuracy: 0.4343 - val_loss: 1.0826 - val_accuracy: 0.4369\n","Epoch 25/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0766 - accuracy: 0.4343 - val_loss: 1.0824 - val_accuracy: 0.4369\n","Epoch 26/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0768 - accuracy: 0.4343 - val_loss: 1.0798 - val_accuracy: 0.4369\n","Epoch 27/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0766 - accuracy: 0.4343 - val_loss: 1.0806 - val_accuracy: 0.4369\n","Epoch 28/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0767 - accuracy: 0.4343 - val_loss: 1.0810 - val_accuracy: 0.4369\n","Epoch 29/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0766 - accuracy: 0.4343 - val_loss: 1.0815 - val_accuracy: 0.4369\n","Epoch 30/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0777 - accuracy: 0.4343 - val_loss: 1.0783 - val_accuracy: 0.4369\n","Results for fold 2\n","Epoch 1/30\n","15/15 [==============================] - 1s 65ms/step - loss: 1.0739 - accuracy: 0.4430 - val_loss: 1.1108 - val_accuracy: 0.3592\n","Epoch 2/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0726 - accuracy: 0.4430 - val_loss: 1.1156 - val_accuracy: 0.3592\n","Epoch 3/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0728 - accuracy: 0.4430 - val_loss: 1.1204 - val_accuracy: 0.3592\n","Epoch 4/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0726 - accuracy: 0.4430 - val_loss: 1.1178 - val_accuracy: 0.3592\n","Epoch 5/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0724 - accuracy: 0.4430 - val_loss: 1.1197 - val_accuracy: 0.3592\n","Epoch 6/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0727 - accuracy: 0.4430 - val_loss: 1.1200 - val_accuracy: 0.3592\n","Epoch 7/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0728 - accuracy: 0.4430 - val_loss: 1.1152 - val_accuracy: 0.3592\n","Epoch 8/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0726 - accuracy: 0.4430 - val_loss: 1.1155 - val_accuracy: 0.3592\n","Epoch 9/30\n","15/15 [==============================] - 1s 52ms/step - loss: 1.0724 - accuracy: 0.4430 - val_loss: 1.1205 - val_accuracy: 0.3592\n","Epoch 10/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0727 - accuracy: 0.4430 - val_loss: 1.1216 - val_accuracy: 0.3592\n","Epoch 11/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0723 - accuracy: 0.4430 - val_loss: 1.1203 - val_accuracy: 0.3592\n","Epoch 12/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0724 - accuracy: 0.4430 - val_loss: 1.1180 - val_accuracy: 0.3592\n","Epoch 13/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0723 - accuracy: 0.4430 - val_loss: 1.1183 - val_accuracy: 0.3592\n","Epoch 14/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0727 - accuracy: 0.4430 - val_loss: 1.1214 - val_accuracy: 0.3592\n","Epoch 15/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0724 - accuracy: 0.4430 - val_loss: 1.1191 - val_accuracy: 0.3592\n","Epoch 16/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0725 - accuracy: 0.4430 - val_loss: 1.1221 - val_accuracy: 0.3592\n","Epoch 17/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0723 - accuracy: 0.4430 - val_loss: 1.1184 - val_accuracy: 0.3592\n","Epoch 18/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0723 - accuracy: 0.4430 - val_loss: 1.1188 - val_accuracy: 0.3592\n","Epoch 19/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0728 - accuracy: 0.4430 - val_loss: 1.1218 - val_accuracy: 0.3592\n","Epoch 20/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0730 - accuracy: 0.4430 - val_loss: 1.1148 - val_accuracy: 0.3592\n","Epoch 21/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0727 - accuracy: 0.4430 - val_loss: 1.1185 - val_accuracy: 0.3592\n","Epoch 22/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0725 - accuracy: 0.4430 - val_loss: 1.1169 - val_accuracy: 0.3592\n","Epoch 23/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0725 - accuracy: 0.4430 - val_loss: 1.1175 - val_accuracy: 0.3592\n","Epoch 24/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0725 - accuracy: 0.4430 - val_loss: 1.1232 - val_accuracy: 0.3592\n","Epoch 25/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0727 - accuracy: 0.4430 - val_loss: 1.1209 - val_accuracy: 0.3592\n","Epoch 26/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0724 - accuracy: 0.4430 - val_loss: 1.1200 - val_accuracy: 0.3592\n","Epoch 27/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0723 - accuracy: 0.4430 - val_loss: 1.1196 - val_accuracy: 0.3592\n","Epoch 28/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0730 - accuracy: 0.4430 - val_loss: 1.1219 - val_accuracy: 0.3592\n","Epoch 29/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0722 - accuracy: 0.4430 - val_loss: 1.1196 - val_accuracy: 0.3592\n","Epoch 30/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0723 - accuracy: 0.4430 - val_loss: 1.1176 - val_accuracy: 0.3592\n","Results for fold 3\n","Epoch 1/30\n","15/15 [==============================] - 1s 61ms/step - loss: 1.0760 - accuracy: 0.4376 - val_loss: 1.0895 - val_accuracy: 0.4078\n","Epoch 2/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0756 - accuracy: 0.4376 - val_loss: 1.0879 - val_accuracy: 0.4078\n","Epoch 3/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0755 - accuracy: 0.4376 - val_loss: 1.0879 - val_accuracy: 0.4078\n","Epoch 4/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0753 - accuracy: 0.4376 - val_loss: 1.0883 - val_accuracy: 0.4078\n","Epoch 5/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0753 - accuracy: 0.4376 - val_loss: 1.0884 - val_accuracy: 0.4078\n","Epoch 6/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0754 - accuracy: 0.4376 - val_loss: 1.0884 - val_accuracy: 0.4078\n","Epoch 7/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0753 - accuracy: 0.4376 - val_loss: 1.0888 - val_accuracy: 0.4078\n","Epoch 8/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0752 - accuracy: 0.4376 - val_loss: 1.0890 - val_accuracy: 0.4078\n","Epoch 9/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0754 - accuracy: 0.4376 - val_loss: 1.0894 - val_accuracy: 0.4078\n","Epoch 10/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0752 - accuracy: 0.4376 - val_loss: 1.0884 - val_accuracy: 0.4078\n","Epoch 11/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0757 - accuracy: 0.4376 - val_loss: 1.0891 - val_accuracy: 0.4078\n","Epoch 12/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0755 - accuracy: 0.4376 - val_loss: 1.0881 - val_accuracy: 0.4078\n","Epoch 13/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0753 - accuracy: 0.4376 - val_loss: 1.0883 - val_accuracy: 0.4078\n","Epoch 14/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0753 - accuracy: 0.4376 - val_loss: 1.0888 - val_accuracy: 0.4078\n","Epoch 15/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0753 - accuracy: 0.4376 - val_loss: 1.0887 - val_accuracy: 0.4078\n","Epoch 16/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0753 - accuracy: 0.4376 - val_loss: 1.0882 - val_accuracy: 0.4078\n","Epoch 17/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0755 - accuracy: 0.4376 - val_loss: 1.0884 - val_accuracy: 0.4078\n","Epoch 18/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0753 - accuracy: 0.4376 - val_loss: 1.0885 - val_accuracy: 0.4078\n","Epoch 19/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0753 - accuracy: 0.4376 - val_loss: 1.0885 - val_accuracy: 0.4078\n","Epoch 20/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0756 - accuracy: 0.4376 - val_loss: 1.0889 - val_accuracy: 0.4078\n","Epoch 21/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0754 - accuracy: 0.4376 - val_loss: 1.0885 - val_accuracy: 0.4078\n","Epoch 22/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0754 - accuracy: 0.4376 - val_loss: 1.0880 - val_accuracy: 0.4078\n","Epoch 23/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0756 - accuracy: 0.4376 - val_loss: 1.0894 - val_accuracy: 0.4078\n","Epoch 24/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0756 - accuracy: 0.4376 - val_loss: 1.0885 - val_accuracy: 0.4078\n","Epoch 25/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0753 - accuracy: 0.4376 - val_loss: 1.0885 - val_accuracy: 0.4078\n","Epoch 26/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0756 - accuracy: 0.4376 - val_loss: 1.0889 - val_accuracy: 0.4078\n","Epoch 27/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0763 - accuracy: 0.4376 - val_loss: 1.0880 - val_accuracy: 0.4078\n","Epoch 28/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0760 - accuracy: 0.4376 - val_loss: 1.0898 - val_accuracy: 0.4078\n","Epoch 29/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0754 - accuracy: 0.4376 - val_loss: 1.0888 - val_accuracy: 0.4078\n","Epoch 30/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0756 - accuracy: 0.4376 - val_loss: 1.0891 - val_accuracy: 0.4078\n","Results for fold 4\n","Epoch 1/30\n","15/15 [==============================] - 1s 64ms/step - loss: 1.0771 - accuracy: 0.4343 - val_loss: 1.0760 - val_accuracy: 0.4369\n","Epoch 2/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0767 - accuracy: 0.4343 - val_loss: 1.0759 - val_accuracy: 0.4369\n","Epoch 3/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0768 - accuracy: 0.4343 - val_loss: 1.0757 - val_accuracy: 0.4369\n","Epoch 4/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0767 - accuracy: 0.4343 - val_loss: 1.0760 - val_accuracy: 0.4369\n","Epoch 5/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0770 - accuracy: 0.4343 - val_loss: 1.0764 - val_accuracy: 0.4369\n","Epoch 6/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0768 - accuracy: 0.4343 - val_loss: 1.0758 - val_accuracy: 0.4369\n","Epoch 7/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0767 - accuracy: 0.4343 - val_loss: 1.0757 - val_accuracy: 0.4369\n","Epoch 8/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0774 - accuracy: 0.4343 - val_loss: 1.0755 - val_accuracy: 0.4369\n","Epoch 9/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0768 - accuracy: 0.4343 - val_loss: 1.0764 - val_accuracy: 0.4369\n","Epoch 10/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0768 - accuracy: 0.4343 - val_loss: 1.0766 - val_accuracy: 0.4369\n","Epoch 11/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0772 - accuracy: 0.4343 - val_loss: 1.0755 - val_accuracy: 0.4369\n","Epoch 12/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0769 - accuracy: 0.4343 - val_loss: 1.0757 - val_accuracy: 0.4369\n","Epoch 13/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0766 - accuracy: 0.4343 - val_loss: 1.0758 - val_accuracy: 0.4369\n","Epoch 14/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0767 - accuracy: 0.4343 - val_loss: 1.0758 - val_accuracy: 0.4369\n","Epoch 15/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0773 - accuracy: 0.4343 - val_loss: 1.0761 - val_accuracy: 0.4369\n","Epoch 16/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0766 - accuracy: 0.4343 - val_loss: 1.0758 - val_accuracy: 0.4369\n","Epoch 17/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0768 - accuracy: 0.4343 - val_loss: 1.0758 - val_accuracy: 0.4369\n","Epoch 18/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0768 - accuracy: 0.4343 - val_loss: 1.0756 - val_accuracy: 0.4369\n","Epoch 19/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0769 - accuracy: 0.4343 - val_loss: 1.0759 - val_accuracy: 0.4369\n","Epoch 20/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0770 - accuracy: 0.4343 - val_loss: 1.0757 - val_accuracy: 0.4369\n","Epoch 21/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0768 - accuracy: 0.4343 - val_loss: 1.0757 - val_accuracy: 0.4369\n","Epoch 22/30\n","15/15 [==============================] - 1s 58ms/step - loss: 1.0776 - accuracy: 0.4343 - val_loss: 1.0761 - val_accuracy: 0.4369\n","Epoch 23/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0769 - accuracy: 0.4343 - val_loss: 1.0758 - val_accuracy: 0.4369\n","Epoch 24/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0768 - accuracy: 0.4343 - val_loss: 1.0762 - val_accuracy: 0.4369\n","Epoch 25/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0769 - accuracy: 0.4343 - val_loss: 1.0760 - val_accuracy: 0.4369\n","Epoch 26/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0767 - accuracy: 0.4343 - val_loss: 1.0761 - val_accuracy: 0.4369\n","Epoch 27/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0767 - accuracy: 0.4343 - val_loss: 1.0766 - val_accuracy: 0.4369\n","Epoch 28/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0769 - accuracy: 0.4343 - val_loss: 1.0762 - val_accuracy: 0.4369\n","Epoch 29/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0767 - accuracy: 0.4343 - val_loss: 1.0758 - val_accuracy: 0.4369\n","Epoch 30/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0766 - accuracy: 0.4343 - val_loss: 1.0759 - val_accuracy: 0.4369\n","Results for fold 5\n","Epoch 1/30\n","15/15 [==============================] - 1s 80ms/step - loss: 1.0803 - accuracy: 0.4273 - val_loss: 1.0452 - val_accuracy: 0.5000\n","Epoch 2/30\n","15/15 [==============================] - 1s 58ms/step - loss: 1.0798 - accuracy: 0.4273 - val_loss: 1.0490 - val_accuracy: 0.5000\n","Epoch 3/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0801 - accuracy: 0.4273 - val_loss: 1.0511 - val_accuracy: 0.5000\n","Epoch 4/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0795 - accuracy: 0.4273 - val_loss: 1.0514 - val_accuracy: 0.5000\n","Epoch 5/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0797 - accuracy: 0.4273 - val_loss: 1.0521 - val_accuracy: 0.5000\n","Epoch 6/30\n","15/15 [==============================] - 1s 52ms/step - loss: 1.0796 - accuracy: 0.4273 - val_loss: 1.0560 - val_accuracy: 0.5000\n","Epoch 7/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0796 - accuracy: 0.4273 - val_loss: 1.0549 - val_accuracy: 0.5000\n","Epoch 8/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0797 - accuracy: 0.4273 - val_loss: 1.0544 - val_accuracy: 0.5000\n","Epoch 9/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0798 - accuracy: 0.4273 - val_loss: 1.0532 - val_accuracy: 0.5000\n","Epoch 10/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0811 - accuracy: 0.4273 - val_loss: 1.0560 - val_accuracy: 0.5000\n","Epoch 11/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0796 - accuracy: 0.4273 - val_loss: 1.0534 - val_accuracy: 0.5000\n","Epoch 12/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0798 - accuracy: 0.4273 - val_loss: 1.0552 - val_accuracy: 0.5000\n","Epoch 13/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0797 - accuracy: 0.4273 - val_loss: 1.0515 - val_accuracy: 0.5000\n","Epoch 14/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0799 - accuracy: 0.4273 - val_loss: 1.0530 - val_accuracy: 0.5000\n","Epoch 15/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0795 - accuracy: 0.4273 - val_loss: 1.0550 - val_accuracy: 0.5000\n","Epoch 16/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0797 - accuracy: 0.4273 - val_loss: 1.0574 - val_accuracy: 0.5000\n","Epoch 17/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0796 - accuracy: 0.4273 - val_loss: 1.0541 - val_accuracy: 0.5000\n","Epoch 18/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0807 - accuracy: 0.4273 - val_loss: 1.0586 - val_accuracy: 0.5000\n","Epoch 19/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0798 - accuracy: 0.4273 - val_loss: 1.0510 - val_accuracy: 0.5000\n","Epoch 20/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0796 - accuracy: 0.4273 - val_loss: 1.0497 - val_accuracy: 0.5000\n","Epoch 21/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0799 - accuracy: 0.4273 - val_loss: 1.0492 - val_accuracy: 0.5000\n","Epoch 22/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0796 - accuracy: 0.4273 - val_loss: 1.0523 - val_accuracy: 0.5000\n","Epoch 23/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0797 - accuracy: 0.4273 - val_loss: 1.0549 - val_accuracy: 0.5000\n","Epoch 24/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0799 - accuracy: 0.4273 - val_loss: 1.0529 - val_accuracy: 0.5000\n","Epoch 25/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0795 - accuracy: 0.4273 - val_loss: 1.0521 - val_accuracy: 0.5000\n","Epoch 26/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0797 - accuracy: 0.4273 - val_loss: 1.0552 - val_accuracy: 0.5000\n","Epoch 27/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0796 - accuracy: 0.4273 - val_loss: 1.0537 - val_accuracy: 0.5000\n","Epoch 28/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0796 - accuracy: 0.4273 - val_loss: 1.0520 - val_accuracy: 0.5000\n","Epoch 29/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0798 - accuracy: 0.4273 - val_loss: 1.0536 - val_accuracy: 0.5000\n","Epoch 30/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0796 - accuracy: 0.4273 - val_loss: 1.0519 - val_accuracy: 0.5000\n","Results for fold 6\n","Epoch 1/30\n","15/15 [==============================] - 1s 67ms/step - loss: 1.0750 - accuracy: 0.4393 - val_loss: 1.0941 - val_accuracy: 0.3922\n","Epoch 2/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0750 - accuracy: 0.4393 - val_loss: 1.0945 - val_accuracy: 0.3922\n","Epoch 3/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0746 - accuracy: 0.4393 - val_loss: 1.0971 - val_accuracy: 0.3922\n","Epoch 4/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0745 - accuracy: 0.4393 - val_loss: 1.0960 - val_accuracy: 0.3922\n","Epoch 5/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0746 - accuracy: 0.4393 - val_loss: 1.0957 - val_accuracy: 0.3922\n","Epoch 6/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0745 - accuracy: 0.4393 - val_loss: 1.0957 - val_accuracy: 0.3922\n","Epoch 7/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0747 - accuracy: 0.4393 - val_loss: 1.0945 - val_accuracy: 0.3922\n","Epoch 8/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0749 - accuracy: 0.4393 - val_loss: 1.0955 - val_accuracy: 0.3922\n","Epoch 9/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0745 - accuracy: 0.4393 - val_loss: 1.0959 - val_accuracy: 0.3922\n","Epoch 10/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0745 - accuracy: 0.4393 - val_loss: 1.0963 - val_accuracy: 0.3922\n","Epoch 11/30\n","15/15 [==============================] - 1s 57ms/step - loss: 1.0745 - accuracy: 0.4393 - val_loss: 1.0970 - val_accuracy: 0.3922\n","Epoch 12/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0748 - accuracy: 0.4393 - val_loss: 1.0973 - val_accuracy: 0.3922\n","Epoch 13/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0744 - accuracy: 0.4393 - val_loss: 1.0966 - val_accuracy: 0.3922\n","Epoch 14/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0747 - accuracy: 0.4393 - val_loss: 1.0946 - val_accuracy: 0.3922\n","Epoch 15/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0747 - accuracy: 0.4393 - val_loss: 1.0945 - val_accuracy: 0.3922\n","Epoch 16/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0745 - accuracy: 0.4393 - val_loss: 1.0957 - val_accuracy: 0.3922\n","Epoch 17/30\n","15/15 [==============================] - 1s 57ms/step - loss: 1.0747 - accuracy: 0.4393 - val_loss: 1.0960 - val_accuracy: 0.3922\n","Epoch 18/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0746 - accuracy: 0.4393 - val_loss: 1.0969 - val_accuracy: 0.3922\n","Epoch 19/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0745 - accuracy: 0.4393 - val_loss: 1.0964 - val_accuracy: 0.3922\n","Epoch 20/30\n","15/15 [==============================] - 1s 52ms/step - loss: 1.0745 - accuracy: 0.4393 - val_loss: 1.0958 - val_accuracy: 0.3922\n","Epoch 21/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0746 - accuracy: 0.4393 - val_loss: 1.0964 - val_accuracy: 0.3922\n","Epoch 22/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0746 - accuracy: 0.4393 - val_loss: 1.0962 - val_accuracy: 0.3922\n","Epoch 23/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0746 - accuracy: 0.4393 - val_loss: 1.0962 - val_accuracy: 0.3922\n","Epoch 24/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0749 - accuracy: 0.4393 - val_loss: 1.0971 - val_accuracy: 0.3922\n","Epoch 25/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0746 - accuracy: 0.4393 - val_loss: 1.0959 - val_accuracy: 0.3922\n","Epoch 26/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0745 - accuracy: 0.4393 - val_loss: 1.0964 - val_accuracy: 0.3922\n","Epoch 27/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0748 - accuracy: 0.4393 - val_loss: 1.0961 - val_accuracy: 0.3922\n","Epoch 28/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0746 - accuracy: 0.4393 - val_loss: 1.0960 - val_accuracy: 0.3922\n","Epoch 29/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0748 - accuracy: 0.4393 - val_loss: 1.0946 - val_accuracy: 0.3922\n","Epoch 30/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0747 - accuracy: 0.4393 - val_loss: 1.0957 - val_accuracy: 0.3922\n","Results for fold 7\n","Epoch 1/30\n","15/15 [==============================] - 1s 63ms/step - loss: 1.0755 - accuracy: 0.4371 - val_loss: 1.0881 - val_accuracy: 0.4118\n","Epoch 2/30\n","15/15 [==============================] - 1s 59ms/step - loss: 1.0765 - accuracy: 0.4371 - val_loss: 1.0924 - val_accuracy: 0.4118\n","Epoch 3/30\n","15/15 [==============================] - 1s 58ms/step - loss: 1.0755 - accuracy: 0.4371 - val_loss: 1.0894 - val_accuracy: 0.4118\n","Epoch 4/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0755 - accuracy: 0.4371 - val_loss: 1.0890 - val_accuracy: 0.4118\n","Epoch 5/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0752 - accuracy: 0.4371 - val_loss: 1.0906 - val_accuracy: 0.4118\n","Epoch 6/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0752 - accuracy: 0.4371 - val_loss: 1.0915 - val_accuracy: 0.4118\n","Epoch 7/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0758 - accuracy: 0.4371 - val_loss: 1.0917 - val_accuracy: 0.4118\n","Epoch 8/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0759 - accuracy: 0.4371 - val_loss: 1.0893 - val_accuracy: 0.4118\n","Epoch 9/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0753 - accuracy: 0.4371 - val_loss: 1.0903 - val_accuracy: 0.4118\n","Epoch 10/30\n","15/15 [==============================] - 1s 59ms/step - loss: 1.0755 - accuracy: 0.4371 - val_loss: 1.0911 - val_accuracy: 0.4118\n","Epoch 11/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0753 - accuracy: 0.4371 - val_loss: 1.0919 - val_accuracy: 0.4118\n","Epoch 12/30\n","15/15 [==============================] - 1s 57ms/step - loss: 1.0754 - accuracy: 0.4371 - val_loss: 1.0900 - val_accuracy: 0.4118\n","Epoch 13/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0757 - accuracy: 0.4371 - val_loss: 1.0909 - val_accuracy: 0.4118\n","Epoch 14/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0756 - accuracy: 0.4371 - val_loss: 1.0910 - val_accuracy: 0.4118\n","Epoch 15/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0754 - accuracy: 0.4371 - val_loss: 1.0906 - val_accuracy: 0.4118\n","Epoch 16/30\n","15/15 [==============================] - 1s 53ms/step - loss: 1.0753 - accuracy: 0.4371 - val_loss: 1.0906 - val_accuracy: 0.4118\n","Epoch 17/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0755 - accuracy: 0.4371 - val_loss: 1.0914 - val_accuracy: 0.4118\n","Epoch 18/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0759 - accuracy: 0.4371 - val_loss: 1.0906 - val_accuracy: 0.4118\n","Epoch 19/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0754 - accuracy: 0.4371 - val_loss: 1.0897 - val_accuracy: 0.4118\n","Epoch 20/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0753 - accuracy: 0.4371 - val_loss: 1.0897 - val_accuracy: 0.4118\n","Epoch 21/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0753 - accuracy: 0.4371 - val_loss: 1.0903 - val_accuracy: 0.4118\n","Epoch 22/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0756 - accuracy: 0.4371 - val_loss: 1.0907 - val_accuracy: 0.4118\n","Epoch 23/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0754 - accuracy: 0.4371 - val_loss: 1.0887 - val_accuracy: 0.4118\n","Epoch 24/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0754 - accuracy: 0.4371 - val_loss: 1.0894 - val_accuracy: 0.4118\n","Epoch 25/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0755 - accuracy: 0.4371 - val_loss: 1.0903 - val_accuracy: 0.4118\n","Epoch 26/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0756 - accuracy: 0.4371 - val_loss: 1.0918 - val_accuracy: 0.4118\n","Epoch 27/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0754 - accuracy: 0.4371 - val_loss: 1.0888 - val_accuracy: 0.4118\n","Epoch 28/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0755 - accuracy: 0.4371 - val_loss: 1.0901 - val_accuracy: 0.4118\n","Epoch 29/30\n","15/15 [==============================] - 1s 57ms/step - loss: 1.0757 - accuracy: 0.4371 - val_loss: 1.0893 - val_accuracy: 0.4118\n","Epoch 30/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0755 - accuracy: 0.4371 - val_loss: 1.0908 - val_accuracy: 0.4118\n","Results for fold 8\n","Epoch 1/30\n","15/15 [==============================] - 1s 57ms/step - loss: 1.0786 - accuracy: 0.4306 - val_loss: 1.0608 - val_accuracy: 0.4706\n","Epoch 2/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0783 - accuracy: 0.4306 - val_loss: 1.0618 - val_accuracy: 0.4706\n","Epoch 3/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0782 - accuracy: 0.4306 - val_loss: 1.0615 - val_accuracy: 0.4706\n","Epoch 4/30\n","15/15 [==============================] - 1s 58ms/step - loss: 1.0782 - accuracy: 0.4306 - val_loss: 1.0611 - val_accuracy: 0.4706\n","Epoch 5/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0784 - accuracy: 0.4306 - val_loss: 1.0612 - val_accuracy: 0.4706\n","Epoch 6/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0784 - accuracy: 0.4306 - val_loss: 1.0608 - val_accuracy: 0.4706\n","Epoch 7/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0784 - accuracy: 0.4306 - val_loss: 1.0615 - val_accuracy: 0.4706\n","Epoch 8/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0784 - accuracy: 0.4306 - val_loss: 1.0607 - val_accuracy: 0.4706\n","Epoch 9/30\n","15/15 [==============================] - 1s 58ms/step - loss: 1.0787 - accuracy: 0.4306 - val_loss: 1.0621 - val_accuracy: 0.4706\n","Epoch 10/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0786 - accuracy: 0.4306 - val_loss: 1.0610 - val_accuracy: 0.4706\n","Epoch 11/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0784 - accuracy: 0.4306 - val_loss: 1.0609 - val_accuracy: 0.4706\n","Epoch 12/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0787 - accuracy: 0.4306 - val_loss: 1.0610 - val_accuracy: 0.4706\n","Epoch 13/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0783 - accuracy: 0.4306 - val_loss: 1.0606 - val_accuracy: 0.4706\n","Epoch 14/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0789 - accuracy: 0.4306 - val_loss: 1.0611 - val_accuracy: 0.4706\n","Epoch 15/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0784 - accuracy: 0.4306 - val_loss: 1.0607 - val_accuracy: 0.4706\n","Epoch 16/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0784 - accuracy: 0.4306 - val_loss: 1.0614 - val_accuracy: 0.4706\n","Epoch 17/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0784 - accuracy: 0.4306 - val_loss: 1.0615 - val_accuracy: 0.4706\n","Epoch 18/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0784 - accuracy: 0.4306 - val_loss: 1.0617 - val_accuracy: 0.4706\n","Epoch 19/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0785 - accuracy: 0.4306 - val_loss: 1.0608 - val_accuracy: 0.4706\n","Epoch 20/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0784 - accuracy: 0.4306 - val_loss: 1.0614 - val_accuracy: 0.4706\n","Epoch 21/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0783 - accuracy: 0.4306 - val_loss: 1.0613 - val_accuracy: 0.4706\n","Epoch 22/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0784 - accuracy: 0.4306 - val_loss: 1.0615 - val_accuracy: 0.4706\n","Epoch 23/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0786 - accuracy: 0.4306 - val_loss: 1.0615 - val_accuracy: 0.4706\n","Epoch 24/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0782 - accuracy: 0.4306 - val_loss: 1.0623 - val_accuracy: 0.4706\n","Epoch 25/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0784 - accuracy: 0.4306 - val_loss: 1.0621 - val_accuracy: 0.4706\n","Epoch 26/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0785 - accuracy: 0.4306 - val_loss: 1.0622 - val_accuracy: 0.4706\n","Epoch 27/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0784 - accuracy: 0.4306 - val_loss: 1.0616 - val_accuracy: 0.4706\n","Epoch 28/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0784 - accuracy: 0.4306 - val_loss: 1.0609 - val_accuracy: 0.4706\n","Epoch 29/30\n","15/15 [==============================] - 1s 57ms/step - loss: 1.0784 - accuracy: 0.4306 - val_loss: 1.0617 - val_accuracy: 0.4706\n","Epoch 30/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0786 - accuracy: 0.4306 - val_loss: 1.0614 - val_accuracy: 0.4706\n","Results for fold 9\n","Epoch 1/30\n","15/15 [==============================] - 1s 57ms/step - loss: 1.0780 - accuracy: 0.4317 - val_loss: 1.0655 - val_accuracy: 0.4608\n","Epoch 2/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0780 - accuracy: 0.4317 - val_loss: 1.0651 - val_accuracy: 0.4608\n","Epoch 3/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0778 - accuracy: 0.4317 - val_loss: 1.0657 - val_accuracy: 0.4608\n","Epoch 4/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0782 - accuracy: 0.4317 - val_loss: 1.0664 - val_accuracy: 0.4608\n","Epoch 5/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0781 - accuracy: 0.4317 - val_loss: 1.0657 - val_accuracy: 0.4608\n","Epoch 6/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0777 - accuracy: 0.4317 - val_loss: 1.0661 - val_accuracy: 0.4608\n","Epoch 7/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0780 - accuracy: 0.4317 - val_loss: 1.0661 - val_accuracy: 0.4608\n","Epoch 8/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0779 - accuracy: 0.4317 - val_loss: 1.0657 - val_accuracy: 0.4608\n","Epoch 9/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0779 - accuracy: 0.4317 - val_loss: 1.0658 - val_accuracy: 0.4608\n","Epoch 10/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0779 - accuracy: 0.4317 - val_loss: 1.0666 - val_accuracy: 0.4608\n","Epoch 11/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0785 - accuracy: 0.4317 - val_loss: 1.0669 - val_accuracy: 0.4608\n","Epoch 12/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0777 - accuracy: 0.4317 - val_loss: 1.0653 - val_accuracy: 0.4608\n","Epoch 13/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0782 - accuracy: 0.4317 - val_loss: 1.0648 - val_accuracy: 0.4608\n","Epoch 14/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0778 - accuracy: 0.4317 - val_loss: 1.0650 - val_accuracy: 0.4608\n","Epoch 15/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0781 - accuracy: 0.4317 - val_loss: 1.0658 - val_accuracy: 0.4608\n","Epoch 16/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0777 - accuracy: 0.4317 - val_loss: 1.0655 - val_accuracy: 0.4608\n","Epoch 17/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0779 - accuracy: 0.4317 - val_loss: 1.0659 - val_accuracy: 0.4608\n","Epoch 18/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0778 - accuracy: 0.4317 - val_loss: 1.0652 - val_accuracy: 0.4608\n","Epoch 19/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0779 - accuracy: 0.4317 - val_loss: 1.0653 - val_accuracy: 0.4608\n","Epoch 20/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0778 - accuracy: 0.4317 - val_loss: 1.0648 - val_accuracy: 0.4608\n","Epoch 21/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0781 - accuracy: 0.4317 - val_loss: 1.0648 - val_accuracy: 0.4608\n","Epoch 22/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0782 - accuracy: 0.4317 - val_loss: 1.0658 - val_accuracy: 0.4608\n","Epoch 23/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0780 - accuracy: 0.4317 - val_loss: 1.0664 - val_accuracy: 0.4608\n","Epoch 24/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0780 - accuracy: 0.4317 - val_loss: 1.0660 - val_accuracy: 0.4608\n","Epoch 25/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0781 - accuracy: 0.4317 - val_loss: 1.0654 - val_accuracy: 0.4608\n","Epoch 26/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0778 - accuracy: 0.4317 - val_loss: 1.0656 - val_accuracy: 0.4608\n","Epoch 27/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0779 - accuracy: 0.4317 - val_loss: 1.0649 - val_accuracy: 0.4608\n","Epoch 28/30\n","15/15 [==============================] - 1s 57ms/step - loss: 1.0781 - accuracy: 0.4317 - val_loss: 1.0651 - val_accuracy: 0.4608\n","Epoch 29/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0778 - accuracy: 0.4317 - val_loss: 1.0657 - val_accuracy: 0.4608\n","Epoch 30/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0779 - accuracy: 0.4317 - val_loss: 1.0652 - val_accuracy: 0.4608\n","Results for fold 10\n","Epoch 1/30\n","15/15 [==============================] - 1s 58ms/step - loss: 1.0784 - accuracy: 0.4306 - val_loss: 1.0618 - val_accuracy: 0.4706\n","Epoch 2/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0786 - accuracy: 0.4306 - val_loss: 1.0614 - val_accuracy: 0.4706\n","Epoch 3/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0784 - accuracy: 0.4306 - val_loss: 1.0623 - val_accuracy: 0.4706\n","Epoch 4/30\n","15/15 [==============================] - 1s 57ms/step - loss: 1.0791 - accuracy: 0.4306 - val_loss: 1.0621 - val_accuracy: 0.4706\n","Epoch 5/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0784 - accuracy: 0.4306 - val_loss: 1.0617 - val_accuracy: 0.4706\n","Epoch 6/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0783 - accuracy: 0.4306 - val_loss: 1.0619 - val_accuracy: 0.4706\n","Epoch 7/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0784 - accuracy: 0.4306 - val_loss: 1.0612 - val_accuracy: 0.4706\n","Epoch 8/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0785 - accuracy: 0.4306 - val_loss: 1.0624 - val_accuracy: 0.4706\n","Epoch 9/30\n","15/15 [==============================] - 1s 52ms/step - loss: 1.0783 - accuracy: 0.4306 - val_loss: 1.0620 - val_accuracy: 0.4706\n","Epoch 10/30\n","15/15 [==============================] - 1s 58ms/step - loss: 1.0783 - accuracy: 0.4306 - val_loss: 1.0625 - val_accuracy: 0.4706\n","Epoch 11/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0783 - accuracy: 0.4306 - val_loss: 1.0623 - val_accuracy: 0.4706\n","Epoch 12/30\n","15/15 [==============================] - 1s 57ms/step - loss: 1.0785 - accuracy: 0.4306 - val_loss: 1.0621 - val_accuracy: 0.4706\n","Epoch 13/30\n","15/15 [==============================] - 1s 57ms/step - loss: 1.0784 - accuracy: 0.4306 - val_loss: 1.0621 - val_accuracy: 0.4706\n","Epoch 14/30\n","15/15 [==============================] - 1s 57ms/step - loss: 1.0781 - accuracy: 0.4306 - val_loss: 1.0614 - val_accuracy: 0.4706\n","Epoch 15/30\n","15/15 [==============================] - 1s 57ms/step - loss: 1.0785 - accuracy: 0.4306 - val_loss: 1.0615 - val_accuracy: 0.4706\n","Epoch 16/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0787 - accuracy: 0.4306 - val_loss: 1.0619 - val_accuracy: 0.4706\n","Epoch 17/30\n","15/15 [==============================] - 1s 54ms/step - loss: 1.0785 - accuracy: 0.4306 - val_loss: 1.0610 - val_accuracy: 0.4706\n","Epoch 18/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0784 - accuracy: 0.4306 - val_loss: 1.0616 - val_accuracy: 0.4706\n","Epoch 19/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0785 - accuracy: 0.4306 - val_loss: 1.0619 - val_accuracy: 0.4706\n","Epoch 20/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0783 - accuracy: 0.4306 - val_loss: 1.0626 - val_accuracy: 0.4706\n","Epoch 21/30\n","15/15 [==============================] - 1s 57ms/step - loss: 1.0785 - accuracy: 0.4306 - val_loss: 1.0619 - val_accuracy: 0.4706\n","Epoch 22/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0784 - accuracy: 0.4306 - val_loss: 1.0615 - val_accuracy: 0.4706\n","Epoch 23/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0784 - accuracy: 0.4306 - val_loss: 1.0617 - val_accuracy: 0.4706\n","Epoch 24/30\n","15/15 [==============================] - 1s 55ms/step - loss: 1.0784 - accuracy: 0.4306 - val_loss: 1.0632 - val_accuracy: 0.4706\n","Epoch 25/30\n","15/15 [==============================] - 1s 57ms/step - loss: 1.0784 - accuracy: 0.4306 - val_loss: 1.0626 - val_accuracy: 0.4706\n","Epoch 26/30\n","15/15 [==============================] - 1s 58ms/step - loss: 1.0783 - accuracy: 0.4306 - val_loss: 1.0623 - val_accuracy: 0.4706\n","Epoch 27/30\n","15/15 [==============================] - 1s 57ms/step - loss: 1.0784 - accuracy: 0.4306 - val_loss: 1.0619 - val_accuracy: 0.4706\n","Epoch 28/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0782 - accuracy: 0.4306 - val_loss: 1.0624 - val_accuracy: 0.4706\n","Epoch 29/30\n","15/15 [==============================] - 1s 56ms/step - loss: 1.0784 - accuracy: 0.4306 - val_loss: 1.0623 - val_accuracy: 0.4706\n","Epoch 30/30\n","15/15 [==============================] - 1s 57ms/step - loss: 1.0785 - accuracy: 0.4306 - val_loss: 1.0617 - val_accuracy: 0.4706\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":723},"id":"51Ipwc2Y2Nxg","executionInfo":{"status":"ok","timestamp":1638896686818,"user_tz":-360,"elapsed":1001,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"9a7dfa82-4eea-4908-b738-60bbc78d0090"},"source":["acrc = model.evaluate(x_test, y_test)\n","pred = model.predict(x_test)\n","f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n","c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n","print(\"Accuracy  : {}\".format(acrc[1]))\n","print(\"F1_Score  : {}\".format(f1scr))\n","#c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n","import seaborn as sns\n","figure = plt.figure(figsize=(9, 9))\n","sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n","plt.tight_layout()\n","plt.ylabel('True label')\n","plt.xlabel('Predicted label')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["8/8 [==============================] - 0s 13ms/step - loss: 1.0935 - accuracy: 0.3945\n","Accuracy  : 0.39453125\n","F1_Score  : 0.18860877684407096\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 648x648 with 2 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"7QQQzEsU2JDU"},"source":["**Old**"]},{"cell_type":"code","metadata":{"id":"H2uyXGKB2ct5"},"source":["def get_channel_attention(x):\n","  y = Conv2D(filters=4, kernel_size=(3,1), strides=(1,1), padding='same')(x)\n","  y = BatchNormalization()(y)\n","  y = Dropout(0.2)(y)\n","  y = MaxPooling2D(pool_size=(2,1))(y)\n","  y = Conv2D(filters=8, kernel_size=(5,1), strides=(1,1), padding='same')(y)\n","  y = BatchNormalization()(y)\n","  y = Dropout(0.2)(y)\n","  y = MaxPooling2D(pool_size=(3,1))(y)\n","  y = Conv2D(filters=16, kernel_size=(7,1), strides=(1,1), padding='same')(y)\n","  y = BatchNormalization()(y)\n","  y = Dropout(0.2)(y)\n","  y = MaxPooling2D(pool_size=(5,1))(y)\n","  y = Conv2D(filters=32, kernel_size=(3,1), strides=(1,1), padding='same')(y)\n","  y = BatchNormalization()(y)\n","  y = Dropout(0.2)(y)\n","  y = MaxPooling2D(pool_size=(8,1))(y)\n","  y = Reshape((32, 32, 1))(y)\n","  y = AvgPool2D(pool_size=(1,32))(y)\n","  y = Dropout(0.2)(y)\n","  '''\n","  y = AvgPool2D(pool_size=(1,32), name='AvgPool2D_1')(x)'''\n","  y = Flatten(name='Flatten_1')(y)\n","  y = Dense(x.shape[2]/8,activation='tanh', name='Dense_1') (y)\n","  y = BatchNormalization(name='BatchNormalization_5')(y)\n","  y = Dropout(0.4, name='Dropout_5')(y)\n","  y = Dense(y.shape[1]*8,activation='tanh', name='Dense_2') (y)\n","  #y = BatchNormalization(name='BatchNormalization_6')(y)\n","  #y = Dropout(0.4, name='Dropout_6')(y)\n","  #y = Dense(y.shape[1]/2,activation='sigmoid', name='Dense_3') (y)\n","  #y = Dropout(0.4, name='Dropout_7')(y)\n","  z = []\n","  for i in range(x.shape[1]):\n","    z.append(y)\n","  y = Concatenate(name='Concatenate_1')(z)\n","  y = Reshape((240, 32, 1), name='Reshape_3')(y)\n","  x = Multiply(name='Multiply_2')([x,y])\n","  x = Reshape((240, 32,1), name='Reshape_4')(x)\n","  return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kMlyz1OdsxSK","executionInfo":{"status":"ok","timestamp":1638715815176,"user_tz":-360,"elapsed":1595,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"235f30bb-b612-43db-8dce-ac3248f33f2f"},"source":["def get_model() :\n","  input_shape = (data.shape[1],data.shape[2],data.shape[3],1)\n","  a = Input(input_shape)\n","  out = get_data_samples_info(a)\n","  out = get_channel_attention(out)\n","  #model=Sequential()\n","  out = Conv2D(filters=8, kernel_size=(5,5), strides=(2,1), padding='same', name='Conv2D_1')(out)\n","  out = BatchNormalization(name='BatchNormalization_7')(out)\n","  out = MaxPooling2D(pool_size=(2,2), name='MaxPooling2D_1')(out)\n","  out = Dropout(0.2, name='Dropout_8')(out)\n","  out = Conv2D(filters=16, kernel_size=(7,7), strides=(3,1), padding='same', name='Conv2D_2')(out)\n","  out = BatchNormalization(name='BatchNormalization_8')(out)\n","  out = MaxPooling2D(pool_size=(2,2), name='MaxPooling2D_2')(out)\n","  out = Dropout(0.2, name='Dropout_9')(out)\n","  out = Conv2D(filters=32, kernel_size=(5,5), strides=(1,1), padding='same', name='Conv2D_3')(out)\n","  out = BatchNormalization(name='BatchNormalization_9')(out)\n","  out = MaxPooling2D(pool_size=(2,2), name='MaxPooling2D_3')(out)\n","  out = Dropout(0.2, name='Dropout_10')(out)\n","  out = Flatten(name='Flatten_2')(out)\n","  out = Dense(256,activation='tanh')(out)\n","  out = Dropout(0.4, name='Dropout_11')(out)\n","  out = Dense(32,activation='relu')(out)\n","  out = Dropout(0.4, name='Dropout_12')(out)\n","  out = Dense(3,activation='softmax')(out)\n","  model = Model(a, out)\n","  opt = keras.optimizers.Adam(learning_rate=0.001)\n","  model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n","  return model\n","model = get_model()\n","print(model.summary())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_3\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_3 (InputLayer)           [(None, 240, 32, 32  0           []                               \n","                                , 1)]                                                             \n","                                                                                                  \n"," Conv3D_1 (Conv3D)              (None, 240, 32, 32,  20          ['input_3[0][0]']                \n","                                 4)                                                               \n","                                                                                                  \n"," BatchNormalization_1 (BatchNor  (None, 240, 32, 32,  16         ['Conv3D_1[0][0]']               \n"," malization)                     4)                                                               \n","                                                                                                  \n"," Dropout_1 (Dropout)            (None, 240, 32, 32,  0           ['BatchNormalization_1[0][0]']   \n","                                 4)                                                               \n","                                                                                                  \n"," Conv3D_2 (Conv3D)              (None, 240, 32, 32,  264         ['Dropout_1[0][0]']              \n","                                 8)                                                               \n","                                                                                                  \n"," BatchNormalization_2 (BatchNor  (None, 240, 32, 32,  32         ['Conv3D_2[0][0]']               \n"," malization)                     8)                                                               \n","                                                                                                  \n"," Dropout_2 (Dropout)            (None, 240, 32, 32,  0           ['BatchNormalization_2[0][0]']   \n","                                 8)                                                               \n","                                                                                                  \n"," Conv3D_4 (Conv3D)              (None, 240, 32, 32,  2064        ['Dropout_2[0][0]']              \n","                                 16)                                                              \n","                                                                                                  \n"," BatchNormalization_3 (BatchNor  (None, 240, 32, 32,  64         ['Conv3D_4[0][0]']               \n"," malization)                     16)                                                              \n","                                                                                                  \n"," Dropout_3 (Dropout)            (None, 240, 32, 32,  0           ['BatchNormalization_3[0][0]']   \n","                                 16)                                                              \n","                                                                                                  \n"," Conv3D_5 (Conv3D)              (None, 240, 32, 32,  16416       ['Dropout_3[0][0]']              \n","                                 32)                                                              \n","                                                                                                  \n"," BatchNormalization_4 (BatchNor  (None, 240, 32, 32,  128        ['Conv3D_5[0][0]']               \n"," malization)                     32)                                                              \n","                                                                                                  \n"," Dropout_4 (Dropout)            (None, 240, 32, 32,  0           ['BatchNormalization_4[0][0]']   \n","                                 32)                                                              \n","                                                                                                  \n"," MaxPooling3D_1 (MaxPooling3D)  (None, 240, 32, 1,   0           ['Dropout_4[0][0]']              \n","                                32)                                                               \n","                                                                                                  \n"," Reshape_1 (Reshape)            (None, 240, 32, 32,  0           ['MaxPooling3D_1[0][0]']         \n","                                 1)                                                               \n","                                                                                                  \n"," Multiply_1 (Multiply)          (None, 240, 32, 32,  0           ['Reshape_1[0][0]',              \n","                                 1)                               'Reshape_1[0][0]']              \n","                                                                                                  \n"," AvgPool3D_1 (AveragePooling3D)  (None, 240, 32, 1,   0          ['Multiply_1[0][0]']             \n","                                1)                                                                \n","                                                                                                  \n"," Reshape_2 (Reshape)            (None, 240, 32, 1)   0           ['AvgPool3D_1[0][0]']            \n","                                                                                                  \n"," conv2d_12 (Conv2D)             (None, 240, 32, 4)   16          ['Reshape_2[0][0]']              \n","                                                                                                  \n"," batch_normalization_12 (BatchN  (None, 240, 32, 4)  16          ['conv2d_12[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," dropout_15 (Dropout)           (None, 240, 32, 4)   0           ['batch_normalization_12[0][0]'] \n","                                                                                                  \n"," max_pooling2d_12 (MaxPooling2D  (None, 120, 32, 4)  0           ['dropout_15[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," conv2d_13 (Conv2D)             (None, 120, 32, 8)   168         ['max_pooling2d_12[0][0]']       \n","                                                                                                  \n"," batch_normalization_13 (BatchN  (None, 120, 32, 8)  32          ['conv2d_13[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," dropout_16 (Dropout)           (None, 120, 32, 8)   0           ['batch_normalization_13[0][0]'] \n","                                                                                                  \n"," max_pooling2d_13 (MaxPooling2D  (None, 40, 32, 8)   0           ['dropout_16[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," conv2d_14 (Conv2D)             (None, 40, 32, 16)   912         ['max_pooling2d_13[0][0]']       \n","                                                                                                  \n"," batch_normalization_14 (BatchN  (None, 40, 32, 16)  64          ['conv2d_14[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," dropout_17 (Dropout)           (None, 40, 32, 16)   0           ['batch_normalization_14[0][0]'] \n","                                                                                                  \n"," max_pooling2d_14 (MaxPooling2D  (None, 8, 32, 16)   0           ['dropout_17[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," conv2d_15 (Conv2D)             (None, 8, 32, 32)    1568        ['max_pooling2d_14[0][0]']       \n","                                                                                                  \n"," batch_normalization_15 (BatchN  (None, 8, 32, 32)   128         ['conv2d_15[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," dropout_18 (Dropout)           (None, 8, 32, 32)    0           ['batch_normalization_15[0][0]'] \n","                                                                                                  \n"," max_pooling2d_15 (MaxPooling2D  (None, 1, 32, 32)   0           ['dropout_18[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," reshape_3 (Reshape)            (None, 32, 32, 1)    0           ['max_pooling2d_15[0][0]']       \n","                                                                                                  \n"," average_pooling2d_3 (AveragePo  (None, 32, 1, 1)    0           ['reshape_3[0][0]']              \n"," oling2D)                                                                                         \n","                                                                                                  \n"," dropout_19 (Dropout)           (None, 32, 1, 1)     0           ['average_pooling2d_3[0][0]']    \n","                                                                                                  \n"," Flatten_1 (Flatten)            (None, 32)           0           ['dropout_19[0][0]']             \n","                                                                                                  \n"," Dense_1 (Dense)                (None, 4)            132         ['Flatten_1[0][0]']              \n","                                                                                                  \n"," BatchNormalization_5 (BatchNor  (None, 4)           16          ['Dense_1[0][0]']                \n"," malization)                                                                                      \n","                                                                                                  \n"," Dropout_5 (Dropout)            (None, 4)            0           ['BatchNormalization_5[0][0]']   \n","                                                                                                  \n"," Dense_2 (Dense)                (None, 32)           160         ['Dropout_5[0][0]']              \n","                                                                                                  \n"," Concatenate_1 (Concatenate)    (None, 7680)         0           ['Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]',                \n","                                                                  'Dense_2[0][0]']                \n","                                                                                                  \n"," Reshape_3 (Reshape)            (None, 240, 32, 1)   0           ['Concatenate_1[0][0]']          \n","                                                                                                  \n"," Multiply_2 (Multiply)          (None, 240, 32, 1)   0           ['Reshape_2[0][0]',              \n","                                                                  'Reshape_3[0][0]']              \n","                                                                                                  \n"," Reshape_4 (Reshape)            (None, 240, 32, 1)   0           ['Multiply_2[0][0]']             \n","                                                                                                  \n"," Conv2D_1 (Conv2D)              (None, 120, 32, 8)   208         ['Reshape_4[0][0]']              \n","                                                                                                  \n"," BatchNormalization_7 (BatchNor  (None, 120, 32, 8)  32          ['Conv2D_1[0][0]']               \n"," malization)                                                                                      \n","                                                                                                  \n"," MaxPooling2D_1 (MaxPooling2D)  (None, 60, 16, 8)    0           ['BatchNormalization_7[0][0]']   \n","                                                                                                  \n"," Dropout_8 (Dropout)            (None, 60, 16, 8)    0           ['MaxPooling2D_1[0][0]']         \n","                                                                                                  \n"," Conv2D_2 (Conv2D)              (None, 20, 16, 16)   6288        ['Dropout_8[0][0]']              \n","                                                                                                  \n"," BatchNormalization_8 (BatchNor  (None, 20, 16, 16)  64          ['Conv2D_2[0][0]']               \n"," malization)                                                                                      \n","                                                                                                  \n"," MaxPooling2D_2 (MaxPooling2D)  (None, 10, 8, 16)    0           ['BatchNormalization_8[0][0]']   \n","                                                                                                  \n"," Dropout_9 (Dropout)            (None, 10, 8, 16)    0           ['MaxPooling2D_2[0][0]']         \n","                                                                                                  \n"," Conv2D_3 (Conv2D)              (None, 10, 8, 32)    12832       ['Dropout_9[0][0]']              \n","                                                                                                  \n"," BatchNormalization_9 (BatchNor  (None, 10, 8, 32)   128         ['Conv2D_3[0][0]']               \n"," malization)                                                                                      \n","                                                                                                  \n"," MaxPooling2D_3 (MaxPooling2D)  (None, 5, 4, 32)     0           ['BatchNormalization_9[0][0]']   \n","                                                                                                  \n"," Dropout_10 (Dropout)           (None, 5, 4, 32)     0           ['MaxPooling2D_3[0][0]']         \n","                                                                                                  \n"," Flatten_2 (Flatten)            (None, 640)          0           ['Dropout_10[0][0]']             \n","                                                                                                  \n"," dense_6 (Dense)                (None, 256)          164096      ['Flatten_2[0][0]']              \n","                                                                                                  \n"," Dropout_11 (Dropout)           (None, 256)          0           ['dense_6[0][0]']                \n","                                                                                                  \n"," dense_7 (Dense)                (None, 32)           8224        ['Dropout_11[0][0]']             \n","                                                                                                  \n"," Dropout_12 (Dropout)           (None, 32)           0           ['dense_7[0][0]']                \n","                                                                                                  \n"," dense_8 (Dense)                (None, 3)            99          ['Dropout_12[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 214,187\n","Trainable params: 213,827\n","Non-trainable params: 360\n","__________________________________________________________________________________________________\n","None\n"]}]},{"cell_type":"code","metadata":{"id":"JU-doHXbyqZt"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v_EJY65oUKbh"},"source":["'''\n","def get_model() :\n","  input_shape = (data.shape[1],data.shape[2],data.shape[3],1)\n","  a = Input(input_shape)\n","  out = get_data_samples_info(a)\n","  out = get_channel_attention(out)\n","  #out = get_window_sequence_info(b)\n","  #model = Model(a, out)\n","  model=Sequential()\n","  model.add(Model(a, out))\n","  model.add(Conv2D(filters=32, kernel_size=(5,5), strides=(2,1), padding='same'))\n","  model.add(BatchNormalization())\n","  model.add(MaxPooling2D(pool_size=(2,2)))\n","  model.add(Dropout(0.2))\n","  model.add(Conv2D(filters=64, kernel_size=(7,7), strides=(3,1), padding='same'))\n","  model.add(BatchNormalization())\n","  model.add(MaxPooling2D(pool_size=(2,2)))\n","  model.add(Dropout(0.2))\n","  model.add(Conv2D(filters=32, kernel_size=(5,5), strides=(1,1), padding='same'))\n","  model.add(BatchNormalization())\n","  model.add(MaxPooling2D(pool_size=(2,2)))\n","  model.add(Dropout(0.2))\n","  model.add(Bidirectional(LSTM((60), activation='tanh', batch_input_shape=(None,240,32),return_sequences=True)))\n","  model.add(BatchNormalization())\n","  model.add(Dropout(0.4))\n","  model.add(Bidirectional(LSTM((60), activation='relu', return_sequences=True)))\n","  model.add(BatchNormalization())\n","  model.add(Dropout(0.4))\n","  model.add(Bidirectional(LSTM((60), activation='elu', return_sequences=False)))\n","  model.add(BatchNormalization())\n","  model.add(Dropout(0.4))\n","  model.add(Flatten())\n","  model.add(Dense(256,activation='tanh'))\n","  model.add(Dropout(0.4))\n","  model.add(Dense(32,activation='relu'))\n","  model.add(Dropout(0.4))\n","  model.add(Dense(3,activation='softmax'))\n","  opt = keras.optimizers.Adam(learning_rate=0.001)\n","  model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n","  return model\n","model = get_model()\n","print(model.summary())\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1jZC2UyIPd33"},"source":["'''\n","def get_model() :\n","    input_shape = (data.shape[1],data.shape[2],data.shape[3],1)\n","    model=Sequential()\n","    model.add(Conv3D(filters=16, kernel_size=(3,3,8), strides=(1,1,2), padding='same', input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling3D(pool_size=(2,2,2)))\n","    model.add(Dropout(0.2))\n","    model.add(Conv3D(filters=32, kernel_size=(5,5,5), strides=(1,1,1), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling3D(pool_size=(2,2,2)))\n","    model.add(Dropout(0.2))\n","    model.add(Conv3D(filters=64, kernel_size=(7,7,7), strides=(1,1,1), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling3D(pool_size=(2,2,2)))\n","    model.add(Dropout(0.2))\n","    model.add(Conv3D(filters=32, kernel_size=(5,5,5), strides=(1,1,1), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling3D(pool_size=(2,2,2)))\n","    model.add(Dropout(0.2))\n","    model.add(Flatten())\n","    model.add(Dense(256,activation='tanh'))\n","    model.add(Dropout(0.4))\n","    model.add(Dense(32,activation='relu'))\n","    model.add(Dropout(0.4))\n","    model.add(Dense(3,activation='softmax'))\n","    opt = keras.optimizers.Adam(learning_rate=0.001)\n","    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n","    return model\n","model = get_model()\n","model.summary()\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n94Q8iJ4rJsF"},"source":["# **Valence**"]},{"cell_type":"code","metadata":{"id":"8tdPOzU7rQRV","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1638718203884,"user_tz":-360,"elapsed":2278254,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"33b0e255-e60a-4679-c03d-a4406550e111"},"source":["val_res = {'accuracy': [], 'f1_score': [], 'confusion_matrix': []}\n","foldNum=0\n","model = get_model()\n","for train_index, val_index in kfold.split(X_train, Y_train):\n","  foldNum = foldNum + 1\n","  #model = get_model()\n","  print(\"Results for fold\",foldNum)\n","  x_train, x_val = X_train[train_index], X_train[val_index]\n","  y_train, y_val = Y_train[train_index], Y_train[val_index]\n","  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n","  layer_name = 'Dense_2'\n","  intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n","  intermediate_output = intermediate_layer_model.predict(x_test)\n","  acc = model.evaluate(x_test, y_test)\n","  print(acc)\n","  val_res['accuracy'].append(acc)\n","  pred = model.predict(x_test)\n","  f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n","  print(f1scr)\n","  val_res['f1_score'].append(f1scr)\n","  val_res['confusion_matrix'].append(confusion_matrix(y_test.argmax(1), pred.argmax(1)))\n","  gc.collect() # Garbage collecter\n","  del x_train, x_val, y_train, y_val, acc, f1scr\n","  gc.collect()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Results for fold 1\n","Epoch 1/30\n","29/29 [==============================] - 75s 2s/step - loss: 1.1788 - accuracy: 0.3692 - val_loss: 1.0996 - val_accuracy: 0.4175\n","Epoch 2/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.1229 - accuracy: 0.4039 - val_loss: 1.0901 - val_accuracy: 0.4369\n","Epoch 3/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.1008 - accuracy: 0.4278 - val_loss: 1.0986 - val_accuracy: 0.4175\n","Epoch 4/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.0924 - accuracy: 0.4354 - val_loss: 1.0853 - val_accuracy: 0.4466\n","Epoch 5/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.0869 - accuracy: 0.4245 - val_loss: 1.0818 - val_accuracy: 0.4369\n","Epoch 6/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.0885 - accuracy: 0.4213 - val_loss: 1.0889 - val_accuracy: 0.4369\n","Epoch 7/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.0872 - accuracy: 0.4311 - val_loss: 1.0797 - val_accuracy: 0.4369\n","Epoch 8/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.0874 - accuracy: 0.4267 - val_loss: 1.0836 - val_accuracy: 0.4369\n","Epoch 9/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.0779 - accuracy: 0.4289 - val_loss: 1.0833 - val_accuracy: 0.4369\n","Epoch 10/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.0875 - accuracy: 0.4191 - val_loss: 1.0839 - val_accuracy: 0.4369\n","Epoch 11/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.0781 - accuracy: 0.4311 - val_loss: 1.0814 - val_accuracy: 0.4369\n","Epoch 12/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.0758 - accuracy: 0.4311 - val_loss: 1.0802 - val_accuracy: 0.4563\n","Epoch 13/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.0715 - accuracy: 0.4430 - val_loss: 1.0821 - val_accuracy: 0.4660\n","Epoch 14/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.0769 - accuracy: 0.4332 - val_loss: 1.0822 - val_accuracy: 0.4369\n","Epoch 15/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.0769 - accuracy: 0.4300 - val_loss: 1.0764 - val_accuracy: 0.4563\n","Epoch 16/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.0804 - accuracy: 0.4224 - val_loss: 1.0774 - val_accuracy: 0.4660\n","Epoch 17/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.0806 - accuracy: 0.4245 - val_loss: 1.0816 - val_accuracy: 0.4369\n","Epoch 18/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.0803 - accuracy: 0.4387 - val_loss: 1.0834 - val_accuracy: 0.4369\n","Epoch 19/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.0689 - accuracy: 0.4408 - val_loss: 1.0795 - val_accuracy: 0.4660\n","Epoch 20/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.0693 - accuracy: 0.4397 - val_loss: 1.0843 - val_accuracy: 0.4369\n","Epoch 21/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.0750 - accuracy: 0.4289 - val_loss: 1.0809 - val_accuracy: 0.4369\n","Epoch 22/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.0740 - accuracy: 0.4376 - val_loss: 1.0814 - val_accuracy: 0.4563\n","Epoch 23/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.0727 - accuracy: 0.4430 - val_loss: 1.0817 - val_accuracy: 0.4563\n","Epoch 24/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.0724 - accuracy: 0.4343 - val_loss: 1.0848 - val_accuracy: 0.4563\n","Epoch 25/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.0757 - accuracy: 0.4300 - val_loss: 1.0860 - val_accuracy: 0.4369\n","Epoch 26/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.0694 - accuracy: 0.4387 - val_loss: 1.0860 - val_accuracy: 0.4369\n","Epoch 27/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.0716 - accuracy: 0.4311 - val_loss: 1.0883 - val_accuracy: 0.4757\n","Epoch 28/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.0720 - accuracy: 0.4256 - val_loss: 1.0922 - val_accuracy: 0.4466\n","Epoch 29/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.0662 - accuracy: 0.4387 - val_loss: 1.0981 - val_accuracy: 0.4563\n","Epoch 30/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.0730 - accuracy: 0.4419 - val_loss: 1.0891 - val_accuracy: 0.4369\n","8/8 [==============================] - 6s 657ms/step - loss: 1.0898 - accuracy: 0.3945\n","[1.089767575263977, 0.39453125]\n","0.18860877684407096\n","Results for fold 2\n","Epoch 1/30\n","29/29 [==============================] - 71s 2s/step - loss: 1.0664 - accuracy: 0.4495 - val_loss: 1.0837 - val_accuracy: 0.3592\n","Epoch 2/30\n","22/29 [=====================>........] - ETA: 16s - loss: 1.0561 - accuracy: 0.4545"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-44c196a78242>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mlayer_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Dense_2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mintermediate_layer_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1219\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \"\"\"\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       raise ValueError(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    548\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \"\"\"\n\u001b[1;32m   1148\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rNDZqY6FN6eV","executionInfo":{"status":"ok","timestamp":1638718376011,"user_tz":-360,"elapsed":722,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"c4a508ab-40d0-4f10-cecd-65fe59cabb24"},"source":["print(intermediate_output.shape)\n","print(intermediate_output[0,:])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(256, 32)\n","[ 0.3131164  -0.1580573   0.13697991  0.23789255 -0.4543351  -0.25573733\n"," -0.3586486  -0.30065918 -0.35399267  0.35143137 -0.07798071  0.05603994\n"," -0.08898091  0.02278246 -0.37165695 -0.02747468 -0.31473905  0.05988819\n","  0.01004803 -0.3488593   0.28138164 -0.06593439 -0.25799796 -0.10766736\n","  0.03267057  0.1256802  -0.0949292  -0.30965248  0.26557216  0.0714929\n"," -0.17453739  0.02032313]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ReV0LNYUO03i","executionInfo":{"status":"ok","timestamp":1638718495263,"user_tz":-360,"elapsed":857,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"71c06c2d-1274-48ec-b5fb-41373263f2e8"},"source":["print(intermediate_output[4,:])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[ 3.25519711e-01 -1.83422014e-01  1.54731944e-01  2.55841523e-01\n"," -4.33328360e-01 -2.29832947e-01 -3.49894851e-01 -3.06481361e-01\n"," -3.43279123e-01  3.56946141e-01 -8.06292295e-02  7.35025555e-02\n"," -1.16506696e-01  2.07025558e-04 -3.72087628e-01 -3.30786780e-02\n"," -3.19745630e-01  6.25137687e-02 -3.60354632e-02 -3.68111461e-01\n","  2.87451148e-01 -6.68187961e-02 -2.61604995e-01 -1.22668579e-01\n","  3.61218490e-02  1.07563213e-01 -7.29484037e-02 -3.17554474e-01\n","  2.61478215e-01  7.22712576e-02 -1.66113958e-01 -2.88187172e-02]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U9ofGeyfOsX6","executionInfo":{"status":"ok","timestamp":1638718448622,"user_tz":-360,"elapsed":682,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"7c441c20-2fd5-4711-a00f-d0d4b58b7653"},"source":["y_test[4]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1., 0., 0.], dtype=float32)"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"AU2RBJ5-KvZc"},"source":["acrc = model.evaluate(x_test, y_test)\n","pred = model.predict(x_test)\n","f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n","c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n","print(\"Accuracy  : {}\".format(acrc[1]))\n","print(\"F1_Score  : {}\".format(f1scr))\n","c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(2,1)\n","import seaborn as sns\n","figure = plt.figure(figsize=(9, 9))\n","sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n","plt.tight_layout()\n","plt.ylabel('True label')\n","plt.xlabel('Predicted label')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e1ypZ2NnYxes"},"source":["# **Arousal**"]},{"cell_type":"code","metadata":{"id":"B7fcxLuwZpkK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636199681354,"user_tz":-360,"elapsed":1233,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"87838d3a-4f4c-494b-d929-785534de9703"},"source":["#arousal\n","X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n","print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 2) (1864, 2)\n"]}]},{"cell_type":"code","metadata":{"id":"4iz5mTT7Zwcp"},"source":["foldNum=0\n","model = get_model()\n","for train_index, val_index in kfold.split(X_train, Y_train):\n","  foldNum = foldNum + 1\n","  print(\"Results for fold\",foldNum)\n","  x_train, x_val = X_train[train_index], X_train[val_index]\n","  y_train, y_val = Y_train[train_index], Y_train[val_index]\n","  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n","  gc.collect() # Garbage collecter\n","  del x_train, x_val, y_train, y_val\n","  gc.collect()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rayztobJpmag"},"source":["acrc = model.evaluate(x_test, y_test)\n","pred = model.predict(x_test)\n","f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n","c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n","print(\"Accuracy  : {}\".format(acrc[1]))\n","print(\"F1_Score  : {}\".format(f1scr))\n","c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(2,1)\n","import seaborn as sns\n","figure = plt.figure(figsize=(9, 9))\n","sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n","plt.tight_layout()\n","plt.ylabel('True label')\n","plt.xlabel('Predicted label')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XoRZB4XAnaye"},"source":["**Extra**"]},{"cell_type":"code","metadata":{"id":"XIY4fiC5qCkI"},"source":["def butter_lowpass(cutoff, fs, order=5):\n","    nyq = 0.5 * fs\n","    normal_cutoff = cutoff / nyq\n","    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n","    return b, a\n","\n","\n","def butter_lowpass_filter(data, cutoff, fs, order=5):\n","    b, a = butter_lowpass(cutoff, fs, order=order)\n","    y = filtfilt(b, a, data)\n","    return y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cPXrZrst909d"},"source":["#[1,3,7,8,21,22,25,26,27,30]\n","#[1,3,4,7,8,19,21,22,25,26,27,28,30]\n","#[8,21,22,26,30]\n","#[0,2,3,4,5,16,19,20,21,22]\n","#[1,2,3,4,8,13,14,16,17,18,19,21,22,25,30] #15 channels\n","channel = np.array([1,2,3,4,13,16,17,19,25,30]) #10 channels\n","scale = len(np.arange(11, 31))\n","sampling_rate = 128\n","window_size = 256\n","skip = 32\n","channel_len = len(channel)\n","classes=2\n","order = 6\n","fs = 128      # sample rate, Hz\n","cutoff = 60  # desired cutoff frequency of the filter, Hz\n","waveletname = 'db4'\n","bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n","         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n","         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O9LZgo2IM9N-"},"source":["from scipy.signal.lti_conversion import cont2discrete\n","const = 1e3\n","def cwt_EER(x):\n","  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n","  energy = np.square(coef)\n","  energy_each_coef_sum = sum(energy.T)\n","  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n","  probability = np.divide(energy,energy_each_coef_sum_tile)\n","  entropy = -probability*np.log(probability)\n","  EER = np.divide(energy, entropy)\n","  #EER = EER/const\n","  return EER"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EotvnIan4d84","executionInfo":{"status":"ok","timestamp":1637382939735,"user_tz":-360,"elapsed":268541,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"97cb71bd-7cf9-4593-c0f0-68d9c4e67823"},"source":["eeg_signal = []\n","valence = []\n","arousal = []\n","dominance = []\n","signal_freq = []\n","eeg_sig = []\n","gc.collect()\n","\n","for person in range(22,23):\n","  print('Person No.' + str(person))\n","  \n","  # EEG files address\n","  if person < 10 :\n","    address = input_path+'s0'+str(person)+'.dat'\n","  else :\n","    address = input_path+'s'+str(person)+'.dat'\n","\n","  with open(address, 'rb') as file:\n","    data = pkl.load(file, encoding = 'latin1')\n","\n","  eeg = data['data']\n","  label = data['labels']\n","  \n","  # Assigning classes\n","  label[label<5] = 0\n","  #label[(label>=4) & (label<6)] = 1\n","  label[label>=5] = 1\n","\n","  val = label.T[0] # Valence label\n","  aro = label.T[1] # Arousal label\n","  #dom = label.T[2] # Dominance label\n","\n","  del data, label\n","  \n","\n","  for i in range(40): # Iterating through 40 vidoes/trials\n","\n","    sig = eeg[i]\n","    sig = sig[:32, 384:]\n","    \n","    dfs = []\n","    for j in channel:\n","      ## Dividing Alpha Band\n","      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n","      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n","\n","    sig = np.array(dfs)\n","    sig = sig.reshape([-1,7680])\n","    eeg_signal.append(sig)\n","  del dfs, sig, eeg\n","  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n","  gc.collect()\n","  for i in range(40):\n","    v = val[i]\n","    a = aro[i]\n","    #d = dom[i]\n","    start = 0\n","    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n","    while start + window_size <=eeg_signal.shape[2]:\n","      for j in range(eeg_signal.shape[1]):\n","        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n","      valence.append(v)\n","      arousal.append(a)\n","      #dominance.append(d)\n","      start += skip\n","#eeg_sig = np.array(eeg_sig)\n","gc.collect()\n","del eeg_signal\n","eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n","data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n","del eeg_sig\n","valence = np.asarray(valence, dtype = np.int8)\n","arousal = np.asarray(arousal, dtype = np.int8)\n","#dominance = np.asarray(dominance, dtype = np.int8)\n","\n","print(data.shape)\n","print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape)#, valence[valence == 2].shape)\n","print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape)#, arousal[arousal == 2].shape)\n","#print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape)\n","\n","valence = np_utils.to_categorical(valence)\n","arousal = np_utils.to_categorical(arousal)\n","#dominance = np_utils.to_categorical(dominance)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Person No.22\n","(9320, 200, 256, 1)\n","(9320,) (4660,) (4660,)\n","(9320,) (3495,) (5825,)\n"]}]}]}