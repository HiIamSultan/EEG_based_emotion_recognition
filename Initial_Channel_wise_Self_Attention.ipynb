{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Initial_Channel_wise&Self_Attention.ipynb","provenance":[{"file_id":"1s7fJkih4-gJBv74IbgBi_1GaWF1F71ql","timestamp":1643009703845},{"file_id":"16MUElg7iEndGHJOrSBvHce8C_ohmxv7H","timestamp":1639318390546},{"file_id":"1lSsTpCnZc7NP67Cj2D0MN2HxalsmnXce","timestamp":1638718545258}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"mJl4myg42Jt-"},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import keras\n","import pickle as pkl\n","from tensorflow import keras\n","import tensorflow.keras.backend as K\n","from keras.models import Sequential,Model\n","from keras.models import Sequential \n","from keras.layers import Dense, Dropout, Flatten, Input, Reshape, BatchNormalization, Bidirectional, LSTM, Multiply, Activation\n","from keras.layers import Conv3D, Conv2D, Conv1D, MaxPool3D, MaxPool2D, MaxPool1D, AvgPool3D, AvgPool2D, AvgPool1D, GlobalMaxPool3D, Attention\n","from keras.layers import GlobalMaxPool2D, GlobalMaxPool1D, SpatialDropout3D, SpatialDropout2D, SpatialDropout1D, GlobalAvgPool3D, MultiHeadAttention\n","from keras.layers import GlobalAvgPool2D, GlobalAvgPool1D, SeparableConv2D, SeparableConv1D, Add, Concatenate, LeakyReLU, ELU, Activation\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import regularizers\n","from keras.utils import np_utils\n","from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n","from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n","from sklearn.utils.class_weight import compute_class_weight\n","import gc"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Data Loading**"],"metadata":{"id":"636j2NDJVajh"}},{"cell_type":"code","metadata":{"id":"_ns3s5JN97fU"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","gc.collect()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ugvNZGZX-DO7"},"source":["input_path='/content/drive/MyDrive/data_preprocessed_python/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def baseline_remove(XR):\n","  XT = XR[:, 384:]\n","  XB_ = (XR[:, :1*128] + XR[:, 1*128:2*128] + XR[:, 2*128:3*128])/3.0\n","  for i in range(60):\n","    XT[:, i*128:(i+1)*128] = XT[:, i*128:(i+1)*128] - XB_\n","  return XT\n"],"metadata":{"id":"CNhxbIwFCs3T"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GHPHG2H5lmju","executionInfo":{"status":"ok","timestamp":1642517535195,"user_tz":-360,"elapsed":2587,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"30a96100-d9fa-4882-99cb-ee962ae6c728"},"source":["eeg_signal = []\n","valence = []\n","arousal = []\n","window_size = 384\n","skip = 384\n","\n","for person in range(5,6):\n","  print('Person No.' + str(person))\n","  \n","  # EEG files address\n","  if person < 10 :\n","    address = input_path+'s0'+str(person)+'.dat'\n","  else :\n","    address = input_path+'s'+str(person)+'.dat'\n","\n","  with open(address, 'rb') as file:\n","    data = pkl.load(file, encoding = 'latin1')\n","\n","  eeg = data['data']\n","  label = data['labels']\n","  \n","  # Assigning classes\n","  label[label<5] = 0\n","  label[label>=5] = 1\n","\n","  val = label.T[0] # Valence label\n","  aro = label.T[1] # Arousal label\n","\n","  del data, label\n","  # Iterating through 40 vidoes/trials\n","  for i in range(40):\n","    sig = eeg[i][:32, :]\n","    sig = baseline_remove(sig)\n","    # Segmenting into 3 seconds (384 timesteps) windows without overlap\n","    start = 0\n","    while start + window_size <=sig.shape[1]:\n","      eeg_signal.append(sig[:, start:start+window_size])\n","      valence.append(val[i])\n","      arousal.append(aro[i])\n","      start += skip \n","  del eeg, val, aro, sig\n","eeg_signal = np.reshape(eeg_signal,[-1,32,384,1])\n","data = np.asarray(eeg_signal, dtype = np.float32) # Using 32 bit floating point value to save memory\n","del eeg_signal\n","valence = np.asarray(valence, dtype = np.int8)\n","arousal = np.asarray(arousal, dtype = np.int8)\n","\n","print(data.shape)\n","print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape)\n","print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape)\n","\n","valence = np_utils.to_categorical(valence)\n","arousal = np_utils.to_categorical(arousal)\n","gc.collect()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Person No.5\n","(800, 32, 384, 1)\n","(800,) (320,) (480,)\n","(800,) (420,) (380,)\n"]},{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"-VMwwMiur8kW"},"source":["# **Proposed Architecture**"]},{"cell_type":"code","source":["def channel_wise_attention(x):\n","  y = AvgPool2D(pool_size=(1,384), name='AvgPool2D_1')(x)\n","  y = Flatten(name='Flatten_1')(y)\n","  y = Dense(5,activation='tanh', name='Dense_1') (y)\n","  y = Dense(32,activation='softmax', name='Dense_2') (y)\n","  x = Multiply(name='Multiply_1')([x, tf.expand_dims(tf.expand_dims(y, axis=2), axis=2)])\n","  return x\n","\n","def CNN_LSTM_Self_Attention(x):\n","  x = Conv2D(filters = 40, kernel_size = (32, 45), strides = (1, 1), padding = 'valid', name = 'Conv2D_1')(x)\n","  x = BatchNormalization(name='BatchNormalization_1')(x)\n","  x = Activation('elu', name = 'Activation_1')(x)\n","  x = MaxPool2D(pool_size=(1, 75), strides = 10, name='MaxPool2D_1')(x)\n","  x = Reshape((-1, x.shape[1]*x.shape[2]*x.shape[3]), name='Reshape_1')(x)\n","  x = LSTM(64, activation='tanh', recurrent_activation='sigmoid', use_bias=True, kernel_initializer='glorot_uniform',\n","           recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4), \n","           bias_regularizer=regularizers.l2(1e-4), activity_regularizer=regularizers.l2(1e-5), kernel_constraint=None, \n","           dropout=0.2, recurrent_dropout=0.2, return_sequences=True, return_state=True, go_backwards=True, name='LSTM_1')(x)\n","  x = LSTM(64, activation='tanh', recurrent_activation='sigmoid', use_bias=True, kernel_initializer='glorot_uniform',\n","           recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4), \n","           bias_regularizer=regularizers.l2(1e-4), activity_regularizer=regularizers.l2(1e-5), kernel_constraint=None, \n","           dropout=0.2, recurrent_dropout=0.2, return_sequences=True, go_backwards=True, name='LSTM_2')(x)\n","  y = MultiHeadAttention(num_heads=8, key_dim=8, name = 'MultiHeadAttention_1')(x, x)\n","  y = Activation('softmax', name = 'Activation_2')(y)\n","  x = Multiply(name='Multiply_2')([x, y])\n","  x = Flatten(name='Flatten_2')(x)\n","  x = Dense(2, activation='softmax', name='Dense_3') (x)\n","  return x\n"],"metadata":{"id":"L0OBRek1JtCR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_model() :\n","  input_shape = (data.shape[1], data.shape[2],1)\n","  a = Input(input_shape, name='Input')\n","  out = channel_wise_attention(a)\n","  out = CNN_LSTM_Self_Attention(out)\n","  model = Model(a, out)\n","  opt = keras.optimizers.Adam(learning_rate=1e-4)\n","  model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n","  return model\n","model = get_model()\n","print(model.summary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zKNJwA_zLrz4","executionInfo":{"status":"ok","timestamp":1642517539438,"user_tz":-360,"elapsed":4248,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"76885960-ccea-46ad-829a-6a7fa3beb94a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layer LSTM_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer LSTM_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," Input (InputLayer)             [(None, 32, 384, 1)  0           []                               \n","                                ]                                                                 \n","                                                                                                  \n"," AvgPool2D_1 (AveragePooling2D)  (None, 32, 1, 1)    0           ['Input[0][0]']                  \n","                                                                                                  \n"," Flatten_1 (Flatten)            (None, 32)           0           ['AvgPool2D_1[0][0]']            \n","                                                                                                  \n"," Dense_1 (Dense)                (None, 5)            165         ['Flatten_1[0][0]']              \n","                                                                                                  \n"," Dense_2 (Dense)                (None, 32)           192         ['Dense_1[0][0]']                \n","                                                                                                  \n"," tf.expand_dims (TFOpLambda)    (None, 32, 1)        0           ['Dense_2[0][0]']                \n","                                                                                                  \n"," tf.expand_dims_1 (TFOpLambda)  (None, 32, 1, 1)     0           ['tf.expand_dims[0][0]']         \n","                                                                                                  \n"," Multiply_1 (Multiply)          (None, 32, 384, 1)   0           ['Input[0][0]',                  \n","                                                                  'tf.expand_dims_1[0][0]']       \n","                                                                                                  \n"," Conv2D_1 (Conv2D)              (None, 1, 340, 40)   57640       ['Multiply_1[0][0]']             \n","                                                                                                  \n"," BatchNormalization_1 (BatchNor  (None, 1, 340, 40)  160         ['Conv2D_1[0][0]']               \n"," malization)                                                                                      \n","                                                                                                  \n"," Activation_1 (Activation)      (None, 1, 340, 40)   0           ['BatchNormalization_1[0][0]']   \n","                                                                                                  \n"," MaxPool2D_1 (MaxPooling2D)     (None, 1, 27, 40)    0           ['Activation_1[0][0]']           \n","                                                                                                  \n"," Reshape_1 (Reshape)            (None, 1, 1080)      0           ['MaxPool2D_1[0][0]']            \n","                                                                                                  \n"," LSTM_1 (LSTM)                  [(None, 1, 64),      293120      ['Reshape_1[0][0]']              \n","                                 (None, 64),                                                      \n","                                 (None, 64)]                                                      \n","                                                                                                  \n"," LSTM_2 (LSTM)                  (None, 1, 64)        33024       ['LSTM_1[0][0]',                 \n","                                                                  'LSTM_1[0][1]',                 \n","                                                                  'LSTM_1[0][2]']                 \n","                                                                                                  \n"," MultiHeadAttention_1 (MultiHea  (None, 1, 64)       16640       ['LSTM_2[0][0]',                 \n"," dAttention)                                                      'LSTM_2[0][0]']                 \n","                                                                                                  \n"," Activation_2 (Activation)      (None, 1, 64)        0           ['MultiHeadAttention_1[0][0]']   \n","                                                                                                  \n"," Multiply_2 (Multiply)          (None, 1, 64)        0           ['LSTM_2[0][0]',                 \n","                                                                  'Activation_2[0][0]']           \n","                                                                                                  \n"," Flatten_2 (Flatten)            (None, 64)           0           ['Multiply_2[0][0]']             \n","                                                                                                  \n"," Dense_3 (Dense)                (None, 2)            130         ['Flatten_2[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 401,071\n","Trainable params: 400,991\n","Non-trainable params: 80\n","__________________________________________________________________________________________________\n","None\n"]}]},{"cell_type":"code","metadata":{"id":"ZC6fgR_XrOSw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642518075794,"user_tz":-360,"elapsed":459,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"2b0c448f-6940-46a7-c7f2-b381d68c8405"},"source":["batch_size = 10\n","epochs = 100\n","kfold = KFold(n_splits=10, random_state=1, shuffle=True)\n","gc.collect()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["49131"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"le6AXdqO3A0E"},"source":["def call_class_weights(yt):\n","  y_integers = np.argmax(yt, axis=1)\n","  class_weights = compute_class_weight(class_weight = 'balanced', classes = np.unique(y_integers), y = y_integers)\n","  d_class_weights = dict(enumerate(class_weights))\n","  return d_class_weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Valence**"],"metadata":{"id":"3F2Pa3j4VhZr"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fbCNIFVD3V2L","executionInfo":{"status":"ok","timestamp":1642517539440,"user_tz":-360,"elapsed":21,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"e8183394-2a20-4a24-cba9-0b50b54ae89a"},"source":["#valence\n","X_train, x_test, Y_train, y_test = train_test_split(data, valence, test_size=0.1, random_state=4)\n","print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(720, 32, 384, 1) (80, 32, 384, 1) (720, 2) (80, 2)\n"]}]},{"cell_type":"code","source":["val_res = {'accuracy': [], 'f1_score': [], 'confusion_matrix': []}\n","foldNum=0\n","#model = get_model()\n","for train_index, val_index in kfold.split(X_train, Y_train):\n","  foldNum = foldNum + 1\n","  model = get_model()\n","  print(\"Results for fold\",foldNum)\n","  x_train, x_val = X_train[train_index], X_train[val_index]\n","  y_train, y_val = Y_train[train_index], Y_train[val_index]\n","  class_weight = call_class_weights(y_train)\n","  model.fit(x_train, y_train, epochs=epochs, class_weight=class_weight, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n","  acc = model.evaluate(x_test, y_test)\n","  print(acc)\n","  val_res['accuracy'].append(acc)\n","  pred = model.predict(x_test)\n","  f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n","  print(f1scr)\n","  val_res['f1_score'].append(f1scr)\n","  val_res['confusion_matrix'].append(confusion_matrix(y_test.argmax(1), pred.argmax(1)))\n","  gc.collect() # Garbage collecter\n","  del x_train, x_val, y_train, y_val, acc, f1scr\n","  gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-qN7aC6MR7T0","outputId":"847c3e6d-d913-4c92-babf-315cf2f5a50a","executionInfo":{"status":"ok","timestamp":1642520134008,"user_tz":-360,"elapsed":2056092,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layer LSTM_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer LSTM_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Results for fold 1\n","Epoch 1/100\n","65/65 [==============================] - 7s 30ms/step - loss: 0.8508 - accuracy: 0.6096 - val_loss: 0.8393 - val_accuracy: 0.8194\n","Epoch 2/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.8293 - accuracy: 0.6620 - val_loss: 0.8181 - val_accuracy: 0.7500\n","Epoch 3/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.8085 - accuracy: 0.7145 - val_loss: 0.7943 - val_accuracy: 0.7917\n","Epoch 4/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.7892 - accuracy: 0.7160 - val_loss: 0.7714 - val_accuracy: 0.7778\n","Epoch 5/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.7697 - accuracy: 0.7284 - val_loss: 0.7422 - val_accuracy: 0.7778\n","Epoch 6/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.7367 - accuracy: 0.7361 - val_loss: 0.6807 - val_accuracy: 0.8056\n","Epoch 7/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.7046 - accuracy: 0.7330 - val_loss: 0.6422 - val_accuracy: 0.8056\n","Epoch 8/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.6671 - accuracy: 0.7793 - val_loss: 0.6244 - val_accuracy: 0.8194\n","Epoch 9/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.6454 - accuracy: 0.7886 - val_loss: 0.6064 - val_accuracy: 0.8333\n","Epoch 10/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.6327 - accuracy: 0.7963 - val_loss: 0.6021 - val_accuracy: 0.8194\n","Epoch 11/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.6072 - accuracy: 0.8256 - val_loss: 0.6181 - val_accuracy: 0.7778\n","Epoch 12/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.5921 - accuracy: 0.8302 - val_loss: 0.6011 - val_accuracy: 0.8194\n","Epoch 13/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.5804 - accuracy: 0.8410 - val_loss: 0.5671 - val_accuracy: 0.8472\n","Epoch 14/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.5684 - accuracy: 0.8627 - val_loss: 0.5735 - val_accuracy: 0.8056\n","Epoch 15/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.5526 - accuracy: 0.8704 - val_loss: 0.5399 - val_accuracy: 0.8750\n","Epoch 16/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.5292 - accuracy: 0.8981 - val_loss: 0.6119 - val_accuracy: 0.7500\n","Epoch 17/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.5318 - accuracy: 0.8796 - val_loss: 0.5241 - val_accuracy: 0.8889\n","Epoch 18/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.5198 - accuracy: 0.8873 - val_loss: 0.5096 - val_accuracy: 0.9028\n","Epoch 19/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.5125 - accuracy: 0.8981 - val_loss: 0.5221 - val_accuracy: 0.8611\n","Epoch 20/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.5020 - accuracy: 0.8951 - val_loss: 0.4918 - val_accuracy: 0.9167\n","Epoch 21/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.4798 - accuracy: 0.9290 - val_loss: 0.4933 - val_accuracy: 0.9167\n","Epoch 22/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.4793 - accuracy: 0.9213 - val_loss: 0.4975 - val_accuracy: 0.8889\n","Epoch 23/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.4754 - accuracy: 0.9259 - val_loss: 0.4867 - val_accuracy: 0.9028\n","Epoch 24/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.4765 - accuracy: 0.9136 - val_loss: 0.6293 - val_accuracy: 0.6528\n","Epoch 25/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.4656 - accuracy: 0.9136 - val_loss: 0.4823 - val_accuracy: 0.9028\n","Epoch 26/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.4518 - accuracy: 0.9429 - val_loss: 0.4687 - val_accuracy: 0.9306\n","Epoch 27/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.4462 - accuracy: 0.9429 - val_loss: 0.4908 - val_accuracy: 0.8750\n","Epoch 28/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.4511 - accuracy: 0.9336 - val_loss: 0.4964 - val_accuracy: 0.8750\n","Epoch 29/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.4430 - accuracy: 0.9383 - val_loss: 0.4586 - val_accuracy: 0.9167\n","Epoch 30/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.4305 - accuracy: 0.9444 - val_loss: 0.5584 - val_accuracy: 0.7778\n","Epoch 31/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.4317 - accuracy: 0.9367 - val_loss: 0.4355 - val_accuracy: 0.9306\n","Epoch 32/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.4204 - accuracy: 0.9537 - val_loss: 0.4522 - val_accuracy: 0.9167\n","Epoch 33/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.4201 - accuracy: 0.9475 - val_loss: 0.4335 - val_accuracy: 0.9444\n","Epoch 34/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.4120 - accuracy: 0.9522 - val_loss: 0.4769 - val_accuracy: 0.8472\n","Epoch 35/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.4258 - accuracy: 0.9321 - val_loss: 0.4264 - val_accuracy: 0.9306\n","Epoch 36/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.3962 - accuracy: 0.9676 - val_loss: 0.4302 - val_accuracy: 0.9167\n","Epoch 37/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.3968 - accuracy: 0.9630 - val_loss: 0.4358 - val_accuracy: 0.9167\n","Epoch 38/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.3934 - accuracy: 0.9614 - val_loss: 0.4322 - val_accuracy: 0.9028\n","Epoch 39/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.4051 - accuracy: 0.9429 - val_loss: 0.4499 - val_accuracy: 0.8889\n","Epoch 40/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.3856 - accuracy: 0.9583 - val_loss: 0.4203 - val_accuracy: 0.9306\n","Epoch 41/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.3766 - accuracy: 0.9707 - val_loss: 0.4194 - val_accuracy: 0.9028\n","Epoch 42/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.3751 - accuracy: 0.9660 - val_loss: 0.4384 - val_accuracy: 0.9028\n","Epoch 43/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.3859 - accuracy: 0.9460 - val_loss: 0.4426 - val_accuracy: 0.8889\n","Epoch 44/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.3660 - accuracy: 0.9722 - val_loss: 0.4017 - val_accuracy: 0.9444\n","Epoch 45/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.3600 - accuracy: 0.9722 - val_loss: 0.4214 - val_accuracy: 0.9028\n","Epoch 46/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.3660 - accuracy: 0.9568 - val_loss: 0.4157 - val_accuracy: 0.9028\n","Epoch 47/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.3645 - accuracy: 0.9630 - val_loss: 0.4629 - val_accuracy: 0.8611\n","Epoch 48/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.3562 - accuracy: 0.9691 - val_loss: 0.5090 - val_accuracy: 0.8194\n","Epoch 49/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.3664 - accuracy: 0.9568 - val_loss: 0.3871 - val_accuracy: 0.9444\n","Epoch 50/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.3520 - accuracy: 0.9691 - val_loss: 0.3639 - val_accuracy: 0.9722\n","Epoch 51/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.3469 - accuracy: 0.9707 - val_loss: 0.3575 - val_accuracy: 0.9722\n","Epoch 52/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.3481 - accuracy: 0.9599 - val_loss: 0.4099 - val_accuracy: 0.9167\n","Epoch 53/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.3353 - accuracy: 0.9707 - val_loss: 0.4060 - val_accuracy: 0.9028\n","Epoch 54/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.3380 - accuracy: 0.9738 - val_loss: 0.4141 - val_accuracy: 0.9028\n","Epoch 55/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.3242 - accuracy: 0.9784 - val_loss: 0.3920 - val_accuracy: 0.9167\n","Epoch 56/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.3261 - accuracy: 0.9784 - val_loss: 0.3959 - val_accuracy: 0.9167\n","Epoch 57/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.3273 - accuracy: 0.9722 - val_loss: 0.4458 - val_accuracy: 0.8611\n","Epoch 58/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.3299 - accuracy: 0.9676 - val_loss: 0.3678 - val_accuracy: 0.9306\n","Epoch 59/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.3125 - accuracy: 0.9830 - val_loss: 0.4053 - val_accuracy: 0.8889\n","Epoch 60/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.3113 - accuracy: 0.9784 - val_loss: 0.3426 - val_accuracy: 0.9583\n","Epoch 61/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.3132 - accuracy: 0.9753 - val_loss: 0.3726 - val_accuracy: 0.9306\n","Epoch 62/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.3229 - accuracy: 0.9630 - val_loss: 0.4191 - val_accuracy: 0.8750\n","Epoch 63/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.3107 - accuracy: 0.9722 - val_loss: 0.3700 - val_accuracy: 0.9167\n","Epoch 64/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.3238 - accuracy: 0.9583 - val_loss: 0.3997 - val_accuracy: 0.9028\n","Epoch 65/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.3077 - accuracy: 0.9722 - val_loss: 0.3880 - val_accuracy: 0.9028\n","Epoch 66/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.2911 - accuracy: 0.9877 - val_loss: 0.3385 - val_accuracy: 0.9583\n","Epoch 67/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.3080 - accuracy: 0.9691 - val_loss: 0.4450 - val_accuracy: 0.8333\n","Epoch 68/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.3056 - accuracy: 0.9691 - val_loss: 0.3530 - val_accuracy: 0.9306\n","Epoch 69/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.2958 - accuracy: 0.9753 - val_loss: 0.3554 - val_accuracy: 0.9306\n","Epoch 70/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.3065 - accuracy: 0.9630 - val_loss: 0.4153 - val_accuracy: 0.8750\n","Epoch 71/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2800 - accuracy: 0.9861 - val_loss: 0.3478 - val_accuracy: 0.9444\n","Epoch 72/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.2849 - accuracy: 0.9799 - val_loss: 0.3268 - val_accuracy: 0.9444\n","Epoch 73/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.2787 - accuracy: 0.9815 - val_loss: 0.3004 - val_accuracy: 0.9722\n","Epoch 74/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.2736 - accuracy: 0.9846 - val_loss: 0.3114 - val_accuracy: 0.9583\n","Epoch 75/100\n","65/65 [==============================] - 2s 23ms/step - loss: 0.2957 - accuracy: 0.9645 - val_loss: 0.3249 - val_accuracy: 0.9444\n","Epoch 76/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2748 - accuracy: 0.9799 - val_loss: 0.3942 - val_accuracy: 0.8750\n","Epoch 77/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2768 - accuracy: 0.9769 - val_loss: 0.3010 - val_accuracy: 0.9722\n","Epoch 78/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.2699 - accuracy: 0.9784 - val_loss: 0.3658 - val_accuracy: 0.9028\n","Epoch 79/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.2741 - accuracy: 0.9753 - val_loss: 0.3626 - val_accuracy: 0.9028\n","Epoch 80/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2600 - accuracy: 0.9877 - val_loss: 0.3296 - val_accuracy: 0.9444\n","Epoch 81/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2730 - accuracy: 0.9769 - val_loss: 0.3113 - val_accuracy: 0.9306\n","Epoch 82/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2619 - accuracy: 0.9830 - val_loss: 0.3584 - val_accuracy: 0.9028\n","Epoch 83/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.2614 - accuracy: 0.9769 - val_loss: 0.3359 - val_accuracy: 0.9167\n","Epoch 84/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.2484 - accuracy: 0.9923 - val_loss: 0.3867 - val_accuracy: 0.8750\n","Epoch 85/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.2392 - accuracy: 0.9954 - val_loss: 0.3357 - val_accuracy: 0.9167\n","Epoch 86/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2552 - accuracy: 0.9799 - val_loss: 0.3324 - val_accuracy: 0.9167\n","Epoch 87/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2457 - accuracy: 0.9877 - val_loss: 0.3981 - val_accuracy: 0.8750\n","Epoch 88/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2421 - accuracy: 0.9877 - val_loss: 0.3814 - val_accuracy: 0.8889\n","Epoch 89/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.2480 - accuracy: 0.9830 - val_loss: 0.3516 - val_accuracy: 0.8889\n","Epoch 90/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.2436 - accuracy: 0.9815 - val_loss: 0.3039 - val_accuracy: 0.9444\n","Epoch 91/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.2419 - accuracy: 0.9861 - val_loss: 0.3447 - val_accuracy: 0.8750\n","Epoch 92/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.2343 - accuracy: 0.9846 - val_loss: 0.3547 - val_accuracy: 0.8889\n","Epoch 93/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.2385 - accuracy: 0.9846 - val_loss: 0.3082 - val_accuracy: 0.9444\n","Epoch 94/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2292 - accuracy: 0.9892 - val_loss: 0.2755 - val_accuracy: 0.9583\n","Epoch 95/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.2468 - accuracy: 0.9738 - val_loss: 0.2955 - val_accuracy: 0.9444\n","Epoch 96/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2449 - accuracy: 0.9784 - val_loss: 0.3834 - val_accuracy: 0.8611\n","Epoch 97/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2338 - accuracy: 0.9861 - val_loss: 0.2962 - val_accuracy: 0.9444\n","Epoch 98/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2267 - accuracy: 0.9892 - val_loss: 0.3857 - val_accuracy: 0.8611\n","Epoch 99/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.2161 - accuracy: 0.9938 - val_loss: 0.2983 - val_accuracy: 0.9167\n","Epoch 100/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.2212 - accuracy: 0.9877 - val_loss: 0.2698 - val_accuracy: 0.9583\n","3/3 [==============================] - 0s 9ms/step - loss: 0.3144 - accuracy: 0.9375\n","[0.3143990635871887, 0.9375]\n","0.928044612340349\n","WARNING:tensorflow:Layer LSTM_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer LSTM_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Results for fold 2\n","Epoch 1/100\n","65/65 [==============================] - 7s 33ms/step - loss: 0.8507 - accuracy: 0.5170 - val_loss: 0.8396 - val_accuracy: 0.5694\n","Epoch 2/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.8285 - accuracy: 0.6590 - val_loss: 0.8186 - val_accuracy: 0.6806\n","Epoch 3/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.8084 - accuracy: 0.6836 - val_loss: 0.7979 - val_accuracy: 0.6667\n","Epoch 4/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.7876 - accuracy: 0.7160 - val_loss: 0.7778 - val_accuracy: 0.6528\n","Epoch 5/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.7589 - accuracy: 0.7284 - val_loss: 0.7541 - val_accuracy: 0.6528\n","Epoch 6/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.7160 - accuracy: 0.7454 - val_loss: 0.7222 - val_accuracy: 0.6528\n","Epoch 7/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.6836 - accuracy: 0.7485 - val_loss: 0.7072 - val_accuracy: 0.6528\n","Epoch 8/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.6677 - accuracy: 0.7670 - val_loss: 0.7031 - val_accuracy: 0.6528\n","Epoch 9/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.6459 - accuracy: 0.7932 - val_loss: 0.6936 - val_accuracy: 0.6667\n","Epoch 10/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.6414 - accuracy: 0.7577 - val_loss: 0.6785 - val_accuracy: 0.6528\n","Epoch 11/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.6051 - accuracy: 0.8179 - val_loss: 0.6722 - val_accuracy: 0.6667\n","Epoch 12/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.6030 - accuracy: 0.8164 - val_loss: 0.6336 - val_accuracy: 0.7500\n","Epoch 13/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.5917 - accuracy: 0.8148 - val_loss: 0.6259 - val_accuracy: 0.7500\n","Epoch 14/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.5838 - accuracy: 0.8318 - val_loss: 0.6000 - val_accuracy: 0.7917\n","Epoch 15/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.5676 - accuracy: 0.8426 - val_loss: 0.6277 - val_accuracy: 0.6944\n","Epoch 16/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.5592 - accuracy: 0.8426 - val_loss: 0.5952 - val_accuracy: 0.7639\n","Epoch 17/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.5678 - accuracy: 0.8256 - val_loss: 0.6437 - val_accuracy: 0.6944\n","Epoch 18/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.5530 - accuracy: 0.8549 - val_loss: 0.6047 - val_accuracy: 0.7361\n","Epoch 19/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.5276 - accuracy: 0.8657 - val_loss: 0.5726 - val_accuracy: 0.8056\n","Epoch 20/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.5133 - accuracy: 0.8920 - val_loss: 0.5325 - val_accuracy: 0.8472\n","Epoch 21/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.4993 - accuracy: 0.9028 - val_loss: 0.5333 - val_accuracy: 0.8194\n","Epoch 22/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.4903 - accuracy: 0.9043 - val_loss: 0.5364 - val_accuracy: 0.8194\n","Epoch 23/100\n","65/65 [==============================] - 2s 23ms/step - loss: 0.4845 - accuracy: 0.9120 - val_loss: 0.5101 - val_accuracy: 0.8333\n","Epoch 24/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.4777 - accuracy: 0.9028 - val_loss: 0.5091 - val_accuracy: 0.8611\n","Epoch 25/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.4753 - accuracy: 0.9012 - val_loss: 0.5303 - val_accuracy: 0.8194\n","Epoch 26/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.4591 - accuracy: 0.9213 - val_loss: 0.5264 - val_accuracy: 0.8194\n","Epoch 27/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.4599 - accuracy: 0.9167 - val_loss: 0.5156 - val_accuracy: 0.8333\n","Epoch 28/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.4530 - accuracy: 0.9167 - val_loss: 0.5139 - val_accuracy: 0.8056\n","Epoch 29/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.4470 - accuracy: 0.9198 - val_loss: 0.5177 - val_accuracy: 0.8333\n","Epoch 30/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.4521 - accuracy: 0.9167 - val_loss: 0.5124 - val_accuracy: 0.8194\n","Epoch 31/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.4430 - accuracy: 0.9228 - val_loss: 0.5017 - val_accuracy: 0.8333\n","Epoch 32/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.4330 - accuracy: 0.9336 - val_loss: 0.4936 - val_accuracy: 0.8611\n","Epoch 33/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.4255 - accuracy: 0.9352 - val_loss: 0.4747 - val_accuracy: 0.8611\n","Epoch 34/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.4193 - accuracy: 0.9336 - val_loss: 0.4787 - val_accuracy: 0.8472\n","Epoch 35/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.4242 - accuracy: 0.9290 - val_loss: 0.4941 - val_accuracy: 0.8472\n","Epoch 36/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.3994 - accuracy: 0.9522 - val_loss: 0.5111 - val_accuracy: 0.8194\n","Epoch 37/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.3981 - accuracy: 0.9475 - val_loss: 0.4890 - val_accuracy: 0.8333\n","Epoch 38/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.4002 - accuracy: 0.9414 - val_loss: 0.4820 - val_accuracy: 0.8472\n","Epoch 39/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.3908 - accuracy: 0.9599 - val_loss: 0.4941 - val_accuracy: 0.8333\n","Epoch 40/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.3913 - accuracy: 0.9491 - val_loss: 0.4620 - val_accuracy: 0.8611\n","Epoch 41/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.3786 - accuracy: 0.9568 - val_loss: 0.4692 - val_accuracy: 0.8750\n","Epoch 42/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.3881 - accuracy: 0.9475 - val_loss: 0.5369 - val_accuracy: 0.7778\n","Epoch 43/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.3735 - accuracy: 0.9599 - val_loss: 0.4735 - val_accuracy: 0.8611\n","Epoch 44/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3683 - accuracy: 0.9568 - val_loss: 0.5129 - val_accuracy: 0.7917\n","Epoch 45/100\n","65/65 [==============================] - 2s 23ms/step - loss: 0.3678 - accuracy: 0.9583 - val_loss: 0.4825 - val_accuracy: 0.8472\n","Epoch 46/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.3575 - accuracy: 0.9645 - val_loss: 0.4839 - val_accuracy: 0.8333\n","Epoch 47/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.3557 - accuracy: 0.9660 - val_loss: 0.4703 - val_accuracy: 0.8333\n","Epoch 48/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.3591 - accuracy: 0.9583 - val_loss: 0.4525 - val_accuracy: 0.8889\n","Epoch 49/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.3484 - accuracy: 0.9630 - val_loss: 0.4386 - val_accuracy: 0.8750\n","Epoch 50/100\n","65/65 [==============================] - 2s 23ms/step - loss: 0.3804 - accuracy: 0.9275 - val_loss: 0.4201 - val_accuracy: 0.8889\n","Epoch 51/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.3325 - accuracy: 0.9738 - val_loss: 0.4436 - val_accuracy: 0.8750\n","Epoch 52/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.3398 - accuracy: 0.9645 - val_loss: 0.4866 - val_accuracy: 0.8333\n","Epoch 53/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3396 - accuracy: 0.9599 - val_loss: 0.3822 - val_accuracy: 0.9167\n","Epoch 54/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.3441 - accuracy: 0.9568 - val_loss: 0.4589 - val_accuracy: 0.8333\n","Epoch 55/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.3466 - accuracy: 0.9475 - val_loss: 0.4427 - val_accuracy: 0.8611\n","Epoch 56/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.3384 - accuracy: 0.9599 - val_loss: 0.4598 - val_accuracy: 0.8472\n","Epoch 57/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3231 - accuracy: 0.9707 - val_loss: 0.5103 - val_accuracy: 0.7917\n","Epoch 58/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.3149 - accuracy: 0.9769 - val_loss: 0.4106 - val_accuracy: 0.8889\n","Epoch 59/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.3150 - accuracy: 0.9722 - val_loss: 0.4016 - val_accuracy: 0.9028\n","Epoch 60/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.3185 - accuracy: 0.9645 - val_loss: 0.3742 - val_accuracy: 0.9167\n","Epoch 61/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.3115 - accuracy: 0.9676 - val_loss: 0.4164 - val_accuracy: 0.8889\n","Epoch 62/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.2993 - accuracy: 0.9799 - val_loss: 0.3897 - val_accuracy: 0.8889\n","Epoch 63/100\n","65/65 [==============================] - 2s 23ms/step - loss: 0.2960 - accuracy: 0.9861 - val_loss: 0.4063 - val_accuracy: 0.8750\n","Epoch 64/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2884 - accuracy: 0.9877 - val_loss: 0.3932 - val_accuracy: 0.9028\n","Epoch 65/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.2985 - accuracy: 0.9738 - val_loss: 0.4024 - val_accuracy: 0.8889\n","Epoch 66/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2893 - accuracy: 0.9846 - val_loss: 0.3689 - val_accuracy: 0.9167\n","Epoch 67/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.2918 - accuracy: 0.9799 - val_loss: 0.3865 - val_accuracy: 0.8889\n","Epoch 68/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.2969 - accuracy: 0.9738 - val_loss: 0.4825 - val_accuracy: 0.8056\n","Epoch 69/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.2871 - accuracy: 0.9769 - val_loss: 0.3777 - val_accuracy: 0.9167\n","Epoch 70/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.3003 - accuracy: 0.9583 - val_loss: 0.3450 - val_accuracy: 0.9306\n","Epoch 71/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2849 - accuracy: 0.9753 - val_loss: 0.3807 - val_accuracy: 0.8889\n","Epoch 72/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.2695 - accuracy: 0.9892 - val_loss: 0.3810 - val_accuracy: 0.9167\n","Epoch 73/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.2605 - accuracy: 0.9907 - val_loss: 0.4396 - val_accuracy: 0.8472\n","Epoch 74/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.2852 - accuracy: 0.9738 - val_loss: 0.4429 - val_accuracy: 0.8333\n","Epoch 75/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.2693 - accuracy: 0.9784 - val_loss: 0.4430 - val_accuracy: 0.8333\n","Epoch 76/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2768 - accuracy: 0.9722 - val_loss: 0.3912 - val_accuracy: 0.8889\n","Epoch 77/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2718 - accuracy: 0.9738 - val_loss: 0.4229 - val_accuracy: 0.8611\n","Epoch 78/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2639 - accuracy: 0.9815 - val_loss: 0.4327 - val_accuracy: 0.8472\n","Epoch 79/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.2809 - accuracy: 0.9630 - val_loss: 0.3481 - val_accuracy: 0.9028\n","Epoch 80/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2730 - accuracy: 0.9691 - val_loss: 0.3927 - val_accuracy: 0.8889\n","Epoch 81/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.2572 - accuracy: 0.9830 - val_loss: 0.3998 - val_accuracy: 0.8750\n","Epoch 82/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2438 - accuracy: 0.9892 - val_loss: 0.3845 - val_accuracy: 0.8889\n","Epoch 83/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2640 - accuracy: 0.9738 - val_loss: 0.3704 - val_accuracy: 0.8750\n","Epoch 84/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.2471 - accuracy: 0.9830 - val_loss: 0.3705 - val_accuracy: 0.8889\n","Epoch 85/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2403 - accuracy: 0.9877 - val_loss: 0.3533 - val_accuracy: 0.9028\n","Epoch 86/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2493 - accuracy: 0.9799 - val_loss: 0.3719 - val_accuracy: 0.8889\n","Epoch 87/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2389 - accuracy: 0.9861 - val_loss: 0.3216 - val_accuracy: 0.9167\n","Epoch 88/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.2417 - accuracy: 0.9861 - val_loss: 0.3150 - val_accuracy: 0.9167\n","Epoch 89/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2266 - accuracy: 0.9938 - val_loss: 0.3128 - val_accuracy: 0.9306\n","Epoch 90/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2349 - accuracy: 0.9815 - val_loss: 0.3509 - val_accuracy: 0.9028\n","Epoch 91/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.2320 - accuracy: 0.9907 - val_loss: 0.3644 - val_accuracy: 0.8889\n","Epoch 92/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.2295 - accuracy: 0.9877 - val_loss: 0.4083 - val_accuracy: 0.8889\n","Epoch 93/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.2260 - accuracy: 0.9877 - val_loss: 0.3805 - val_accuracy: 0.8750\n","Epoch 94/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2233 - accuracy: 0.9877 - val_loss: 0.3579 - val_accuracy: 0.9028\n","Epoch 95/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.2194 - accuracy: 0.9892 - val_loss: 0.4437 - val_accuracy: 0.8472\n","Epoch 96/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2425 - accuracy: 0.9707 - val_loss: 0.4223 - val_accuracy: 0.8611\n","Epoch 97/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.2403 - accuracy: 0.9784 - val_loss: 0.3628 - val_accuracy: 0.8889\n","Epoch 98/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.2067 - accuracy: 0.9969 - val_loss: 0.3580 - val_accuracy: 0.8750\n","Epoch 99/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.2217 - accuracy: 0.9830 - val_loss: 0.3288 - val_accuracy: 0.9028\n","Epoch 100/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.2129 - accuracy: 0.9907 - val_loss: 0.4049 - val_accuracy: 0.8472\n","3/3 [==============================] - 0s 9ms/step - loss: 0.3025 - accuracy: 0.9375\n","[0.3025203049182892, 0.9375]\n","0.928044612340349\n","WARNING:tensorflow:Layer LSTM_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer LSTM_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Results for fold 3\n","Epoch 1/100\n","65/65 [==============================] - 8s 37ms/step - loss: 0.8507 - accuracy: 0.6096 - val_loss: 0.8390 - val_accuracy: 0.6944\n","Epoch 2/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.8290 - accuracy: 0.7006 - val_loss: 0.8175 - val_accuracy: 0.7639\n","Epoch 3/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.8093 - accuracy: 0.7207 - val_loss: 0.7974 - val_accuracy: 0.7500\n","Epoch 4/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.7887 - accuracy: 0.7284 - val_loss: 0.7691 - val_accuracy: 0.7083\n","Epoch 5/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.7650 - accuracy: 0.7377 - val_loss: 0.7308 - val_accuracy: 0.7778\n","Epoch 6/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.7344 - accuracy: 0.7515 - val_loss: 0.6984 - val_accuracy: 0.7639\n","Epoch 7/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.6997 - accuracy: 0.7623 - val_loss: 0.6606 - val_accuracy: 0.7917\n","Epoch 8/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.6735 - accuracy: 0.7670 - val_loss: 0.6325 - val_accuracy: 0.8472\n","Epoch 9/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.6523 - accuracy: 0.7809 - val_loss: 0.6350 - val_accuracy: 0.7917\n","Epoch 10/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.6267 - accuracy: 0.8071 - val_loss: 0.5979 - val_accuracy: 0.8750\n","Epoch 11/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.6121 - accuracy: 0.7994 - val_loss: 0.5992 - val_accuracy: 0.8056\n","Epoch 12/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.6045 - accuracy: 0.8117 - val_loss: 0.6002 - val_accuracy: 0.8056\n","Epoch 13/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.6004 - accuracy: 0.8009 - val_loss: 0.5989 - val_accuracy: 0.7639\n","Epoch 14/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.5713 - accuracy: 0.8287 - val_loss: 0.5514 - val_accuracy: 0.8611\n","Epoch 15/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.5438 - accuracy: 0.8704 - val_loss: 0.5506 - val_accuracy: 0.8333\n","Epoch 16/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.5453 - accuracy: 0.8657 - val_loss: 0.5810 - val_accuracy: 0.7917\n","Epoch 17/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.5331 - accuracy: 0.8796 - val_loss: 0.5366 - val_accuracy: 0.8750\n","Epoch 18/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.5195 - accuracy: 0.8873 - val_loss: 0.5164 - val_accuracy: 0.8889\n","Epoch 19/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.5056 - accuracy: 0.8750 - val_loss: 0.5286 - val_accuracy: 0.8472\n","Epoch 20/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.5025 - accuracy: 0.9012 - val_loss: 0.5001 - val_accuracy: 0.9028\n","Epoch 21/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.4792 - accuracy: 0.9275 - val_loss: 0.4908 - val_accuracy: 0.8889\n","Epoch 22/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.4851 - accuracy: 0.8997 - val_loss: 0.5205 - val_accuracy: 0.8472\n","Epoch 23/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.4830 - accuracy: 0.8997 - val_loss: 0.5636 - val_accuracy: 0.7778\n","Epoch 24/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4675 - accuracy: 0.9198 - val_loss: 0.4933 - val_accuracy: 0.8472\n","Epoch 25/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.4432 - accuracy: 0.9429 - val_loss: 0.4724 - val_accuracy: 0.9028\n","Epoch 26/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4545 - accuracy: 0.9105 - val_loss: 0.4563 - val_accuracy: 0.9028\n","Epoch 27/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.4338 - accuracy: 0.9398 - val_loss: 0.4547 - val_accuracy: 0.9028\n","Epoch 28/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.4281 - accuracy: 0.9460 - val_loss: 0.4623 - val_accuracy: 0.9167\n","Epoch 29/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.4384 - accuracy: 0.9228 - val_loss: 0.4447 - val_accuracy: 0.9167\n","Epoch 30/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.4414 - accuracy: 0.9105 - val_loss: 0.4289 - val_accuracy: 0.9444\n","Epoch 31/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4209 - accuracy: 0.9367 - val_loss: 0.4791 - val_accuracy: 0.8611\n","Epoch 32/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4076 - accuracy: 0.9491 - val_loss: 0.4533 - val_accuracy: 0.8750\n","Epoch 33/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.4123 - accuracy: 0.9367 - val_loss: 0.4457 - val_accuracy: 0.9167\n","Epoch 34/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.4193 - accuracy: 0.9306 - val_loss: 0.4623 - val_accuracy: 0.8611\n","Epoch 35/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3901 - accuracy: 0.9491 - val_loss: 0.4486 - val_accuracy: 0.8750\n","Epoch 36/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3899 - accuracy: 0.9568 - val_loss: 0.4446 - val_accuracy: 0.8750\n","Epoch 37/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.3692 - accuracy: 0.9707 - val_loss: 0.4165 - val_accuracy: 0.9306\n","Epoch 38/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3854 - accuracy: 0.9444 - val_loss: 0.4843 - val_accuracy: 0.8333\n","Epoch 39/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3841 - accuracy: 0.9475 - val_loss: 0.4110 - val_accuracy: 0.9306\n","Epoch 40/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.3692 - accuracy: 0.9599 - val_loss: 0.4083 - val_accuracy: 0.9306\n","Epoch 41/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3612 - accuracy: 0.9630 - val_loss: 0.4158 - val_accuracy: 0.9028\n","Epoch 42/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3621 - accuracy: 0.9645 - val_loss: 0.4118 - val_accuracy: 0.9167\n","Epoch 43/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.3579 - accuracy: 0.9552 - val_loss: 0.4109 - val_accuracy: 0.8889\n","Epoch 44/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3697 - accuracy: 0.9414 - val_loss: 0.5155 - val_accuracy: 0.8194\n","Epoch 45/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3598 - accuracy: 0.9506 - val_loss: 0.4129 - val_accuracy: 0.9028\n","Epoch 46/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.3449 - accuracy: 0.9660 - val_loss: 0.3871 - val_accuracy: 0.9444\n","Epoch 47/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3379 - accuracy: 0.9707 - val_loss: 0.3922 - val_accuracy: 0.9167\n","Epoch 48/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3410 - accuracy: 0.9614 - val_loss: 0.4011 - val_accuracy: 0.9028\n","Epoch 49/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3253 - accuracy: 0.9784 - val_loss: 0.3960 - val_accuracy: 0.8750\n","Epoch 50/100\n","65/65 [==============================] - 2s 38ms/step - loss: 0.3359 - accuracy: 0.9660 - val_loss: 0.4323 - val_accuracy: 0.8750\n","Epoch 51/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3280 - accuracy: 0.9614 - val_loss: 0.3927 - val_accuracy: 0.9167\n","Epoch 52/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3302 - accuracy: 0.9630 - val_loss: 0.3964 - val_accuracy: 0.9028\n","Epoch 53/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.3084 - accuracy: 0.9784 - val_loss: 0.3641 - val_accuracy: 0.9306\n","Epoch 54/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3154 - accuracy: 0.9691 - val_loss: 0.3946 - val_accuracy: 0.8750\n","Epoch 55/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3087 - accuracy: 0.9722 - val_loss: 0.3484 - val_accuracy: 0.9444\n","Epoch 56/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.3049 - accuracy: 0.9722 - val_loss: 0.3825 - val_accuracy: 0.8889\n","Epoch 57/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3004 - accuracy: 0.9799 - val_loss: 0.3621 - val_accuracy: 0.9306\n","Epoch 58/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2894 - accuracy: 0.9830 - val_loss: 0.3619 - val_accuracy: 0.9306\n","Epoch 59/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2948 - accuracy: 0.9769 - val_loss: 0.3689 - val_accuracy: 0.9028\n","Epoch 60/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2988 - accuracy: 0.9707 - val_loss: 0.4254 - val_accuracy: 0.8472\n","Epoch 61/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3059 - accuracy: 0.9599 - val_loss: 0.4091 - val_accuracy: 0.8611\n","Epoch 62/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2911 - accuracy: 0.9769 - val_loss: 0.3745 - val_accuracy: 0.9028\n","Epoch 63/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.2795 - accuracy: 0.9846 - val_loss: 0.3428 - val_accuracy: 0.9444\n","Epoch 64/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2846 - accuracy: 0.9753 - val_loss: 0.3787 - val_accuracy: 0.9028\n","Epoch 65/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2752 - accuracy: 0.9799 - val_loss: 0.3545 - val_accuracy: 0.9167\n","Epoch 66/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2688 - accuracy: 0.9846 - val_loss: 0.3581 - val_accuracy: 0.9167\n","Epoch 67/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2774 - accuracy: 0.9738 - val_loss: 0.3459 - val_accuracy: 0.9167\n","Epoch 68/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2682 - accuracy: 0.9784 - val_loss: 0.3726 - val_accuracy: 0.9028\n","Epoch 69/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2671 - accuracy: 0.9784 - val_loss: 0.3603 - val_accuracy: 0.8889\n","Epoch 70/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2633 - accuracy: 0.9769 - val_loss: 0.3255 - val_accuracy: 0.9444\n","Epoch 71/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2591 - accuracy: 0.9799 - val_loss: 0.4017 - val_accuracy: 0.8750\n","Epoch 72/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2491 - accuracy: 0.9892 - val_loss: 0.3200 - val_accuracy: 0.9444\n","Epoch 73/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2486 - accuracy: 0.9877 - val_loss: 0.3571 - val_accuracy: 0.9028\n","Epoch 74/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2476 - accuracy: 0.9892 - val_loss: 0.3897 - val_accuracy: 0.8750\n","Epoch 75/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2472 - accuracy: 0.9861 - val_loss: 0.4170 - val_accuracy: 0.8472\n","Epoch 76/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.2626 - accuracy: 0.9722 - val_loss: 0.3628 - val_accuracy: 0.9028\n","Epoch 77/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2559 - accuracy: 0.9769 - val_loss: 0.3037 - val_accuracy: 0.9306\n","Epoch 78/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2314 - accuracy: 0.9923 - val_loss: 0.3332 - val_accuracy: 0.8889\n","Epoch 79/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2383 - accuracy: 0.9892 - val_loss: 0.3352 - val_accuracy: 0.9167\n","Epoch 80/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2376 - accuracy: 0.9861 - val_loss: 0.4298 - val_accuracy: 0.8472\n","Epoch 81/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2358 - accuracy: 0.9846 - val_loss: 0.3496 - val_accuracy: 0.9028\n","Epoch 82/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2453 - accuracy: 0.9738 - val_loss: 0.3045 - val_accuracy: 0.9306\n","Epoch 83/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2310 - accuracy: 0.9846 - val_loss: 0.3061 - val_accuracy: 0.9306\n","Epoch 84/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2358 - accuracy: 0.9799 - val_loss: 0.3416 - val_accuracy: 0.9028\n","Epoch 85/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2320 - accuracy: 0.9815 - val_loss: 0.2786 - val_accuracy: 0.9583\n","Epoch 86/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2259 - accuracy: 0.9846 - val_loss: 0.3353 - val_accuracy: 0.9028\n","Epoch 87/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2260 - accuracy: 0.9830 - val_loss: 0.3968 - val_accuracy: 0.8611\n","Epoch 88/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2140 - accuracy: 0.9877 - val_loss: 0.3804 - val_accuracy: 0.8611\n","Epoch 89/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2257 - accuracy: 0.9799 - val_loss: 0.3161 - val_accuracy: 0.9028\n","Epoch 90/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2062 - accuracy: 0.9954 - val_loss: 0.3297 - val_accuracy: 0.9028\n","Epoch 91/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2116 - accuracy: 0.9877 - val_loss: 0.2805 - val_accuracy: 0.9583\n","Epoch 92/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2070 - accuracy: 0.9907 - val_loss: 0.3175 - val_accuracy: 0.9028\n","Epoch 93/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2033 - accuracy: 0.9892 - val_loss: 0.3529 - val_accuracy: 0.8889\n","Epoch 94/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2024 - accuracy: 0.9907 - val_loss: 0.2854 - val_accuracy: 0.9444\n","Epoch 95/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2096 - accuracy: 0.9846 - val_loss: 0.3193 - val_accuracy: 0.9167\n","Epoch 96/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2168 - accuracy: 0.9784 - val_loss: 0.3205 - val_accuracy: 0.8889\n","Epoch 97/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2104 - accuracy: 0.9815 - val_loss: 0.3025 - val_accuracy: 0.9306\n","Epoch 98/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2014 - accuracy: 0.9861 - val_loss: 0.2601 - val_accuracy: 0.9583\n","Epoch 99/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.2104 - accuracy: 0.9753 - val_loss: 0.2837 - val_accuracy: 0.9306\n","Epoch 100/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2100 - accuracy: 0.9784 - val_loss: 0.2684 - val_accuracy: 0.9444\n","3/3 [==============================] - 0s 13ms/step - loss: 0.3604 - accuracy: 0.8750\n","[0.3604029715061188, 0.875]\n","0.8511904761904763\n","WARNING:tensorflow:Layer LSTM_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer LSTM_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Results for fold 4\n","Epoch 1/100\n","65/65 [==============================] - 9s 44ms/step - loss: 0.8504 - accuracy: 0.5941 - val_loss: 0.8394 - val_accuracy: 0.7083\n","Epoch 2/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.8283 - accuracy: 0.6867 - val_loss: 0.8193 - val_accuracy: 0.6111\n","Epoch 3/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.8079 - accuracy: 0.6898 - val_loss: 0.7979 - val_accuracy: 0.7500\n","Epoch 4/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.7872 - accuracy: 0.6867 - val_loss: 0.7777 - val_accuracy: 0.6667\n","Epoch 5/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.7638 - accuracy: 0.7222 - val_loss: 0.7499 - val_accuracy: 0.6528\n","Epoch 6/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.7358 - accuracy: 0.7114 - val_loss: 0.7461 - val_accuracy: 0.5972\n","Epoch 7/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.7014 - accuracy: 0.7485 - val_loss: 0.7032 - val_accuracy: 0.6806\n","Epoch 8/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.6722 - accuracy: 0.7948 - val_loss: 0.6733 - val_accuracy: 0.7500\n","Epoch 9/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.6660 - accuracy: 0.7654 - val_loss: 0.6624 - val_accuracy: 0.7639\n","Epoch 10/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.6406 - accuracy: 0.8040 - val_loss: 0.6499 - val_accuracy: 0.7639\n","Epoch 11/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.6321 - accuracy: 0.7994 - val_loss: 0.6541 - val_accuracy: 0.7917\n","Epoch 12/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.6129 - accuracy: 0.8364 - val_loss: 0.6444 - val_accuracy: 0.7639\n","Epoch 13/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.6061 - accuracy: 0.8441 - val_loss: 0.6516 - val_accuracy: 0.7222\n","Epoch 14/100\n","65/65 [==============================] - 3s 39ms/step - loss: 0.5883 - accuracy: 0.8519 - val_loss: 0.6260 - val_accuracy: 0.7500\n","Epoch 15/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.5864 - accuracy: 0.8534 - val_loss: 0.6199 - val_accuracy: 0.7778\n","Epoch 16/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.5749 - accuracy: 0.8534 - val_loss: 0.5884 - val_accuracy: 0.8194\n","Epoch 17/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.5605 - accuracy: 0.8673 - val_loss: 0.5735 - val_accuracy: 0.8333\n","Epoch 18/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.5547 - accuracy: 0.8673 - val_loss: 0.5854 - val_accuracy: 0.8194\n","Epoch 19/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.5362 - accuracy: 0.8858 - val_loss: 0.5886 - val_accuracy: 0.7778\n","Epoch 20/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.5337 - accuracy: 0.8951 - val_loss: 0.5632 - val_accuracy: 0.8333\n","Epoch 21/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.5274 - accuracy: 0.8889 - val_loss: 0.5616 - val_accuracy: 0.8194\n","Epoch 22/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.5175 - accuracy: 0.8997 - val_loss: 0.5582 - val_accuracy: 0.8472\n","Epoch 23/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.5102 - accuracy: 0.8981 - val_loss: 0.5607 - val_accuracy: 0.8194\n","Epoch 24/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.5135 - accuracy: 0.8935 - val_loss: 0.5311 - val_accuracy: 0.8750\n","Epoch 25/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4898 - accuracy: 0.9182 - val_loss: 0.5202 - val_accuracy: 0.8750\n","Epoch 26/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.4818 - accuracy: 0.9306 - val_loss: 0.5388 - val_accuracy: 0.8611\n","Epoch 27/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.4818 - accuracy: 0.9198 - val_loss: 0.5414 - val_accuracy: 0.8472\n","Epoch 28/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4716 - accuracy: 0.9259 - val_loss: 0.5322 - val_accuracy: 0.8472\n","Epoch 29/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.4732 - accuracy: 0.9198 - val_loss: 0.5268 - val_accuracy: 0.8611\n","Epoch 30/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.4638 - accuracy: 0.9336 - val_loss: 0.5180 - val_accuracy: 0.8611\n","Epoch 31/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.4548 - accuracy: 0.9352 - val_loss: 0.4970 - val_accuracy: 0.8889\n","Epoch 32/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.4568 - accuracy: 0.9259 - val_loss: 0.5134 - val_accuracy: 0.8611\n","Epoch 33/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4533 - accuracy: 0.9336 - val_loss: 0.5035 - val_accuracy: 0.8750\n","Epoch 34/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.4497 - accuracy: 0.9336 - val_loss: 0.5106 - val_accuracy: 0.8472\n","Epoch 35/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.4371 - accuracy: 0.9398 - val_loss: 0.5337 - val_accuracy: 0.8333\n","Epoch 36/100\n","65/65 [==============================] - 2s 23ms/step - loss: 0.4321 - accuracy: 0.9506 - val_loss: 0.4791 - val_accuracy: 0.8889\n","Epoch 37/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4191 - accuracy: 0.9599 - val_loss: 0.4786 - val_accuracy: 0.8889\n","Epoch 38/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.4085 - accuracy: 0.9614 - val_loss: 0.5341 - val_accuracy: 0.8056\n","Epoch 39/100\n","65/65 [==============================] - 2s 23ms/step - loss: 0.4008 - accuracy: 0.9707 - val_loss: 0.4632 - val_accuracy: 0.9028\n","Epoch 40/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.4092 - accuracy: 0.9552 - val_loss: 0.4274 - val_accuracy: 0.9167\n","Epoch 41/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.4053 - accuracy: 0.9522 - val_loss: 0.4802 - val_accuracy: 0.8750\n","Epoch 42/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4186 - accuracy: 0.9383 - val_loss: 0.5051 - val_accuracy: 0.8333\n","Epoch 43/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4020 - accuracy: 0.9552 - val_loss: 0.5072 - val_accuracy: 0.8472\n","Epoch 44/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3874 - accuracy: 0.9707 - val_loss: 0.4711 - val_accuracy: 0.8750\n","Epoch 45/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3924 - accuracy: 0.9599 - val_loss: 0.4849 - val_accuracy: 0.8472\n","Epoch 46/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.3892 - accuracy: 0.9537 - val_loss: 0.4188 - val_accuracy: 0.9306\n","Epoch 47/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.3940 - accuracy: 0.9460 - val_loss: 0.4570 - val_accuracy: 0.8889\n","Epoch 48/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.3863 - accuracy: 0.9568 - val_loss: 0.4412 - val_accuracy: 0.9028\n","Epoch 49/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3810 - accuracy: 0.9599 - val_loss: 0.4237 - val_accuracy: 0.9167\n","Epoch 50/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.3658 - accuracy: 0.9784 - val_loss: 0.4331 - val_accuracy: 0.9028\n","Epoch 51/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.3645 - accuracy: 0.9660 - val_loss: 0.5154 - val_accuracy: 0.8194\n","Epoch 52/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.3724 - accuracy: 0.9537 - val_loss: 0.4468 - val_accuracy: 0.8750\n","Epoch 53/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.3671 - accuracy: 0.9645 - val_loss: 0.4620 - val_accuracy: 0.8611\n","Epoch 54/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.3748 - accuracy: 0.9506 - val_loss: 0.5061 - val_accuracy: 0.8194\n","Epoch 55/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.3765 - accuracy: 0.9506 - val_loss: 0.4666 - val_accuracy: 0.8611\n","Epoch 56/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3655 - accuracy: 0.9552 - val_loss: 0.4588 - val_accuracy: 0.8750\n","Epoch 57/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.3556 - accuracy: 0.9660 - val_loss: 0.4621 - val_accuracy: 0.8611\n","Epoch 58/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3449 - accuracy: 0.9676 - val_loss: 0.4415 - val_accuracy: 0.8889\n","Epoch 59/100\n","65/65 [==============================] - 3s 39ms/step - loss: 0.3492 - accuracy: 0.9630 - val_loss: 0.4755 - val_accuracy: 0.8472\n","Epoch 60/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3565 - accuracy: 0.9568 - val_loss: 0.5361 - val_accuracy: 0.7639\n","Epoch 61/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3392 - accuracy: 0.9707 - val_loss: 0.3971 - val_accuracy: 0.8889\n","Epoch 62/100\n","65/65 [==============================] - 2s 38ms/step - loss: 0.3432 - accuracy: 0.9630 - val_loss: 0.4712 - val_accuracy: 0.8333\n","Epoch 63/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.3213 - accuracy: 0.9799 - val_loss: 0.4460 - val_accuracy: 0.8611\n","Epoch 64/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.3335 - accuracy: 0.9691 - val_loss: 0.4106 - val_accuracy: 0.8750\n","Epoch 65/100\n","65/65 [==============================] - 3s 39ms/step - loss: 0.3225 - accuracy: 0.9753 - val_loss: 0.4413 - val_accuracy: 0.8611\n","Epoch 66/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3209 - accuracy: 0.9753 - val_loss: 0.4117 - val_accuracy: 0.9028\n","Epoch 67/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3097 - accuracy: 0.9846 - val_loss: 0.3953 - val_accuracy: 0.9028\n","Epoch 68/100\n","65/65 [==============================] - 2s 38ms/step - loss: 0.3052 - accuracy: 0.9861 - val_loss: 0.4523 - val_accuracy: 0.8611\n","Epoch 69/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3182 - accuracy: 0.9722 - val_loss: 0.4500 - val_accuracy: 0.8333\n","Epoch 70/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3014 - accuracy: 0.9846 - val_loss: 0.4545 - val_accuracy: 0.8472\n","Epoch 71/100\n","65/65 [==============================] - 2s 38ms/step - loss: 0.3019 - accuracy: 0.9815 - val_loss: 0.4626 - val_accuracy: 0.8333\n","Epoch 72/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2983 - accuracy: 0.9830 - val_loss: 0.3943 - val_accuracy: 0.9028\n","Epoch 73/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2865 - accuracy: 0.9907 - val_loss: 0.3811 - val_accuracy: 0.8889\n","Epoch 74/100\n","65/65 [==============================] - 3s 40ms/step - loss: 0.2910 - accuracy: 0.9861 - val_loss: 0.4278 - val_accuracy: 0.8750\n","Epoch 75/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3061 - accuracy: 0.9691 - val_loss: 0.3920 - val_accuracy: 0.8750\n","Epoch 76/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2862 - accuracy: 0.9877 - val_loss: 0.4112 - val_accuracy: 0.8889\n","Epoch 77/100\n","65/65 [==============================] - 2s 38ms/step - loss: 0.3106 - accuracy: 0.9599 - val_loss: 0.3739 - val_accuracy: 0.9167\n","Epoch 78/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2875 - accuracy: 0.9799 - val_loss: 0.3958 - val_accuracy: 0.9028\n","Epoch 79/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2855 - accuracy: 0.9815 - val_loss: 0.3928 - val_accuracy: 0.9028\n","Epoch 80/100\n","65/65 [==============================] - 2s 38ms/step - loss: 0.2772 - accuracy: 0.9846 - val_loss: 0.4220 - val_accuracy: 0.8750\n","Epoch 81/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.2972 - accuracy: 0.9614 - val_loss: 0.3957 - val_accuracy: 0.8889\n","Epoch 82/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2780 - accuracy: 0.9830 - val_loss: 0.4214 - val_accuracy: 0.8611\n","Epoch 83/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2680 - accuracy: 0.9892 - val_loss: 0.3707 - val_accuracy: 0.9028\n","Epoch 84/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2561 - accuracy: 0.9969 - val_loss: 0.4120 - val_accuracy: 0.8750\n","Epoch 85/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.2678 - accuracy: 0.9877 - val_loss: 0.4432 - val_accuracy: 0.8333\n","Epoch 86/100\n","65/65 [==============================] - 3s 40ms/step - loss: 0.2671 - accuracy: 0.9815 - val_loss: 0.4039 - val_accuracy: 0.8750\n","Epoch 87/100\n","65/65 [==============================] - 3s 39ms/step - loss: 0.2842 - accuracy: 0.9676 - val_loss: 0.4008 - val_accuracy: 0.8889\n","Epoch 88/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2863 - accuracy: 0.9630 - val_loss: 0.3560 - val_accuracy: 0.9167\n","Epoch 89/100\n","65/65 [==============================] - 3s 41ms/step - loss: 0.2745 - accuracy: 0.9707 - val_loss: 0.3865 - val_accuracy: 0.8889\n","Epoch 90/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.2814 - accuracy: 0.9676 - val_loss: 0.4382 - val_accuracy: 0.8333\n","Epoch 91/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2698 - accuracy: 0.9769 - val_loss: 0.4403 - val_accuracy: 0.8472\n","Epoch 92/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2555 - accuracy: 0.9861 - val_loss: 0.4651 - val_accuracy: 0.8333\n","Epoch 93/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.2754 - accuracy: 0.9660 - val_loss: 0.3510 - val_accuracy: 0.9306\n","Epoch 94/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2598 - accuracy: 0.9753 - val_loss: 0.3462 - val_accuracy: 0.9167\n","Epoch 95/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.2383 - accuracy: 0.9954 - val_loss: 0.3824 - val_accuracy: 0.8889\n","Epoch 96/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2455 - accuracy: 0.9861 - val_loss: 0.3984 - val_accuracy: 0.8750\n","Epoch 97/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2387 - accuracy: 0.9907 - val_loss: 0.4762 - val_accuracy: 0.8194\n","Epoch 98/100\n","65/65 [==============================] - 3s 42ms/step - loss: 0.2306 - accuracy: 0.9938 - val_loss: 0.4533 - val_accuracy: 0.8472\n","Epoch 99/100\n","65/65 [==============================] - 3s 39ms/step - loss: 0.2414 - accuracy: 0.9830 - val_loss: 0.4106 - val_accuracy: 0.8750\n","Epoch 100/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.2301 - accuracy: 0.9938 - val_loss: 0.3812 - val_accuracy: 0.8889\n","3/3 [==============================] - 0s 11ms/step - loss: 0.3701 - accuracy: 0.8875\n","[0.37010568380355835, 0.887499988079071]\n","0.8773633111905978\n","WARNING:tensorflow:Layer LSTM_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer LSTM_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Results for fold 5\n","Epoch 1/100\n","65/65 [==============================] - 8s 39ms/step - loss: 0.8512 - accuracy: 0.5123 - val_loss: 0.8390 - val_accuracy: 0.7917\n","Epoch 2/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.8297 - accuracy: 0.6852 - val_loss: 0.8185 - val_accuracy: 0.7778\n","Epoch 3/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.8098 - accuracy: 0.7099 - val_loss: 0.7937 - val_accuracy: 0.8056\n","Epoch 4/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.7887 - accuracy: 0.7469 - val_loss: 0.7685 - val_accuracy: 0.7778\n","Epoch 5/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.7516 - accuracy: 0.7222 - val_loss: 0.6777 - val_accuracy: 0.8194\n","Epoch 6/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.7095 - accuracy: 0.7130 - val_loss: 0.6242 - val_accuracy: 0.8472\n","Epoch 7/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.6704 - accuracy: 0.7515 - val_loss: 0.6019 - val_accuracy: 0.8472\n","Epoch 8/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.6400 - accuracy: 0.7963 - val_loss: 0.5882 - val_accuracy: 0.8611\n","Epoch 9/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.6126 - accuracy: 0.8210 - val_loss: 0.5757 - val_accuracy: 0.8611\n","Epoch 10/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.5998 - accuracy: 0.8287 - val_loss: 0.5593 - val_accuracy: 0.8750\n","Epoch 11/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.5925 - accuracy: 0.8241 - val_loss: 0.5579 - val_accuracy: 0.8611\n","Epoch 12/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.5566 - accuracy: 0.8765 - val_loss: 0.5773 - val_accuracy: 0.7917\n","Epoch 13/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.5544 - accuracy: 0.8472 - val_loss: 0.5717 - val_accuracy: 0.8056\n","Epoch 14/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.5499 - accuracy: 0.8627 - val_loss: 0.5505 - val_accuracy: 0.8194\n","Epoch 15/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.5341 - accuracy: 0.8657 - val_loss: 0.5496 - val_accuracy: 0.8194\n","Epoch 16/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.5205 - accuracy: 0.8781 - val_loss: 0.5607 - val_accuracy: 0.8194\n","Epoch 17/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.5058 - accuracy: 0.8889 - val_loss: 0.5511 - val_accuracy: 0.7917\n","Epoch 18/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.5102 - accuracy: 0.8796 - val_loss: 0.5320 - val_accuracy: 0.8333\n","Epoch 19/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.4899 - accuracy: 0.8951 - val_loss: 0.5117 - val_accuracy: 0.8750\n","Epoch 20/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.4825 - accuracy: 0.9043 - val_loss: 0.5214 - val_accuracy: 0.8472\n","Epoch 21/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.4711 - accuracy: 0.9120 - val_loss: 0.5261 - val_accuracy: 0.8194\n","Epoch 22/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.4719 - accuracy: 0.9090 - val_loss: 0.4945 - val_accuracy: 0.8750\n","Epoch 23/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.4600 - accuracy: 0.9120 - val_loss: 0.4846 - val_accuracy: 0.8750\n","Epoch 24/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.4488 - accuracy: 0.9074 - val_loss: 0.4980 - val_accuracy: 0.8472\n","Epoch 25/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4264 - accuracy: 0.9398 - val_loss: 0.5028 - val_accuracy: 0.8472\n","Epoch 26/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.4178 - accuracy: 0.9444 - val_loss: 0.4802 - val_accuracy: 0.8750\n","Epoch 27/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.4250 - accuracy: 0.9290 - val_loss: 0.4820 - val_accuracy: 0.8611\n","Epoch 28/100\n","65/65 [==============================] - 3s 43ms/step - loss: 0.4189 - accuracy: 0.9306 - val_loss: 0.5147 - val_accuracy: 0.8194\n","Epoch 29/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.4037 - accuracy: 0.9475 - val_loss: 0.4796 - val_accuracy: 0.8611\n","Epoch 30/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.4042 - accuracy: 0.9414 - val_loss: 0.4928 - val_accuracy: 0.8472\n","Epoch 31/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.3764 - accuracy: 0.9722 - val_loss: 0.4846 - val_accuracy: 0.8472\n","Epoch 32/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.3877 - accuracy: 0.9460 - val_loss: 0.4847 - val_accuracy: 0.8333\n","Epoch 33/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.3904 - accuracy: 0.9398 - val_loss: 0.5006 - val_accuracy: 0.8194\n","Epoch 34/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.3792 - accuracy: 0.9475 - val_loss: 0.4927 - val_accuracy: 0.8333\n","Epoch 35/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.3782 - accuracy: 0.9522 - val_loss: 0.4450 - val_accuracy: 0.8750\n","Epoch 36/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.3680 - accuracy: 0.9537 - val_loss: 0.4814 - val_accuracy: 0.8333\n","Epoch 37/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.3561 - accuracy: 0.9660 - val_loss: 0.4535 - val_accuracy: 0.8889\n","Epoch 38/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3531 - accuracy: 0.9691 - val_loss: 0.4601 - val_accuracy: 0.8611\n","Epoch 39/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3448 - accuracy: 0.9753 - val_loss: 0.4584 - val_accuracy: 0.8611\n","Epoch 40/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3501 - accuracy: 0.9552 - val_loss: 0.4648 - val_accuracy: 0.8472\n","Epoch 41/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.3492 - accuracy: 0.9522 - val_loss: 0.4600 - val_accuracy: 0.8611\n","Epoch 42/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.3536 - accuracy: 0.9491 - val_loss: 0.4690 - val_accuracy: 0.8333\n","Epoch 43/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3414 - accuracy: 0.9568 - val_loss: 0.4637 - val_accuracy: 0.8472\n","Epoch 44/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3331 - accuracy: 0.9722 - val_loss: 0.4661 - val_accuracy: 0.8472\n","Epoch 45/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3366 - accuracy: 0.9599 - val_loss: 0.4121 - val_accuracy: 0.8889\n","Epoch 46/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3319 - accuracy: 0.9599 - val_loss: 0.4602 - val_accuracy: 0.8472\n","Epoch 47/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3194 - accuracy: 0.9691 - val_loss: 0.4431 - val_accuracy: 0.8194\n","Epoch 48/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3267 - accuracy: 0.9599 - val_loss: 0.4298 - val_accuracy: 0.8750\n","Epoch 49/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.3156 - accuracy: 0.9722 - val_loss: 0.4268 - val_accuracy: 0.8750\n","Epoch 50/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.3040 - accuracy: 0.9799 - val_loss: 0.4153 - val_accuracy: 0.8889\n","Epoch 51/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.3109 - accuracy: 0.9691 - val_loss: 0.3991 - val_accuracy: 0.8889\n","Epoch 52/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.2928 - accuracy: 0.9799 - val_loss: 0.4141 - val_accuracy: 0.8889\n","Epoch 53/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.2935 - accuracy: 0.9784 - val_loss: 0.4051 - val_accuracy: 0.8889\n","Epoch 54/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.2844 - accuracy: 0.9830 - val_loss: 0.4157 - val_accuracy: 0.8750\n","Epoch 55/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.2827 - accuracy: 0.9861 - val_loss: 0.4418 - val_accuracy: 0.8472\n","Epoch 56/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2972 - accuracy: 0.9660 - val_loss: 0.3895 - val_accuracy: 0.8889\n","Epoch 57/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2833 - accuracy: 0.9815 - val_loss: 0.3978 - val_accuracy: 0.8750\n","Epoch 58/100\n","65/65 [==============================] - 3s 40ms/step - loss: 0.2801 - accuracy: 0.9784 - val_loss: 0.4175 - val_accuracy: 0.8750\n","Epoch 59/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2775 - accuracy: 0.9815 - val_loss: 0.4261 - val_accuracy: 0.8472\n","Epoch 60/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.2849 - accuracy: 0.9676 - val_loss: 0.4398 - val_accuracy: 0.8472\n","Epoch 61/100\n","65/65 [==============================] - 3s 41ms/step - loss: 0.2803 - accuracy: 0.9722 - val_loss: 0.4168 - val_accuracy: 0.8750\n","Epoch 62/100\n","65/65 [==============================] - 2s 38ms/step - loss: 0.2620 - accuracy: 0.9923 - val_loss: 0.4129 - val_accuracy: 0.8611\n","Epoch 63/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2550 - accuracy: 0.9892 - val_loss: 0.4036 - val_accuracy: 0.8611\n","Epoch 64/100\n","65/65 [==============================] - 3s 39ms/step - loss: 0.2628 - accuracy: 0.9815 - val_loss: 0.4437 - val_accuracy: 0.8472\n","Epoch 65/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2569 - accuracy: 0.9846 - val_loss: 0.4166 - val_accuracy: 0.8611\n","Epoch 66/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2652 - accuracy: 0.9784 - val_loss: 0.3867 - val_accuracy: 0.9028\n","Epoch 67/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2616 - accuracy: 0.9769 - val_loss: 0.4373 - val_accuracy: 0.8472\n","Epoch 68/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2448 - accuracy: 0.9907 - val_loss: 0.4218 - val_accuracy: 0.8472\n","Epoch 69/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.2530 - accuracy: 0.9784 - val_loss: 0.4183 - val_accuracy: 0.8750\n","Epoch 70/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.2466 - accuracy: 0.9877 - val_loss: 0.4262 - val_accuracy: 0.8333\n","Epoch 71/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2495 - accuracy: 0.9830 - val_loss: 0.3796 - val_accuracy: 0.8889\n","Epoch 72/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.2495 - accuracy: 0.9784 - val_loss: 0.4259 - val_accuracy: 0.8611\n","Epoch 73/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.2300 - accuracy: 0.9923 - val_loss: 0.3805 - val_accuracy: 0.8750\n","Epoch 74/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.2426 - accuracy: 0.9799 - val_loss: 0.4240 - val_accuracy: 0.8611\n","Epoch 75/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.2317 - accuracy: 0.9877 - val_loss: 0.3859 - val_accuracy: 0.8611\n","Epoch 76/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.2259 - accuracy: 0.9938 - val_loss: 0.3995 - val_accuracy: 0.8611\n","Epoch 77/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2226 - accuracy: 0.9923 - val_loss: 0.3716 - val_accuracy: 0.8750\n","Epoch 78/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2552 - accuracy: 0.9676 - val_loss: 0.3986 - val_accuracy: 0.8750\n","Epoch 79/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2405 - accuracy: 0.9769 - val_loss: 0.3851 - val_accuracy: 0.8750\n","Epoch 80/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2176 - accuracy: 0.9907 - val_loss: 0.3630 - val_accuracy: 0.8889\n","Epoch 81/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2300 - accuracy: 0.9830 - val_loss: 0.3904 - val_accuracy: 0.8750\n","Epoch 82/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2340 - accuracy: 0.9784 - val_loss: 0.3826 - val_accuracy: 0.8750\n","Epoch 83/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.2212 - accuracy: 0.9877 - val_loss: 0.3886 - val_accuracy: 0.8611\n","Epoch 84/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2183 - accuracy: 0.9830 - val_loss: 0.4199 - val_accuracy: 0.8333\n","Epoch 85/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2080 - accuracy: 0.9923 - val_loss: 0.3572 - val_accuracy: 0.9028\n","Epoch 86/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2105 - accuracy: 0.9877 - val_loss: 0.3556 - val_accuracy: 0.8889\n","Epoch 87/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2055 - accuracy: 0.9923 - val_loss: 0.3637 - val_accuracy: 0.8889\n","Epoch 88/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.1975 - accuracy: 0.9985 - val_loss: 0.3268 - val_accuracy: 0.9028\n","Epoch 89/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.1931 - accuracy: 0.9954 - val_loss: 0.3801 - val_accuracy: 0.8750\n","Epoch 90/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.1944 - accuracy: 0.9954 - val_loss: 0.3516 - val_accuracy: 0.9028\n","Epoch 91/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.1934 - accuracy: 0.9923 - val_loss: 0.3508 - val_accuracy: 0.8889\n","Epoch 92/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2151 - accuracy: 0.9784 - val_loss: 0.3480 - val_accuracy: 0.8889\n","Epoch 93/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2107 - accuracy: 0.9799 - val_loss: 0.3468 - val_accuracy: 0.8889\n","Epoch 94/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.1971 - accuracy: 0.9907 - val_loss: 0.2945 - val_accuracy: 0.9306\n","Epoch 95/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.1854 - accuracy: 0.9969 - val_loss: 0.3538 - val_accuracy: 0.8611\n","Epoch 96/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.1834 - accuracy: 0.9985 - val_loss: 0.3691 - val_accuracy: 0.8750\n","Epoch 97/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.1880 - accuracy: 0.9892 - val_loss: 0.3383 - val_accuracy: 0.8889\n","Epoch 98/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.1879 - accuracy: 0.9907 - val_loss: 0.3805 - val_accuracy: 0.8611\n","Epoch 99/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.1832 - accuracy: 0.9954 - val_loss: 0.3568 - val_accuracy: 0.8611\n","Epoch 100/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.1806 - accuracy: 0.9938 - val_loss: 0.3651 - val_accuracy: 0.8889\n","3/3 [==============================] - 0s 11ms/step - loss: 0.3136 - accuracy: 0.9125\n","[0.3135650157928467, 0.9125000238418579]\n","0.9012519837771116\n","WARNING:tensorflow:Layer LSTM_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer LSTM_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Results for fold 6\n","Epoch 1/100\n","65/65 [==============================] - 9s 46ms/step - loss: 0.8511 - accuracy: 0.5833 - val_loss: 0.8397 - val_accuracy: 0.7500\n","Epoch 2/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.8297 - accuracy: 0.7037 - val_loss: 0.8186 - val_accuracy: 0.7083\n","Epoch 3/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.8101 - accuracy: 0.7160 - val_loss: 0.7980 - val_accuracy: 0.7361\n","Epoch 4/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.7913 - accuracy: 0.7114 - val_loss: 0.7768 - val_accuracy: 0.7639\n","Epoch 5/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.7709 - accuracy: 0.7222 - val_loss: 0.7431 - val_accuracy: 0.7778\n","Epoch 6/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.7368 - accuracy: 0.7731 - val_loss: 0.7004 - val_accuracy: 0.7639\n","Epoch 7/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.6998 - accuracy: 0.7747 - val_loss: 0.6753 - val_accuracy: 0.7639\n","Epoch 8/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.6866 - accuracy: 0.7377 - val_loss: 0.6494 - val_accuracy: 0.8056\n","Epoch 9/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.6609 - accuracy: 0.7593 - val_loss: 0.6091 - val_accuracy: 0.8611\n","Epoch 10/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.6425 - accuracy: 0.7762 - val_loss: 0.6015 - val_accuracy: 0.8333\n","Epoch 11/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.6175 - accuracy: 0.8102 - val_loss: 0.5785 - val_accuracy: 0.8611\n","Epoch 12/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.6065 - accuracy: 0.8086 - val_loss: 0.5714 - val_accuracy: 0.8333\n","Epoch 13/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.5884 - accuracy: 0.8364 - val_loss: 0.5630 - val_accuracy: 0.8472\n","Epoch 14/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.5666 - accuracy: 0.8395 - val_loss: 0.5557 - val_accuracy: 0.8750\n","Epoch 15/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.5558 - accuracy: 0.8472 - val_loss: 0.5457 - val_accuracy: 0.8333\n","Epoch 16/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.5482 - accuracy: 0.8565 - val_loss: 0.5161 - val_accuracy: 0.9028\n","Epoch 17/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.5315 - accuracy: 0.8750 - val_loss: 0.5258 - val_accuracy: 0.8472\n","Epoch 18/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.5237 - accuracy: 0.8580 - val_loss: 0.4832 - val_accuracy: 0.9167\n","Epoch 19/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.5113 - accuracy: 0.8688 - val_loss: 0.5029 - val_accuracy: 0.8889\n","Epoch 20/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.4955 - accuracy: 0.8843 - val_loss: 0.5044 - val_accuracy: 0.8472\n","Epoch 21/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.4881 - accuracy: 0.8951 - val_loss: 0.4728 - val_accuracy: 0.9167\n","Epoch 22/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.4752 - accuracy: 0.9012 - val_loss: 0.4713 - val_accuracy: 0.8889\n","Epoch 23/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4629 - accuracy: 0.9059 - val_loss: 0.5086 - val_accuracy: 0.8333\n","Epoch 24/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.4681 - accuracy: 0.8951 - val_loss: 0.4841 - val_accuracy: 0.8750\n","Epoch 25/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.4299 - accuracy: 0.9383 - val_loss: 0.4563 - val_accuracy: 0.8889\n","Epoch 26/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4273 - accuracy: 0.9306 - val_loss: 0.4740 - val_accuracy: 0.8611\n","Epoch 27/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4409 - accuracy: 0.9182 - val_loss: 0.4239 - val_accuracy: 0.9306\n","Epoch 28/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4490 - accuracy: 0.8904 - val_loss: 0.4288 - val_accuracy: 0.9028\n","Epoch 29/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.4121 - accuracy: 0.9398 - val_loss: 0.4116 - val_accuracy: 0.9444\n","Epoch 30/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4023 - accuracy: 0.9460 - val_loss: 0.4251 - val_accuracy: 0.9306\n","Epoch 31/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4097 - accuracy: 0.9259 - val_loss: 0.4030 - val_accuracy: 0.9306\n","Epoch 32/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3854 - accuracy: 0.9522 - val_loss: 0.4158 - val_accuracy: 0.9028\n","Epoch 33/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3988 - accuracy: 0.9398 - val_loss: 0.4151 - val_accuracy: 0.9167\n","Epoch 34/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3853 - accuracy: 0.9506 - val_loss: 0.4067 - val_accuracy: 0.9167\n","Epoch 35/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3701 - accuracy: 0.9506 - val_loss: 0.3890 - val_accuracy: 0.9306\n","Epoch 36/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3983 - accuracy: 0.9275 - val_loss: 0.3712 - val_accuracy: 0.9583\n","Epoch 37/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3638 - accuracy: 0.9522 - val_loss: 0.3982 - val_accuracy: 0.9167\n","Epoch 38/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3621 - accuracy: 0.9568 - val_loss: 0.4057 - val_accuracy: 0.9167\n","Epoch 39/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.3515 - accuracy: 0.9660 - val_loss: 0.3743 - val_accuracy: 0.9444\n","Epoch 40/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.3656 - accuracy: 0.9352 - val_loss: 0.3644 - val_accuracy: 0.9583\n","Epoch 41/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3502 - accuracy: 0.9568 - val_loss: 0.3691 - val_accuracy: 0.9444\n","Epoch 42/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.3569 - accuracy: 0.9414 - val_loss: 0.3630 - val_accuracy: 0.9583\n","Epoch 43/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3420 - accuracy: 0.9630 - val_loss: 0.3674 - val_accuracy: 0.9306\n","Epoch 44/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3326 - accuracy: 0.9707 - val_loss: 0.3441 - val_accuracy: 0.9583\n","Epoch 45/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3358 - accuracy: 0.9583 - val_loss: 0.3516 - val_accuracy: 0.9444\n","Epoch 46/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3270 - accuracy: 0.9676 - val_loss: 0.3483 - val_accuracy: 0.9444\n","Epoch 47/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3093 - accuracy: 0.9815 - val_loss: 0.3725 - val_accuracy: 0.9028\n","Epoch 48/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3228 - accuracy: 0.9645 - val_loss: 0.3198 - val_accuracy: 0.9722\n","Epoch 49/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.3072 - accuracy: 0.9753 - val_loss: 0.3322 - val_accuracy: 0.9444\n","Epoch 50/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3192 - accuracy: 0.9599 - val_loss: 0.3438 - val_accuracy: 0.9444\n","Epoch 51/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.3023 - accuracy: 0.9769 - val_loss: 0.3306 - val_accuracy: 0.9583\n","Epoch 52/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3004 - accuracy: 0.9753 - val_loss: 0.3329 - val_accuracy: 0.9444\n","Epoch 53/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.3067 - accuracy: 0.9614 - val_loss: 0.3357 - val_accuracy: 0.9444\n","Epoch 54/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.2931 - accuracy: 0.9769 - val_loss: 0.3154 - val_accuracy: 0.9583\n","Epoch 55/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2999 - accuracy: 0.9753 - val_loss: 0.3443 - val_accuracy: 0.9306\n","Epoch 56/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2930 - accuracy: 0.9691 - val_loss: 0.3229 - val_accuracy: 0.9306\n","Epoch 57/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2789 - accuracy: 0.9784 - val_loss: 0.3010 - val_accuracy: 0.9583\n","Epoch 58/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2747 - accuracy: 0.9892 - val_loss: 0.3102 - val_accuracy: 0.9444\n","Epoch 59/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2721 - accuracy: 0.9830 - val_loss: 0.2878 - val_accuracy: 0.9722\n","Epoch 60/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2857 - accuracy: 0.9691 - val_loss: 0.3625 - val_accuracy: 0.9028\n","Epoch 61/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2825 - accuracy: 0.9691 - val_loss: 0.2934 - val_accuracy: 0.9583\n","Epoch 62/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2751 - accuracy: 0.9769 - val_loss: 0.2935 - val_accuracy: 0.9583\n","Epoch 63/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2690 - accuracy: 0.9815 - val_loss: 0.3452 - val_accuracy: 0.9306\n","Epoch 64/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2790 - accuracy: 0.9660 - val_loss: 0.2821 - val_accuracy: 0.9583\n","Epoch 65/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2673 - accuracy: 0.9784 - val_loss: 0.2901 - val_accuracy: 0.9444\n","Epoch 66/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2754 - accuracy: 0.9676 - val_loss: 0.3323 - val_accuracy: 0.9167\n","Epoch 67/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2624 - accuracy: 0.9784 - val_loss: 0.3015 - val_accuracy: 0.9444\n","Epoch 68/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2689 - accuracy: 0.9660 - val_loss: 0.3112 - val_accuracy: 0.9444\n","Epoch 69/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2664 - accuracy: 0.9707 - val_loss: 0.2827 - val_accuracy: 0.9583\n","Epoch 70/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2419 - accuracy: 0.9877 - val_loss: 0.2711 - val_accuracy: 0.9722\n","Epoch 71/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2418 - accuracy: 0.9892 - val_loss: 0.2838 - val_accuracy: 0.9583\n","Epoch 72/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2408 - accuracy: 0.9846 - val_loss: 0.2818 - val_accuracy: 0.9583\n","Epoch 73/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2310 - accuracy: 0.9892 - val_loss: 0.2833 - val_accuracy: 0.9444\n","Epoch 74/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2344 - accuracy: 0.9846 - val_loss: 0.2967 - val_accuracy: 0.9444\n","Epoch 75/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2346 - accuracy: 0.9846 - val_loss: 0.3245 - val_accuracy: 0.9167\n","Epoch 76/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2334 - accuracy: 0.9830 - val_loss: 0.2874 - val_accuracy: 0.9444\n","Epoch 77/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2277 - accuracy: 0.9907 - val_loss: 0.2815 - val_accuracy: 0.9444\n","Epoch 78/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2413 - accuracy: 0.9738 - val_loss: 0.2608 - val_accuracy: 0.9583\n","Epoch 79/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2305 - accuracy: 0.9846 - val_loss: 0.2698 - val_accuracy: 0.9583\n","Epoch 80/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2376 - accuracy: 0.9769 - val_loss: 0.2453 - val_accuracy: 0.9722\n","Epoch 81/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2434 - accuracy: 0.9722 - val_loss: 0.2722 - val_accuracy: 0.9583\n","Epoch 82/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2345 - accuracy: 0.9784 - val_loss: 0.2708 - val_accuracy: 0.9444\n","Epoch 83/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2113 - accuracy: 0.9938 - val_loss: 0.2252 - val_accuracy: 0.9722\n","Epoch 84/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2171 - accuracy: 0.9846 - val_loss: 0.2725 - val_accuracy: 0.9444\n","Epoch 85/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2159 - accuracy: 0.9846 - val_loss: 0.2581 - val_accuracy: 0.9583\n","Epoch 86/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2058 - accuracy: 0.9907 - val_loss: 0.2545 - val_accuracy: 0.9583\n","Epoch 87/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2036 - accuracy: 0.9938 - val_loss: 0.2251 - val_accuracy: 0.9861\n","Epoch 88/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.1997 - accuracy: 0.9923 - val_loss: 0.2355 - val_accuracy: 0.9722\n","Epoch 89/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.2004 - accuracy: 0.9907 - val_loss: 0.2276 - val_accuracy: 0.9722\n","Epoch 90/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.1930 - accuracy: 0.9954 - val_loss: 0.2478 - val_accuracy: 0.9583\n","Epoch 91/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2015 - accuracy: 0.9907 - val_loss: 0.2696 - val_accuracy: 0.9444\n","Epoch 92/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.1971 - accuracy: 0.9907 - val_loss: 0.2796 - val_accuracy: 0.9167\n","Epoch 93/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.1935 - accuracy: 0.9907 - val_loss: 0.2445 - val_accuracy: 0.9583\n","Epoch 94/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2129 - accuracy: 0.9769 - val_loss: 0.2937 - val_accuracy: 0.9306\n","Epoch 95/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2118 - accuracy: 0.9799 - val_loss: 0.2538 - val_accuracy: 0.9444\n","Epoch 96/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2073 - accuracy: 0.9769 - val_loss: 0.2378 - val_accuracy: 0.9583\n","Epoch 97/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2003 - accuracy: 0.9799 - val_loss: 0.2958 - val_accuracy: 0.9028\n","Epoch 98/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.1994 - accuracy: 0.9830 - val_loss: 0.2399 - val_accuracy: 0.9306\n","Epoch 99/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.1863 - accuracy: 0.9877 - val_loss: 0.2165 - val_accuracy: 0.9722\n","Epoch 100/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.1891 - accuracy: 0.9877 - val_loss: 0.2341 - val_accuracy: 0.9444\n","3/3 [==============================] - 0s 14ms/step - loss: 0.3485 - accuracy: 0.8875\n","[0.3484911024570465, 0.887499988079071]\n","0.8753246753246753\n","WARNING:tensorflow:Layer LSTM_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer LSTM_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Results for fold 7\n","Epoch 1/100\n","65/65 [==============================] - 10s 46ms/step - loss: 0.8503 - accuracy: 0.6065 - val_loss: 0.8386 - val_accuracy: 0.7361\n","Epoch 2/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.8283 - accuracy: 0.6852 - val_loss: 0.8172 - val_accuracy: 0.6806\n","Epoch 3/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.8075 - accuracy: 0.7207 - val_loss: 0.7963 - val_accuracy: 0.6944\n","Epoch 4/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.7883 - accuracy: 0.7238 - val_loss: 0.7753 - val_accuracy: 0.6944\n","Epoch 5/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.7633 - accuracy: 0.7114 - val_loss: 0.7429 - val_accuracy: 0.6389\n","Epoch 6/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.7297 - accuracy: 0.6929 - val_loss: 0.7024 - val_accuracy: 0.6944\n","Epoch 7/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.6919 - accuracy: 0.7346 - val_loss: 0.6987 - val_accuracy: 0.6806\n","Epoch 8/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.6756 - accuracy: 0.7454 - val_loss: 0.6693 - val_accuracy: 0.7222\n","Epoch 9/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.6579 - accuracy: 0.7685 - val_loss: 0.6521 - val_accuracy: 0.7500\n","Epoch 10/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.6331 - accuracy: 0.7917 - val_loss: 0.6078 - val_accuracy: 0.8194\n","Epoch 11/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.6321 - accuracy: 0.7809 - val_loss: 0.6240 - val_accuracy: 0.7500\n","Epoch 12/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.6102 - accuracy: 0.8133 - val_loss: 0.6043 - val_accuracy: 0.8056\n","Epoch 13/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.5987 - accuracy: 0.8241 - val_loss: 0.5907 - val_accuracy: 0.8333\n","Epoch 14/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.5940 - accuracy: 0.8194 - val_loss: 0.6065 - val_accuracy: 0.7917\n","Epoch 15/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.5810 - accuracy: 0.8349 - val_loss: 0.5908 - val_accuracy: 0.8056\n","Epoch 16/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.5748 - accuracy: 0.8349 - val_loss: 0.5555 - val_accuracy: 0.8611\n","Epoch 17/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.5529 - accuracy: 0.8657 - val_loss: 0.5374 - val_accuracy: 0.8750\n","Epoch 18/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.5449 - accuracy: 0.8750 - val_loss: 0.5459 - val_accuracy: 0.8611\n","Epoch 19/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.5422 - accuracy: 0.8596 - val_loss: 0.5454 - val_accuracy: 0.8472\n","Epoch 20/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.5346 - accuracy: 0.8688 - val_loss: 0.5570 - val_accuracy: 0.7917\n","Epoch 21/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.5273 - accuracy: 0.8735 - val_loss: 0.5276 - val_accuracy: 0.8889\n","Epoch 22/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.5194 - accuracy: 0.8735 - val_loss: 0.5320 - val_accuracy: 0.8333\n","Epoch 23/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.5039 - accuracy: 0.8951 - val_loss: 0.5835 - val_accuracy: 0.7639\n","Epoch 24/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4908 - accuracy: 0.8981 - val_loss: 0.5222 - val_accuracy: 0.8472\n","Epoch 25/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.4875 - accuracy: 0.9012 - val_loss: 0.5017 - val_accuracy: 0.8611\n","Epoch 26/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4790 - accuracy: 0.9028 - val_loss: 0.4944 - val_accuracy: 0.8611\n","Epoch 27/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.4691 - accuracy: 0.9090 - val_loss: 0.6266 - val_accuracy: 0.7083\n","Epoch 28/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.4668 - accuracy: 0.9043 - val_loss: 0.4966 - val_accuracy: 0.8611\n","Epoch 29/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.4651 - accuracy: 0.9136 - val_loss: 0.4792 - val_accuracy: 0.8750\n","Epoch 30/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4564 - accuracy: 0.9198 - val_loss: 0.4791 - val_accuracy: 0.8889\n","Epoch 31/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.4403 - accuracy: 0.9306 - val_loss: 0.4788 - val_accuracy: 0.8889\n","Epoch 32/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4324 - accuracy: 0.9414 - val_loss: 0.5211 - val_accuracy: 0.8194\n","Epoch 33/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4370 - accuracy: 0.9151 - val_loss: 0.4748 - val_accuracy: 0.8611\n","Epoch 34/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.4190 - accuracy: 0.9444 - val_loss: 0.4784 - val_accuracy: 0.8750\n","Epoch 35/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.4151 - accuracy: 0.9475 - val_loss: 0.4769 - val_accuracy: 0.8472\n","Epoch 36/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.4079 - accuracy: 0.9460 - val_loss: 0.4655 - val_accuracy: 0.8889\n","Epoch 37/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.4048 - accuracy: 0.9552 - val_loss: 0.4660 - val_accuracy: 0.8750\n","Epoch 38/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4014 - accuracy: 0.9460 - val_loss: 0.4423 - val_accuracy: 0.8889\n","Epoch 39/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.4168 - accuracy: 0.9244 - val_loss: 0.4524 - val_accuracy: 0.8750\n","Epoch 40/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3914 - accuracy: 0.9506 - val_loss: 0.4344 - val_accuracy: 0.8750\n","Epoch 41/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4035 - accuracy: 0.9321 - val_loss: 0.4533 - val_accuracy: 0.8611\n","Epoch 42/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.3715 - accuracy: 0.9676 - val_loss: 0.4459 - val_accuracy: 0.8750\n","Epoch 43/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.3882 - accuracy: 0.9414 - val_loss: 0.4340 - val_accuracy: 0.8889\n","Epoch 44/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.3771 - accuracy: 0.9583 - val_loss: 0.4269 - val_accuracy: 0.9028\n","Epoch 45/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.3667 - accuracy: 0.9645 - val_loss: 0.4137 - val_accuracy: 0.9167\n","Epoch 46/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.3629 - accuracy: 0.9614 - val_loss: 0.4384 - val_accuracy: 0.8750\n","Epoch 47/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.3496 - accuracy: 0.9707 - val_loss: 0.3974 - val_accuracy: 0.9028\n","Epoch 48/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.3434 - accuracy: 0.9769 - val_loss: 0.4123 - val_accuracy: 0.9028\n","Epoch 49/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.3623 - accuracy: 0.9522 - val_loss: 0.4194 - val_accuracy: 0.8889\n","Epoch 50/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.3506 - accuracy: 0.9614 - val_loss: 0.3988 - val_accuracy: 0.9167\n","Epoch 51/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.3350 - accuracy: 0.9738 - val_loss: 0.3957 - val_accuracy: 0.9167\n","Epoch 52/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.3316 - accuracy: 0.9769 - val_loss: 0.4214 - val_accuracy: 0.8750\n","Epoch 53/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.3385 - accuracy: 0.9676 - val_loss: 0.3990 - val_accuracy: 0.9028\n","Epoch 54/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.3247 - accuracy: 0.9753 - val_loss: 0.4333 - val_accuracy: 0.8611\n","Epoch 55/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3162 - accuracy: 0.9799 - val_loss: 0.3718 - val_accuracy: 0.9306\n","Epoch 56/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3230 - accuracy: 0.9753 - val_loss: 0.4190 - val_accuracy: 0.8750\n","Epoch 57/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3134 - accuracy: 0.9815 - val_loss: 0.3831 - val_accuracy: 0.9167\n","Epoch 58/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3167 - accuracy: 0.9769 - val_loss: 0.3815 - val_accuracy: 0.9028\n","Epoch 59/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.3072 - accuracy: 0.9738 - val_loss: 0.3684 - val_accuracy: 0.9306\n","Epoch 60/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.3090 - accuracy: 0.9784 - val_loss: 0.3708 - val_accuracy: 0.9167\n","Epoch 61/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.3047 - accuracy: 0.9830 - val_loss: 0.4144 - val_accuracy: 0.8750\n","Epoch 62/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2899 - accuracy: 0.9877 - val_loss: 0.3640 - val_accuracy: 0.9167\n","Epoch 63/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.2923 - accuracy: 0.9815 - val_loss: 0.3813 - val_accuracy: 0.9167\n","Epoch 64/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.3044 - accuracy: 0.9691 - val_loss: 0.4044 - val_accuracy: 0.8611\n","Epoch 65/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.2990 - accuracy: 0.9722 - val_loss: 0.3805 - val_accuracy: 0.8889\n","Epoch 66/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2974 - accuracy: 0.9707 - val_loss: 0.3913 - val_accuracy: 0.8889\n","Epoch 67/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.2821 - accuracy: 0.9877 - val_loss: 0.3707 - val_accuracy: 0.9167\n","Epoch 68/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.2911 - accuracy: 0.9738 - val_loss: 0.3297 - val_accuracy: 0.9444\n","Epoch 69/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2920 - accuracy: 0.9753 - val_loss: 0.3492 - val_accuracy: 0.9028\n","Epoch 70/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2864 - accuracy: 0.9769 - val_loss: 0.3566 - val_accuracy: 0.9028\n","Epoch 71/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2709 - accuracy: 0.9861 - val_loss: 0.3382 - val_accuracy: 0.9444\n","Epoch 72/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2755 - accuracy: 0.9784 - val_loss: 0.3356 - val_accuracy: 0.9306\n","Epoch 73/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.2731 - accuracy: 0.9815 - val_loss: 0.3418 - val_accuracy: 0.9306\n","Epoch 74/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.2686 - accuracy: 0.9815 - val_loss: 0.3434 - val_accuracy: 0.9167\n","Epoch 75/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.2616 - accuracy: 0.9830 - val_loss: 0.4004 - val_accuracy: 0.8611\n","Epoch 76/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.2664 - accuracy: 0.9815 - val_loss: 0.3327 - val_accuracy: 0.9167\n","Epoch 77/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.2625 - accuracy: 0.9846 - val_loss: 0.4217 - val_accuracy: 0.8750\n","Epoch 78/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.2567 - accuracy: 0.9799 - val_loss: 0.3552 - val_accuracy: 0.9167\n","Epoch 79/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.2560 - accuracy: 0.9815 - val_loss: 0.3709 - val_accuracy: 0.8750\n","Epoch 80/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.2548 - accuracy: 0.9830 - val_loss: 0.3461 - val_accuracy: 0.8889\n","Epoch 81/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.2415 - accuracy: 0.9907 - val_loss: 0.2998 - val_accuracy: 0.9444\n","Epoch 82/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.2471 - accuracy: 0.9830 - val_loss: 0.3409 - val_accuracy: 0.9306\n","Epoch 83/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.2448 - accuracy: 0.9830 - val_loss: 0.3041 - val_accuracy: 0.9306\n","Epoch 84/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.2465 - accuracy: 0.9830 - val_loss: 0.2990 - val_accuracy: 0.9444\n","Epoch 85/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.2585 - accuracy: 0.9707 - val_loss: 0.3062 - val_accuracy: 0.9444\n","Epoch 86/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.2349 - accuracy: 0.9846 - val_loss: 0.3181 - val_accuracy: 0.9306\n","Epoch 87/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2413 - accuracy: 0.9784 - val_loss: 0.3229 - val_accuracy: 0.9167\n","Epoch 88/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2420 - accuracy: 0.9753 - val_loss: 0.3261 - val_accuracy: 0.9167\n","Epoch 89/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2274 - accuracy: 0.9892 - val_loss: 0.3309 - val_accuracy: 0.9306\n","Epoch 90/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2174 - accuracy: 0.9954 - val_loss: 0.3366 - val_accuracy: 0.9028\n","Epoch 91/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2129 - accuracy: 0.9938 - val_loss: 0.3688 - val_accuracy: 0.8611\n","Epoch 92/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2243 - accuracy: 0.9877 - val_loss: 0.3233 - val_accuracy: 0.9167\n","Epoch 93/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2311 - accuracy: 0.9707 - val_loss: 0.3472 - val_accuracy: 0.9028\n","Epoch 94/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2298 - accuracy: 0.9784 - val_loss: 0.3563 - val_accuracy: 0.9028\n","Epoch 95/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2162 - accuracy: 0.9907 - val_loss: 0.3640 - val_accuracy: 0.8750\n","Epoch 96/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2110 - accuracy: 0.9907 - val_loss: 0.3338 - val_accuracy: 0.9028\n","Epoch 97/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2193 - accuracy: 0.9877 - val_loss: 0.3444 - val_accuracy: 0.8889\n","Epoch 98/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2068 - accuracy: 0.9923 - val_loss: 0.3925 - val_accuracy: 0.8750\n","Epoch 99/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2047 - accuracy: 0.9923 - val_loss: 0.3046 - val_accuracy: 0.9167\n","Epoch 100/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2085 - accuracy: 0.9846 - val_loss: 0.3045 - val_accuracy: 0.9167\n","3/3 [==============================] - 0s 10ms/step - loss: 0.3619 - accuracy: 0.8625\n","[0.3618752360343933, 0.862500011920929]\n","0.8416981471487678\n","WARNING:tensorflow:Layer LSTM_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer LSTM_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Results for fold 8\n","Epoch 1/100\n","65/65 [==============================] - 8s 38ms/step - loss: 0.8505 - accuracy: 0.5833 - val_loss: 0.8391 - val_accuracy: 0.6250\n","Epoch 2/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.8281 - accuracy: 0.6759 - val_loss: 0.8177 - val_accuracy: 0.6667\n","Epoch 3/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.8068 - accuracy: 0.6898 - val_loss: 0.7972 - val_accuracy: 0.6389\n","Epoch 4/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.7870 - accuracy: 0.7068 - val_loss: 0.7796 - val_accuracy: 0.6667\n","Epoch 5/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.7673 - accuracy: 0.6883 - val_loss: 0.7603 - val_accuracy: 0.6667\n","Epoch 6/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.7347 - accuracy: 0.7269 - val_loss: 0.7349 - val_accuracy: 0.6528\n","Epoch 7/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.6978 - accuracy: 0.7392 - val_loss: 0.7191 - val_accuracy: 0.6806\n","Epoch 8/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.6736 - accuracy: 0.7392 - val_loss: 0.6856 - val_accuracy: 0.6806\n","Epoch 9/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.6306 - accuracy: 0.8179 - val_loss: 0.6724 - val_accuracy: 0.7083\n","Epoch 10/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.6278 - accuracy: 0.7870 - val_loss: 0.6561 - val_accuracy: 0.6944\n","Epoch 11/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.6093 - accuracy: 0.8164 - val_loss: 0.6621 - val_accuracy: 0.6944\n","Epoch 12/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.5800 - accuracy: 0.8565 - val_loss: 0.6415 - val_accuracy: 0.7222\n","Epoch 13/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.5772 - accuracy: 0.8457 - val_loss: 0.6269 - val_accuracy: 0.7361\n","Epoch 14/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.5508 - accuracy: 0.8719 - val_loss: 0.6181 - val_accuracy: 0.7917\n","Epoch 15/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.5493 - accuracy: 0.8719 - val_loss: 0.6175 - val_accuracy: 0.7500\n","Epoch 16/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.5306 - accuracy: 0.8889 - val_loss: 0.6118 - val_accuracy: 0.7361\n","Epoch 17/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.5234 - accuracy: 0.8858 - val_loss: 0.5811 - val_accuracy: 0.8194\n","Epoch 18/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.5166 - accuracy: 0.8889 - val_loss: 0.6149 - val_accuracy: 0.7361\n","Epoch 19/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.5132 - accuracy: 0.8873 - val_loss: 0.5993 - val_accuracy: 0.7222\n","Epoch 20/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.4959 - accuracy: 0.9151 - val_loss: 0.5697 - val_accuracy: 0.8056\n","Epoch 21/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4957 - accuracy: 0.8951 - val_loss: 0.5560 - val_accuracy: 0.8472\n","Epoch 22/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4825 - accuracy: 0.9182 - val_loss: 0.5394 - val_accuracy: 0.8472\n","Epoch 23/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.4799 - accuracy: 0.9136 - val_loss: 0.5628 - val_accuracy: 0.7778\n","Epoch 24/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4665 - accuracy: 0.9321 - val_loss: 0.5551 - val_accuracy: 0.7778\n","Epoch 25/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.4636 - accuracy: 0.9321 - val_loss: 0.5606 - val_accuracy: 0.7778\n","Epoch 26/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.4616 - accuracy: 0.9228 - val_loss: 0.5691 - val_accuracy: 0.7778\n","Epoch 27/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.4450 - accuracy: 0.9383 - val_loss: 0.5330 - val_accuracy: 0.8333\n","Epoch 28/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.4384 - accuracy: 0.9429 - val_loss: 0.5511 - val_accuracy: 0.8056\n","Epoch 29/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.4341 - accuracy: 0.9429 - val_loss: 0.5541 - val_accuracy: 0.8056\n","Epoch 30/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.4273 - accuracy: 0.9475 - val_loss: 0.5009 - val_accuracy: 0.8611\n","Epoch 31/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.4280 - accuracy: 0.9383 - val_loss: 0.5286 - val_accuracy: 0.8333\n","Epoch 32/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.4240 - accuracy: 0.9367 - val_loss: 0.5463 - val_accuracy: 0.7917\n","Epoch 33/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.4069 - accuracy: 0.9583 - val_loss: 0.5212 - val_accuracy: 0.7917\n","Epoch 34/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.3992 - accuracy: 0.9630 - val_loss: 0.5546 - val_accuracy: 0.7917\n","Epoch 35/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.4131 - accuracy: 0.9414 - val_loss: 0.5372 - val_accuracy: 0.7917\n","Epoch 36/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.4009 - accuracy: 0.9599 - val_loss: 0.4771 - val_accuracy: 0.8611\n","Epoch 37/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.3926 - accuracy: 0.9614 - val_loss: 0.6223 - val_accuracy: 0.6944\n","Epoch 38/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.4088 - accuracy: 0.9352 - val_loss: 0.5187 - val_accuracy: 0.8333\n","Epoch 39/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.3988 - accuracy: 0.9336 - val_loss: 0.5809 - val_accuracy: 0.7639\n","Epoch 40/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.3975 - accuracy: 0.9367 - val_loss: 0.5092 - val_accuracy: 0.8194\n","Epoch 41/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.3696 - accuracy: 0.9707 - val_loss: 0.5012 - val_accuracy: 0.8333\n","Epoch 42/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.3817 - accuracy: 0.9537 - val_loss: 0.4919 - val_accuracy: 0.8472\n","Epoch 43/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3694 - accuracy: 0.9660 - val_loss: 0.5300 - val_accuracy: 0.8056\n","Epoch 44/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3720 - accuracy: 0.9630 - val_loss: 0.5041 - val_accuracy: 0.8333\n","Epoch 45/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3586 - accuracy: 0.9645 - val_loss: 0.5584 - val_accuracy: 0.7778\n","Epoch 46/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3580 - accuracy: 0.9645 - val_loss: 0.4930 - val_accuracy: 0.8333\n","Epoch 47/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3531 - accuracy: 0.9676 - val_loss: 0.4809 - val_accuracy: 0.8194\n","Epoch 48/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3351 - accuracy: 0.9846 - val_loss: 0.4766 - val_accuracy: 0.8333\n","Epoch 49/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3505 - accuracy: 0.9676 - val_loss: 0.5344 - val_accuracy: 0.7917\n","Epoch 50/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3384 - accuracy: 0.9769 - val_loss: 0.4680 - val_accuracy: 0.8333\n","Epoch 51/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3377 - accuracy: 0.9753 - val_loss: 0.5627 - val_accuracy: 0.7639\n","Epoch 52/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3445 - accuracy: 0.9707 - val_loss: 0.5284 - val_accuracy: 0.8056\n","Epoch 53/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3406 - accuracy: 0.9676 - val_loss: 0.4916 - val_accuracy: 0.8333\n","Epoch 54/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3205 - accuracy: 0.9815 - val_loss: 0.4314 - val_accuracy: 0.8750\n","Epoch 55/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3433 - accuracy: 0.9599 - val_loss: 0.4800 - val_accuracy: 0.8194\n","Epoch 56/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3194 - accuracy: 0.9815 - val_loss: 0.4892 - val_accuracy: 0.8194\n","Epoch 57/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3241 - accuracy: 0.9691 - val_loss: 0.4719 - val_accuracy: 0.8472\n","Epoch 58/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3113 - accuracy: 0.9799 - val_loss: 0.5000 - val_accuracy: 0.8194\n","Epoch 59/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3236 - accuracy: 0.9660 - val_loss: 0.4860 - val_accuracy: 0.8333\n","Epoch 60/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3407 - accuracy: 0.9491 - val_loss: 0.5342 - val_accuracy: 0.7778\n","Epoch 61/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3197 - accuracy: 0.9691 - val_loss: 0.4231 - val_accuracy: 0.8889\n","Epoch 62/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.3149 - accuracy: 0.9676 - val_loss: 0.4501 - val_accuracy: 0.8472\n","Epoch 63/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.3139 - accuracy: 0.9645 - val_loss: 0.3924 - val_accuracy: 0.9167\n","Epoch 64/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3063 - accuracy: 0.9753 - val_loss: 0.4447 - val_accuracy: 0.8472\n","Epoch 65/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.2939 - accuracy: 0.9815 - val_loss: 0.4098 - val_accuracy: 0.8889\n","Epoch 66/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2933 - accuracy: 0.9784 - val_loss: 0.4588 - val_accuracy: 0.8472\n","Epoch 67/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.3005 - accuracy: 0.9722 - val_loss: 0.4404 - val_accuracy: 0.8611\n","Epoch 68/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.2828 - accuracy: 0.9846 - val_loss: 0.4098 - val_accuracy: 0.8889\n","Epoch 69/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2710 - accuracy: 0.9954 - val_loss: 0.4167 - val_accuracy: 0.8889\n","Epoch 70/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2745 - accuracy: 0.9892 - val_loss: 0.4246 - val_accuracy: 0.8611\n","Epoch 71/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.2794 - accuracy: 0.9799 - val_loss: 0.3914 - val_accuracy: 0.9028\n","Epoch 72/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2882 - accuracy: 0.9753 - val_loss: 0.4622 - val_accuracy: 0.8333\n","Epoch 73/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2888 - accuracy: 0.9676 - val_loss: 0.5014 - val_accuracy: 0.7917\n","Epoch 74/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2894 - accuracy: 0.9753 - val_loss: 0.4276 - val_accuracy: 0.8472\n","Epoch 75/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2580 - accuracy: 0.9923 - val_loss: 0.4359 - val_accuracy: 0.8472\n","Epoch 76/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2548 - accuracy: 0.9938 - val_loss: 0.5095 - val_accuracy: 0.7917\n","Epoch 77/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2661 - accuracy: 0.9846 - val_loss: 0.4015 - val_accuracy: 0.9028\n","Epoch 78/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2607 - accuracy: 0.9846 - val_loss: 0.3964 - val_accuracy: 0.8750\n","Epoch 79/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2536 - accuracy: 0.9907 - val_loss: 0.4646 - val_accuracy: 0.8194\n","Epoch 80/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2699 - accuracy: 0.9753 - val_loss: 0.4104 - val_accuracy: 0.8611\n","Epoch 81/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2505 - accuracy: 0.9923 - val_loss: 0.4102 - val_accuracy: 0.8889\n","Epoch 82/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2487 - accuracy: 0.9907 - val_loss: 0.3639 - val_accuracy: 0.9167\n","Epoch 83/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2420 - accuracy: 0.9954 - val_loss: 0.4069 - val_accuracy: 0.8750\n","Epoch 84/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2440 - accuracy: 0.9892 - val_loss: 0.4242 - val_accuracy: 0.8472\n","Epoch 85/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2392 - accuracy: 0.9923 - val_loss: 0.4217 - val_accuracy: 0.8333\n","Epoch 86/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2567 - accuracy: 0.9784 - val_loss: 0.4161 - val_accuracy: 0.8472\n","Epoch 87/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2657 - accuracy: 0.9676 - val_loss: 0.5463 - val_accuracy: 0.7778\n","Epoch 88/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2406 - accuracy: 0.9861 - val_loss: 0.3535 - val_accuracy: 0.9167\n","Epoch 89/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2326 - accuracy: 0.9938 - val_loss: 0.3817 - val_accuracy: 0.8472\n","Epoch 90/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2254 - accuracy: 0.9969 - val_loss: 0.4087 - val_accuracy: 0.8611\n","Epoch 91/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2257 - accuracy: 0.9938 - val_loss: 0.3704 - val_accuracy: 0.8889\n","Epoch 92/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2265 - accuracy: 0.9907 - val_loss: 0.3783 - val_accuracy: 0.8889\n","Epoch 93/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.2241 - accuracy: 0.9938 - val_loss: 0.5185 - val_accuracy: 0.8056\n","Epoch 94/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.2431 - accuracy: 0.9784 - val_loss: 0.3889 - val_accuracy: 0.8889\n","Epoch 95/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.2363 - accuracy: 0.9799 - val_loss: 0.3503 - val_accuracy: 0.8889\n","Epoch 96/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2279 - accuracy: 0.9861 - val_loss: 0.4436 - val_accuracy: 0.8056\n","Epoch 97/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.2279 - accuracy: 0.9846 - val_loss: 0.4512 - val_accuracy: 0.8333\n","Epoch 98/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.2147 - accuracy: 0.9938 - val_loss: 0.4034 - val_accuracy: 0.8333\n","Epoch 99/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.2105 - accuracy: 0.9969 - val_loss: 0.3801 - val_accuracy: 0.8889\n","Epoch 100/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.2094 - accuracy: 0.9954 - val_loss: 0.3971 - val_accuracy: 0.8333\n","3/3 [==============================] - 0s 14ms/step - loss: 0.2921 - accuracy: 0.9375\n","[0.29210662841796875, 0.9375]\n","0.9307359307359307\n","WARNING:tensorflow:Layer LSTM_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer LSTM_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Results for fold 9\n","Epoch 1/100\n","65/65 [==============================] - 8s 42ms/step - loss: 0.8507 - accuracy: 0.5556 - val_loss: 0.8401 - val_accuracy: 0.5694\n","Epoch 2/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.8288 - accuracy: 0.7238 - val_loss: 0.8182 - val_accuracy: 0.7222\n","Epoch 3/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.8080 - accuracy: 0.7222 - val_loss: 0.7959 - val_accuracy: 0.7222\n","Epoch 4/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.7858 - accuracy: 0.7269 - val_loss: 0.7691 - val_accuracy: 0.6806\n","Epoch 5/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.7530 - accuracy: 0.7346 - val_loss: 0.7338 - val_accuracy: 0.7083\n","Epoch 6/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.7155 - accuracy: 0.7346 - val_loss: 0.6902 - val_accuracy: 0.7222\n","Epoch 7/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.6960 - accuracy: 0.7593 - val_loss: 0.7050 - val_accuracy: 0.6528\n","Epoch 8/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.6610 - accuracy: 0.7855 - val_loss: 0.6742 - val_accuracy: 0.7361\n","Epoch 9/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.6388 - accuracy: 0.8148 - val_loss: 0.6679 - val_accuracy: 0.7083\n","Epoch 10/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.6268 - accuracy: 0.8071 - val_loss: 0.6309 - val_accuracy: 0.7500\n","Epoch 11/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.6209 - accuracy: 0.7855 - val_loss: 0.6556 - val_accuracy: 0.6806\n","Epoch 12/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.5989 - accuracy: 0.8133 - val_loss: 0.6040 - val_accuracy: 0.8056\n","Epoch 13/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.5915 - accuracy: 0.8179 - val_loss: 0.6135 - val_accuracy: 0.7639\n","Epoch 14/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.5644 - accuracy: 0.8549 - val_loss: 0.5975 - val_accuracy: 0.7778\n","Epoch 15/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.5703 - accuracy: 0.8426 - val_loss: 0.5989 - val_accuracy: 0.7917\n","Epoch 16/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.5470 - accuracy: 0.8735 - val_loss: 0.5657 - val_accuracy: 0.8333\n","Epoch 17/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.5517 - accuracy: 0.8534 - val_loss: 0.5551 - val_accuracy: 0.8472\n","Epoch 18/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.5230 - accuracy: 0.8827 - val_loss: 0.5843 - val_accuracy: 0.7917\n","Epoch 19/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.5395 - accuracy: 0.8534 - val_loss: 0.5488 - val_accuracy: 0.8333\n","Epoch 20/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.5006 - accuracy: 0.9059 - val_loss: 0.5523 - val_accuracy: 0.8611\n","Epoch 21/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.4980 - accuracy: 0.8904 - val_loss: 0.5432 - val_accuracy: 0.8194\n","Epoch 22/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.4991 - accuracy: 0.8827 - val_loss: 0.5428 - val_accuracy: 0.8056\n","Epoch 23/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.4860 - accuracy: 0.9043 - val_loss: 0.6022 - val_accuracy: 0.7361\n","Epoch 24/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.4727 - accuracy: 0.9059 - val_loss: 0.4979 - val_accuracy: 0.8750\n","Epoch 25/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.4856 - accuracy: 0.9043 - val_loss: 0.4958 - val_accuracy: 0.8750\n","Epoch 26/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.4753 - accuracy: 0.8981 - val_loss: 0.5131 - val_accuracy: 0.8333\n","Epoch 27/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.4642 - accuracy: 0.9059 - val_loss: 0.4873 - val_accuracy: 0.8750\n","Epoch 28/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.4517 - accuracy: 0.9182 - val_loss: 0.4791 - val_accuracy: 0.8611\n","Epoch 29/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.4660 - accuracy: 0.8966 - val_loss: 0.4909 - val_accuracy: 0.8889\n","Epoch 30/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.4605 - accuracy: 0.9028 - val_loss: 0.4897 - val_accuracy: 0.8472\n","Epoch 31/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.4429 - accuracy: 0.9182 - val_loss: 0.4675 - val_accuracy: 0.8750\n","Epoch 32/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.4302 - accuracy: 0.9352 - val_loss: 0.4647 - val_accuracy: 0.8750\n","Epoch 33/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.4170 - accuracy: 0.9321 - val_loss: 0.4425 - val_accuracy: 0.9028\n","Epoch 34/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.4187 - accuracy: 0.9306 - val_loss: 0.4618 - val_accuracy: 0.8889\n","Epoch 35/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.4030 - accuracy: 0.9429 - val_loss: 0.4917 - val_accuracy: 0.8194\n","Epoch 36/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.4342 - accuracy: 0.9028 - val_loss: 0.4548 - val_accuracy: 0.8750\n","Epoch 37/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4029 - accuracy: 0.9414 - val_loss: 0.4621 - val_accuracy: 0.8750\n","Epoch 38/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3979 - accuracy: 0.9414 - val_loss: 0.4351 - val_accuracy: 0.9167\n","Epoch 39/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3852 - accuracy: 0.9491 - val_loss: 0.4265 - val_accuracy: 0.9028\n","Epoch 40/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3675 - accuracy: 0.9645 - val_loss: 0.4445 - val_accuracy: 0.8889\n","Epoch 41/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3695 - accuracy: 0.9660 - val_loss: 0.4104 - val_accuracy: 0.9306\n","Epoch 42/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.3716 - accuracy: 0.9506 - val_loss: 0.4157 - val_accuracy: 0.9167\n","Epoch 43/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3642 - accuracy: 0.9583 - val_loss: 0.4115 - val_accuracy: 0.9167\n","Epoch 44/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3686 - accuracy: 0.9460 - val_loss: 0.4193 - val_accuracy: 0.9167\n","Epoch 45/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3605 - accuracy: 0.9568 - val_loss: 0.3719 - val_accuracy: 0.9444\n","Epoch 46/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3472 - accuracy: 0.9614 - val_loss: 0.4468 - val_accuracy: 0.8611\n","Epoch 47/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3392 - accuracy: 0.9769 - val_loss: 0.3832 - val_accuracy: 0.9306\n","Epoch 48/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3352 - accuracy: 0.9691 - val_loss: 0.4049 - val_accuracy: 0.8889\n","Epoch 49/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.3587 - accuracy: 0.9475 - val_loss: 0.4207 - val_accuracy: 0.8889\n","Epoch 50/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3479 - accuracy: 0.9522 - val_loss: 0.4253 - val_accuracy: 0.8750\n","Epoch 51/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3334 - accuracy: 0.9599 - val_loss: 0.4132 - val_accuracy: 0.8750\n","Epoch 52/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3442 - accuracy: 0.9552 - val_loss: 0.4143 - val_accuracy: 0.8889\n","Epoch 53/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3256 - accuracy: 0.9707 - val_loss: 0.3766 - val_accuracy: 0.9167\n","Epoch 54/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3171 - accuracy: 0.9707 - val_loss: 0.3686 - val_accuracy: 0.9306\n","Epoch 55/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3199 - accuracy: 0.9691 - val_loss: 0.3934 - val_accuracy: 0.9028\n","Epoch 56/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3239 - accuracy: 0.9630 - val_loss: 0.3589 - val_accuracy: 0.9444\n","Epoch 57/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3197 - accuracy: 0.9660 - val_loss: 0.3958 - val_accuracy: 0.8889\n","Epoch 58/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2904 - accuracy: 0.9877 - val_loss: 0.3717 - val_accuracy: 0.9167\n","Epoch 59/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.3034 - accuracy: 0.9753 - val_loss: 0.3641 - val_accuracy: 0.9167\n","Epoch 60/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2967 - accuracy: 0.9753 - val_loss: 0.3905 - val_accuracy: 0.8889\n","Epoch 61/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.3050 - accuracy: 0.9660 - val_loss: 0.4198 - val_accuracy: 0.8472\n","Epoch 62/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2913 - accuracy: 0.9784 - val_loss: 0.3374 - val_accuracy: 0.9306\n","Epoch 63/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3039 - accuracy: 0.9645 - val_loss: 0.3948 - val_accuracy: 0.8889\n","Epoch 64/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2892 - accuracy: 0.9691 - val_loss: 0.4129 - val_accuracy: 0.8611\n","Epoch 65/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.2899 - accuracy: 0.9722 - val_loss: 0.4210 - val_accuracy: 0.8611\n","Epoch 66/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2817 - accuracy: 0.9753 - val_loss: 0.3745 - val_accuracy: 0.9028\n","Epoch 67/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2771 - accuracy: 0.9784 - val_loss: 0.3776 - val_accuracy: 0.8750\n","Epoch 68/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2740 - accuracy: 0.9769 - val_loss: 0.3660 - val_accuracy: 0.8889\n","Epoch 69/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.2754 - accuracy: 0.9769 - val_loss: 0.3413 - val_accuracy: 0.9306\n","Epoch 70/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.2722 - accuracy: 0.9769 - val_loss: 0.3956 - val_accuracy: 0.8611\n","Epoch 71/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.2722 - accuracy: 0.9722 - val_loss: 0.4081 - val_accuracy: 0.8611\n","Epoch 72/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.2736 - accuracy: 0.9753 - val_loss: 0.3504 - val_accuracy: 0.9167\n","Epoch 73/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2666 - accuracy: 0.9722 - val_loss: 0.4064 - val_accuracy: 0.8472\n","Epoch 74/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2674 - accuracy: 0.9769 - val_loss: 0.3899 - val_accuracy: 0.8750\n","Epoch 75/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2613 - accuracy: 0.9753 - val_loss: 0.3702 - val_accuracy: 0.9028\n","Epoch 76/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2466 - accuracy: 0.9877 - val_loss: 0.3473 - val_accuracy: 0.9167\n","Epoch 77/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2448 - accuracy: 0.9877 - val_loss: 0.3145 - val_accuracy: 0.9167\n","Epoch 78/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2458 - accuracy: 0.9861 - val_loss: 0.3569 - val_accuracy: 0.9028\n","Epoch 79/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2474 - accuracy: 0.9815 - val_loss: 0.3061 - val_accuracy: 0.9444\n","Epoch 80/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2414 - accuracy: 0.9846 - val_loss: 0.3033 - val_accuracy: 0.9444\n","Epoch 81/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2394 - accuracy: 0.9815 - val_loss: 0.3123 - val_accuracy: 0.9444\n","Epoch 82/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2320 - accuracy: 0.9892 - val_loss: 0.3381 - val_accuracy: 0.9167\n","Epoch 83/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2377 - accuracy: 0.9830 - val_loss: 0.3513 - val_accuracy: 0.8889\n","Epoch 84/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2419 - accuracy: 0.9815 - val_loss: 0.3618 - val_accuracy: 0.9028\n","Epoch 85/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2284 - accuracy: 0.9861 - val_loss: 0.3305 - val_accuracy: 0.9167\n","Epoch 86/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2398 - accuracy: 0.9738 - val_loss: 0.3220 - val_accuracy: 0.9167\n","Epoch 87/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2275 - accuracy: 0.9861 - val_loss: 0.3188 - val_accuracy: 0.9306\n","Epoch 88/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2279 - accuracy: 0.9846 - val_loss: 0.3358 - val_accuracy: 0.9028\n","Epoch 89/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2387 - accuracy: 0.9707 - val_loss: 0.4264 - val_accuracy: 0.8472\n","Epoch 90/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2329 - accuracy: 0.9753 - val_loss: 0.3214 - val_accuracy: 0.9167\n","Epoch 91/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2192 - accuracy: 0.9830 - val_loss: 0.3058 - val_accuracy: 0.9167\n","Epoch 92/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2227 - accuracy: 0.9799 - val_loss: 0.3188 - val_accuracy: 0.9306\n","Epoch 93/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2181 - accuracy: 0.9815 - val_loss: 0.3051 - val_accuracy: 0.9167\n","Epoch 94/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2129 - accuracy: 0.9846 - val_loss: 0.3624 - val_accuracy: 0.8889\n","Epoch 95/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2072 - accuracy: 0.9861 - val_loss: 0.2882 - val_accuracy: 0.9444\n","Epoch 96/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2021 - accuracy: 0.9907 - val_loss: 0.2830 - val_accuracy: 0.9444\n","Epoch 97/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2014 - accuracy: 0.9907 - val_loss: 0.2571 - val_accuracy: 0.9722\n","Epoch 98/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.1932 - accuracy: 0.9954 - val_loss: 0.3107 - val_accuracy: 0.9167\n","Epoch 99/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.1948 - accuracy: 0.9938 - val_loss: 0.2544 - val_accuracy: 0.9583\n","Epoch 100/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.1884 - accuracy: 0.9954 - val_loss: 0.2622 - val_accuracy: 0.9583\n","3/3 [==============================] - 0s 13ms/step - loss: 0.2841 - accuracy: 0.9375\n","[0.28405916690826416, 0.9375]\n","0.9294657026979369\n","WARNING:tensorflow:Layer LSTM_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer LSTM_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Results for fold 10\n","Epoch 1/100\n","65/65 [==============================] - 8s 38ms/step - loss: 0.8506 - accuracy: 0.5154 - val_loss: 0.8393 - val_accuracy: 0.6389\n","Epoch 2/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.8284 - accuracy: 0.6929 - val_loss: 0.8184 - val_accuracy: 0.6806\n","Epoch 3/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.8084 - accuracy: 0.6836 - val_loss: 0.7985 - val_accuracy: 0.6806\n","Epoch 4/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.7870 - accuracy: 0.7238 - val_loss: 0.7765 - val_accuracy: 0.6111\n","Epoch 5/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.7603 - accuracy: 0.7083 - val_loss: 0.7317 - val_accuracy: 0.7361\n","Epoch 6/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.7176 - accuracy: 0.7361 - val_loss: 0.6879 - val_accuracy: 0.7917\n","Epoch 7/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.6907 - accuracy: 0.7454 - val_loss: 0.6566 - val_accuracy: 0.7917\n","Epoch 8/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.6682 - accuracy: 0.7377 - val_loss: 0.6506 - val_accuracy: 0.7639\n","Epoch 9/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.6362 - accuracy: 0.7747 - val_loss: 0.6308 - val_accuracy: 0.7778\n","Epoch 10/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.6400 - accuracy: 0.7577 - val_loss: 0.6109 - val_accuracy: 0.7778\n","Epoch 11/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.6205 - accuracy: 0.7824 - val_loss: 0.6102 - val_accuracy: 0.7778\n","Epoch 12/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.5911 - accuracy: 0.8194 - val_loss: 0.6060 - val_accuracy: 0.7778\n","Epoch 13/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.5959 - accuracy: 0.7963 - val_loss: 0.5826 - val_accuracy: 0.8194\n","Epoch 14/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.5749 - accuracy: 0.8287 - val_loss: 0.5629 - val_accuracy: 0.8333\n","Epoch 15/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.5656 - accuracy: 0.8302 - val_loss: 0.5820 - val_accuracy: 0.8056\n","Epoch 16/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.5515 - accuracy: 0.8426 - val_loss: 0.5762 - val_accuracy: 0.7778\n","Epoch 17/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.5397 - accuracy: 0.8457 - val_loss: 0.5598 - val_accuracy: 0.8194\n","Epoch 18/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.5313 - accuracy: 0.8596 - val_loss: 0.5532 - val_accuracy: 0.8056\n","Epoch 19/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.5373 - accuracy: 0.8410 - val_loss: 0.5330 - val_accuracy: 0.8333\n","Epoch 20/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.5109 - accuracy: 0.8750 - val_loss: 0.5038 - val_accuracy: 0.8889\n","Epoch 21/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.5069 - accuracy: 0.8673 - val_loss: 0.5069 - val_accuracy: 0.8750\n","Epoch 22/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.4970 - accuracy: 0.8735 - val_loss: 0.5171 - val_accuracy: 0.8333\n","Epoch 23/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4895 - accuracy: 0.8735 - val_loss: 0.5174 - val_accuracy: 0.8194\n","Epoch 24/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4750 - accuracy: 0.9043 - val_loss: 0.4844 - val_accuracy: 0.8889\n","Epoch 25/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4699 - accuracy: 0.8981 - val_loss: 0.5063 - val_accuracy: 0.8472\n","Epoch 26/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4673 - accuracy: 0.8966 - val_loss: 0.4941 - val_accuracy: 0.8472\n","Epoch 27/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4554 - accuracy: 0.9074 - val_loss: 0.4752 - val_accuracy: 0.8750\n","Epoch 28/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.4354 - accuracy: 0.9167 - val_loss: 0.4730 - val_accuracy: 0.8750\n","Epoch 29/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4359 - accuracy: 0.9136 - val_loss: 0.4632 - val_accuracy: 0.8611\n","Epoch 30/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4399 - accuracy: 0.9043 - val_loss: 0.4592 - val_accuracy: 0.8750\n","Epoch 31/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.4357 - accuracy: 0.9105 - val_loss: 0.4445 - val_accuracy: 0.9028\n","Epoch 32/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4252 - accuracy: 0.9213 - val_loss: 0.4925 - val_accuracy: 0.8472\n","Epoch 33/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4021 - accuracy: 0.9429 - val_loss: 0.4494 - val_accuracy: 0.8611\n","Epoch 34/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.4040 - accuracy: 0.9352 - val_loss: 0.4390 - val_accuracy: 0.9028\n","Epoch 35/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.4014 - accuracy: 0.9352 - val_loss: 0.4436 - val_accuracy: 0.8889\n","Epoch 36/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3980 - accuracy: 0.9352 - val_loss: 0.4092 - val_accuracy: 0.9167\n","Epoch 37/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.3734 - accuracy: 0.9599 - val_loss: 0.4430 - val_accuracy: 0.8889\n","Epoch 38/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.3858 - accuracy: 0.9352 - val_loss: 0.4155 - val_accuracy: 0.9167\n","Epoch 39/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.3747 - accuracy: 0.9475 - val_loss: 0.4229 - val_accuracy: 0.9028\n","Epoch 40/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.3905 - accuracy: 0.9228 - val_loss: 0.4476 - val_accuracy: 0.8750\n","Epoch 41/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.3703 - accuracy: 0.9506 - val_loss: 0.4610 - val_accuracy: 0.8472\n","Epoch 42/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3579 - accuracy: 0.9537 - val_loss: 0.4425 - val_accuracy: 0.8611\n","Epoch 43/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3651 - accuracy: 0.9429 - val_loss: 0.4282 - val_accuracy: 0.8889\n","Epoch 44/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3601 - accuracy: 0.9522 - val_loss: 0.4423 - val_accuracy: 0.8611\n","Epoch 45/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3389 - accuracy: 0.9645 - val_loss: 0.3888 - val_accuracy: 0.9028\n","Epoch 46/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3538 - accuracy: 0.9491 - val_loss: 0.3619 - val_accuracy: 0.9444\n","Epoch 47/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.3292 - accuracy: 0.9645 - val_loss: 0.3709 - val_accuracy: 0.9167\n","Epoch 48/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3366 - accuracy: 0.9568 - val_loss: 0.4178 - val_accuracy: 0.8611\n","Epoch 49/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3273 - accuracy: 0.9614 - val_loss: 0.4037 - val_accuracy: 0.8750\n","Epoch 50/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3259 - accuracy: 0.9614 - val_loss: 0.3753 - val_accuracy: 0.9167\n","Epoch 51/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.3345 - accuracy: 0.9522 - val_loss: 0.3776 - val_accuracy: 0.9167\n","Epoch 52/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.3100 - accuracy: 0.9722 - val_loss: 0.3742 - val_accuracy: 0.9028\n","Epoch 53/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3027 - accuracy: 0.9769 - val_loss: 0.4248 - val_accuracy: 0.8611\n","Epoch 54/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3083 - accuracy: 0.9691 - val_loss: 0.3407 - val_accuracy: 0.9306\n","Epoch 55/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3144 - accuracy: 0.9645 - val_loss: 0.3561 - val_accuracy: 0.9167\n","Epoch 56/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3262 - accuracy: 0.9522 - val_loss: 0.4053 - val_accuracy: 0.8750\n","Epoch 57/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3129 - accuracy: 0.9599 - val_loss: 0.3732 - val_accuracy: 0.8889\n","Epoch 58/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2979 - accuracy: 0.9738 - val_loss: 0.3444 - val_accuracy: 0.9167\n","Epoch 59/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3004 - accuracy: 0.9691 - val_loss: 0.3409 - val_accuracy: 0.9444\n","Epoch 60/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2856 - accuracy: 0.9769 - val_loss: 0.3899 - val_accuracy: 0.8889\n","Epoch 61/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2969 - accuracy: 0.9691 - val_loss: 0.3572 - val_accuracy: 0.9167\n","Epoch 62/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2969 - accuracy: 0.9614 - val_loss: 0.3240 - val_accuracy: 0.9583\n","Epoch 63/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2919 - accuracy: 0.9630 - val_loss: 0.3267 - val_accuracy: 0.9444\n","Epoch 64/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2840 - accuracy: 0.9722 - val_loss: 0.4203 - val_accuracy: 0.8611\n","Epoch 65/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2918 - accuracy: 0.9645 - val_loss: 0.2975 - val_accuracy: 0.9583\n","Epoch 66/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2716 - accuracy: 0.9722 - val_loss: 0.3385 - val_accuracy: 0.9167\n","Epoch 67/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2733 - accuracy: 0.9738 - val_loss: 0.3293 - val_accuracy: 0.9306\n","Epoch 68/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2580 - accuracy: 0.9830 - val_loss: 0.2915 - val_accuracy: 0.9722\n","Epoch 69/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2610 - accuracy: 0.9830 - val_loss: 0.3241 - val_accuracy: 0.9167\n","Epoch 70/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2582 - accuracy: 0.9830 - val_loss: 0.3625 - val_accuracy: 0.8750\n","Epoch 71/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2490 - accuracy: 0.9877 - val_loss: 0.3424 - val_accuracy: 0.9028\n","Epoch 72/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2456 - accuracy: 0.9846 - val_loss: 0.3249 - val_accuracy: 0.9306\n","Epoch 73/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2511 - accuracy: 0.9846 - val_loss: 0.3041 - val_accuracy: 0.9444\n","Epoch 74/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.2597 - accuracy: 0.9753 - val_loss: 0.3094 - val_accuracy: 0.9306\n","Epoch 75/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.2503 - accuracy: 0.9784 - val_loss: 0.3406 - val_accuracy: 0.9028\n","Epoch 76/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2596 - accuracy: 0.9676 - val_loss: 0.3212 - val_accuracy: 0.9306\n","Epoch 77/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2411 - accuracy: 0.9799 - val_loss: 0.2883 - val_accuracy: 0.9583\n","Epoch 78/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2447 - accuracy: 0.9769 - val_loss: 0.2987 - val_accuracy: 0.9444\n","Epoch 79/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2404 - accuracy: 0.9799 - val_loss: 0.3518 - val_accuracy: 0.8750\n","Epoch 80/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.2243 - accuracy: 0.9877 - val_loss: 0.3391 - val_accuracy: 0.8889\n","Epoch 81/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2289 - accuracy: 0.9846 - val_loss: 0.3411 - val_accuracy: 0.9028\n","Epoch 82/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2220 - accuracy: 0.9861 - val_loss: 0.2995 - val_accuracy: 0.9167\n","Epoch 83/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2286 - accuracy: 0.9846 - val_loss: 0.3110 - val_accuracy: 0.9306\n","Epoch 84/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2323 - accuracy: 0.9830 - val_loss: 0.3693 - val_accuracy: 0.8611\n","Epoch 85/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2317 - accuracy: 0.9799 - val_loss: 0.3097 - val_accuracy: 0.9167\n","Epoch 86/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2298 - accuracy: 0.9799 - val_loss: 0.3144 - val_accuracy: 0.9167\n","Epoch 87/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2214 - accuracy: 0.9846 - val_loss: 0.2944 - val_accuracy: 0.9167\n","Epoch 88/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2263 - accuracy: 0.9753 - val_loss: 0.3326 - val_accuracy: 0.9028\n","Epoch 89/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2070 - accuracy: 0.9877 - val_loss: 0.3150 - val_accuracy: 0.9167\n","Epoch 90/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2192 - accuracy: 0.9846 - val_loss: 0.2835 - val_accuracy: 0.9306\n","Epoch 91/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2125 - accuracy: 0.9830 - val_loss: 0.2726 - val_accuracy: 0.9583\n","Epoch 92/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2124 - accuracy: 0.9799 - val_loss: 0.3162 - val_accuracy: 0.9028\n","Epoch 93/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2040 - accuracy: 0.9907 - val_loss: 0.2870 - val_accuracy: 0.9306\n","Epoch 94/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2014 - accuracy: 0.9892 - val_loss: 0.2830 - val_accuracy: 0.9167\n","Epoch 95/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2002 - accuracy: 0.9846 - val_loss: 0.2621 - val_accuracy: 0.9444\n","Epoch 96/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2032 - accuracy: 0.9830 - val_loss: 0.3122 - val_accuracy: 0.9028\n","Epoch 97/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.1942 - accuracy: 0.9846 - val_loss: 0.3293 - val_accuracy: 0.9028\n","Epoch 98/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.1967 - accuracy: 0.9861 - val_loss: 0.3128 - val_accuracy: 0.9167\n","Epoch 99/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.1836 - accuracy: 0.9954 - val_loss: 0.2599 - val_accuracy: 0.9583\n","Epoch 100/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.1975 - accuracy: 0.9861 - val_loss: 0.2698 - val_accuracy: 0.9306\n","3/3 [==============================] - 0s 17ms/step - loss: 0.3388 - accuracy: 0.9000\n","[0.3387681543827057, 0.8999999761581421]\n","0.886039886039886\n"]}]},{"cell_type":"code","source":["acrc = np.array(val_res['accuracy']).mean(axis=0)\n","f1scr = np.array(val_res['f1_score']).mean(axis=0)\n","print(\"Accuracy  : {}\".format(acrc[1]))\n","print(\"F1_Score  : {}\".format(f1scr))\n","cmatrix = np.array(val_res['confusion_matrix']).mean(axis=0)\n","c_matrix = cmatrix/np.sum(cmatrix, axis=1).reshape(2,1)\n","import seaborn as sns\n","figure = plt.figure(figsize=(9, 9))\n","sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n","plt.tight_layout()\n","plt.ylabel('True label')\n","plt.xlabel('Predicted label')\n","plt.show()"],"metadata":{"id":"aUUIuZ3PVDcp","colab":{"base_uri":"https://localhost:8080/","height":706},"executionInfo":{"status":"ok","timestamp":1642520134902,"user_tz":-360,"elapsed":901,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"725f5b43-0af2-47c8-b404-6398dcf48d8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy  : 0.9074999988079071\n","F1_Score  : 0.894915933778608\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 648x648 with 2 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"e1ypZ2NnYxes"},"source":["# **Arousal**"]},{"cell_type":"code","metadata":{"id":"B7fcxLuwZpkK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642520134903,"user_tz":-360,"elapsed":27,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"3180cd47-e085-4ea0-c12b-76a4b25eb9df"},"source":["#arousal\n","X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.1, random_state=4)\n","print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(720, 32, 384, 1) (80, 32, 384, 1) (720, 2) (80, 2)\n"]}]},{"cell_type":"code","metadata":{"id":"4iz5mTT7Zwcp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642522237861,"user_tz":-360,"elapsed":2102983,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"e9dde167-0336-4498-aeed-49ea662b2145"},"source":["val_res = {'accuracy': [], 'f1_score': [], 'confusion_matrix': []}\n","foldNum=0\n","#model = get_model()\n","for train_index, val_index in kfold.split(X_train, Y_train):\n","  foldNum = foldNum + 1\n","  model = get_model()\n","  print(\"Results for fold\",foldNum)\n","  x_train, x_val = X_train[train_index], X_train[val_index]\n","  y_train, y_val = Y_train[train_index], Y_train[val_index]\n","  class_weight = call_class_weights(y_train)\n","  model.fit(x_train, y_train, epochs=epochs, class_weight=class_weight, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n","  acc = model.evaluate(x_test, y_test)\n","  print(acc)\n","  val_res['accuracy'].append(acc)\n","  pred = model.predict(x_test)\n","  f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n","  print(f1scr)\n","  val_res['f1_score'].append(f1scr)\n","  val_res['confusion_matrix'].append(confusion_matrix(y_test.argmax(1), pred.argmax(1)))\n","  gc.collect() # Garbage collecter\n","  del x_train, x_val, y_train, y_val, acc, f1scr\n","  gc.collect()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layer LSTM_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer LSTM_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Results for fold 1\n","Epoch 1/100\n","65/65 [==============================] - 7s 31ms/step - loss: 0.8509 - accuracy: 0.4815 - val_loss: 0.8401 - val_accuracy: 0.5972\n","Epoch 2/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.8307 - accuracy: 0.4907 - val_loss: 0.8211 - val_accuracy: 0.5972\n","Epoch 3/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.8126 - accuracy: 0.6312 - val_loss: 0.8037 - val_accuracy: 0.6389\n","Epoch 4/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.7967 - accuracy: 0.5926 - val_loss: 0.7887 - val_accuracy: 0.6389\n","Epoch 5/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.7810 - accuracy: 0.6806 - val_loss: 0.7743 - val_accuracy: 0.6250\n","Epoch 6/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.7643 - accuracy: 0.6836 - val_loss: 0.7599 - val_accuracy: 0.5694\n","Epoch 7/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.7358 - accuracy: 0.6852 - val_loss: 0.7353 - val_accuracy: 0.6250\n","Epoch 8/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.6939 - accuracy: 0.7114 - val_loss: 0.7045 - val_accuracy: 0.6806\n","Epoch 9/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.6570 - accuracy: 0.7546 - val_loss: 0.7001 - val_accuracy: 0.6528\n","Epoch 10/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.6500 - accuracy: 0.7377 - val_loss: 0.6710 - val_accuracy: 0.6806\n","Epoch 11/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.6220 - accuracy: 0.7747 - val_loss: 0.6627 - val_accuracy: 0.6944\n","Epoch 12/100\n","65/65 [==============================] - 1s 20ms/step - loss: 0.5974 - accuracy: 0.7932 - val_loss: 0.6213 - val_accuracy: 0.7639\n","Epoch 13/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.5745 - accuracy: 0.8333 - val_loss: 0.6310 - val_accuracy: 0.7083\n","Epoch 14/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.5700 - accuracy: 0.8241 - val_loss: 0.6170 - val_accuracy: 0.7639\n","Epoch 15/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.5434 - accuracy: 0.8657 - val_loss: 0.6170 - val_accuracy: 0.7361\n","Epoch 16/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.5422 - accuracy: 0.8503 - val_loss: 0.5917 - val_accuracy: 0.8056\n","Epoch 17/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.5332 - accuracy: 0.8534 - val_loss: 0.5769 - val_accuracy: 0.8194\n","Epoch 18/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.5248 - accuracy: 0.8580 - val_loss: 0.5836 - val_accuracy: 0.7778\n","Epoch 19/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.5025 - accuracy: 0.8920 - val_loss: 0.5616 - val_accuracy: 0.7500\n","Epoch 20/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.4973 - accuracy: 0.8858 - val_loss: 0.5397 - val_accuracy: 0.8194\n","Epoch 21/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.4786 - accuracy: 0.9074 - val_loss: 0.5415 - val_accuracy: 0.8056\n","Epoch 22/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.4696 - accuracy: 0.9136 - val_loss: 0.5488 - val_accuracy: 0.7639\n","Epoch 23/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.4655 - accuracy: 0.9012 - val_loss: 0.5339 - val_accuracy: 0.7917\n","Epoch 24/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.4597 - accuracy: 0.9059 - val_loss: 0.5244 - val_accuracy: 0.8056\n","Epoch 25/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.4469 - accuracy: 0.9321 - val_loss: 0.5193 - val_accuracy: 0.8611\n","Epoch 26/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.4381 - accuracy: 0.9244 - val_loss: 0.5228 - val_accuracy: 0.8333\n","Epoch 27/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.4333 - accuracy: 0.9290 - val_loss: 0.5242 - val_accuracy: 0.8194\n","Epoch 28/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.4370 - accuracy: 0.9228 - val_loss: 0.4772 - val_accuracy: 0.8611\n","Epoch 29/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.4133 - accuracy: 0.9352 - val_loss: 0.4945 - val_accuracy: 0.8194\n","Epoch 30/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.4032 - accuracy: 0.9506 - val_loss: 0.4987 - val_accuracy: 0.8056\n","Epoch 31/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.4025 - accuracy: 0.9444 - val_loss: 0.5026 - val_accuracy: 0.8194\n","Epoch 32/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.3942 - accuracy: 0.9475 - val_loss: 0.4839 - val_accuracy: 0.8194\n","Epoch 33/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.3823 - accuracy: 0.9537 - val_loss: 0.4664 - val_accuracy: 0.8333\n","Epoch 34/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.3833 - accuracy: 0.9568 - val_loss: 0.4322 - val_accuracy: 0.8889\n","Epoch 35/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.3757 - accuracy: 0.9522 - val_loss: 0.4581 - val_accuracy: 0.8750\n","Epoch 36/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.3645 - accuracy: 0.9676 - val_loss: 0.4438 - val_accuracy: 0.8889\n","Epoch 37/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.3688 - accuracy: 0.9583 - val_loss: 0.4850 - val_accuracy: 0.8333\n","Epoch 38/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.3676 - accuracy: 0.9506 - val_loss: 0.4289 - val_accuracy: 0.8889\n","Epoch 39/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.3744 - accuracy: 0.9475 - val_loss: 0.4954 - val_accuracy: 0.8194\n","Epoch 40/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.3565 - accuracy: 0.9599 - val_loss: 0.4192 - val_accuracy: 0.9028\n","Epoch 41/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.3365 - accuracy: 0.9784 - val_loss: 0.4246 - val_accuracy: 0.9028\n","Epoch 42/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.3312 - accuracy: 0.9769 - val_loss: 0.4397 - val_accuracy: 0.8472\n","Epoch 43/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.3236 - accuracy: 0.9815 - val_loss: 0.4451 - val_accuracy: 0.8472\n","Epoch 44/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.3284 - accuracy: 0.9753 - val_loss: 0.4203 - val_accuracy: 0.8611\n","Epoch 45/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.3258 - accuracy: 0.9738 - val_loss: 0.3583 - val_accuracy: 0.9583\n","Epoch 46/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.3088 - accuracy: 0.9907 - val_loss: 0.4293 - val_accuracy: 0.8472\n","Epoch 47/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.3156 - accuracy: 0.9753 - val_loss: 0.4830 - val_accuracy: 0.8194\n","Epoch 48/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.3047 - accuracy: 0.9861 - val_loss: 0.4295 - val_accuracy: 0.8750\n","Epoch 49/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.3123 - accuracy: 0.9691 - val_loss: 0.4163 - val_accuracy: 0.8611\n","Epoch 50/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.3003 - accuracy: 0.9815 - val_loss: 0.3944 - val_accuracy: 0.8750\n","Epoch 51/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.3021 - accuracy: 0.9722 - val_loss: 0.4221 - val_accuracy: 0.8750\n","Epoch 52/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.3052 - accuracy: 0.9738 - val_loss: 0.4029 - val_accuracy: 0.8750\n","Epoch 53/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.2936 - accuracy: 0.9815 - val_loss: 0.4041 - val_accuracy: 0.8889\n","Epoch 54/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2965 - accuracy: 0.9784 - val_loss: 0.3753 - val_accuracy: 0.9306\n","Epoch 55/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2882 - accuracy: 0.9784 - val_loss: 0.4147 - val_accuracy: 0.8611\n","Epoch 56/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2805 - accuracy: 0.9815 - val_loss: 0.3592 - val_accuracy: 0.9306\n","Epoch 57/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.2845 - accuracy: 0.9799 - val_loss: 0.3502 - val_accuracy: 0.9167\n","Epoch 58/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.2816 - accuracy: 0.9799 - val_loss: 0.4521 - val_accuracy: 0.8333\n","Epoch 59/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.2868 - accuracy: 0.9738 - val_loss: 0.3870 - val_accuracy: 0.8750\n","Epoch 60/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.2664 - accuracy: 0.9907 - val_loss: 0.4013 - val_accuracy: 0.8611\n","Epoch 61/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.2822 - accuracy: 0.9722 - val_loss: 0.3871 - val_accuracy: 0.8889\n","Epoch 62/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2726 - accuracy: 0.9769 - val_loss: 0.3657 - val_accuracy: 0.8889\n","Epoch 63/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.2629 - accuracy: 0.9830 - val_loss: 0.3314 - val_accuracy: 0.9028\n","Epoch 64/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.2563 - accuracy: 0.9877 - val_loss: 0.3607 - val_accuracy: 0.9167\n","Epoch 65/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.2494 - accuracy: 0.9892 - val_loss: 0.3486 - val_accuracy: 0.9306\n","Epoch 66/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.2489 - accuracy: 0.9892 - val_loss: 0.3663 - val_accuracy: 0.9028\n","Epoch 67/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.2591 - accuracy: 0.9815 - val_loss: 0.3285 - val_accuracy: 0.9167\n","Epoch 68/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.2506 - accuracy: 0.9877 - val_loss: 0.3363 - val_accuracy: 0.9167\n","Epoch 69/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.2474 - accuracy: 0.9877 - val_loss: 0.3584 - val_accuracy: 0.8889\n","Epoch 70/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.2432 - accuracy: 0.9861 - val_loss: 0.4115 - val_accuracy: 0.8611\n","Epoch 71/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.2371 - accuracy: 0.9938 - val_loss: 0.3319 - val_accuracy: 0.9306\n","Epoch 72/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.2297 - accuracy: 0.9954 - val_loss: 0.3122 - val_accuracy: 0.9306\n","Epoch 73/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.2369 - accuracy: 0.9877 - val_loss: 0.4019 - val_accuracy: 0.8611\n","Epoch 74/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.2316 - accuracy: 0.9892 - val_loss: 0.3795 - val_accuracy: 0.8750\n","Epoch 75/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.2475 - accuracy: 0.9784 - val_loss: 0.3358 - val_accuracy: 0.9028\n","Epoch 76/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.2203 - accuracy: 0.9985 - val_loss: 0.3543 - val_accuracy: 0.9028\n","Epoch 77/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.2198 - accuracy: 0.9985 - val_loss: 0.3577 - val_accuracy: 0.8750\n","Epoch 78/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.2248 - accuracy: 0.9907 - val_loss: 0.3347 - val_accuracy: 0.9306\n","Epoch 79/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.2178 - accuracy: 0.9907 - val_loss: 0.3089 - val_accuracy: 0.9167\n","Epoch 80/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.2123 - accuracy: 0.9938 - val_loss: 0.3454 - val_accuracy: 0.8889\n","Epoch 81/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.2135 - accuracy: 0.9954 - val_loss: 0.3665 - val_accuracy: 0.8889\n","Epoch 82/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.2239 - accuracy: 0.9815 - val_loss: 0.3711 - val_accuracy: 0.8750\n","Epoch 83/100\n","65/65 [==============================] - 2s 23ms/step - loss: 0.2233 - accuracy: 0.9830 - val_loss: 0.3620 - val_accuracy: 0.8750\n","Epoch 84/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.2229 - accuracy: 0.9830 - val_loss: 0.4102 - val_accuracy: 0.8472\n","Epoch 85/100\n","65/65 [==============================] - 2s 23ms/step - loss: 0.2208 - accuracy: 0.9830 - val_loss: 0.3394 - val_accuracy: 0.8889\n","Epoch 86/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.2158 - accuracy: 0.9846 - val_loss: 0.3318 - val_accuracy: 0.9167\n","Epoch 87/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.2048 - accuracy: 0.9907 - val_loss: 0.3805 - val_accuracy: 0.8750\n","Epoch 88/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.2039 - accuracy: 0.9907 - val_loss: 0.3893 - val_accuracy: 0.8889\n","Epoch 89/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.2059 - accuracy: 0.9892 - val_loss: 0.3127 - val_accuracy: 0.9167\n","Epoch 90/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.1947 - accuracy: 0.9954 - val_loss: 0.3092 - val_accuracy: 0.9028\n","Epoch 91/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.1988 - accuracy: 0.9892 - val_loss: 0.3506 - val_accuracy: 0.8750\n","Epoch 92/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.1968 - accuracy: 0.9892 - val_loss: 0.3623 - val_accuracy: 0.8611\n","Epoch 93/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2031 - accuracy: 0.9815 - val_loss: 0.3387 - val_accuracy: 0.8889\n","Epoch 94/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.1959 - accuracy: 0.9892 - val_loss: 0.3139 - val_accuracy: 0.9306\n","Epoch 95/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.1845 - accuracy: 0.9969 - val_loss: 0.3824 - val_accuracy: 0.8472\n","Epoch 96/100\n","65/65 [==============================] - 2s 23ms/step - loss: 0.1869 - accuracy: 0.9954 - val_loss: 0.3087 - val_accuracy: 0.9167\n","Epoch 97/100\n","65/65 [==============================] - 2s 23ms/step - loss: 0.1811 - accuracy: 0.9954 - val_loss: 0.3246 - val_accuracy: 0.8889\n","Epoch 98/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.1787 - accuracy: 0.9969 - val_loss: 0.3063 - val_accuracy: 0.9167\n","Epoch 99/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.1810 - accuracy: 0.9923 - val_loss: 0.3064 - val_accuracy: 0.8889\n","Epoch 100/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.1863 - accuracy: 0.9877 - val_loss: 0.3814 - val_accuracy: 0.8611\n","3/3 [==============================] - 0s 7ms/step - loss: 0.4234 - accuracy: 0.8500\n","[0.4233829379081726, 0.8500000238418579]\n","0.8420013166556946\n","WARNING:tensorflow:Layer LSTM_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer LSTM_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Results for fold 2\n","Epoch 1/100\n","65/65 [==============================] - 7s 32ms/step - loss: 0.8511 - accuracy: 0.5108 - val_loss: 0.8404 - val_accuracy: 0.4861\n","Epoch 2/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.8304 - accuracy: 0.6065 - val_loss: 0.8208 - val_accuracy: 0.5278\n","Epoch 3/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.8122 - accuracy: 0.6204 - val_loss: 0.8041 - val_accuracy: 0.5556\n","Epoch 4/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.7960 - accuracy: 0.6435 - val_loss: 0.7888 - val_accuracy: 0.6806\n","Epoch 5/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.7813 - accuracy: 0.6590 - val_loss: 0.7737 - val_accuracy: 0.5833\n","Epoch 6/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.7671 - accuracy: 0.6991 - val_loss: 0.7569 - val_accuracy: 0.6944\n","Epoch 7/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.7471 - accuracy: 0.7253 - val_loss: 0.7294 - val_accuracy: 0.6528\n","Epoch 8/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.7139 - accuracy: 0.7608 - val_loss: 0.7031 - val_accuracy: 0.7361\n","Epoch 9/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.6847 - accuracy: 0.7639 - val_loss: 0.6714 - val_accuracy: 0.6944\n","Epoch 10/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.6442 - accuracy: 0.8302 - val_loss: 0.6348 - val_accuracy: 0.8194\n","Epoch 11/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.6234 - accuracy: 0.8241 - val_loss: 0.6205 - val_accuracy: 0.8194\n","Epoch 12/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.5925 - accuracy: 0.8642 - val_loss: 0.6489 - val_accuracy: 0.7083\n","Epoch 13/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.5763 - accuracy: 0.8673 - val_loss: 0.6064 - val_accuracy: 0.8056\n","Epoch 14/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.5664 - accuracy: 0.8596 - val_loss: 0.6000 - val_accuracy: 0.7639\n","Epoch 15/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.5538 - accuracy: 0.8719 - val_loss: 0.5755 - val_accuracy: 0.8333\n","Epoch 16/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.5363 - accuracy: 0.8873 - val_loss: 0.5368 - val_accuracy: 0.9028\n","Epoch 17/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.5127 - accuracy: 0.9198 - val_loss: 0.5559 - val_accuracy: 0.8333\n","Epoch 18/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.5032 - accuracy: 0.9290 - val_loss: 0.5192 - val_accuracy: 0.8889\n","Epoch 19/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.5056 - accuracy: 0.9059 - val_loss: 0.5178 - val_accuracy: 0.8889\n","Epoch 20/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.5002 - accuracy: 0.9167 - val_loss: 0.5455 - val_accuracy: 0.8194\n","Epoch 21/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.4952 - accuracy: 0.9105 - val_loss: 0.4762 - val_accuracy: 0.9444\n","Epoch 22/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.4945 - accuracy: 0.8997 - val_loss: 0.5166 - val_accuracy: 0.8750\n","Epoch 23/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.4525 - accuracy: 0.9645 - val_loss: 0.4832 - val_accuracy: 0.9028\n","Epoch 24/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.4608 - accuracy: 0.9444 - val_loss: 0.4805 - val_accuracy: 0.9167\n","Epoch 25/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.4433 - accuracy: 0.9537 - val_loss: 0.5006 - val_accuracy: 0.8611\n","Epoch 26/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.4435 - accuracy: 0.9506 - val_loss: 0.5251 - val_accuracy: 0.8472\n","Epoch 27/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.4535 - accuracy: 0.9306 - val_loss: 0.5197 - val_accuracy: 0.8472\n","Epoch 28/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.4392 - accuracy: 0.9460 - val_loss: 0.5052 - val_accuracy: 0.8750\n","Epoch 29/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.4639 - accuracy: 0.9074 - val_loss: 0.4627 - val_accuracy: 0.9028\n","Epoch 30/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.4383 - accuracy: 0.9429 - val_loss: 0.5212 - val_accuracy: 0.8194\n","Epoch 31/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.4386 - accuracy: 0.9352 - val_loss: 0.4503 - val_accuracy: 0.9167\n","Epoch 32/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4330 - accuracy: 0.9321 - val_loss: 0.5413 - val_accuracy: 0.8056\n","Epoch 33/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.4173 - accuracy: 0.9506 - val_loss: 0.4612 - val_accuracy: 0.9028\n","Epoch 34/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.4122 - accuracy: 0.9537 - val_loss: 0.4589 - val_accuracy: 0.9028\n","Epoch 35/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.4146 - accuracy: 0.9475 - val_loss: 0.4479 - val_accuracy: 0.8889\n","Epoch 36/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.4024 - accuracy: 0.9552 - val_loss: 0.4734 - val_accuracy: 0.9028\n","Epoch 37/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.4026 - accuracy: 0.9583 - val_loss: 0.4800 - val_accuracy: 0.8750\n","Epoch 38/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.3797 - accuracy: 0.9784 - val_loss: 0.4382 - val_accuracy: 0.9167\n","Epoch 39/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.3952 - accuracy: 0.9568 - val_loss: 0.4569 - val_accuracy: 0.9028\n","Epoch 40/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.3776 - accuracy: 0.9707 - val_loss: 0.4461 - val_accuracy: 0.9028\n","Epoch 41/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.4009 - accuracy: 0.9383 - val_loss: 0.4322 - val_accuracy: 0.9028\n","Epoch 42/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.3791 - accuracy: 0.9660 - val_loss: 0.4173 - val_accuracy: 0.9306\n","Epoch 43/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.3736 - accuracy: 0.9676 - val_loss: 0.4263 - val_accuracy: 0.9028\n","Epoch 44/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.3804 - accuracy: 0.9568 - val_loss: 0.4554 - val_accuracy: 0.8889\n","Epoch 45/100\n","65/65 [==============================] - 2s 23ms/step - loss: 0.3624 - accuracy: 0.9738 - val_loss: 0.4065 - val_accuracy: 0.9306\n","Epoch 46/100\n","65/65 [==============================] - 2s 23ms/step - loss: 0.3546 - accuracy: 0.9753 - val_loss: 0.3871 - val_accuracy: 0.9583\n","Epoch 47/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.3728 - accuracy: 0.9522 - val_loss: 0.5331 - val_accuracy: 0.7917\n","Epoch 48/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.3643 - accuracy: 0.9583 - val_loss: 0.4143 - val_accuracy: 0.9167\n","Epoch 49/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.3567 - accuracy: 0.9691 - val_loss: 0.4258 - val_accuracy: 0.8889\n","Epoch 50/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.3450 - accuracy: 0.9784 - val_loss: 0.3881 - val_accuracy: 0.9444\n","Epoch 51/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.3611 - accuracy: 0.9552 - val_loss: 0.4072 - val_accuracy: 0.9167\n","Epoch 52/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.3497 - accuracy: 0.9630 - val_loss: 0.4291 - val_accuracy: 0.8889\n","Epoch 53/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.3372 - accuracy: 0.9738 - val_loss: 0.4112 - val_accuracy: 0.9028\n","Epoch 54/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.3319 - accuracy: 0.9753 - val_loss: 0.4728 - val_accuracy: 0.8472\n","Epoch 55/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.3461 - accuracy: 0.9660 - val_loss: 0.3533 - val_accuracy: 0.9722\n","Epoch 56/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.3362 - accuracy: 0.9707 - val_loss: 0.4185 - val_accuracy: 0.9028\n","Epoch 57/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3371 - accuracy: 0.9614 - val_loss: 0.3869 - val_accuracy: 0.9167\n","Epoch 58/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.3180 - accuracy: 0.9861 - val_loss: 0.4185 - val_accuracy: 0.8889\n","Epoch 59/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.3269 - accuracy: 0.9707 - val_loss: 0.3785 - val_accuracy: 0.9167\n","Epoch 60/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.3068 - accuracy: 0.9861 - val_loss: 0.3791 - val_accuracy: 0.9167\n","Epoch 61/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.3327 - accuracy: 0.9660 - val_loss: 0.3588 - val_accuracy: 0.9444\n","Epoch 62/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.3012 - accuracy: 0.9861 - val_loss: 0.3489 - val_accuracy: 0.9583\n","Epoch 63/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.3018 - accuracy: 0.9830 - val_loss: 0.3837 - val_accuracy: 0.9028\n","Epoch 64/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.3101 - accuracy: 0.9753 - val_loss: 0.4302 - val_accuracy: 0.8750\n","Epoch 65/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2957 - accuracy: 0.9846 - val_loss: 0.3568 - val_accuracy: 0.9444\n","Epoch 66/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.2941 - accuracy: 0.9861 - val_loss: 0.4217 - val_accuracy: 0.8750\n","Epoch 67/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2894 - accuracy: 0.9861 - val_loss: 0.3544 - val_accuracy: 0.9306\n","Epoch 68/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.2860 - accuracy: 0.9892 - val_loss: 0.3287 - val_accuracy: 0.9583\n","Epoch 69/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.2884 - accuracy: 0.9846 - val_loss: 0.3365 - val_accuracy: 0.9444\n","Epoch 70/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.3068 - accuracy: 0.9630 - val_loss: 0.4186 - val_accuracy: 0.8750\n","Epoch 71/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.2809 - accuracy: 0.9861 - val_loss: 0.3479 - val_accuracy: 0.9306\n","Epoch 72/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.3121 - accuracy: 0.9583 - val_loss: 0.4332 - val_accuracy: 0.8750\n","Epoch 73/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.2888 - accuracy: 0.9753 - val_loss: 0.3694 - val_accuracy: 0.9028\n","Epoch 74/100\n","65/65 [==============================] - 2s 23ms/step - loss: 0.2863 - accuracy: 0.9784 - val_loss: 0.3919 - val_accuracy: 0.9028\n","Epoch 75/100\n","65/65 [==============================] - 1s 21ms/step - loss: 0.2804 - accuracy: 0.9799 - val_loss: 0.4358 - val_accuracy: 0.8472\n","Epoch 76/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.2749 - accuracy: 0.9830 - val_loss: 0.3846 - val_accuracy: 0.9028\n","Epoch 77/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.2762 - accuracy: 0.9830 - val_loss: 0.3511 - val_accuracy: 0.9167\n","Epoch 78/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.2676 - accuracy: 0.9877 - val_loss: 0.3481 - val_accuracy: 0.9444\n","Epoch 79/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.2593 - accuracy: 0.9877 - val_loss: 0.4512 - val_accuracy: 0.8472\n","Epoch 80/100\n","65/65 [==============================] - 1s 22ms/step - loss: 0.2726 - accuracy: 0.9769 - val_loss: 0.3319 - val_accuracy: 0.9167\n","Epoch 81/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.2607 - accuracy: 0.9877 - val_loss: 0.3395 - val_accuracy: 0.9306\n","Epoch 82/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.2678 - accuracy: 0.9784 - val_loss: 0.2959 - val_accuracy: 0.9722\n","Epoch 83/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.2871 - accuracy: 0.9583 - val_loss: 0.4816 - val_accuracy: 0.8056\n","Epoch 84/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.2565 - accuracy: 0.9846 - val_loss: 0.3778 - val_accuracy: 0.9028\n","Epoch 85/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2622 - accuracy: 0.9784 - val_loss: 0.3275 - val_accuracy: 0.9306\n","Epoch 86/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2638 - accuracy: 0.9738 - val_loss: 0.3883 - val_accuracy: 0.8611\n","Epoch 87/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2556 - accuracy: 0.9815 - val_loss: 0.4527 - val_accuracy: 0.8472\n","Epoch 88/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2627 - accuracy: 0.9753 - val_loss: 0.4052 - val_accuracy: 0.8889\n","Epoch 89/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.2538 - accuracy: 0.9769 - val_loss: 0.3869 - val_accuracy: 0.8889\n","Epoch 90/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.2421 - accuracy: 0.9861 - val_loss: 0.3556 - val_accuracy: 0.9028\n","Epoch 91/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.2450 - accuracy: 0.9846 - val_loss: 0.3036 - val_accuracy: 0.9306\n","Epoch 92/100\n","65/65 [==============================] - 2s 23ms/step - loss: 0.2290 - accuracy: 0.9954 - val_loss: 0.3271 - val_accuracy: 0.9306\n","Epoch 93/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.2326 - accuracy: 0.9892 - val_loss: 0.2997 - val_accuracy: 0.9444\n","Epoch 94/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.2381 - accuracy: 0.9815 - val_loss: 0.2774 - val_accuracy: 0.9583\n","Epoch 95/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.2375 - accuracy: 0.9846 - val_loss: 0.3026 - val_accuracy: 0.9444\n","Epoch 96/100\n","65/65 [==============================] - 2s 23ms/step - loss: 0.2175 - accuracy: 0.9969 - val_loss: 0.3489 - val_accuracy: 0.9028\n","Epoch 97/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.2320 - accuracy: 0.9830 - val_loss: 0.4139 - val_accuracy: 0.8750\n","Epoch 98/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.2170 - accuracy: 0.9954 - val_loss: 0.3301 - val_accuracy: 0.9167\n","Epoch 99/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.2103 - accuracy: 1.0000 - val_loss: 0.3071 - val_accuracy: 0.9444\n","Epoch 100/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2133 - accuracy: 0.9923 - val_loss: 0.4607 - val_accuracy: 0.8333\n","3/3 [==============================] - 0s 11ms/step - loss: 0.6554 - accuracy: 0.7000\n","[0.6554327011108398, 0.699999988079071]\n","0.6992481203007519\n","WARNING:tensorflow:Layer LSTM_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer LSTM_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Results for fold 3\n","Epoch 1/100\n","65/65 [==============================] - 10s 44ms/step - loss: 0.8517 - accuracy: 0.5448 - val_loss: 0.8411 - val_accuracy: 0.5139\n","Epoch 2/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.8321 - accuracy: 0.5910 - val_loss: 0.8228 - val_accuracy: 0.5417\n","Epoch 3/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.8148 - accuracy: 0.6343 - val_loss: 0.8065 - val_accuracy: 0.5417\n","Epoch 4/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.7994 - accuracy: 0.6250 - val_loss: 0.7925 - val_accuracy: 0.5417\n","Epoch 5/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.7856 - accuracy: 0.6466 - val_loss: 0.7767 - val_accuracy: 0.6528\n","Epoch 6/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.7704 - accuracy: 0.6929 - val_loss: 0.7610 - val_accuracy: 0.6111\n","Epoch 7/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.7530 - accuracy: 0.7068 - val_loss: 0.7440 - val_accuracy: 0.6250\n","Epoch 8/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.7275 - accuracy: 0.7253 - val_loss: 0.7219 - val_accuracy: 0.6806\n","Epoch 9/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.6958 - accuracy: 0.7114 - val_loss: 0.6634 - val_accuracy: 0.7639\n","Epoch 10/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.6577 - accuracy: 0.7377 - val_loss: 0.6724 - val_accuracy: 0.6806\n","Epoch 11/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.6360 - accuracy: 0.7824 - val_loss: 0.6373 - val_accuracy: 0.7222\n","Epoch 12/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.6137 - accuracy: 0.7932 - val_loss: 0.6089 - val_accuracy: 0.7639\n","Epoch 13/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.5990 - accuracy: 0.8102 - val_loss: 0.5903 - val_accuracy: 0.7917\n","Epoch 14/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.5662 - accuracy: 0.8565 - val_loss: 0.6159 - val_accuracy: 0.7500\n","Epoch 15/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.5673 - accuracy: 0.8426 - val_loss: 0.6148 - val_accuracy: 0.7778\n","Epoch 16/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.5538 - accuracy: 0.8519 - val_loss: 0.5887 - val_accuracy: 0.7917\n","Epoch 17/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.5390 - accuracy: 0.8673 - val_loss: 0.5890 - val_accuracy: 0.7778\n","Epoch 18/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.5261 - accuracy: 0.8935 - val_loss: 0.5666 - val_accuracy: 0.8194\n","Epoch 19/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.5172 - accuracy: 0.8858 - val_loss: 0.5513 - val_accuracy: 0.8472\n","Epoch 20/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.4995 - accuracy: 0.8981 - val_loss: 0.5840 - val_accuracy: 0.7361\n","Epoch 21/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.5102 - accuracy: 0.8688 - val_loss: 0.5416 - val_accuracy: 0.8472\n","Epoch 22/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4857 - accuracy: 0.9043 - val_loss: 0.5218 - val_accuracy: 0.8472\n","Epoch 23/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4829 - accuracy: 0.9028 - val_loss: 0.5205 - val_accuracy: 0.8333\n","Epoch 24/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4667 - accuracy: 0.9259 - val_loss: 0.5376 - val_accuracy: 0.8194\n","Epoch 25/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4587 - accuracy: 0.9213 - val_loss: 0.5251 - val_accuracy: 0.8472\n","Epoch 26/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4480 - accuracy: 0.9182 - val_loss: 0.5126 - val_accuracy: 0.8333\n","Epoch 27/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4450 - accuracy: 0.9290 - val_loss: 0.4889 - val_accuracy: 0.8611\n","Epoch 28/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.4299 - accuracy: 0.9475 - val_loss: 0.4658 - val_accuracy: 0.8750\n","Epoch 29/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4413 - accuracy: 0.9182 - val_loss: 0.4829 - val_accuracy: 0.8750\n","Epoch 30/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.4208 - accuracy: 0.9460 - val_loss: 0.4637 - val_accuracy: 0.8889\n","Epoch 31/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.4112 - accuracy: 0.9460 - val_loss: 0.5262 - val_accuracy: 0.8194\n","Epoch 32/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.4188 - accuracy: 0.9398 - val_loss: 0.4604 - val_accuracy: 0.8611\n","Epoch 33/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4094 - accuracy: 0.9414 - val_loss: 0.4932 - val_accuracy: 0.8750\n","Epoch 34/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3943 - accuracy: 0.9599 - val_loss: 0.4852 - val_accuracy: 0.8472\n","Epoch 35/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3857 - accuracy: 0.9552 - val_loss: 0.4763 - val_accuracy: 0.8750\n","Epoch 36/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3907 - accuracy: 0.9475 - val_loss: 0.4753 - val_accuracy: 0.8611\n","Epoch 37/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3857 - accuracy: 0.9552 - val_loss: 0.4298 - val_accuracy: 0.9167\n","Epoch 38/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3840 - accuracy: 0.9460 - val_loss: 0.4514 - val_accuracy: 0.8750\n","Epoch 39/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3838 - accuracy: 0.9491 - val_loss: 0.4280 - val_accuracy: 0.8889\n","Epoch 40/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3715 - accuracy: 0.9522 - val_loss: 0.4510 - val_accuracy: 0.8472\n","Epoch 41/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3572 - accuracy: 0.9707 - val_loss: 0.4475 - val_accuracy: 0.8750\n","Epoch 42/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3514 - accuracy: 0.9707 - val_loss: 0.4740 - val_accuracy: 0.8333\n","Epoch 43/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3564 - accuracy: 0.9707 - val_loss: 0.4554 - val_accuracy: 0.8611\n","Epoch 44/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3572 - accuracy: 0.9568 - val_loss: 0.4946 - val_accuracy: 0.8333\n","Epoch 45/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3432 - accuracy: 0.9707 - val_loss: 0.4508 - val_accuracy: 0.8472\n","Epoch 46/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3319 - accuracy: 0.9738 - val_loss: 0.3999 - val_accuracy: 0.9028\n","Epoch 47/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3254 - accuracy: 0.9769 - val_loss: 0.4539 - val_accuracy: 0.8472\n","Epoch 48/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3106 - accuracy: 0.9969 - val_loss: 0.4190 - val_accuracy: 0.8611\n","Epoch 49/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3177 - accuracy: 0.9784 - val_loss: 0.4451 - val_accuracy: 0.8472\n","Epoch 50/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3291 - accuracy: 0.9660 - val_loss: 0.4851 - val_accuracy: 0.8333\n","Epoch 51/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3344 - accuracy: 0.9630 - val_loss: 0.4021 - val_accuracy: 0.8750\n","Epoch 52/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3201 - accuracy: 0.9738 - val_loss: 0.4020 - val_accuracy: 0.9028\n","Epoch 53/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3043 - accuracy: 0.9846 - val_loss: 0.3873 - val_accuracy: 0.9306\n","Epoch 54/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3010 - accuracy: 0.9799 - val_loss: 0.3891 - val_accuracy: 0.8889\n","Epoch 55/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3137 - accuracy: 0.9707 - val_loss: 0.3977 - val_accuracy: 0.8889\n","Epoch 56/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2914 - accuracy: 0.9923 - val_loss: 0.3481 - val_accuracy: 0.9444\n","Epoch 57/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2877 - accuracy: 0.9907 - val_loss: 0.3665 - val_accuracy: 0.9167\n","Epoch 58/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2921 - accuracy: 0.9799 - val_loss: 0.3733 - val_accuracy: 0.9167\n","Epoch 59/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2905 - accuracy: 0.9784 - val_loss: 0.3700 - val_accuracy: 0.8889\n","Epoch 60/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2832 - accuracy: 0.9815 - val_loss: 0.3979 - val_accuracy: 0.8611\n","Epoch 61/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2857 - accuracy: 0.9815 - val_loss: 0.3586 - val_accuracy: 0.9028\n","Epoch 62/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2804 - accuracy: 0.9799 - val_loss: 0.3765 - val_accuracy: 0.8889\n","Epoch 63/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2774 - accuracy: 0.9815 - val_loss: 0.3763 - val_accuracy: 0.8889\n","Epoch 64/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2746 - accuracy: 0.9799 - val_loss: 0.3499 - val_accuracy: 0.9167\n","Epoch 65/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2759 - accuracy: 0.9846 - val_loss: 0.3931 - val_accuracy: 0.8889\n","Epoch 66/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2621 - accuracy: 0.9861 - val_loss: 0.4114 - val_accuracy: 0.8750\n","Epoch 67/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2586 - accuracy: 0.9892 - val_loss: 0.3862 - val_accuracy: 0.8889\n","Epoch 68/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2496 - accuracy: 0.9923 - val_loss: 0.3695 - val_accuracy: 0.8889\n","Epoch 69/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2452 - accuracy: 0.9985 - val_loss: 0.4104 - val_accuracy: 0.8472\n","Epoch 70/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2490 - accuracy: 0.9892 - val_loss: 0.3577 - val_accuracy: 0.9028\n","Epoch 71/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2572 - accuracy: 0.9846 - val_loss: 0.3564 - val_accuracy: 0.8889\n","Epoch 72/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2603 - accuracy: 0.9784 - val_loss: 0.3376 - val_accuracy: 0.9306\n","Epoch 73/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2484 - accuracy: 0.9907 - val_loss: 0.3627 - val_accuracy: 0.8889\n","Epoch 74/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2375 - accuracy: 0.9923 - val_loss: 0.3555 - val_accuracy: 0.9167\n","Epoch 75/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2507 - accuracy: 0.9815 - val_loss: 0.3357 - val_accuracy: 0.9167\n","Epoch 76/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2351 - accuracy: 0.9954 - val_loss: 0.3583 - val_accuracy: 0.8889\n","Epoch 77/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2449 - accuracy: 0.9815 - val_loss: 0.3307 - val_accuracy: 0.9167\n","Epoch 78/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2297 - accuracy: 0.9907 - val_loss: 0.3259 - val_accuracy: 0.9167\n","Epoch 79/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2249 - accuracy: 0.9938 - val_loss: 0.3416 - val_accuracy: 0.9167\n","Epoch 80/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2405 - accuracy: 0.9799 - val_loss: 0.2749 - val_accuracy: 0.9444\n","Epoch 81/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2465 - accuracy: 0.9707 - val_loss: 0.3020 - val_accuracy: 0.9444\n","Epoch 82/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2296 - accuracy: 0.9877 - val_loss: 0.3038 - val_accuracy: 0.9444\n","Epoch 83/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2386 - accuracy: 0.9738 - val_loss: 0.3183 - val_accuracy: 0.9306\n","Epoch 84/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2348 - accuracy: 0.9815 - val_loss: 0.2843 - val_accuracy: 0.9306\n","Epoch 85/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2262 - accuracy: 0.9830 - val_loss: 0.3282 - val_accuracy: 0.8889\n","Epoch 86/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2283 - accuracy: 0.9799 - val_loss: 0.3285 - val_accuracy: 0.9306\n","Epoch 87/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2250 - accuracy: 0.9784 - val_loss: 0.3703 - val_accuracy: 0.8750\n","Epoch 88/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2144 - accuracy: 0.9877 - val_loss: 0.3240 - val_accuracy: 0.9167\n","Epoch 89/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2108 - accuracy: 0.9877 - val_loss: 0.2715 - val_accuracy: 0.9583\n","Epoch 90/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2062 - accuracy: 0.9938 - val_loss: 0.3103 - val_accuracy: 0.9167\n","Epoch 91/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2064 - accuracy: 0.9892 - val_loss: 0.2904 - val_accuracy: 0.9306\n","Epoch 92/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2009 - accuracy: 0.9938 - val_loss: 0.3158 - val_accuracy: 0.9167\n","Epoch 93/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.1994 - accuracy: 0.9969 - val_loss: 0.2955 - val_accuracy: 0.9167\n","Epoch 94/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.1966 - accuracy: 0.9938 - val_loss: 0.3342 - val_accuracy: 0.8889\n","Epoch 95/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.1961 - accuracy: 0.9923 - val_loss: 0.3376 - val_accuracy: 0.9028\n","Epoch 96/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.1900 - accuracy: 0.9954 - val_loss: 0.3240 - val_accuracy: 0.8889\n","Epoch 97/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.1945 - accuracy: 0.9907 - val_loss: 0.3476 - val_accuracy: 0.8750\n","Epoch 98/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.1976 - accuracy: 0.9907 - val_loss: 0.2915 - val_accuracy: 0.9444\n","Epoch 99/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.1994 - accuracy: 0.9846 - val_loss: 0.3714 - val_accuracy: 0.8750\n","Epoch 100/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.1945 - accuracy: 0.9892 - val_loss: 0.3517 - val_accuracy: 0.9167\n","3/3 [==============================] - 0s 10ms/step - loss: 0.4861 - accuracy: 0.7750\n","[0.48606857657432556, 0.7749999761581421]\n","0.7727272727272727\n","WARNING:tensorflow:Layer LSTM_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer LSTM_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Results for fold 4\n","Epoch 1/100\n","65/65 [==============================] - 10s 46ms/step - loss: 0.8519 - accuracy: 0.4660 - val_loss: 0.8415 - val_accuracy: 0.5278\n","Epoch 2/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.8323 - accuracy: 0.5818 - val_loss: 0.8229 - val_accuracy: 0.6667\n","Epoch 3/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.8143 - accuracy: 0.6173 - val_loss: 0.8064 - val_accuracy: 0.6667\n","Epoch 4/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.7988 - accuracy: 0.6435 - val_loss: 0.7912 - val_accuracy: 0.6667\n","Epoch 5/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.7840 - accuracy: 0.6667 - val_loss: 0.7770 - val_accuracy: 0.7222\n","Epoch 6/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.7693 - accuracy: 0.6728 - val_loss: 0.7604 - val_accuracy: 0.7083\n","Epoch 7/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.7456 - accuracy: 0.7114 - val_loss: 0.7304 - val_accuracy: 0.6944\n","Epoch 8/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.7066 - accuracy: 0.7438 - val_loss: 0.6909 - val_accuracy: 0.7222\n","Epoch 9/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.6705 - accuracy: 0.7716 - val_loss: 0.6695 - val_accuracy: 0.7361\n","Epoch 10/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.6308 - accuracy: 0.8148 - val_loss: 0.6314 - val_accuracy: 0.8056\n","Epoch 11/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.5940 - accuracy: 0.8395 - val_loss: 0.6156 - val_accuracy: 0.7778\n","Epoch 12/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.5912 - accuracy: 0.8349 - val_loss: 0.6073 - val_accuracy: 0.7778\n","Epoch 13/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.5792 - accuracy: 0.8534 - val_loss: 0.6180 - val_accuracy: 0.7639\n","Epoch 14/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.5591 - accuracy: 0.8719 - val_loss: 0.5771 - val_accuracy: 0.8194\n","Epoch 15/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.5445 - accuracy: 0.8750 - val_loss: 0.5434 - val_accuracy: 0.9028\n","Epoch 16/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.5378 - accuracy: 0.8765 - val_loss: 0.5564 - val_accuracy: 0.8472\n","Epoch 17/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.5315 - accuracy: 0.8889 - val_loss: 0.5339 - val_accuracy: 0.8611\n","Epoch 18/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.5097 - accuracy: 0.9136 - val_loss: 0.5465 - val_accuracy: 0.8611\n","Epoch 19/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.5198 - accuracy: 0.8796 - val_loss: 0.4974 - val_accuracy: 0.9028\n","Epoch 20/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.5131 - accuracy: 0.8873 - val_loss: 0.5319 - val_accuracy: 0.8611\n","Epoch 21/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.5185 - accuracy: 0.8627 - val_loss: 0.5504 - val_accuracy: 0.8056\n","Epoch 22/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4891 - accuracy: 0.9043 - val_loss: 0.5084 - val_accuracy: 0.8750\n","Epoch 23/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.4813 - accuracy: 0.9120 - val_loss: 0.5390 - val_accuracy: 0.8333\n","Epoch 24/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.4634 - accuracy: 0.9275 - val_loss: 0.4999 - val_accuracy: 0.8750\n","Epoch 25/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.4689 - accuracy: 0.9213 - val_loss: 0.5119 - val_accuracy: 0.8333\n","Epoch 26/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.4578 - accuracy: 0.9336 - val_loss: 0.4570 - val_accuracy: 0.9306\n","Epoch 27/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4424 - accuracy: 0.9475 - val_loss: 0.4433 - val_accuracy: 0.9167\n","Epoch 28/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.4416 - accuracy: 0.9414 - val_loss: 0.4628 - val_accuracy: 0.9028\n","Epoch 29/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4409 - accuracy: 0.9414 - val_loss: 0.4527 - val_accuracy: 0.9444\n","Epoch 30/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4336 - accuracy: 0.9460 - val_loss: 0.5307 - val_accuracy: 0.8333\n","Epoch 31/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4268 - accuracy: 0.9506 - val_loss: 0.4656 - val_accuracy: 0.9306\n","Epoch 32/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4378 - accuracy: 0.9244 - val_loss: 0.4577 - val_accuracy: 0.9028\n","Epoch 33/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4173 - accuracy: 0.9506 - val_loss: 0.4319 - val_accuracy: 0.9444\n","Epoch 34/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4078 - accuracy: 0.9599 - val_loss: 0.4278 - val_accuracy: 0.9444\n","Epoch 35/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4252 - accuracy: 0.9367 - val_loss: 0.4288 - val_accuracy: 0.9167\n","Epoch 36/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4177 - accuracy: 0.9352 - val_loss: 0.4152 - val_accuracy: 0.9583\n","Epoch 37/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3892 - accuracy: 0.9676 - val_loss: 0.4578 - val_accuracy: 0.8750\n","Epoch 38/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4003 - accuracy: 0.9475 - val_loss: 0.4622 - val_accuracy: 0.8750\n","Epoch 39/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.4046 - accuracy: 0.9429 - val_loss: 0.4699 - val_accuracy: 0.8889\n","Epoch 40/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3902 - accuracy: 0.9568 - val_loss: 0.4152 - val_accuracy: 0.9306\n","Epoch 41/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3905 - accuracy: 0.9506 - val_loss: 0.4045 - val_accuracy: 0.9444\n","Epoch 42/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3842 - accuracy: 0.9552 - val_loss: 0.4341 - val_accuracy: 0.9167\n","Epoch 43/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3833 - accuracy: 0.9522 - val_loss: 0.4440 - val_accuracy: 0.8889\n","Epoch 44/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3835 - accuracy: 0.9475 - val_loss: 0.3997 - val_accuracy: 0.9444\n","Epoch 45/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3709 - accuracy: 0.9645 - val_loss: 0.4010 - val_accuracy: 0.9306\n","Epoch 46/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3689 - accuracy: 0.9568 - val_loss: 0.4166 - val_accuracy: 0.9167\n","Epoch 47/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3545 - accuracy: 0.9707 - val_loss: 0.4390 - val_accuracy: 0.8889\n","Epoch 48/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3623 - accuracy: 0.9583 - val_loss: 0.5251 - val_accuracy: 0.8056\n","Epoch 49/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3554 - accuracy: 0.9614 - val_loss: 0.3781 - val_accuracy: 0.9306\n","Epoch 50/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3515 - accuracy: 0.9645 - val_loss: 0.4095 - val_accuracy: 0.8889\n","Epoch 51/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3455 - accuracy: 0.9691 - val_loss: 0.4037 - val_accuracy: 0.9167\n","Epoch 52/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3359 - accuracy: 0.9784 - val_loss: 0.4389 - val_accuracy: 0.8750\n","Epoch 53/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3431 - accuracy: 0.9676 - val_loss: 0.5385 - val_accuracy: 0.7639\n","Epoch 54/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3294 - accuracy: 0.9753 - val_loss: 0.4272 - val_accuracy: 0.8750\n","Epoch 55/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3425 - accuracy: 0.9614 - val_loss: 0.4524 - val_accuracy: 0.8472\n","Epoch 56/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3205 - accuracy: 0.9815 - val_loss: 0.4081 - val_accuracy: 0.9028\n","Epoch 57/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3343 - accuracy: 0.9676 - val_loss: 0.4035 - val_accuracy: 0.9167\n","Epoch 58/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3264 - accuracy: 0.9722 - val_loss: 0.5112 - val_accuracy: 0.7778\n","Epoch 59/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3363 - accuracy: 0.9583 - val_loss: 0.4335 - val_accuracy: 0.8611\n","Epoch 60/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3119 - accuracy: 0.9799 - val_loss: 0.3661 - val_accuracy: 0.9444\n","Epoch 61/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2998 - accuracy: 0.9877 - val_loss: 0.3761 - val_accuracy: 0.9306\n","Epoch 62/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3103 - accuracy: 0.9799 - val_loss: 0.4608 - val_accuracy: 0.8472\n","Epoch 63/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3091 - accuracy: 0.9769 - val_loss: 0.3445 - val_accuracy: 0.9444\n","Epoch 64/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3011 - accuracy: 0.9815 - val_loss: 0.3493 - val_accuracy: 0.9583\n","Epoch 65/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3007 - accuracy: 0.9784 - val_loss: 0.3332 - val_accuracy: 0.9583\n","Epoch 66/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2923 - accuracy: 0.9861 - val_loss: 0.3627 - val_accuracy: 0.9167\n","Epoch 67/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2928 - accuracy: 0.9830 - val_loss: 0.4074 - val_accuracy: 0.8750\n","Epoch 68/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2905 - accuracy: 0.9830 - val_loss: 0.3792 - val_accuracy: 0.9028\n","Epoch 69/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2804 - accuracy: 0.9861 - val_loss: 0.3401 - val_accuracy: 0.9444\n","Epoch 70/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2745 - accuracy: 0.9907 - val_loss: 0.4408 - val_accuracy: 0.8472\n","Epoch 71/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2723 - accuracy: 0.9892 - val_loss: 0.3926 - val_accuracy: 0.8750\n","Epoch 72/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2845 - accuracy: 0.9799 - val_loss: 0.4137 - val_accuracy: 0.8750\n","Epoch 73/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2798 - accuracy: 0.9799 - val_loss: 0.3231 - val_accuracy: 0.9444\n","Epoch 74/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3074 - accuracy: 0.9568 - val_loss: 0.3740 - val_accuracy: 0.9028\n","Epoch 75/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2690 - accuracy: 0.9892 - val_loss: 0.3768 - val_accuracy: 0.9167\n","Epoch 76/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2671 - accuracy: 0.9892 - val_loss: 0.4687 - val_accuracy: 0.8194\n","Epoch 77/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2714 - accuracy: 0.9815 - val_loss: 0.3660 - val_accuracy: 0.9167\n","Epoch 78/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2638 - accuracy: 0.9830 - val_loss: 0.4582 - val_accuracy: 0.8333\n","Epoch 79/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2676 - accuracy: 0.9815 - val_loss: 0.3695 - val_accuracy: 0.9028\n","Epoch 80/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2622 - accuracy: 0.9861 - val_loss: 0.3918 - val_accuracy: 0.8889\n","Epoch 81/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2564 - accuracy: 0.9846 - val_loss: 0.3803 - val_accuracy: 0.9028\n","Epoch 82/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2594 - accuracy: 0.9830 - val_loss: 0.3855 - val_accuracy: 0.8889\n","Epoch 83/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2513 - accuracy: 0.9877 - val_loss: 0.3605 - val_accuracy: 0.9167\n","Epoch 84/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2500 - accuracy: 0.9892 - val_loss: 0.3476 - val_accuracy: 0.9306\n","Epoch 85/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2600 - accuracy: 0.9799 - val_loss: 0.2908 - val_accuracy: 0.9722\n","Epoch 86/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2688 - accuracy: 0.9676 - val_loss: 0.2995 - val_accuracy: 0.9583\n","Epoch 87/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.2480 - accuracy: 0.9830 - val_loss: 0.3285 - val_accuracy: 0.9306\n","Epoch 88/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2411 - accuracy: 0.9877 - val_loss: 0.3052 - val_accuracy: 0.9306\n","Epoch 89/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.2408 - accuracy: 0.9877 - val_loss: 0.3770 - val_accuracy: 0.8750\n","Epoch 90/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.2579 - accuracy: 0.9738 - val_loss: 0.3669 - val_accuracy: 0.8889\n","Epoch 91/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2333 - accuracy: 0.9877 - val_loss: 0.3168 - val_accuracy: 0.9167\n","Epoch 92/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.2430 - accuracy: 0.9861 - val_loss: 0.3454 - val_accuracy: 0.9028\n","Epoch 93/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.2254 - accuracy: 0.9923 - val_loss: 0.3082 - val_accuracy: 0.9306\n","Epoch 94/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.2239 - accuracy: 0.9938 - val_loss: 0.3702 - val_accuracy: 0.8889\n","Epoch 95/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.2157 - accuracy: 0.9969 - val_loss: 0.3804 - val_accuracy: 0.8750\n","Epoch 96/100\n","65/65 [==============================] - 2s 23ms/step - loss: 0.2205 - accuracy: 0.9907 - val_loss: 0.3053 - val_accuracy: 0.9444\n","Epoch 97/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.2203 - accuracy: 0.9907 - val_loss: 0.3756 - val_accuracy: 0.8611\n","Epoch 98/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.2598 - accuracy: 0.9583 - val_loss: 0.3661 - val_accuracy: 0.8750\n","Epoch 99/100\n","65/65 [==============================] - 2s 23ms/step - loss: 0.2215 - accuracy: 0.9877 - val_loss: 0.3437 - val_accuracy: 0.9028\n","Epoch 100/100\n","65/65 [==============================] - 1s 23ms/step - loss: 0.2154 - accuracy: 0.9907 - val_loss: 0.2929 - val_accuracy: 0.9306\n","3/3 [==============================] - 0s 10ms/step - loss: 0.3643 - accuracy: 0.9000\n","[0.3642613887786865, 0.8999999761581421]\n","0.8918187964841109\n","WARNING:tensorflow:Layer LSTM_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer LSTM_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Results for fold 5\n","Epoch 1/100\n","65/65 [==============================] - 7s 35ms/step - loss: 0.8504 - accuracy: 0.4923 - val_loss: 0.8388 - val_accuracy: 0.6250\n","Epoch 2/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.8288 - accuracy: 0.5679 - val_loss: 0.8187 - val_accuracy: 0.6250\n","Epoch 3/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.8100 - accuracy: 0.6111 - val_loss: 0.8012 - val_accuracy: 0.6111\n","Epoch 4/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.7936 - accuracy: 0.6497 - val_loss: 0.7856 - val_accuracy: 0.5972\n","Epoch 5/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.7790 - accuracy: 0.6528 - val_loss: 0.7725 - val_accuracy: 0.6667\n","Epoch 6/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.7581 - accuracy: 0.7114 - val_loss: 0.7554 - val_accuracy: 0.6111\n","Epoch 7/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.7208 - accuracy: 0.6852 - val_loss: 0.7498 - val_accuracy: 0.5833\n","Epoch 8/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.6831 - accuracy: 0.7099 - val_loss: 0.7120 - val_accuracy: 0.6528\n","Epoch 9/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.6698 - accuracy: 0.7130 - val_loss: 0.6822 - val_accuracy: 0.6667\n","Epoch 10/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.6554 - accuracy: 0.7454 - val_loss: 0.6650 - val_accuracy: 0.7222\n","Epoch 11/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.6232 - accuracy: 0.8009 - val_loss: 0.6704 - val_accuracy: 0.6944\n","Epoch 12/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.6094 - accuracy: 0.8025 - val_loss: 0.6511 - val_accuracy: 0.7361\n","Epoch 13/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.5939 - accuracy: 0.8117 - val_loss: 0.6589 - val_accuracy: 0.7083\n","Epoch 14/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.5822 - accuracy: 0.8241 - val_loss: 0.6282 - val_accuracy: 0.7222\n","Epoch 15/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.5847 - accuracy: 0.8040 - val_loss: 0.6316 - val_accuracy: 0.7222\n","Epoch 16/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.5567 - accuracy: 0.8549 - val_loss: 0.6090 - val_accuracy: 0.8056\n","Epoch 17/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.5507 - accuracy: 0.8472 - val_loss: 0.6093 - val_accuracy: 0.7361\n","Epoch 18/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.5420 - accuracy: 0.8503 - val_loss: 0.6561 - val_accuracy: 0.6528\n","Epoch 19/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.5192 - accuracy: 0.8765 - val_loss: 0.5727 - val_accuracy: 0.8194\n","Epoch 20/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.5156 - accuracy: 0.8796 - val_loss: 0.5486 - val_accuracy: 0.8194\n","Epoch 21/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.5190 - accuracy: 0.8673 - val_loss: 0.5341 - val_accuracy: 0.8472\n","Epoch 22/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.5048 - accuracy: 0.8843 - val_loss: 0.5483 - val_accuracy: 0.8333\n","Epoch 23/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.5036 - accuracy: 0.8750 - val_loss: 0.5700 - val_accuracy: 0.7917\n","Epoch 24/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4836 - accuracy: 0.9074 - val_loss: 0.5555 - val_accuracy: 0.7639\n","Epoch 25/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4763 - accuracy: 0.9074 - val_loss: 0.5094 - val_accuracy: 0.8750\n","Epoch 26/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4810 - accuracy: 0.8812 - val_loss: 0.4934 - val_accuracy: 0.9167\n","Epoch 27/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4540 - accuracy: 0.9151 - val_loss: 0.5070 - val_accuracy: 0.8611\n","Epoch 28/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.4640 - accuracy: 0.8981 - val_loss: 0.5039 - val_accuracy: 0.8611\n","Epoch 29/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4531 - accuracy: 0.9167 - val_loss: 0.4850 - val_accuracy: 0.8750\n","Epoch 30/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4415 - accuracy: 0.9244 - val_loss: 0.4889 - val_accuracy: 0.8750\n","Epoch 31/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4240 - accuracy: 0.9398 - val_loss: 0.4486 - val_accuracy: 0.9167\n","Epoch 32/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4227 - accuracy: 0.9367 - val_loss: 0.5073 - val_accuracy: 0.8194\n","Epoch 33/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4155 - accuracy: 0.9475 - val_loss: 0.4875 - val_accuracy: 0.8611\n","Epoch 34/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4134 - accuracy: 0.9367 - val_loss: 0.4626 - val_accuracy: 0.8750\n","Epoch 35/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4163 - accuracy: 0.9290 - val_loss: 0.4524 - val_accuracy: 0.8889\n","Epoch 36/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4047 - accuracy: 0.9414 - val_loss: 0.4373 - val_accuracy: 0.9028\n","Epoch 37/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3971 - accuracy: 0.9429 - val_loss: 0.4604 - val_accuracy: 0.8750\n","Epoch 38/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3967 - accuracy: 0.9444 - val_loss: 0.6193 - val_accuracy: 0.6806\n","Epoch 39/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3976 - accuracy: 0.9383 - val_loss: 0.4287 - val_accuracy: 0.9167\n","Epoch 40/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3847 - accuracy: 0.9506 - val_loss: 0.4694 - val_accuracy: 0.8472\n","Epoch 41/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3893 - accuracy: 0.9275 - val_loss: 0.4337 - val_accuracy: 0.9167\n","Epoch 42/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3746 - accuracy: 0.9491 - val_loss: 0.4086 - val_accuracy: 0.9306\n","Epoch 43/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3543 - accuracy: 0.9707 - val_loss: 0.4044 - val_accuracy: 0.8889\n","Epoch 44/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3507 - accuracy: 0.9722 - val_loss: 0.4232 - val_accuracy: 0.9028\n","Epoch 45/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3443 - accuracy: 0.9738 - val_loss: 0.4074 - val_accuracy: 0.9028\n","Epoch 46/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3454 - accuracy: 0.9645 - val_loss: 0.4141 - val_accuracy: 0.9028\n","Epoch 47/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3473 - accuracy: 0.9599 - val_loss: 0.3875 - val_accuracy: 0.9028\n","Epoch 48/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3391 - accuracy: 0.9753 - val_loss: 0.4356 - val_accuracy: 0.8611\n","Epoch 49/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3442 - accuracy: 0.9599 - val_loss: 0.3812 - val_accuracy: 0.9167\n","Epoch 50/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3362 - accuracy: 0.9660 - val_loss: 0.3770 - val_accuracy: 0.9167\n","Epoch 51/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3292 - accuracy: 0.9722 - val_loss: 0.3954 - val_accuracy: 0.9167\n","Epoch 52/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3337 - accuracy: 0.9537 - val_loss: 0.3526 - val_accuracy: 0.9722\n","Epoch 53/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3233 - accuracy: 0.9660 - val_loss: 0.3725 - val_accuracy: 0.9167\n","Epoch 54/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3194 - accuracy: 0.9691 - val_loss: 0.3786 - val_accuracy: 0.9167\n","Epoch 55/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3026 - accuracy: 0.9830 - val_loss: 0.3494 - val_accuracy: 0.9444\n","Epoch 56/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3033 - accuracy: 0.9815 - val_loss: 0.3666 - val_accuracy: 0.9028\n","Epoch 57/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2932 - accuracy: 0.9892 - val_loss: 0.3748 - val_accuracy: 0.9028\n","Epoch 58/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3009 - accuracy: 0.9722 - val_loss: 0.3555 - val_accuracy: 0.9306\n","Epoch 59/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3062 - accuracy: 0.9722 - val_loss: 0.3620 - val_accuracy: 0.9167\n","Epoch 60/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2902 - accuracy: 0.9846 - val_loss: 0.4105 - val_accuracy: 0.8889\n","Epoch 61/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3030 - accuracy: 0.9660 - val_loss: 0.3531 - val_accuracy: 0.9306\n","Epoch 62/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2921 - accuracy: 0.9722 - val_loss: 0.3646 - val_accuracy: 0.9167\n","Epoch 63/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2965 - accuracy: 0.9660 - val_loss: 0.3264 - val_accuracy: 0.9444\n","Epoch 64/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2876 - accuracy: 0.9753 - val_loss: 0.4522 - val_accuracy: 0.8194\n","Epoch 65/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2740 - accuracy: 0.9877 - val_loss: 0.3271 - val_accuracy: 0.9583\n","Epoch 66/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2805 - accuracy: 0.9753 - val_loss: 0.3342 - val_accuracy: 0.9306\n","Epoch 67/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2684 - accuracy: 0.9830 - val_loss: 0.2996 - val_accuracy: 0.9583\n","Epoch 68/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2664 - accuracy: 0.9861 - val_loss: 0.5152 - val_accuracy: 0.7778\n","Epoch 69/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2695 - accuracy: 0.9815 - val_loss: 0.3159 - val_accuracy: 0.9583\n","Epoch 70/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2582 - accuracy: 0.9907 - val_loss: 0.3281 - val_accuracy: 0.9306\n","Epoch 71/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2589 - accuracy: 0.9861 - val_loss: 0.3211 - val_accuracy: 0.9167\n","Epoch 72/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2629 - accuracy: 0.9784 - val_loss: 0.3627 - val_accuracy: 0.9028\n","Epoch 73/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2578 - accuracy: 0.9830 - val_loss: 0.3356 - val_accuracy: 0.9306\n","Epoch 74/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2464 - accuracy: 0.9907 - val_loss: 0.3046 - val_accuracy: 0.9583\n","Epoch 75/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2501 - accuracy: 0.9846 - val_loss: 0.2990 - val_accuracy: 0.9583\n","Epoch 76/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2491 - accuracy: 0.9799 - val_loss: 0.4675 - val_accuracy: 0.7917\n","Epoch 77/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2512 - accuracy: 0.9815 - val_loss: 0.3389 - val_accuracy: 0.9167\n","Epoch 78/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2394 - accuracy: 0.9877 - val_loss: 0.3312 - val_accuracy: 0.8889\n","Epoch 79/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2333 - accuracy: 0.9923 - val_loss: 0.4744 - val_accuracy: 0.7917\n","Epoch 80/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2276 - accuracy: 0.9954 - val_loss: 0.3256 - val_accuracy: 0.9028\n","Epoch 81/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2279 - accuracy: 0.9938 - val_loss: 0.3149 - val_accuracy: 0.9306\n","Epoch 82/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2393 - accuracy: 0.9799 - val_loss: 0.2987 - val_accuracy: 0.9306\n","Epoch 83/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2297 - accuracy: 0.9892 - val_loss: 0.3018 - val_accuracy: 0.9306\n","Epoch 84/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2305 - accuracy: 0.9892 - val_loss: 0.2678 - val_accuracy: 0.9583\n","Epoch 85/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2264 - accuracy: 0.9846 - val_loss: 0.3057 - val_accuracy: 0.9306\n","Epoch 86/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2233 - accuracy: 0.9877 - val_loss: 0.3452 - val_accuracy: 0.8889\n","Epoch 87/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2560 - accuracy: 0.9568 - val_loss: 0.3651 - val_accuracy: 0.8889\n","Epoch 88/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2274 - accuracy: 0.9830 - val_loss: 0.3109 - val_accuracy: 0.9167\n","Epoch 89/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2117 - accuracy: 0.9954 - val_loss: 0.2838 - val_accuracy: 0.9444\n","Epoch 90/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2176 - accuracy: 0.9907 - val_loss: 0.3134 - val_accuracy: 0.9028\n","Epoch 91/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2094 - accuracy: 0.9923 - val_loss: 0.2594 - val_accuracy: 0.9583\n","Epoch 92/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2030 - accuracy: 0.9954 - val_loss: 0.2272 - val_accuracy: 0.9722\n","Epoch 93/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2029 - accuracy: 0.9923 - val_loss: 0.2559 - val_accuracy: 0.9583\n","Epoch 94/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2028 - accuracy: 0.9923 - val_loss: 0.3536 - val_accuracy: 0.8889\n","Epoch 95/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.1960 - accuracy: 0.9954 - val_loss: 0.3169 - val_accuracy: 0.9028\n","Epoch 96/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.1976 - accuracy: 0.9938 - val_loss: 0.2708 - val_accuracy: 0.9444\n","Epoch 97/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2072 - accuracy: 0.9861 - val_loss: 0.3488 - val_accuracy: 0.8889\n","Epoch 98/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2159 - accuracy: 0.9830 - val_loss: 0.3037 - val_accuracy: 0.9167\n","Epoch 99/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.1982 - accuracy: 0.9923 - val_loss: 0.3076 - val_accuracy: 0.9028\n","Epoch 100/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.1914 - accuracy: 0.9938 - val_loss: 0.2882 - val_accuracy: 0.9167\n","3/3 [==============================] - 0s 11ms/step - loss: 0.3884 - accuracy: 0.8500\n","[0.38838785886764526, 0.8500000238418579]\n","0.84\n","WARNING:tensorflow:Layer LSTM_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer LSTM_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Results for fold 6\n","Epoch 1/100\n","65/65 [==============================] - 9s 44ms/step - loss: 0.8509 - accuracy: 0.5340 - val_loss: 0.8398 - val_accuracy: 0.5278\n","Epoch 2/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.8301 - accuracy: 0.6157 - val_loss: 0.8203 - val_accuracy: 0.5417\n","Epoch 3/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.8117 - accuracy: 0.6142 - val_loss: 0.8031 - val_accuracy: 0.5556\n","Epoch 4/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.7955 - accuracy: 0.6373 - val_loss: 0.7869 - val_accuracy: 0.6944\n","Epoch 5/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.7802 - accuracy: 0.6836 - val_loss: 0.7702 - val_accuracy: 0.7083\n","Epoch 6/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.7648 - accuracy: 0.6698 - val_loss: 0.7513 - val_accuracy: 0.6389\n","Epoch 7/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.7319 - accuracy: 0.6790 - val_loss: 0.7532 - val_accuracy: 0.5417\n","Epoch 8/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.6899 - accuracy: 0.7130 - val_loss: 0.6519 - val_accuracy: 0.7639\n","Epoch 9/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.6586 - accuracy: 0.7500 - val_loss: 0.6169 - val_accuracy: 0.7778\n","Epoch 10/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.6562 - accuracy: 0.7346 - val_loss: 0.6045 - val_accuracy: 0.8194\n","Epoch 11/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.6158 - accuracy: 0.7901 - val_loss: 0.5956 - val_accuracy: 0.8194\n","Epoch 12/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.6076 - accuracy: 0.8009 - val_loss: 0.5889 - val_accuracy: 0.8194\n","Epoch 13/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.5879 - accuracy: 0.8194 - val_loss: 0.5989 - val_accuracy: 0.7778\n","Epoch 14/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.5760 - accuracy: 0.8318 - val_loss: 0.5682 - val_accuracy: 0.8611\n","Epoch 15/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.5709 - accuracy: 0.8210 - val_loss: 0.5571 - val_accuracy: 0.8194\n","Epoch 16/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.5474 - accuracy: 0.8565 - val_loss: 0.5505 - val_accuracy: 0.8472\n","Epoch 17/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.5329 - accuracy: 0.8611 - val_loss: 0.5466 - val_accuracy: 0.8194\n","Epoch 18/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.5293 - accuracy: 0.8627 - val_loss: 0.5345 - val_accuracy: 0.8611\n","Epoch 19/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.5245 - accuracy: 0.8688 - val_loss: 0.5175 - val_accuracy: 0.8889\n","Epoch 20/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.5037 - accuracy: 0.8765 - val_loss: 0.5693 - val_accuracy: 0.7639\n","Epoch 21/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4950 - accuracy: 0.8951 - val_loss: 0.5385 - val_accuracy: 0.8194\n","Epoch 22/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4958 - accuracy: 0.8781 - val_loss: 0.4950 - val_accuracy: 0.8889\n","Epoch 23/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.4848 - accuracy: 0.8997 - val_loss: 0.5053 - val_accuracy: 0.8611\n","Epoch 24/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4710 - accuracy: 0.9074 - val_loss: 0.5000 - val_accuracy: 0.8750\n","Epoch 25/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4786 - accuracy: 0.8858 - val_loss: 0.4917 - val_accuracy: 0.8889\n","Epoch 26/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4741 - accuracy: 0.8781 - val_loss: 0.4601 - val_accuracy: 0.9167\n","Epoch 27/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4438 - accuracy: 0.9244 - val_loss: 0.4478 - val_accuracy: 0.9306\n","Epoch 28/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4487 - accuracy: 0.9105 - val_loss: 0.4509 - val_accuracy: 0.8889\n","Epoch 29/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.4427 - accuracy: 0.9198 - val_loss: 0.4526 - val_accuracy: 0.8889\n","Epoch 30/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4263 - accuracy: 0.9275 - val_loss: 0.4505 - val_accuracy: 0.9028\n","Epoch 31/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4240 - accuracy: 0.9244 - val_loss: 0.5072 - val_accuracy: 0.8472\n","Epoch 32/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.4197 - accuracy: 0.9228 - val_loss: 0.4673 - val_accuracy: 0.8889\n","Epoch 33/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4134 - accuracy: 0.9306 - val_loss: 0.4205 - val_accuracy: 0.9306\n","Epoch 34/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3931 - accuracy: 0.9491 - val_loss: 0.4257 - val_accuracy: 0.9306\n","Epoch 35/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3963 - accuracy: 0.9429 - val_loss: 0.4224 - val_accuracy: 0.9167\n","Epoch 36/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3981 - accuracy: 0.9398 - val_loss: 0.4261 - val_accuracy: 0.9167\n","Epoch 37/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3914 - accuracy: 0.9414 - val_loss: 0.4415 - val_accuracy: 0.9028\n","Epoch 38/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3955 - accuracy: 0.9398 - val_loss: 0.4307 - val_accuracy: 0.8750\n","Epoch 39/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3847 - accuracy: 0.9491 - val_loss: 0.4228 - val_accuracy: 0.9028\n","Epoch 40/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3774 - accuracy: 0.9444 - val_loss: 0.4120 - val_accuracy: 0.9167\n","Epoch 41/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3721 - accuracy: 0.9506 - val_loss: 0.4096 - val_accuracy: 0.9028\n","Epoch 42/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3677 - accuracy: 0.9537 - val_loss: 0.3892 - val_accuracy: 0.9167\n","Epoch 43/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3451 - accuracy: 0.9691 - val_loss: 0.4003 - val_accuracy: 0.9028\n","Epoch 44/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3638 - accuracy: 0.9444 - val_loss: 0.4023 - val_accuracy: 0.9028\n","Epoch 45/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3496 - accuracy: 0.9630 - val_loss: 0.3935 - val_accuracy: 0.9306\n","Epoch 46/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3394 - accuracy: 0.9630 - val_loss: 0.4020 - val_accuracy: 0.9028\n","Epoch 47/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3328 - accuracy: 0.9753 - val_loss: 0.4260 - val_accuracy: 0.8472\n","Epoch 48/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3316 - accuracy: 0.9691 - val_loss: 0.3681 - val_accuracy: 0.9306\n","Epoch 49/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3282 - accuracy: 0.9660 - val_loss: 0.3810 - val_accuracy: 0.9306\n","Epoch 50/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3160 - accuracy: 0.9738 - val_loss: 0.3684 - val_accuracy: 0.9444\n","Epoch 51/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3217 - accuracy: 0.9660 - val_loss: 0.3423 - val_accuracy: 0.9583\n","Epoch 52/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3257 - accuracy: 0.9676 - val_loss: 0.4061 - val_accuracy: 0.8611\n","Epoch 53/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3088 - accuracy: 0.9738 - val_loss: 0.3652 - val_accuracy: 0.9306\n","Epoch 54/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3083 - accuracy: 0.9722 - val_loss: 0.3389 - val_accuracy: 0.9444\n","Epoch 55/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2992 - accuracy: 0.9815 - val_loss: 0.3443 - val_accuracy: 0.9444\n","Epoch 56/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3072 - accuracy: 0.9676 - val_loss: 0.3437 - val_accuracy: 0.9583\n","Epoch 57/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3010 - accuracy: 0.9753 - val_loss: 0.3533 - val_accuracy: 0.9444\n","Epoch 58/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3149 - accuracy: 0.9599 - val_loss: 0.4434 - val_accuracy: 0.8194\n","Epoch 59/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3033 - accuracy: 0.9645 - val_loss: 0.3300 - val_accuracy: 0.9583\n","Epoch 60/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2861 - accuracy: 0.9861 - val_loss: 0.3459 - val_accuracy: 0.9167\n","Epoch 61/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3014 - accuracy: 0.9630 - val_loss: 0.3571 - val_accuracy: 0.9028\n","Epoch 62/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2834 - accuracy: 0.9815 - val_loss: 0.3789 - val_accuracy: 0.9028\n","Epoch 63/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2790 - accuracy: 0.9799 - val_loss: 0.3983 - val_accuracy: 0.8889\n","Epoch 64/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2825 - accuracy: 0.9784 - val_loss: 0.3158 - val_accuracy: 0.9583\n","Epoch 65/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2632 - accuracy: 0.9907 - val_loss: 0.3528 - val_accuracy: 0.9167\n","Epoch 66/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2669 - accuracy: 0.9846 - val_loss: 0.3428 - val_accuracy: 0.9306\n","Epoch 67/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2632 - accuracy: 0.9830 - val_loss: 0.3238 - val_accuracy: 0.9444\n","Epoch 68/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2669 - accuracy: 0.9799 - val_loss: 0.3337 - val_accuracy: 0.9306\n","Epoch 69/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2606 - accuracy: 0.9830 - val_loss: 0.3231 - val_accuracy: 0.9306\n","Epoch 70/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2499 - accuracy: 0.9877 - val_loss: 0.3122 - val_accuracy: 0.9306\n","Epoch 71/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2531 - accuracy: 0.9877 - val_loss: 0.3872 - val_accuracy: 0.8750\n","Epoch 72/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2484 - accuracy: 0.9907 - val_loss: 0.2950 - val_accuracy: 0.9444\n","Epoch 73/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2474 - accuracy: 0.9861 - val_loss: 0.3369 - val_accuracy: 0.9167\n","Epoch 74/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2461 - accuracy: 0.9892 - val_loss: 0.3194 - val_accuracy: 0.9306\n","Epoch 75/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2359 - accuracy: 0.9923 - val_loss: 0.3038 - val_accuracy: 0.9444\n","Epoch 76/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2433 - accuracy: 0.9830 - val_loss: 0.3127 - val_accuracy: 0.9444\n","Epoch 77/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2439 - accuracy: 0.9846 - val_loss: 0.2941 - val_accuracy: 0.9444\n","Epoch 78/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2466 - accuracy: 0.9799 - val_loss: 0.3342 - val_accuracy: 0.9167\n","Epoch 79/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2409 - accuracy: 0.9846 - val_loss: 0.3132 - val_accuracy: 0.9306\n","Epoch 80/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2343 - accuracy: 0.9861 - val_loss: 0.3671 - val_accuracy: 0.8750\n","Epoch 81/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2271 - accuracy: 0.9877 - val_loss: 0.3096 - val_accuracy: 0.9306\n","Epoch 82/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2195 - accuracy: 0.9954 - val_loss: 0.3368 - val_accuracy: 0.8889\n","Epoch 83/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2238 - accuracy: 0.9907 - val_loss: 0.3460 - val_accuracy: 0.9028\n","Epoch 84/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2300 - accuracy: 0.9846 - val_loss: 0.2963 - val_accuracy: 0.9306\n","Epoch 85/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2248 - accuracy: 0.9830 - val_loss: 0.3830 - val_accuracy: 0.8750\n","Epoch 86/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2141 - accuracy: 0.9907 - val_loss: 0.3466 - val_accuracy: 0.9028\n","Epoch 87/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2099 - accuracy: 0.9938 - val_loss: 0.3810 - val_accuracy: 0.8750\n","Epoch 88/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2105 - accuracy: 0.9923 - val_loss: 0.3253 - val_accuracy: 0.9167\n","Epoch 89/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.2400 - accuracy: 0.9738 - val_loss: 0.2702 - val_accuracy: 0.9306\n","Epoch 90/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2172 - accuracy: 0.9877 - val_loss: 0.3090 - val_accuracy: 0.9167\n","Epoch 91/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2181 - accuracy: 0.9830 - val_loss: 0.2721 - val_accuracy: 0.9583\n","Epoch 92/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.2023 - accuracy: 0.9938 - val_loss: 0.2822 - val_accuracy: 0.9444\n","Epoch 93/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2033 - accuracy: 0.9923 - val_loss: 0.3134 - val_accuracy: 0.9167\n","Epoch 94/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2004 - accuracy: 0.9907 - val_loss: 0.2762 - val_accuracy: 0.9444\n","Epoch 95/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2060 - accuracy: 0.9846 - val_loss: 0.3087 - val_accuracy: 0.9028\n","Epoch 96/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2039 - accuracy: 0.9861 - val_loss: 0.2603 - val_accuracy: 0.9583\n","Epoch 97/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.1929 - accuracy: 0.9954 - val_loss: 0.2784 - val_accuracy: 0.9167\n","Epoch 98/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.1850 - accuracy: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.9444\n","Epoch 99/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.1844 - accuracy: 0.9969 - val_loss: 0.2941 - val_accuracy: 0.9306\n","Epoch 100/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.1872 - accuracy: 0.9923 - val_loss: 0.2657 - val_accuracy: 0.9444\n","3/3 [==============================] - 0s 11ms/step - loss: 0.3947 - accuracy: 0.8500\n","[0.39469456672668457, 0.8500000238418579]\n","0.8420013166556946\n","WARNING:tensorflow:Layer LSTM_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer LSTM_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Results for fold 7\n","Epoch 1/100\n","65/65 [==============================] - 8s 38ms/step - loss: 0.8517 - accuracy: 0.4769 - val_loss: 0.8412 - val_accuracy: 0.6111\n","Epoch 2/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.8318 - accuracy: 0.5833 - val_loss: 0.8224 - val_accuracy: 0.6389\n","Epoch 3/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.8145 - accuracy: 0.6559 - val_loss: 0.8055 - val_accuracy: 0.6250\n","Epoch 4/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.7988 - accuracy: 0.5895 - val_loss: 0.7896 - val_accuracy: 0.6389\n","Epoch 5/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.7830 - accuracy: 0.6991 - val_loss: 0.7753 - val_accuracy: 0.6528\n","Epoch 6/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.7696 - accuracy: 0.6605 - val_loss: 0.7572 - val_accuracy: 0.6250\n","Epoch 7/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.7442 - accuracy: 0.6960 - val_loss: 0.7236 - val_accuracy: 0.7222\n","Epoch 8/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.7041 - accuracy: 0.7515 - val_loss: 0.6874 - val_accuracy: 0.7222\n","Epoch 9/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.6630 - accuracy: 0.7886 - val_loss: 0.6653 - val_accuracy: 0.7500\n","Epoch 10/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.6473 - accuracy: 0.7762 - val_loss: 0.6958 - val_accuracy: 0.6389\n","Epoch 11/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.6301 - accuracy: 0.7840 - val_loss: 0.6052 - val_accuracy: 0.8333\n","Epoch 12/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.5988 - accuracy: 0.8287 - val_loss: 0.6058 - val_accuracy: 0.7778\n","Epoch 13/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.5755 - accuracy: 0.8627 - val_loss: 0.5927 - val_accuracy: 0.8056\n","Epoch 14/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.5606 - accuracy: 0.8596 - val_loss: 0.5757 - val_accuracy: 0.8472\n","Epoch 15/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.5307 - accuracy: 0.8951 - val_loss: 0.5497 - val_accuracy: 0.8750\n","Epoch 16/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.5283 - accuracy: 0.8920 - val_loss: 0.5444 - val_accuracy: 0.8472\n","Epoch 17/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.5105 - accuracy: 0.9059 - val_loss: 0.5454 - val_accuracy: 0.8472\n","Epoch 18/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.5066 - accuracy: 0.8997 - val_loss: 0.5412 - val_accuracy: 0.8611\n","Epoch 19/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.5119 - accuracy: 0.8781 - val_loss: 0.5597 - val_accuracy: 0.8333\n","Epoch 20/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.4868 - accuracy: 0.9090 - val_loss: 0.5353 - val_accuracy: 0.8333\n","Epoch 21/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.4978 - accuracy: 0.8843 - val_loss: 0.5375 - val_accuracy: 0.8333\n","Epoch 22/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.4699 - accuracy: 0.9259 - val_loss: 0.6059 - val_accuracy: 0.7222\n","Epoch 23/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.4633 - accuracy: 0.9244 - val_loss: 0.5100 - val_accuracy: 0.8472\n","Epoch 24/100\n","65/65 [==============================] - 2s 25ms/step - loss: 0.4581 - accuracy: 0.9259 - val_loss: 0.5191 - val_accuracy: 0.8333\n","Epoch 25/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.4688 - accuracy: 0.9136 - val_loss: 0.5083 - val_accuracy: 0.8472\n","Epoch 26/100\n","65/65 [==============================] - 2s 24ms/step - loss: 0.4338 - accuracy: 0.9383 - val_loss: 0.4796 - val_accuracy: 0.9028\n","Epoch 27/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4432 - accuracy: 0.9275 - val_loss: 0.4686 - val_accuracy: 0.9028\n","Epoch 28/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.4257 - accuracy: 0.9383 - val_loss: 0.5056 - val_accuracy: 0.8194\n","Epoch 29/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.4208 - accuracy: 0.9414 - val_loss: 0.4563 - val_accuracy: 0.9028\n","Epoch 30/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4029 - accuracy: 0.9630 - val_loss: 0.4814 - val_accuracy: 0.8472\n","Epoch 31/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.4056 - accuracy: 0.9522 - val_loss: 0.4443 - val_accuracy: 0.9167\n","Epoch 32/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4253 - accuracy: 0.9275 - val_loss: 0.5149 - val_accuracy: 0.7778\n","Epoch 33/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.4044 - accuracy: 0.9475 - val_loss: 0.4513 - val_accuracy: 0.8889\n","Epoch 34/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.4170 - accuracy: 0.9259 - val_loss: 0.4593 - val_accuracy: 0.8611\n","Epoch 35/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.3854 - accuracy: 0.9645 - val_loss: 0.4469 - val_accuracy: 0.8889\n","Epoch 36/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3817 - accuracy: 0.9691 - val_loss: 0.4666 - val_accuracy: 0.8750\n","Epoch 37/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3797 - accuracy: 0.9568 - val_loss: 0.4630 - val_accuracy: 0.8611\n","Epoch 38/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.3839 - accuracy: 0.9614 - val_loss: 0.4659 - val_accuracy: 0.8611\n","Epoch 39/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3767 - accuracy: 0.9583 - val_loss: 0.4304 - val_accuracy: 0.9028\n","Epoch 40/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.3658 - accuracy: 0.9676 - val_loss: 0.4447 - val_accuracy: 0.8750\n","Epoch 41/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3616 - accuracy: 0.9676 - val_loss: 0.4395 - val_accuracy: 0.8889\n","Epoch 42/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.3626 - accuracy: 0.9660 - val_loss: 0.5369 - val_accuracy: 0.8056\n","Epoch 43/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3537 - accuracy: 0.9722 - val_loss: 0.5003 - val_accuracy: 0.8194\n","Epoch 44/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3710 - accuracy: 0.9522 - val_loss: 0.4808 - val_accuracy: 0.8194\n","Epoch 45/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3546 - accuracy: 0.9583 - val_loss: 0.4846 - val_accuracy: 0.8333\n","Epoch 46/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3302 - accuracy: 0.9846 - val_loss: 0.4350 - val_accuracy: 0.8889\n","Epoch 47/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3366 - accuracy: 0.9722 - val_loss: 0.4183 - val_accuracy: 0.9028\n","Epoch 48/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3398 - accuracy: 0.9660 - val_loss: 0.4472 - val_accuracy: 0.8611\n","Epoch 49/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3429 - accuracy: 0.9645 - val_loss: 0.4643 - val_accuracy: 0.8472\n","Epoch 50/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3214 - accuracy: 0.9784 - val_loss: 0.4123 - val_accuracy: 0.8889\n","Epoch 51/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3158 - accuracy: 0.9830 - val_loss: 0.4155 - val_accuracy: 0.8889\n","Epoch 52/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3257 - accuracy: 0.9722 - val_loss: 0.4456 - val_accuracy: 0.8750\n","Epoch 53/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.3497 - accuracy: 0.9444 - val_loss: 0.4161 - val_accuracy: 0.9028\n","Epoch 54/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3082 - accuracy: 0.9877 - val_loss: 0.4139 - val_accuracy: 0.8889\n","Epoch 55/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3092 - accuracy: 0.9799 - val_loss: 0.5011 - val_accuracy: 0.7917\n","Epoch 56/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3287 - accuracy: 0.9583 - val_loss: 0.4173 - val_accuracy: 0.8889\n","Epoch 57/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3124 - accuracy: 0.9707 - val_loss: 0.3989 - val_accuracy: 0.8889\n","Epoch 58/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2963 - accuracy: 0.9861 - val_loss: 0.3769 - val_accuracy: 0.9167\n","Epoch 59/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3003 - accuracy: 0.9815 - val_loss: 0.4238 - val_accuracy: 0.8611\n","Epoch 60/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3320 - accuracy: 0.9475 - val_loss: 0.4278 - val_accuracy: 0.8611\n","Epoch 61/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2909 - accuracy: 0.9846 - val_loss: 0.4087 - val_accuracy: 0.8750\n","Epoch 62/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2980 - accuracy: 0.9753 - val_loss: 0.3969 - val_accuracy: 0.8889\n","Epoch 63/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2906 - accuracy: 0.9830 - val_loss: 0.3689 - val_accuracy: 0.9028\n","Epoch 64/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2886 - accuracy: 0.9830 - val_loss: 0.5112 - val_accuracy: 0.8056\n","Epoch 65/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2853 - accuracy: 0.9815 - val_loss: 0.3618 - val_accuracy: 0.9167\n","Epoch 66/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.2869 - accuracy: 0.9753 - val_loss: 0.3655 - val_accuracy: 0.9167\n","Epoch 67/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2702 - accuracy: 0.9907 - val_loss: 0.3992 - val_accuracy: 0.8750\n","Epoch 68/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2765 - accuracy: 0.9830 - val_loss: 0.4002 - val_accuracy: 0.8611\n","Epoch 69/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2638 - accuracy: 0.9938 - val_loss: 0.3639 - val_accuracy: 0.9167\n","Epoch 70/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2599 - accuracy: 0.9938 - val_loss: 0.4236 - val_accuracy: 0.8472\n","Epoch 71/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2656 - accuracy: 0.9892 - val_loss: 0.3678 - val_accuracy: 0.9028\n","Epoch 72/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2590 - accuracy: 0.9861 - val_loss: 0.3698 - val_accuracy: 0.9167\n","Epoch 73/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2657 - accuracy: 0.9861 - val_loss: 0.3664 - val_accuracy: 0.9028\n","Epoch 74/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2670 - accuracy: 0.9815 - val_loss: 0.3488 - val_accuracy: 0.9306\n","Epoch 75/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2560 - accuracy: 0.9877 - val_loss: 0.3833 - val_accuracy: 0.8750\n","Epoch 76/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2661 - accuracy: 0.9769 - val_loss: 0.5229 - val_accuracy: 0.7917\n","Epoch 77/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2554 - accuracy: 0.9877 - val_loss: 0.3496 - val_accuracy: 0.9167\n","Epoch 78/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2448 - accuracy: 0.9907 - val_loss: 0.3461 - val_accuracy: 0.9167\n","Epoch 79/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2405 - accuracy: 0.9938 - val_loss: 0.3336 - val_accuracy: 0.9306\n","Epoch 80/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2404 - accuracy: 0.9923 - val_loss: 0.3695 - val_accuracy: 0.8889\n","Epoch 81/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2417 - accuracy: 0.9907 - val_loss: 0.3403 - val_accuracy: 0.9167\n","Epoch 82/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2273 - accuracy: 0.9969 - val_loss: 0.3480 - val_accuracy: 0.9028\n","Epoch 83/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2380 - accuracy: 0.9907 - val_loss: 0.3605 - val_accuracy: 0.8889\n","Epoch 84/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2448 - accuracy: 0.9799 - val_loss: 0.3596 - val_accuracy: 0.9028\n","Epoch 85/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2431 - accuracy: 0.9861 - val_loss: 0.3799 - val_accuracy: 0.8889\n","Epoch 86/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2241 - accuracy: 0.9938 - val_loss: 0.4022 - val_accuracy: 0.8750\n","Epoch 87/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2330 - accuracy: 0.9877 - val_loss: 0.3087 - val_accuracy: 0.9306\n","Epoch 88/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2371 - accuracy: 0.9830 - val_loss: 0.3234 - val_accuracy: 0.9167\n","Epoch 89/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2166 - accuracy: 0.9969 - val_loss: 0.3047 - val_accuracy: 0.9306\n","Epoch 90/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2241 - accuracy: 0.9892 - val_loss: 0.3343 - val_accuracy: 0.9028\n","Epoch 91/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2215 - accuracy: 0.9892 - val_loss: 0.3117 - val_accuracy: 0.9444\n","Epoch 92/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2232 - accuracy: 0.9892 - val_loss: 0.2771 - val_accuracy: 0.9583\n","Epoch 93/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2212 - accuracy: 0.9877 - val_loss: 0.2875 - val_accuracy: 0.9306\n","Epoch 94/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2382 - accuracy: 0.9738 - val_loss: 0.3099 - val_accuracy: 0.9306\n","Epoch 95/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2158 - accuracy: 0.9907 - val_loss: 0.3575 - val_accuracy: 0.9028\n","Epoch 96/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2066 - accuracy: 0.9954 - val_loss: 0.3033 - val_accuracy: 0.9306\n","Epoch 97/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2101 - accuracy: 0.9938 - val_loss: 0.3082 - val_accuracy: 0.9306\n","Epoch 98/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2122 - accuracy: 0.9892 - val_loss: 0.3577 - val_accuracy: 0.8750\n","Epoch 99/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.1998 - accuracy: 0.9969 - val_loss: 0.3632 - val_accuracy: 0.8889\n","Epoch 100/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2133 - accuracy: 0.9861 - val_loss: 0.3068 - val_accuracy: 0.9306\n","3/3 [==============================] - 0s 13ms/step - loss: 0.3143 - accuracy: 0.9250\n","[0.314274400472641, 0.925000011920929]\n","0.9175824175824177\n","WARNING:tensorflow:Layer LSTM_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer LSTM_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Results for fold 8\n","Epoch 1/100\n","65/65 [==============================] - 9s 45ms/step - loss: 0.8513 - accuracy: 0.5340 - val_loss: 0.8402 - val_accuracy: 0.5833\n","Epoch 2/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.8310 - accuracy: 0.6250 - val_loss: 0.8210 - val_accuracy: 0.6250\n","Epoch 3/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.8130 - accuracy: 0.6497 - val_loss: 0.8042 - val_accuracy: 0.6667\n","Epoch 4/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.7960 - accuracy: 0.7176 - val_loss: 0.7878 - val_accuracy: 0.6667\n","Epoch 5/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.7805 - accuracy: 0.6991 - val_loss: 0.7704 - val_accuracy: 0.6944\n","Epoch 6/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.7598 - accuracy: 0.7160 - val_loss: 0.7383 - val_accuracy: 0.6944\n","Epoch 7/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.7199 - accuracy: 0.6728 - val_loss: 0.6981 - val_accuracy: 0.7222\n","Epoch 8/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.6755 - accuracy: 0.7407 - val_loss: 0.6827 - val_accuracy: 0.6806\n","Epoch 9/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.6590 - accuracy: 0.7330 - val_loss: 0.6731 - val_accuracy: 0.6944\n","Epoch 10/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.6395 - accuracy: 0.7515 - val_loss: 0.6684 - val_accuracy: 0.7083\n","Epoch 11/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.6103 - accuracy: 0.7963 - val_loss: 0.6287 - val_accuracy: 0.7500\n","Epoch 12/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.5947 - accuracy: 0.8102 - val_loss: 0.6213 - val_accuracy: 0.7639\n","Epoch 13/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.5874 - accuracy: 0.8133 - val_loss: 0.6153 - val_accuracy: 0.7639\n","Epoch 14/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.5633 - accuracy: 0.8349 - val_loss: 0.6076 - val_accuracy: 0.7917\n","Epoch 15/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.5611 - accuracy: 0.8302 - val_loss: 0.6317 - val_accuracy: 0.6667\n","Epoch 16/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.5420 - accuracy: 0.8534 - val_loss: 0.5834 - val_accuracy: 0.7778\n","Epoch 17/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.5270 - accuracy: 0.8611 - val_loss: 0.5639 - val_accuracy: 0.8194\n","Epoch 18/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.5210 - accuracy: 0.8735 - val_loss: 0.5642 - val_accuracy: 0.7778\n","Epoch 19/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.5007 - accuracy: 0.8827 - val_loss: 0.5747 - val_accuracy: 0.7361\n","Epoch 20/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.5018 - accuracy: 0.8750 - val_loss: 0.5573 - val_accuracy: 0.8056\n","Epoch 21/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4997 - accuracy: 0.8781 - val_loss: 0.5249 - val_accuracy: 0.8333\n","Epoch 22/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.4804 - accuracy: 0.9028 - val_loss: 0.5295 - val_accuracy: 0.8194\n","Epoch 23/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4549 - accuracy: 0.9213 - val_loss: 0.5239 - val_accuracy: 0.8333\n","Epoch 24/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.4608 - accuracy: 0.9167 - val_loss: 0.5247 - val_accuracy: 0.8472\n","Epoch 25/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.4649 - accuracy: 0.9090 - val_loss: 0.5432 - val_accuracy: 0.8056\n","Epoch 26/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4528 - accuracy: 0.9151 - val_loss: 0.5556 - val_accuracy: 0.7500\n","Epoch 27/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.4298 - accuracy: 0.9352 - val_loss: 0.5185 - val_accuracy: 0.8194\n","Epoch 28/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4285 - accuracy: 0.9259 - val_loss: 0.5179 - val_accuracy: 0.8056\n","Epoch 29/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.4222 - accuracy: 0.9290 - val_loss: 0.5099 - val_accuracy: 0.7917\n","Epoch 30/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4192 - accuracy: 0.9414 - val_loss: 0.5166 - val_accuracy: 0.8194\n","Epoch 31/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.4049 - accuracy: 0.9568 - val_loss: 0.4986 - val_accuracy: 0.8194\n","Epoch 32/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4017 - accuracy: 0.9414 - val_loss: 0.4973 - val_accuracy: 0.8333\n","Epoch 33/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.4061 - accuracy: 0.9352 - val_loss: 0.4966 - val_accuracy: 0.8194\n","Epoch 34/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3942 - accuracy: 0.9444 - val_loss: 0.4551 - val_accuracy: 0.8472\n","Epoch 35/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3787 - accuracy: 0.9614 - val_loss: 0.4581 - val_accuracy: 0.8750\n","Epoch 36/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.3824 - accuracy: 0.9491 - val_loss: 0.5447 - val_accuracy: 0.7639\n","Epoch 37/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3725 - accuracy: 0.9583 - val_loss: 0.4397 - val_accuracy: 0.9028\n","Epoch 38/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3585 - accuracy: 0.9691 - val_loss: 0.4741 - val_accuracy: 0.8333\n","Epoch 39/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.3722 - accuracy: 0.9522 - val_loss: 0.4905 - val_accuracy: 0.8333\n","Epoch 40/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.3509 - accuracy: 0.9676 - val_loss: 0.4457 - val_accuracy: 0.8611\n","Epoch 41/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3522 - accuracy: 0.9568 - val_loss: 0.5137 - val_accuracy: 0.7778\n","Epoch 42/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.3459 - accuracy: 0.9660 - val_loss: 0.4357 - val_accuracy: 0.8750\n","Epoch 43/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.3379 - accuracy: 0.9691 - val_loss: 0.4319 - val_accuracy: 0.9028\n","Epoch 44/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.3411 - accuracy: 0.9676 - val_loss: 0.4446 - val_accuracy: 0.8611\n","Epoch 45/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3357 - accuracy: 0.9630 - val_loss: 0.4624 - val_accuracy: 0.8472\n","Epoch 46/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3276 - accuracy: 0.9738 - val_loss: 0.4572 - val_accuracy: 0.8472\n","Epoch 47/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3325 - accuracy: 0.9645 - val_loss: 0.4281 - val_accuracy: 0.8472\n","Epoch 48/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.3262 - accuracy: 0.9645 - val_loss: 0.3997 - val_accuracy: 0.8750\n","Epoch 49/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.3197 - accuracy: 0.9738 - val_loss: 0.4062 - val_accuracy: 0.8889\n","Epoch 50/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3096 - accuracy: 0.9784 - val_loss: 0.4587 - val_accuracy: 0.8333\n","Epoch 51/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3146 - accuracy: 0.9722 - val_loss: 0.4118 - val_accuracy: 0.8750\n","Epoch 52/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3145 - accuracy: 0.9660 - val_loss: 0.4533 - val_accuracy: 0.8333\n","Epoch 53/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2974 - accuracy: 0.9815 - val_loss: 0.3958 - val_accuracy: 0.9028\n","Epoch 54/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.3004 - accuracy: 0.9738 - val_loss: 0.4605 - val_accuracy: 0.8333\n","Epoch 55/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3004 - accuracy: 0.9738 - val_loss: 0.4471 - val_accuracy: 0.8472\n","Epoch 56/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3028 - accuracy: 0.9707 - val_loss: 0.4016 - val_accuracy: 0.8750\n","Epoch 57/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2972 - accuracy: 0.9691 - val_loss: 0.3875 - val_accuracy: 0.9167\n","Epoch 58/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2832 - accuracy: 0.9830 - val_loss: 0.4174 - val_accuracy: 0.8750\n","Epoch 59/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2868 - accuracy: 0.9784 - val_loss: 0.4508 - val_accuracy: 0.8333\n","Epoch 60/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2864 - accuracy: 0.9769 - val_loss: 0.4524 - val_accuracy: 0.8333\n","Epoch 61/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2720 - accuracy: 0.9846 - val_loss: 0.4034 - val_accuracy: 0.8750\n","Epoch 62/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2652 - accuracy: 0.9877 - val_loss: 0.3780 - val_accuracy: 0.8889\n","Epoch 63/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2726 - accuracy: 0.9830 - val_loss: 0.3731 - val_accuracy: 0.8889\n","Epoch 64/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2886 - accuracy: 0.9707 - val_loss: 0.4791 - val_accuracy: 0.7917\n","Epoch 65/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2605 - accuracy: 0.9892 - val_loss: 0.3824 - val_accuracy: 0.8889\n","Epoch 66/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2578 - accuracy: 0.9892 - val_loss: 0.4072 - val_accuracy: 0.8472\n","Epoch 67/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2573 - accuracy: 0.9861 - val_loss: 0.3985 - val_accuracy: 0.8750\n","Epoch 68/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2601 - accuracy: 0.9830 - val_loss: 0.3759 - val_accuracy: 0.8750\n","Epoch 69/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2734 - accuracy: 0.9753 - val_loss: 0.3883 - val_accuracy: 0.8611\n","Epoch 70/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2569 - accuracy: 0.9830 - val_loss: 0.4436 - val_accuracy: 0.8333\n","Epoch 71/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2564 - accuracy: 0.9830 - val_loss: 0.4012 - val_accuracy: 0.8611\n","Epoch 72/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2412 - accuracy: 0.9892 - val_loss: 0.3637 - val_accuracy: 0.8889\n","Epoch 73/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2371 - accuracy: 0.9892 - val_loss: 0.3622 - val_accuracy: 0.9028\n","Epoch 74/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2404 - accuracy: 0.9877 - val_loss: 0.3840 - val_accuracy: 0.8750\n","Epoch 75/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2296 - accuracy: 0.9907 - val_loss: 0.4069 - val_accuracy: 0.8333\n","Epoch 76/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2396 - accuracy: 0.9861 - val_loss: 0.3647 - val_accuracy: 0.8750\n","Epoch 77/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2289 - accuracy: 0.9923 - val_loss: 0.4005 - val_accuracy: 0.8750\n","Epoch 78/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2274 - accuracy: 0.9861 - val_loss: 0.3435 - val_accuracy: 0.9167\n","Epoch 79/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2376 - accuracy: 0.9815 - val_loss: 0.3541 - val_accuracy: 0.8889\n","Epoch 80/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2350 - accuracy: 0.9861 - val_loss: 0.3482 - val_accuracy: 0.9028\n","Epoch 81/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2276 - accuracy: 0.9861 - val_loss: 0.3800 - val_accuracy: 0.8750\n","Epoch 82/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2314 - accuracy: 0.9830 - val_loss: 0.4061 - val_accuracy: 0.8333\n","Epoch 83/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2199 - accuracy: 0.9907 - val_loss: 0.3699 - val_accuracy: 0.8889\n","Epoch 84/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2219 - accuracy: 0.9830 - val_loss: 0.3558 - val_accuracy: 0.8889\n","Epoch 85/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2173 - accuracy: 0.9907 - val_loss: 0.3103 - val_accuracy: 0.9306\n","Epoch 86/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2217 - accuracy: 0.9846 - val_loss: 0.3230 - val_accuracy: 0.9167\n","Epoch 87/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2095 - accuracy: 0.9938 - val_loss: 0.4484 - val_accuracy: 0.8194\n","Epoch 88/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.2181 - accuracy: 0.9907 - val_loss: 0.3774 - val_accuracy: 0.8611\n","Epoch 89/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.2092 - accuracy: 0.9877 - val_loss: 0.4135 - val_accuracy: 0.8333\n","Epoch 90/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.1983 - accuracy: 0.9969 - val_loss: 0.3891 - val_accuracy: 0.8750\n","Epoch 91/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2117 - accuracy: 0.9846 - val_loss: 0.3438 - val_accuracy: 0.8750\n","Epoch 92/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.1918 - accuracy: 0.9985 - val_loss: 0.3313 - val_accuracy: 0.9028\n","Epoch 93/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.1899 - accuracy: 0.9954 - val_loss: 0.3376 - val_accuracy: 0.8750\n","Epoch 94/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2127 - accuracy: 0.9753 - val_loss: 0.3743 - val_accuracy: 0.8611\n","Epoch 95/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2254 - accuracy: 0.9738 - val_loss: 0.3535 - val_accuracy: 0.8611\n","Epoch 96/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.1993 - accuracy: 0.9907 - val_loss: 0.4316 - val_accuracy: 0.8333\n","Epoch 97/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.1965 - accuracy: 0.9846 - val_loss: 0.3561 - val_accuracy: 0.8889\n","Epoch 98/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.1864 - accuracy: 0.9954 - val_loss: 0.3466 - val_accuracy: 0.9028\n","Epoch 99/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.1806 - accuracy: 0.9985 - val_loss: 0.3046 - val_accuracy: 0.9306\n","Epoch 100/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.1931 - accuracy: 0.9907 - val_loss: 0.3481 - val_accuracy: 0.8750\n","3/3 [==============================] - 0s 13ms/step - loss: 0.3104 - accuracy: 0.9250\n","[0.310409814119339, 0.925000011920929]\n","0.9188640973630832\n","WARNING:tensorflow:Layer LSTM_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer LSTM_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Results for fold 9\n","Epoch 1/100\n","65/65 [==============================] - 10s 49ms/step - loss: 0.8510 - accuracy: 0.5448 - val_loss: 0.8405 - val_accuracy: 0.5694\n","Epoch 2/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.8305 - accuracy: 0.6188 - val_loss: 0.8217 - val_accuracy: 0.5556\n","Epoch 3/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.8130 - accuracy: 0.6235 - val_loss: 0.8050 - val_accuracy: 0.5694\n","Epoch 4/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.7969 - accuracy: 0.6698 - val_loss: 0.7897 - val_accuracy: 0.5833\n","Epoch 5/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.7809 - accuracy: 0.6698 - val_loss: 0.7750 - val_accuracy: 0.6111\n","Epoch 6/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.7623 - accuracy: 0.6975 - val_loss: 0.7563 - val_accuracy: 0.6111\n","Epoch 7/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.7317 - accuracy: 0.7052 - val_loss: 0.7071 - val_accuracy: 0.7083\n","Epoch 8/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.6804 - accuracy: 0.7608 - val_loss: 0.6847 - val_accuracy: 0.6944\n","Epoch 9/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.6573 - accuracy: 0.7562 - val_loss: 0.6375 - val_accuracy: 0.7917\n","Epoch 10/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.6236 - accuracy: 0.8009 - val_loss: 0.6100 - val_accuracy: 0.8333\n","Epoch 11/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.5948 - accuracy: 0.8318 - val_loss: 0.6087 - val_accuracy: 0.7917\n","Epoch 12/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.5860 - accuracy: 0.8318 - val_loss: 0.6153 - val_accuracy: 0.7917\n","Epoch 13/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.5661 - accuracy: 0.8657 - val_loss: 0.5780 - val_accuracy: 0.8611\n","Epoch 14/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.5595 - accuracy: 0.8503 - val_loss: 0.5665 - val_accuracy: 0.8472\n","Epoch 15/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.5561 - accuracy: 0.8534 - val_loss: 0.5545 - val_accuracy: 0.8472\n","Epoch 16/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.5342 - accuracy: 0.8812 - val_loss: 0.5322 - val_accuracy: 0.8889\n","Epoch 17/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.5267 - accuracy: 0.8935 - val_loss: 0.5223 - val_accuracy: 0.8750\n","Epoch 18/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.5166 - accuracy: 0.8889 - val_loss: 0.5226 - val_accuracy: 0.8889\n","Epoch 19/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.5146 - accuracy: 0.8889 - val_loss: 0.5091 - val_accuracy: 0.8889\n","Epoch 20/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4853 - accuracy: 0.9259 - val_loss: 0.5311 - val_accuracy: 0.8472\n","Epoch 21/100\n","65/65 [==============================] - 2s 27ms/step - loss: 0.4827 - accuracy: 0.9213 - val_loss: 0.5128 - val_accuracy: 0.8889\n","Epoch 22/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.4786 - accuracy: 0.9228 - val_loss: 0.5358 - val_accuracy: 0.8194\n","Epoch 23/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.4784 - accuracy: 0.9198 - val_loss: 0.5046 - val_accuracy: 0.8611\n","Epoch 24/100\n","65/65 [==============================] - 2s 26ms/step - loss: 0.4613 - accuracy: 0.9367 - val_loss: 0.5057 - val_accuracy: 0.8611\n","Epoch 25/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.4572 - accuracy: 0.9290 - val_loss: 0.5252 - val_accuracy: 0.8333\n","Epoch 26/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4635 - accuracy: 0.9244 - val_loss: 0.5122 - val_accuracy: 0.8333\n","Epoch 27/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.4557 - accuracy: 0.9275 - val_loss: 0.4667 - val_accuracy: 0.9167\n","Epoch 28/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4344 - accuracy: 0.9568 - val_loss: 0.4605 - val_accuracy: 0.9028\n","Epoch 29/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4493 - accuracy: 0.9259 - val_loss: 0.4410 - val_accuracy: 0.9444\n","Epoch 30/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4318 - accuracy: 0.9444 - val_loss: 0.4648 - val_accuracy: 0.8889\n","Epoch 31/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.4276 - accuracy: 0.9444 - val_loss: 0.4468 - val_accuracy: 0.9306\n","Epoch 32/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4142 - accuracy: 0.9583 - val_loss: 0.4295 - val_accuracy: 0.9444\n","Epoch 33/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4108 - accuracy: 0.9568 - val_loss: 0.4470 - val_accuracy: 0.9167\n","Epoch 34/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4311 - accuracy: 0.9275 - val_loss: 0.4776 - val_accuracy: 0.8889\n","Epoch 35/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.4016 - accuracy: 0.9583 - val_loss: 0.4404 - val_accuracy: 0.9306\n","Epoch 36/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.4002 - accuracy: 0.9583 - val_loss: 0.4251 - val_accuracy: 0.9306\n","Epoch 37/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4041 - accuracy: 0.9429 - val_loss: 0.4291 - val_accuracy: 0.9306\n","Epoch 38/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.4040 - accuracy: 0.9475 - val_loss: 0.4280 - val_accuracy: 0.9306\n","Epoch 39/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3919 - accuracy: 0.9552 - val_loss: 0.4387 - val_accuracy: 0.9167\n","Epoch 40/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3827 - accuracy: 0.9676 - val_loss: 0.4032 - val_accuracy: 0.9306\n","Epoch 41/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3940 - accuracy: 0.9444 - val_loss: 0.4313 - val_accuracy: 0.9028\n","Epoch 42/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3824 - accuracy: 0.9552 - val_loss: 0.4088 - val_accuracy: 0.9306\n","Epoch 43/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.3733 - accuracy: 0.9630 - val_loss: 0.4322 - val_accuracy: 0.8889\n","Epoch 44/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.3673 - accuracy: 0.9707 - val_loss: 0.4128 - val_accuracy: 0.9306\n","Epoch 45/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.3569 - accuracy: 0.9769 - val_loss: 0.3930 - val_accuracy: 0.9444\n","Epoch 46/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3551 - accuracy: 0.9753 - val_loss: 0.4411 - val_accuracy: 0.8889\n","Epoch 47/100\n","65/65 [==============================] - 2s 38ms/step - loss: 0.3537 - accuracy: 0.9707 - val_loss: 0.4248 - val_accuracy: 0.8889\n","Epoch 48/100\n","65/65 [==============================] - 3s 39ms/step - loss: 0.3637 - accuracy: 0.9599 - val_loss: 0.4349 - val_accuracy: 0.8750\n","Epoch 49/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3505 - accuracy: 0.9691 - val_loss: 0.3780 - val_accuracy: 0.9444\n","Epoch 50/100\n","65/65 [==============================] - 2s 28ms/step - loss: 0.3454 - accuracy: 0.9722 - val_loss: 0.3949 - val_accuracy: 0.9167\n","Epoch 51/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3561 - accuracy: 0.9537 - val_loss: 0.3886 - val_accuracy: 0.9444\n","Epoch 52/100\n","65/65 [==============================] - 3s 42ms/step - loss: 0.3432 - accuracy: 0.9645 - val_loss: 0.3720 - val_accuracy: 0.9306\n","Epoch 53/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.3490 - accuracy: 0.9630 - val_loss: 0.3915 - val_accuracy: 0.9167\n","Epoch 54/100\n","65/65 [==============================] - 3s 44ms/step - loss: 0.3277 - accuracy: 0.9799 - val_loss: 0.3910 - val_accuracy: 0.9167\n","Epoch 55/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3330 - accuracy: 0.9722 - val_loss: 0.3889 - val_accuracy: 0.9167\n","Epoch 56/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3367 - accuracy: 0.9676 - val_loss: 0.3478 - val_accuracy: 0.9583\n","Epoch 57/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.3206 - accuracy: 0.9830 - val_loss: 0.4290 - val_accuracy: 0.8611\n","Epoch 58/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.3250 - accuracy: 0.9722 - val_loss: 0.3900 - val_accuracy: 0.9167\n","Epoch 59/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.3185 - accuracy: 0.9738 - val_loss: 0.4310 - val_accuracy: 0.8750\n","Epoch 60/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3322 - accuracy: 0.9599 - val_loss: 0.3996 - val_accuracy: 0.8889\n","Epoch 61/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3217 - accuracy: 0.9707 - val_loss: 0.3897 - val_accuracy: 0.9167\n","Epoch 62/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.3007 - accuracy: 0.9861 - val_loss: 0.3576 - val_accuracy: 0.9444\n","Epoch 63/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.3062 - accuracy: 0.9769 - val_loss: 0.3827 - val_accuracy: 0.9306\n","Epoch 64/100\n","65/65 [==============================] - 2s 29ms/step - loss: 0.3086 - accuracy: 0.9784 - val_loss: 0.4709 - val_accuracy: 0.8333\n","Epoch 65/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2889 - accuracy: 0.9892 - val_loss: 0.4672 - val_accuracy: 0.8472\n","Epoch 66/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.2910 - accuracy: 0.9892 - val_loss: 0.3654 - val_accuracy: 0.9306\n","Epoch 67/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2854 - accuracy: 0.9907 - val_loss: 0.3346 - val_accuracy: 0.9583\n","Epoch 68/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2908 - accuracy: 0.9830 - val_loss: 0.3271 - val_accuracy: 0.9444\n","Epoch 69/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2831 - accuracy: 0.9846 - val_loss: 0.3358 - val_accuracy: 0.9444\n","Epoch 70/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.3153 - accuracy: 0.9568 - val_loss: 0.4874 - val_accuracy: 0.8194\n","Epoch 71/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.3114 - accuracy: 0.9599 - val_loss: 0.4404 - val_accuracy: 0.8750\n","Epoch 72/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.3034 - accuracy: 0.9645 - val_loss: 0.3458 - val_accuracy: 0.9306\n","Epoch 73/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.2838 - accuracy: 0.9799 - val_loss: 0.3935 - val_accuracy: 0.8889\n","Epoch 74/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.2959 - accuracy: 0.9676 - val_loss: 0.3809 - val_accuracy: 0.9167\n","Epoch 75/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.2853 - accuracy: 0.9738 - val_loss: 0.4522 - val_accuracy: 0.8472\n","Epoch 76/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.2706 - accuracy: 0.9861 - val_loss: 0.3116 - val_accuracy: 0.9583\n","Epoch 77/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2725 - accuracy: 0.9815 - val_loss: 0.3416 - val_accuracy: 0.9306\n","Epoch 78/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2798 - accuracy: 0.9769 - val_loss: 0.3423 - val_accuracy: 0.9306\n","Epoch 79/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2588 - accuracy: 0.9923 - val_loss: 0.3688 - val_accuracy: 0.9167\n","Epoch 80/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.2575 - accuracy: 0.9877 - val_loss: 0.3763 - val_accuracy: 0.9028\n","Epoch 81/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2726 - accuracy: 0.9769 - val_loss: 0.3227 - val_accuracy: 0.9306\n","Epoch 82/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.2585 - accuracy: 0.9861 - val_loss: 0.3178 - val_accuracy: 0.9306\n","Epoch 83/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2481 - accuracy: 0.9892 - val_loss: 0.3415 - val_accuracy: 0.9306\n","Epoch 84/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2467 - accuracy: 0.9923 - val_loss: 0.3165 - val_accuracy: 0.9444\n","Epoch 85/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.2364 - accuracy: 0.9969 - val_loss: 0.3364 - val_accuracy: 0.9306\n","Epoch 86/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.2587 - accuracy: 0.9784 - val_loss: 0.3107 - val_accuracy: 0.9444\n","Epoch 87/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2448 - accuracy: 0.9892 - val_loss: 0.3676 - val_accuracy: 0.9028\n","Epoch 88/100\n","65/65 [==============================] - 2s 38ms/step - loss: 0.2471 - accuracy: 0.9846 - val_loss: 0.3122 - val_accuracy: 0.9306\n","Epoch 89/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.2292 - accuracy: 0.9985 - val_loss: 0.3312 - val_accuracy: 0.9167\n","Epoch 90/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.2299 - accuracy: 0.9954 - val_loss: 0.3656 - val_accuracy: 0.9028\n","Epoch 91/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.2467 - accuracy: 0.9769 - val_loss: 0.3486 - val_accuracy: 0.9028\n","Epoch 92/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2602 - accuracy: 0.9707 - val_loss: 0.3930 - val_accuracy: 0.8750\n","Epoch 93/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.2290 - accuracy: 0.9892 - val_loss: 0.4004 - val_accuracy: 0.8750\n","Epoch 94/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.2395 - accuracy: 0.9799 - val_loss: 0.3174 - val_accuracy: 0.9306\n","Epoch 95/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.2313 - accuracy: 0.9861 - val_loss: 0.3561 - val_accuracy: 0.9028\n","Epoch 96/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2292 - accuracy: 0.9846 - val_loss: 0.3889 - val_accuracy: 0.8889\n","Epoch 97/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.2221 - accuracy: 0.9907 - val_loss: 0.3938 - val_accuracy: 0.8750\n","Epoch 98/100\n","65/65 [==============================] - 2s 38ms/step - loss: 0.2230 - accuracy: 0.9907 - val_loss: 0.3216 - val_accuracy: 0.9167\n","Epoch 99/100\n","65/65 [==============================] - 2s 38ms/step - loss: 0.2199 - accuracy: 0.9892 - val_loss: 0.4181 - val_accuracy: 0.8611\n","Epoch 100/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.2159 - accuracy: 0.9923 - val_loss: 0.2757 - val_accuracy: 0.9583\n","3/3 [==============================] - 0s 17ms/step - loss: 0.3881 - accuracy: 0.8625\n","[0.3880663216114044, 0.862500011920929]\n","0.8501107136773973\n","WARNING:tensorflow:Layer LSTM_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer LSTM_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Results for fold 10\n","Epoch 1/100\n","65/65 [==============================] - 10s 48ms/step - loss: 0.8514 - accuracy: 0.4892 - val_loss: 0.8405 - val_accuracy: 0.7361\n","Epoch 2/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.8311 - accuracy: 0.6327 - val_loss: 0.8208 - val_accuracy: 0.7222\n","Epoch 3/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.8132 - accuracy: 0.6466 - val_loss: 0.8026 - val_accuracy: 0.7222\n","Epoch 4/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.7970 - accuracy: 0.6636 - val_loss: 0.7865 - val_accuracy: 0.7500\n","Epoch 5/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.7824 - accuracy: 0.6497 - val_loss: 0.7684 - val_accuracy: 0.8194\n","Epoch 6/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.7636 - accuracy: 0.6852 - val_loss: 0.7337 - val_accuracy: 0.7639\n","Epoch 7/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.7289 - accuracy: 0.6883 - val_loss: 0.6846 - val_accuracy: 0.7917\n","Epoch 8/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.6950 - accuracy: 0.7330 - val_loss: 0.7290 - val_accuracy: 0.6111\n","Epoch 9/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.6754 - accuracy: 0.7454 - val_loss: 0.6538 - val_accuracy: 0.7500\n","Epoch 10/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.6464 - accuracy: 0.7824 - val_loss: 0.6423 - val_accuracy: 0.7639\n","Epoch 11/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.6317 - accuracy: 0.7716 - val_loss: 0.6361 - val_accuracy: 0.7361\n","Epoch 12/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.6036 - accuracy: 0.8117 - val_loss: 0.6328 - val_accuracy: 0.7222\n","Epoch 13/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.5914 - accuracy: 0.8164 - val_loss: 0.6369 - val_accuracy: 0.7083\n","Epoch 14/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.5742 - accuracy: 0.8333 - val_loss: 0.6647 - val_accuracy: 0.6667\n","Epoch 15/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.5704 - accuracy: 0.8287 - val_loss: 0.5478 - val_accuracy: 0.8472\n","Epoch 16/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.5424 - accuracy: 0.8549 - val_loss: 0.5965 - val_accuracy: 0.7500\n","Epoch 17/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.5339 - accuracy: 0.8719 - val_loss: 0.5316 - val_accuracy: 0.8333\n","Epoch 18/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.5245 - accuracy: 0.8580 - val_loss: 0.5645 - val_accuracy: 0.8056\n","Epoch 19/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.5086 - accuracy: 0.8781 - val_loss: 0.5834 - val_accuracy: 0.7500\n","Epoch 20/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.4807 - accuracy: 0.9290 - val_loss: 0.5105 - val_accuracy: 0.8889\n","Epoch 21/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.4800 - accuracy: 0.9167 - val_loss: 0.5079 - val_accuracy: 0.8472\n","Epoch 22/100\n","65/65 [==============================] - 2s 38ms/step - loss: 0.4668 - accuracy: 0.9213 - val_loss: 0.5194 - val_accuracy: 0.8472\n","Epoch 23/100\n","65/65 [==============================] - 3s 39ms/step - loss: 0.4810 - accuracy: 0.8904 - val_loss: 0.5516 - val_accuracy: 0.8056\n","Epoch 24/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.4667 - accuracy: 0.9059 - val_loss: 0.4829 - val_accuracy: 0.9028\n","Epoch 25/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.4545 - accuracy: 0.9228 - val_loss: 0.5163 - val_accuracy: 0.8333\n","Epoch 26/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.4416 - accuracy: 0.9228 - val_loss: 0.4801 - val_accuracy: 0.8889\n","Epoch 27/100\n","65/65 [==============================] - 2s 34ms/step - loss: 0.4437 - accuracy: 0.9105 - val_loss: 0.5080 - val_accuracy: 0.8472\n","Epoch 28/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.4103 - accuracy: 0.9537 - val_loss: 0.4810 - val_accuracy: 0.8889\n","Epoch 29/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.4269 - accuracy: 0.9321 - val_loss: 0.4906 - val_accuracy: 0.8611\n","Epoch 30/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.4155 - accuracy: 0.9383 - val_loss: 0.4584 - val_accuracy: 0.8750\n","Epoch 31/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.4098 - accuracy: 0.9414 - val_loss: 0.4718 - val_accuracy: 0.8750\n","Epoch 32/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.4031 - accuracy: 0.9383 - val_loss: 0.5597 - val_accuracy: 0.7500\n","Epoch 33/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.3900 - accuracy: 0.9491 - val_loss: 0.4475 - val_accuracy: 0.8889\n","Epoch 34/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.3859 - accuracy: 0.9537 - val_loss: 0.4387 - val_accuracy: 0.8750\n","Epoch 35/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.3854 - accuracy: 0.9444 - val_loss: 0.4494 - val_accuracy: 0.8889\n","Epoch 36/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.3731 - accuracy: 0.9630 - val_loss: 0.4368 - val_accuracy: 0.8889\n","Epoch 37/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.3687 - accuracy: 0.9599 - val_loss: 0.4222 - val_accuracy: 0.9028\n","Epoch 38/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.3714 - accuracy: 0.9599 - val_loss: 0.4342 - val_accuracy: 0.8889\n","Epoch 39/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.3586 - accuracy: 0.9660 - val_loss: 0.4426 - val_accuracy: 0.8889\n","Epoch 40/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.3586 - accuracy: 0.9630 - val_loss: 0.4327 - val_accuracy: 0.8889\n","Epoch 41/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.3554 - accuracy: 0.9691 - val_loss: 0.4609 - val_accuracy: 0.8472\n","Epoch 42/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.3474 - accuracy: 0.9645 - val_loss: 0.4179 - val_accuracy: 0.8889\n","Epoch 43/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.3536 - accuracy: 0.9522 - val_loss: 0.4102 - val_accuracy: 0.9028\n","Epoch 44/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.3355 - accuracy: 0.9722 - val_loss: 0.4081 - val_accuracy: 0.9028\n","Epoch 45/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.3322 - accuracy: 0.9722 - val_loss: 0.4217 - val_accuracy: 0.9028\n","Epoch 46/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.3205 - accuracy: 0.9799 - val_loss: 0.4373 - val_accuracy: 0.8611\n","Epoch 47/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.3220 - accuracy: 0.9753 - val_loss: 0.4649 - val_accuracy: 0.8333\n","Epoch 48/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.3284 - accuracy: 0.9676 - val_loss: 0.4359 - val_accuracy: 0.8750\n","Epoch 49/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.3084 - accuracy: 0.9815 - val_loss: 0.4448 - val_accuracy: 0.8750\n","Epoch 50/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.3154 - accuracy: 0.9738 - val_loss: 0.4483 - val_accuracy: 0.8333\n","Epoch 51/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.3139 - accuracy: 0.9691 - val_loss: 0.3803 - val_accuracy: 0.8889\n","Epoch 52/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.3076 - accuracy: 0.9722 - val_loss: 0.4228 - val_accuracy: 0.8750\n","Epoch 53/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.2925 - accuracy: 0.9877 - val_loss: 0.3627 - val_accuracy: 0.9028\n","Epoch 54/100\n","65/65 [==============================] - 3s 41ms/step - loss: 0.2968 - accuracy: 0.9830 - val_loss: 0.4209 - val_accuracy: 0.8750\n","Epoch 55/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.2921 - accuracy: 0.9784 - val_loss: 0.4108 - val_accuracy: 0.8750\n","Epoch 56/100\n","65/65 [==============================] - 2s 38ms/step - loss: 0.2869 - accuracy: 0.9861 - val_loss: 0.3575 - val_accuracy: 0.9306\n","Epoch 57/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.2886 - accuracy: 0.9784 - val_loss: 0.3473 - val_accuracy: 0.9444\n","Epoch 58/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.2798 - accuracy: 0.9830 - val_loss: 0.4446 - val_accuracy: 0.8472\n","Epoch 59/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.2906 - accuracy: 0.9738 - val_loss: 0.3505 - val_accuracy: 0.9444\n","Epoch 60/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2748 - accuracy: 0.9877 - val_loss: 0.3758 - val_accuracy: 0.9028\n","Epoch 61/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2713 - accuracy: 0.9846 - val_loss: 0.3360 - val_accuracy: 0.9444\n","Epoch 62/100\n","65/65 [==============================] - 3s 39ms/step - loss: 0.2773 - accuracy: 0.9753 - val_loss: 0.3689 - val_accuracy: 0.8750\n","Epoch 63/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.2738 - accuracy: 0.9830 - val_loss: 0.3547 - val_accuracy: 0.8750\n","Epoch 64/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2657 - accuracy: 0.9846 - val_loss: 0.4416 - val_accuracy: 0.8472\n","Epoch 65/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.2687 - accuracy: 0.9830 - val_loss: 0.3713 - val_accuracy: 0.8889\n","Epoch 66/100\n","65/65 [==============================] - 3s 38ms/step - loss: 0.2655 - accuracy: 0.9799 - val_loss: 0.3282 - val_accuracy: 0.9306\n","Epoch 67/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.2577 - accuracy: 0.9877 - val_loss: 0.3317 - val_accuracy: 0.9167\n","Epoch 68/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2555 - accuracy: 0.9846 - val_loss: 0.3704 - val_accuracy: 0.8889\n","Epoch 69/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2532 - accuracy: 0.9892 - val_loss: 0.4905 - val_accuracy: 0.7917\n","Epoch 70/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2579 - accuracy: 0.9830 - val_loss: 0.3923 - val_accuracy: 0.8750\n","Epoch 71/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.2494 - accuracy: 0.9846 - val_loss: 0.3875 - val_accuracy: 0.8889\n","Epoch 72/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2448 - accuracy: 0.9846 - val_loss: 0.3945 - val_accuracy: 0.8750\n","Epoch 73/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2465 - accuracy: 0.9815 - val_loss: 0.3512 - val_accuracy: 0.9028\n","Epoch 74/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.2512 - accuracy: 0.9784 - val_loss: 0.3457 - val_accuracy: 0.9028\n","Epoch 75/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2294 - accuracy: 0.9907 - val_loss: 0.3841 - val_accuracy: 0.8750\n","Epoch 76/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2317 - accuracy: 0.9892 - val_loss: 0.3356 - val_accuracy: 0.9306\n","Epoch 77/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.2416 - accuracy: 0.9815 - val_loss: 0.3164 - val_accuracy: 0.9306\n","Epoch 78/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.2315 - accuracy: 0.9861 - val_loss: 0.3551 - val_accuracy: 0.9167\n","Epoch 79/100\n","65/65 [==============================] - 2s 37ms/step - loss: 0.2320 - accuracy: 0.9861 - val_loss: 0.3251 - val_accuracy: 0.9167\n","Epoch 80/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2410 - accuracy: 0.9784 - val_loss: 0.3150 - val_accuracy: 0.9444\n","Epoch 81/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2216 - accuracy: 0.9938 - val_loss: 0.3235 - val_accuracy: 0.9306\n","Epoch 82/100\n","65/65 [==============================] - 2s 38ms/step - loss: 0.2276 - accuracy: 0.9846 - val_loss: 0.3216 - val_accuracy: 0.9306\n","Epoch 83/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2489 - accuracy: 0.9676 - val_loss: 0.3289 - val_accuracy: 0.9167\n","Epoch 84/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2292 - accuracy: 0.9830 - val_loss: 0.3149 - val_accuracy: 0.9306\n","Epoch 85/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2116 - accuracy: 0.9938 - val_loss: 0.2706 - val_accuracy: 0.9444\n","Epoch 86/100\n","65/65 [==============================] - 2s 36ms/step - loss: 0.2151 - accuracy: 0.9923 - val_loss: 0.4022 - val_accuracy: 0.8611\n","Epoch 87/100\n","65/65 [==============================] - 2s 35ms/step - loss: 0.2117 - accuracy: 0.9907 - val_loss: 0.2953 - val_accuracy: 0.9306\n","Epoch 88/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.2037 - accuracy: 0.9938 - val_loss: 0.2920 - val_accuracy: 0.9444\n","Epoch 89/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2032 - accuracy: 0.9923 - val_loss: 0.3404 - val_accuracy: 0.8750\n","Epoch 90/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2029 - accuracy: 0.9907 - val_loss: 0.3064 - val_accuracy: 0.9167\n","Epoch 91/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.2037 - accuracy: 0.9892 - val_loss: 0.3348 - val_accuracy: 0.9028\n","Epoch 92/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2054 - accuracy: 0.9861 - val_loss: 0.3400 - val_accuracy: 0.8889\n","Epoch 93/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2046 - accuracy: 0.9861 - val_loss: 0.3491 - val_accuracy: 0.8889\n","Epoch 94/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.2059 - accuracy: 0.9815 - val_loss: 0.3199 - val_accuracy: 0.8889\n","Epoch 95/100\n","65/65 [==============================] - 2s 31ms/step - loss: 0.1898 - accuracy: 0.9969 - val_loss: 0.3167 - val_accuracy: 0.9167\n","Epoch 96/100\n","65/65 [==============================] - 2s 30ms/step - loss: 0.1815 - accuracy: 0.9985 - val_loss: 0.3313 - val_accuracy: 0.8889\n","Epoch 97/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.1938 - accuracy: 0.9892 - val_loss: 0.3275 - val_accuracy: 0.8889\n","Epoch 98/100\n","65/65 [==============================] - 2s 33ms/step - loss: 0.1827 - accuracy: 0.9954 - val_loss: 0.2528 - val_accuracy: 0.9583\n","Epoch 99/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.1827 - accuracy: 0.9938 - val_loss: 0.3813 - val_accuracy: 0.8750\n","Epoch 100/100\n","65/65 [==============================] - 2s 32ms/step - loss: 0.1794 - accuracy: 0.9969 - val_loss: 0.2982 - val_accuracy: 0.8889\n","3/3 [==============================] - 0s 10ms/step - loss: 0.4299 - accuracy: 0.8375\n","[0.4299244284629822, 0.8374999761581421]\n","0.831578947368421\n"]}]},{"cell_type":"code","metadata":{"id":"rayztobJpmag","colab":{"base_uri":"https://localhost:8080/","height":706},"executionInfo":{"status":"ok","timestamp":1642522237862,"user_tz":-360,"elapsed":21,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"aa9a31fe-54d6-460a-d784-cdc7f92bf7e2"},"source":["acrc = np.array(val_res['accuracy']).mean(axis=0)\n","f1scr = np.array(val_res['f1_score']).mean(axis=0)\n","print(\"Accuracy  : {}\".format(acrc[1]))\n","print(\"F1_Score  : {}\".format(f1scr))\n","cmatrix = np.array(val_res['confusion_matrix']).mean(axis=0)\n","c_matrix = cmatrix/np.sum(cmatrix, axis=1).reshape(2,1)\n","import seaborn as sns\n","figure = plt.figure(figsize=(9, 9))\n","sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n","plt.tight_layout()\n","plt.ylabel('True label')\n","plt.xlabel('Predicted label')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy  : 0.8475000023841858\n","F1_Score  : 0.8405932998814845\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 648x648 with 2 Axes>"]},"metadata":{"needs_background":"light"}}]}]}