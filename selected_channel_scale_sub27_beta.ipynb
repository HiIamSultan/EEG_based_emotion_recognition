{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"selected_channel&scale_sub27_beta.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"mJl4myg42Jt-"},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from scipy.signal import butter, lfilter, freqz, filtfilt\n","from pywt import swt, cwt\n","import scipy.misc\n","from scipy.signal import welch\n","import tensorflow as tf\n","import keras\n","from tensorflow import keras\n","import tensorflow.keras.backend as K\n","from keras.models import Sequential,Model\n","from keras.models import Sequential \n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n","from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n","from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n","from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n","from tensorflow.keras.optimizers import Adam\n","from keras.utils import np_utils\n","from sklearn.preprocessing import StandardScaler                                                      \n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import confusion_matrix \n","from scipy import signal\n","import pickle as pkl\n","from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n","from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n","import gc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ns3s5JN97fU","executionInfo":{"status":"ok","timestamp":1632974538608,"user_tz":-360,"elapsed":20663,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"b2911182-e7ad-4aba-e150-48238bba0224"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","gc.collect()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]},{"output_type":"execute_result","data":{"text/plain":["11"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"ugvNZGZX-DO7"},"source":["input_path='/content/drive/MyDrive/data_preprocessed_python/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XIY4fiC5qCkI"},"source":["def butter_lowpass(cutoff, fs, order=5):\n","    nyq = 0.5 * fs\n","    normal_cutoff = cutoff / nyq\n","    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n","    return b, a\n","\n","\n","def butter_lowpass_filter(data, cutoff, fs, order=5):\n","    b, a = butter_lowpass(cutoff, fs, order=order)\n","    y = filtfilt(b, a, data)\n","    return y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O9LZgo2IM9N-"},"source":["from scipy.signal.lti_conversion import cont2discrete\n","const = 1e3\n","def cwt_EER(x):\n","  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n","  energy = np.square(coef)\n","  energy_each_coef_sum = sum(energy.T)\n","  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n","  probability = np.divide(energy,energy_each_coef_sum_tile)\n","  entropy = -probability*np.log(probability)\n","  EER = np.divide(energy, entropy)\n","  #EER = EER/const\n","  return EER"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cPXrZrst909d"},"source":["channel = np.array([1,3,7,8,21,22,25,26,27,30])\n","scale = len(np.arange(11, 31))\n","sampling_rate = 128\n","window_size = 256\n","skip = 32\n","channel_len = len(channel)\n","classes=3\n","order = 6\n","fs = 128      # sample rate, Hz\n","cutoff = 60  # desired cutoff frequency of the filter, Hz\n","waveletname = 'db4'\n","bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n","         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n","         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EotvnIan4d84","executionInfo":{"status":"ok","timestamp":1632976128540,"user_tz":-360,"elapsed":277764,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"cd0f457a-ccd8-4c89-e6b2-afe62eec1164"},"source":["eeg_signal = []\n","valence = []\n","arousal = []\n","dominance = []\n","signal_freq = []\n","eeg_sig = []\n","gc.collect()\n","\n","for person in range(27,28):\n","  print('Person No.' + str(person))\n","  \n","  # EEG files address\n","  if person < 10 :\n","    address = input_path+'s0'+str(person)+'.dat'\n","  else :\n","    address = input_path+'s'+str(person)+'.dat'\n","\n","  with open(address, 'rb') as file:\n","    data = pkl.load(file, encoding = 'latin1')\n","\n","  eeg = data['data']\n","  label = data['labels']\n","  \n","  # Assigning classes\n","  label[label<4] = 0\n","  label[(label>=4) & (label<6)] = 1\n","  label[(label>=6) & (label<=9)] = 2     \n","\n","  val = label.T[0] # Valence label\n","  aro = label.T[1] # Arousal label\n","  dom = label.T[2] # Dominance label\n","\n","  del data, label\n","  \n","\n","  for i in range(40): # Iterating through 40 vidoes/trials\n","\n","    sig = eeg[i]\n","    sig = sig[:32, 384:]\n","    \n","    dfs = []\n","    for j in channel:\n","      ## Dividing Alpha Band\n","      num, den = signal.butter(4, bands['beta'], 'bandpass')\n","      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n","\n","    sig = np.array(dfs)\n","    sig = sig.reshape([-1,7680])\n","    eeg_signal.append(sig)\n","  del dfs, sig, eeg\n","  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n","  gc.collect()\n","  for i in range(40):\n","    v = val[i]\n","    a = aro[i]\n","    d = dom[i]\n","    start = 0\n","    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n","    while start + window_size <=eeg_signal.shape[2]:\n","      for j in range(eeg_signal.shape[1]):\n","        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n","      valence.append(v)\n","      arousal.append(a)\n","      dominance.append(d)\n","      start += skip\n","#eeg_sig = np.array(eeg_sig)\n","gc.collect()\n","del eeg_signal\n","eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n","data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n","del eeg_sig\n","valence = np.asarray(valence, dtype = np.int8)\n","arousal = np.asarray(arousal, dtype = np.int8)\n","dominance = np.asarray(dominance, dtype = np.int8)\n","\n","print(data.shape)\n","print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n","print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n","print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n","\n","valence = np_utils.to_categorical(valence)\n","arousal = np_utils.to_categorical(arousal)\n","dominance = np_utils.to_categorical(dominance)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Person No.27\n","(9320, 200, 256, 1)\n","(9320,) (1165,) (3029,) (5126,)\n","(9320,) (2796,) (2796,) (3728,)\n","(9320,) (0,) (233,) (9087,)\n"]}]},{"cell_type":"markdown","metadata":{"id":"-VMwwMiur8kW"},"source":["# **Proposed Architecture**"]},{"cell_type":"code","metadata":{"id":"1jZC2UyIPd33"},"source":["def get_model() :\n","    input_shape = (data.shape[1],data.shape[2],1)\n","    model=Sequential()\n","    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","    model.add(Dropout(0.2))\n","    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","    model.add(Dropout(0.2))\n","    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","    model.add(Dropout(0.2))\n","    model.add(Flatten())\n","    model.add(Dense(256,activation='tanh'))\n","    model.add(Dropout(0.4))\n","    model.add(Dense(32,activation='relu'))\n","    model.add(Dropout(0.4))\n","    model.add(Dense(3,activation='softmax'))\n","    opt = keras.optimizers.Adam(learning_rate=0.001)\n","    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n","    return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RpLb7uFzTl7H","executionInfo":{"status":"ok","timestamp":1632976144716,"user_tz":-360,"elapsed":6170,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"ef71acfc-906c-4382-a1c4-977de9804f94"},"source":["model = get_model()\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 100, 128, 16)      416       \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 100, 128, 16)      64        \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 50, 64, 16)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 768)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 256)               196864    \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 32)                8224      \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 32)                0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 3)                 99        \n","=================================================================\n","Total params: 397,123\n","Trainable params: 396,899\n","Non-trainable params: 224\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZC6fgR_XrOSw","executionInfo":{"status":"ok","timestamp":1632976150068,"user_tz":-360,"elapsed":332,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"45f1a3ba-3d61-4fe2-c7fb-35ac20839da8"},"source":["batch_size = 128\n","epochs = 50\n","kfold = KFold(10, True, 1)\n","gc.collect()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["198"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"n94Q8iJ4rJsF"},"source":["# **Valence**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wHEnzkdKqgOS","executionInfo":{"status":"ok","timestamp":1632976154047,"user_tz":-360,"elapsed":706,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"aacf4b63-44ea-49b8-9b40-d109d0da486d"},"source":["#valence\n","X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n","print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"]}]},{"cell_type":"code","metadata":{"id":"8tdPOzU7rQRV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632978492352,"user_tz":-360,"elapsed":2331506,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"7c26f526-cdfc-4a9f-fa51-0a6ae72eb32a"},"source":["foldNum=0\n","model = get_model()\n","for train_index, val_index in kfold.split(X_train, Y_train):\n","  foldNum = foldNum + 1\n","  print(\"Results for fold\",foldNum)\n","  x_train, x_val = X_train[train_index], X_train[val_index]\n","  y_train, y_val = Y_train[train_index], Y_train[val_index]\n","  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n","  gc.collect() # Garbage collecter\n","  del x_train, x_val, y_train, y_val\n","  gc.collect()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Results for fold 1\n","Epoch 1/50\n","53/53 [==============================] - 37s 90ms/step - loss: 1.0136 - accuracy: 0.5173 - val_loss: 0.9539 - val_accuracy: 0.5603\n","Epoch 2/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.9688 - accuracy: 0.5386 - val_loss: 0.9486 - val_accuracy: 0.5670\n","Epoch 3/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.9617 - accuracy: 0.5458 - val_loss: 0.9138 - val_accuracy: 0.5603\n","Epoch 4/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.9443 - accuracy: 0.5539 - val_loss: 0.9282 - val_accuracy: 0.5456\n","Epoch 5/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.9297 - accuracy: 0.5560 - val_loss: 0.9125 - val_accuracy: 0.5777\n","Epoch 6/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.9194 - accuracy: 0.5672 - val_loss: 0.9728 - val_accuracy: 0.5898\n","Epoch 7/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.9167 - accuracy: 0.5785 - val_loss: 0.9556 - val_accuracy: 0.5764\n","Epoch 8/50\n","53/53 [==============================] - 4s 73ms/step - loss: 0.8960 - accuracy: 0.5873 - val_loss: 0.9257 - val_accuracy: 0.5791\n","Epoch 9/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.8842 - accuracy: 0.5994 - val_loss: 0.9880 - val_accuracy: 0.5174\n","Epoch 10/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.8747 - accuracy: 0.6037 - val_loss: 0.8963 - val_accuracy: 0.5871\n","Epoch 11/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.8611 - accuracy: 0.6100 - val_loss: 0.9889 - val_accuracy: 0.4853\n","Epoch 12/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.8456 - accuracy: 0.6200 - val_loss: 1.0034 - val_accuracy: 0.4960\n","Epoch 13/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.8429 - accuracy: 0.6221 - val_loss: 0.9625 - val_accuracy: 0.5268\n","Epoch 14/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.8322 - accuracy: 0.6185 - val_loss: 0.9300 - val_accuracy: 0.6046\n","Epoch 15/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.8096 - accuracy: 0.6404 - val_loss: 0.9003 - val_accuracy: 0.6153\n","Epoch 16/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.7947 - accuracy: 0.6462 - val_loss: 0.8678 - val_accuracy: 0.6086\n","Epoch 17/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.7765 - accuracy: 0.6544 - val_loss: 0.9453 - val_accuracy: 0.6340\n","Epoch 18/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.7541 - accuracy: 0.6665 - val_loss: 0.8498 - val_accuracy: 0.6649\n","Epoch 19/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.7608 - accuracy: 0.6692 - val_loss: 0.9345 - val_accuracy: 0.5389\n","Epoch 20/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.7314 - accuracy: 0.6721 - val_loss: 0.8413 - val_accuracy: 0.6408\n","Epoch 21/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.7026 - accuracy: 0.6988 - val_loss: 0.8625 - val_accuracy: 0.6300\n","Epoch 22/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.6919 - accuracy: 0.6988 - val_loss: 0.8343 - val_accuracy: 0.6180\n","Epoch 23/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.6706 - accuracy: 0.7100 - val_loss: 0.8586 - val_accuracy: 0.6019\n","Epoch 24/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.6392 - accuracy: 0.7265 - val_loss: 0.8696 - val_accuracy: 0.5925\n","Epoch 25/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.6101 - accuracy: 0.7402 - val_loss: 0.9769 - val_accuracy: 0.5349\n","Epoch 26/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.5986 - accuracy: 0.7481 - val_loss: 0.9506 - val_accuracy: 0.5295\n","Epoch 27/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.5838 - accuracy: 0.7550 - val_loss: 0.7910 - val_accuracy: 0.6689\n","Epoch 28/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.5643 - accuracy: 0.7668 - val_loss: 0.7979 - val_accuracy: 0.6515\n","Epoch 29/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.5875 - accuracy: 0.7528 - val_loss: 0.9788 - val_accuracy: 0.5630\n","Epoch 30/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.5361 - accuracy: 0.7793 - val_loss: 0.8661 - val_accuracy: 0.5925\n","Epoch 31/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.5155 - accuracy: 0.7909 - val_loss: 1.0926 - val_accuracy: 0.5027\n","Epoch 32/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.4962 - accuracy: 0.7975 - val_loss: 0.8480 - val_accuracy: 0.6488\n","Epoch 33/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.4856 - accuracy: 0.8055 - val_loss: 0.8848 - val_accuracy: 0.6113\n","Epoch 34/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.5121 - accuracy: 0.7854 - val_loss: 0.8372 - val_accuracy: 0.6005\n","Epoch 35/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.4901 - accuracy: 0.8043 - val_loss: 1.0222 - val_accuracy: 0.5335\n","Epoch 36/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.4240 - accuracy: 0.8308 - val_loss: 0.6707 - val_accuracy: 0.7185\n","Epoch 37/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.4035 - accuracy: 0.8413 - val_loss: 1.1138 - val_accuracy: 0.5375\n","Epoch 38/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.4118 - accuracy: 0.8404 - val_loss: 0.8574 - val_accuracy: 0.6287\n","Epoch 39/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.4029 - accuracy: 0.8393 - val_loss: 0.7359 - val_accuracy: 0.6743\n","Epoch 40/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.3629 - accuracy: 0.8607 - val_loss: 0.8817 - val_accuracy: 0.6287\n","Epoch 41/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.3605 - accuracy: 0.8617 - val_loss: 0.6816 - val_accuracy: 0.7225\n","Epoch 42/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.3577 - accuracy: 0.8665 - val_loss: 0.7764 - val_accuracy: 0.6877\n","Epoch 43/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.3674 - accuracy: 0.8566 - val_loss: 0.7054 - val_accuracy: 0.6917\n","Epoch 44/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.3377 - accuracy: 0.8696 - val_loss: 0.7740 - val_accuracy: 0.6635\n","Epoch 45/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.3222 - accuracy: 0.8799 - val_loss: 0.7570 - val_accuracy: 0.6622\n","Epoch 46/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.3004 - accuracy: 0.8861 - val_loss: 1.3425 - val_accuracy: 0.5080\n","Epoch 47/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.3203 - accuracy: 0.8763 - val_loss: 0.7538 - val_accuracy: 0.6810\n","Epoch 48/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.3273 - accuracy: 0.8756 - val_loss: 1.4979 - val_accuracy: 0.4558\n","Epoch 49/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.3153 - accuracy: 0.8826 - val_loss: 0.7593 - val_accuracy: 0.6568\n","Epoch 50/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.2616 - accuracy: 0.9049 - val_loss: 0.7721 - val_accuracy: 0.6783\n","Results for fold 2\n","Epoch 1/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.3084 - accuracy: 0.8846 - val_loss: 0.4380 - val_accuracy: 0.8445\n","Epoch 2/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.2799 - accuracy: 0.8984 - val_loss: 0.9272 - val_accuracy: 0.6367\n","Epoch 3/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.4203 - accuracy: 0.8477 - val_loss: 0.8895 - val_accuracy: 0.6113\n","Epoch 4/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.2721 - accuracy: 0.9009 - val_loss: 0.6082 - val_accuracy: 0.7440\n","Epoch 5/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.2432 - accuracy: 0.9076 - val_loss: 0.3992 - val_accuracy: 0.8485\n","Epoch 6/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.2385 - accuracy: 0.9109 - val_loss: 0.4775 - val_accuracy: 0.7962\n","Epoch 7/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.2425 - accuracy: 0.9095 - val_loss: 1.0805 - val_accuracy: 0.5456\n","Epoch 8/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.2366 - accuracy: 0.9154 - val_loss: 0.7228 - val_accuracy: 0.6957\n","Epoch 9/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.2149 - accuracy: 0.9271 - val_loss: 0.6786 - val_accuracy: 0.7440\n","Epoch 10/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.2130 - accuracy: 0.9209 - val_loss: 0.4885 - val_accuracy: 0.7909\n","Epoch 11/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.2000 - accuracy: 0.9276 - val_loss: 0.6201 - val_accuracy: 0.7761\n","Epoch 12/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.2032 - accuracy: 0.9250 - val_loss: 0.9575 - val_accuracy: 0.6542\n","Epoch 13/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1935 - accuracy: 0.9295 - val_loss: 0.5454 - val_accuracy: 0.7761\n","Epoch 14/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.1840 - accuracy: 0.9337 - val_loss: 0.8212 - val_accuracy: 0.7024\n","Epoch 15/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.2021 - accuracy: 0.9258 - val_loss: 0.9655 - val_accuracy: 0.6676\n","Epoch 16/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.2086 - accuracy: 0.9253 - val_loss: 0.5874 - val_accuracy: 0.7855\n","Epoch 17/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.1775 - accuracy: 0.9386 - val_loss: 0.9036 - val_accuracy: 0.6890\n","Epoch 18/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1889 - accuracy: 0.9317 - val_loss: 1.2830 - val_accuracy: 0.5684\n","Epoch 19/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.2170 - accuracy: 0.9238 - val_loss: 0.4111 - val_accuracy: 0.8432\n","Epoch 20/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.1622 - accuracy: 0.9435 - val_loss: 0.5228 - val_accuracy: 0.8217\n","Epoch 21/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.1731 - accuracy: 0.9370 - val_loss: 0.8874 - val_accuracy: 0.6796\n","Epoch 22/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.2070 - accuracy: 0.9253 - val_loss: 0.5550 - val_accuracy: 0.7748\n","Epoch 23/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.1970 - accuracy: 0.9307 - val_loss: 1.0564 - val_accuracy: 0.6448\n","Epoch 24/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.2299 - accuracy: 0.9221 - val_loss: 0.4147 - val_accuracy: 0.8432\n","Epoch 25/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1543 - accuracy: 0.9489 - val_loss: 0.6013 - val_accuracy: 0.7627\n","Epoch 26/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.1265 - accuracy: 0.9565 - val_loss: 0.8113 - val_accuracy: 0.7198\n","Epoch 27/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1454 - accuracy: 0.9517 - val_loss: 0.4387 - val_accuracy: 0.8472\n","Epoch 28/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1413 - accuracy: 0.9508 - val_loss: 0.5839 - val_accuracy: 0.8029\n","Epoch 29/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.1235 - accuracy: 0.9568 - val_loss: 0.8060 - val_accuracy: 0.7158\n","Epoch 30/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.1562 - accuracy: 0.9472 - val_loss: 0.5809 - val_accuracy: 0.7949\n","Epoch 31/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1453 - accuracy: 0.9513 - val_loss: 0.4802 - val_accuracy: 0.8271\n","Epoch 32/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1272 - accuracy: 0.9557 - val_loss: 0.7212 - val_accuracy: 0.7614\n","Epoch 33/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.1311 - accuracy: 0.9563 - val_loss: 0.6509 - val_accuracy: 0.7895\n","Epoch 34/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.1409 - accuracy: 0.9513 - val_loss: 0.4113 - val_accuracy: 0.8566\n","Epoch 35/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1075 - accuracy: 0.9621 - val_loss: 0.4448 - val_accuracy: 0.8499\n","Epoch 36/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1169 - accuracy: 0.9601 - val_loss: 0.5845 - val_accuracy: 0.8177\n","Epoch 37/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.1196 - accuracy: 0.9598 - val_loss: 0.7974 - val_accuracy: 0.7574\n","Epoch 38/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.1151 - accuracy: 0.9621 - val_loss: 1.0127 - val_accuracy: 0.7105\n","Epoch 39/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.1109 - accuracy: 0.9627 - val_loss: 1.0800 - val_accuracy: 0.6716\n","Epoch 40/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.1239 - accuracy: 0.9620 - val_loss: 0.5710 - val_accuracy: 0.8150\n","Epoch 41/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.1218 - accuracy: 0.9574 - val_loss: 1.4566 - val_accuracy: 0.5885\n","Epoch 42/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1445 - accuracy: 0.9529 - val_loss: 0.5494 - val_accuracy: 0.8097\n","Epoch 43/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.1117 - accuracy: 0.9644 - val_loss: 0.6670 - val_accuracy: 0.7909\n","Epoch 44/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1120 - accuracy: 0.9644 - val_loss: 0.8274 - val_accuracy: 0.7507\n","Epoch 45/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1014 - accuracy: 0.9653 - val_loss: 1.5954 - val_accuracy: 0.6273\n","Epoch 46/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.1298 - accuracy: 0.9562 - val_loss: 1.0075 - val_accuracy: 0.6542\n","Epoch 47/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.1085 - accuracy: 0.9611 - val_loss: 0.9488 - val_accuracy: 0.6957\n","Epoch 48/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1151 - accuracy: 0.9605 - val_loss: 0.4922 - val_accuracy: 0.8164\n","Epoch 49/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0856 - accuracy: 0.9686 - val_loss: 0.7986 - val_accuracy: 0.7735\n","Epoch 50/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0877 - accuracy: 0.9705 - val_loss: 0.6651 - val_accuracy: 0.8164\n","Results for fold 3\n","Epoch 1/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.1426 - accuracy: 0.9534 - val_loss: 0.5090 - val_accuracy: 0.8177\n","Epoch 2/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.1085 - accuracy: 0.9617 - val_loss: 0.4188 - val_accuracy: 0.8579\n","Epoch 3/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.1144 - accuracy: 0.9633 - val_loss: 0.4068 - val_accuracy: 0.8633\n","Epoch 4/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1039 - accuracy: 0.9648 - val_loss: 0.5473 - val_accuracy: 0.8217\n","Epoch 5/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1119 - accuracy: 0.9623 - val_loss: 0.3253 - val_accuracy: 0.8928\n","Epoch 6/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.1028 - accuracy: 0.9650 - val_loss: 0.4374 - val_accuracy: 0.8499\n","Epoch 7/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.1475 - accuracy: 0.9472 - val_loss: 0.5523 - val_accuracy: 0.7855\n","Epoch 8/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.1006 - accuracy: 0.9666 - val_loss: 0.5652 - val_accuracy: 0.8016\n","Epoch 9/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0888 - accuracy: 0.9681 - val_loss: 0.8536 - val_accuracy: 0.7306\n","Epoch 10/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0975 - accuracy: 0.9657 - val_loss: 0.3822 - val_accuracy: 0.8673\n","Epoch 11/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.1031 - accuracy: 0.9633 - val_loss: 0.5242 - val_accuracy: 0.8298\n","Epoch 12/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1009 - accuracy: 0.9657 - val_loss: 0.4750 - val_accuracy: 0.8271\n","Epoch 13/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.1025 - accuracy: 0.9654 - val_loss: 0.3746 - val_accuracy: 0.8713\n","Epoch 14/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0909 - accuracy: 0.9686 - val_loss: 0.4098 - val_accuracy: 0.8713\n","Epoch 15/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0698 - accuracy: 0.9769 - val_loss: 0.3363 - val_accuracy: 0.8874\n","Epoch 16/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0862 - accuracy: 0.9709 - val_loss: 0.2590 - val_accuracy: 0.9263\n","Epoch 17/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.1034 - accuracy: 0.9651 - val_loss: 0.3731 - val_accuracy: 0.8619\n","Epoch 18/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0897 - accuracy: 0.9705 - val_loss: 0.4169 - val_accuracy: 0.8566\n","Epoch 19/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0828 - accuracy: 0.9723 - val_loss: 0.3659 - val_accuracy: 0.8901\n","Epoch 20/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0785 - accuracy: 0.9747 - val_loss: 0.5035 - val_accuracy: 0.8445\n","Epoch 21/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0986 - accuracy: 0.9648 - val_loss: 0.2401 - val_accuracy: 0.9236\n","Epoch 22/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0828 - accuracy: 0.9718 - val_loss: 0.1897 - val_accuracy: 0.9303\n","Epoch 23/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0977 - accuracy: 0.9680 - val_loss: 0.5069 - val_accuracy: 0.8351\n","Epoch 24/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0699 - accuracy: 0.9778 - val_loss: 0.6432 - val_accuracy: 0.8204\n","Epoch 25/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0651 - accuracy: 0.9784 - val_loss: 0.5907 - val_accuracy: 0.8418\n","Epoch 26/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0801 - accuracy: 0.9732 - val_loss: 0.4206 - val_accuracy: 0.8700\n","Epoch 27/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0844 - accuracy: 0.9726 - val_loss: 1.0487 - val_accuracy: 0.7265\n","Epoch 28/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.3231 - accuracy: 0.8984 - val_loss: 0.8119 - val_accuracy: 0.6542\n","Epoch 29/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.1329 - accuracy: 0.9569 - val_loss: 0.3288 - val_accuracy: 0.8861\n","Epoch 30/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0831 - accuracy: 0.9721 - val_loss: 0.3705 - val_accuracy: 0.8740\n","Epoch 31/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0791 - accuracy: 0.9747 - val_loss: 0.7721 - val_accuracy: 0.7788\n","Epoch 32/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0684 - accuracy: 0.9800 - val_loss: 0.5654 - val_accuracy: 0.8324\n","Epoch 33/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0568 - accuracy: 0.9839 - val_loss: 0.2856 - val_accuracy: 0.9169\n","Epoch 34/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0522 - accuracy: 0.9829 - val_loss: 0.3861 - val_accuracy: 0.8740\n","Epoch 35/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0784 - accuracy: 0.9742 - val_loss: 0.3966 - val_accuracy: 0.8686\n","Epoch 36/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0752 - accuracy: 0.9768 - val_loss: 0.3401 - val_accuracy: 0.8874\n","Epoch 37/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0679 - accuracy: 0.9782 - val_loss: 0.2777 - val_accuracy: 0.9062\n","Epoch 38/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.1071 - accuracy: 0.9653 - val_loss: 0.2814 - val_accuracy: 0.9115\n","Epoch 39/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0668 - accuracy: 0.9790 - val_loss: 0.3679 - val_accuracy: 0.8807\n","Epoch 40/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0687 - accuracy: 0.9778 - val_loss: 0.3143 - val_accuracy: 0.9048\n","Epoch 41/50\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0781 - accuracy: 0.9741 - val_loss: 0.7488 - val_accuracy: 0.7574\n","Epoch 42/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0669 - accuracy: 0.9773 - val_loss: 0.1776 - val_accuracy: 0.9303\n","Epoch 43/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0689 - accuracy: 0.9775 - val_loss: 0.4485 - val_accuracy: 0.8579\n","Epoch 44/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0856 - accuracy: 0.9732 - val_loss: 0.4967 - val_accuracy: 0.8324\n","Epoch 45/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.1287 - accuracy: 0.9559 - val_loss: 0.2862 - val_accuracy: 0.9008\n","Epoch 46/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0655 - accuracy: 0.9788 - val_loss: 0.7542 - val_accuracy: 0.8003\n","Epoch 47/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0584 - accuracy: 0.9800 - val_loss: 0.4036 - val_accuracy: 0.8780\n","Epoch 48/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0599 - accuracy: 0.9805 - val_loss: 0.3895 - val_accuracy: 0.8887\n","Epoch 49/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0577 - accuracy: 0.9821 - val_loss: 0.6118 - val_accuracy: 0.8324\n","Epoch 50/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0633 - accuracy: 0.9803 - val_loss: 0.4770 - val_accuracy: 0.8633\n","Results for fold 4\n","Epoch 1/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0757 - accuracy: 0.9765 - val_loss: 0.4764 - val_accuracy: 0.8525\n","Epoch 2/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0785 - accuracy: 0.9751 - val_loss: 0.4816 - val_accuracy: 0.8512\n","Epoch 3/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0659 - accuracy: 0.9800 - val_loss: 0.1545 - val_accuracy: 0.9370\n","Epoch 4/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0604 - accuracy: 0.9799 - val_loss: 0.0749 - val_accuracy: 0.9759\n","Epoch 5/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0552 - accuracy: 0.9814 - val_loss: 0.2983 - val_accuracy: 0.9062\n","Epoch 6/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0466 - accuracy: 0.9842 - val_loss: 0.1471 - val_accuracy: 0.9504\n","Epoch 7/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0559 - accuracy: 0.9833 - val_loss: 0.2734 - val_accuracy: 0.9263\n","Epoch 8/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0671 - accuracy: 0.9787 - val_loss: 0.2241 - val_accuracy: 0.9290\n","Epoch 9/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0748 - accuracy: 0.9741 - val_loss: 0.4054 - val_accuracy: 0.8807\n","Epoch 10/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0561 - accuracy: 0.9805 - val_loss: 0.2120 - val_accuracy: 0.9276\n","Epoch 11/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0528 - accuracy: 0.9839 - val_loss: 0.2371 - val_accuracy: 0.9223\n","Epoch 12/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0615 - accuracy: 0.9787 - val_loss: 0.5692 - val_accuracy: 0.8257\n","Epoch 13/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0704 - accuracy: 0.9772 - val_loss: 0.1020 - val_accuracy: 0.9625\n","Epoch 14/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0666 - accuracy: 0.9794 - val_loss: 0.2227 - val_accuracy: 0.9303\n","Epoch 15/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0739 - accuracy: 0.9754 - val_loss: 0.2952 - val_accuracy: 0.8995\n","Epoch 16/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0606 - accuracy: 0.9811 - val_loss: 0.0999 - val_accuracy: 0.9638\n","Epoch 17/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0507 - accuracy: 0.9842 - val_loss: 0.3254 - val_accuracy: 0.8995\n","Epoch 18/50\n","53/53 [==============================] - 4s 79ms/step - loss: 0.0860 - accuracy: 0.9702 - val_loss: 0.2199 - val_accuracy: 0.9249\n","Epoch 19/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0584 - accuracy: 0.9814 - val_loss: 0.3518 - val_accuracy: 0.8820\n","Epoch 20/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0491 - accuracy: 0.9827 - val_loss: 0.2607 - val_accuracy: 0.9155\n","Epoch 21/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0567 - accuracy: 0.9797 - val_loss: 0.4900 - val_accuracy: 0.8700\n","Epoch 22/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.1043 - accuracy: 0.9659 - val_loss: 0.1762 - val_accuracy: 0.9370\n","Epoch 23/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0968 - accuracy: 0.9726 - val_loss: 0.7016 - val_accuracy: 0.7936\n","Epoch 24/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0696 - accuracy: 0.9811 - val_loss: 0.3057 - val_accuracy: 0.8914\n","Epoch 25/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0503 - accuracy: 0.9827 - val_loss: 0.3348 - val_accuracy: 0.8968\n","Epoch 26/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0429 - accuracy: 0.9852 - val_loss: 0.4106 - val_accuracy: 0.8673\n","Epoch 27/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0478 - accuracy: 0.9832 - val_loss: 0.4216 - val_accuracy: 0.8619\n","Epoch 28/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0523 - accuracy: 0.9839 - val_loss: 0.1702 - val_accuracy: 0.9410\n","Epoch 29/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.1217 - accuracy: 0.9623 - val_loss: 0.2446 - val_accuracy: 0.9075\n","Epoch 30/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0668 - accuracy: 0.9788 - val_loss: 0.1419 - val_accuracy: 0.9450\n","Epoch 31/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0497 - accuracy: 0.9841 - val_loss: 0.0903 - val_accuracy: 0.9638\n","Epoch 32/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0558 - accuracy: 0.9821 - val_loss: 0.3498 - val_accuracy: 0.8887\n","Epoch 33/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0579 - accuracy: 0.9820 - val_loss: 0.3678 - val_accuracy: 0.8914\n","Epoch 34/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0547 - accuracy: 0.9815 - val_loss: 0.3566 - val_accuracy: 0.8861\n","Epoch 35/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0555 - accuracy: 0.9806 - val_loss: 0.1789 - val_accuracy: 0.9397\n","Epoch 36/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0438 - accuracy: 0.9866 - val_loss: 0.1941 - val_accuracy: 0.9397\n","Epoch 37/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0284 - accuracy: 0.9908 - val_loss: 0.1721 - val_accuracy: 0.9450\n","Epoch 38/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0366 - accuracy: 0.9894 - val_loss: 0.1642 - val_accuracy: 0.9504\n","Epoch 39/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0351 - accuracy: 0.9872 - val_loss: 0.2185 - val_accuracy: 0.9303\n","Epoch 40/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0495 - accuracy: 0.9836 - val_loss: 0.4237 - val_accuracy: 0.8807\n","Epoch 41/50\n","53/53 [==============================] - 4s 79ms/step - loss: 0.0593 - accuracy: 0.9799 - val_loss: 0.6183 - val_accuracy: 0.8405\n","Epoch 42/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0521 - accuracy: 0.9823 - val_loss: 0.6827 - val_accuracy: 0.8204\n","Epoch 43/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0556 - accuracy: 0.9811 - val_loss: 0.5308 - val_accuracy: 0.8284\n","Epoch 44/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0587 - accuracy: 0.9812 - val_loss: 0.5044 - val_accuracy: 0.8566\n","Epoch 45/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0521 - accuracy: 0.9836 - val_loss: 0.2182 - val_accuracy: 0.9196\n","Epoch 46/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0465 - accuracy: 0.9855 - val_loss: 0.2565 - val_accuracy: 0.9196\n","Epoch 47/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0464 - accuracy: 0.9846 - val_loss: 0.2051 - val_accuracy: 0.9357\n","Epoch 48/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0480 - accuracy: 0.9846 - val_loss: 0.2273 - val_accuracy: 0.9276\n","Epoch 49/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0446 - accuracy: 0.9863 - val_loss: 0.1835 - val_accuracy: 0.9370\n","Epoch 50/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0490 - accuracy: 0.9861 - val_loss: 0.1034 - val_accuracy: 0.9611\n","Results for fold 5\n","Epoch 1/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0825 - accuracy: 0.9738 - val_loss: 0.2576 - val_accuracy: 0.9008\n","Epoch 2/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.1026 - accuracy: 0.9654 - val_loss: 0.3693 - val_accuracy: 0.8727\n","Epoch 3/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0434 - accuracy: 0.9860 - val_loss: 0.2016 - val_accuracy: 0.9397\n","Epoch 4/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0449 - accuracy: 0.9852 - val_loss: 0.2785 - val_accuracy: 0.9236\n","Epoch 5/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0586 - accuracy: 0.9818 - val_loss: 1.0044 - val_accuracy: 0.7091\n","Epoch 6/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0655 - accuracy: 0.9772 - val_loss: 0.2038 - val_accuracy: 0.9397\n","Epoch 7/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0429 - accuracy: 0.9860 - val_loss: 0.1841 - val_accuracy: 0.9504\n","Epoch 8/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0615 - accuracy: 0.9790 - val_loss: 0.7702 - val_accuracy: 0.8056\n","Epoch 9/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0521 - accuracy: 0.9842 - val_loss: 0.4030 - val_accuracy: 0.8807\n","Epoch 10/50\n","53/53 [==============================] - 4s 79ms/step - loss: 0.0500 - accuracy: 0.9824 - val_loss: 0.6328 - val_accuracy: 0.8190\n","Epoch 11/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0616 - accuracy: 0.9809 - val_loss: 0.2229 - val_accuracy: 0.9209\n","Epoch 12/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0598 - accuracy: 0.9811 - val_loss: 0.2730 - val_accuracy: 0.9223\n","Epoch 13/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0712 - accuracy: 0.9785 - val_loss: 0.4271 - val_accuracy: 0.8579\n","Epoch 14/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0400 - accuracy: 0.9891 - val_loss: 0.3473 - val_accuracy: 0.8954\n","Epoch 15/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0315 - accuracy: 0.9903 - val_loss: 0.4386 - val_accuracy: 0.8713\n","Epoch 16/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0318 - accuracy: 0.9896 - val_loss: 0.3748 - val_accuracy: 0.8941\n","Epoch 17/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0353 - accuracy: 0.9891 - val_loss: 0.2688 - val_accuracy: 0.9223\n","Epoch 18/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0467 - accuracy: 0.9860 - val_loss: 0.2640 - val_accuracy: 0.9155\n","Epoch 19/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0469 - accuracy: 0.9854 - val_loss: 0.7177 - val_accuracy: 0.8137\n","Epoch 20/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0496 - accuracy: 0.9855 - val_loss: 0.4096 - val_accuracy: 0.8807\n","Epoch 21/50\n","53/53 [==============================] - 4s 79ms/step - loss: 0.0425 - accuracy: 0.9852 - val_loss: 0.3788 - val_accuracy: 0.8954\n","Epoch 22/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0495 - accuracy: 0.9841 - val_loss: 0.7191 - val_accuracy: 0.7936\n","Epoch 23/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0325 - accuracy: 0.9902 - val_loss: 0.7139 - val_accuracy: 0.8458\n","Epoch 24/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0588 - accuracy: 0.9812 - val_loss: 0.4301 - val_accuracy: 0.8767\n","Epoch 25/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0530 - accuracy: 0.9848 - val_loss: 0.2854 - val_accuracy: 0.9021\n","Epoch 26/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0419 - accuracy: 0.9876 - val_loss: 0.3013 - val_accuracy: 0.9209\n","Epoch 27/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0542 - accuracy: 0.9826 - val_loss: 0.3476 - val_accuracy: 0.8914\n","Epoch 28/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0402 - accuracy: 0.9866 - val_loss: 0.1844 - val_accuracy: 0.9477\n","Epoch 29/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0445 - accuracy: 0.9858 - val_loss: 0.1064 - val_accuracy: 0.9692\n","Epoch 30/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0393 - accuracy: 0.9875 - val_loss: 0.2104 - val_accuracy: 0.9330\n","Epoch 31/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0409 - accuracy: 0.9867 - val_loss: 0.5578 - val_accuracy: 0.8646\n","Epoch 32/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0445 - accuracy: 0.9839 - val_loss: 1.1439 - val_accuracy: 0.7440\n","Epoch 33/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0372 - accuracy: 0.9884 - val_loss: 0.5965 - val_accuracy: 0.8512\n","Epoch 34/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0418 - accuracy: 0.9866 - val_loss: 0.6239 - val_accuracy: 0.8458\n","Epoch 35/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0375 - accuracy: 0.9884 - val_loss: 0.1614 - val_accuracy: 0.9450\n","Epoch 36/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0403 - accuracy: 0.9872 - val_loss: 0.3914 - val_accuracy: 0.8847\n","Epoch 37/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0433 - accuracy: 0.9869 - val_loss: 0.3396 - val_accuracy: 0.8874\n","Epoch 38/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0409 - accuracy: 0.9881 - val_loss: 0.3410 - val_accuracy: 0.9088\n","Epoch 39/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0417 - accuracy: 0.9860 - val_loss: 0.3146 - val_accuracy: 0.9008\n","Epoch 40/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0300 - accuracy: 0.9893 - val_loss: 0.7550 - val_accuracy: 0.8123\n","Epoch 41/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0363 - accuracy: 0.9888 - val_loss: 0.2208 - val_accuracy: 0.9343\n","Epoch 42/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0476 - accuracy: 0.9869 - val_loss: 0.5926 - val_accuracy: 0.8445\n","Epoch 43/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0407 - accuracy: 0.9866 - val_loss: 0.1805 - val_accuracy: 0.9584\n","Epoch 44/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0356 - accuracy: 0.9881 - val_loss: 0.2884 - val_accuracy: 0.9142\n","Epoch 45/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0371 - accuracy: 0.9881 - val_loss: 0.3839 - val_accuracy: 0.8847\n","Epoch 46/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0311 - accuracy: 0.9896 - val_loss: 0.8827 - val_accuracy: 0.7936\n","Epoch 47/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0374 - accuracy: 0.9881 - val_loss: 0.1284 - val_accuracy: 0.9611\n","Epoch 48/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0462 - accuracy: 0.9864 - val_loss: 1.0317 - val_accuracy: 0.7480\n","Epoch 49/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0590 - accuracy: 0.9817 - val_loss: 0.3828 - val_accuracy: 0.8874\n","Epoch 50/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0478 - accuracy: 0.9838 - val_loss: 0.3500 - val_accuracy: 0.8928\n","Results for fold 6\n","Epoch 1/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0529 - accuracy: 0.9833 - val_loss: 0.1214 - val_accuracy: 0.9611\n","Epoch 2/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0460 - accuracy: 0.9855 - val_loss: 0.0944 - val_accuracy: 0.9611\n","Epoch 3/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0300 - accuracy: 0.9897 - val_loss: 0.1755 - val_accuracy: 0.9437\n","Epoch 4/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0422 - accuracy: 0.9881 - val_loss: 0.6452 - val_accuracy: 0.8405\n","Epoch 5/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0513 - accuracy: 0.9832 - val_loss: 0.0498 - val_accuracy: 0.9799\n","Epoch 6/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0387 - accuracy: 0.9858 - val_loss: 0.1855 - val_accuracy: 0.9424\n","Epoch 7/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0465 - accuracy: 0.9852 - val_loss: 0.0645 - val_accuracy: 0.9786\n","Epoch 8/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0392 - accuracy: 0.9861 - val_loss: 0.3096 - val_accuracy: 0.9008\n","Epoch 9/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0396 - accuracy: 0.9872 - val_loss: 0.2857 - val_accuracy: 0.9062\n","Epoch 10/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0339 - accuracy: 0.9888 - val_loss: 0.3324 - val_accuracy: 0.9115\n","Epoch 11/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0373 - accuracy: 0.9866 - val_loss: 0.0532 - val_accuracy: 0.9812\n","Epoch 12/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0407 - accuracy: 0.9873 - val_loss: 0.0920 - val_accuracy: 0.9665\n","Epoch 13/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0499 - accuracy: 0.9838 - val_loss: 0.0358 - val_accuracy: 0.9853\n","Epoch 14/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0387 - accuracy: 0.9870 - val_loss: 0.0583 - val_accuracy: 0.9839\n","Epoch 15/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0418 - accuracy: 0.9897 - val_loss: 0.1743 - val_accuracy: 0.9370\n","Epoch 16/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0614 - accuracy: 0.9806 - val_loss: 0.0738 - val_accuracy: 0.9665\n","Epoch 17/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0842 - accuracy: 0.9751 - val_loss: 0.0373 - val_accuracy: 0.9866\n","Epoch 18/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0695 - accuracy: 0.9781 - val_loss: 0.0799 - val_accuracy: 0.9692\n","Epoch 19/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0400 - accuracy: 0.9864 - val_loss: 0.5855 - val_accuracy: 0.8458\n","Epoch 20/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0367 - accuracy: 0.9893 - val_loss: 0.1877 - val_accuracy: 0.9370\n","Epoch 21/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0426 - accuracy: 0.9869 - val_loss: 0.1006 - val_accuracy: 0.9692\n","Epoch 22/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0316 - accuracy: 0.9893 - val_loss: 0.0694 - val_accuracy: 0.9759\n","Epoch 23/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0341 - accuracy: 0.9882 - val_loss: 0.1540 - val_accuracy: 0.9584\n","Epoch 24/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0372 - accuracy: 0.9878 - val_loss: 0.1079 - val_accuracy: 0.9651\n","Epoch 25/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0353 - accuracy: 0.9905 - val_loss: 0.1084 - val_accuracy: 0.9625\n","Epoch 26/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0308 - accuracy: 0.9897 - val_loss: 0.1643 - val_accuracy: 0.9477\n","Epoch 27/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0317 - accuracy: 0.9902 - val_loss: 0.1884 - val_accuracy: 0.9410\n","Epoch 28/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0314 - accuracy: 0.9905 - val_loss: 0.0800 - val_accuracy: 0.9692\n","Epoch 29/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0315 - accuracy: 0.9899 - val_loss: 0.1062 - val_accuracy: 0.9718\n","Epoch 30/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0330 - accuracy: 0.9893 - val_loss: 0.1286 - val_accuracy: 0.9558\n","Epoch 31/50\n","53/53 [==============================] - 4s 80ms/step - loss: 0.0375 - accuracy: 0.9881 - val_loss: 0.2614 - val_accuracy: 0.9209\n","Epoch 32/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0346 - accuracy: 0.9876 - val_loss: 0.3403 - val_accuracy: 0.9155\n","Epoch 33/50\n","53/53 [==============================] - 4s 79ms/step - loss: 0.0345 - accuracy: 0.9887 - val_loss: 0.1428 - val_accuracy: 0.9611\n","Epoch 34/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0296 - accuracy: 0.9900 - val_loss: 0.2502 - val_accuracy: 0.9276\n","Epoch 35/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0262 - accuracy: 0.9914 - val_loss: 0.3761 - val_accuracy: 0.9075\n","Epoch 36/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0300 - accuracy: 0.9903 - val_loss: 0.1042 - val_accuracy: 0.9638\n","Epoch 37/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0286 - accuracy: 0.9911 - val_loss: 0.1305 - val_accuracy: 0.9611\n","Epoch 38/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.1399 - accuracy: 0.9602 - val_loss: 0.2542 - val_accuracy: 0.9008\n","Epoch 39/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0488 - accuracy: 0.9855 - val_loss: 0.2917 - val_accuracy: 0.8981\n","Epoch 40/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0435 - accuracy: 0.9869 - val_loss: 0.5745 - val_accuracy: 0.8378\n","Epoch 41/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0288 - accuracy: 0.9927 - val_loss: 0.0401 - val_accuracy: 0.9853\n","Epoch 42/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0329 - accuracy: 0.9890 - val_loss: 0.4507 - val_accuracy: 0.8807\n","Epoch 43/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0302 - accuracy: 0.9906 - val_loss: 0.1618 - val_accuracy: 0.9464\n","Epoch 44/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0380 - accuracy: 0.9896 - val_loss: 0.1682 - val_accuracy: 0.9464\n","Epoch 45/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0354 - accuracy: 0.9894 - val_loss: 0.0847 - val_accuracy: 0.9665\n","Epoch 46/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0322 - accuracy: 0.9903 - val_loss: 0.0979 - val_accuracy: 0.9692\n","Epoch 47/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0379 - accuracy: 0.9888 - val_loss: 0.2175 - val_accuracy: 0.9464\n","Epoch 48/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0318 - accuracy: 0.9893 - val_loss: 0.0616 - val_accuracy: 0.9772\n","Epoch 49/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0438 - accuracy: 0.9884 - val_loss: 0.1876 - val_accuracy: 0.9517\n","Epoch 50/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0323 - accuracy: 0.9872 - val_loss: 0.1015 - val_accuracy: 0.9678\n","Results for fold 7\n","Epoch 1/50\n","53/53 [==============================] - 5s 87ms/step - loss: 0.0270 - accuracy: 0.9908 - val_loss: 0.1706 - val_accuracy: 0.9544\n","Epoch 2/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0286 - accuracy: 0.9918 - val_loss: 0.3932 - val_accuracy: 0.8953\n","Epoch 3/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0724 - accuracy: 0.9781 - val_loss: 0.1415 - val_accuracy: 0.9570\n","Epoch 4/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0710 - accuracy: 0.9766 - val_loss: 0.2368 - val_accuracy: 0.9195\n","Epoch 5/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0369 - accuracy: 0.9897 - val_loss: 0.1152 - val_accuracy: 0.9678\n","Epoch 6/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0245 - accuracy: 0.9937 - val_loss: 0.2551 - val_accuracy: 0.9221\n","Epoch 7/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0308 - accuracy: 0.9909 - val_loss: 0.2890 - val_accuracy: 0.9168\n","Epoch 8/50\n","53/53 [==============================] - 4s 79ms/step - loss: 0.0247 - accuracy: 0.9918 - val_loss: 0.2937 - val_accuracy: 0.9235\n","Epoch 9/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0249 - accuracy: 0.9920 - val_loss: 0.1042 - val_accuracy: 0.9624\n","Epoch 10/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0476 - accuracy: 0.9833 - val_loss: 0.1564 - val_accuracy: 0.9517\n","Epoch 11/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0506 - accuracy: 0.9847 - val_loss: 0.2164 - val_accuracy: 0.9342\n","Epoch 12/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0352 - accuracy: 0.9897 - val_loss: 0.1658 - val_accuracy: 0.9570\n","Epoch 13/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0305 - accuracy: 0.9894 - val_loss: 0.1784 - val_accuracy: 0.9517\n","Epoch 14/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0278 - accuracy: 0.9915 - val_loss: 0.1602 - val_accuracy: 0.9530\n","Epoch 15/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0522 - accuracy: 0.9844 - val_loss: 0.1575 - val_accuracy: 0.9517\n","Epoch 16/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0310 - accuracy: 0.9899 - val_loss: 0.1185 - val_accuracy: 0.9651\n","Epoch 17/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0283 - accuracy: 0.9903 - val_loss: 0.3023 - val_accuracy: 0.9154\n","Epoch 18/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0202 - accuracy: 0.9940 - val_loss: 0.2335 - val_accuracy: 0.9315\n","Epoch 19/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0281 - accuracy: 0.9921 - val_loss: 0.1164 - val_accuracy: 0.9584\n","Epoch 20/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0355 - accuracy: 0.9890 - val_loss: 0.1623 - val_accuracy: 0.9530\n","Epoch 21/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0295 - accuracy: 0.9912 - val_loss: 0.0919 - val_accuracy: 0.9718\n","Epoch 22/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0316 - accuracy: 0.9897 - val_loss: 0.1833 - val_accuracy: 0.9383\n","Epoch 23/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0376 - accuracy: 0.9885 - val_loss: 0.2950 - val_accuracy: 0.9195\n","Epoch 24/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0270 - accuracy: 0.9912 - val_loss: 0.2554 - val_accuracy: 0.9275\n","Epoch 25/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0272 - accuracy: 0.9912 - val_loss: 0.2539 - val_accuracy: 0.9302\n","Epoch 26/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0292 - accuracy: 0.9905 - val_loss: 0.1840 - val_accuracy: 0.9530\n","Epoch 27/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0230 - accuracy: 0.9927 - val_loss: 0.1324 - val_accuracy: 0.9651\n","Epoch 28/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0380 - accuracy: 0.9894 - val_loss: 0.5193 - val_accuracy: 0.8792\n","Epoch 29/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0335 - accuracy: 0.9891 - val_loss: 0.2298 - val_accuracy: 0.9436\n","Epoch 30/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0367 - accuracy: 0.9890 - val_loss: 0.8129 - val_accuracy: 0.8107\n","Epoch 31/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0353 - accuracy: 0.9900 - val_loss: 0.0767 - val_accuracy: 0.9732\n","Epoch 32/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0245 - accuracy: 0.9928 - val_loss: 0.1635 - val_accuracy: 0.9396\n","Epoch 33/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0195 - accuracy: 0.9945 - val_loss: 0.4391 - val_accuracy: 0.8752\n","Epoch 34/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0268 - accuracy: 0.9908 - val_loss: 1.0484 - val_accuracy: 0.7517\n","Epoch 35/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0217 - accuracy: 0.9937 - val_loss: 0.1659 - val_accuracy: 0.9503\n","Epoch 36/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0231 - accuracy: 0.9925 - val_loss: 0.2646 - val_accuracy: 0.9289\n","Epoch 37/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0392 - accuracy: 0.9875 - val_loss: 0.4853 - val_accuracy: 0.8698\n","Epoch 38/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0313 - accuracy: 0.9888 - val_loss: 0.3878 - val_accuracy: 0.8805\n","Epoch 39/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0310 - accuracy: 0.9905 - val_loss: 0.1025 - val_accuracy: 0.9664\n","Epoch 40/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0330 - accuracy: 0.9888 - val_loss: 0.0927 - val_accuracy: 0.9705\n","Epoch 41/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0299 - accuracy: 0.9902 - val_loss: 0.1413 - val_accuracy: 0.9597\n","Epoch 42/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0285 - accuracy: 0.9905 - val_loss: 0.2346 - val_accuracy: 0.9356\n","Epoch 43/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0219 - accuracy: 0.9930 - val_loss: 0.2823 - val_accuracy: 0.9208\n","Epoch 44/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0305 - accuracy: 0.9897 - val_loss: 0.2471 - val_accuracy: 0.9315\n","Epoch 45/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0390 - accuracy: 0.9867 - val_loss: 0.1613 - val_accuracy: 0.9477\n","Epoch 46/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0277 - accuracy: 0.9915 - val_loss: 0.2544 - val_accuracy: 0.9315\n","Epoch 47/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0282 - accuracy: 0.9911 - val_loss: 0.5191 - val_accuracy: 0.8752\n","Epoch 48/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0423 - accuracy: 0.9872 - val_loss: 0.2322 - val_accuracy: 0.9275\n","Epoch 49/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0783 - accuracy: 0.9756 - val_loss: 0.2616 - val_accuracy: 0.9235\n","Epoch 50/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0447 - accuracy: 0.9861 - val_loss: 0.1643 - val_accuracy: 0.9490\n","Results for fold 8\n","Epoch 1/50\n","53/53 [==============================] - 4s 79ms/step - loss: 0.0285 - accuracy: 0.9928 - val_loss: 0.0130 - val_accuracy: 0.9973\n","Epoch 2/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0217 - accuracy: 0.9939 - val_loss: 0.0682 - val_accuracy: 0.9799\n","Epoch 3/50\n","53/53 [==============================] - 4s 80ms/step - loss: 0.0293 - accuracy: 0.9912 - val_loss: 0.0980 - val_accuracy: 0.9584\n","Epoch 4/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0338 - accuracy: 0.9879 - val_loss: 0.0874 - val_accuracy: 0.9691\n","Epoch 5/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0353 - accuracy: 0.9884 - val_loss: 0.5625 - val_accuracy: 0.8577\n","Epoch 6/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0252 - accuracy: 0.9924 - val_loss: 0.2265 - val_accuracy: 0.9423\n","Epoch 7/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0261 - accuracy: 0.9905 - val_loss: 0.0830 - val_accuracy: 0.9638\n","Epoch 8/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0269 - accuracy: 0.9923 - val_loss: 0.1536 - val_accuracy: 0.9557\n","Epoch 9/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0323 - accuracy: 0.9899 - val_loss: 0.2412 - val_accuracy: 0.9168\n","Epoch 10/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0302 - accuracy: 0.9900 - val_loss: 0.1786 - val_accuracy: 0.9342\n","Epoch 11/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0201 - accuracy: 0.9940 - val_loss: 0.1248 - val_accuracy: 0.9597\n","Epoch 12/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0256 - accuracy: 0.9928 - val_loss: 0.3608 - val_accuracy: 0.9101\n","Epoch 13/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0269 - accuracy: 0.9925 - val_loss: 0.6142 - val_accuracy: 0.8591\n","Epoch 14/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0402 - accuracy: 0.9867 - val_loss: 0.0534 - val_accuracy: 0.9799\n","Epoch 15/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0353 - accuracy: 0.9878 - val_loss: 0.1826 - val_accuracy: 0.9369\n","Epoch 16/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0268 - accuracy: 0.9920 - val_loss: 0.2370 - val_accuracy: 0.9396\n","Epoch 17/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0322 - accuracy: 0.9912 - val_loss: 0.2493 - val_accuracy: 0.9235\n","Epoch 18/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0254 - accuracy: 0.9918 - val_loss: 0.0917 - val_accuracy: 0.9638\n","Epoch 19/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.1394 - val_accuracy: 0.9624\n","Epoch 20/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0290 - accuracy: 0.9903 - val_loss: 0.1087 - val_accuracy: 0.9638\n","Epoch 21/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0354 - accuracy: 0.9902 - val_loss: 0.2077 - val_accuracy: 0.9356\n","Epoch 22/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0211 - accuracy: 0.9942 - val_loss: 0.2678 - val_accuracy: 0.9262\n","Epoch 23/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0274 - accuracy: 0.9917 - val_loss: 0.2606 - val_accuracy: 0.9275\n","Epoch 24/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0335 - accuracy: 0.9903 - val_loss: 0.2508 - val_accuracy: 0.9289\n","Epoch 25/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0277 - accuracy: 0.9909 - val_loss: 0.6053 - val_accuracy: 0.8497\n","Epoch 26/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0234 - accuracy: 0.9925 - val_loss: 0.3988 - val_accuracy: 0.9034\n","Epoch 27/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0417 - accuracy: 0.9882 - val_loss: 0.3940 - val_accuracy: 0.8913\n","Epoch 28/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0302 - accuracy: 0.9906 - val_loss: 0.2739 - val_accuracy: 0.9221\n","Epoch 29/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0290 - accuracy: 0.9915 - val_loss: 0.5513 - val_accuracy: 0.8564\n","Epoch 30/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0310 - accuracy: 0.9890 - val_loss: 0.0974 - val_accuracy: 0.9664\n","Epoch 31/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0236 - accuracy: 0.9914 - val_loss: 0.2748 - val_accuracy: 0.9289\n","Epoch 32/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0316 - accuracy: 0.9897 - val_loss: 0.1683 - val_accuracy: 0.9423\n","Epoch 33/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0286 - accuracy: 0.9900 - val_loss: 0.6535 - val_accuracy: 0.8443\n","Epoch 34/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0423 - accuracy: 0.9878 - val_loss: 0.4231 - val_accuracy: 0.8711\n","Epoch 35/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0281 - accuracy: 0.9906 - val_loss: 0.2696 - val_accuracy: 0.9235\n","Epoch 36/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0247 - accuracy: 0.9912 - val_loss: 0.4125 - val_accuracy: 0.8953\n","Epoch 37/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0260 - accuracy: 0.9912 - val_loss: 0.1585 - val_accuracy: 0.9570\n","Epoch 38/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0277 - accuracy: 0.9912 - val_loss: 0.6853 - val_accuracy: 0.8362\n","Epoch 39/50\n","53/53 [==============================] - 4s 80ms/step - loss: 0.0302 - accuracy: 0.9905 - val_loss: 1.4166 - val_accuracy: 0.7235\n","Epoch 40/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0608 - accuracy: 0.9809 - val_loss: 0.2729 - val_accuracy: 0.9181\n","Epoch 41/50\n","53/53 [==============================] - 4s 80ms/step - loss: 0.0298 - accuracy: 0.9909 - val_loss: 0.3984 - val_accuracy: 0.8953\n","Epoch 42/50\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0265 - accuracy: 0.9927 - val_loss: 0.4528 - val_accuracy: 0.8913\n","Epoch 43/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0217 - accuracy: 0.9928 - val_loss: 0.1635 - val_accuracy: 0.9490\n","Epoch 44/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0219 - accuracy: 0.9937 - val_loss: 0.0935 - val_accuracy: 0.9691\n","Epoch 45/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0402 - accuracy: 0.9876 - val_loss: 0.4841 - val_accuracy: 0.8725\n","Epoch 46/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0278 - accuracy: 0.9917 - val_loss: 0.1376 - val_accuracy: 0.9517\n","Epoch 47/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0170 - accuracy: 0.9937 - val_loss: 0.2531 - val_accuracy: 0.9289\n","Epoch 48/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0197 - accuracy: 0.9934 - val_loss: 0.4118 - val_accuracy: 0.9020\n","Epoch 49/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 0.3042 - val_accuracy: 0.9262\n","Epoch 50/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0269 - accuracy: 0.9906 - val_loss: 0.3004 - val_accuracy: 0.9289\n","Results for fold 9\n","Epoch 1/50\n","53/53 [==============================] - 4s 79ms/step - loss: 0.0257 - accuracy: 0.9927 - val_loss: 0.1426 - val_accuracy: 0.9651\n","Epoch 2/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0290 - accuracy: 0.9918 - val_loss: 0.1792 - val_accuracy: 0.9503\n","Epoch 3/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0300 - accuracy: 0.9912 - val_loss: 0.1942 - val_accuracy: 0.9477\n","Epoch 4/50\n","53/53 [==============================] - 4s 79ms/step - loss: 0.0371 - accuracy: 0.9884 - val_loss: 0.3820 - val_accuracy: 0.8966\n","Epoch 5/50\n","53/53 [==============================] - 4s 79ms/step - loss: 0.0243 - accuracy: 0.9930 - val_loss: 0.2536 - val_accuracy: 0.9221\n","Epoch 6/50\n","53/53 [==============================] - 4s 79ms/step - loss: 0.0194 - accuracy: 0.9940 - val_loss: 0.0637 - val_accuracy: 0.9812\n","Epoch 7/50\n","53/53 [==============================] - 4s 79ms/step - loss: 0.0191 - accuracy: 0.9940 - val_loss: 0.2353 - val_accuracy: 0.9383\n","Epoch 8/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0339 - accuracy: 0.9905 - val_loss: 0.1189 - val_accuracy: 0.9638\n","Epoch 9/50\n","53/53 [==============================] - 4s 79ms/step - loss: 0.0247 - accuracy: 0.9931 - val_loss: 0.2175 - val_accuracy: 0.9436\n","Epoch 10/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0244 - accuracy: 0.9915 - val_loss: 0.2293 - val_accuracy: 0.9356\n","Epoch 11/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0354 - accuracy: 0.9887 - val_loss: 0.7181 - val_accuracy: 0.8081\n","Epoch 12/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0322 - accuracy: 0.9909 - val_loss: 0.1159 - val_accuracy: 0.9570\n","Epoch 13/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0274 - accuracy: 0.9923 - val_loss: 0.0402 - val_accuracy: 0.9852\n","Epoch 14/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0365 - accuracy: 0.9897 - val_loss: 0.0693 - val_accuracy: 0.9785\n","Epoch 15/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0284 - accuracy: 0.9894 - val_loss: 0.1191 - val_accuracy: 0.9611\n","Epoch 16/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0218 - accuracy: 0.9928 - val_loss: 0.1338 - val_accuracy: 0.9638\n","Epoch 17/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0273 - accuracy: 0.9933 - val_loss: 0.4873 - val_accuracy: 0.8859\n","Epoch 18/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0564 - accuracy: 0.9820 - val_loss: 0.4594 - val_accuracy: 0.8711\n","Epoch 19/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0205 - accuracy: 0.9943 - val_loss: 0.2242 - val_accuracy: 0.9248\n","Epoch 20/50\n","53/53 [==============================] - 4s 79ms/step - loss: 0.0254 - accuracy: 0.9924 - val_loss: 0.1424 - val_accuracy: 0.9544\n","Epoch 21/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0218 - accuracy: 0.9936 - val_loss: 0.0601 - val_accuracy: 0.9785\n","Epoch 22/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0202 - accuracy: 0.9945 - val_loss: 0.0533 - val_accuracy: 0.9785\n","Epoch 23/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0218 - accuracy: 0.9933 - val_loss: 0.0392 - val_accuracy: 0.9839\n","Epoch 24/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0490 - accuracy: 0.9845 - val_loss: 0.3520 - val_accuracy: 0.8899\n","Epoch 25/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0959 - accuracy: 0.9723 - val_loss: 0.0503 - val_accuracy: 0.9812\n","Epoch 26/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0232 - accuracy: 0.9933 - val_loss: 0.0891 - val_accuracy: 0.9718\n","Epoch 27/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0228 - accuracy: 0.9937 - val_loss: 0.2453 - val_accuracy: 0.9329\n","Epoch 28/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 0.1190 - val_accuracy: 0.9651\n","Epoch 29/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0202 - accuracy: 0.9937 - val_loss: 0.1714 - val_accuracy: 0.9544\n","Epoch 30/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0217 - accuracy: 0.9923 - val_loss: 0.0871 - val_accuracy: 0.9732\n","Epoch 31/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0252 - accuracy: 0.9917 - val_loss: 0.0954 - val_accuracy: 0.9745\n","Epoch 32/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0246 - accuracy: 0.9933 - val_loss: 0.1319 - val_accuracy: 0.9678\n","Epoch 33/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0300 - accuracy: 0.9905 - val_loss: 0.0997 - val_accuracy: 0.9732\n","Epoch 34/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0219 - accuracy: 0.9931 - val_loss: 0.0823 - val_accuracy: 0.9758\n","Epoch 35/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0180 - accuracy: 0.9943 - val_loss: 0.0745 - val_accuracy: 0.9745\n","Epoch 36/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0255 - accuracy: 0.9924 - val_loss: 0.3083 - val_accuracy: 0.9235\n","Epoch 37/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0344 - accuracy: 0.9887 - val_loss: 1.2142 - val_accuracy: 0.7315\n","Epoch 38/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0328 - accuracy: 0.9890 - val_loss: 0.2214 - val_accuracy: 0.9289\n","Epoch 39/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0267 - accuracy: 0.9906 - val_loss: 0.1376 - val_accuracy: 0.9570\n","Epoch 40/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0397 - accuracy: 0.9878 - val_loss: 0.2001 - val_accuracy: 0.9396\n","Epoch 41/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0246 - accuracy: 0.9918 - val_loss: 0.3428 - val_accuracy: 0.9060\n","Epoch 42/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0252 - accuracy: 0.9931 - val_loss: 0.1042 - val_accuracy: 0.9544\n","Epoch 43/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0280 - accuracy: 0.9909 - val_loss: 0.1267 - val_accuracy: 0.9678\n","Epoch 44/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0228 - accuracy: 0.9924 - val_loss: 0.2268 - val_accuracy: 0.9409\n","Epoch 45/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0203 - accuracy: 0.9951 - val_loss: 0.0839 - val_accuracy: 0.9745\n","Epoch 46/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0188 - accuracy: 0.9945 - val_loss: 0.1553 - val_accuracy: 0.9503\n","Epoch 47/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0168 - accuracy: 0.9952 - val_loss: 0.1503 - val_accuracy: 0.9584\n","Epoch 48/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0288 - accuracy: 0.9928 - val_loss: 0.1965 - val_accuracy: 0.9517\n","Epoch 49/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0371 - accuracy: 0.9878 - val_loss: 0.3970 - val_accuracy: 0.8966\n","Epoch 50/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0228 - accuracy: 0.9936 - val_loss: 0.2374 - val_accuracy: 0.9369\n","Results for fold 10\n","Epoch 1/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0221 - accuracy: 0.9914 - val_loss: 0.0690 - val_accuracy: 0.9799\n","Epoch 2/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0307 - accuracy: 0.9912 - val_loss: 0.0991 - val_accuracy: 0.9664\n","Epoch 3/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0220 - accuracy: 0.9930 - val_loss: 0.0911 - val_accuracy: 0.9718\n","Epoch 4/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0178 - accuracy: 0.9954 - val_loss: 0.1076 - val_accuracy: 0.9664\n","Epoch 5/50\n","53/53 [==============================] - 4s 79ms/step - loss: 0.0230 - accuracy: 0.9921 - val_loss: 0.1936 - val_accuracy: 0.9396\n","Epoch 6/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0208 - accuracy: 0.9939 - val_loss: 0.2312 - val_accuracy: 0.9356\n","Epoch 7/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0169 - accuracy: 0.9948 - val_loss: 0.1988 - val_accuracy: 0.9463\n","Epoch 8/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0195 - accuracy: 0.9939 - val_loss: 0.2144 - val_accuracy: 0.9423\n","Epoch 9/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0299 - accuracy: 0.9912 - val_loss: 0.3023 - val_accuracy: 0.9168\n","Epoch 10/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0308 - accuracy: 0.9911 - val_loss: 0.1462 - val_accuracy: 0.9530\n","Epoch 11/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.2136 - val_accuracy: 0.9409\n","Epoch 12/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0177 - accuracy: 0.9942 - val_loss: 0.1301 - val_accuracy: 0.9678\n","Epoch 13/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0215 - accuracy: 0.9940 - val_loss: 0.2522 - val_accuracy: 0.9262\n","Epoch 14/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0229 - accuracy: 0.9933 - val_loss: 0.1908 - val_accuracy: 0.9436\n","Epoch 15/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0170 - accuracy: 0.9943 - val_loss: 0.3820 - val_accuracy: 0.8913\n","Epoch 16/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.2200 - val_accuracy: 0.9396\n","Epoch 17/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0246 - accuracy: 0.9931 - val_loss: 0.1741 - val_accuracy: 0.9463\n","Epoch 18/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0362 - accuracy: 0.9887 - val_loss: 0.0840 - val_accuracy: 0.9772\n","Epoch 19/50\n","53/53 [==============================] - 4s 80ms/step - loss: 0.0304 - accuracy: 0.9911 - val_loss: 0.1500 - val_accuracy: 0.9530\n","Epoch 20/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.1605 - val_accuracy: 0.9530\n","Epoch 21/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0178 - accuracy: 0.9955 - val_loss: 0.2627 - val_accuracy: 0.9289\n","Epoch 22/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0260 - accuracy: 0.9917 - val_loss: 0.1759 - val_accuracy: 0.9450\n","Epoch 23/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0181 - accuracy: 0.9937 - val_loss: 0.3968 - val_accuracy: 0.9047\n","Epoch 24/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0250 - accuracy: 0.9925 - val_loss: 0.1448 - val_accuracy: 0.9503\n","Epoch 25/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 0.4026 - val_accuracy: 0.8966\n","Epoch 26/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0255 - accuracy: 0.9923 - val_loss: 0.1725 - val_accuracy: 0.9436\n","Epoch 27/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0188 - accuracy: 0.9931 - val_loss: 0.1298 - val_accuracy: 0.9584\n","Epoch 28/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0202 - accuracy: 0.9942 - val_loss: 0.0868 - val_accuracy: 0.9732\n","Epoch 29/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0222 - accuracy: 0.9937 - val_loss: 0.1627 - val_accuracy: 0.9570\n","Epoch 30/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0314 - accuracy: 0.9894 - val_loss: 0.1120 - val_accuracy: 0.9664\n","Epoch 31/50\n","53/53 [==============================] - 4s 81ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 0.0639 - val_accuracy: 0.9799\n","Epoch 32/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0199 - accuracy: 0.9942 - val_loss: 0.3253 - val_accuracy: 0.9195\n","Epoch 33/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0206 - accuracy: 0.9937 - val_loss: 0.1793 - val_accuracy: 0.9530\n","Epoch 34/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0219 - accuracy: 0.9934 - val_loss: 0.1808 - val_accuracy: 0.9503\n","Epoch 35/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0241 - accuracy: 0.9920 - val_loss: 0.1888 - val_accuracy: 0.9530\n","Epoch 36/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0222 - accuracy: 0.9930 - val_loss: 0.1740 - val_accuracy: 0.9517\n","Epoch 37/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.2141 - val_accuracy: 0.9463\n","Epoch 38/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0200 - accuracy: 0.9920 - val_loss: 0.1102 - val_accuracy: 0.9678\n","Epoch 39/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0196 - accuracy: 0.9940 - val_loss: 0.1599 - val_accuracy: 0.9503\n","Epoch 40/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.2147 - val_accuracy: 0.9490\n","Epoch 41/50\n","53/53 [==============================] - 4s 79ms/step - loss: 0.0383 - accuracy: 0.9893 - val_loss: 1.3291 - val_accuracy: 0.6980\n","Epoch 42/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0329 - accuracy: 0.9903 - val_loss: 0.0898 - val_accuracy: 0.9651\n","Epoch 43/50\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0168 - accuracy: 0.9943 - val_loss: 0.1653 - val_accuracy: 0.9490\n","Epoch 44/50\n","53/53 [==============================] - 4s 79ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 0.0802 - val_accuracy: 0.9732\n","Epoch 45/50\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0179 - accuracy: 0.9957 - val_loss: 0.1989 - val_accuracy: 0.9463\n","Epoch 46/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0183 - accuracy: 0.9951 - val_loss: 0.2052 - val_accuracy: 0.9423\n","Epoch 47/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0198 - accuracy: 0.9949 - val_loss: 0.1687 - val_accuracy: 0.9570\n","Epoch 48/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0256 - accuracy: 0.9923 - val_loss: 0.2232 - val_accuracy: 0.9329\n","Epoch 49/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.2113 - val_accuracy: 0.9423\n","Epoch 50/50\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0248 - accuracy: 0.9917 - val_loss: 0.5369 - val_accuracy: 0.8671\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":723},"id":"CAnc2SJa3o9f","executionInfo":{"status":"ok","timestamp":1632978508313,"user_tz":-360,"elapsed":3208,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"9ea643f2-74a6-441a-f799-8a299eb011e8"},"source":["acrc = model.evaluate(x_test, y_test)\n","pred = model.predict(x_test)\n","f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n","c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n","print(\"Accuracy  : {}\".format(acrc[1]))\n","print(\"F1_Score  : {}\".format(f1scr))\n","c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n","import seaborn as sns\n","figure = plt.figure(figsize=(9, 9))\n","sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n","plt.tight_layout()\n","plt.ylabel('True label')\n","plt.xlabel('Predicted label')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["59/59 [==============================] - 1s 12ms/step - loss: 0.8638 - accuracy: 0.8187\n","Accuracy  : 0.8186695575714111\n","F1_Score  : 0.8066468357543933\n"]},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAmgAAAKOCAYAAAAS8uXWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debRcVZk34N++SZA5TMkNJEGBgIwOiIjYQogigzSDgo1D+6korTZIa6uAItrYKJPiBK0gKnY7NM4oCNjKqCAgKkJAGVRIhAQZBdQkN/v7IzfhJpJB9ObspJ7HVWvdOrXr1D6sstab33v2OaXWGgAA2tHX9QQAAFiYAg0AoDEKNACAxijQAAAao0ADAGjMyK4nsDir7fh2y0vp3MzLTup6CpAkGdFXup4CJElWX6V08mVc7ZmHdVYX/PGnn1juxyxBAwBojAINAKAxzbY4AQAWKL2VKfXW0QIArAAUaAAAjdHiBADa183i0c5I0AAAGiNBAwDaZ5EAAABdkqABAO1zDhoAAF1SoAEANEaLEwBon0UCAAB0SYIGALTPIgEAALqkQAMAaIwWJwDQPosEAADokgQNAGifRQIAAHRJggYAtM85aAAAdEmBBgDQGC1OAKB9FgkAANAlCRoA0D6LBAAA6JIEDQBon3PQAADokgINAKAxWpwAQPssEgAAoEsSNACgfRI0AAC6pEADAGiMFicA0L4+10EDAKBDEjQAoH0WCQAA0CUJGgDQPvfiBACgSwo0AIDGaHECAO2zSAAAgC5J0ACA9lkkAABAlxRoAACN0eIEANpnkQAAAF2SoAEA7bNIAACALknQAID2OQcNAIAuKdAAABqjxQkAtM8iAQAAuiRBAwDaZ5EAAABdkqABAO1zDhoAAF1SoAEANEaLEwBon0UCAAB0SYIGALRPggYAQJcUaAAAjdHiBADa5zpoAAB0SYIGALTPIgEAALokQQMA2uccNAAAuqRAAwBojBYnANA+iwQAAOiSBA0AaJ9FAgAAdEmCBgA0r0jQAADokgINAKAxWpwAQPO0OAEA6JQEDQBoX28FaBI0AIDWKNAAABqjxQkANM8iAQAAOiVBAwCaJ0EDAKBTEjQAoHkSNAAAOqVAAwBojBYnANA8LU4AADolQQMA2tdbAZoEDQCgNRK0FdTuOz01p/z7fhnR15fPfevHOeXzFy/0+sbj1s0n3/OybLDOGrn/oT/mde/9YqbPfDBJ8vCVJ+WG2+5Kktx59wM56O2fXe7zZ8X1ox9enlNO/EDmzp2b/Q84MK855A0LvT5r1qy8991H5qabpmb06HXywZM+nI3Gj88Nv7g+H3j/e5MktdYc+sZ/zW4v2D13331X3vvuo3LfffemJDngwJfl5a98dQdHxormh1dcnpNPPD5zB+Zm/5ccmNe9/tCFXp81a1be864jc9PUGzN6nXVy4skfzkbjJ+SBB+7PO952RG684Ybsu9/+Oerdxy54z3fP/04+c+anUkrJmLFj858fPDnrrrvu8j40HkevnYOmQFsB9fWVfOSdB+TFh52R6TMfzBVnH5HvXD41N/96xoIxHzxin3zh/J/kC+ddm113mJTj3rx3Dnnfl5Ikf/zz7Oz0qlO7mj4rsIGBgZz4gffntE+dlf7+/rz6FS/LLpN3y6abTVow5lvf+GrWWnt0vvmdC3Phd8/Lxz9ySj548qmZNGnzfP6LX8nIkSPz+3tm5uUHHZDn77pbRo4Ykbe+/Z3Zcqtt8sgjj+SfD35pnrPTzgvtExY1MDCQE44/Lv91xmfSP64/rzz4oOy625RsNuR7882vfzVrrb12zj3/olzw3fPy0VM/lBNPOTVPWuVJefNhR+TWW2/Jbbf8asH4OXPm5OQTP5CvffO8rLvuuvnIh0/O/37pf/LGNx/exSHS47Q4V0DP3mbj3Dbt3vzmd/dl9pyBfOWin2WfXbZZaMyWm/Tn0mtuSZJceu2tf/E6PBE33nB9Jk7cOBMmTMyoUavkRXvunUsv+cFCYy69+AfZZ9/9kiQv2H2PXH31Vam1ZtXVVsvIkfP+TfjnP89a8K/hDcaMzZZbzft+rrHGGnnKpptl5swZgSW54RfXZ+LGG2fCxHnfxT322juXXPz9hcZccvH384/77p8keeHue+TqH1+ZWmtWW331PHP7Z+VJq6yy0Phaa2qt+eMfH02tNQ8//HDGjBm73I4Jhhq2Aq2UsmUp5chSyscGH0eWUrYars/rJRuNGZ1pMx5Y8Hz6zAcyfszohcb84pbfZb/dtkuS7Dd526y95qpZb/TqSZJVVxmZK84+IpeedXj+cVeFG8tu5syZ6R83bsHzsWP7M3PGjEXGzEj/uA2TJCNHjsyaa66VBx+Y93294fqf52UH7JODD9wvRx/z3gUF23y/mz49v7z5pmy73dOH+UhY0Q39niVJf/+43PMX38WZGbfId/GBBx7I4owaNSrvOua9edlL9s2LpuyS22+7Lfu/5MDhOQD+aqWUzh5dGJYCrZRyZJIvZ96ai6sHHyXJl0opRy3hfYeWUq4tpVw7Z+b1wzG1nnH0R7+T52+/Wa7877fm+dtvlukzHsjAwNwkyVP3Oz7/8P8+mv/3ni/k5Lful03Gr9/xbOkV2z7t6TnnG9/J5794Tj571pn585//vOC1Rx99JO/897fk399xVNZcc80OZ0mvmj17dr56zpfzpa98Ixf94LJsscUW+cynz+h6WvSo4ToH7ZAk29RaZw/dWEr5cJIbk5zweG+qtZ6R5IwkWW3Ht9dhmtsK73f3PJgJ/esseD5+7DqZfs+DC4256/cP5eAjz06SrLHaKtl/t+3y4MN/Gnz/Q0mS3/zuvlx23W15xlPH59fT711Os2dFNnbs2My4++4Fz2fOnJGx/f2LjOnPjLvvSn//uMyZMycPP/yHjF5nnYXGbLLpZll99dVz2623ZOttts2c2bPzzrcdkT33/sdMeeGLlsuxsGKb/z2bb8aMuzPmL76LY3P33Xelf9xj38V1FvkuDvWrX96cJJk4ceMkye577JXPnnXmMMyeJ6LXFgkMV4tzbpKNHmf7hoOv8Te4duqdmTRxgzx5o/UyauSIHPSiZ+S8y29caMz6o1df8GV+x2um5OxvX5MkWWet1bLKqBELxjz3aU/JTb92vg/LZutttsudd/w206dNy+zZs3LRBednl113W2jMLpN3y3fO/VaS5PvfuzDP3nGnlFIyfdq0zJkzJ0ly1++m5ze/uT0bbTQ+tdYc975jssmmm+ZVr37N8j4kVlDbbLtd7vjtY9/FC797fiZPnrLQmF0nT8m3z/1mkuT/hnwXF2fM2LG5/bbbct999yVJrrryR9lk002H7yBYaZRS9iyl/LKUcuvjdQpLKRuXUi4upfy0lHJ9KWXvpe1zuBK0f0vy/VLKLUnuHNy2cZJJSQ4bps/sGQMDc/PWk7+Rb3/sDRnRV3L2t6/JTbfPyHsO3SPX3XRnzrt8anZ51qQc9+a9UpNc8dPb828nfT1JsuVTxubjRx+YubWmr5Sc8vmLF1r9CUsycuTIvOPoY3L4m16fgblzs+/+L8lmkzbPJ0/7WLbaZtvsOnlK9jvgwBz77iOz/z57ZO21R+cDJ30oSfKzn/4kZ3/mzIwcNSqllBz1rmOzzrrr5mfX/STnf+fcTNp8i7ziZQckSd58+L/lH56/a5eHSuNGjhyZI9/1nrz5jYdk7sDc7HfAS7PZpM1z+ic+lq232TaTd5uS/V9yYI45+p3Zd+8XZe3Ro3PCSR9e8P6995iSRx5+JLNnz87FP/h+Tj/jrGy22aQc+qZ/zetf86qMHDkyG260Uf7jPz/Y4VGyIiiljEhyWpLdk0xLck0p5dxa69Qhw45Jck6t9b9KKVsnOT/JU5a431qHp5NYSulLsmOS8YObpie5ptY6sCzv1+KkBTMvO6nrKUCSZERfb7V3aNfqq3TTa1z/1V/qrC649/MvX+wxl1Kem+R9tdY9Bp8fnSS11g8OGfOpJLfXWk8cHP+hWuvOS/rMYbsOWq11bpKrhmv/AAANGJ/HuoXJvBTtOYuMeV+Si0ophydZI8kLl7ZT10EDANpXunsMvcrE4GPh21Ys3cuTfK7WOiHJ3kn+e7DTuFjuJAAAsARDrzLxOKYnmTjk+YTBbUMdkmTPwX1dWUpZNckGSWYu7jMlaABA8xq+UO01STYvpWxSSlklycFJzl1kzB1JXjB4HFslWTXJPUvaqQINAOAJqrXOybwrVFyY5KbMW615YynluFLKvoPD/j3JG0opP0/ypSSvqUtZpanFCQDwN6i1np95l84Yuu3YIX9PTfK8v2afCjQAoHnuJAAAQKckaABA8yRoAAB0SoEGANAYLU4AoH291eGUoAEAtEaCBgA0zyIBAAA6JUEDAJonQQMAoFMKNACAxmhxAgDN0+IEAKBTEjQAoHkSNAAAOiVBAwDa11sBmgQNAKA1CjQAgMZocQIAzbNIAACATknQAIDmSdAAAOiUAg0AoDFanABA87Q4AQDolAQNAGhfbwVoEjQAgNZI0ACA5jkHDQCATinQAAAao8UJADRPixMAgE5J0ACA5knQAADolAQNAGieBA0AgE4p0AAAGqPFCQC0r7c6nBI0AIDWSNAAgOZZJAAAQKcUaAAAjdHiBACap8UJAECnJGgAQPN6LECToAEAtEaCBgA0zzloAAB0SoEGANAYLU4AoHk91uGUoAEAtEaCBgA0zyIBAAA6pUADAGiMFicA0Lwe63BK0AAAWiNBAwCa19fXWxGaBA0AoDESNACgec5BAwCgUwo0AIDGaHECAM1zJwEAADolQQMAmtdjAZoEDQCgNRI0AKB5zkEDAKBTCjQAgMZocQIAzdPiBACgUxI0AKB5PRagSdAAAFqjQAMAaIwWJwDQPIsEAADolAQNAGhejwVoEjQAgNZI0ACA5jkHDQCATinQAAAao8UJADSvxzqcEjQAgNZI0ACA5lkkAABApyRoAEDzeixAk6ABALRGgQYA0BgtTgCgeRYJAADQqWYTtHsuP7nrKUDG7HR411OAJMn913yi6ylAp3osQJOgAQC0RoEGANCYZlucAADzWSQAAECnJGgAQPN6LECToAEAtEaCBgA0zzloAAB0SoEGANAYLU4AoHk91uGUoAEAtEaCBgA0zyIBAAA6pUADAGiMFicA0DwtTgAAOiVBAwCa12MBmgQNAKA1EjQAoHnOQQMAoFMKNACAxmhxAgDN67EOpwQNAKA1EjQAoHkWCQAA0CkJGgDQvB4L0CRoAACtUaABAPwNSil7llJ+WUq5tZRy1GLGvKyUMrWUcmMp5YtL26cWJwDQvL5Ge5yllBFJTkuye5JpSa4ppZxba506ZMzmSY5O8rxa6/2llLFL268EDQDgidsxya211ttrrbOSfDnJfouMeUOS02qt9ydJrXXm0naqQAMAmldKl49yaCnl2iGPQ4dMbXySO4c8nza4bagtkmxRSvlhKeWqUsqeSzteLU4AgCWotZ6R5Iy/YRcjk2yeZHKSCUkuK6VsV2t9YHFvkKABADxx05NMHPJ8wuC2oaYlObfWOrvW+uskv8q8gm2xFGgAQPNKKZ09luKaJJuXUjYppayS5OAk5y4y5puZl56llLJB5rU8b1/SThVoAABPUK11TpLDklyY5KYk59RabyylHFdK2Xdw2IVJ7i2lTE1ycZJ31FrvXdJ+nYMGADSvr82rbCRJaq3nJzl/kW3HDvm7Jnnb4GOZSNAAABojQQMAmrcM54KtVCRoAACNUaABADRGixMAaF6PdTglaAAArZGgAQDNK+mtCE2CBgDQGAkaANC8li9UOxwkaAAAjVGgAQA0RosTAGieOwkAANApCRoA0LweC9AkaAAArVGgAQA0RosTAGheX4/1OCVoAACNkaABAM3rsQBNggYA0BoJGgDQPBeqBQCgUwo0AIDGaHECAM3rsQ6nBA0AoDUSNACgeS5UCwBApxRoAACN0eIEAJrXWw1OCRoAQHMkaABA89xJAACATknQAIDm9fVWgCZBAwBojQINAKAxWpwAQPMsEgAAoFMSNACgeT0WoEnQAABaI0EDAJrnHDQAADqlQAMAaIwWJwDQvF67k8BiC7RSyseT1MW9Xmt9y7DMCACgxy0pQbt2uc0CAGAJem2RwGILtFrr2UOfl1JWr7U+OvxTAgDobUtdJFBKeW4pZWqSmwefP72UcvqwzwwAoEctyyrOjyTZI8m9SVJr/XmSXYZzUgAAQ5UOH11Ypsts1FrvXGTTwDDMBQCALNtlNu4speycpJZSRiU5IslNwzstAIDH9PXYIoFlSdDemORfk4xP8rskzxh8DgDAMFhqglZr/X2SVy6HuQAAPK4eC9CWaRXnpqWUb5dS7imlzCylfKuUsunymBwAQC9alhbnF5Ock2TDJBsl+UqSLw3npAAAetmyFGir11r/u9Y6Z/DxP0lWHe6JAQDMV0rp7NGFJd2Lc73BP79bSjkqyZcz796c/5Tk/OUwNwCAnrSkRQI/ybyCbH7p+C9DXqtJjh6uSQEADNVriwSWdC/OTZbnRAAAmGdZLlSbUsq2SbbOkHPPaq2fH65JAQAM1WsXql1qgVZKeW+SyZlXoJ2fZK8kVyRRoAEADINlWcV5YJIXJLm71vraJE9PMnpYZwUA0MOWpcX5x1rr3FLKnFLK2klmJpk4zPPicfzoistzyonHZ2Du3Oz/kgPz2kMOXej1WbNm5dh3H5mbpt6Y0aPXyQknfzgbjZ+Qq678YT7+kQ9l9uzZGTVqVI542zuz43N2SpIc+rp/zu/vuSdPWnVe9/q0T56V9dZff7kfGyum3XfeKqe848CM6OvL5775o5zy2e8t9PrGG66bT773Vdlg3TVz/0OP5nXvPjvTZz6QXXbYPCe9/aULxj31Kf159VGfzbcvuX55HwIrsB9efllOPOH4zB2YmwNeelAOecNf/ia+++h35qYbb8zoddbJSR86NePHT0iSnHXmp/KNr301fSP6cuTRx+R5//D8JMleu0/J6muskRF9fRkxckS+dM7Xl/tx8fh6rMO5TAXataWUdZKcmXkrOx9OcuWwzoq/MDAwkBM+cFxOP+Mz6e/vzz+//KDsOnlKNt1s0oIx3/z6V7P22mvnW+ddlAu/e14+9pEP5YSTT80666ybj3z8vzJmbH9uveVXOexNr88F/3fZgvf95wknZ+tttuvisFiB9fWVfOSol+XFb/pEps94IFd84R35zqW/yM23371gzAffekC+cN7V+cK3f5xdn71Fjjt83xzyns/nsmtvyU4Hn5AkWXft1XPDue/N/111U1eHwgpoYGAgHzj+uHzqzM+mv78/r/inAzN5tynZbNJjv4nf+NpXsvbaa+c7F3wv3z3/vHzkw6fk5A99JLfdemsuOP+8fP3c8zJz5oz8y+tfm3PPuzAjRoxIknz6s2dn3XXXW9xHw3Kx1BZnrfXNtdYHaq2fTLJ7kv832OpkObrxhuszceONM2HCxIwatUpetOfeueTi7y805tJLvp999t0/SfKC3ffI1T++MrXWbLnV1hkztj9JstmkzfPnP/05s2bNWu7HwMrl2ds+Jbfd+fv8Zvq9mT1nIF+58LrsM/lpC43ZctMNc+nVv0ySXHrNr7LP5L/8h8ABL3xmLvrh1PzxT7OXy7xZOdzwi+szceKTM2HixIxaZZXsufeL/+I38eIf/CD77ndAkmT3F+2Rq6+a95t4ycXfz557vzirrLJKJkyYmIkTn5wbfiG9bV2vXah2sQVaKWX7RR9J1ksycvBvlqOZM2akv3/DBc/7+8flnpkzFhpzz4yZC8aMHDkya665Vh544IGFxnz/exdmy622ziqrrLJg2/ve8668/KD9c+anTk+tdRiPgpXJRmNHZ9qM+xc8nz7j/owfs/Dpqb/41fTsN+UZSZL9pjw9a6+5WtYbvcZCYw7aY/ucc8FPhn/CrFRmzpiRcRuOW/B8bH9/ZsxY+Ddx5swZGTduyG/iWmvlgQfuz4wZM9I/7rH39o/rz8z57y3JG99wSA4+6CX56jn/O/wHAouxpBbnh5bwWk0y5Yl8YCnltbXWzy7mtUOTHJokH/3EJ/O61x/6eMN4gm679ZZ87CMfymmfOmvBtv/84CkZ29+fRx55OO9421ty3re/tSCFg7/V0ad+I6ceeVBete9z8sPrbs30GfdnYGDugtfHbbB2ttl8o3zvyqkdzhIe87n//lL6+/tz77335o2vf2022XTTPGuHZ3c9LXrQki5Uu9swfeZ/JHncAq3WekaSM5Lk4T+Lcoaa96/DuxY8nzHj7gVty/nG9I/NjBl3pX/cuMyZMycPP/yHrLPOOvPG33133v7Ww3Lc8Sdm4sSNF9pvkqyxxprZc+99cuMN1yvQWCa/m/lgJvSvu+D5+P51M/2eBxcac9c9D+bgt386SbLGaqtk/xc8Iw8+/McFr7909+1z7g+uz5w5cwN/jbH9/bn7rsfOd5zXZVj4N3Hs2P7cffeQ38Q//CHrrLNu+vv7M+Pux9474+4ZC34L5+9j/fXXz5QX7p4bfnG9Aq0Ry3LZiZXJsBxvKeX6xTx+kaR/qTvgL2y9zXa587e/zfRp0zJ79qxcdMH52XXywiHmrpOn5DvnfjPJvFbms3fcKaWU/OGhh3LEYf+Sw4/49zzjmY91p+fMmZP775/Xopo9e3auuPSSbDZpi+V3UKzQrr3xt5m08Zg8eaP1M2rkiBy0x/Y5b5FVmOuvs8aC8zfe8bo9cva3rlro9Zft+aycc8G1y23OrDy22Xa73HHHbzJt2p2ZPWtWLjj/vOy628K/iZN3m5Jzv/WNJMn3LrowOz5n3m/irrtNyQXnn5dZs2Zl2rQ7c8cdv8m22z0tjz76aB555OEkyaOPPporf/TDTJq0+XI/NkiW8U4CT0B/kj2S3L/I9pLkR8P0mSu1kSNH5p3vek8Oe9MhGRiYm/32f2k2m7R5/uu0j2XrrbfNrrtNyX4HHJj3vOud2e/FL8ro0aPzgZM+nCT53y9/IXfecUfO/NTpOfNTpyeZdzmN1VZbLYe98ZDMmTMnc+fOzY7PeW4OeOlBXR4mK5CBgbl564nn5Nun/2tG9JWc/a2rctPtd+c9b3pxrpt6R8679BfZZYfNc9zh+6bW5Irrbs2/ffCcBe/feMP1MmHcurn8J7d2eBSsqEaOHJmj331s3nTo6zN37kD2P+ClmTRp85z28Y9mm222zeQpL8gBLz0w7z7qHdlnz92z9ujROemUU5MkkyZtnhftuVcO2HfvjBgxIu865tiMGDEi9917b976ln9NkswZGMjeL94nz3v+Ll0eJkN0dbJ+V8pwnBReSjkryWdrrVc8zmtfrLW+Ymn70OKkBWN2OrzrKUCS5P5rPtH1FCBJsurIdFIpveWbN3dWF3xs/y2X+zEvy62eSpJXJtm01npcKWXjJONqrVcv7j211kOW8NpSizMAgKH6eitAW6Zz0E5P8twkLx98/ockpw3bjAAAetyynIP2nFrr9qWUnyZJrfX+UsoqS3sTAABPzLIUaLNLKSMy79pnKaWMSWJNPACw3Ghx/qWPJflGkrGllOOTXJHkA8M6KwCAHrbUBK3W+oVSyk+SvCDzLpOxf63VXY0BgOWm1y6zsSyrODdO8miSbw/dVmu9YzgnBgDQq5blHLTzMu/8s5Jk1SSbJPllkm2GcV4AAD1rWVqc2w19XkrZPsmbh21GAACLsEhgKWqt1yV5zjDMBQCALNs5aG8b8rQvyfZJfjdsMwIAWESPrRFYpnPQ1hry95zMOyfta8MzHQAAlligDV6gdq1a69uX03wAAP5CX49FaIs9B62UMrLWOpDkectxPgAAPW9JCdrVmXe+2c9KKecm+UqSR+a/WGv9+jDPDQCgJy3LOWirJrk3yZQ8dj20mkSBBgAsF3/1ZSdWcEsq0MYOruC8IY8VZvPVYZ0VAEAPW1KBNiLJmlm4MJtPgQYALDc9tkZgiQXaXbXW45bbTAAASLLkAq3HalUAoFUus/GYFyy3WQAAsMBiC7Ra633LcyIAAMyzLJfZAADoVI91OHvusiIAAM2ToAEAzeuToAEA0CUFGgBAY7Q4AYDmuQ4aAACdkqABAM3rsQBNggYA0BoJGgDQPJfZAACgUwo0AIDGaHECAM0r6a0epwQNAKAxEjQAoHkWCQAA0CkJGgDQPAkaAACdUqABADRGixMAaF7psZtxStAAABojQQMAmmeRAAAAnVKgAQA0RosTAGhej60RkKABAPwtSil7llJ+WUq5tZRy1BLGvbSUUkspOyxtnxI0AKB5fY1GaKWUEUlOS7J7kmlJrimlnFtrnbrIuLWSHJHkx8uyXwkaAMATt2OSW2utt9daZyX5cpL9Hmfc+5OcmORPy7JTBRoA0Ly+0t2jlHJoKeXaIY9Dh0xtfJI7hzyfNrhtgVLK9kkm1lrPW9bj1eIEAFiCWusZSc54Iu8tpfQl+XCS1/w175OgAQA8cdOTTBzyfMLgtvnWSrJtkktKKb9JslOSc5e2UECCBgA0r9E1AklyTZLNSymbZF5hdnCSV8x/sdb6YJIN5j8vpVyS5O211muXtFMJGgDAE1RrnZPksCQXJrkpyTm11htLKceVUvZ9ovuVoAEAzetLuxFarfX8JOcvsu3YxYydvCz7lKABADRGggYANK/hc9CGhQQNAKAxCjQAgMZocQIAzevT4gQAoEsSNACgeX09tkpAggYA0BgFGgBAY7Q4AYDm9ViHU4IGANAaCRoA0DyLBAAA6JQEDQBoXo8FaBI0AIDWKNAAABqjxQkANK/XEqVeO14AgOZJ0ACA5pUeWyUgQQMAaIwCDQCgMVqcAEDzeqvBKUEDAGiOBA0AaJ57cQIA0CkJGgDQvN7KzyRoAADNUaABADRGixMAaF6PrRGQoAEAtEaCBgA0z704AQDolAQNAGheryVKvXa8AADNU6ABADRGixMAaJ5FAgAAdEqCBgA0r7fyMwkaAEBzFGgAAI1ptsX5wKOzu54C5KpzP9j1FCBJ8oxjLux6CpAkufmEPTr5XIsEAADoVLMJGgDAfL2WKPXa8QIANE+CBgA0zzloAAB0SoEGANAYLU4AoML/EB0AABACSURBVHm91eCUoAEANEeCBgA0r8fWCEjQAABaI0EDAJrX12NnoUnQAAAao0ADAGiMFicA0DyLBAAA6JQEDQBoXrFIAACALinQAAAao8UJADTPIgEAADolQQMAmudOAgAAdEqCBgA0zzloAAB0SoEGANAYLU4AoHlanAAAdEqCBgA0z704AQDolAINAKAxWpwAQPP6eqvDKUEDAGiNBA0AaJ5FAgAAdEqCBgA0z4VqAQDolAINAKAxWpwAQPMsEgAAoFMSNACgeS5UCwBApyRoAEDznIMGAECnFGgAAI3R4gQAmudOAgAAdEqCBgA0r8cCNAkaAEBrFGgAAI3R4gQAmtfXY6sEJGgAAI2RoAEAzeut/EyCBgDQHAkaANC+HovQJGgAAI1RoAEANEaLEwBoXumxHqcEDQCgMRI0AKB5PXadWgkaAEBrJGgAQPN6LECToAEAtEaBBgDQGC1OAKB9PdbjlKABADRGggYANM+FagEA6JQCDQCgMVqcAEDz3EkAAIBOSdAAgOb1WIAmQQMAaI0EDQBoX49FaBI0AIDGKNAAABqjxQkANM+dBAAAWGallD1LKb8spdxaSjnqcV5/Wyllainl+lLK90spT17aPhVoAEDzSunuseR5lRFJTkuyV5Ktk7y8lLL1IsN+mmSHWuvTknw1yUlLO14FGgDAE7djkltrrbfXWmcl+XKS/YYOqLVeXGt9dPDpVUkmLG2nCjQAgCdufJI7hzyfNrhtcQ5J8t2l7dQiAQCgeV0uESilHJrk0CGbzqi1nvEE9vOqJDsk2XVpYxVoAABLMFiMLa4gm55k4pDnEwa3LaSU8sIk706ya631z0v7TAUaANC+dq+ycU2SzUspm2ReYXZwklcMHVBKeWaSTyXZs9Y6c1l26hw0AIAnqNY6J8lhSS5MclOSc2qtN5ZSjiul7Ds47OQkayb5SinlZ6WUc5e2XwkaANC8li9UW2s9P8n5i2w7dsjfL/xr9ylBAwBojAINAKAxWpwAQPOWdkX/lY0EDQCgMRI0AKB5PRagSdAAAFojQQMA2tdjEZoEDQCgMQo0AIDGaHECAM1r+U4Cw0GCBgDQGAkaANC8XrtQrQJtJXD1lVfktFNPzNy5A9l735fk5a9+/UKvX//Ta3PaqSfl9tt+lWPef1J2nfKijmbKyuZnV/8onz39lMydOzcv2Gv/7P/y1yz0+tTrr8vZp38ov7391vzbMcdnp10eu1/w/5z5sfz0x1ckSV76ytdn5918L/n7+IctNsi7/3HL9JWSr14zLWde+uuFXj9qn6fmOZuulyRZbdSIrLfmKtnxP37QxVRhsRRoK7iBgYF87JTjc9LHzsiYsePy5tcenOc+f7c8ZZPNFowZ279h3vme9+crXzy7w5myspk7MJCzPn5ijjnxtKw/pj9H/+urs8POu2TCkzddMGaDsePy5ne+L98+578Xeu91V12RX99yc0761Bcze9bs/Me//0uesePOWX2NNZf3YbCS6SvJsfttldeddW1mPPinfOWw5+YHN83MbTMfWTDmhO/8csHfr9p542y10VpdTBWWyDloK7ibp/4i4ydsnI3GT8yoUaOy2+575UeXXbzQmHEbjc9mmz81pdfyYYbVrb+8MeM2mpj+jSZk5KhR2Xnyi3LNDy9daMzYcRvlyZtuntK38E/NtN/enq2etn1GjBiZVVdbLRtvOik/u+bK5Tl9VlJPmzg6d9z7aKbd98fMHqg5/+d35QVbj13s+Bc/fVzO+9ndy3GGPFGlw0cXhq1AK6VsWUp5QSllzUW27zlcn9mLfn/PzIwZO27B8zFj+/P7e2Z0OCN6xX2/n5n1x/YveL7+mLG5796Zy/TeJ2+2RX5+zY/y5z/9KQ89+EBu/NlPcq/vLX8H/Wuvmrse/NOC53c/+Kf0r73q447daJ1VM37d1XPVbfcur+nBMhuWAq2U8pYk30pyeJIbSin7DXn5A0t436GllGtLKdd+4XOfHo6pAQ14+g475Zk7Pi/HHPG6fPT4d2WLrbdLX59An+Vr76dvmItuuDtza9czYZn0WIQ2XOegvSHJs2qtD5dSnpLkq6WUp9RaP5olHGqt9YwkZyTJtPtn+b/MMthgzNjcM/OxeP6emTOywZj+JbwD/j7W22Bs7p35WOp17z0zs976i28lLeolrzwkL3nlIUmSjx7/7mw4YeO/+xzpPTMe+lM2HP1YYjZu9KqZ8dCfHnfs3k8fl/d/86blNTX4qwzXP1n7aq0PJ0mt9TdJJifZq5Ty4fTc3bSG15ZbbZvpd/42d/1uWmbPnp2Lv/fd7Pz8yV1Pix6w2VO3zl3T78zMu6ZnzuzZ+dElF2WHnXdZpvfOHRjIHx58IEny29tvyR2/viVP32Gn4ZwuPeIX0x7Kk9dfPePXXS2jRpTs/fQN84Opf9l632TMGhm92qj89I4HOpglT0Tp8H9dGK4EbUYp5Rm11p8lyWCStk+SzyTZbpg+syeNGDkyh7/9XTnyiDdm7tyB7LXPAXnKppPy2TM+kaduuU123mW33Dz1hrz3yCPy8B/+kCuvuDRnn3l6PvOlb3Y9dVZwI0aMzOsOf0eOP+rwzJ07kN323DcTn7JZ/vdzn8xmW2yVHXbeNbfefGNOed878sjDD+UnV16ec84+Ix8+65zMGZiTY9/6hiTJ6quvkcOPen9GjLConL/dwNya9597U8563bPS11fytWun59aZj+Tw3SflhmkP5uKb7kkyuDjg53d1PFtYvFLr37+TWEqZkGROrfUvlsaUUp5Xa/3h0vahxUkL7n34z11PAZIk/3Taj7qeAiRJbj5hj04ipZvverSzumDLDVdf7sc8LP9krbVOW8JrSy3OAACG6rUrRVk2BQDQGCd9AADN67EATYIGANAaCRoA0L4ei9AkaAAAjVGgAQA0RosTAGheV1f074oEDQCgMRI0AKB5LlQLAECnFGgAAI3R4gQAmtdjHU4JGgBAayRoAED7eixCk6ABADRGggYANM+FagEA6JQCDQCgMVqcAEDz3EkAAIBOSdAAgOb1WIAmQQMAaI0CDQCgMVqcAED7eqzHKUEDAGiMBA0AaJ47CQAA0CkJGgDQPBeqBQCgUwo0AIDGaHECAM3rsQ6nBA0AoDUSNACgeRYJAADQKQkaALAC6K0ITYIGANAYBRoAQGO0OAGA5lkkAABApyRoAEDzeixAk6ABALRGgQYA0BgtTgCgeRYJAADQKQkaANC80mPLBCRoAACNkaABAO3rrQBNggYA0BoFGgBAY7Q4AYDm9ViHU4IGANAaCRoA0DwXqgUAoFMSNACgeS5UCwBApxRoAACN0eIEANrXWx1OCRoAQGskaABA83osQJOgAQC0RoEGANAYLU4AoHnuJAAAQKckaABA89xJAACATknQAIDmOQcNAIBOKdAAABqjQAMAaIwCDQCgMRYJAADNs0gAAIBOSdAAgOa5UC0AAJ1SoAEANEaLEwBonkUCAAB0SoIGADSvxwI0CRoAQGsUaAAAjdHiBADa12M9TgkaAEBjJGgAQPPcSQAAgE5J0ACA5rlQLQAAnVKgAQA0RosTAGhej3U4JWgAAK2RoAEA7euxCE2CBgDQGAUaAEBjtDgBgOa5kwAAAJ2SoAEAzXMnAQAAOlVqrV3PgWFSSjm01npG1/MA30Va4HvIikSCtnI7tOsJwCDfRVrge8gKQ4EGANAYBRoAQGMUaCs351rQCt9FWuB7yArDIgEAgMZI0AAAGqNAAwBojAJtJVVK2bOU8stSyq2llKO6ng+9qZTymVLKzFLKDV3Phd5VSplYSrm4lDK1lHJjKeWIrucES+MctJVQKWVEkl8l2T3JtCTXJHl5rXVqpxOj55RSdknycJLP11q37Xo+9KZSyoZJNqy1XldKWSvJT5Ls7zeRlknQVk47Jrm11np7rXVWki8n2a/jOdGDaq2XJbmv63nQ22qtd9Varxv8+w9JbkoyvttZwZIp0FZO45PcOeT5tPgxAkgp5SlJnpnkx93OBJZMgQZATyilrJnka0n+rdb6UNfzgSVRoK2cpieZOOT5hMFtAD2plDIq84qzL9Rav971fGBpFGgrp2uSbF5K2aSUskqSg5Oc2/GcADpRSilJzkpyU631w13PB5aFAm0lVGudk+SwJBdm3smw59Rab+x2VvSiUsqXklyZ5KmllGmllEO6nhM96XlJ/jnJlFLKzwYfe3c9KVgSl9kAAGiMBA0AoDEKNACAxijQAAAao0ADAGiMAg0AoDEKNFgJlVIGBi8lcEMp5SullNX/hn19rpRy4ODfny6lbL2EsZNLKTs/gc/4TSllg2XdvsiYh//Kz3pfKeXtf+0cAZYnBRqsnP5Ya31GrXXbJLOSvHHoi6WUkU9kp7XW19dapy5hyOQkf3WBBsDCFGiw8rs8yaTBdOvyUsq5SaaWUkaUUk4upVxTSrm+lPIvybyrrpdSPlFK+WUp5f+SjJ2/o1LKJaWUHQb/3rOUcl0p5eellO8P3oT6jUneOpjePb+UMqaU8rXBz7imlPK8wfeuX0q5qJRyYynl00nK0g6ilPLNUspPBt9z6CKvnTq4/fullDGD2zYrpVww+J7LSylb/j3+YwIsD0/oX9HAimEwKdsryQWDm7ZPsm2t9deDRc6DtdZnl1KelOSHpZSLkjwzyVOTbJ2kP8nUJJ9ZZL9jkpyZZJfBfa1Xa72vlPLJJA/XWk8ZHPfFJKfWWq8opWyceXe32CrJe5NcUWs9rpTy4iTLcoeB1w1+xmpJrimlfK3Wem+SNZJcW2t9aynl2MF9H5bkjCRvrLXeUkp5TpLTk0x5Av8ZAZY7BRqsnFYrpfxs8O/LM+8+hDsnubrW+uvB7S9K8rT555clGZ1k8yS7JPlSrXUgye9KKT94nP3vlOSy+fuqtd63mHm8MMnW826FmCRZu5Sy5uBnvGTwveeVUu5fhmN6SynlgMG/Jw7O9d4kc5P87+D2/0ny9cHP2DnJV4Z89pOW4TMAmqBAg5XTH2utzxi6YbBQeWTopiSH11ovXGTc3/MehX1Jdqq1/ulx5rLMSimTM6/Ye26t9dFSyiVJVl3M8Dr4uQ8s+t8AYEXhHDToXRcmeVMpZVSSlFK2KKWskeSyJP80eI7ahkl2e5z3XpVkl1LKJoPvXW9w+x+SrDVk3EVJDp//pJQyv2C6LMkrBrftlWTdpcx1dJL7B4uzLTMvwZuvL8n8FPAVmdc6fSjJr0spBw1+RimlPH0pnwHQDAUa9K5PZ975ZdeVUm5I8qnMS9W/keSWwdc+n+TKRd9Ya70nyaGZ1078eR5rMX47yQHzFwkkeUuSHQYXIUzNY6tJ/yPzCrwbM6/VecdS5npBkpGllJuSnJB5BeJ8jyTZcfAYpiQ5bnD7K5McMji/G5Pstwz/TQCaUGqtXc8BAIAhJGgAAI1RoAEANEaBBgDQGAUaAEBjFGgAAI1RoAEANEaBBgDQmP8Pw4JCYPQM+agAAAAASUVORK5CYII=\n","text/plain":["<Figure size 648x648 with 2 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"e1ypZ2NnYxes"},"source":["# **Arousal**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B7fcxLuwZpkK","outputId":"84fae40f-6f12-4c72-fdd4-e6291d667673"},"source":["#arousal\n","X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n","print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4iz5mTT7Zwcp","outputId":"ec2577b5-6ac2-45f6-e53e-308b7afb1900"},"source":["foldNum=0\n","model = get_model()\n","for train_index, val_index in kfold.split(X_train, Y_train):\n","  foldNum = foldNum + 1\n","  print(\"Results for fold\",foldNum)\n","  x_train, x_val = X_train[train_index], X_train[val_index]\n","  y_train, y_val = Y_train[train_index], Y_train[val_index]\n","  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n","  gc.collect() # Garbage collecter\n","  del x_train, x_val, y_train, y_val\n","  gc.collect()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Results for fold 1\n","Epoch 1/50\n","53/53 [==============================] - 4s 53ms/step - loss: 1.2166 - accuracy: 0.4003 - val_loss: 1.0597 - val_accuracy: 0.4625\n","Epoch 2/50\n","53/53 [==============================] - 2s 42ms/step - loss: 1.0764 - accuracy: 0.4736 - val_loss: 1.0714 - val_accuracy: 0.4625\n","Epoch 3/50\n","53/53 [==============================] - 2s 42ms/step - loss: 1.0576 - accuracy: 0.4859 - val_loss: 1.0639 - val_accuracy: 0.4625\n","Epoch 4/50\n","53/53 [==============================] - 2s 42ms/step - loss: 1.0569 - accuracy: 0.4890 - val_loss: 1.0627 - val_accuracy: 0.4625\n","Epoch 5/50\n","53/53 [==============================] - 2s 42ms/step - loss: 1.0550 - accuracy: 0.4836 - val_loss: 1.0570 - val_accuracy: 0.4625\n","Epoch 6/50\n","53/53 [==============================] - 2s 42ms/step - loss: 1.0480 - accuracy: 0.4808 - val_loss: 1.0579 - val_accuracy: 0.4625\n","Epoch 7/50\n","53/53 [==============================] - 2s 42ms/step - loss: 1.0529 - accuracy: 0.4797 - val_loss: 1.0598 - val_accuracy: 0.4625\n","Epoch 8/50\n","53/53 [==============================] - 2s 41ms/step - loss: 1.0494 - accuracy: 0.4702 - val_loss: 1.0536 - val_accuracy: 0.4625\n","Epoch 9/50\n","53/53 [==============================] - 2s 42ms/step - loss: 1.0430 - accuracy: 0.4769 - val_loss: 1.0530 - val_accuracy: 0.4625\n","Epoch 10/50\n","53/53 [==============================] - 2s 41ms/step - loss: 1.0453 - accuracy: 0.4768 - val_loss: 1.0496 - val_accuracy: 0.4625\n","Epoch 11/50\n","53/53 [==============================] - 2s 42ms/step - loss: 1.0400 - accuracy: 0.4783 - val_loss: 1.0455 - val_accuracy: 0.4625\n","Epoch 12/50\n","53/53 [==============================] - 2s 42ms/step - loss: 1.0390 - accuracy: 0.4798 - val_loss: 1.0492 - val_accuracy: 0.4625\n","Epoch 13/50\n","53/53 [==============================] - 2s 42ms/step - loss: 1.0360 - accuracy: 0.4736 - val_loss: 1.0408 - val_accuracy: 0.4625\n","Epoch 14/50\n","53/53 [==============================] - 2s 42ms/step - loss: 1.0255 - accuracy: 0.4853 - val_loss: 1.0390 - val_accuracy: 0.4625\n","Epoch 15/50\n","53/53 [==============================] - 2s 42ms/step - loss: 1.0343 - accuracy: 0.4752 - val_loss: 1.0384 - val_accuracy: 0.4625\n","Epoch 16/50\n","53/53 [==============================] - 2s 42ms/step - loss: 1.0357 - accuracy: 0.4732 - val_loss: 1.0355 - val_accuracy: 0.4625\n","Epoch 17/50\n","53/53 [==============================] - 2s 42ms/step - loss: 1.0288 - accuracy: 0.4759 - val_loss: 1.0362 - val_accuracy: 0.4625\n","Epoch 18/50\n","53/53 [==============================] - 2s 41ms/step - loss: 1.0206 - accuracy: 0.4874 - val_loss: 1.0432 - val_accuracy: 0.4625\n","Epoch 19/50\n","53/53 [==============================] - 2s 42ms/step - loss: 1.0273 - accuracy: 0.4864 - val_loss: 1.0255 - val_accuracy: 0.4625\n","Epoch 20/50\n","53/53 [==============================] - 2s 42ms/step - loss: 1.0161 - accuracy: 0.4896 - val_loss: 1.0213 - val_accuracy: 0.4826\n","Epoch 21/50\n","53/53 [==============================] - 2s 42ms/step - loss: 1.0224 - accuracy: 0.4841 - val_loss: 1.0157 - val_accuracy: 0.4786\n","Epoch 22/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.9964 - accuracy: 0.4924 - val_loss: 1.0181 - val_accuracy: 0.4853\n","Epoch 23/50\n","53/53 [==============================] - 2s 42ms/step - loss: 1.0140 - accuracy: 0.4781 - val_loss: 1.0137 - val_accuracy: 0.4692\n","Epoch 24/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.9922 - accuracy: 0.4985 - val_loss: 0.9908 - val_accuracy: 0.4920\n","Epoch 25/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.9825 - accuracy: 0.5083 - val_loss: 0.9891 - val_accuracy: 0.5080\n","Epoch 26/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.9797 - accuracy: 0.5058 - val_loss: 0.9818 - val_accuracy: 0.4987\n","Epoch 27/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.9838 - accuracy: 0.5002 - val_loss: 0.9915 - val_accuracy: 0.5040\n","Epoch 28/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.9736 - accuracy: 0.5077 - val_loss: 1.0507 - val_accuracy: 0.4826\n","Epoch 29/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.9501 - accuracy: 0.5213 - val_loss: 0.9484 - val_accuracy: 0.5308\n","Epoch 30/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.9398 - accuracy: 0.5379 - val_loss: 0.9268 - val_accuracy: 0.5282\n","Epoch 31/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.9260 - accuracy: 0.5519 - val_loss: 0.9701 - val_accuracy: 0.5228\n","Epoch 32/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.9293 - accuracy: 0.5405 - val_loss: 0.9419 - val_accuracy: 0.5121\n","Epoch 33/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.9006 - accuracy: 0.5602 - val_loss: 0.9366 - val_accuracy: 0.5416\n","Epoch 34/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.8964 - accuracy: 0.5566 - val_loss: 0.9099 - val_accuracy: 0.5697\n","Epoch 35/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.8800 - accuracy: 0.5626 - val_loss: 0.8878 - val_accuracy: 0.5509\n","Epoch 36/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.8701 - accuracy: 0.5745 - val_loss: 0.8610 - val_accuracy: 0.5925\n","Epoch 37/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.8542 - accuracy: 0.5807 - val_loss: 0.8593 - val_accuracy: 0.6019\n","Epoch 38/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.8351 - accuracy: 0.5908 - val_loss: 0.8123 - val_accuracy: 0.6126\n","Epoch 39/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.8084 - accuracy: 0.6195 - val_loss: 0.7913 - val_accuracy: 0.6340\n","Epoch 40/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.7577 - accuracy: 0.6459 - val_loss: 0.8621 - val_accuracy: 0.5751\n","Epoch 41/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.7516 - accuracy: 0.6456 - val_loss: 0.7799 - val_accuracy: 0.6622\n","Epoch 42/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.7146 - accuracy: 0.6757 - val_loss: 0.7171 - val_accuracy: 0.6689\n","Epoch 43/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.6832 - accuracy: 0.6885 - val_loss: 0.7371 - val_accuracy: 0.6501\n","Epoch 44/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.6472 - accuracy: 0.7134 - val_loss: 0.6306 - val_accuracy: 0.7172\n","Epoch 45/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.6331 - accuracy: 0.7307 - val_loss: 0.6848 - val_accuracy: 0.7131\n","Epoch 46/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.5394 - accuracy: 0.7694 - val_loss: 0.5079 - val_accuracy: 0.8016\n","Epoch 47/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.5164 - accuracy: 0.7807 - val_loss: 0.4816 - val_accuracy: 0.8056\n","Epoch 48/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.4774 - accuracy: 0.8040 - val_loss: 0.4509 - val_accuracy: 0.8137\n","Epoch 49/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.4743 - accuracy: 0.8153 - val_loss: 0.4914 - val_accuracy: 0.7936\n","Epoch 50/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.4472 - accuracy: 0.8288 - val_loss: 0.4235 - val_accuracy: 0.8177\n","Results for fold 2\n","Epoch 1/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.3799 - accuracy: 0.8581 - val_loss: 0.1482 - val_accuracy: 0.9517\n","Epoch 2/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.3502 - accuracy: 0.8702 - val_loss: 0.1366 - val_accuracy: 0.9531\n","Epoch 3/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.3171 - accuracy: 0.8841 - val_loss: 0.0985 - val_accuracy: 0.9705\n","Epoch 4/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.2870 - accuracy: 0.8939 - val_loss: 0.1345 - val_accuracy: 0.9491\n","Epoch 5/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.2800 - accuracy: 0.9009 - val_loss: 0.0887 - val_accuracy: 0.9759\n","Epoch 6/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.2457 - accuracy: 0.9165 - val_loss: 0.1043 - val_accuracy: 0.9665\n","Epoch 7/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.1997 - accuracy: 0.9319 - val_loss: 0.1019 - val_accuracy: 0.9665\n","Epoch 8/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.2173 - accuracy: 0.9247 - val_loss: 0.0575 - val_accuracy: 0.9839\n","Epoch 9/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.1843 - accuracy: 0.9361 - val_loss: 0.0856 - val_accuracy: 0.9665\n","Epoch 10/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.1848 - accuracy: 0.9347 - val_loss: 0.0664 - val_accuracy: 0.9705\n","Epoch 11/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.1876 - accuracy: 0.9385 - val_loss: 0.0661 - val_accuracy: 0.9759\n","Epoch 12/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.1345 - accuracy: 0.9568 - val_loss: 0.0638 - val_accuracy: 0.9786\n","Epoch 13/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.1473 - accuracy: 0.9493 - val_loss: 0.0765 - val_accuracy: 0.9665\n","Epoch 14/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.1218 - accuracy: 0.9599 - val_loss: 0.0499 - val_accuracy: 0.9799\n","Epoch 15/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.1311 - accuracy: 0.9566 - val_loss: 0.0301 - val_accuracy: 0.9920\n","Epoch 16/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.1264 - accuracy: 0.9586 - val_loss: 0.0436 - val_accuracy: 0.9866\n","Epoch 17/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.1081 - accuracy: 0.9656 - val_loss: 0.0229 - val_accuracy: 0.9946\n","Epoch 18/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0973 - accuracy: 0.9690 - val_loss: 0.0563 - val_accuracy: 0.9745\n","Epoch 19/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0968 - accuracy: 0.9680 - val_loss: 0.0298 - val_accuracy: 0.9879\n","Epoch 20/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.1062 - accuracy: 0.9668 - val_loss: 0.0480 - val_accuracy: 0.9786\n","Epoch 21/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0962 - accuracy: 0.9702 - val_loss: 0.0458 - val_accuracy: 0.9812\n","Epoch 22/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.1079 - accuracy: 0.9657 - val_loss: 0.0572 - val_accuracy: 0.9826\n","Epoch 23/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0928 - accuracy: 0.9709 - val_loss: 0.0544 - val_accuracy: 0.9772\n","Epoch 24/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0819 - accuracy: 0.9727 - val_loss: 0.0745 - val_accuracy: 0.9759\n","Epoch 25/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0811 - accuracy: 0.9756 - val_loss: 0.0487 - val_accuracy: 0.9853\n","Epoch 26/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0879 - accuracy: 0.9726 - val_loss: 0.0248 - val_accuracy: 0.9920\n","Epoch 27/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0768 - accuracy: 0.9770 - val_loss: 0.0404 - val_accuracy: 0.9866\n","Epoch 28/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0686 - accuracy: 0.9806 - val_loss: 0.0372 - val_accuracy: 0.9879\n","Epoch 29/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0599 - accuracy: 0.9815 - val_loss: 0.0245 - val_accuracy: 0.9906\n","Epoch 30/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0642 - accuracy: 0.9805 - val_loss: 0.0431 - val_accuracy: 0.9826\n","Epoch 31/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0916 - accuracy: 0.9729 - val_loss: 0.0271 - val_accuracy: 0.9920\n","Epoch 32/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0650 - accuracy: 0.9815 - val_loss: 0.0269 - val_accuracy: 0.9920\n","Epoch 33/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0768 - accuracy: 0.9762 - val_loss: 0.0408 - val_accuracy: 0.9853\n","Epoch 34/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0753 - accuracy: 0.9769 - val_loss: 0.0201 - val_accuracy: 0.9920\n","Epoch 35/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0406 - accuracy: 0.9869 - val_loss: 0.0289 - val_accuracy: 0.9933\n","Epoch 36/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0575 - accuracy: 0.9821 - val_loss: 0.0373 - val_accuracy: 0.9893\n","Epoch 37/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0612 - accuracy: 0.9796 - val_loss: 0.0482 - val_accuracy: 0.9826\n","Epoch 38/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0522 - accuracy: 0.9848 - val_loss: 0.0272 - val_accuracy: 0.9920\n","Epoch 39/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0573 - accuracy: 0.9820 - val_loss: 0.0459 - val_accuracy: 0.9866\n","Epoch 40/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0599 - accuracy: 0.9800 - val_loss: 0.0197 - val_accuracy: 0.9933\n","Epoch 41/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0464 - accuracy: 0.9838 - val_loss: 0.0315 - val_accuracy: 0.9879\n","Epoch 42/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0698 - accuracy: 0.9800 - val_loss: 0.0348 - val_accuracy: 0.9893\n","Epoch 43/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0699 - accuracy: 0.9800 - val_loss: 0.0299 - val_accuracy: 0.9893\n","Epoch 44/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0646 - accuracy: 0.9806 - val_loss: 0.0322 - val_accuracy: 0.9920\n","Epoch 45/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0597 - accuracy: 0.9809 - val_loss: 0.0292 - val_accuracy: 0.9906\n","Epoch 46/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0402 - accuracy: 0.9879 - val_loss: 0.0313 - val_accuracy: 0.9906\n","Epoch 47/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0473 - accuracy: 0.9855 - val_loss: 0.0280 - val_accuracy: 0.9893\n","Epoch 48/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0454 - accuracy: 0.9869 - val_loss: 0.0266 - val_accuracy: 0.9920\n","Epoch 49/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0504 - accuracy: 0.9832 - val_loss: 0.0178 - val_accuracy: 0.9960\n","Epoch 50/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0506 - accuracy: 0.9838 - val_loss: 0.0227 - val_accuracy: 0.9946\n","Results for fold 3\n","Epoch 1/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0702 - accuracy: 0.9791 - val_loss: 8.7723e-04 - val_accuracy: 1.0000\n","Epoch 2/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0554 - accuracy: 0.9824 - val_loss: 4.0542e-04 - val_accuracy: 1.0000\n","Epoch 3/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0671 - accuracy: 0.9784 - val_loss: 2.0583e-04 - val_accuracy: 1.0000\n","Epoch 4/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0395 - accuracy: 0.9860 - val_loss: 4.7776e-05 - val_accuracy: 1.0000\n","Epoch 5/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0425 - accuracy: 0.9844 - val_loss: 6.5159e-05 - val_accuracy: 1.0000\n","Epoch 6/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0503 - accuracy: 0.9842 - val_loss: 2.6522e-04 - val_accuracy: 1.0000\n","Epoch 7/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0484 - accuracy: 0.9885 - val_loss: 2.5370e-04 - val_accuracy: 1.0000\n","Epoch 8/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0436 - accuracy: 0.9858 - val_loss: 9.3242e-05 - val_accuracy: 1.0000\n","Epoch 9/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0477 - accuracy: 0.9852 - val_loss: 0.0015 - val_accuracy: 1.0000\n","Epoch 10/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0565 - accuracy: 0.9842 - val_loss: 0.0011 - val_accuracy: 1.0000\n","Epoch 11/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0543 - accuracy: 0.9836 - val_loss: 0.0047 - val_accuracy: 0.9987\n","Epoch 12/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0603 - accuracy: 0.9830 - val_loss: 0.0012 - val_accuracy: 1.0000\n","Epoch 13/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0390 - accuracy: 0.9879 - val_loss: 1.1115e-04 - val_accuracy: 1.0000\n","Epoch 14/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0342 - accuracy: 0.9896 - val_loss: 0.0017 - val_accuracy: 0.9987\n","Epoch 15/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0456 - accuracy: 0.9870 - val_loss: 1.5865e-04 - val_accuracy: 1.0000\n","Epoch 16/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0395 - accuracy: 0.9876 - val_loss: 0.0018 - val_accuracy: 0.9987\n","Epoch 17/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0392 - accuracy: 0.9864 - val_loss: 1.9996e-04 - val_accuracy: 1.0000\n","Epoch 18/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0515 - accuracy: 0.9848 - val_loss: 0.0011 - val_accuracy: 1.0000\n","Epoch 19/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0464 - accuracy: 0.9855 - val_loss: 0.0020 - val_accuracy: 0.9987\n","Epoch 20/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0342 - accuracy: 0.9891 - val_loss: 0.0011 - val_accuracy: 0.9987\n","Epoch 21/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0390 - accuracy: 0.9875 - val_loss: 3.6885e-04 - val_accuracy: 1.0000\n","Epoch 22/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0323 - accuracy: 0.9891 - val_loss: 5.2533e-05 - val_accuracy: 1.0000\n","Epoch 23/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0332 - accuracy: 0.9903 - val_loss: 0.0026 - val_accuracy: 0.9987\n","Epoch 24/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0371 - accuracy: 0.9890 - val_loss: 1.4189e-04 - val_accuracy: 1.0000\n","Epoch 25/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0385 - accuracy: 0.9857 - val_loss: 2.7526e-04 - val_accuracy: 1.0000\n","Epoch 26/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0386 - accuracy: 0.9855 - val_loss: 3.0909e-04 - val_accuracy: 1.0000\n","Epoch 27/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0451 - accuracy: 0.9855 - val_loss: 3.3223e-04 - val_accuracy: 1.0000\n","Epoch 28/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0265 - accuracy: 0.9908 - val_loss: 1.1792e-04 - val_accuracy: 1.0000\n","Epoch 29/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0336 - accuracy: 0.9900 - val_loss: 7.7420e-04 - val_accuracy: 1.0000\n","Epoch 30/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0314 - accuracy: 0.9908 - val_loss: 6.1036e-04 - val_accuracy: 1.0000\n","Epoch 31/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0446 - accuracy: 0.9875 - val_loss: 7.7679e-04 - val_accuracy: 1.0000\n","Epoch 32/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0354 - accuracy: 0.9900 - val_loss: 1.0860e-04 - val_accuracy: 1.0000\n","Epoch 33/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0348 - accuracy: 0.9879 - val_loss: 1.5052e-04 - val_accuracy: 1.0000\n","Epoch 34/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0357 - accuracy: 0.9888 - val_loss: 0.0020 - val_accuracy: 1.0000\n","Epoch 35/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0417 - accuracy: 0.9878 - val_loss: 3.2915e-04 - val_accuracy: 1.0000\n","Epoch 36/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0293 - accuracy: 0.9908 - val_loss: 6.3399e-04 - val_accuracy: 1.0000\n","Epoch 37/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0365 - accuracy: 0.9881 - val_loss: 6.7017e-04 - val_accuracy: 1.0000\n","Epoch 38/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0241 - accuracy: 0.9921 - val_loss: 1.6509e-04 - val_accuracy: 1.0000\n","Epoch 39/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0236 - accuracy: 0.9923 - val_loss: 5.4368e-04 - val_accuracy: 1.0000\n","Epoch 40/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0333 - accuracy: 0.9896 - val_loss: 0.0019 - val_accuracy: 0.9987\n","Epoch 41/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0328 - accuracy: 0.9908 - val_loss: 0.0025 - val_accuracy: 0.9987\n","Epoch 42/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0296 - accuracy: 0.9903 - val_loss: 6.1893e-04 - val_accuracy: 1.0000\n","Epoch 43/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0347 - accuracy: 0.9894 - val_loss: 0.0024 - val_accuracy: 0.9987\n","Epoch 44/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0444 - accuracy: 0.9873 - val_loss: 3.6730e-04 - val_accuracy: 1.0000\n","Epoch 45/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0273 - accuracy: 0.9928 - val_loss: 4.9319e-04 - val_accuracy: 1.0000\n","Epoch 46/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0307 - accuracy: 0.9914 - val_loss: 0.0041 - val_accuracy: 0.9987\n","Epoch 47/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0265 - accuracy: 0.9933 - val_loss: 0.0022 - val_accuracy: 0.9987\n","Epoch 48/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0247 - accuracy: 0.9921 - val_loss: 5.4626e-04 - val_accuracy: 1.0000\n","Epoch 49/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0293 - accuracy: 0.9915 - val_loss: 0.0016 - val_accuracy: 1.0000\n","Epoch 50/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0434 - accuracy: 0.9864 - val_loss: 0.0015 - val_accuracy: 1.0000\n","Results for fold 4\n","Epoch 1/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0427 - accuracy: 0.9864 - val_loss: 1.9969e-05 - val_accuracy: 1.0000\n","Epoch 2/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0363 - accuracy: 0.9888 - val_loss: 7.2222e-06 - val_accuracy: 1.0000\n","Epoch 3/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0319 - accuracy: 0.9900 - val_loss: 3.4646e-05 - val_accuracy: 1.0000\n","Epoch 4/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0359 - accuracy: 0.9906 - val_loss: 1.3373e-05 - val_accuracy: 1.0000\n","Epoch 5/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0230 - accuracy: 0.9928 - val_loss: 2.6293e-05 - val_accuracy: 1.0000\n","Epoch 6/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0303 - accuracy: 0.9905 - val_loss: 5.6865e-05 - val_accuracy: 1.0000\n","Epoch 7/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0293 - accuracy: 0.9900 - val_loss: 5.8500e-05 - val_accuracy: 1.0000\n","Epoch 8/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0170 - accuracy: 0.9940 - val_loss: 4.0915e-06 - val_accuracy: 1.0000\n","Epoch 9/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0251 - accuracy: 0.9930 - val_loss: 1.0419e-04 - val_accuracy: 1.0000\n","Epoch 10/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0333 - accuracy: 0.9897 - val_loss: 0.0022 - val_accuracy: 0.9987\n","Epoch 11/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0329 - accuracy: 0.9911 - val_loss: 1.6014e-05 - val_accuracy: 1.0000\n","Epoch 12/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0192 - accuracy: 0.9934 - val_loss: 1.5414e-04 - val_accuracy: 1.0000\n","Epoch 13/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0257 - accuracy: 0.9936 - val_loss: 1.1080e-05 - val_accuracy: 1.0000\n","Epoch 14/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0244 - accuracy: 0.9921 - val_loss: 0.0021 - val_accuracy: 0.9987\n","Epoch 15/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0280 - accuracy: 0.9908 - val_loss: 2.3930e-05 - val_accuracy: 1.0000\n","Epoch 16/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0309 - accuracy: 0.9908 - val_loss: 1.3216e-04 - val_accuracy: 1.0000\n","Epoch 17/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0291 - accuracy: 0.9908 - val_loss: 3.2199e-05 - val_accuracy: 1.0000\n","Epoch 18/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0203 - accuracy: 0.9940 - val_loss: 1.7372e-04 - val_accuracy: 1.0000\n","Epoch 19/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0260 - accuracy: 0.9920 - val_loss: 5.9370e-05 - val_accuracy: 1.0000\n","Epoch 20/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0273 - accuracy: 0.9914 - val_loss: 1.2632e-04 - val_accuracy: 1.0000\n","Epoch 21/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 6.1333e-05 - val_accuracy: 1.0000\n","Epoch 22/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0206 - accuracy: 0.9931 - val_loss: 7.6978e-06 - val_accuracy: 1.0000\n","Epoch 23/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0271 - accuracy: 0.9925 - val_loss: 2.8790e-05 - val_accuracy: 1.0000\n","Epoch 24/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0263 - accuracy: 0.9915 - val_loss: 2.9820e-04 - val_accuracy: 1.0000\n","Epoch 25/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0292 - accuracy: 0.9918 - val_loss: 7.4135e-04 - val_accuracy: 1.0000\n","Epoch 26/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0277 - accuracy: 0.9914 - val_loss: 4.3460e-04 - val_accuracy: 1.0000\n","Epoch 27/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0244 - accuracy: 0.9921 - val_loss: 7.4316e-04 - val_accuracy: 1.0000\n","Epoch 28/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0195 - accuracy: 0.9939 - val_loss: 1.1243e-04 - val_accuracy: 1.0000\n","Epoch 29/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0226 - accuracy: 0.9934 - val_loss: 3.6079e-04 - val_accuracy: 1.0000\n","Epoch 30/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 1.0259e-05 - val_accuracy: 1.0000\n","Epoch 31/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0137 - accuracy: 0.9972 - val_loss: 2.2716e-05 - val_accuracy: 1.0000\n","Epoch 32/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0283 - accuracy: 0.9908 - val_loss: 0.0011 - val_accuracy: 1.0000\n","Epoch 33/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0311 - accuracy: 0.9914 - val_loss: 4.3748e-04 - val_accuracy: 1.0000\n","Epoch 34/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0275 - accuracy: 0.9911 - val_loss: 4.7912e-04 - val_accuracy: 1.0000\n","Epoch 35/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0218 - accuracy: 0.9945 - val_loss: 6.3151e-05 - val_accuracy: 1.0000\n","Epoch 36/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0177 - accuracy: 0.9946 - val_loss: 2.6099e-05 - val_accuracy: 1.0000\n","Epoch 37/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0254 - accuracy: 0.9917 - val_loss: 0.0012 - val_accuracy: 1.0000\n","Epoch 38/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0195 - accuracy: 0.9942 - val_loss: 2.3284e-04 - val_accuracy: 1.0000\n","Epoch 39/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0246 - accuracy: 0.9930 - val_loss: 3.0581e-04 - val_accuracy: 1.0000\n","Epoch 40/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0169 - accuracy: 0.9954 - val_loss: 1.1323e-04 - val_accuracy: 1.0000\n","Epoch 41/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0265 - accuracy: 0.9914 - val_loss: 2.7688e-05 - val_accuracy: 1.0000\n","Epoch 42/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0271 - accuracy: 0.9925 - val_loss: 0.0016 - val_accuracy: 0.9987\n","Epoch 43/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0299 - accuracy: 0.9908 - val_loss: 1.5549e-04 - val_accuracy: 1.0000\n","Epoch 44/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0242 - accuracy: 0.9928 - val_loss: 0.0015 - val_accuracy: 0.9987\n","Epoch 45/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0210 - accuracy: 0.9930 - val_loss: 1.4360e-04 - val_accuracy: 1.0000\n","Epoch 46/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0220 - accuracy: 0.9931 - val_loss: 2.3315e-04 - val_accuracy: 1.0000\n","Epoch 47/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0208 - accuracy: 0.9937 - val_loss: 8.3783e-05 - val_accuracy: 1.0000\n","Epoch 48/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0201 - accuracy: 0.9940 - val_loss: 1.5962e-05 - val_accuracy: 1.0000\n","Epoch 49/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0205 - accuracy: 0.9940 - val_loss: 6.9540e-05 - val_accuracy: 1.0000\n","Epoch 50/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 8.8678e-05 - val_accuracy: 1.0000\n","Results for fold 5\n","Epoch 1/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0219 - accuracy: 0.9930 - val_loss: 2.8506e-06 - val_accuracy: 1.0000\n","Epoch 2/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0275 - accuracy: 0.9911 - val_loss: 9.3919e-06 - val_accuracy: 1.0000\n","Epoch 3/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0271 - accuracy: 0.9918 - val_loss: 4.7640e-06 - val_accuracy: 1.0000\n","Epoch 4/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 2.3979e-06 - val_accuracy: 1.0000\n","Epoch 5/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 8.5265e-06 - val_accuracy: 1.0000\n","Epoch 6/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0189 - accuracy: 0.9948 - val_loss: 2.0530e-05 - val_accuracy: 1.0000\n","Epoch 7/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 1.5300e-05 - val_accuracy: 1.0000\n","Epoch 8/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0172 - accuracy: 0.9937 - val_loss: 8.7449e-06 - val_accuracy: 1.0000\n","Epoch 9/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0223 - accuracy: 0.9936 - val_loss: 2.6896e-05 - val_accuracy: 1.0000\n","Epoch 10/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0208 - accuracy: 0.9943 - val_loss: 2.0860e-05 - val_accuracy: 1.0000\n","Epoch 11/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0231 - accuracy: 0.9931 - val_loss: 3.3641e-04 - val_accuracy: 1.0000\n","Epoch 12/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0216 - accuracy: 0.9921 - val_loss: 3.3944e-06 - val_accuracy: 1.0000\n","Epoch 13/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0162 - accuracy: 0.9963 - val_loss: 8.8122e-06 - val_accuracy: 1.0000\n","Epoch 14/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 4.2372e-04 - val_accuracy: 1.0000\n","Epoch 15/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0220 - accuracy: 0.9923 - val_loss: 0.0018 - val_accuracy: 0.9987\n","Epoch 16/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0195 - accuracy: 0.9946 - val_loss: 1.9555e-05 - val_accuracy: 1.0000\n","Epoch 17/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0240 - accuracy: 0.9925 - val_loss: 8.1456e-06 - val_accuracy: 1.0000\n","Epoch 18/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0151 - accuracy: 0.9964 - val_loss: 6.8370e-06 - val_accuracy: 1.0000\n","Epoch 19/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0209 - accuracy: 0.9931 - val_loss: 1.4539e-05 - val_accuracy: 1.0000\n","Epoch 20/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.0020 - val_accuracy: 0.9987\n","Epoch 21/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0226 - accuracy: 0.9911 - val_loss: 1.6883e-05 - val_accuracy: 1.0000\n","Epoch 22/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0196 - accuracy: 0.9948 - val_loss: 3.4448e-05 - val_accuracy: 1.0000\n","Epoch 23/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 9.6630e-05 - val_accuracy: 1.0000\n","Epoch 24/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0205 - accuracy: 0.9934 - val_loss: 1.0423e-05 - val_accuracy: 1.0000\n","Epoch 25/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 2.0838e-05 - val_accuracy: 1.0000\n","Epoch 26/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0249 - accuracy: 0.9928 - val_loss: 3.4273e-05 - val_accuracy: 1.0000\n","Epoch 27/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 1.9487e-05 - val_accuracy: 1.0000\n","Epoch 28/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 5.4797e-05 - val_accuracy: 1.0000\n","Epoch 29/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0189 - accuracy: 0.9946 - val_loss: 1.4141e-05 - val_accuracy: 1.0000\n","Epoch 30/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0163 - accuracy: 0.9948 - val_loss: 1.3190e-04 - val_accuracy: 1.0000\n","Epoch 31/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0145 - accuracy: 0.9945 - val_loss: 8.8230e-04 - val_accuracy: 1.0000\n","Epoch 32/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0233 - accuracy: 0.9936 - val_loss: 3.7266e-05 - val_accuracy: 1.0000\n","Epoch 33/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0192 - accuracy: 0.9934 - val_loss: 2.1165e-05 - val_accuracy: 1.0000\n","Epoch 34/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0264 - accuracy: 0.9914 - val_loss: 5.3798e-04 - val_accuracy: 1.0000\n","Epoch 35/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0186 - accuracy: 0.9942 - val_loss: 1.5780e-04 - val_accuracy: 1.0000\n","Epoch 36/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0160 - accuracy: 0.9961 - val_loss: 1.4821e-04 - val_accuracy: 1.0000\n","Epoch 37/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0131 - accuracy: 0.9948 - val_loss: 2.6384e-05 - val_accuracy: 1.0000\n","Epoch 38/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0210 - accuracy: 0.9949 - val_loss: 5.6579e-05 - val_accuracy: 1.0000\n","Epoch 39/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0279 - accuracy: 0.9920 - val_loss: 1.4182e-04 - val_accuracy: 1.0000\n","Epoch 40/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0193 - accuracy: 0.9952 - val_loss: 9.0154e-05 - val_accuracy: 1.0000\n","Epoch 41/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0088 - accuracy: 0.9975 - val_loss: 6.5888e-05 - val_accuracy: 1.0000\n","Epoch 42/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0201 - accuracy: 0.9928 - val_loss: 1.3557e-04 - val_accuracy: 1.0000\n","Epoch 43/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0173 - accuracy: 0.9951 - val_loss: 1.5737e-05 - val_accuracy: 1.0000\n","Epoch 44/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0165 - accuracy: 0.9958 - val_loss: 1.5842e-05 - val_accuracy: 1.0000\n","Epoch 45/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 1.9267e-05 - val_accuracy: 1.0000\n","Epoch 46/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 1.5155e-05 - val_accuracy: 1.0000\n","Epoch 47/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 1.5908e-05 - val_accuracy: 1.0000\n","Epoch 48/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0114 - accuracy: 0.9967 - val_loss: 1.9046e-05 - val_accuracy: 1.0000\n","Epoch 49/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 5.9838e-05 - val_accuracy: 1.0000\n","Epoch 50/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0121 - accuracy: 0.9966 - val_loss: 2.8672e-06 - val_accuracy: 1.0000\n","Results for fold 6\n","Epoch 1/50\n","53/53 [==============================] - 2s 45ms/step - loss: 0.0235 - accuracy: 0.9936 - val_loss: 1.2554e-05 - val_accuracy: 1.0000\n","Epoch 2/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 2.0893e-06 - val_accuracy: 1.0000\n","Epoch 3/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 7.0047e-07 - val_accuracy: 1.0000\n","Epoch 4/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0170 - accuracy: 0.9951 - val_loss: 4.2781e-06 - val_accuracy: 1.0000\n","Epoch 5/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 4.7756e-06 - val_accuracy: 1.0000\n","Epoch 6/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0194 - accuracy: 0.9936 - val_loss: 1.4617e-05 - val_accuracy: 1.0000\n","Epoch 7/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0169 - accuracy: 0.9955 - val_loss: 1.9786e-06 - val_accuracy: 1.0000\n","Epoch 8/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0161 - accuracy: 0.9946 - val_loss: 1.2242e-05 - val_accuracy: 1.0000\n","Epoch 9/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0227 - accuracy: 0.9931 - val_loss: 9.9760e-05 - val_accuracy: 1.0000\n","Epoch 10/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0165 - accuracy: 0.9960 - val_loss: 1.0534e-05 - val_accuracy: 1.0000\n","Epoch 11/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0229 - accuracy: 0.9927 - val_loss: 1.4907e-04 - val_accuracy: 1.0000\n","Epoch 12/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0205 - accuracy: 0.9940 - val_loss: 8.8651e-04 - val_accuracy: 1.0000\n","Epoch 13/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0221 - accuracy: 0.9924 - val_loss: 1.7176e-05 - val_accuracy: 1.0000\n","Epoch 14/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0153 - accuracy: 0.9955 - val_loss: 1.3360e-06 - val_accuracy: 1.0000\n","Epoch 15/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 1.1512e-06 - val_accuracy: 1.0000\n","Epoch 16/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0214 - accuracy: 0.9928 - val_loss: 7.1356e-06 - val_accuracy: 1.0000\n","Epoch 17/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0143 - accuracy: 0.9967 - val_loss: 8.4838e-06 - val_accuracy: 1.0000\n","Epoch 18/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0163 - accuracy: 0.9948 - val_loss: 2.8350e-05 - val_accuracy: 1.0000\n","Epoch 19/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0157 - accuracy: 0.9949 - val_loss: 2.0367e-05 - val_accuracy: 1.0000\n","Epoch 20/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0187 - accuracy: 0.9948 - val_loss: 8.7207e-06 - val_accuracy: 1.0000\n","Epoch 21/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 1.9169e-06 - val_accuracy: 1.0000\n","Epoch 22/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 9.5637e-07 - val_accuracy: 1.0000\n","Epoch 23/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0155 - accuracy: 0.9957 - val_loss: 8.9498e-07 - val_accuracy: 1.0000\n","Epoch 24/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0192 - accuracy: 0.9948 - val_loss: 4.1679e-04 - val_accuracy: 1.0000\n","Epoch 25/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0106 - accuracy: 0.9961 - val_loss: 9.5310e-05 - val_accuracy: 1.0000\n","Epoch 26/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 3.1316e-06 - val_accuracy: 1.0000\n","Epoch 27/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0146 - accuracy: 0.9948 - val_loss: 1.4400e-05 - val_accuracy: 1.0000\n","Epoch 28/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 3.5090e-06 - val_accuracy: 1.0000\n","Epoch 29/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0144 - accuracy: 0.9951 - val_loss: 2.9187e-05 - val_accuracy: 1.0000\n","Epoch 30/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0149 - accuracy: 0.9943 - val_loss: 0.0013 - val_accuracy: 0.9987\n","Epoch 31/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0246 - accuracy: 0.9933 - val_loss: 4.7576e-05 - val_accuracy: 1.0000\n","Epoch 32/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0196 - accuracy: 0.9942 - val_loss: 1.0556e-05 - val_accuracy: 1.0000\n","Epoch 33/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 2.7114e-04 - val_accuracy: 1.0000\n","Epoch 34/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0148 - accuracy: 0.9945 - val_loss: 1.0890e-06 - val_accuracy: 1.0000\n","Epoch 35/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0230 - accuracy: 0.9925 - val_loss: 7.6789e-05 - val_accuracy: 1.0000\n","Epoch 36/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 2.3325e-06 - val_accuracy: 1.0000\n","Epoch 37/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 5.4749e-05 - val_accuracy: 1.0000\n","Epoch 38/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 9.0113e-06 - val_accuracy: 1.0000\n","Epoch 39/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 1.8056e-06 - val_accuracy: 1.0000\n","Epoch 40/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0240 - accuracy: 0.9933 - val_loss: 7.7343e-05 - val_accuracy: 1.0000\n","Epoch 41/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 8.1748e-05 - val_accuracy: 1.0000\n","Epoch 42/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 1.6681e-06 - val_accuracy: 1.0000\n","Epoch 43/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 8.8861e-06 - val_accuracy: 1.0000\n","Epoch 44/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0139 - accuracy: 0.9954 - val_loss: 5.9647e-05 - val_accuracy: 1.0000\n","Epoch 45/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0118 - accuracy: 0.9970 - val_loss: 8.1584e-06 - val_accuracy: 1.0000\n","Epoch 46/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0083 - accuracy: 0.9969 - val_loss: 2.2902e-06 - val_accuracy: 1.0000\n","Epoch 47/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0127 - accuracy: 0.9967 - val_loss: 9.6993e-06 - val_accuracy: 1.0000\n","Epoch 48/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.0028 - val_accuracy: 0.9987\n","Epoch 49/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 5.8115e-05 - val_accuracy: 1.0000\n","Epoch 50/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0156 - accuracy: 0.9955 - val_loss: 3.7153e-05 - val_accuracy: 1.0000\n","Results for fold 7\n","Epoch 1/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0206 - accuracy: 0.9937 - val_loss: 1.2729e-06 - val_accuracy: 1.0000\n","Epoch 2/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 7.0002e-07 - val_accuracy: 1.0000\n","Epoch 3/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 4.8434e-06 - val_accuracy: 1.0000\n","Epoch 4/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0132 - accuracy: 0.9951 - val_loss: 1.5872e-06 - val_accuracy: 1.0000\n","Epoch 5/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 9.2905e-07 - val_accuracy: 1.0000\n","Epoch 6/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 2.7665e-07 - val_accuracy: 1.0000\n","Epoch 7/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0139 - accuracy: 0.9954 - val_loss: 1.5585e-07 - val_accuracy: 1.0000\n","Epoch 8/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 2.1793e-07 - val_accuracy: 1.0000\n","Epoch 9/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0182 - accuracy: 0.9957 - val_loss: 8.5721e-06 - val_accuracy: 1.0000\n","Epoch 10/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0172 - accuracy: 0.9952 - val_loss: 3.9218e-07 - val_accuracy: 1.0000\n","Epoch 11/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0131 - accuracy: 0.9955 - val_loss: 9.8516e-06 - val_accuracy: 1.0000\n","Epoch 12/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0193 - accuracy: 0.9955 - val_loss: 8.0051e-07 - val_accuracy: 1.0000\n","Epoch 13/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0127 - accuracy: 0.9951 - val_loss: 5.3490e-07 - val_accuracy: 1.0000\n","Epoch 14/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 1.6265e-06 - val_accuracy: 1.0000\n","Epoch 15/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0237 - accuracy: 0.9909 - val_loss: 1.5944e-05 - val_accuracy: 1.0000\n","Epoch 16/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 6.6064e-07 - val_accuracy: 1.0000\n","Epoch 17/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0164 - accuracy: 0.9958 - val_loss: 5.7731e-07 - val_accuracy: 1.0000\n","Epoch 18/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 5.6083e-07 - val_accuracy: 1.0000\n","Epoch 19/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0131 - accuracy: 0.9955 - val_loss: 4.2108e-05 - val_accuracy: 1.0000\n","Epoch 20/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0160 - accuracy: 0.9952 - val_loss: 1.2020e-06 - val_accuracy: 1.0000\n","Epoch 21/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0185 - accuracy: 0.9963 - val_loss: 1.6740e-04 - val_accuracy: 1.0000\n","Epoch 22/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0130 - accuracy: 0.9954 - val_loss: 8.4304e-07 - val_accuracy: 1.0000\n","Epoch 23/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0206 - accuracy: 0.9927 - val_loss: 1.1399e-05 - val_accuracy: 1.0000\n","Epoch 24/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 8.9637e-07 - val_accuracy: 1.0000\n","Epoch 25/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0140 - accuracy: 0.9964 - val_loss: 2.9250e-07 - val_accuracy: 1.0000\n","Epoch 26/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0129 - accuracy: 0.9970 - val_loss: 6.7601e-07 - val_accuracy: 1.0000\n","Epoch 27/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 3.7583e-06 - val_accuracy: 1.0000\n","Epoch 28/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 1.6338e-06 - val_accuracy: 1.0000\n","Epoch 29/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 1.0787e-05 - val_accuracy: 1.0000\n","Epoch 30/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 1.0921e-06 - val_accuracy: 1.0000\n","Epoch 31/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0091 - accuracy: 0.9967 - val_loss: 9.0567e-08 - val_accuracy: 1.0000\n","Epoch 32/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 1.9640e-06 - val_accuracy: 1.0000\n","Epoch 33/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0129 - accuracy: 0.9964 - val_loss: 2.8129e-07 - val_accuracy: 1.0000\n","Epoch 34/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0130 - accuracy: 0.9952 - val_loss: 4.1778e-07 - val_accuracy: 1.0000\n","Epoch 35/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0117 - accuracy: 0.9967 - val_loss: 2.3425e-07 - val_accuracy: 1.0000\n","Epoch 36/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0165 - accuracy: 0.9943 - val_loss: 1.0724e-04 - val_accuracy: 1.0000\n","Epoch 37/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0104 - accuracy: 0.9964 - val_loss: 5.0221e-06 - val_accuracy: 1.0000\n","Epoch 38/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0188 - accuracy: 0.9943 - val_loss: 2.5049e-05 - val_accuracy: 1.0000\n","Epoch 39/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 3.4507e-05 - val_accuracy: 1.0000\n","Epoch 40/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0102 - accuracy: 0.9960 - val_loss: 3.3586e-07 - val_accuracy: 1.0000\n","Epoch 41/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 9.0219e-07 - val_accuracy: 1.0000\n","Epoch 42/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 1.7681e-07 - val_accuracy: 1.0000\n","Epoch 43/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 1.2369e-05 - val_accuracy: 1.0000\n","Epoch 44/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 1.3441e-06 - val_accuracy: 1.0000\n","Epoch 45/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0189 - accuracy: 0.9946 - val_loss: 1.0658e-05 - val_accuracy: 1.0000\n","Epoch 46/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0181 - accuracy: 0.9936 - val_loss: 5.9556e-06 - val_accuracy: 1.0000\n","Epoch 47/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 2.3204e-05 - val_accuracy: 1.0000\n","Epoch 48/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0124 - accuracy: 0.9955 - val_loss: 3.7778e-04 - val_accuracy: 1.0000\n","Epoch 49/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0143 - accuracy: 0.9963 - val_loss: 1.7077e-05 - val_accuracy: 1.0000\n","Epoch 50/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0145 - accuracy: 0.9955 - val_loss: 7.3259e-05 - val_accuracy: 1.0000\n","Results for fold 8\n","Epoch 1/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0140 - accuracy: 0.9955 - val_loss: 3.9361e-04 - val_accuracy: 1.0000\n","Epoch 2/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0189 - accuracy: 0.9948 - val_loss: 3.3175e-06 - val_accuracy: 1.0000\n","Epoch 3/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0235 - accuracy: 0.9923 - val_loss: 6.8738e-06 - val_accuracy: 1.0000\n","Epoch 4/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 1.2571e-06 - val_accuracy: 1.0000\n","Epoch 5/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 1.2164e-05 - val_accuracy: 1.0000\n","Epoch 6/50\n","53/53 [==============================] - 2s 45ms/step - loss: 0.0092 - accuracy: 0.9978 - val_loss: 1.1077e-06 - val_accuracy: 1.0000\n","Epoch 7/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0190 - accuracy: 0.9945 - val_loss: 2.6686e-06 - val_accuracy: 1.0000\n","Epoch 8/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0185 - accuracy: 0.9954 - val_loss: 5.6500e-07 - val_accuracy: 1.0000\n","Epoch 9/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0090 - accuracy: 0.9975 - val_loss: 1.1903e-06 - val_accuracy: 1.0000\n","Epoch 10/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 7.2849e-07 - val_accuracy: 1.0000\n","Epoch 11/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 1.3233e-07 - val_accuracy: 1.0000\n","Epoch 12/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 2.7266e-06 - val_accuracy: 1.0000\n","Epoch 13/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0096 - accuracy: 0.9964 - val_loss: 2.1377e-07 - val_accuracy: 1.0000\n","Epoch 14/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0120 - accuracy: 0.9966 - val_loss: 2.2193e-07 - val_accuracy: 1.0000\n","Epoch 15/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 1.1897e-05 - val_accuracy: 1.0000\n","Epoch 16/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 4.3585e-06 - val_accuracy: 1.0000\n","Epoch 17/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 1.9796e-06 - val_accuracy: 1.0000\n","Epoch 18/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 2.0495e-06 - val_accuracy: 1.0000\n","Epoch 19/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0130 - accuracy: 0.9951 - val_loss: 3.3850e-04 - val_accuracy: 1.0000\n","Epoch 20/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 2.2345e-06 - val_accuracy: 1.0000\n","Epoch 21/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0177 - accuracy: 0.9954 - val_loss: 8.3689e-06 - val_accuracy: 1.0000\n","Epoch 22/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 1.7848e-06 - val_accuracy: 1.0000\n","Epoch 23/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 2.8690e-07 - val_accuracy: 1.0000\n","Epoch 24/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 7.4732e-07 - val_accuracy: 1.0000\n","Epoch 25/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 2.7584e-07 - val_accuracy: 1.0000\n","Epoch 26/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0057 - accuracy: 0.9979 - val_loss: 6.5919e-07 - val_accuracy: 1.0000\n","Epoch 27/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0138 - accuracy: 0.9961 - val_loss: 5.3330e-07 - val_accuracy: 1.0000\n","Epoch 28/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0091 - accuracy: 0.9966 - val_loss: 2.3329e-07 - val_accuracy: 1.0000\n","Epoch 29/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 2.1217e-05 - val_accuracy: 1.0000\n","Epoch 30/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0176 - accuracy: 0.9946 - val_loss: 6.5791e-07 - val_accuracy: 1.0000\n","Epoch 31/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0151 - accuracy: 0.9964 - val_loss: 1.2727e-06 - val_accuracy: 1.0000\n","Epoch 32/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0113 - accuracy: 0.9972 - val_loss: 6.3933e-06 - val_accuracy: 1.0000\n","Epoch 33/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 1.6687e-05 - val_accuracy: 1.0000\n","Epoch 34/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 5.0785e-06 - val_accuracy: 1.0000\n","Epoch 35/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 1.9416e-06 - val_accuracy: 1.0000\n","Epoch 36/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 1.5414e-04 - val_accuracy: 1.0000\n","Epoch 37/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0190 - accuracy: 0.9955 - val_loss: 1.8043e-06 - val_accuracy: 1.0000\n","Epoch 38/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0097 - accuracy: 0.9978 - val_loss: 2.4086e-06 - val_accuracy: 1.0000\n","Epoch 39/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0207 - accuracy: 0.9954 - val_loss: 4.9014e-04 - val_accuracy: 1.0000\n","Epoch 40/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0134 - accuracy: 0.9969 - val_loss: 3.5793e-06 - val_accuracy: 1.0000\n","Epoch 41/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 6.1107e-07 - val_accuracy: 1.0000\n","Epoch 42/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0083 - accuracy: 0.9978 - val_loss: 6.7076e-06 - val_accuracy: 1.0000\n","Epoch 43/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0122 - accuracy: 0.9967 - val_loss: 1.3036e-05 - val_accuracy: 1.0000\n","Epoch 44/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0150 - accuracy: 0.9966 - val_loss: 3.6142e-05 - val_accuracy: 1.0000\n","Epoch 45/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 1.0368e-05 - val_accuracy: 1.0000\n","Epoch 46/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0095 - accuracy: 0.9964 - val_loss: 1.0020e-06 - val_accuracy: 1.0000\n","Epoch 47/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 2.5195e-06 - val_accuracy: 1.0000\n","Epoch 48/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 1.6166e-06 - val_accuracy: 1.0000\n","Epoch 49/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 9.8571e-04 - val_accuracy: 0.9987\n","Epoch 50/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 7.7587e-06 - val_accuracy: 1.0000\n","Results for fold 9\n","Epoch 1/50\n","53/53 [==============================] - 2s 45ms/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 3.8403e-08 - val_accuracy: 1.0000\n","Epoch 2/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0130 - accuracy: 0.9966 - val_loss: 4.3087e-07 - val_accuracy: 1.0000\n","Epoch 3/50\n","53/53 [==============================] - 2s 45ms/step - loss: 0.0150 - accuracy: 0.9961 - val_loss: 1.4180e-06 - val_accuracy: 1.0000\n","Epoch 4/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 9.0710e-07 - val_accuracy: 1.0000\n","Epoch 5/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 1.1985e-07 - val_accuracy: 1.0000\n","Epoch 6/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 6.7685e-08 - val_accuracy: 1.0000\n","Epoch 7/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 1.9761e-07 - val_accuracy: 1.0000\n","Epoch 8/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0136 - accuracy: 0.9955 - val_loss: 5.4195e-07 - val_accuracy: 1.0000\n","Epoch 9/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 4.4687e-07 - val_accuracy: 1.0000\n","Epoch 10/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0151 - accuracy: 0.9958 - val_loss: 2.3634e-06 - val_accuracy: 1.0000\n","Epoch 11/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 8.0028e-07 - val_accuracy: 1.0000\n","Epoch 12/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 1.6033e-07 - val_accuracy: 1.0000\n","Epoch 13/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 1.3742e-06 - val_accuracy: 1.0000\n","Epoch 14/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0185 - accuracy: 0.9948 - val_loss: 5.0503e-06 - val_accuracy: 1.0000\n","Epoch 15/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0213 - accuracy: 0.9949 - val_loss: 6.5547e-06 - val_accuracy: 1.0000\n","Epoch 16/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 4.5058e-07 - val_accuracy: 1.0000\n","Epoch 17/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 2.9090e-07 - val_accuracy: 1.0000\n","Epoch 18/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 2.4404e-06 - val_accuracy: 1.0000\n","Epoch 19/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 2.7797e-06 - val_accuracy: 1.0000\n","Epoch 20/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 1.2738e-06 - val_accuracy: 1.0000\n","Epoch 21/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 1.0452e-06 - val_accuracy: 1.0000\n","Epoch 22/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 5.2434e-06 - val_accuracy: 1.0000\n","Epoch 23/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0125 - accuracy: 0.9955 - val_loss: 1.5622e-06 - val_accuracy: 1.0000\n","Epoch 24/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 2.4498e-07 - val_accuracy: 1.0000\n","Epoch 25/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 2.0209e-07 - val_accuracy: 1.0000\n","Epoch 26/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 5.3779e-07 - val_accuracy: 1.0000\n","Epoch 27/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 3.0530e-07 - val_accuracy: 1.0000\n","Epoch 28/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0102 - accuracy: 0.9972 - val_loss: 1.0273e-07 - val_accuracy: 1.0000\n","Epoch 29/50\n","53/53 [==============================] - 2s 45ms/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 7.4086e-08 - val_accuracy: 1.0000\n","Epoch 30/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 7.2537e-06 - val_accuracy: 1.0000\n","Epoch 31/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0168 - accuracy: 0.9949 - val_loss: 1.1885e-06 - val_accuracy: 1.0000\n","Epoch 32/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 1.5232e-06 - val_accuracy: 1.0000\n","Epoch 33/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 1.8241e-07 - val_accuracy: 1.0000\n","Epoch 34/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 1.2483e-06 - val_accuracy: 1.0000\n","Epoch 35/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 3.5553e-07 - val_accuracy: 1.0000\n","Epoch 36/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 5.1457e-07 - val_accuracy: 1.0000\n","Epoch 37/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 8.8327e-08 - val_accuracy: 1.0000\n","Epoch 38/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0109 - accuracy: 0.9972 - val_loss: 2.0382e-06 - val_accuracy: 1.0000\n","Epoch 39/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 3.2693e-06 - val_accuracy: 1.0000\n","Epoch 40/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 1.2865e-07 - val_accuracy: 1.0000\n","Epoch 41/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 1.5969e-07 - val_accuracy: 1.0000\n","Epoch 42/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0127 - accuracy: 0.9967 - val_loss: 2.1938e-07 - val_accuracy: 1.0000\n","Epoch 43/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 7.3811e-07 - val_accuracy: 1.0000\n","Epoch 44/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 2.5042e-07 - val_accuracy: 1.0000\n","Epoch 45/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0121 - accuracy: 0.9966 - val_loss: 3.1786e-05 - val_accuracy: 1.0000\n","Epoch 46/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0073 - accuracy: 0.9970 - val_loss: 3.4017e-07 - val_accuracy: 1.0000\n","Epoch 47/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 2.9234e-07 - val_accuracy: 1.0000\n","Epoch 48/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0088 - accuracy: 0.9979 - val_loss: 3.4338e-07 - val_accuracy: 1.0000\n","Epoch 49/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0063 - accuracy: 0.9973 - val_loss: 4.2992e-06 - val_accuracy: 1.0000\n","Epoch 50/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0093 - accuracy: 0.9984 - val_loss: 4.3506e-07 - val_accuracy: 1.0000\n","Results for fold 10\n","Epoch 1/50\n","53/53 [==============================] - 2s 46ms/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 2.7378e-07 - val_accuracy: 1.0000\n","Epoch 2/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 2.3864e-06 - val_accuracy: 1.0000\n","Epoch 3/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0202 - accuracy: 0.9949 - val_loss: 1.8316e-05 - val_accuracy: 1.0000\n","Epoch 4/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 4.4964e-06 - val_accuracy: 1.0000\n","Epoch 5/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0114 - accuracy: 0.9954 - val_loss: 4.6348e-05 - val_accuracy: 1.0000\n","Epoch 6/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 3.6865e-06 - val_accuracy: 1.0000\n","Epoch 7/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 2.2673e-04 - val_accuracy: 1.0000\n","Epoch 8/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0120 - accuracy: 0.9957 - val_loss: 1.5258e-06 - val_accuracy: 1.0000\n","Epoch 9/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 3.4786e-07 - val_accuracy: 1.0000\n","Epoch 10/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 2.1962e-06 - val_accuracy: 1.0000\n","Epoch 11/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 3.6026e-05 - val_accuracy: 1.0000\n","Epoch 12/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 4.2749e-06 - val_accuracy: 1.0000\n","Epoch 13/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0145 - accuracy: 0.9949 - val_loss: 5.9012e-05 - val_accuracy: 1.0000\n","Epoch 14/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0131 - accuracy: 0.9964 - val_loss: 5.0130e-07 - val_accuracy: 1.0000\n","Epoch 15/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 5.9266e-07 - val_accuracy: 1.0000\n","Epoch 16/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0096 - accuracy: 0.9973 - val_loss: 4.5361e-07 - val_accuracy: 1.0000\n","Epoch 17/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 1.3560e-05 - val_accuracy: 1.0000\n","Epoch 18/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0165 - accuracy: 0.9948 - val_loss: 1.7067e-06 - val_accuracy: 1.0000\n","Epoch 19/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0178 - accuracy: 0.9949 - val_loss: 6.6785e-06 - val_accuracy: 1.0000\n","Epoch 20/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 6.2135e-04 - val_accuracy: 1.0000\n","Epoch 21/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 5.9075e-07 - val_accuracy: 1.0000\n","Epoch 22/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 4.4970e-06 - val_accuracy: 1.0000\n","Epoch 23/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0095 - accuracy: 0.9975 - val_loss: 1.5519e-06 - val_accuracy: 1.0000\n","Epoch 24/50\n","53/53 [==============================] - 2s 45ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 2.9197e-05 - val_accuracy: 1.0000\n","Epoch 25/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0112 - accuracy: 0.9970 - val_loss: 1.5719e-06 - val_accuracy: 1.0000\n","Epoch 26/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 1.8855e-06 - val_accuracy: 1.0000\n","Epoch 27/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 5.0575e-06 - val_accuracy: 1.0000\n","Epoch 28/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 2.1201e-06 - val_accuracy: 1.0000\n","Epoch 29/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 6.3710e-05 - val_accuracy: 1.0000\n","Epoch 30/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0145 - accuracy: 0.9966 - val_loss: 3.7515e-05 - val_accuracy: 1.0000\n","Epoch 31/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0110 - accuracy: 0.9957 - val_loss: 1.2913e-05 - val_accuracy: 1.0000\n","Epoch 32/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 2.6812e-06 - val_accuracy: 1.0000\n","Epoch 33/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0085 - accuracy: 0.9978 - val_loss: 2.8827e-06 - val_accuracy: 1.0000\n","Epoch 34/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 1.1241e-06 - val_accuracy: 1.0000\n","Epoch 35/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0115 - accuracy: 0.9972 - val_loss: 1.6519e-06 - val_accuracy: 1.0000\n","Epoch 36/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0093 - accuracy: 0.9975 - val_loss: 1.9192e-06 - val_accuracy: 1.0000\n","Epoch 37/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0099 - accuracy: 0.9975 - val_loss: 1.5805e-06 - val_accuracy: 1.0000\n","Epoch 38/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 5.6242e-07 - val_accuracy: 1.0000\n","Epoch 39/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 4.0252e-06 - val_accuracy: 1.0000\n","Epoch 40/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0137 - accuracy: 0.9969 - val_loss: 1.5973e-05 - val_accuracy: 1.0000\n","Epoch 41/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0106 - accuracy: 0.9976 - val_loss: 7.4553e-06 - val_accuracy: 1.0000\n","Epoch 42/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 1.1994e-04 - val_accuracy: 1.0000\n","Epoch 43/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 4.2320e-07 - val_accuracy: 1.0000\n","Epoch 44/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 1.6044e-05 - val_accuracy: 1.0000\n","Epoch 45/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0129 - accuracy: 0.9967 - val_loss: 1.0323e-06 - val_accuracy: 1.0000\n","Epoch 46/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 8.6799e-07 - val_accuracy: 1.0000\n","Epoch 47/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0159 - accuracy: 0.9967 - val_loss: 3.3005e-06 - val_accuracy: 1.0000\n","Epoch 48/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 1.2491e-04 - val_accuracy: 1.0000\n","Epoch 49/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 1.2041e-06 - val_accuracy: 1.0000\n","Epoch 50/50\n","53/53 [==============================] - 2s 45ms/step - loss: 0.0109 - accuracy: 0.9967 - val_loss: 1.8961e-07 - val_accuracy: 1.0000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Lr-SH0e6flrE","colab":{"base_uri":"https://localhost:8080/","height":722},"outputId":"80dbaffb-f468-42bd-a07c-271528bd2122"},"source":["acrc = model.evaluate(x_test, y_test)\n","pred = model.predict(x_test)\n","f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n","c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n","print(\"Accuracy  : {}\".format(acrc[1]))\n","print(\"F1_Score  : {}\".format(f1scr))\n","c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n","import seaborn as sns\n","figure = plt.figure(figsize=(9, 9))\n","sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n","plt.tight_layout()\n","plt.ylabel('True label')\n","plt.xlabel('Predicted label')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["59/59 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 0.9995\n","Accuracy  : 0.9994634985923767\n","F1_Score  : 0.9994777265218358\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAmgAAAKOCAYAAAAS8uXWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de7RdZXkv4N+bRIoK3ooEClGhxCoX73eHiigawIJU22ptPXrQVCteqvUUtQdbPGqv2mPBYrycoq1YqbcoabAHYYAM0SAqcqltvBSCkLSIVkVPIHznj70C2zTZexPYmR+Zz+NYY6w111xzfitjjc3r7/2+Oau1FgAA+rFg6AEAAPCzFGgAAJ1RoAEAdEaBBgDQGQUaAEBnFGgAAJ1RoAEA3A5V9YGq2lBVl27j/aqqd1XV2qq6pKoeMdsxFWgAALfP3yRZNsP7RyRZOnksT/LXsx1QgQYAcDu01s5L8r0ZdjkmyQfblAuT3Kuq9p7pmIvuyAHeke768OPd4oDBXb/m5KGHANCVXRelhjjvUHXBT796ym9nKvXabEVrbcVtPMw+Sa6a9nrdZNs12/pAtwUaAMDQJsXYbS3IbjctTgCA+XV1kiXTXu872bZNCjQAoH+1YJjHHWNlkhdOVnM+LskPWmvbbG8mWpwAALdLVZ2e5NAke1TVuiRvTnKXJGmtnZpkVZIjk6xNckOSF892TAUaAMDt0Fp7/izvtySvuC3HVKABAP2rQRaPDsYcNACAzkjQAID+3XET9u8UxvVtAQDuBCRoAED/zEEDAGBICjQAgM5ocQIA/bNIAACAIUnQAID+WSQAAMCQJGgAQP/MQQMAYEgKNACAzmhxAgD9s0gAAIAhSdAAgP5ZJAAAwJAUaAAAndHiBAD6Z5EAAABDkqABAP2zSAAAgCFJ0ACA/pmDBgDAkBRoAACd0eIEAPpnkQAAAEOSoAEA/ZOgAQAwJAkaANC/BS6zAQDAgBRoAACd0eIEAPpnkQAAAEOSoAEA/XMvTgAAhiRBAwD6Zw4aAABDUqABAHRGixMA6J9FAgAADEmCBgD0zyIBAACGpEADAOiMFicA0D+LBAAAGJIEDQDon0UCAAAMSYIGAPTPHDQAAIakQAMA6IwWJwDQP4sEAAAYkgQNAOifRQIAAAxJggYA9M8cNAAAhqRAAwDojBYnANA/LU4AAIYkQQMA+ucyGwAADEmCBgD0zxw0AACGpEADAOiMFicA0D+LBAAAGJIEDQDon0UCAAAMSYEGANAZLU4AoH8WCQAAMCQJGgDQvZKgAQAwJAkaANA9CRoAAINSoAEAdEaLEwDo37g6nBI0AIDeSNAAgO5ZJAAAwKAkaABA9yRoAAAMSoEGANAZLU4AoHtanAAADEqCBgB0T4IGAMCgJGgAQP/GFaBJ0AAAeqNA2wmd+uYX5N/OfnsuOuONQw+Fkbvg/PNy9FHPzLOWHZ73v3fF0MNhJzPb72vjxo15/etek2ctOzwveN6v5uqr193y3vvf+548a9nhOfqoZ+aCz5+fJLn2mmty3It+K8f+8pE59uij8ncfOm2HfRfYkgJtJ/ShT1+YY15xytDDYOQ2bdqUt731pLz71PflEyvPzOpVn8k3164deljsJOby+/rEx87IPe5xj3xm9T/lN1/4ovzlO/48SfLNtWuzetWZ+fjKM/Pu97wvb/tff5RNmzZl4aKF+b3/cUI+8elV+dvT/z4fOf3DfrMdqapBHkOZtwKtqh5UVb9fVe+aPH6/qh48X+fjVhdc/M187wc3DD0MRu7Sr1+SJUvun32XLMlddtkly448Kueec/bQw2InMZff1zmf+1yOPubYJMnhz3hmvnThF9Jay7nnnJ1lRx6VXXbZJfvuuyRLltw/l379ktz3vnvmwQcelCS5+913y/77758NG9bv8O8GyTwVaFX1+0k+kqkpfV+aPCrJ6VV1wnycE+jLhvXrs9fee93yes/Fi7N+vf/YcceYy+9rw4b12WuvvZMkixYtym67757vf//6rF+/Pov3uvWzi/danA1bfPbqq9fln6+4Ioc85KHz+C24LcaWoM3XKs7jkhzUWrtx+saqekeSy5L88dY+VFXLkyxPkkX7HppFexw0T8MDgK274cc/zute86q8/oQ3Zrfddht6OIzUfLU4b07yC1vZvvfkva1qra1orT2qtfYoxRncue25eHGuvebaW15vWL8+ixcvHnBE7Ezm8vvac8/Fufbaa5IkN910U370wx/mXve6dxYvXpz119762fXXrs+ek8/eeOONee1rXpUjj/rlPP3wZ+yAbwJbN18F2muSnF1V/1hVKyaP1UnOTvLqeTon0JGDDj4kV175naxbd1Vu3Lgxq1edmac89bChh8VOYi6/r0OfelhWfuoTSZJ/+uxZecxjH5eqylOeelhWrzozGzduzLp1V+XKK7+Tgw95SFpr+cMT35T9998/L3zRi4f4WsxAi/MO0FpbXVUPTPKYJPtMNl+dZE1rbdN8nJNbnfb2F+VJj1yaPe61W9aufkvecuqqnPbJLww9LEZm0aJFecObTszLl78kN9+8Kc8+9jk54IClQw+LncS2fl+n/NX/zkEHHZxDD3tajn3Oc/OmE16fZy07PPe45z3zp3/+ziTJAQcszTOWHZFjjz4yCxcuzBv/4MQsXLgwF3/5onxm5aey9IEPzK/9yjFJkle+5rV50pOfMuRXZaSqtTb0GLbqrg8/vs+BMSrXrzl56CEAdGXXRcNc0//nX3j6IHXBdR98/iDf13XQAAA6416cAED/3IsTAIAhKdAAADqjxQkAdG/IS14MQYIGANAZCRoA0D0JGgAAg5KgAQDdk6ABADAoBRoAQGe0OAGA/o2rwylBAwC4PapqWVV9o6rWVtUJW3n/flV1TlV9paouqaojZzumBA0A6F6viwSqamGSU5IcnmRdkjVVtbK1dvm03f4gyUdba39dVQcmWZXkATMdV4IGALD9HpNkbWvtW621jUk+kuSYLfZpSe4xeX7PJN+d7aAKNACAbaiq5VV10bTH8i122SfJVdNer5tsm+4Pk/xmVa3LVHr2ytnOq8UJAHRvqBZna21FkhW38zDPT/I3rbW/qKrHJ/lQVR3cWrt5Wx+QoAEAbL+rkyyZ9nrfybbpjkvy0SRprX0hya5J9pjpoAo0AKB7VTXIYw7WJFlaVftV1S5Jnpdk5Rb7XJnkaZPv8eBMFWj/PtNBFWgAANuptXZTkuOTnJXkikyt1rysqk6qqqMnu70uyUur6mtJTk/yotZam+m45qABAN3r9TIbSdJaW5Wpyf/Tt5047fnlSZ54W44pQQMA6IwCDQCgM1qcAED/+u1wzgsJGgBAZyRoAED3el4kMB8kaAAAnZGgAQDdk6ABADAoBRoAQGe0OAGA7mlxAgAwKAkaANC/cQVoEjQAgN5I0ACA7pmDBgDAoBRoAACd0eIEALqnxQkAwKAkaABA9yRoAAAMSoEGANAZLU4AoHtanAAADEqCBgD0b1wBmgQNAKA3EjQAoHvmoAEAMCgFGgBAZ7Q4AYDuaXECADAoCRoA0L2RBWgSNACA3kjQAIDumYMGAMCgFGgAAJ3R4gQAujeyDqcEDQCgNxI0AKB7FgkAADAoCRoA0L2RBWgSNACA3ijQAAA6o8UJAHRvwYJx9TglaAAAnZGgAQDds0gAAIBBKdAAADqjxQkAdM+dBAAAGJQEDQDo3sgCNAkaAEBvJGgAQPfMQQMAYFAKNACAzmhxAgDd0+IEAGBQEjQAoHsjC9AkaAAAvZGgAQDdMwcNAIBBKdAAADqjxQkAdG9kHU4JGgBAbyRoAED3LBIAAGBQEjQAoHsjC9AkaAAAvVGgAQB0RosTAOieRQIAAAxKggYAdG9kAZoEDQCgNwo0AIDOaHECAN2zSAAAgEF1m6Bdv+bkoYcAufejjx96CJDE30QYWYAmQQMA6E23CRoAwGbmoAEAMCgFGgBAZ7Q4AYDujazDKUEDAOiNBA0A6J5FAgAADEqCBgB0b2QBmgQNAKA3CjQAgM5ocQIA3bNIAACAQUnQAIDuSdAAABiUBA0A6N7IAjQJGgBAbxRoAACd0eIEALpnkQAAAIOSoAEA3RtZgCZBAwDojQINAKAzWpwAQPcsEgAAYFASNACgeyML0CRoAAC9kaABAN1bMLIITYIGANAZBRoAQGe0OAGA7o2swylBAwDojQQNAOieC9UCADAoCRoA0L0F4wrQJGgAAL1RoAEA3A5VtayqvlFVa6vqhG3s82tVdXlVXVZVH57tmFqcAED3el0kUFULk5yS5PAk65KsqaqVrbXLp+2zNMkbkjyxtXZ9Ve0523ElaAAA2+8xSda21r7VWtuY5CNJjtlin5cmOaW1dn2StNY2zHZQBRoA0L2qYR5zsE+Sq6a9XjfZNt0Dkzywqi6oqguratlsB9XiBADYhqpanmT5tE0rWmsrbuNhFiVZmuTQJPsmOa+qDmmtfX+mDwAAdK0yzBy0STE2U0F2dZIl017vO9k23bokX2yt3Zjk21X1L5kq2NZs66BanAAA229NkqVVtV9V7ZLkeUlWbrHPJzOVnqWq9shUy/NbMx1UgQYAsJ1aazclOT7JWUmuSPLR1tplVXVSVR092e2sJNdV1eVJzkny+tbadTMdV4sTAOhez3cSaK2tSrJqi20nTnvekrx28pgTCRoAQGckaABA93q9UO18kaABAHRGgQYA0BktTgCgeyPrcErQAAB6I0EDALq3YGQRmgQNAKAzEjQAoHsjC9AkaAAAvVGgAQB0RosTAOieOwkAADAoCRoA0L2RBWgSNACA3kjQAIDuuVAtAACDUqABAHRGixMA6N64GpwSNACA7kjQAIDuuVAtAACDkqABAN1bMK4ATYIGANAbBRoAQGe0OAGA7lkkAADAoCRoAED3RhagSdAAAHqjQAMA6IwWJwDQPYsEAAAYlAQNAOje2O4ksM0Crar+Kknb1vuttVfNy4gAAEZupgTtoh02CgCAGYxtDto2C7TW2mnTX1fV3VprN8z/kAAAxm3WRQJV9fiqujzJP09eP7Sq3j3vIwMAGKm5rOL8yyTPTHJdkrTWvpbkyfM5KACA6Wqgx1DmdJmN1tpVW2zaNA9jAQAgc7vMxlVV9YQkrarukuTVSa6Y32EBANxqwcgWCcwlQXtZklck2SfJd5M8bPIaAIB5MGuC1lr7jyQv2AFjAQDYqpEFaHNaxbl/VX26qv69qjZU1aeqav8dMTgAgDGaS4vzw0k+mmTvJL+Q5Iwkp8/noAAAxmwuBdrdWmsfaq3dNHn8bZJd53tgAACbVdUgj6HMdC/O+0ye/mNVnZDkI5m6N+evJ1m1A8YGADBKMy0S+HKmCrLN5eNvT3uvJXnDfA0KAGC6sS0SmOlenPvtyIEAADBlLheqTVUdnOTATJt71lr74HwNCgBgzGYt0KrqzUkOzVSBtirJEUk+n0SBBgDsEO4k8F89N8nTklzbWntxkocmuee8jgoAYMTmUqD9pLV2c5KbquoeSTYkWTK/w+L2uuD883L0Uc/Ms5Ydnve/d8XQw2GkTn3zC/JvZ789F53xxqGHwsj5m3jnVzXMYyhzKdAuqqp7JXlvplZ2XpzkC/M6Km6XTZs25W1vPSnvPvV9+cTKM7N61WfyzbVrhx4WI/ShT1+YY15xytDDYOT8TeTOaC734vydydNTq2p1knu01i6Z32Fxe1z69UuyZMn9s++SqaBz2ZFH5dxzzs4vHnDAwCNjbC64+Ju53973mX1HmEf+Ju4chrxo7BC2maBV1SO2fCS5T5JFk+fbpapevL2fZW42rF+fvfbe65bXey5enPXr1w84IoDh+JvIndFMCdpfzPBeS3LYdp7zj5L8n629UVXLkyxPkpPf/Z4c99Ll23kKAIA7r5kuVPvU7T1oVW2rBVpJFs9wzhVJViTJT29K297zj92eixfn2muuveX1hvXrs3jxNv/ZAXZq/ibuHOYyaX5nMl/fd3GSFyb55a08rpunczJx0MGH5Morv5N1667KjRs3ZvWqM/OUp25v4Alw5+ZvIndGc7qTwHb4TJLdWmtf3fKNqjp3ns7JxKJFi/KGN52Yly9/SW6+eVOefexzcsABS4ceFiN02ttflCc9cmn2uNduWbv6LXnLqaty2ictAmfH8jdx5zC2RQLVWp+dRC1OenDvRx8/9BAgSXL9mpOHHgIkSXZdlEEqpVd98p8HqQve9ewHDfJ953Krp0rygiT7t9ZOqqr7JdmrtfaleR8dAECSBeMK0OY0B+3dSR6f5PmT1z9M4sqTAADzZC5z0B7bWntEVX0lSVpr11fVLvM8LgCA0ZpLgXZjVS3M1LXPUlX3TXLzvI4KAGAaLc7/6l1JPpFkz6p6a5LPJ3nbvI4KAGDE5nIvzr+rqi8neVqmLjT77NbaFfM+MgCAibFdZmMuqzjvl+SGJJ+evq21duV8DgwAYKzmMgftzEzNP6skuybZL8k3khw0j+MCALjF2OagzaXFecj011X1iCS/M28jAgAYudt8L87W2sVJHjsPYwEAIHObg/baaS8XJHlEku/O24gAALYwsjUCc5qDtvu05zdlak7ax+ZnOAAAzFigTS5Qu3tr7fd20HgAAP6LBSOL0LY5B62qFrXWNiV54g4cDwDA6M2UoH0pU/PNvlpVK5OckeTHm99srX18nscGADBKc5mDtmuS65Iclluvh9aSKNAAgB3iNl924k5upgJtz8kKzktza2G2WZvXUQEAjNhMBdrCJLvlZwuzzRRoAMAOM7I1AjMWaNe01k7aYSMBACDJzAXayGpVAKBXLrNxq6ftsFEAAHCLbRZorbXv7ciBAAAwZS6X2QAAGNTIOpyju6wIAED3JGgAQPcWSNAAABiSBA0A6J7LbAAAMCgFGgBAZ7Q4AYDujazDKUEDAOiNBA0A6J7LbAAAMCgJGgDQvcq4IjQJGgBAZxRoAACd0eIEALpnkQAAAIOSoAEA3ZOgAQAwKAUaAEBntDgBgO7VyG7GKUEDAOiMBA0A6J5FAgAADEqCBgB0b2RT0CRoAAC9UaABAHRGixMA6N6CkfU4JWgAAJ2RoAEA3XOZDQAABqVAAwC6VzXMY25jq2VV9Y2qWltVJ8yw33OqqlXVo2Y7pgINAGA7VdXCJKckOSLJgUmeX1UHbmW/3ZO8OskX53JcBRoAwPZ7TJK1rbVvtdY2JvlIkmO2st9bkvxJkp/O5aAKNACgewtSgzzmYJ8kV017vW6y7RZV9YgkS1prZ879+wIAsFVVtbyqLpr2WH4bP78gyTuSvO62fM5lNgCA7g11ndrW2ookK2bY5eokS6a93neybbPdkxyc5Nya+hJ7JVlZVUe31i7a1kElaAAA229NkqVVtV9V7ZLkeUlWbn6ztfaD1toerbUHtNYekOTCJDMWZ4kEDQC4E+j1QrWttZuq6vgkZyVZmOQDrbXLquqkJBe11lbOfIStU6ABANwOrbVVSVZtse3Ebex76FyOqcUJANAZCRoA0L0FQ60SGIgEDQCgMxI0AKB7IwvQJGgAAL1RoAEAdEaLEwDonkUCAAAMSoIGAHRvZAGaBA0AoDcSNACge2NLlMb2fQEAuqdAAwDojBYnANC9GtkqAQkaAEBnJGgAQPfGlZ9J0AAAuiNBAwC651ZPAAAMSoEGANAZLU4AoHvjanBK0AAAuiNBAwC6N7I1AhI0AIDeSNAAgO651RMAAINSoAEAdEaLEwDo3tgSpbF9XwCA7knQAIDuWSQAAMCgFGgAAJ3R4gQAujeuBqcEDQCgOxI0AKB7Y1skoECDGVy/5uShhwBJkns/+vihhwBJkp98xd/FHUGBBgB0b2xzssb2fQEAuqdAAwDojBYnANC9sS0SkKABAHRGggYAdG9c+ZkEDQCgOxI0AKB7I5uCJkEDAOiNAg0AoDNanABA9xaMbJmABA0AoDMSNACgexYJAAAwKAkaANC9MgcNAIAhKdAAADqjxQkAdM8iAQAABiVBAwC650K1AAAMSoEGANAZLU4AoHsWCQAAMCgJGgDQPQkaAACDkqABAN1zL04AAAalQAMA6IwWJwDQvQXj6nBK0AAAeiNBAwC6Z5EAAACDkqABAN1zoVoAAAalQAMA6IwWJwDQPYsEAAAYlAQNAOieC9UCADAoCRoA0D1z0AAAGJQCDQCgM1qcAED33EkAAIBBSdAAgO6NLECToAEA9EaBBgDQGS1OAKB7C0a2SkCCBgDQGQkaANC9ceVnEjQAgO5I0ACA/o0sQpOgAQB0RoEGANAZLU4AoHs1sh6nBA0AoDMSNACgeyO7Tq0EDQCgNxI0AKB7IwvQJGgAAL1RoAEAdEaLEwDo38h6nBI0AIDOSNAAgO65UC0AAINSoAEAdEaLEwDonjsJAAAwKAkaANC9kQVoEjQAgN5I0ACA/o0sQpOgAQB0RoEGANAZLU4AoHvuJAAAwKAkaABA91yoFgCAOauqZVX1japaW1UnbOX911bV5VV1SVWdXVX3n+2YCjQAoHs10GPWcVUtTHJKkiOSHJjk+VV14Ba7fSXJo1prD0nyD0n+dLbjKtAAALbfY5Ksba19q7W2MclHkhwzfYfW2jmttRsmLy9Msu9sB1WgAQBsQ1Utr6qLpj2Wb7HLPkmumvZ63WTbthyX5B9nO69FAgBA/wZaJNBaW5FkxR1xrKr6zSSPSvKU2fZVoAEAbL+rkyyZ9nrfybafUVVPT/KmJE9prf2/2Q6qQAMAutfxhWrXJFlaVftlqjB7XpLfmL5DVT08yXuSLGutbZjLQc1BAwDYTq21m5Icn+SsJFck+Whr7bKqOqmqjp7s9mdJdktyRlV9tapWznZcCRoA0L2eL1TbWluVZNUW206c9vzpt/WYEjQAgM4o0AAAOqPFCQB0r+MO57yQoAEAdEaCBgD0b2QRmgQNAKAzCjQAgM5ocQIA3ev4TgLzQoIGANAZCRoA0L2e7yQwHyRoO6kLzj8vRx/1zDxr2eF5/3tXDD0cRsrvkB6c+uYX5N/OfnsuOuONQw8F5kyBthPatGlT3vbWk/LuU9+XT6w8M6tXfSbfXLt26GExMn6H9OJDn74wx7zilKGHwe1UAz2GMm8FWlU9qKqeVlW7bbF92XydkymXfv2SLFly/+y7ZEnusssuWXbkUTn3nLOHHhYj43dILy64+Jv53g9uGHoYcJvMS4FWVa9K8qkkr0xyaVUdM+3tt83HObnVhvXrs9fee93yes/Fi7N+/foBR8QY+R0CbL/5StBemuSRrbVnJzk0yf+sqldP3ttmYlhVy6vqoqq6yHwVAOAWI+txztcqzgWttR8lSWvtO1V1aJJ/qKr7Z4av21pbkWRFkvz0prR5GttOb8/Fi3PtNdfe8nrD+vVZvHjxgCNijPwOAbbffCVo66vqYZtfTIq1ZyXZI8kh83ROJg46+JBceeV3sm7dVblx48asXnVmnvLUw4YeFiPjdwjckWqg/w1lvhK0Fya5afqG1tpNSV5YVe+Zp3MysWjRorzhTSfm5ctfkptv3pRnH/ucHHDA0qGHxcj4HdKL097+ojzpkUuzx712y9rVb8lbTl2V0z75haGHBTOq1vrsJGpxAtzq3o8+fughQJLkJ185eZBY6RvX3jBIXfBLe91tkO/rOmgAAJ1RoAEAdMa9OAGA7o3sVpwSNACA3kjQAID+jSxCk6ABAHRGggYAdG/Ii8YOQYIGANAZBRoAQGe0OAGA7tW4OpwSNACA3kjQAIDujSxAk6ABAPRGgQYA0BktTgCgfyPrcUrQAAA6I0EDALrnTgIAAAxKggYAdM+FagEAGJQCDQCgM1qcAED3RtbhlKABAPRGggYA9G9kEZoEDQCgMxI0AKB7LlQLAMCgFGgAAJ3R4gQAuudOAgAADEqCBgB0b2QBmgQNAKA3EjQAoHvmoAEAMCgFGgBAZ7Q4AYA7gXH1OCVoAACdkaABAN2zSAAAgEEp0AAAOqPFCQB0b2QdTgkaAEBvJGgAQPcsEgAAYFASNACgezWyWWgSNACAzijQAAA6o8UJAPRvXB1OCRoAQG8kaABA90YWoEnQAAB6I0EDALrnQrUAAAxKgQYA0BktTgCge+4kAADAoCRoAED/xhWgSdAAAHojQQMAujeyAE2CBgDQGwUaAEBntDgBgO65kwAAAIOSoAEA3XOhWgAABqVAAwDojBYnANA9iwQAABiUAg0AoDMKNACAzpiDBgB0zxw0AAAGpUADAOiMFicA0D13EgAAYFASNACgexYJAAAwKAkaANC9kQVoEjQAgN4o0AAAOqPFCQD0b2Q9TgkaAEBnJGgAQPdcqBYAgEFJ0ACA7rlQLQAAg1KgAQB0RosTAOjeyDqcEjQAgN5I0ACA/o0sQpOgAQB0RoEGANAZLU4AoHvuJAAAwJxV1bKq+kZVra2qE7by/s9V1d9P3v9iVT1gtmMq0ACA7lUN85h9XLUwySlJjkhyYJLnV9WBW+x2XJLrW2sHJHlnkj+Z7bgKNACA7feYJGtba99qrW1M8pEkx2yxzzFJTps8/4ckT6uaufzrdg7arotG1myeB1W1vLW2YuhxgN/i7feTr5w89BDu9PwO79yGqguqanmS5dM2rdjid7RPkqumvV6X5LFbHOaWfVprN1XVD5L8fJL/2NZ5JWg7t+Wz7wI7hN8iPfA75DZrra1orT1q2mOHFPkKNACA7Xd1kiXTXu872bbVfapqUZJ7JrlupoMq0AAAtt+aJEurar+q2iXJ85Ks3GKflUn+2+T5c5N8rrXWZjpot3PQuEOYa0Ev/Bbpgd8hd7jJnLLjk5yVZGGSD7TWLquqk5Jc1FpbmeT9ST5UVWuTfC9TRdyMapYCDgCAHUyLEwCgMwo0AIDOKNB2UrPddgJ2hKr6QFVtqKpLhx4L41VVS6rqnKq6vKouq6pXDz0mmI05aDuhyW0n/iXJ4Zm6YN6aJM9vrV0+6MAYnap6cpIfJflga+3gocfDOFXV3kn2bq1dXFW7J/lykmf7m0jPJGg7p7ncdgLmXWvtvEytWILBtNauaa1dPHn+wyRXZOrK7tAtBdrOaWu3nfDHCBi9qnpAkocn+eKwI4GZKdAAGIWq2i3Jx5K8prX2n0OPB6QnNHAAAAQGSURBVGaiQNs5zeW2EwCjUVV3yVRx9nettY8PPR6YjQJt5zSX204AjEJVVaau5H5Fa+0dQ48H5kKBthNqrd2UZPNtJ65I8tHW2mXDjooxqqrTk3whyS9V1bqqOm7oMTFKT0zyW0kOq6qvTh5HDj0omInLbAAAdEaCBgDQGQUaAEBnFGgAAJ1RoAEAdEaBBgDQGQUa7ISqatPkUgKXVtUZVXW323Gsv6mq506ev6+qDpxh30Or6gnbcY7vVNUec92+xT4/uo3n+sOq+r3bOkaAHUmBBjunn7TWHtZaOzjJxiQvm/5mVS3anoO21l7SWrt8hl0OTXKbCzQAfpYCDXZ+5yc5YJJunV9VK5NcXlULq+rPqmpNVV1SVb+dTF11vapOrqpvVNX/TbLn5gNV1blV9ajJ82VVdXFVfa2qzp7chPplSX53kt49qaruW1Ufm5xjTVU9cfLZn6+qz1bVZVX1viQ125eoqk9W1Zcnn1m+xXvvnGw/u6ruO9n2i1W1evKZ86vqQXfEPybAjrBd/y8auHOYJGVHJFk92fSIJAe31r49KXJ+0Fp7dFX9XJILquqzSR6e5JeSHJhkcZLLk3xgi+PeN8l7kzx5cqz7tNa+V1WnJvlRa+3PJ/t9OMk7W2ufr6r7ZeruFg9O8uYkn2+tnVRVRyWZyx0G/vvkHHdNsqaqPtZauy7J3ZNc1Fr73ao6cXLs45OsSPKy1tq/VtVjk7w7yWHb8c8IsMMp0GDndNeq+urk+fmZug/hE5J8qbX27cn2ZyR5yOb5ZUnumWRpkicnOb21tinJd6vqc1s5/uOSnLf5WK21721jHE9PcuDUrRCTJPeoqt0m5/iVyWfPrKrr5/CdXlVVx06eL5mM9bokNyf5+8n2v03y8ck5npDkjGnn/rk5nAOgCwo02Dn9pLX2sOkbJoXKj6dvSvLK1tpZW+x3R96jcEGSx7XWfrqVscxZVR2aqWLv8a21G6rq3CS7bmP3Njnv97f8NwC4szAHDcbrrCQvr6q7JElVPbCq7p7kvCS/PpmjtneSp27lsxcmeXJV7Tf57H0m23+YZPdp+302ySs3v6iqzQXTeUl+Y7LtiCT3nmWs90xy/aQ4e1CmErzNFiTZnAL+RqZap/+Z5NtV9auTc1RVPXSWcwB0Q4EG4/W+TM0vu7iqLk3ynkyl6p9I8q+T9z6Y5AtbfrC19u9Jlmeqnfi13Npi/HSSYzcvEkjyqiSPmixCuDy3rib9o0wVeJdlqtV55SxjXZ1kUVVdkeSPM1UgbvbjJI+ZfIfDkpw02f6CJMdNxndZkmPm8G8C0IVqrQ09BgAAppGgAQB0RoEGANAZBRoAQGcUaAAAnVGgAQB0RoEGANAZBRoAQGf+P0Zk9/tyWTqSAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 648x648 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"lJehdYs6ZBcD"},"source":["# **Dominance**"]},{"cell_type":"code","metadata":{"id":"MqwJWlxMZEe6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7a8ee7c7-e2b9-4f90-f2cd-6864e5b6a3a1"},"source":["#dominance\n","X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n","print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UljSiW-xZMC_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"03cc21e0-fcfc-46f8-a826-9a6e26ce68af"},"source":["foldNum=0\n","model = get_model()\n","for train_index, val_index in kfold.split(X_train, Y_train):\n","  foldNum = foldNum + 1\n","  print(\"Results for fold\",foldNum)\n","  x_train, x_val = X_train[train_index], X_train[val_index]\n","  y_train, y_val = Y_train[train_index], Y_train[val_index]\n","  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n","  gc.collect() # Garbage collecter\n","  del x_train, x_val, y_train, y_val\n","  gc.collect()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Results for fold 1\n","Epoch 1/50\n","53/53 [==============================] - 4s 53ms/step - loss: 1.1432 - accuracy: 0.4195 - val_loss: 1.0363 - val_accuracy: 0.4330\n","Epoch 2/50\n","53/53 [==============================] - 2s 41ms/step - loss: 1.0247 - accuracy: 0.4497 - val_loss: 1.0433 - val_accuracy: 0.4370\n","Epoch 3/50\n","53/53 [==============================] - 2s 42ms/step - loss: 1.0288 - accuracy: 0.4481 - val_loss: 1.0293 - val_accuracy: 0.4410\n","Epoch 4/50\n","53/53 [==============================] - 2s 42ms/step - loss: 1.0139 - accuracy: 0.4540 - val_loss: 1.0190 - val_accuracy: 0.4598\n","Epoch 5/50\n","53/53 [==============================] - 2s 42ms/step - loss: 1.0217 - accuracy: 0.4491 - val_loss: 1.0152 - val_accuracy: 0.4678\n","Epoch 6/50\n","53/53 [==============================] - 2s 43ms/step - loss: 1.0112 - accuracy: 0.4433 - val_loss: 1.0189 - val_accuracy: 0.4745\n","Epoch 7/50\n","53/53 [==============================] - 2s 42ms/step - loss: 1.0047 - accuracy: 0.4626 - val_loss: 1.0135 - val_accuracy: 0.4692\n","Epoch 8/50\n","53/53 [==============================] - 2s 43ms/step - loss: 1.0120 - accuracy: 0.4591 - val_loss: 1.0105 - val_accuracy: 0.4705\n","Epoch 9/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.9984 - accuracy: 0.4692 - val_loss: 1.0074 - val_accuracy: 0.4732\n","Epoch 10/50\n","53/53 [==============================] - 2s 42ms/step - loss: 1.0051 - accuracy: 0.4523 - val_loss: 1.0081 - val_accuracy: 0.4759\n","Epoch 11/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.9915 - accuracy: 0.4734 - val_loss: 1.0075 - val_accuracy: 0.4799\n","Epoch 12/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.9943 - accuracy: 0.4773 - val_loss: 1.0060 - val_accuracy: 0.4558\n","Epoch 13/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.9893 - accuracy: 0.4736 - val_loss: 1.0031 - val_accuracy: 0.4638\n","Epoch 14/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.9820 - accuracy: 0.4655 - val_loss: 1.0010 - val_accuracy: 0.4732\n","Epoch 15/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.9781 - accuracy: 0.4785 - val_loss: 1.0024 - val_accuracy: 0.4692\n","Epoch 16/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.9854 - accuracy: 0.4760 - val_loss: 0.9899 - val_accuracy: 0.4879\n","Epoch 17/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.9798 - accuracy: 0.4831 - val_loss: 0.9876 - val_accuracy: 0.4692\n","Epoch 18/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.9720 - accuracy: 0.4766 - val_loss: 0.9791 - val_accuracy: 0.4826\n","Epoch 19/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.9670 - accuracy: 0.4706 - val_loss: 0.9933 - val_accuracy: 0.4853\n","Epoch 20/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.9564 - accuracy: 0.4880 - val_loss: 0.9778 - val_accuracy: 0.5080\n","Epoch 21/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.9580 - accuracy: 0.4755 - val_loss: 0.9499 - val_accuracy: 0.5295\n","Epoch 22/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.9380 - accuracy: 0.5062 - val_loss: 0.9758 - val_accuracy: 0.5040\n","Epoch 23/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.9461 - accuracy: 0.5019 - val_loss: 0.9520 - val_accuracy: 0.4879\n","Epoch 24/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.9401 - accuracy: 0.5099 - val_loss: 0.9501 - val_accuracy: 0.5134\n","Epoch 25/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.9300 - accuracy: 0.5155 - val_loss: 0.9500 - val_accuracy: 0.4933\n","Epoch 26/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.9249 - accuracy: 0.5160 - val_loss: 0.9327 - val_accuracy: 0.5094\n","Epoch 27/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.9242 - accuracy: 0.5086 - val_loss: 0.9335 - val_accuracy: 0.5134\n","Epoch 28/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.9127 - accuracy: 0.5144 - val_loss: 0.9332 - val_accuracy: 0.5000\n","Epoch 29/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.9027 - accuracy: 0.5248 - val_loss: 0.9597 - val_accuracy: 0.5094\n","Epoch 30/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.9005 - accuracy: 0.5307 - val_loss: 0.9178 - val_accuracy: 0.5389\n","Epoch 31/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.8911 - accuracy: 0.5371 - val_loss: 0.9111 - val_accuracy: 0.5080\n","Epoch 32/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.8790 - accuracy: 0.5475 - val_loss: 0.8975 - val_accuracy: 0.5389\n","Epoch 33/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.8705 - accuracy: 0.5481 - val_loss: 0.9084 - val_accuracy: 0.5349\n","Epoch 34/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.8676 - accuracy: 0.5450 - val_loss: 0.8768 - val_accuracy: 0.5469\n","Epoch 35/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.8715 - accuracy: 0.5460 - val_loss: 0.8877 - val_accuracy: 0.5550\n","Epoch 36/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.8427 - accuracy: 0.5648 - val_loss: 0.8896 - val_accuracy: 0.5724\n","Epoch 37/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.8252 - accuracy: 0.5747 - val_loss: 0.8514 - val_accuracy: 0.5710\n","Epoch 38/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.8293 - accuracy: 0.5747 - val_loss: 0.8905 - val_accuracy: 0.5777\n","Epoch 39/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.7970 - accuracy: 0.5979 - val_loss: 0.8383 - val_accuracy: 0.5871\n","Epoch 40/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.7964 - accuracy: 0.6005 - val_loss: 0.8210 - val_accuracy: 0.5831\n","Epoch 41/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.7867 - accuracy: 0.6037 - val_loss: 0.8280 - val_accuracy: 0.5912\n","Epoch 42/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.7561 - accuracy: 0.6181 - val_loss: 0.8160 - val_accuracy: 0.6086\n","Epoch 43/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.7461 - accuracy: 0.6234 - val_loss: 0.8082 - val_accuracy: 0.6139\n","Epoch 44/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.7251 - accuracy: 0.6438 - val_loss: 0.7618 - val_accuracy: 0.6542\n","Epoch 45/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.7128 - accuracy: 0.6459 - val_loss: 0.7364 - val_accuracy: 0.6488\n","Epoch 46/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.7251 - accuracy: 0.6431 - val_loss: 0.6910 - val_accuracy: 0.6850\n","Epoch 47/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.6426 - accuracy: 0.6846 - val_loss: 0.7036 - val_accuracy: 0.6689\n","Epoch 48/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.6174 - accuracy: 0.7109 - val_loss: 0.7018 - val_accuracy: 0.6944\n","Epoch 49/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.6046 - accuracy: 0.7195 - val_loss: 0.6290 - val_accuracy: 0.7212\n","Epoch 50/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.5681 - accuracy: 0.7382 - val_loss: 0.7011 - val_accuracy: 0.6863\n","Results for fold 2\n","Epoch 1/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.5781 - accuracy: 0.7414 - val_loss: 0.4188 - val_accuracy: 0.8164\n","Epoch 2/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.5422 - accuracy: 0.7565 - val_loss: 0.3694 - val_accuracy: 0.8472\n","Epoch 3/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.4877 - accuracy: 0.7946 - val_loss: 0.4812 - val_accuracy: 0.7802\n","Epoch 4/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.4854 - accuracy: 0.7955 - val_loss: 0.3537 - val_accuracy: 0.8432\n","Epoch 5/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.4380 - accuracy: 0.8107 - val_loss: 0.3822 - val_accuracy: 0.8445\n","Epoch 6/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.4329 - accuracy: 0.8201 - val_loss: 0.3099 - val_accuracy: 0.8820\n","Epoch 7/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.3863 - accuracy: 0.8432 - val_loss: 0.2605 - val_accuracy: 0.9035\n","Epoch 8/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.3398 - accuracy: 0.8669 - val_loss: 0.2352 - val_accuracy: 0.9115\n","Epoch 9/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.3297 - accuracy: 0.8727 - val_loss: 0.2394 - val_accuracy: 0.9102\n","Epoch 10/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.3060 - accuracy: 0.8808 - val_loss: 0.2386 - val_accuracy: 0.9115\n","Epoch 11/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.2571 - accuracy: 0.9051 - val_loss: 0.2285 - val_accuracy: 0.9102\n","Epoch 12/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.2433 - accuracy: 0.9083 - val_loss: 0.2936 - val_accuracy: 0.8968\n","Epoch 13/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.2370 - accuracy: 0.9131 - val_loss: 0.1932 - val_accuracy: 0.9303\n","Epoch 14/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.2199 - accuracy: 0.9209 - val_loss: 0.1822 - val_accuracy: 0.9370\n","Epoch 15/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.2050 - accuracy: 0.9249 - val_loss: 0.1690 - val_accuracy: 0.9424\n","Epoch 16/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.1807 - accuracy: 0.9365 - val_loss: 0.1456 - val_accuracy: 0.9571\n","Epoch 17/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.1685 - accuracy: 0.9419 - val_loss: 0.1812 - val_accuracy: 0.9276\n","Epoch 18/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.1451 - accuracy: 0.9507 - val_loss: 0.1410 - val_accuracy: 0.9544\n","Epoch 19/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.1526 - accuracy: 0.9472 - val_loss: 0.1196 - val_accuracy: 0.9625\n","Epoch 20/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.1393 - accuracy: 0.9528 - val_loss: 0.1703 - val_accuracy: 0.9424\n","Epoch 21/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.1298 - accuracy: 0.9584 - val_loss: 0.1518 - val_accuracy: 0.9450\n","Epoch 22/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.1163 - accuracy: 0.9611 - val_loss: 0.1502 - val_accuracy: 0.9517\n","Epoch 23/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.1197 - accuracy: 0.9571 - val_loss: 0.1468 - val_accuracy: 0.9477\n","Epoch 24/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.1183 - accuracy: 0.9608 - val_loss: 0.1414 - val_accuracy: 0.9477\n","Epoch 25/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.1179 - accuracy: 0.9598 - val_loss: 0.1621 - val_accuracy: 0.9343\n","Epoch 26/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.1086 - accuracy: 0.9645 - val_loss: 0.1338 - val_accuracy: 0.9584\n","Epoch 27/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.1094 - accuracy: 0.9647 - val_loss: 0.1413 - val_accuracy: 0.9611\n","Epoch 28/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.1001 - accuracy: 0.9689 - val_loss: 0.1166 - val_accuracy: 0.9544\n","Epoch 29/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0828 - accuracy: 0.9732 - val_loss: 0.1323 - val_accuracy: 0.9584\n","Epoch 30/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0904 - accuracy: 0.9705 - val_loss: 0.1474 - val_accuracy: 0.9571\n","Epoch 31/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0839 - accuracy: 0.9709 - val_loss: 0.0912 - val_accuracy: 0.9678\n","Epoch 32/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0826 - accuracy: 0.9721 - val_loss: 0.0878 - val_accuracy: 0.9705\n","Epoch 33/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0692 - accuracy: 0.9776 - val_loss: 0.1204 - val_accuracy: 0.9625\n","Epoch 34/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0732 - accuracy: 0.9751 - val_loss: 0.0881 - val_accuracy: 0.9705\n","Epoch 35/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0735 - accuracy: 0.9754 - val_loss: 0.0853 - val_accuracy: 0.9732\n","Epoch 36/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0851 - accuracy: 0.9726 - val_loss: 0.1043 - val_accuracy: 0.9638\n","Epoch 37/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0811 - accuracy: 0.9757 - val_loss: 0.1322 - val_accuracy: 0.9598\n","Epoch 38/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0661 - accuracy: 0.9791 - val_loss: 0.1064 - val_accuracy: 0.9732\n","Epoch 39/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0850 - accuracy: 0.9741 - val_loss: 0.0960 - val_accuracy: 0.9665\n","Epoch 40/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0550 - accuracy: 0.9809 - val_loss: 0.1136 - val_accuracy: 0.9665\n","Epoch 41/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0742 - accuracy: 0.9775 - val_loss: 0.0864 - val_accuracy: 0.9678\n","Epoch 42/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0526 - accuracy: 0.9839 - val_loss: 0.0774 - val_accuracy: 0.9772\n","Epoch 43/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0521 - accuracy: 0.9842 - val_loss: 0.1191 - val_accuracy: 0.9678\n","Epoch 44/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0625 - accuracy: 0.9826 - val_loss: 0.1152 - val_accuracy: 0.9678\n","Epoch 45/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0517 - accuracy: 0.9823 - val_loss: 0.0910 - val_accuracy: 0.9692\n","Epoch 46/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0583 - accuracy: 0.9821 - val_loss: 0.0860 - val_accuracy: 0.9732\n","Epoch 47/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0541 - accuracy: 0.9830 - val_loss: 0.0845 - val_accuracy: 0.9732\n","Epoch 48/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0543 - accuracy: 0.9845 - val_loss: 0.0876 - val_accuracy: 0.9665\n","Epoch 49/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0598 - accuracy: 0.9814 - val_loss: 0.0920 - val_accuracy: 0.9732\n","Epoch 50/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0442 - accuracy: 0.9873 - val_loss: 0.0875 - val_accuracy: 0.9718\n","Results for fold 3\n","Epoch 1/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0724 - accuracy: 0.9790 - val_loss: 3.7278e-04 - val_accuracy: 1.0000\n","Epoch 2/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0555 - accuracy: 0.9808 - val_loss: 1.7168e-04 - val_accuracy: 1.0000\n","Epoch 3/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0646 - accuracy: 0.9800 - val_loss: 3.6052e-04 - val_accuracy: 1.0000\n","Epoch 4/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0572 - accuracy: 0.9814 - val_loss: 0.0017 - val_accuracy: 1.0000\n","Epoch 5/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0557 - accuracy: 0.9842 - val_loss: 6.7536e-04 - val_accuracy: 1.0000\n","Epoch 6/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0398 - accuracy: 0.9864 - val_loss: 5.5701e-04 - val_accuracy: 1.0000\n","Epoch 7/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0394 - accuracy: 0.9879 - val_loss: 6.9099e-04 - val_accuracy: 1.0000\n","Epoch 8/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0556 - accuracy: 0.9835 - val_loss: 4.0891e-04 - val_accuracy: 1.0000\n","Epoch 9/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0569 - accuracy: 0.9824 - val_loss: 4.5334e-04 - val_accuracy: 1.0000\n","Epoch 10/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0566 - accuracy: 0.9839 - val_loss: 3.6828e-04 - val_accuracy: 1.0000\n","Epoch 11/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0419 - accuracy: 0.9852 - val_loss: 1.1950e-04 - val_accuracy: 1.0000\n","Epoch 12/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0500 - accuracy: 0.9849 - val_loss: 0.0012 - val_accuracy: 1.0000\n","Epoch 13/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0387 - accuracy: 0.9885 - val_loss: 3.0744e-04 - val_accuracy: 1.0000\n","Epoch 14/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0423 - accuracy: 0.9885 - val_loss: 0.0012 - val_accuracy: 1.0000\n","Epoch 15/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0370 - accuracy: 0.9881 - val_loss: 0.0065 - val_accuracy: 0.9987\n","Epoch 16/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0423 - accuracy: 0.9872 - val_loss: 0.0028 - val_accuracy: 0.9987\n","Epoch 17/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0495 - accuracy: 0.9842 - val_loss: 0.0023 - val_accuracy: 1.0000\n","Epoch 18/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0325 - accuracy: 0.9903 - val_loss: 0.0022 - val_accuracy: 1.0000\n","Epoch 19/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0315 - accuracy: 0.9897 - val_loss: 0.0076 - val_accuracy: 0.9973\n","Epoch 20/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0308 - accuracy: 0.9906 - val_loss: 0.0065 - val_accuracy: 0.9987\n","Epoch 21/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0343 - accuracy: 0.9864 - val_loss: 0.0035 - val_accuracy: 0.9987\n","Epoch 22/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0460 - accuracy: 0.9864 - val_loss: 4.6277e-04 - val_accuracy: 1.0000\n","Epoch 23/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0513 - accuracy: 0.9849 - val_loss: 0.0015 - val_accuracy: 1.0000\n","Epoch 24/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0352 - accuracy: 0.9890 - val_loss: 6.2693e-04 - val_accuracy: 1.0000\n","Epoch 25/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0351 - accuracy: 0.9891 - val_loss: 9.5590e-04 - val_accuracy: 1.0000\n","Epoch 26/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0385 - accuracy: 0.9878 - val_loss: 7.5987e-04 - val_accuracy: 1.0000\n","Epoch 27/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0407 - accuracy: 0.9873 - val_loss: 4.7091e-04 - val_accuracy: 1.0000\n","Epoch 28/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0271 - accuracy: 0.9903 - val_loss: 0.0011 - val_accuracy: 1.0000\n","Epoch 29/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0265 - accuracy: 0.9912 - val_loss: 0.0070 - val_accuracy: 0.9960\n","Epoch 30/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0374 - accuracy: 0.9887 - val_loss: 0.0028 - val_accuracy: 0.9987\n","Epoch 31/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0392 - accuracy: 0.9872 - val_loss: 0.0046 - val_accuracy: 0.9973\n","Epoch 32/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0329 - accuracy: 0.9908 - val_loss: 8.6987e-04 - val_accuracy: 1.0000\n","Epoch 33/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0256 - accuracy: 0.9909 - val_loss: 0.0030 - val_accuracy: 0.9987\n","Epoch 34/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0282 - accuracy: 0.9920 - val_loss: 0.0034 - val_accuracy: 0.9987\n","Epoch 35/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0370 - accuracy: 0.9884 - val_loss: 2.0862e-04 - val_accuracy: 1.0000\n","Epoch 36/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0369 - accuracy: 0.9875 - val_loss: 0.0019 - val_accuracy: 1.0000\n","Epoch 37/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0398 - accuracy: 0.9860 - val_loss: 0.0032 - val_accuracy: 0.9987\n","Epoch 38/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0297 - accuracy: 0.9908 - val_loss: 6.5184e-04 - val_accuracy: 1.0000\n","Epoch 39/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0504 - accuracy: 0.9826 - val_loss: 0.0016 - val_accuracy: 1.0000\n","Epoch 40/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0332 - accuracy: 0.9911 - val_loss: 3.9751e-04 - val_accuracy: 1.0000\n","Epoch 41/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0375 - accuracy: 0.9876 - val_loss: 0.0016 - val_accuracy: 1.0000\n","Epoch 42/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0181 - accuracy: 0.9939 - val_loss: 1.3683e-04 - val_accuracy: 1.0000\n","Epoch 43/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0260 - accuracy: 0.9914 - val_loss: 0.0016 - val_accuracy: 1.0000\n","Epoch 44/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0414 - accuracy: 0.9875 - val_loss: 0.0027 - val_accuracy: 0.9987\n","Epoch 45/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0273 - accuracy: 0.9915 - val_loss: 6.8420e-04 - val_accuracy: 1.0000\n","Epoch 46/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0287 - accuracy: 0.9906 - val_loss: 1.6908e-04 - val_accuracy: 1.0000\n","Epoch 47/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0228 - accuracy: 0.9933 - val_loss: 1.1642e-04 - val_accuracy: 1.0000\n","Epoch 48/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0234 - accuracy: 0.9934 - val_loss: 5.4106e-04 - val_accuracy: 1.0000\n","Epoch 49/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0308 - accuracy: 0.9891 - val_loss: 0.0081 - val_accuracy: 0.9946\n","Epoch 50/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0442 - accuracy: 0.9873 - val_loss: 0.0011 - val_accuracy: 1.0000\n","Results for fold 4\n","Epoch 1/50\n","53/53 [==============================] - 2s 45ms/step - loss: 0.0352 - accuracy: 0.9890 - val_loss: 7.1085e-05 - val_accuracy: 1.0000\n","Epoch 2/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0309 - accuracy: 0.9906 - val_loss: 2.1986e-05 - val_accuracy: 1.0000\n","Epoch 3/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0234 - accuracy: 0.9928 - val_loss: 1.1358e-05 - val_accuracy: 1.0000\n","Epoch 4/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0380 - accuracy: 0.9887 - val_loss: 4.1655e-04 - val_accuracy: 1.0000\n","Epoch 5/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0280 - accuracy: 0.9909 - val_loss: 6.0781e-05 - val_accuracy: 1.0000\n","Epoch 6/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0301 - accuracy: 0.9902 - val_loss: 1.7038e-05 - val_accuracy: 1.0000\n","Epoch 7/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0241 - accuracy: 0.9923 - val_loss: 1.2703e-04 - val_accuracy: 1.0000\n","Epoch 8/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0268 - accuracy: 0.9906 - val_loss: 6.7394e-05 - val_accuracy: 1.0000\n","Epoch 9/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0241 - accuracy: 0.9924 - val_loss: 2.6768e-04 - val_accuracy: 1.0000\n","Epoch 10/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0242 - accuracy: 0.9920 - val_loss: 5.4403e-05 - val_accuracy: 1.0000\n","Epoch 11/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0342 - accuracy: 0.9893 - val_loss: 1.5562e-04 - val_accuracy: 1.0000\n","Epoch 12/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0309 - accuracy: 0.9914 - val_loss: 1.4411e-04 - val_accuracy: 1.0000\n","Epoch 13/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0313 - accuracy: 0.9900 - val_loss: 2.5002e-04 - val_accuracy: 1.0000\n","Epoch 14/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0245 - accuracy: 0.9924 - val_loss: 1.1961e-04 - val_accuracy: 1.0000\n","Epoch 15/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0213 - accuracy: 0.9925 - val_loss: 7.2785e-05 - val_accuracy: 1.0000\n","Epoch 16/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0223 - accuracy: 0.9923 - val_loss: 1.0778e-04 - val_accuracy: 1.0000\n","Epoch 17/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0291 - accuracy: 0.9918 - val_loss: 7.2552e-05 - val_accuracy: 1.0000\n","Epoch 18/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0297 - accuracy: 0.9908 - val_loss: 3.0536e-04 - val_accuracy: 1.0000\n","Epoch 19/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0334 - accuracy: 0.9900 - val_loss: 7.6099e-05 - val_accuracy: 1.0000\n","Epoch 20/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0331 - accuracy: 0.9903 - val_loss: 3.5696e-04 - val_accuracy: 1.0000\n","Epoch 21/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0279 - accuracy: 0.9915 - val_loss: 1.5559e-04 - val_accuracy: 1.0000\n","Epoch 22/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0181 - accuracy: 0.9957 - val_loss: 1.0092e-04 - val_accuracy: 1.0000\n","Epoch 23/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0266 - accuracy: 0.9921 - val_loss: 5.9197e-04 - val_accuracy: 1.0000\n","Epoch 24/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0212 - accuracy: 0.9937 - val_loss: 1.0896e-04 - val_accuracy: 1.0000\n","Epoch 25/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0228 - accuracy: 0.9936 - val_loss: 1.3729e-04 - val_accuracy: 1.0000\n","Epoch 26/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 2.6339e-05 - val_accuracy: 1.0000\n","Epoch 27/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0180 - accuracy: 0.9945 - val_loss: 1.3654e-04 - val_accuracy: 1.0000\n","Epoch 28/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0282 - accuracy: 0.9906 - val_loss: 0.0011 - val_accuracy: 1.0000\n","Epoch 29/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0341 - accuracy: 0.9896 - val_loss: 6.9758e-04 - val_accuracy: 1.0000\n","Epoch 30/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0331 - accuracy: 0.9894 - val_loss: 0.0018 - val_accuracy: 0.9987\n","Epoch 31/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0326 - accuracy: 0.9905 - val_loss: 2.6339e-04 - val_accuracy: 1.0000\n","Epoch 32/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0237 - accuracy: 0.9940 - val_loss: 5.4417e-04 - val_accuracy: 1.0000\n","Epoch 33/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0217 - accuracy: 0.9925 - val_loss: 4.8884e-05 - val_accuracy: 1.0000\n","Epoch 34/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0249 - accuracy: 0.9915 - val_loss: 0.0011 - val_accuracy: 1.0000\n","Epoch 35/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 2.2782e-04 - val_accuracy: 1.0000\n","Epoch 36/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0225 - accuracy: 0.9936 - val_loss: 5.3095e-05 - val_accuracy: 1.0000\n","Epoch 37/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0212 - accuracy: 0.9937 - val_loss: 2.8079e-04 - val_accuracy: 1.0000\n","Epoch 38/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0225 - accuracy: 0.9925 - val_loss: 8.9670e-04 - val_accuracy: 1.0000\n","Epoch 39/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0212 - accuracy: 0.9942 - val_loss: 2.7607e-04 - val_accuracy: 1.0000\n","Epoch 40/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0305 - accuracy: 0.9899 - val_loss: 1.6565e-04 - val_accuracy: 1.0000\n","Epoch 41/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0275 - accuracy: 0.9911 - val_loss: 1.0777e-04 - val_accuracy: 1.0000\n","Epoch 42/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0241 - accuracy: 0.9933 - val_loss: 6.9199e-05 - val_accuracy: 1.0000\n","Epoch 43/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0239 - accuracy: 0.9927 - val_loss: 6.1026e-05 - val_accuracy: 1.0000\n","Epoch 44/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0237 - accuracy: 0.9934 - val_loss: 8.7065e-05 - val_accuracy: 1.0000\n","Epoch 45/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0166 - accuracy: 0.9943 - val_loss: 1.3986e-04 - val_accuracy: 1.0000\n","Epoch 46/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0240 - accuracy: 0.9936 - val_loss: 9.3530e-04 - val_accuracy: 1.0000\n","Epoch 47/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0224 - accuracy: 0.9933 - val_loss: 1.6234e-04 - val_accuracy: 1.0000\n","Epoch 48/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0188 - accuracy: 0.9945 - val_loss: 9.8178e-05 - val_accuracy: 1.0000\n","Epoch 49/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 1.2209e-05 - val_accuracy: 1.0000\n","Epoch 50/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0173 - accuracy: 0.9951 - val_loss: 8.5166e-05 - val_accuracy: 1.0000\n","Results for fold 5\n","Epoch 1/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0346 - accuracy: 0.9903 - val_loss: 0.0253 - val_accuracy: 0.9933\n","Epoch 2/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0247 - accuracy: 0.9914 - val_loss: 5.1006e-04 - val_accuracy: 1.0000\n","Epoch 3/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0174 - accuracy: 0.9942 - val_loss: 3.8240e-04 - val_accuracy: 1.0000\n","Epoch 4/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0199 - accuracy: 0.9948 - val_loss: 1.7058e-05 - val_accuracy: 1.0000\n","Epoch 5/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0242 - accuracy: 0.9920 - val_loss: 4.2406e-05 - val_accuracy: 1.0000\n","Epoch 6/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0176 - accuracy: 0.9957 - val_loss: 4.8154e-04 - val_accuracy: 1.0000\n","Epoch 7/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0317 - accuracy: 0.9909 - val_loss: 8.7854e-05 - val_accuracy: 1.0000\n","Epoch 8/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0238 - accuracy: 0.9936 - val_loss: 4.0296e-04 - val_accuracy: 1.0000\n","Epoch 9/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0192 - accuracy: 0.9931 - val_loss: 2.1289e-05 - val_accuracy: 1.0000\n","Epoch 10/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0257 - accuracy: 0.9927 - val_loss: 6.5187e-05 - val_accuracy: 1.0000\n","Epoch 11/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0298 - accuracy: 0.9897 - val_loss: 2.3612e-04 - val_accuracy: 1.0000\n","Epoch 12/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0252 - accuracy: 0.9921 - val_loss: 1.7135e-04 - val_accuracy: 1.0000\n","Epoch 13/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0213 - accuracy: 0.9942 - val_loss: 9.8954e-04 - val_accuracy: 1.0000\n","Epoch 14/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0162 - accuracy: 0.9940 - val_loss: 9.4046e-05 - val_accuracy: 1.0000\n","Epoch 15/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 2.0653e-04 - val_accuracy: 1.0000\n","Epoch 16/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 4.9087e-05 - val_accuracy: 1.0000\n","Epoch 17/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0191 - accuracy: 0.9943 - val_loss: 5.0806e-05 - val_accuracy: 1.0000\n","Epoch 18/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0221 - accuracy: 0.9928 - val_loss: 1.8610e-05 - val_accuracy: 1.0000\n","Epoch 19/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0188 - accuracy: 0.9927 - val_loss: 6.1430e-05 - val_accuracy: 1.0000\n","Epoch 20/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0175 - accuracy: 0.9949 - val_loss: 2.8111e-04 - val_accuracy: 1.0000\n","Epoch 21/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0156 - accuracy: 0.9948 - val_loss: 6.8288e-05 - val_accuracy: 1.0000\n","Epoch 22/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0168 - accuracy: 0.9955 - val_loss: 5.4837e-04 - val_accuracy: 1.0000\n","Epoch 23/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0191 - accuracy: 0.9933 - val_loss: 8.3250e-06 - val_accuracy: 1.0000\n","Epoch 24/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0226 - accuracy: 0.9927 - val_loss: 1.9237e-05 - val_accuracy: 1.0000\n","Epoch 25/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 4.5957e-05 - val_accuracy: 1.0000\n","Epoch 26/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 1.2758e-04 - val_accuracy: 1.0000\n","Epoch 27/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0241 - accuracy: 0.9923 - val_loss: 2.0322e-04 - val_accuracy: 1.0000\n","Epoch 28/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0207 - accuracy: 0.9943 - val_loss: 0.0025 - val_accuracy: 0.9987\n","Epoch 29/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0273 - accuracy: 0.9909 - val_loss: 2.9389e-04 - val_accuracy: 1.0000\n","Epoch 30/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0232 - accuracy: 0.9936 - val_loss: 2.0793e-04 - val_accuracy: 1.0000\n","Epoch 31/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 1.5071e-04 - val_accuracy: 1.0000\n","Epoch 32/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0214 - accuracy: 0.9951 - val_loss: 0.0033 - val_accuracy: 0.9987\n","Epoch 33/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0207 - accuracy: 0.9936 - val_loss: 0.0081 - val_accuracy: 0.9987\n","Epoch 34/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0234 - accuracy: 0.9931 - val_loss: 2.3358e-05 - val_accuracy: 1.0000\n","Epoch 35/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 5.1295e-04 - val_accuracy: 1.0000\n","Epoch 36/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.0014 - val_accuracy: 0.9987\n","Epoch 37/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0140 - accuracy: 0.9946 - val_loss: 1.8618e-05 - val_accuracy: 1.0000\n","Epoch 38/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 2.4425e-04 - val_accuracy: 1.0000\n","Epoch 39/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0180 - accuracy: 0.9934 - val_loss: 3.0039e-05 - val_accuracy: 1.0000\n","Epoch 40/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0201 - accuracy: 0.9948 - val_loss: 3.1591e-05 - val_accuracy: 1.0000\n","Epoch 41/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0227 - accuracy: 0.9934 - val_loss: 0.0015 - val_accuracy: 0.9987\n","Epoch 42/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0169 - accuracy: 0.9946 - val_loss: 6.7949e-05 - val_accuracy: 1.0000\n","Epoch 43/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 5.3645e-05 - val_accuracy: 1.0000\n","Epoch 44/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 5.1699e-06 - val_accuracy: 1.0000\n","Epoch 45/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0140 - accuracy: 0.9964 - val_loss: 1.3550e-04 - val_accuracy: 1.0000\n","Epoch 46/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0204 - accuracy: 0.9934 - val_loss: 7.0804e-05 - val_accuracy: 1.0000\n","Epoch 47/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0190 - accuracy: 0.9936 - val_loss: 0.0034 - val_accuracy: 0.9987\n","Epoch 48/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0213 - accuracy: 0.9925 - val_loss: 0.0040 - val_accuracy: 0.9987\n","Epoch 49/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0243 - accuracy: 0.9936 - val_loss: 4.8235e-04 - val_accuracy: 1.0000\n","Epoch 50/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0210 - accuracy: 0.9937 - val_loss: 3.0116e-04 - val_accuracy: 1.0000\n","Results for fold 6\n","Epoch 1/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0212 - accuracy: 0.9949 - val_loss: 1.2641e-05 - val_accuracy: 1.0000\n","Epoch 2/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0300 - accuracy: 0.9924 - val_loss: 8.2454e-06 - val_accuracy: 1.0000\n","Epoch 3/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0198 - accuracy: 0.9948 - val_loss: 4.4255e-04 - val_accuracy: 1.0000\n","Epoch 4/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 1.6447e-06 - val_accuracy: 1.0000\n","Epoch 5/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0163 - accuracy: 0.9952 - val_loss: 2.3452e-06 - val_accuracy: 1.0000\n","Epoch 6/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 5.0215e-06 - val_accuracy: 1.0000\n","Epoch 7/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0193 - accuracy: 0.9931 - val_loss: 6.3588e-06 - val_accuracy: 1.0000\n","Epoch 8/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 4.9133e-06 - val_accuracy: 1.0000\n","Epoch 9/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0149 - accuracy: 0.9945 - val_loss: 1.1262e-06 - val_accuracy: 1.0000\n","Epoch 10/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 3.4102e-06 - val_accuracy: 1.0000\n","Epoch 11/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0130 - accuracy: 0.9951 - val_loss: 8.5004e-06 - val_accuracy: 1.0000\n","Epoch 12/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0152 - accuracy: 0.9966 - val_loss: 6.0617e-06 - val_accuracy: 1.0000\n","Epoch 13/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0297 - accuracy: 0.9920 - val_loss: 1.2035e-05 - val_accuracy: 1.0000\n","Epoch 14/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0229 - accuracy: 0.9921 - val_loss: 8.0394e-06 - val_accuracy: 1.0000\n","Epoch 15/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0159 - accuracy: 0.9942 - val_loss: 1.5113e-06 - val_accuracy: 1.0000\n","Epoch 16/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0188 - accuracy: 0.9949 - val_loss: 2.1613e-04 - val_accuracy: 1.0000\n","Epoch 17/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 1.8544e-05 - val_accuracy: 1.0000\n","Epoch 18/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0153 - accuracy: 0.9955 - val_loss: 1.0540e-05 - val_accuracy: 1.0000\n","Epoch 19/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0136 - accuracy: 0.9955 - val_loss: 1.2184e-06 - val_accuracy: 1.0000\n","Epoch 20/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0187 - accuracy: 0.9946 - val_loss: 4.3171e-06 - val_accuracy: 1.0000\n","Epoch 21/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0208 - accuracy: 0.9934 - val_loss: 1.9324e-05 - val_accuracy: 1.0000\n","Epoch 22/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0104 - accuracy: 0.9972 - val_loss: 1.8488e-06 - val_accuracy: 1.0000\n","Epoch 23/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 9.7781e-07 - val_accuracy: 1.0000\n","Epoch 24/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 1.5661e-06 - val_accuracy: 1.0000\n","Epoch 25/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 2.3811e-05 - val_accuracy: 1.0000\n","Epoch 26/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 1.9711e-05 - val_accuracy: 1.0000\n","Epoch 27/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0093 - accuracy: 0.9963 - val_loss: 4.7569e-05 - val_accuracy: 1.0000\n","Epoch 28/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0254 - accuracy: 0.9923 - val_loss: 5.6981e-04 - val_accuracy: 1.0000\n","Epoch 29/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0180 - accuracy: 0.9943 - val_loss: 8.6581e-06 - val_accuracy: 1.0000\n","Epoch 30/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 1.8355e-04 - val_accuracy: 1.0000\n","Epoch 31/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0139 - accuracy: 0.9960 - val_loss: 1.8063e-04 - val_accuracy: 1.0000\n","Epoch 32/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 5.3611e-06 - val_accuracy: 1.0000\n","Epoch 33/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0191 - accuracy: 0.9952 - val_loss: 3.2458e-05 - val_accuracy: 1.0000\n","Epoch 34/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0139 - accuracy: 0.9946 - val_loss: 7.2608e-06 - val_accuracy: 1.0000\n","Epoch 35/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 4.4315e-06 - val_accuracy: 1.0000\n","Epoch 36/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 9.0424e-06 - val_accuracy: 1.0000\n","Epoch 37/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0189 - accuracy: 0.9952 - val_loss: 1.2545e-04 - val_accuracy: 1.0000\n","Epoch 38/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 4.9067e-05 - val_accuracy: 1.0000\n","Epoch 39/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 3.7545e-05 - val_accuracy: 1.0000\n","Epoch 40/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0147 - accuracy: 0.9961 - val_loss: 7.2666e-05 - val_accuracy: 1.0000\n","Epoch 41/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 9.9311e-06 - val_accuracy: 1.0000\n","Epoch 42/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 5.7751e-05 - val_accuracy: 1.0000\n","Epoch 43/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 2.2216e-04 - val_accuracy: 1.0000\n","Epoch 44/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 2.3193e-05 - val_accuracy: 1.0000\n","Epoch 45/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0146 - accuracy: 0.9960 - val_loss: 8.0191e-06 - val_accuracy: 1.0000\n","Epoch 46/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0183 - accuracy: 0.9954 - val_loss: 4.8237e-05 - val_accuracy: 1.0000\n","Epoch 47/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 3.6486e-04 - val_accuracy: 1.0000\n","Epoch 48/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0122 - accuracy: 0.9970 - val_loss: 3.6403e-05 - val_accuracy: 1.0000\n","Epoch 49/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0089 - accuracy: 0.9967 - val_loss: 2.0511e-06 - val_accuracy: 1.0000\n","Epoch 50/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0142 - accuracy: 0.9952 - val_loss: 0.0042 - val_accuracy: 0.9987\n","Results for fold 7\n","Epoch 1/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0240 - accuracy: 0.9934 - val_loss: 4.4854e-05 - val_accuracy: 1.0000\n","Epoch 2/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0245 - accuracy: 0.9917 - val_loss: 4.9920e-06 - val_accuracy: 1.0000\n","Epoch 3/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0131 - accuracy: 0.9952 - val_loss: 4.7060e-06 - val_accuracy: 1.0000\n","Epoch 4/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0086 - accuracy: 0.9966 - val_loss: 1.1249e-07 - val_accuracy: 1.0000\n","Epoch 5/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0156 - accuracy: 0.9952 - val_loss: 6.5996e-07 - val_accuracy: 1.0000\n","Epoch 6/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0272 - accuracy: 0.9928 - val_loss: 9.1366e-06 - val_accuracy: 1.0000\n","Epoch 7/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0155 - accuracy: 0.9952 - val_loss: 2.5495e-04 - val_accuracy: 1.0000\n","Epoch 8/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0150 - accuracy: 0.9955 - val_loss: 1.3397e-06 - val_accuracy: 1.0000\n","Epoch 9/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0235 - accuracy: 0.9934 - val_loss: 4.7240e-06 - val_accuracy: 1.0000\n","Epoch 10/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 3.1256e-06 - val_accuracy: 1.0000\n","Epoch 11/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0104 - accuracy: 0.9961 - val_loss: 9.8001e-06 - val_accuracy: 1.0000\n","Epoch 12/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0183 - accuracy: 0.9948 - val_loss: 1.1552e-06 - val_accuracy: 1.0000\n","Epoch 13/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 8.0175e-05 - val_accuracy: 1.0000\n","Epoch 14/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0137 - accuracy: 0.9972 - val_loss: 1.2682e-05 - val_accuracy: 1.0000\n","Epoch 15/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0151 - accuracy: 0.9958 - val_loss: 1.3536e-06 - val_accuracy: 1.0000\n","Epoch 16/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0165 - accuracy: 0.9943 - val_loss: 1.2275e-06 - val_accuracy: 1.0000\n","Epoch 17/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 2.9038e-05 - val_accuracy: 1.0000\n","Epoch 18/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 1.0867e-06 - val_accuracy: 1.0000\n","Epoch 19/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0140 - accuracy: 0.9963 - val_loss: 1.9829e-05 - val_accuracy: 1.0000\n","Epoch 20/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 1.3125e-06 - val_accuracy: 1.0000\n","Epoch 21/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 1.8098e-04 - val_accuracy: 1.0000\n","Epoch 22/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0084 - accuracy: 0.9975 - val_loss: 7.8255e-06 - val_accuracy: 1.0000\n","Epoch 23/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0096 - accuracy: 0.9975 - val_loss: 1.9169e-07 - val_accuracy: 1.0000\n","Epoch 24/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0130 - accuracy: 0.9964 - val_loss: 4.8050e-06 - val_accuracy: 1.0000\n","Epoch 25/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0123 - accuracy: 0.9957 - val_loss: 3.0910e-05 - val_accuracy: 1.0000\n","Epoch 26/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0206 - accuracy: 0.9942 - val_loss: 1.7915e-04 - val_accuracy: 1.0000\n","Epoch 27/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 3.0185e-05 - val_accuracy: 1.0000\n","Epoch 28/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0180 - accuracy: 0.9952 - val_loss: 5.1680e-06 - val_accuracy: 1.0000\n","Epoch 29/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 3.3516e-05 - val_accuracy: 1.0000\n","Epoch 30/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0118 - accuracy: 0.9954 - val_loss: 9.5059e-07 - val_accuracy: 1.0000\n","Epoch 31/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0091 - accuracy: 0.9964 - val_loss: 3.9106e-07 - val_accuracy: 1.0000\n","Epoch 32/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 3.4719e-06 - val_accuracy: 1.0000\n","Epoch 33/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0290 - accuracy: 0.9930 - val_loss: 8.7186e-05 - val_accuracy: 1.0000\n","Epoch 34/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 7.4949e-06 - val_accuracy: 1.0000\n","Epoch 35/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0098 - accuracy: 0.9984 - val_loss: 1.7270e-06 - val_accuracy: 1.0000\n","Epoch 36/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 3.3529e-05 - val_accuracy: 1.0000\n","Epoch 37/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 1.1805e-06 - val_accuracy: 1.0000\n","Epoch 38/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0085 - accuracy: 0.9966 - val_loss: 3.5290e-06 - val_accuracy: 1.0000\n","Epoch 39/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0120 - accuracy: 0.9952 - val_loss: 5.1595e-06 - val_accuracy: 1.0000\n","Epoch 40/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 9.5018e-05 - val_accuracy: 1.0000\n","Epoch 41/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0202 - accuracy: 0.9960 - val_loss: 1.0724e-05 - val_accuracy: 1.0000\n","Epoch 42/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.0045 - val_accuracy: 0.9987\n","Epoch 43/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 6.8164e-06 - val_accuracy: 1.0000\n","Epoch 44/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 1.0420e-05 - val_accuracy: 1.0000\n","Epoch 45/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 1.7598e-04 - val_accuracy: 1.0000\n","Epoch 46/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 1.7876e-05 - val_accuracy: 1.0000\n","Epoch 47/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 9.0783e-07 - val_accuracy: 1.0000\n","Epoch 48/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 3.3727e-06 - val_accuracy: 1.0000\n","Epoch 49/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 6.1605e-06 - val_accuracy: 1.0000\n","Epoch 50/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 2.9089e-05 - val_accuracy: 1.0000\n","Results for fold 8\n","Epoch 1/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 5.7647e-07 - val_accuracy: 1.0000\n","Epoch 2/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 5.6677e-05 - val_accuracy: 1.0000\n","Epoch 3/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0193 - accuracy: 0.9948 - val_loss: 2.5113e-06 - val_accuracy: 1.0000\n","Epoch 4/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 1.3121e-05 - val_accuracy: 1.0000\n","Epoch 5/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 4.7013e-06 - val_accuracy: 1.0000\n","Epoch 6/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0143 - accuracy: 0.9963 - val_loss: 3.0177e-06 - val_accuracy: 1.0000\n","Epoch 7/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0122 - accuracy: 0.9954 - val_loss: 1.2109e-06 - val_accuracy: 1.0000\n","Epoch 8/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0167 - accuracy: 0.9954 - val_loss: 4.2383e-06 - val_accuracy: 1.0000\n","Epoch 9/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 8.0319e-07 - val_accuracy: 1.0000\n","Epoch 10/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 2.0769e-07 - val_accuracy: 1.0000\n","Epoch 11/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 2.3618e-06 - val_accuracy: 1.0000\n","Epoch 12/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 1.2305e-07 - val_accuracy: 1.0000\n","Epoch 13/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0132 - accuracy: 0.9964 - val_loss: 1.0730e-06 - val_accuracy: 1.0000\n","Epoch 14/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0214 - accuracy: 0.9946 - val_loss: 1.8610e-06 - val_accuracy: 1.0000\n","Epoch 15/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 1.9522e-06 - val_accuracy: 1.0000\n","Epoch 16/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 1.8051e-06 - val_accuracy: 1.0000\n","Epoch 17/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0121 - accuracy: 0.9957 - val_loss: 2.0129e-07 - val_accuracy: 1.0000\n","Epoch 18/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0092 - accuracy: 0.9978 - val_loss: 1.5185e-07 - val_accuracy: 1.0000\n","Epoch 19/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 3.2978e-07 - val_accuracy: 1.0000\n","Epoch 20/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0085 - accuracy: 0.9969 - val_loss: 1.9272e-05 - val_accuracy: 1.0000\n","Epoch 21/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 6.1794e-05 - val_accuracy: 1.0000\n","Epoch 22/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0106 - accuracy: 0.9973 - val_loss: 7.2179e-06 - val_accuracy: 1.0000\n","Epoch 23/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 1.3249e-04 - val_accuracy: 1.0000\n","Epoch 24/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 7.5291e-06 - val_accuracy: 1.0000\n","Epoch 25/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0112 - accuracy: 0.9960 - val_loss: 2.6429e-06 - val_accuracy: 1.0000\n","Epoch 26/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0130 - accuracy: 0.9952 - val_loss: 8.6845e-06 - val_accuracy: 1.0000\n","Epoch 27/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0155 - accuracy: 0.9960 - val_loss: 3.7025e-04 - val_accuracy: 1.0000\n","Epoch 28/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0175 - accuracy: 0.9957 - val_loss: 2.5847e-04 - val_accuracy: 1.0000\n","Epoch 29/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 3.7925e-06 - val_accuracy: 1.0000\n","Epoch 30/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0161 - accuracy: 0.9957 - val_loss: 3.4632e-05 - val_accuracy: 1.0000\n","Epoch 31/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0135 - accuracy: 0.9964 - val_loss: 1.1774e-04 - val_accuracy: 1.0000\n","Epoch 32/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0127 - accuracy: 0.9964 - val_loss: 2.9360e-04 - val_accuracy: 1.0000\n","Epoch 33/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0136 - accuracy: 0.9970 - val_loss: 1.7045e-05 - val_accuracy: 1.0000\n","Epoch 34/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 3.4913e-06 - val_accuracy: 1.0000\n","Epoch 35/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 1.2825e-04 - val_accuracy: 1.0000\n","Epoch 36/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0142 - accuracy: 0.9967 - val_loss: 8.3249e-05 - val_accuracy: 1.0000\n","Epoch 37/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0172 - accuracy: 0.9961 - val_loss: 3.1953e-05 - val_accuracy: 1.0000\n","Epoch 38/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 4.5823e-05 - val_accuracy: 1.0000\n","Epoch 39/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0097 - accuracy: 0.9967 - val_loss: 3.3653e-06 - val_accuracy: 1.0000\n","Epoch 40/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 3.6587e-05 - val_accuracy: 1.0000\n","Epoch 41/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0148 - accuracy: 0.9958 - val_loss: 8.6972e-06 - val_accuracy: 1.0000\n","Epoch 42/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 2.9892e-06 - val_accuracy: 1.0000\n","Epoch 43/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 2.5017e-06 - val_accuracy: 1.0000\n","Epoch 44/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 9.3957e-06 - val_accuracy: 1.0000\n","Epoch 45/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 5.0922e-06 - val_accuracy: 1.0000\n","Epoch 46/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0155 - accuracy: 0.9961 - val_loss: 3.9463e-05 - val_accuracy: 1.0000\n","Epoch 47/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 4.0595e-05 - val_accuracy: 1.0000\n","Epoch 48/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0158 - accuracy: 0.9960 - val_loss: 2.0186e-04 - val_accuracy: 1.0000\n","Epoch 49/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 8.0105e-04 - val_accuracy: 1.0000\n","Epoch 50/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 1.0392e-05 - val_accuracy: 1.0000\n","Results for fold 9\n","Epoch 1/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0124 - accuracy: 0.9966 - val_loss: 8.8487e-08 - val_accuracy: 1.0000\n","Epoch 2/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0117 - accuracy: 0.9967 - val_loss: 2.3162e-06 - val_accuracy: 1.0000\n","Epoch 3/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 3.0513e-07 - val_accuracy: 1.0000\n","Epoch 4/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0158 - accuracy: 0.9957 - val_loss: 1.5828e-06 - val_accuracy: 1.0000\n","Epoch 5/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 7.5997e-07 - val_accuracy: 1.0000\n","Epoch 6/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0106 - accuracy: 0.9975 - val_loss: 2.5313e-07 - val_accuracy: 1.0000\n","Epoch 7/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 7.8784e-07 - val_accuracy: 1.0000\n","Epoch 8/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 8.7981e-07 - val_accuracy: 1.0000\n","Epoch 9/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 3.2546e-07 - val_accuracy: 1.0000\n","Epoch 10/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 3.1458e-07 - val_accuracy: 1.0000\n","Epoch 11/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 3.3025e-07 - val_accuracy: 1.0000\n","Epoch 12/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0175 - accuracy: 0.9957 - val_loss: 6.4336e-06 - val_accuracy: 1.0000\n","Epoch 13/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0128 - accuracy: 0.9955 - val_loss: 1.7894e-05 - val_accuracy: 1.0000\n","Epoch 14/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0149 - accuracy: 0.9948 - val_loss: 1.1971e-06 - val_accuracy: 1.0000\n","Epoch 15/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 1.4508e-06 - val_accuracy: 1.0000\n","Epoch 16/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 1.8211e-05 - val_accuracy: 1.0000\n","Epoch 17/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 4.1490e-07 - val_accuracy: 1.0000\n","Epoch 18/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 1.3633e-07 - val_accuracy: 1.0000\n","Epoch 19/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 7.8726e-08 - val_accuracy: 1.0000\n","Epoch 20/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0081 - accuracy: 0.9981 - val_loss: 2.9567e-06 - val_accuracy: 1.0000\n","Epoch 21/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 1.7811e-05 - val_accuracy: 1.0000\n","Epoch 22/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 3.0194e-07 - val_accuracy: 1.0000\n","Epoch 23/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 1.4813e-06 - val_accuracy: 1.0000\n","Epoch 24/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0111 - accuracy: 0.9951 - val_loss: 5.4180e-06 - val_accuracy: 1.0000\n","Epoch 25/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0123 - accuracy: 0.9975 - val_loss: 2.0484e-06 - val_accuracy: 1.0000\n","Epoch 26/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 1.1479e-06 - val_accuracy: 1.0000\n","Epoch 27/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 7.9370e-07 - val_accuracy: 1.0000\n","Epoch 28/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0161 - accuracy: 0.9955 - val_loss: 5.8265e-05 - val_accuracy: 1.0000\n","Epoch 29/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0098 - accuracy: 0.9975 - val_loss: 6.9715e-06 - val_accuracy: 1.0000\n","Epoch 30/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 1.5058e-06 - val_accuracy: 1.0000\n","Epoch 31/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0156 - accuracy: 0.9955 - val_loss: 5.3096e-05 - val_accuracy: 1.0000\n","Epoch 32/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 3.1397e-06 - val_accuracy: 1.0000\n","Epoch 33/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 4.4082e-06 - val_accuracy: 1.0000\n","Epoch 34/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 6.3121e-07 - val_accuracy: 1.0000\n","Epoch 35/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 1.1249e-07 - val_accuracy: 1.0000\n","Epoch 36/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0115 - accuracy: 0.9973 - val_loss: 1.2001e-07 - val_accuracy: 1.0000\n","Epoch 37/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 4.5302e-06 - val_accuracy: 1.0000\n","Epoch 38/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0092 - accuracy: 0.9978 - val_loss: 0.0012 - val_accuracy: 1.0000\n","Epoch 39/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 4.5787e-04 - val_accuracy: 1.0000\n","Epoch 40/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0151 - accuracy: 0.9967 - val_loss: 1.3105e-05 - val_accuracy: 1.0000\n","Epoch 41/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 4.7174e-05 - val_accuracy: 1.0000\n","Epoch 42/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0199 - accuracy: 0.9954 - val_loss: 1.2316e-05 - val_accuracy: 1.0000\n","Epoch 43/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0101 - accuracy: 0.9958 - val_loss: 1.0742e-04 - val_accuracy: 1.0000\n","Epoch 44/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 4.9877e-06 - val_accuracy: 1.0000\n","Epoch 45/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 4.1984e-06 - val_accuracy: 1.0000\n","Epoch 46/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 5.2346e-04 - val_accuracy: 1.0000\n","Epoch 47/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 5.2213e-06 - val_accuracy: 1.0000\n","Epoch 48/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0093 - accuracy: 0.9975 - val_loss: 1.9386e-06 - val_accuracy: 1.0000\n","Epoch 49/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 4.7740e-06 - val_accuracy: 1.0000\n","Epoch 50/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 3.4338e-07 - val_accuracy: 1.0000\n","Results for fold 10\n","Epoch 1/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 2.5762e-08 - val_accuracy: 1.0000\n","Epoch 2/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 2.2625e-07 - val_accuracy: 1.0000\n","Epoch 3/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 4.7032e-04 - val_accuracy: 1.0000\n","Epoch 4/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0130 - accuracy: 0.9972 - val_loss: 5.1410e-07 - val_accuracy: 1.0000\n","Epoch 5/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0186 - accuracy: 0.9957 - val_loss: 4.2373e-06 - val_accuracy: 1.0000\n","Epoch 6/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0083 - accuracy: 0.9978 - val_loss: 1.8337e-07 - val_accuracy: 1.0000\n","Epoch 7/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 1.6721e-07 - val_accuracy: 1.0000\n","Epoch 8/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 7.0601e-07 - val_accuracy: 1.0000\n","Epoch 9/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 1.6096e-06 - val_accuracy: 1.0000\n","Epoch 10/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 6.9873e-07 - val_accuracy: 1.0000\n","Epoch 11/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0160 - accuracy: 0.9954 - val_loss: 9.4722e-07 - val_accuracy: 1.0000\n","Epoch 12/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0136 - accuracy: 0.9975 - val_loss: 1.4205e-06 - val_accuracy: 1.0000\n","Epoch 13/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 5.5249e-07 - val_accuracy: 1.0000\n","Epoch 14/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0123 - accuracy: 0.9970 - val_loss: 8.9388e-06 - val_accuracy: 1.0000\n","Epoch 15/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 1.9941e-06 - val_accuracy: 1.0000\n","Epoch 16/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0117 - accuracy: 0.9972 - val_loss: 7.6646e-08 - val_accuracy: 1.0000\n","Epoch 17/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 1.1761e-07 - val_accuracy: 1.0000\n","Epoch 18/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 4.3843e-08 - val_accuracy: 1.0000\n","Epoch 19/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0087 - accuracy: 0.9978 - val_loss: 5.2721e-07 - val_accuracy: 1.0000\n","Epoch 20/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 3.7202e-07 - val_accuracy: 1.0000\n","Epoch 21/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 2.0449e-07 - val_accuracy: 1.0000\n","Epoch 22/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 1.5681e-07 - val_accuracy: 1.0000\n","Epoch 23/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 8.3526e-08 - val_accuracy: 1.0000\n","Epoch 24/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 1.5081e-05 - val_accuracy: 1.0000\n","Epoch 25/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 4.8004e-08 - val_accuracy: 1.0000\n","Epoch 26/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0163 - accuracy: 0.9960 - val_loss: 1.0834e-06 - val_accuracy: 1.0000\n","Epoch 27/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0153 - accuracy: 0.9945 - val_loss: 7.8113e-07 - val_accuracy: 1.0000\n","Epoch 28/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 8.1730e-07 - val_accuracy: 1.0000\n","Epoch 29/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 1.2396e-06 - val_accuracy: 1.0000\n","Epoch 30/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 3.8882e-07 - val_accuracy: 1.0000\n","Epoch 31/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 1.3953e-07 - val_accuracy: 1.0000\n","Epoch 32/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 4.8562e-07 - val_accuracy: 1.0000\n","Epoch 33/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 1.8937e-05 - val_accuracy: 1.0000\n","Epoch 34/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0130 - accuracy: 0.9951 - val_loss: 2.2962e-07 - val_accuracy: 1.0000\n","Epoch 35/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0136 - accuracy: 0.9960 - val_loss: 1.2929e-07 - val_accuracy: 1.0000\n","Epoch 36/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0128 - accuracy: 0.9975 - val_loss: 3.7426e-07 - val_accuracy: 1.0000\n","Epoch 37/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0105 - accuracy: 0.9976 - val_loss: 2.7937e-07 - val_accuracy: 1.0000\n","Epoch 38/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0079 - accuracy: 0.9978 - val_loss: 4.2757e-06 - val_accuracy: 1.0000\n","Epoch 39/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 1.6019e-06 - val_accuracy: 1.0000\n","Epoch 40/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 1.2168e-04 - val_accuracy: 1.0000\n","Epoch 41/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0104 - accuracy: 0.9975 - val_loss: 1.8074e-06 - val_accuracy: 1.0000\n","Epoch 42/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 9.4305e-07 - val_accuracy: 1.0000\n","Epoch 43/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 1.3480e-06 - val_accuracy: 1.0000\n","Epoch 44/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 1.3729e-07 - val_accuracy: 1.0000\n","Epoch 45/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 1.5983e-06 - val_accuracy: 1.0000\n","Epoch 46/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 7.8574e-05 - val_accuracy: 1.0000\n","Epoch 47/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 1.0071e-06 - val_accuracy: 1.0000\n","Epoch 48/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0145 - accuracy: 0.9963 - val_loss: 1.0712e-04 - val_accuracy: 1.0000\n","Epoch 49/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 1.1361e-07 - val_accuracy: 1.0000\n","Epoch 50/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 6.4805e-08 - val_accuracy: 1.0000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9_olzDVBZS7u","colab":{"base_uri":"https://localhost:8080/","height":722},"outputId":"fdac31bb-1350-4747-d384-e6e64aed06b6"},"source":["acrc = model.evaluate(x_test, y_test)\n","pred = model.predict(x_test)\n","f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n","c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n","print(\"Accuracy  : {}\".format(acrc[1]))\n","print(\"F1_Score  : {}\".format(f1scr))\n","c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n","import seaborn as sns\n","figure = plt.figure(figsize=(9, 9))\n","sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n","plt.tight_layout()\n","plt.ylabel('True label')\n","plt.xlabel('Predicted label')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["59/59 [==============================] - 0s 6ms/step - loss: 0.0153 - accuracy: 0.9979\n","Accuracy  : 0.9978540539741516\n","F1_Score  : 0.9972349266130291\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 648x648 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}