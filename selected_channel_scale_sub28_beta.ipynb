{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"selected_channel&scale_sub28_beta.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"mJl4myg42Jt-","executionInfo":{"status":"ok","timestamp":1642412212268,"user_tz":-360,"elapsed":3469,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from scipy.signal import butter, lfilter, freqz, filtfilt\n","from pywt import swt, cwt\n","import scipy.misc\n","from scipy.signal import welch\n","import tensorflow as tf\n","import keras\n","from tensorflow import keras\n","import tensorflow.keras.backend as K\n","from keras.models import Sequential,Model\n","from keras.models import Sequential \n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n","from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n","from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n","from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n","from tensorflow.keras.optimizers import Adam\n","from keras.utils import np_utils\n","from sklearn.preprocessing import StandardScaler                                                      \n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import confusion_matrix \n","from scipy import signal\n","import pickle as pkl\n","from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n","from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n","import gc"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ns3s5JN97fU","executionInfo":{"status":"ok","timestamp":1642412236959,"user_tz":-360,"elapsed":21701,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"3a9a6e77-7132-4322-f413-b4374fa8546b"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","gc.collect()"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]},{"output_type":"execute_result","data":{"text/plain":["103"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"ugvNZGZX-DO7","executionInfo":{"status":"ok","timestamp":1642412236961,"user_tz":-360,"elapsed":11,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}}},"source":["input_path='/content/drive/MyDrive/data_preprocessed_python/'"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"XIY4fiC5qCkI"},"source":["def butter_lowpass(cutoff, fs, order=5):\n","    nyq = 0.5 * fs\n","    normal_cutoff = cutoff / nyq\n","    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n","    return b, a\n","\n","\n","def butter_lowpass_filter(data, cutoff, fs, order=5):\n","    b, a = butter_lowpass(cutoff, fs, order=order)\n","    y = filtfilt(b, a, data)\n","    return y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O9LZgo2IM9N-"},"source":["from scipy.signal.lti_conversion import cont2discrete\n","const = 1e3\n","def cwt_EER(x):\n","  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n","  energy = np.square(coef)\n","  energy_each_coef_sum = sum(energy.T)\n","  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n","  probability = np.divide(energy,energy_each_coef_sum_tile)\n","  entropy = -probability*np.log(probability)\n","  EER = np.divide(energy, entropy)\n","  #EER = EER/const\n","  return EER"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cPXrZrst909d","executionInfo":{"status":"ok","timestamp":1642412236961,"user_tz":-360,"elapsed":9,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}}},"source":["channel = np.array([1,3,7,8,21,22,25,26,27,30])\n","scale = len(np.arange(11, 31))\n","sampling_rate = 128\n","window_size = 256\n","skip = 32\n","channel_len = len(channel)\n","classes=3\n","order = 6\n","fs = 128      # sample rate, Hz\n","cutoff = 60  # desired cutoff frequency of the filter, Hz\n","waveletname = 'db4'\n","bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n","         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n","         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"],"execution_count":4,"outputs":[]},{"cell_type":"code","source":["eeg_signal = []\n","valence = []\n","arousal = []\n","dominance = []\n","signal_freq = []\n","eeg_sig = []\n","baseline = []\n","gc.collect()\n","\n","for person in range(28,29):\n","  print('Person No.' + str(person))\n","  \n","  # EEG files address\n","  if person < 10 :\n","    address = input_path+'s0'+str(person)+'.dat'\n","  else :\n","    address = input_path+'s'+str(person)+'.dat'\n","\n","  with open(address, 'rb') as file:\n","    data = pkl.load(file, encoding = 'latin1')\n","\n","  eeg = data['data']\n","  label = data['labels']\n","  \n","  # Assigning classes\n","  label[label<=5] = 0\n","  label[label>5] = 1\n","\n","  val = label.T[0] # Valence label\n","  aro = label.T[1] # Arousal label\n","  dom = label.T[2] # Dominance label\n","\n","  del data, label\n","  \n","\n","  for i in range(40): # Iterating through 40 vidoes/trials\n","\n","    sig = eeg[i]\n","    sig = sig[:32, 384:]\n","    bas = sig[:32, :384]\n","    eeg_signal.append(sig)\n","    baseline.append(bas)\n","  del sig, eeg, bas\n","  eeg_signal = np.reshape(eeg_signal,[-1,32,7680])\n","  for i in range(40):\n","    v = val[i]\n","    a = aro[i]\n","    d = dom[i]\n","    start = 0\n","    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n","    while start + window_size <=eeg_signal.shape[2]:\n","      eeg_sig.append(eeg_signal[i, :, start:start+window_size])\n","      valence.append(v)\n","      arousal.append(a)\n","      dominance.append(d)\n","      start += skip\n","data = np.asarray(eeg_sig, dtype = np.float32).reshape([-1,32,256]) # Using 32 bit floating point value to save memory\n","baseline = np.array(baseline, dtype=np.float32).reshape([-1,32,384])\n","valence = np.asarray(valence, dtype = np.int8)\n","arousal = np.asarray(arousal, dtype = np.int8)\n","dominance = np.asarray(dominance, dtype = np.int8)\n","del eeg_sig, eeg_signal, val, aro, dom\n","\n","print(data.shape)\n","print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n","print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n","print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n","\n","valence = np_utils.to_categorical(valence)\n","arousal = np_utils.to_categorical(arousal)\n","dominance = np_utils.to_categorical(dominance)\n","print(valence.shape)\n","print(arousal.shape)\n","print(dominance.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s58WbfVzaOo8","executionInfo":{"status":"ok","timestamp":1642416671676,"user_tz":-360,"elapsed":649,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"7fcb06e3-8bc0-4385-b1a3-91a39bb159a2"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Person No.28\n","(9320, 32, 256)\n","(9320,) (3495,) (5825,) (0,)\n","(9320,) (5126,) (4194,) (0,)\n","(9320,) (3029,) (6291,) (0,)\n","(9320, 2)\n","(9320, 2)\n","(9320, 2)\n"]}]},{"cell_type":"code","source":["print(data.max())\n","print(data.min())\n","print(data.mean())\n","print(baseline.max())\n","print(baseline.min())\n","print(baseline.mean())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RiiKBiZ6cNMs","executionInfo":{"status":"ok","timestamp":1642416754893,"user_tz":-360,"elapsed":449,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"0aa8a1aa-78f7-4a55-f62d-0c6c04ab2990"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["580.05334\n","-635.9261\n","-1.546625e-10\n","421.37744\n","-436.2461\n","-9.313226e-10\n"]}]},{"cell_type":"code","source":["data[0,:,1000]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7fjzKDRUb10b","executionInfo":{"status":"ok","timestamp":1642412935764,"user_tz":-360,"elapsed":539,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"03f1d31a-0e7c-42c5-ab51-cc2e85a6176b"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-30.955956, -21.411451, -26.538635, -25.896759, -23.485445,\n","        90.28499 , -57.60127 ,  12.688501,  17.96365 , -31.164703],\n","      dtype=float32)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EotvnIan4d84","executionInfo":{"status":"ok","timestamp":1633076710834,"user_tz":-360,"elapsed":276460,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"43a09aa6-21e0-4b14-ceea-465b3a047c1c"},"source":["eeg_signal = []\n","valence = []\n","arousal = []\n","dominance = []\n","signal_freq = []\n","eeg_sig = []\n","gc.collect()\n","\n","for person in range(28,29):\n","  print('Person No.' + str(person))\n","  \n","  # EEG files address\n","  if person < 10 :\n","    address = input_path+'s0'+str(person)+'.dat'\n","  else :\n","    address = input_path+'s'+str(person)+'.dat'\n","\n","  with open(address, 'rb') as file:\n","    data = pkl.load(file, encoding = 'latin1')\n","\n","  eeg = data['data']\n","  label = data['labels']\n","  \n","  # Assigning classes\n","  label[label<4] = 0\n","  label[(label>=4) & (label<6)] = 1\n","  label[(label>=6) & (label<=9)] = 2     \n","\n","  val = label.T[0] # Valence label\n","  aro = label.T[1] # Arousal label\n","  dom = label.T[2] # Dominance label\n","\n","  del data, label\n","  \n","\n","  for i in range(40): # Iterating through 40 vidoes/trials\n","\n","    sig = eeg[i]\n","    sig = sig[:32, 384:]\n","    \n","    dfs = []\n","    for j in channel:\n","      ## Dividing Alpha Band\n","      num, den = signal.butter(4, bands['beta'], 'bandpass')\n","      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n","\n","    sig = np.array(dfs)\n","    sig = sig.reshape([-1,7680])\n","    eeg_signal.append(sig)\n","  del dfs, sig, eeg\n","  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n","  gc.collect()\n","  for i in range(40):\n","    v = val[i]\n","    a = aro[i]\n","    d = dom[i]\n","    start = 0\n","    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n","    while start + window_size <=eeg_signal.shape[2]:\n","      for j in range(eeg_signal.shape[1]):\n","        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n","      valence.append(v)\n","      arousal.append(a)\n","      dominance.append(d)\n","      start += skip\n","#eeg_sig = np.array(eeg_sig)\n","gc.collect()\n","del eeg_signal\n","eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n","data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n","del eeg_sig\n","valence = np.asarray(valence, dtype = np.int8)\n","arousal = np.asarray(arousal, dtype = np.int8)\n","dominance = np.asarray(dominance, dtype = np.int8)\n","\n","print(data.shape)\n","print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n","print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n","print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n","\n","valence = np_utils.to_categorical(valence)\n","arousal = np_utils.to_categorical(arousal)\n","dominance = np_utils.to_categorical(dominance)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Person No.28\n","(9320, 200, 256, 1)\n","(9320,) (3029,) (1398,) (4893,)\n","(9320,) (4427,) (699,) (4194,)\n","(9320,) (2796,) (1398,) (5126,)\n"]}]},{"cell_type":"markdown","metadata":{"id":"-VMwwMiur8kW"},"source":["# **Proposed Architecture**"]},{"cell_type":"code","metadata":{"id":"1jZC2UyIPd33"},"source":["def get_model() :\n","    input_shape = (data.shape[1],data.shape[2],1)\n","    model=Sequential()\n","    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","    model.add(Dropout(0.2))\n","    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","    model.add(Dropout(0.2))\n","    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","    model.add(Dropout(0.2))\n","    model.add(Flatten())\n","    model.add(Dense(256,activation='tanh'))\n","    model.add(Dropout(0.4))\n","    model.add(Dense(32,activation='relu'))\n","    model.add(Dropout(0.4))\n","    model.add(Dense(3,activation='softmax'))\n","    opt = keras.optimizers.Adam(learning_rate=0.001)\n","    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n","    return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RpLb7uFzTl7H","executionInfo":{"status":"ok","timestamp":1633076717137,"user_tz":-360,"elapsed":6316,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"e2182187-4528-4e6c-a38c-5bcb65a38b3d"},"source":["model = get_model()\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 100, 128, 16)      416       \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 100, 128, 16)      64        \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 50, 64, 16)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 768)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 256)               196864    \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 32)                8224      \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 32)                0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 3)                 99        \n","=================================================================\n","Total params: 397,123\n","Trainable params: 396,899\n","Non-trainable params: 224\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZC6fgR_XrOSw","executionInfo":{"status":"ok","timestamp":1633076717138,"user_tz":-360,"elapsed":15,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"f4bc8281-309a-491f-db5b-91516c6b4db0"},"source":["batch_size = 128\n","epochs = 30\n","kfold = KFold(10, True, 1)\n","gc.collect()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["522"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"n94Q8iJ4rJsF"},"source":["# **Valence**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wHEnzkdKqgOS","executionInfo":{"status":"ok","timestamp":1633076717619,"user_tz":-360,"elapsed":492,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"ac0f44d4-7bbf-431c-9df3-a9a1c8036fa7"},"source":["#valence\n","X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n","print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"]}]},{"cell_type":"code","metadata":{"id":"8tdPOzU7rQRV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633078164567,"user_tz":-360,"elapsed":1446950,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"f865656c-e3b9-44ef-a968-da3554d925ab"},"source":["foldNum=0\n","model = get_model()\n","for train_index, val_index in kfold.split(X_train, Y_train):\n","  foldNum = foldNum + 1\n","  print(\"Results for fold\",foldNum)\n","  x_train, x_val = X_train[train_index], X_train[val_index]\n","  y_train, y_val = Y_train[train_index], Y_train[val_index]\n","  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n","  gc.collect() # Garbage collecter\n","  del x_train, x_val, y_train, y_val\n","  gc.collect()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Results for fold 1\n","Epoch 1/30\n","53/53 [==============================] - 37s 89ms/step - loss: 1.0484 - accuracy: 0.4881 - val_loss: 0.9804 - val_accuracy: 0.5308\n","Epoch 2/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.9929 - accuracy: 0.5238 - val_loss: 0.9638 - val_accuracy: 0.5308\n","Epoch 3/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.9918 - accuracy: 0.5232 - val_loss: 0.9564 - val_accuracy: 0.5308\n","Epoch 4/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.9930 - accuracy: 0.5259 - val_loss: 0.9495 - val_accuracy: 0.5308\n","Epoch 5/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.9828 - accuracy: 0.5286 - val_loss: 0.9464 - val_accuracy: 0.5509\n","Epoch 6/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.9822 - accuracy: 0.5264 - val_loss: 0.9432 - val_accuracy: 0.5322\n","Epoch 7/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.9759 - accuracy: 0.5337 - val_loss: 0.9362 - val_accuracy: 0.5375\n","Epoch 8/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.9793 - accuracy: 0.5252 - val_loss: 0.9471 - val_accuracy: 0.5402\n","Epoch 9/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.9730 - accuracy: 0.5271 - val_loss: 0.9358 - val_accuracy: 0.5308\n","Epoch 10/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.9722 - accuracy: 0.5311 - val_loss: 0.9434 - val_accuracy: 0.5389\n","Epoch 11/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.9675 - accuracy: 0.5286 - val_loss: 0.9369 - val_accuracy: 0.5657\n","Epoch 12/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.9623 - accuracy: 0.5340 - val_loss: 0.9194 - val_accuracy: 0.5536\n","Epoch 13/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.9581 - accuracy: 0.5291 - val_loss: 0.9486 - val_accuracy: 0.5335\n","Epoch 14/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.9546 - accuracy: 0.5335 - val_loss: 0.9396 - val_accuracy: 0.5643\n","Epoch 15/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.9521 - accuracy: 0.5365 - val_loss: 0.9215 - val_accuracy: 0.5469\n","Epoch 16/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.9475 - accuracy: 0.5404 - val_loss: 0.9527 - val_accuracy: 0.5214\n","Epoch 17/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.9480 - accuracy: 0.5435 - val_loss: 0.9641 - val_accuracy: 0.5027\n","Epoch 18/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.9444 - accuracy: 0.5355 - val_loss: 0.9065 - val_accuracy: 0.5563\n","Epoch 19/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.9423 - accuracy: 0.5437 - val_loss: 0.9304 - val_accuracy: 0.5523\n","Epoch 20/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.9361 - accuracy: 0.5428 - val_loss: 0.9170 - val_accuracy: 0.5643\n","Epoch 21/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.9340 - accuracy: 0.5472 - val_loss: 0.9164 - val_accuracy: 0.5697\n","Epoch 22/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.9336 - accuracy: 0.5501 - val_loss: 0.9239 - val_accuracy: 0.5483\n","Epoch 23/30\n","53/53 [==============================] - 4s 71ms/step - loss: 0.9236 - accuracy: 0.5559 - val_loss: 0.9287 - val_accuracy: 0.5643\n","Epoch 24/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.9155 - accuracy: 0.5556 - val_loss: 0.8972 - val_accuracy: 0.5831\n","Epoch 25/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.9076 - accuracy: 0.5601 - val_loss: 0.8893 - val_accuracy: 0.5992\n","Epoch 26/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.9004 - accuracy: 0.5657 - val_loss: 0.9210 - val_accuracy: 0.5308\n","Epoch 27/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.9007 - accuracy: 0.5677 - val_loss: 0.9513 - val_accuracy: 0.5000\n","Epoch 28/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.8915 - accuracy: 0.5742 - val_loss: 0.8759 - val_accuracy: 0.5670\n","Epoch 29/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.8807 - accuracy: 0.5788 - val_loss: 0.8638 - val_accuracy: 0.5992\n","Epoch 30/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.8704 - accuracy: 0.5858 - val_loss: 0.8504 - val_accuracy: 0.6113\n","Results for fold 2\n","Epoch 1/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.8593 - accuracy: 0.5961 - val_loss: 0.7947 - val_accuracy: 0.6287\n","Epoch 2/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.8554 - accuracy: 0.5875 - val_loss: 0.8179 - val_accuracy: 0.6046\n","Epoch 3/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.8458 - accuracy: 0.6037 - val_loss: 0.7831 - val_accuracy: 0.6206\n","Epoch 4/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.8287 - accuracy: 0.6186 - val_loss: 0.8197 - val_accuracy: 0.6086\n","Epoch 5/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.8219 - accuracy: 0.6174 - val_loss: 0.8525 - val_accuracy: 0.6032\n","Epoch 6/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.8134 - accuracy: 0.6244 - val_loss: 0.8802 - val_accuracy: 0.5912\n","Epoch 7/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.8070 - accuracy: 0.6213 - val_loss: 0.7568 - val_accuracy: 0.6488\n","Epoch 8/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.7881 - accuracy: 0.6343 - val_loss: 0.7889 - val_accuracy: 0.6233\n","Epoch 9/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.7672 - accuracy: 0.6504 - val_loss: 0.7989 - val_accuracy: 0.6032\n","Epoch 10/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.7627 - accuracy: 0.6443 - val_loss: 0.8357 - val_accuracy: 0.6072\n","Epoch 11/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.7323 - accuracy: 0.6681 - val_loss: 0.7323 - val_accuracy: 0.6609\n","Epoch 12/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.7138 - accuracy: 0.6851 - val_loss: 0.7178 - val_accuracy: 0.6729\n","Epoch 13/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.7127 - accuracy: 0.6799 - val_loss: 0.7266 - val_accuracy: 0.6796\n","Epoch 14/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.6875 - accuracy: 0.6990 - val_loss: 0.7086 - val_accuracy: 0.6702\n","Epoch 15/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.6856 - accuracy: 0.6917 - val_loss: 0.6838 - val_accuracy: 0.6877\n","Epoch 16/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.6663 - accuracy: 0.7036 - val_loss: 0.7048 - val_accuracy: 0.6756\n","Epoch 17/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.6418 - accuracy: 0.7212 - val_loss: 0.7099 - val_accuracy: 0.6890\n","Epoch 18/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.6116 - accuracy: 0.7377 - val_loss: 0.6402 - val_accuracy: 0.7252\n","Epoch 19/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.5750 - accuracy: 0.7474 - val_loss: 0.6712 - val_accuracy: 0.6971\n","Epoch 20/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.5563 - accuracy: 0.7694 - val_loss: 0.5746 - val_accuracy: 0.7587\n","Epoch 21/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.5368 - accuracy: 0.7723 - val_loss: 0.5538 - val_accuracy: 0.7534\n","Epoch 22/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.5285 - accuracy: 0.7844 - val_loss: 0.5565 - val_accuracy: 0.7547\n","Epoch 23/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.5101 - accuracy: 0.7958 - val_loss: 0.5645 - val_accuracy: 0.7614\n","Epoch 24/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.4904 - accuracy: 0.8085 - val_loss: 0.5292 - val_accuracy: 0.7855\n","Epoch 25/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.4698 - accuracy: 0.8133 - val_loss: 0.5172 - val_accuracy: 0.7895\n","Epoch 26/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.4289 - accuracy: 0.8335 - val_loss: 0.4525 - val_accuracy: 0.8177\n","Epoch 27/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.4016 - accuracy: 0.8373 - val_loss: 0.4350 - val_accuracy: 0.8217\n","Epoch 28/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.4256 - accuracy: 0.8316 - val_loss: 0.4601 - val_accuracy: 0.8110\n","Epoch 29/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.3785 - accuracy: 0.8542 - val_loss: 0.3874 - val_accuracy: 0.8405\n","Epoch 30/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.3459 - accuracy: 0.8681 - val_loss: 0.3982 - val_accuracy: 0.8365\n","Results for fold 3\n","Epoch 1/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.3885 - accuracy: 0.8589 - val_loss: 0.2186 - val_accuracy: 0.9330\n","Epoch 2/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.3637 - accuracy: 0.8614 - val_loss: 0.1777 - val_accuracy: 0.9437\n","Epoch 3/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.3167 - accuracy: 0.8861 - val_loss: 0.1799 - val_accuracy: 0.9330\n","Epoch 4/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.3023 - accuracy: 0.8911 - val_loss: 0.1527 - val_accuracy: 0.9477\n","Epoch 5/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.2860 - accuracy: 0.8961 - val_loss: 0.1534 - val_accuracy: 0.9477\n","Epoch 6/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.2933 - accuracy: 0.8940 - val_loss: 0.1475 - val_accuracy: 0.9450\n","Epoch 7/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.2823 - accuracy: 0.8973 - val_loss: 0.1889 - val_accuracy: 0.9330\n","Epoch 8/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.2757 - accuracy: 0.9001 - val_loss: 0.1587 - val_accuracy: 0.9397\n","Epoch 9/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.2438 - accuracy: 0.9151 - val_loss: 0.1725 - val_accuracy: 0.9410\n","Epoch 10/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.2488 - accuracy: 0.9140 - val_loss: 0.1366 - val_accuracy: 0.9477\n","Epoch 11/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.2123 - accuracy: 0.9238 - val_loss: 0.1105 - val_accuracy: 0.9598\n","Epoch 12/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.2072 - accuracy: 0.9279 - val_loss: 0.1412 - val_accuracy: 0.9464\n","Epoch 13/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.2053 - accuracy: 0.9306 - val_loss: 0.1635 - val_accuracy: 0.9370\n","Epoch 14/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.2073 - accuracy: 0.9283 - val_loss: 0.1654 - val_accuracy: 0.9424\n","Epoch 15/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.2066 - accuracy: 0.9227 - val_loss: 0.1507 - val_accuracy: 0.9491\n","Epoch 16/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1974 - accuracy: 0.9285 - val_loss: 0.1444 - val_accuracy: 0.9491\n","Epoch 17/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.2029 - accuracy: 0.9300 - val_loss: 0.1227 - val_accuracy: 0.9571\n","Epoch 18/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1576 - accuracy: 0.9440 - val_loss: 0.1890 - val_accuracy: 0.9450\n","Epoch 19/30\n","53/53 [==============================] - 4s 77ms/step - loss: 0.1785 - accuracy: 0.9393 - val_loss: 0.1204 - val_accuracy: 0.9491\n","Epoch 20/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1500 - accuracy: 0.9496 - val_loss: 0.1198 - val_accuracy: 0.9558\n","Epoch 21/30\n","53/53 [==============================] - 4s 77ms/step - loss: 0.1516 - accuracy: 0.9501 - val_loss: 0.1277 - val_accuracy: 0.9571\n","Epoch 22/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1568 - accuracy: 0.9475 - val_loss: 0.1638 - val_accuracy: 0.9383\n","Epoch 23/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1328 - accuracy: 0.9528 - val_loss: 0.1606 - val_accuracy: 0.9437\n","Epoch 24/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1381 - accuracy: 0.9538 - val_loss: 0.0932 - val_accuracy: 0.9692\n","Epoch 25/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1194 - accuracy: 0.9596 - val_loss: 0.1067 - val_accuracy: 0.9611\n","Epoch 26/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1261 - accuracy: 0.9595 - val_loss: 0.1035 - val_accuracy: 0.9665\n","Epoch 27/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.1140 - accuracy: 0.9608 - val_loss: 0.1183 - val_accuracy: 0.9584\n","Epoch 28/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1271 - accuracy: 0.9566 - val_loss: 0.1441 - val_accuracy: 0.9598\n","Epoch 29/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1307 - accuracy: 0.9560 - val_loss: 0.1015 - val_accuracy: 0.9651\n","Epoch 30/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1175 - accuracy: 0.9607 - val_loss: 0.1446 - val_accuracy: 0.9491\n","Results for fold 4\n","Epoch 1/30\n","53/53 [==============================] - 4s 76ms/step - loss: 0.1394 - accuracy: 0.9535 - val_loss: 0.0072 - val_accuracy: 1.0000\n","Epoch 2/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1386 - accuracy: 0.9563 - val_loss: 0.0065 - val_accuracy: 0.9987\n","Epoch 3/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1141 - accuracy: 0.9638 - val_loss: 0.0086 - val_accuracy: 0.9987\n","Epoch 4/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1168 - accuracy: 0.9638 - val_loss: 0.0094 - val_accuracy: 0.9973\n","Epoch 5/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1070 - accuracy: 0.9617 - val_loss: 0.0059 - val_accuracy: 0.9987\n","Epoch 6/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1208 - accuracy: 0.9607 - val_loss: 0.0052 - val_accuracy: 1.0000\n","Epoch 7/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1091 - accuracy: 0.9653 - val_loss: 0.0065 - val_accuracy: 0.9987\n","Epoch 8/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0925 - accuracy: 0.9723 - val_loss: 0.0374 - val_accuracy: 0.9879\n","Epoch 9/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1028 - accuracy: 0.9680 - val_loss: 0.0100 - val_accuracy: 0.9960\n","Epoch 10/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0817 - accuracy: 0.9738 - val_loss: 0.0129 - val_accuracy: 0.9960\n","Epoch 11/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0947 - accuracy: 0.9709 - val_loss: 0.0201 - val_accuracy: 0.9946\n","Epoch 12/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1053 - accuracy: 0.9638 - val_loss: 0.0179 - val_accuracy: 0.9946\n","Epoch 13/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0993 - accuracy: 0.9683 - val_loss: 0.0272 - val_accuracy: 0.9893\n","Epoch 14/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0981 - accuracy: 0.9684 - val_loss: 0.0131 - val_accuracy: 0.9973\n","Epoch 15/30\n","53/53 [==============================] - 4s 76ms/step - loss: 0.1056 - accuracy: 0.9659 - val_loss: 0.0192 - val_accuracy: 0.9960\n","Epoch 16/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0783 - accuracy: 0.9736 - val_loss: 0.0214 - val_accuracy: 0.9920\n","Epoch 17/30\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0944 - accuracy: 0.9708 - val_loss: 0.0178 - val_accuracy: 0.9960\n","Epoch 18/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0748 - accuracy: 0.9736 - val_loss: 0.0069 - val_accuracy: 0.9973\n","Epoch 19/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0795 - accuracy: 0.9741 - val_loss: 0.0129 - val_accuracy: 0.9960\n","Epoch 20/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0954 - accuracy: 0.9693 - val_loss: 0.0186 - val_accuracy: 0.9920\n","Epoch 21/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0840 - accuracy: 0.9739 - val_loss: 0.0133 - val_accuracy: 0.9960\n","Epoch 22/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0740 - accuracy: 0.9768 - val_loss: 0.0106 - val_accuracy: 0.9960\n","Epoch 23/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.0737 - accuracy: 0.9769 - val_loss: 0.0081 - val_accuracy: 0.9973\n","Epoch 24/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0693 - accuracy: 0.9775 - val_loss: 0.0122 - val_accuracy: 0.9960\n","Epoch 25/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0775 - accuracy: 0.9757 - val_loss: 0.0096 - val_accuracy: 0.9946\n","Epoch 26/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0709 - accuracy: 0.9768 - val_loss: 0.0146 - val_accuracy: 0.9946\n","Epoch 27/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0657 - accuracy: 0.9781 - val_loss: 0.0137 - val_accuracy: 0.9946\n","Epoch 28/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0933 - accuracy: 0.9708 - val_loss: 0.0145 - val_accuracy: 0.9973\n","Epoch 29/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0733 - accuracy: 0.9772 - val_loss: 0.0116 - val_accuracy: 0.9973\n","Epoch 30/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0728 - accuracy: 0.9748 - val_loss: 0.0097 - val_accuracy: 0.9973\n","Results for fold 5\n","Epoch 1/30\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0736 - accuracy: 0.9757 - val_loss: 0.0018 - val_accuracy: 1.0000\n","Epoch 2/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0755 - accuracy: 0.9757 - val_loss: 5.3361e-04 - val_accuracy: 1.0000\n","Epoch 3/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0631 - accuracy: 0.9805 - val_loss: 0.0067 - val_accuracy: 0.9973\n","Epoch 4/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0796 - accuracy: 0.9744 - val_loss: 0.0084 - val_accuracy: 0.9987\n","Epoch 5/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0623 - accuracy: 0.9794 - val_loss: 0.0027 - val_accuracy: 0.9987\n","Epoch 6/30\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0727 - accuracy: 0.9778 - val_loss: 0.0023 - val_accuracy: 1.0000\n","Epoch 7/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0576 - accuracy: 0.9824 - val_loss: 4.6421e-04 - val_accuracy: 1.0000\n","Epoch 8/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0623 - accuracy: 0.9802 - val_loss: 0.0051 - val_accuracy: 0.9987\n","Epoch 9/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0710 - accuracy: 0.9779 - val_loss: 0.0077 - val_accuracy: 0.9973\n","Epoch 10/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0610 - accuracy: 0.9803 - val_loss: 0.0027 - val_accuracy: 1.0000\n","Epoch 11/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0717 - accuracy: 0.9769 - val_loss: 0.0041 - val_accuracy: 0.9987\n","Epoch 12/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0787 - accuracy: 0.9742 - val_loss: 0.0042 - val_accuracy: 0.9987\n","Epoch 13/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0587 - accuracy: 0.9799 - val_loss: 0.0020 - val_accuracy: 1.0000\n","Epoch 14/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0707 - accuracy: 0.9779 - val_loss: 0.0071 - val_accuracy: 0.9960\n","Epoch 15/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0559 - accuracy: 0.9838 - val_loss: 0.0019 - val_accuracy: 1.0000\n","Epoch 16/30\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0572 - accuracy: 0.9841 - val_loss: 0.0186 - val_accuracy: 0.9906\n","Epoch 17/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0617 - accuracy: 0.9797 - val_loss: 0.0124 - val_accuracy: 0.9920\n","Epoch 18/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0618 - accuracy: 0.9797 - val_loss: 0.0033 - val_accuracy: 1.0000\n","Epoch 19/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0562 - accuracy: 0.9824 - val_loss: 0.0024 - val_accuracy: 0.9987\n","Epoch 20/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0609 - accuracy: 0.9785 - val_loss: 0.0044 - val_accuracy: 0.9987\n","Epoch 21/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0706 - accuracy: 0.9770 - val_loss: 0.0022 - val_accuracy: 1.0000\n","Epoch 22/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0549 - accuracy: 0.9812 - val_loss: 0.0023 - val_accuracy: 1.0000\n","Epoch 23/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0568 - accuracy: 0.9787 - val_loss: 0.0032 - val_accuracy: 1.0000\n","Epoch 24/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0513 - accuracy: 0.9841 - val_loss: 9.1052e-04 - val_accuracy: 1.0000\n","Epoch 25/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0612 - accuracy: 0.9823 - val_loss: 0.0052 - val_accuracy: 0.9987\n","Epoch 26/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0502 - accuracy: 0.9854 - val_loss: 0.0033 - val_accuracy: 0.9987\n","Epoch 27/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0451 - accuracy: 0.9845 - val_loss: 0.0018 - val_accuracy: 1.0000\n","Epoch 28/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0472 - accuracy: 0.9835 - val_loss: 0.0032 - val_accuracy: 1.0000\n","Epoch 29/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0497 - accuracy: 0.9844 - val_loss: 0.0034 - val_accuracy: 0.9987\n","Epoch 30/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0523 - accuracy: 0.9833 - val_loss: 0.0051 - val_accuracy: 0.9987\n","Results for fold 6\n","Epoch 1/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0501 - accuracy: 0.9838 - val_loss: 1.0967e-04 - val_accuracy: 1.0000\n","Epoch 2/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0506 - accuracy: 0.9818 - val_loss: 2.0972e-04 - val_accuracy: 1.0000\n","Epoch 3/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0563 - accuracy: 0.9820 - val_loss: 3.3753e-04 - val_accuracy: 1.0000\n","Epoch 4/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0687 - accuracy: 0.9769 - val_loss: 5.6580e-04 - val_accuracy: 1.0000\n","Epoch 5/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0437 - accuracy: 0.9866 - val_loss: 8.0188e-05 - val_accuracy: 1.0000\n","Epoch 6/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0489 - accuracy: 0.9854 - val_loss: 0.0014 - val_accuracy: 1.0000\n","Epoch 7/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0475 - accuracy: 0.9848 - val_loss: 1.5418e-04 - val_accuracy: 1.0000\n","Epoch 8/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0572 - accuracy: 0.9824 - val_loss: 0.0012 - val_accuracy: 1.0000\n","Epoch 9/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0570 - accuracy: 0.9821 - val_loss: 3.4008e-04 - val_accuracy: 1.0000\n","Epoch 10/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0502 - accuracy: 0.9830 - val_loss: 2.5256e-04 - val_accuracy: 1.0000\n","Epoch 11/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0422 - accuracy: 0.9860 - val_loss: 6.1252e-04 - val_accuracy: 1.0000\n","Epoch 12/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0456 - accuracy: 0.9867 - val_loss: 0.0015 - val_accuracy: 1.0000\n","Epoch 13/30\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0543 - accuracy: 0.9829 - val_loss: 6.3332e-04 - val_accuracy: 1.0000\n","Epoch 14/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0567 - accuracy: 0.9824 - val_loss: 0.0027 - val_accuracy: 1.0000\n","Epoch 15/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0542 - accuracy: 0.9827 - val_loss: 7.7303e-04 - val_accuracy: 1.0000\n","Epoch 16/30\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0452 - accuracy: 0.9846 - val_loss: 0.0031 - val_accuracy: 0.9987\n","Epoch 17/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0430 - accuracy: 0.9854 - val_loss: 0.0015 - val_accuracy: 1.0000\n","Epoch 18/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0519 - accuracy: 0.9808 - val_loss: 0.0018 - val_accuracy: 1.0000\n","Epoch 19/30\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0375 - accuracy: 0.9885 - val_loss: 0.0020 - val_accuracy: 0.9987\n","Epoch 20/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0475 - accuracy: 0.9861 - val_loss: 0.0099 - val_accuracy: 0.9973\n","Epoch 21/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0518 - accuracy: 0.9830 - val_loss: 4.1883e-04 - val_accuracy: 1.0000\n","Epoch 22/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0472 - accuracy: 0.9858 - val_loss: 3.8865e-04 - val_accuracy: 1.0000\n","Epoch 23/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0354 - accuracy: 0.9878 - val_loss: 3.0830e-04 - val_accuracy: 1.0000\n","Epoch 24/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0396 - accuracy: 0.9890 - val_loss: 9.4275e-04 - val_accuracy: 1.0000\n","Epoch 25/30\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0305 - accuracy: 0.9888 - val_loss: 0.0112 - val_accuracy: 0.9960\n","Epoch 26/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0604 - accuracy: 0.9811 - val_loss: 0.0268 - val_accuracy: 0.9893\n","Epoch 27/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0496 - accuracy: 0.9832 - val_loss: 8.0549e-04 - val_accuracy: 1.0000\n","Epoch 28/30\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0455 - accuracy: 0.9858 - val_loss: 0.0139 - val_accuracy: 0.9933\n","Epoch 29/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0500 - accuracy: 0.9838 - val_loss: 0.0010 - val_accuracy: 1.0000\n","Epoch 30/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0540 - accuracy: 0.9833 - val_loss: 0.0058 - val_accuracy: 0.9987\n","Results for fold 7\n","Epoch 1/30\n","53/53 [==============================] - 4s 83ms/step - loss: 0.0488 - accuracy: 0.9836 - val_loss: 6.5765e-04 - val_accuracy: 1.0000\n","Epoch 2/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0492 - accuracy: 0.9842 - val_loss: 1.4059e-04 - val_accuracy: 1.0000\n","Epoch 3/30\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0435 - accuracy: 0.9848 - val_loss: 3.1481e-04 - val_accuracy: 1.0000\n","Epoch 4/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0439 - accuracy: 0.9851 - val_loss: 1.5325e-04 - val_accuracy: 1.0000\n","Epoch 5/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0499 - accuracy: 0.9836 - val_loss: 2.1710e-04 - val_accuracy: 1.0000\n","Epoch 6/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0458 - accuracy: 0.9852 - val_loss: 9.6803e-04 - val_accuracy: 1.0000\n","Epoch 7/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0435 - accuracy: 0.9850 - val_loss: 9.6323e-05 - val_accuracy: 1.0000\n","Epoch 8/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0335 - accuracy: 0.9897 - val_loss: 0.0012 - val_accuracy: 1.0000\n","Epoch 9/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0304 - accuracy: 0.9893 - val_loss: 1.8661e-04 - val_accuracy: 1.0000\n","Epoch 10/30\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0432 - accuracy: 0.9881 - val_loss: 4.0163e-04 - val_accuracy: 1.0000\n","Epoch 11/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0500 - accuracy: 0.9841 - val_loss: 7.4234e-04 - val_accuracy: 1.0000\n","Epoch 12/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0350 - accuracy: 0.9887 - val_loss: 4.0901e-04 - val_accuracy: 1.0000\n","Epoch 13/30\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0436 - accuracy: 0.9879 - val_loss: 3.7448e-04 - val_accuracy: 1.0000\n","Epoch 14/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0376 - accuracy: 0.9890 - val_loss: 9.3361e-05 - val_accuracy: 1.0000\n","Epoch 15/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0394 - accuracy: 0.9870 - val_loss: 2.0839e-04 - val_accuracy: 1.0000\n","Epoch 16/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0450 - accuracy: 0.9848 - val_loss: 6.8186e-04 - val_accuracy: 1.0000\n","Epoch 17/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0464 - accuracy: 0.9842 - val_loss: 2.6547e-04 - val_accuracy: 1.0000\n","Epoch 18/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0345 - accuracy: 0.9897 - val_loss: 4.3194e-04 - val_accuracy: 1.0000\n","Epoch 19/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0356 - accuracy: 0.9879 - val_loss: 0.0013 - val_accuracy: 1.0000\n","Epoch 20/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0433 - accuracy: 0.9858 - val_loss: 1.3232e-04 - val_accuracy: 1.0000\n","Epoch 21/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0447 - accuracy: 0.9879 - val_loss: 0.0023 - val_accuracy: 0.9987\n","Epoch 22/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0484 - accuracy: 0.9851 - val_loss: 2.5301e-04 - val_accuracy: 1.0000\n","Epoch 23/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0315 - accuracy: 0.9911 - val_loss: 1.3671e-04 - val_accuracy: 1.0000\n","Epoch 24/30\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0354 - accuracy: 0.9891 - val_loss: 4.2948e-04 - val_accuracy: 1.0000\n","Epoch 25/30\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0371 - accuracy: 0.9875 - val_loss: 8.4304e-05 - val_accuracy: 1.0000\n","Epoch 26/30\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0413 - accuracy: 0.9873 - val_loss: 0.0010 - val_accuracy: 1.0000\n","Epoch 27/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0416 - accuracy: 0.9876 - val_loss: 8.4678e-04 - val_accuracy: 1.0000\n","Epoch 28/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0421 - accuracy: 0.9872 - val_loss: 6.5952e-04 - val_accuracy: 1.0000\n","Epoch 29/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0322 - accuracy: 0.9894 - val_loss: 0.0014 - val_accuracy: 1.0000\n","Epoch 30/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0462 - accuracy: 0.9857 - val_loss: 7.9997e-04 - val_accuracy: 1.0000\n","Results for fold 8\n","Epoch 1/30\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0416 - accuracy: 0.9869 - val_loss: 1.0174e-04 - val_accuracy: 1.0000\n","Epoch 2/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0320 - accuracy: 0.9908 - val_loss: 3.7537e-05 - val_accuracy: 1.0000\n","Epoch 3/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0307 - accuracy: 0.9911 - val_loss: 5.0567e-05 - val_accuracy: 1.0000\n","Epoch 4/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0392 - accuracy: 0.9866 - val_loss: 2.7930e-04 - val_accuracy: 1.0000\n","Epoch 5/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0310 - accuracy: 0.9882 - val_loss: 3.1966e-05 - val_accuracy: 1.0000\n","Epoch 6/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0367 - accuracy: 0.9876 - val_loss: 7.6627e-05 - val_accuracy: 1.0000\n","Epoch 7/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0430 - accuracy: 0.9876 - val_loss: 2.3320e-05 - val_accuracy: 1.0000\n","Epoch 8/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0322 - accuracy: 0.9903 - val_loss: 4.7100e-05 - val_accuracy: 1.0000\n","Epoch 9/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0360 - accuracy: 0.9884 - val_loss: 7.6394e-05 - val_accuracy: 1.0000\n","Epoch 10/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0398 - accuracy: 0.9858 - val_loss: 0.0011 - val_accuracy: 1.0000\n","Epoch 11/30\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0507 - accuracy: 0.9847 - val_loss: 1.7467e-04 - val_accuracy: 1.0000\n","Epoch 12/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0411 - accuracy: 0.9872 - val_loss: 6.0733e-05 - val_accuracy: 1.0000\n","Epoch 13/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0352 - accuracy: 0.9890 - val_loss: 0.0013 - val_accuracy: 1.0000\n","Epoch 14/30\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0275 - accuracy: 0.9900 - val_loss: 3.1131e-05 - val_accuracy: 1.0000\n","Epoch 15/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0346 - accuracy: 0.9885 - val_loss: 0.0124 - val_accuracy: 0.9973\n","Epoch 16/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0414 - accuracy: 0.9872 - val_loss: 4.7317e-05 - val_accuracy: 1.0000\n","Epoch 17/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0364 - accuracy: 0.9890 - val_loss: 6.4645e-05 - val_accuracy: 1.0000\n","Epoch 18/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0343 - accuracy: 0.9891 - val_loss: 4.2249e-04 - val_accuracy: 1.0000\n","Epoch 19/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0467 - accuracy: 0.9833 - val_loss: 4.6374e-04 - val_accuracy: 1.0000\n","Epoch 20/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0308 - accuracy: 0.9909 - val_loss: 7.8839e-04 - val_accuracy: 1.0000\n","Epoch 21/30\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0355 - accuracy: 0.9884 - val_loss: 6.0669e-04 - val_accuracy: 1.0000\n","Epoch 22/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0296 - accuracy: 0.9887 - val_loss: 0.0046 - val_accuracy: 0.9973\n","Epoch 23/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0322 - accuracy: 0.9896 - val_loss: 3.5806e-05 - val_accuracy: 1.0000\n","Epoch 24/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0256 - accuracy: 0.9918 - val_loss: 8.5181e-05 - val_accuracy: 1.0000\n","Epoch 25/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0246 - accuracy: 0.9923 - val_loss: 4.1199e-04 - val_accuracy: 1.0000\n","Epoch 26/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0370 - accuracy: 0.9885 - val_loss: 0.0052 - val_accuracy: 0.9973\n","Epoch 27/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0345 - accuracy: 0.9885 - val_loss: 2.9587e-05 - val_accuracy: 1.0000\n","Epoch 28/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0267 - accuracy: 0.9920 - val_loss: 0.0019 - val_accuracy: 0.9987\n","Epoch 29/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0357 - accuracy: 0.9887 - val_loss: 1.5923e-04 - val_accuracy: 1.0000\n","Epoch 30/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0399 - accuracy: 0.9869 - val_loss: 0.0055 - val_accuracy: 1.0000\n","Results for fold 9\n","Epoch 1/30\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0371 - accuracy: 0.9873 - val_loss: 4.3086e-05 - val_accuracy: 1.0000\n","Epoch 2/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0344 - accuracy: 0.9893 - val_loss: 4.1399e-04 - val_accuracy: 1.0000\n","Epoch 3/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0363 - accuracy: 0.9908 - val_loss: 8.7668e-04 - val_accuracy: 1.0000\n","Epoch 4/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0290 - accuracy: 0.9908 - val_loss: 1.4148e-04 - val_accuracy: 1.0000\n","Epoch 5/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0361 - accuracy: 0.9891 - val_loss: 6.7431e-04 - val_accuracy: 1.0000\n","Epoch 6/30\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 2.2055e-04 - val_accuracy: 1.0000\n","Epoch 7/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 0.0030 - val_accuracy: 0.9987\n","Epoch 8/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0362 - accuracy: 0.9879 - val_loss: 4.4869e-04 - val_accuracy: 1.0000\n","Epoch 9/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0302 - accuracy: 0.9908 - val_loss: 6.1984e-05 - val_accuracy: 1.0000\n","Epoch 10/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0420 - accuracy: 0.9857 - val_loss: 1.5187e-04 - val_accuracy: 1.0000\n","Epoch 11/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0341 - accuracy: 0.9888 - val_loss: 5.4263e-04 - val_accuracy: 1.0000\n","Epoch 12/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0358 - accuracy: 0.9894 - val_loss: 3.3363e-05 - val_accuracy: 1.0000\n","Epoch 13/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0342 - accuracy: 0.9911 - val_loss: 4.0935e-04 - val_accuracy: 1.0000\n","Epoch 14/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0224 - accuracy: 0.9927 - val_loss: 2.3159e-05 - val_accuracy: 1.0000\n","Epoch 15/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0223 - accuracy: 0.9918 - val_loss: 7.8662e-05 - val_accuracy: 1.0000\n","Epoch 16/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0330 - accuracy: 0.9888 - val_loss: 7.8182e-05 - val_accuracy: 1.0000\n","Epoch 17/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0313 - accuracy: 0.9888 - val_loss: 2.2596e-04 - val_accuracy: 1.0000\n","Epoch 18/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0230 - accuracy: 0.9930 - val_loss: 5.1681e-05 - val_accuracy: 1.0000\n","Epoch 19/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0264 - accuracy: 0.9923 - val_loss: 0.0013 - val_accuracy: 1.0000\n","Epoch 20/30\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0331 - accuracy: 0.9914 - val_loss: 2.9229e-04 - val_accuracy: 1.0000\n","Epoch 21/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0253 - accuracy: 0.9909 - val_loss: 2.9574e-04 - val_accuracy: 1.0000\n","Epoch 22/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0182 - accuracy: 0.9945 - val_loss: 2.5354e-05 - val_accuracy: 1.0000\n","Epoch 23/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0269 - accuracy: 0.9917 - val_loss: 2.2152e-04 - val_accuracy: 1.0000\n","Epoch 24/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0394 - accuracy: 0.9879 - val_loss: 9.8953e-04 - val_accuracy: 1.0000\n","Epoch 25/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0359 - accuracy: 0.9888 - val_loss: 6.9030e-05 - val_accuracy: 1.0000\n","Epoch 26/30\n","53/53 [==============================] - 4s 78ms/step - loss: 0.0237 - accuracy: 0.9918 - val_loss: 0.0027 - val_accuracy: 0.9987\n","Epoch 27/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0194 - accuracy: 0.9931 - val_loss: 5.5071e-05 - val_accuracy: 1.0000\n","Epoch 28/30\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0273 - accuracy: 0.9905 - val_loss: 4.0740e-04 - val_accuracy: 1.0000\n","Epoch 29/30\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0412 - accuracy: 0.9875 - val_loss: 0.0026 - val_accuracy: 0.9987\n","Epoch 30/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0300 - accuracy: 0.9888 - val_loss: 2.3960e-04 - val_accuracy: 1.0000\n","Results for fold 10\n","Epoch 1/30\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0304 - accuracy: 0.9900 - val_loss: 2.5880e-05 - val_accuracy: 1.0000\n","Epoch 2/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0266 - accuracy: 0.9914 - val_loss: 2.2697e-05 - val_accuracy: 1.0000\n","Epoch 3/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0319 - accuracy: 0.9896 - val_loss: 8.7912e-06 - val_accuracy: 1.0000\n","Epoch 4/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0344 - accuracy: 0.9896 - val_loss: 6.1914e-05 - val_accuracy: 1.0000\n","Epoch 5/30\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0274 - accuracy: 0.9914 - val_loss: 1.8797e-04 - val_accuracy: 1.0000\n","Epoch 6/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0374 - accuracy: 0.9894 - val_loss: 3.6904e-05 - val_accuracy: 1.0000\n","Epoch 7/30\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0157 - accuracy: 0.9958 - val_loss: 9.9254e-05 - val_accuracy: 1.0000\n","Epoch 8/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0296 - accuracy: 0.9923 - val_loss: 1.0252e-04 - val_accuracy: 1.0000\n","Epoch 9/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0211 - accuracy: 0.9936 - val_loss: 1.3455e-04 - val_accuracy: 1.0000\n","Epoch 10/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0244 - accuracy: 0.9931 - val_loss: 2.8135e-05 - val_accuracy: 1.0000\n","Epoch 11/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0209 - accuracy: 0.9930 - val_loss: 6.2277e-05 - val_accuracy: 1.0000\n","Epoch 12/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0350 - accuracy: 0.9905 - val_loss: 4.0779e-05 - val_accuracy: 1.0000\n","Epoch 13/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0299 - accuracy: 0.9900 - val_loss: 6.5855e-05 - val_accuracy: 1.0000\n","Epoch 14/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0264 - accuracy: 0.9908 - val_loss: 1.6392e-04 - val_accuracy: 1.0000\n","Epoch 15/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0260 - accuracy: 0.9921 - val_loss: 7.0807e-06 - val_accuracy: 1.0000\n","Epoch 16/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0217 - accuracy: 0.9921 - val_loss: 2.9442e-05 - val_accuracy: 1.0000\n","Epoch 17/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0262 - accuracy: 0.9914 - val_loss: 2.8993e-05 - val_accuracy: 1.0000\n","Epoch 18/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0306 - accuracy: 0.9887 - val_loss: 4.6795e-05 - val_accuracy: 1.0000\n","Epoch 19/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0258 - accuracy: 0.9909 - val_loss: 1.4505e-04 - val_accuracy: 1.0000\n","Epoch 20/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0267 - accuracy: 0.9906 - val_loss: 4.7035e-05 - val_accuracy: 1.0000\n","Epoch 21/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0333 - accuracy: 0.9897 - val_loss: 4.1964e-04 - val_accuracy: 1.0000\n","Epoch 22/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0281 - accuracy: 0.9900 - val_loss: 6.9744e-05 - val_accuracy: 1.0000\n","Epoch 23/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0312 - accuracy: 0.9891 - val_loss: 7.0384e-05 - val_accuracy: 1.0000\n","Epoch 24/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0254 - accuracy: 0.9903 - val_loss: 1.5247e-05 - val_accuracy: 1.0000\n","Epoch 25/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0254 - accuracy: 0.9914 - val_loss: 1.6405e-04 - val_accuracy: 1.0000\n","Epoch 26/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 0.0025 - val_accuracy: 0.9987\n","Epoch 27/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0206 - accuracy: 0.9946 - val_loss: 4.3451e-06 - val_accuracy: 1.0000\n","Epoch 28/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0206 - accuracy: 0.9930 - val_loss: 2.8873e-04 - val_accuracy: 1.0000\n","Epoch 29/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0324 - accuracy: 0.9900 - val_loss: 7.7305e-05 - val_accuracy: 1.0000\n","Epoch 30/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0264 - accuracy: 0.9914 - val_loss: 5.1498e-05 - val_accuracy: 1.0000\n"]}]},{"cell_type":"code","metadata":{"id":"CAnc2SJa3o9f","colab":{"base_uri":"https://localhost:8080/","height":723},"executionInfo":{"status":"ok","timestamp":1633078167861,"user_tz":-360,"elapsed":3306,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"f4715be2-e0cf-43db-ad9f-37e9890d4db8"},"source":["acrc = model.evaluate(x_test, y_test)\n","pred = model.predict(x_test)\n","f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n","c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n","print(\"Accuracy  : {}\".format(acrc[1]))\n","print(\"F1_Score  : {}\".format(f1scr))\n","c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n","import seaborn as sns\n","figure = plt.figure(figsize=(9, 9))\n","sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n","plt.tight_layout()\n","plt.ylabel('True label')\n","plt.xlabel('Predicted label')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["59/59 [==============================] - 1s 14ms/step - loss: 0.0532 - accuracy: 0.9785\n","Accuracy  : 0.9785407781600952\n","F1_Score  : 0.9765589754372006\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 648x648 with 2 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"e1ypZ2NnYxes"},"source":["# **Arousal**"]},{"cell_type":"code","metadata":{"id":"B7fcxLuwZpkK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633078168662,"user_tz":-360,"elapsed":817,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"fcc7a2c5-b7bb-4ef8-d30e-7b2613d67fcf"},"source":["#arousal\n","X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n","print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4iz5mTT7Zwcp","executionInfo":{"status":"ok","timestamp":1633079499340,"user_tz":-360,"elapsed":1330683,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"a78226ed-cb5f-4828-a3b3-ed7a0d79ce3e"},"source":["foldNum=0\n","model = get_model()\n","for train_index, val_index in kfold.split(X_train, Y_train):\n","  foldNum = foldNum + 1\n","  print(\"Results for fold\",foldNum)\n","  x_train, x_val = X_train[train_index], X_train[val_index]\n","  y_train, y_val = Y_train[train_index], Y_train[val_index]\n","  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n","  gc.collect() # Garbage collecter\n","  del x_train, x_val, y_train, y_val\n","  gc.collect()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Results for fold 1\n","Epoch 1/30\n","53/53 [==============================] - 5s 79ms/step - loss: 0.9854 - accuracy: 0.4763 - val_loss: 0.8786 - val_accuracy: 0.4665\n","Epoch 2/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.9470 - accuracy: 0.4785 - val_loss: 0.8674 - val_accuracy: 0.5040\n","Epoch 3/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.9325 - accuracy: 0.4809 - val_loss: 0.8819 - val_accuracy: 0.5268\n","Epoch 4/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.9339 - accuracy: 0.4939 - val_loss: 0.8676 - val_accuracy: 0.5241\n","Epoch 5/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.9274 - accuracy: 0.4781 - val_loss: 0.8741 - val_accuracy: 0.5121\n","Epoch 6/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.9210 - accuracy: 0.4750 - val_loss: 0.8534 - val_accuracy: 0.5188\n","Epoch 7/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.9181 - accuracy: 0.4849 - val_loss: 0.8671 - val_accuracy: 0.5174\n","Epoch 8/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.9018 - accuracy: 0.4934 - val_loss: 0.8673 - val_accuracy: 0.5255\n","Epoch 9/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.9046 - accuracy: 0.5033 - val_loss: 0.8608 - val_accuracy: 0.5134\n","Epoch 10/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.8973 - accuracy: 0.4832 - val_loss: 0.8866 - val_accuracy: 0.5174\n","Epoch 11/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.8879 - accuracy: 0.5037 - val_loss: 0.8358 - val_accuracy: 0.5255\n","Epoch 12/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.8883 - accuracy: 0.5048 - val_loss: 0.8310 - val_accuracy: 0.5523\n","Epoch 13/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.8824 - accuracy: 0.5116 - val_loss: 0.8454 - val_accuracy: 0.5349\n","Epoch 14/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.8780 - accuracy: 0.5139 - val_loss: 0.8276 - val_accuracy: 0.5255\n","Epoch 15/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.8675 - accuracy: 0.5136 - val_loss: 0.8393 - val_accuracy: 0.5322\n","Epoch 16/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.8656 - accuracy: 0.5139 - val_loss: 0.8560 - val_accuracy: 0.5228\n","Epoch 17/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.8630 - accuracy: 0.5204 - val_loss: 0.8144 - val_accuracy: 0.5375\n","Epoch 18/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.8536 - accuracy: 0.5246 - val_loss: 0.8533 - val_accuracy: 0.5670\n","Epoch 19/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.8464 - accuracy: 0.5289 - val_loss: 0.8067 - val_accuracy: 0.5536\n","Epoch 20/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.8406 - accuracy: 0.5320 - val_loss: 0.8246 - val_accuracy: 0.5268\n","Epoch 21/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.8394 - accuracy: 0.5386 - val_loss: 0.8420 - val_accuracy: 0.5228\n","Epoch 22/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.8311 - accuracy: 0.5374 - val_loss: 0.8213 - val_accuracy: 0.5429\n","Epoch 23/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.8291 - accuracy: 0.5408 - val_loss: 0.8169 - val_accuracy: 0.5791\n","Epoch 24/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.8209 - accuracy: 0.5478 - val_loss: 0.8054 - val_accuracy: 0.5684\n","Epoch 25/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.8106 - accuracy: 0.5587 - val_loss: 0.7816 - val_accuracy: 0.5818\n","Epoch 26/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.8018 - accuracy: 0.5653 - val_loss: 0.8146 - val_accuracy: 0.5791\n","Epoch 27/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.7996 - accuracy: 0.5684 - val_loss: 0.8035 - val_accuracy: 0.5670\n","Epoch 28/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.7826 - accuracy: 0.5805 - val_loss: 0.7973 - val_accuracy: 0.5952\n","Epoch 29/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.7719 - accuracy: 0.5866 - val_loss: 0.7755 - val_accuracy: 0.5858\n","Epoch 30/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.7562 - accuracy: 0.5920 - val_loss: 0.8011 - val_accuracy: 0.5657\n","Results for fold 2\n","Epoch 1/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.7605 - accuracy: 0.5900 - val_loss: 0.7055 - val_accuracy: 0.6408\n","Epoch 2/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.7359 - accuracy: 0.6048 - val_loss: 0.7482 - val_accuracy: 0.5979\n","Epoch 3/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.7434 - accuracy: 0.6079 - val_loss: 0.7526 - val_accuracy: 0.5925\n","Epoch 4/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.7359 - accuracy: 0.6182 - val_loss: 0.7220 - val_accuracy: 0.6166\n","Epoch 5/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.7128 - accuracy: 0.6329 - val_loss: 0.7162 - val_accuracy: 0.6408\n","Epoch 6/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.7150 - accuracy: 0.6332 - val_loss: 0.6774 - val_accuracy: 0.6475\n","Epoch 7/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.6879 - accuracy: 0.6532 - val_loss: 0.6944 - val_accuracy: 0.6448\n","Epoch 8/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.6714 - accuracy: 0.6608 - val_loss: 0.7312 - val_accuracy: 0.6220\n","Epoch 9/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.6617 - accuracy: 0.6745 - val_loss: 0.7918 - val_accuracy: 0.6247\n","Epoch 10/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.6564 - accuracy: 0.6726 - val_loss: 0.7213 - val_accuracy: 0.6434\n","Epoch 11/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.6454 - accuracy: 0.6814 - val_loss: 0.6513 - val_accuracy: 0.6595\n","Epoch 12/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.6297 - accuracy: 0.6903 - val_loss: 0.6250 - val_accuracy: 0.6997\n","Epoch 13/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.6162 - accuracy: 0.7061 - val_loss: 0.6764 - val_accuracy: 0.6810\n","Epoch 14/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.6050 - accuracy: 0.7149 - val_loss: 0.6310 - val_accuracy: 0.6823\n","Epoch 15/30\n","53/53 [==============================] - 4s 71ms/step - loss: 0.5780 - accuracy: 0.7300 - val_loss: 0.6458 - val_accuracy: 0.6971\n","Epoch 16/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.5706 - accuracy: 0.7262 - val_loss: 0.6194 - val_accuracy: 0.6823\n","Epoch 17/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.5761 - accuracy: 0.7326 - val_loss: 0.5733 - val_accuracy: 0.7265\n","Epoch 18/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.5530 - accuracy: 0.7349 - val_loss: 0.6086 - val_accuracy: 0.7131\n","Epoch 19/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.5520 - accuracy: 0.7489 - val_loss: 0.6203 - val_accuracy: 0.6917\n","Epoch 20/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.5245 - accuracy: 0.7630 - val_loss: 0.5727 - val_accuracy: 0.7198\n","Epoch 21/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.5053 - accuracy: 0.7693 - val_loss: 0.5743 - val_accuracy: 0.7507\n","Epoch 22/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.4872 - accuracy: 0.7751 - val_loss: 0.5704 - val_accuracy: 0.7466\n","Epoch 23/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.5034 - accuracy: 0.7763 - val_loss: 0.5215 - val_accuracy: 0.7493\n","Epoch 24/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.4592 - accuracy: 0.7987 - val_loss: 0.5345 - val_accuracy: 0.7587\n","Epoch 25/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.4573 - accuracy: 0.8000 - val_loss: 0.5220 - val_accuracy: 0.7748\n","Epoch 26/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.4576 - accuracy: 0.8028 - val_loss: 0.5758 - val_accuracy: 0.7587\n","Epoch 27/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.4393 - accuracy: 0.8116 - val_loss: 0.5212 - val_accuracy: 0.7681\n","Epoch 28/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.4246 - accuracy: 0.8194 - val_loss: 0.5126 - val_accuracy: 0.7788\n","Epoch 29/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.4097 - accuracy: 0.8230 - val_loss: 0.5231 - val_accuracy: 0.7466\n","Epoch 30/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.3913 - accuracy: 0.8359 - val_loss: 0.5094 - val_accuracy: 0.7641\n","Results for fold 3\n","Epoch 1/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.4145 - accuracy: 0.8267 - val_loss: 0.2796 - val_accuracy: 0.8874\n","Epoch 2/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.3877 - accuracy: 0.8356 - val_loss: 0.2452 - val_accuracy: 0.8995\n","Epoch 3/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.3970 - accuracy: 0.8350 - val_loss: 0.2607 - val_accuracy: 0.9008\n","Epoch 4/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.3687 - accuracy: 0.8423 - val_loss: 0.2394 - val_accuracy: 0.9115\n","Epoch 5/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.3775 - accuracy: 0.8462 - val_loss: 0.2491 - val_accuracy: 0.8995\n","Epoch 6/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.3627 - accuracy: 0.8466 - val_loss: 0.2888 - val_accuracy: 0.8861\n","Epoch 7/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.3350 - accuracy: 0.8632 - val_loss: 0.2863 - val_accuracy: 0.8794\n","Epoch 8/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.3296 - accuracy: 0.8627 - val_loss: 0.2389 - val_accuracy: 0.8954\n","Epoch 9/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.3507 - accuracy: 0.8586 - val_loss: 0.3355 - val_accuracy: 0.8499\n","Epoch 10/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.3437 - accuracy: 0.8611 - val_loss: 0.2947 - val_accuracy: 0.8767\n","Epoch 11/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.3158 - accuracy: 0.8742 - val_loss: 0.2360 - val_accuracy: 0.8914\n","Epoch 12/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.3004 - accuracy: 0.8824 - val_loss: 0.2410 - val_accuracy: 0.9008\n","Epoch 13/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.3083 - accuracy: 0.8775 - val_loss: 0.2181 - val_accuracy: 0.9088\n","Epoch 14/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.2772 - accuracy: 0.8885 - val_loss: 0.2345 - val_accuracy: 0.8914\n","Epoch 15/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.2716 - accuracy: 0.8949 - val_loss: 0.2204 - val_accuracy: 0.9075\n","Epoch 16/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.2801 - accuracy: 0.8888 - val_loss: 0.2516 - val_accuracy: 0.8981\n","Epoch 17/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.2795 - accuracy: 0.8897 - val_loss: 0.1975 - val_accuracy: 0.9115\n","Epoch 18/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.2728 - accuracy: 0.8960 - val_loss: 0.2411 - val_accuracy: 0.8995\n","Epoch 19/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.2575 - accuracy: 0.9040 - val_loss: 0.2777 - val_accuracy: 0.8874\n","Epoch 20/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.2413 - accuracy: 0.9064 - val_loss: 0.2783 - val_accuracy: 0.8753\n","Epoch 21/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.2441 - accuracy: 0.9015 - val_loss: 0.2623 - val_accuracy: 0.8995\n","Epoch 22/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.2170 - accuracy: 0.9130 - val_loss: 0.2174 - val_accuracy: 0.9129\n","Epoch 23/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.2340 - accuracy: 0.9080 - val_loss: 0.2227 - val_accuracy: 0.9035\n","Epoch 24/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.2269 - accuracy: 0.9133 - val_loss: 0.2412 - val_accuracy: 0.8995\n","Epoch 25/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.1970 - accuracy: 0.9280 - val_loss: 0.2383 - val_accuracy: 0.9021\n","Epoch 26/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.2184 - accuracy: 0.9197 - val_loss: 0.2168 - val_accuracy: 0.9062\n","Epoch 27/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.2036 - accuracy: 0.9227 - val_loss: 0.2102 - val_accuracy: 0.9155\n","Epoch 28/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.1927 - accuracy: 0.9306 - val_loss: 0.2388 - val_accuracy: 0.9075\n","Epoch 29/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.2083 - accuracy: 0.9216 - val_loss: 0.2229 - val_accuracy: 0.8981\n","Epoch 30/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.1904 - accuracy: 0.9335 - val_loss: 0.2605 - val_accuracy: 0.8901\n","Results for fold 4\n","Epoch 1/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.2262 - accuracy: 0.9204 - val_loss: 0.0751 - val_accuracy: 0.9786\n","Epoch 2/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1973 - accuracy: 0.9301 - val_loss: 0.0725 - val_accuracy: 0.9759\n","Epoch 3/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1990 - accuracy: 0.9270 - val_loss: 0.0593 - val_accuracy: 0.9826\n","Epoch 4/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.2034 - accuracy: 0.9238 - val_loss: 0.1259 - val_accuracy: 0.9477\n","Epoch 5/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1848 - accuracy: 0.9334 - val_loss: 0.0475 - val_accuracy: 0.9906\n","Epoch 6/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1796 - accuracy: 0.9331 - val_loss: 0.1245 - val_accuracy: 0.9464\n","Epoch 7/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1753 - accuracy: 0.9355 - val_loss: 0.0830 - val_accuracy: 0.9705\n","Epoch 8/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.1737 - accuracy: 0.9401 - val_loss: 0.0636 - val_accuracy: 0.9812\n","Epoch 9/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1678 - accuracy: 0.9410 - val_loss: 0.0897 - val_accuracy: 0.9732\n","Epoch 10/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1696 - accuracy: 0.9383 - val_loss: 0.0748 - val_accuracy: 0.9745\n","Epoch 11/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.1653 - accuracy: 0.9401 - val_loss: 0.0801 - val_accuracy: 0.9705\n","Epoch 12/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.1693 - accuracy: 0.9386 - val_loss: 0.1055 - val_accuracy: 0.9625\n","Epoch 13/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1696 - accuracy: 0.9387 - val_loss: 0.0886 - val_accuracy: 0.9732\n","Epoch 14/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1441 - accuracy: 0.9492 - val_loss: 0.0863 - val_accuracy: 0.9692\n","Epoch 15/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.1787 - accuracy: 0.9359 - val_loss: 0.1233 - val_accuracy: 0.9558\n","Epoch 16/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.1490 - accuracy: 0.9505 - val_loss: 0.1691 - val_accuracy: 0.9477\n","Epoch 17/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1310 - accuracy: 0.9554 - val_loss: 0.1004 - val_accuracy: 0.9625\n","Epoch 18/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1448 - accuracy: 0.9472 - val_loss: 0.0948 - val_accuracy: 0.9665\n","Epoch 19/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.1443 - accuracy: 0.9496 - val_loss: 0.1046 - val_accuracy: 0.9584\n","Epoch 20/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1476 - accuracy: 0.9493 - val_loss: 0.0627 - val_accuracy: 0.9732\n","Epoch 21/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1310 - accuracy: 0.9537 - val_loss: 0.0792 - val_accuracy: 0.9718\n","Epoch 22/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1378 - accuracy: 0.9511 - val_loss: 0.0909 - val_accuracy: 0.9638\n","Epoch 23/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1270 - accuracy: 0.9538 - val_loss: 0.1061 - val_accuracy: 0.9611\n","Epoch 24/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.1192 - accuracy: 0.9615 - val_loss: 0.0656 - val_accuracy: 0.9786\n","Epoch 25/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1275 - accuracy: 0.9553 - val_loss: 0.0831 - val_accuracy: 0.9665\n","Epoch 26/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1247 - accuracy: 0.9557 - val_loss: 0.1029 - val_accuracy: 0.9705\n","Epoch 27/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.1104 - accuracy: 0.9624 - val_loss: 0.0871 - val_accuracy: 0.9651\n","Epoch 28/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.1216 - accuracy: 0.9583 - val_loss: 0.0870 - val_accuracy: 0.9772\n","Epoch 29/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1208 - accuracy: 0.9595 - val_loss: 0.0903 - val_accuracy: 0.9651\n","Epoch 30/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.1227 - accuracy: 0.9544 - val_loss: 0.0780 - val_accuracy: 0.9692\n","Results for fold 5\n","Epoch 1/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.1592 - accuracy: 0.9449 - val_loss: 0.0172 - val_accuracy: 0.9973\n","Epoch 2/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1235 - accuracy: 0.9577 - val_loss: 0.0068 - val_accuracy: 1.0000\n","Epoch 3/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.1439 - accuracy: 0.9505 - val_loss: 0.0181 - val_accuracy: 0.9973\n","Epoch 4/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1240 - accuracy: 0.9586 - val_loss: 0.0287 - val_accuracy: 0.9906\n","Epoch 5/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.1375 - accuracy: 0.9502 - val_loss: 0.0227 - val_accuracy: 0.9946\n","Epoch 6/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1111 - accuracy: 0.9629 - val_loss: 0.0112 - val_accuracy: 0.9987\n","Epoch 7/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.1159 - accuracy: 0.9617 - val_loss: 0.0317 - val_accuracy: 0.9893\n","Epoch 8/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1157 - accuracy: 0.9592 - val_loss: 0.0156 - val_accuracy: 0.9973\n","Epoch 9/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0948 - accuracy: 0.9683 - val_loss: 0.0126 - val_accuracy: 0.9973\n","Epoch 10/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1080 - accuracy: 0.9607 - val_loss: 0.0226 - val_accuracy: 0.9906\n","Epoch 11/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1117 - accuracy: 0.9608 - val_loss: 0.0569 - val_accuracy: 0.9786\n","Epoch 12/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.1180 - accuracy: 0.9601 - val_loss: 0.0346 - val_accuracy: 0.9866\n","Epoch 13/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.1017 - accuracy: 0.9647 - val_loss: 0.0307 - val_accuracy: 0.9893\n","Epoch 14/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0966 - accuracy: 0.9674 - val_loss: 0.0279 - val_accuracy: 0.9920\n","Epoch 15/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.0965 - accuracy: 0.9672 - val_loss: 0.0284 - val_accuracy: 0.9920\n","Epoch 16/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0944 - accuracy: 0.9694 - val_loss: 0.0279 - val_accuracy: 0.9920\n","Epoch 17/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.1071 - accuracy: 0.9621 - val_loss: 0.0312 - val_accuracy: 0.9906\n","Epoch 18/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1002 - accuracy: 0.9684 - val_loss: 0.0162 - val_accuracy: 0.9987\n","Epoch 19/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.1043 - accuracy: 0.9663 - val_loss: 0.0364 - val_accuracy: 0.9893\n","Epoch 20/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0932 - accuracy: 0.9672 - val_loss: 0.0213 - val_accuracy: 0.9946\n","Epoch 21/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0938 - accuracy: 0.9690 - val_loss: 0.0275 - val_accuracy: 0.9906\n","Epoch 22/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0860 - accuracy: 0.9717 - val_loss: 0.0321 - val_accuracy: 0.9893\n","Epoch 23/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0941 - accuracy: 0.9703 - val_loss: 0.0324 - val_accuracy: 0.9866\n","Epoch 24/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0907 - accuracy: 0.9706 - val_loss: 0.0299 - val_accuracy: 0.9906\n","Epoch 25/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0916 - accuracy: 0.9681 - val_loss: 0.0649 - val_accuracy: 0.9786\n","Epoch 26/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0938 - accuracy: 0.9715 - val_loss: 0.0257 - val_accuracy: 0.9906\n","Epoch 27/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1007 - accuracy: 0.9674 - val_loss: 0.0604 - val_accuracy: 0.9772\n","Epoch 28/30\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0937 - accuracy: 0.9683 - val_loss: 0.0538 - val_accuracy: 0.9812\n","Epoch 29/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0817 - accuracy: 0.9736 - val_loss: 0.0267 - val_accuracy: 0.9920\n","Epoch 30/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0903 - accuracy: 0.9689 - val_loss: 0.0222 - val_accuracy: 0.9906\n","Results for fold 6\n","Epoch 1/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0988 - accuracy: 0.9672 - val_loss: 0.0048 - val_accuracy: 1.0000\n","Epoch 2/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0875 - accuracy: 0.9708 - val_loss: 0.0050 - val_accuracy: 1.0000\n","Epoch 3/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0917 - accuracy: 0.9697 - val_loss: 0.0093 - val_accuracy: 0.9973\n","Epoch 4/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1054 - accuracy: 0.9657 - val_loss: 0.0082 - val_accuracy: 0.9987\n","Epoch 5/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.0913 - accuracy: 0.9690 - val_loss: 0.0057 - val_accuracy: 1.0000\n","Epoch 6/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0912 - accuracy: 0.9706 - val_loss: 0.0066 - val_accuracy: 0.9987\n","Epoch 7/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0925 - accuracy: 0.9678 - val_loss: 0.0061 - val_accuracy: 1.0000\n","Epoch 8/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0912 - accuracy: 0.9709 - val_loss: 0.0222 - val_accuracy: 0.9920\n","Epoch 9/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0852 - accuracy: 0.9700 - val_loss: 0.0068 - val_accuracy: 0.9987\n","Epoch 10/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0639 - accuracy: 0.9790 - val_loss: 0.0101 - val_accuracy: 0.9987\n","Epoch 11/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0943 - accuracy: 0.9681 - val_loss: 0.0099 - val_accuracy: 0.9973\n","Epoch 12/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0771 - accuracy: 0.9729 - val_loss: 0.0164 - val_accuracy: 0.9946\n","Epoch 13/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0837 - accuracy: 0.9730 - val_loss: 0.0122 - val_accuracy: 0.9987\n","Epoch 14/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0728 - accuracy: 0.9770 - val_loss: 0.0092 - val_accuracy: 0.9960\n","Epoch 15/30\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0848 - accuracy: 0.9708 - val_loss: 0.0118 - val_accuracy: 0.9946\n","Epoch 16/30\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0662 - accuracy: 0.9773 - val_loss: 0.0075 - val_accuracy: 0.9960\n","Epoch 17/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0823 - accuracy: 0.9705 - val_loss: 0.0101 - val_accuracy: 0.9946\n","Epoch 18/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.1030 - accuracy: 0.9678 - val_loss: 0.0452 - val_accuracy: 0.9839\n","Epoch 19/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0708 - accuracy: 0.9782 - val_loss: 0.0118 - val_accuracy: 0.9960\n","Epoch 20/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0719 - accuracy: 0.9760 - val_loss: 0.0160 - val_accuracy: 0.9933\n","Epoch 21/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0796 - accuracy: 0.9729 - val_loss: 0.0257 - val_accuracy: 0.9893\n","Epoch 22/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.0728 - accuracy: 0.9768 - val_loss: 0.0144 - val_accuracy: 0.9960\n","Epoch 23/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0697 - accuracy: 0.9794 - val_loss: 0.0314 - val_accuracy: 0.9853\n","Epoch 24/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.0800 - accuracy: 0.9744 - val_loss: 0.0230 - val_accuracy: 0.9906\n","Epoch 25/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0822 - accuracy: 0.9726 - val_loss: 0.0265 - val_accuracy: 0.9906\n","Epoch 26/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.0663 - accuracy: 0.9784 - val_loss: 0.0141 - val_accuracy: 0.9973\n","Epoch 27/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0849 - accuracy: 0.9702 - val_loss: 0.0075 - val_accuracy: 0.9960\n","Epoch 28/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0748 - accuracy: 0.9773 - val_loss: 0.0116 - val_accuracy: 0.9960\n","Epoch 29/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0747 - accuracy: 0.9756 - val_loss: 0.0176 - val_accuracy: 0.9933\n","Epoch 30/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0602 - accuracy: 0.9811 - val_loss: 0.0324 - val_accuracy: 0.9920\n","Results for fold 7\n","Epoch 1/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0763 - accuracy: 0.9724 - val_loss: 0.0051 - val_accuracy: 0.9987\n","Epoch 2/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0852 - accuracy: 0.9745 - val_loss: 0.0011 - val_accuracy: 1.0000\n","Epoch 3/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0837 - accuracy: 0.9729 - val_loss: 0.0152 - val_accuracy: 0.9946\n","Epoch 4/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0740 - accuracy: 0.9729 - val_loss: 0.0028 - val_accuracy: 1.0000\n","Epoch 5/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0699 - accuracy: 0.9769 - val_loss: 0.0081 - val_accuracy: 0.9973\n","Epoch 6/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0773 - accuracy: 0.9747 - val_loss: 0.0027 - val_accuracy: 1.0000\n","Epoch 7/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0644 - accuracy: 0.9788 - val_loss: 0.0088 - val_accuracy: 0.9973\n","Epoch 8/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0668 - accuracy: 0.9788 - val_loss: 0.0022 - val_accuracy: 1.0000\n","Epoch 9/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0613 - accuracy: 0.9788 - val_loss: 0.0041 - val_accuracy: 0.9987\n","Epoch 10/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.0815 - accuracy: 0.9712 - val_loss: 0.0048 - val_accuracy: 1.0000\n","Epoch 11/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0661 - accuracy: 0.9759 - val_loss: 0.0029 - val_accuracy: 1.0000\n","Epoch 12/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0599 - accuracy: 0.9802 - val_loss: 0.0042 - val_accuracy: 0.9987\n","Epoch 13/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0621 - accuracy: 0.9788 - val_loss: 0.0030 - val_accuracy: 1.0000\n","Epoch 14/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0680 - accuracy: 0.9776 - val_loss: 0.0039 - val_accuracy: 1.0000\n","Epoch 15/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0563 - accuracy: 0.9815 - val_loss: 0.0068 - val_accuracy: 0.9987\n","Epoch 16/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.0592 - accuracy: 0.9811 - val_loss: 0.0097 - val_accuracy: 0.9960\n","Epoch 17/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0774 - accuracy: 0.9744 - val_loss: 0.0190 - val_accuracy: 0.9933\n","Epoch 18/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0587 - accuracy: 0.9803 - val_loss: 0.0109 - val_accuracy: 0.9960\n","Epoch 19/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0553 - accuracy: 0.9839 - val_loss: 0.0079 - val_accuracy: 0.9960\n","Epoch 20/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0599 - accuracy: 0.9829 - val_loss: 0.0048 - val_accuracy: 0.9987\n","Epoch 21/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0513 - accuracy: 0.9833 - val_loss: 0.0040 - val_accuracy: 1.0000\n","Epoch 22/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0627 - accuracy: 0.9820 - val_loss: 0.0059 - val_accuracy: 0.9987\n","Epoch 23/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0616 - accuracy: 0.9829 - val_loss: 0.0030 - val_accuracy: 0.9987\n","Epoch 24/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0565 - accuracy: 0.9821 - val_loss: 0.0207 - val_accuracy: 0.9960\n","Epoch 25/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0632 - accuracy: 0.9802 - val_loss: 0.0037 - val_accuracy: 1.0000\n","Epoch 26/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0534 - accuracy: 0.9820 - val_loss: 0.0060 - val_accuracy: 0.9987\n","Epoch 27/30\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0709 - accuracy: 0.9772 - val_loss: 0.0095 - val_accuracy: 0.9973\n","Epoch 28/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.0623 - accuracy: 0.9787 - val_loss: 0.0071 - val_accuracy: 0.9973\n","Epoch 29/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0451 - accuracy: 0.9864 - val_loss: 0.0024 - val_accuracy: 1.0000\n","Epoch 30/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0480 - accuracy: 0.9847 - val_loss: 0.0093 - val_accuracy: 0.9973\n","Results for fold 8\n","Epoch 1/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0716 - accuracy: 0.9753 - val_loss: 0.0038 - val_accuracy: 0.9987\n","Epoch 2/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0679 - accuracy: 0.9781 - val_loss: 0.0055 - val_accuracy: 0.9973\n","Epoch 3/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0621 - accuracy: 0.9809 - val_loss: 0.0034 - val_accuracy: 0.9987\n","Epoch 4/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0504 - accuracy: 0.9852 - val_loss: 0.0046 - val_accuracy: 1.0000\n","Epoch 5/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0603 - accuracy: 0.9803 - val_loss: 0.0033 - val_accuracy: 1.0000\n","Epoch 6/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0808 - accuracy: 0.9721 - val_loss: 0.0149 - val_accuracy: 0.9960\n","Epoch 7/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0683 - accuracy: 0.9765 - val_loss: 0.0017 - val_accuracy: 1.0000\n","Epoch 8/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0655 - accuracy: 0.9784 - val_loss: 0.0023 - val_accuracy: 1.0000\n","Epoch 9/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0507 - accuracy: 0.9844 - val_loss: 0.0115 - val_accuracy: 0.9973\n","Epoch 10/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0616 - accuracy: 0.9812 - val_loss: 0.0057 - val_accuracy: 0.9987\n","Epoch 11/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0482 - accuracy: 0.9857 - val_loss: 0.0091 - val_accuracy: 0.9946\n","Epoch 12/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0748 - accuracy: 0.9771 - val_loss: 0.0032 - val_accuracy: 1.0000\n","Epoch 13/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0576 - accuracy: 0.9838 - val_loss: 0.0040 - val_accuracy: 0.9987\n","Epoch 14/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0528 - accuracy: 0.9839 - val_loss: 0.0017 - val_accuracy: 1.0000\n","Epoch 15/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0503 - accuracy: 0.9851 - val_loss: 0.0025 - val_accuracy: 1.0000\n","Epoch 16/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0564 - accuracy: 0.9827 - val_loss: 0.0015 - val_accuracy: 1.0000\n","Epoch 17/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0439 - accuracy: 0.9876 - val_loss: 0.0013 - val_accuracy: 1.0000\n","Epoch 18/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0572 - accuracy: 0.9809 - val_loss: 0.0012 - val_accuracy: 1.0000\n","Epoch 19/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0518 - accuracy: 0.9830 - val_loss: 0.0030 - val_accuracy: 0.9987\n","Epoch 20/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0529 - accuracy: 0.9817 - val_loss: 0.0029 - val_accuracy: 1.0000\n","Epoch 21/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0499 - accuracy: 0.9827 - val_loss: 0.0020 - val_accuracy: 1.0000\n","Epoch 22/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0524 - accuracy: 0.9833 - val_loss: 0.0022 - val_accuracy: 1.0000\n","Epoch 23/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0501 - accuracy: 0.9827 - val_loss: 0.0044 - val_accuracy: 0.9987\n","Epoch 24/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0421 - accuracy: 0.9869 - val_loss: 0.0067 - val_accuracy: 0.9987\n","Epoch 25/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0541 - accuracy: 0.9832 - val_loss: 0.0019 - val_accuracy: 1.0000\n","Epoch 26/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0560 - accuracy: 0.9818 - val_loss: 0.0053 - val_accuracy: 0.9973\n","Epoch 27/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0469 - accuracy: 0.9841 - val_loss: 0.0013 - val_accuracy: 1.0000\n","Epoch 28/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0333 - accuracy: 0.9876 - val_loss: 0.0095 - val_accuracy: 0.9960\n","Epoch 29/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0571 - accuracy: 0.9827 - val_loss: 0.0042 - val_accuracy: 1.0000\n","Epoch 30/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0501 - accuracy: 0.9826 - val_loss: 0.0098 - val_accuracy: 0.9987\n","Results for fold 9\n","Epoch 1/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0583 - accuracy: 0.9829 - val_loss: 0.0015 - val_accuracy: 1.0000\n","Epoch 2/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0615 - accuracy: 0.9812 - val_loss: 4.0974e-04 - val_accuracy: 1.0000\n","Epoch 3/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0546 - accuracy: 0.9803 - val_loss: 0.0028 - val_accuracy: 0.9987\n","Epoch 4/30\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0492 - accuracy: 0.9836 - val_loss: 0.0010 - val_accuracy: 1.0000\n","Epoch 5/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0653 - accuracy: 0.9782 - val_loss: 0.0013 - val_accuracy: 1.0000\n","Epoch 6/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0485 - accuracy: 0.9833 - val_loss: 0.0013 - val_accuracy: 1.0000\n","Epoch 7/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0565 - accuracy: 0.9814 - val_loss: 0.0016 - val_accuracy: 1.0000\n","Epoch 8/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0483 - accuracy: 0.9848 - val_loss: 0.0015 - val_accuracy: 1.0000\n","Epoch 9/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0431 - accuracy: 0.9855 - val_loss: 0.0034 - val_accuracy: 0.9987\n","Epoch 10/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0614 - accuracy: 0.9817 - val_loss: 0.0039 - val_accuracy: 0.9987\n","Epoch 11/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0523 - accuracy: 0.9847 - val_loss: 9.5020e-04 - val_accuracy: 1.0000\n","Epoch 12/30\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0530 - accuracy: 0.9823 - val_loss: 0.0047 - val_accuracy: 0.9973\n","Epoch 13/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0562 - accuracy: 0.9815 - val_loss: 0.0049 - val_accuracy: 0.9987\n","Epoch 14/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0504 - accuracy: 0.9850 - val_loss: 0.0032 - val_accuracy: 1.0000\n","Epoch 15/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0513 - accuracy: 0.9847 - val_loss: 0.0084 - val_accuracy: 0.9960\n","Epoch 16/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0627 - accuracy: 0.9814 - val_loss: 0.0020 - val_accuracy: 1.0000\n","Epoch 17/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0508 - accuracy: 0.9826 - val_loss: 6.9995e-04 - val_accuracy: 1.0000\n","Epoch 18/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0352 - accuracy: 0.9894 - val_loss: 3.1959e-04 - val_accuracy: 1.0000\n","Epoch 19/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0465 - accuracy: 0.9866 - val_loss: 0.0045 - val_accuracy: 0.9987\n","Epoch 20/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0517 - accuracy: 0.9839 - val_loss: 0.0022 - val_accuracy: 0.9987\n","Epoch 21/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0580 - accuracy: 0.9812 - val_loss: 0.0045 - val_accuracy: 0.9987\n","Epoch 22/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0554 - accuracy: 0.9817 - val_loss: 0.0049 - val_accuracy: 0.9987\n","Epoch 23/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0442 - accuracy: 0.9851 - val_loss: 0.0018 - val_accuracy: 1.0000\n","Epoch 24/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0433 - accuracy: 0.9855 - val_loss: 0.0021 - val_accuracy: 1.0000\n","Epoch 25/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0383 - accuracy: 0.9890 - val_loss: 6.5469e-04 - val_accuracy: 1.0000\n","Epoch 26/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0438 - accuracy: 0.9879 - val_loss: 0.0025 - val_accuracy: 0.9987\n","Epoch 27/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0440 - accuracy: 0.9864 - val_loss: 0.0034 - val_accuracy: 0.9973\n","Epoch 28/30\n","53/53 [==============================] - 4s 72ms/step - loss: 0.0425 - accuracy: 0.9855 - val_loss: 0.0297 - val_accuracy: 0.9960\n","Epoch 29/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0464 - accuracy: 0.9848 - val_loss: 0.0069 - val_accuracy: 0.9973\n","Epoch 30/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0481 - accuracy: 0.9838 - val_loss: 0.0020 - val_accuracy: 1.0000\n","Results for fold 10\n","Epoch 1/30\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0574 - accuracy: 0.9817 - val_loss: 0.0016 - val_accuracy: 1.0000\n","Epoch 2/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0436 - accuracy: 0.9850 - val_loss: 4.1872e-04 - val_accuracy: 1.0000\n","Epoch 3/30\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0430 - accuracy: 0.9869 - val_loss: 4.4781e-04 - val_accuracy: 1.0000\n","Epoch 4/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0588 - accuracy: 0.9832 - val_loss: 0.0073 - val_accuracy: 0.9973\n","Epoch 5/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0539 - accuracy: 0.9830 - val_loss: 5.6798e-04 - val_accuracy: 1.0000\n","Epoch 6/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0403 - accuracy: 0.9873 - val_loss: 5.8236e-04 - val_accuracy: 1.0000\n","Epoch 7/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0564 - accuracy: 0.9832 - val_loss: 0.0011 - val_accuracy: 1.0000\n","Epoch 8/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0434 - accuracy: 0.9864 - val_loss: 0.0024 - val_accuracy: 0.9987\n","Epoch 9/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0478 - accuracy: 0.9857 - val_loss: 7.4269e-04 - val_accuracy: 1.0000\n","Epoch 10/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0444 - accuracy: 0.9864 - val_loss: 0.0023 - val_accuracy: 1.0000\n","Epoch 11/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0587 - accuracy: 0.9820 - val_loss: 0.0010 - val_accuracy: 1.0000\n","Epoch 12/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0466 - accuracy: 0.9829 - val_loss: 4.5461e-04 - val_accuracy: 1.0000\n","Epoch 13/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0496 - accuracy: 0.9842 - val_loss: 0.0014 - val_accuracy: 1.0000\n","Epoch 14/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0333 - accuracy: 0.9890 - val_loss: 4.8664e-04 - val_accuracy: 1.0000\n","Epoch 15/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0352 - accuracy: 0.9876 - val_loss: 0.0011 - val_accuracy: 1.0000\n","Epoch 16/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0513 - accuracy: 0.9835 - val_loss: 0.0024 - val_accuracy: 1.0000\n","Epoch 17/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0410 - accuracy: 0.9875 - val_loss: 0.0058 - val_accuracy: 0.9973\n","Epoch 18/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0441 - accuracy: 0.9878 - val_loss: 7.3001e-04 - val_accuracy: 1.0000\n","Epoch 19/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0322 - accuracy: 0.9900 - val_loss: 4.8503e-04 - val_accuracy: 1.0000\n","Epoch 20/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0417 - accuracy: 0.9881 - val_loss: 0.0032 - val_accuracy: 0.9987\n","Epoch 21/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0339 - accuracy: 0.9887 - val_loss: 4.8143e-04 - val_accuracy: 1.0000\n","Epoch 22/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0420 - accuracy: 0.9881 - val_loss: 8.4191e-04 - val_accuracy: 1.0000\n","Epoch 23/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0448 - accuracy: 0.9860 - val_loss: 0.0027 - val_accuracy: 0.9987\n","Epoch 24/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0376 - accuracy: 0.9900 - val_loss: 0.0017 - val_accuracy: 0.9987\n","Epoch 25/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0556 - accuracy: 0.9824 - val_loss: 0.0016 - val_accuracy: 1.0000\n","Epoch 26/30\n","53/53 [==============================] - 4s 73ms/step - loss: 0.0520 - accuracy: 0.9838 - val_loss: 0.0024 - val_accuracy: 0.9987\n","Epoch 27/30\n","53/53 [==============================] - 4s 75ms/step - loss: 0.0428 - accuracy: 0.9855 - val_loss: 0.0057 - val_accuracy: 0.9973\n","Epoch 28/30\n","53/53 [==============================] - 4s 77ms/step - loss: 0.0457 - accuracy: 0.9845 - val_loss: 0.0010 - val_accuracy: 1.0000\n","Epoch 29/30\n","53/53 [==============================] - 4s 76ms/step - loss: 0.0295 - accuracy: 0.9903 - val_loss: 9.3418e-04 - val_accuracy: 1.0000\n","Epoch 30/30\n","53/53 [==============================] - 4s 74ms/step - loss: 0.0355 - accuracy: 0.9887 - val_loss: 0.0016 - val_accuracy: 1.0000\n"]}]},{"cell_type":"code","metadata":{"id":"Lr-SH0e6flrE","colab":{"base_uri":"https://localhost:8080/","height":723},"executionInfo":{"status":"ok","timestamp":1633079501009,"user_tz":-360,"elapsed":1675,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"6494ab6e-e305-48f3-b7a3-29c8bc425acd"},"source":["acrc = model.evaluate(x_test, y_test)\n","pred = model.predict(x_test)\n","f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n","c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n","print(\"Accuracy  : {}\".format(acrc[1]))\n","print(\"F1_Score  : {}\".format(f1scr))\n","c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n","import seaborn as sns\n","figure = plt.figure(figsize=(9, 9))\n","sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n","plt.tight_layout()\n","plt.ylabel('True label')\n","plt.xlabel('Predicted label')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["59/59 [==============================] - 1s 10ms/step - loss: 0.2935 - accuracy: 0.9249\n","Accuracy  : 0.9248927235603333\n","F1_Score  : 0.910079342209381\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 648x648 with 2 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"lJehdYs6ZBcD"},"source":["# **Dominance**"]},{"cell_type":"code","metadata":{"id":"MqwJWlxMZEe6","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1633079501010,"user_tz":-360,"elapsed":18,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"29ead12e-3062-4094-d8e8-963635752cbc"},"source":["'''#dominance\n","X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n","print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'#dominance\\nX_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\\nprint(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"UljSiW-xZMC_","colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"status":"ok","timestamp":1633079501588,"user_tz":-360,"elapsed":594,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"79ebe04f-bd23-4729-e849-7f4d59eb50db"},"source":["'''foldNum=0\n","model = get_model()\n","for train_index, val_index in kfold.split(X_train, Y_train):\n","  foldNum = foldNum + 1\n","  print(\"Results for fold\",foldNum)\n","  x_train, x_val = X_train[train_index], X_train[val_index]\n","  y_train, y_val = Y_train[train_index], Y_train[val_index]\n","  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n","  gc.collect() # Garbage collecter\n","  del x_train, x_val, y_train, y_val\n","  gc.collect()'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'foldNum=0\\nmodel = get_model()\\nfor train_index, val_index in kfold.split(X_train, Y_train):\\n  foldNum = foldNum + 1\\n  print(\"Results for fold\",foldNum)\\n  x_train, x_val = X_train[train_index], X_train[val_index]\\n  y_train, y_val = Y_train[train_index], Y_train[val_index]\\n  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\\n  gc.collect() # Garbage collecter\\n  del x_train, x_val, y_train, y_val\\n  gc.collect()'"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"9_olzDVBZS7u","colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"status":"ok","timestamp":1633079501590,"user_tz":-360,"elapsed":15,"user":{"displayName":"Md. Sultan Mahmud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gju89IzFjYiP4fZ3sUWAkIsdLbpCuHq_qWSPhXU=s64","userId":"08891987988249300794"}},"outputId":"efc266ed-160e-4fe8-c3d2-50dee4f720ec"},"source":["'''acrc = model.evaluate(x_test, y_test)\n","pred = model.predict(x_test)\n","f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n","c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n","print(\"Accuracy  : {}\".format(acrc[1]))\n","print(\"F1_Score  : {}\".format(f1scr))\n","c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n","import seaborn as sns\n","figure = plt.figure(figsize=(9, 9))\n","sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n","plt.tight_layout()\n","plt.ylabel('True label')\n","plt.xlabel('Predicted label')\n","plt.show()'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'acrc = model.evaluate(x_test, y_test)\\npred = model.predict(x_test)\\nf1scr = f1_score(y_test.argmax(1), pred.argmax(1), average=\\'macro\\')\\nc_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\\nprint(\"Accuracy  : {}\".format(acrc[1]))\\nprint(\"F1_Score  : {}\".format(f1scr))\\nc_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\\nimport seaborn as sns\\nfigure = plt.figure(figsize=(9, 9))\\nsns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\\nplt.tight_layout()\\nplt.ylabel(\\'True label\\')\\nplt.xlabel(\\'Predicted label\\')\\nplt.show()'"]},"metadata":{},"execution_count":19}]}]}