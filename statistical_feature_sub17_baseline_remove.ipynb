{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"statistical_feature_sub17_baseline_remove.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"mJl4myg42Jt-"},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from scipy.signal import butter, lfilter, freqz, filtfilt\n","from pywt import swt, cwt\n","import scipy.misc\n","from scipy.signal import welch\n","import tensorflow as tf\n","import keras\n","from tensorflow import keras\n","import tensorflow.keras.backend as K\n","from keras.models import Sequential,Model\n","from keras.models import Sequential \n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n","from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n","from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n","from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n","#from keras.optimizers import Adam\n","from keras.utils import np_utils\n","from sklearn.preprocessing import StandardScaler                                                      \n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import confusion_matrix \n","from scipy import signal\n","import pickle as pkl\n","from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n","from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n","import gc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ns3s5JN97fU","outputId":"51c45f6d-868f-424f-febc-e27706f9b3c1","executionInfo":{"status":"ok","timestamp":1651809652221,"user_tz":-360,"elapsed":70650,"user":{"displayName":"Md. Sultan Mahmud","userId":"06779944893886852404"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","gc.collect()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]},{"output_type":"execute_result","data":{"text/plain":["125"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"ugvNZGZX-DO7"},"source":["input_path='/content/drive/MyDrive/data_preprocessed_python/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def baseline_remove(XR):\n","  XT = XR[:, 384:]\n","  XB_ = (XR[:, :1*128] + XR[:, 1*128:2*128] + XR[:, 2*128:3*128])/3.0\n","  for i in range(60):\n","    XT[:, i*128:(i+1)*128] = XT[:, i*128:(i+1)*128] - XB_\n","  return XT\n"],"metadata":{"id":"MQuu-DcDI2A6"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cPXrZrst909d"},"source":["#channel = np.array([1,3,7,8,21,22,25,26,27,30])\n","scale = len(np.arange(11, 31))\n","sampling_rate = 128\n","window_size = 256\n","skip =16\n","#channel_len = len(channel)\n","classes=2\n","order = 6\n","fs = 128      # sample rate, Hz\n","cutoff = 60  # desired cutoff frequency of the filter, Hz\n","waveletname = 'db4'\n","bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n","         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n","         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EotvnIan4d84","outputId":"e3939af5-8c1b-4935-f22f-0d95d2a7e007","executionInfo":{"status":"ok","timestamp":1651809833972,"user_tz":-360,"elapsed":1134,"user":{"displayName":"Md. Sultan Mahmud","userId":"06779944893886852404"}}},"source":["eeg_signal = []\n","valence = []\n","arousal = []\n","window_size = 256\n","skip = 256\n","\n","for person in range(17,18):\n","  print('Person No.' + str(person))\n","  \n","  \n","  # EEG files address\n","  if person < 10 :\n","    address = input_path+'s0'+str(person)+'.dat'\n","  else :\n","    address = input_path+'s'+str(person)+'.dat'\n","\n","  with open(address, 'rb') as file:\n","    data = pkl.load(file, encoding = 'latin1')\n","\n","  eeg = data['data']\n","  label = data['labels']\n","  \n","  # Assigning classes\n","  label[label<5] = 0\n","  label[label>=5] = 1\n","\n","  val = label.T[0] # Valence label\n","  aro = label.T[1] # Arousal label\n","\n","  del data, label\n","  # Iterating through 40 vidoes/trials\n","  for i in range(40):\n","    sig = eeg[i][:32, :]\n","    sig = baseline_remove(sig)\n","    # Segmenting into 3 seconds (384 timesteps) windows without overlap\n","    start = 0\n","    while start + window_size <=sig.shape[1]:\n","      eeg_signal.append(sig[:, start:start+window_size])\n","      valence.append(val[i])\n","      arousal.append(aro[i])\n","      start += skip \n","  del eeg, val, aro, sig\n","eeg_signal = np.reshape(eeg_signal,[-1,32,256,1])\n","data = np.asarray(eeg_signal, dtype = np.float32) # Using 32 bit floating point value to save memory\n","del eeg_signal\n","valence = np.asarray(valence, dtype = np.int8)\n","arousal = np.asarray(arousal, dtype = np.int8)\n","\n","print(data.shape)\n","print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape)\n","print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape)\n","\n","valence = np_utils.to_categorical(valence)\n","arousal = np_utils.to_categorical(arousal)\n","gc.collect()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Person No.17\n","(1200, 32, 256, 1)\n","(1200,) (540,) (660,)\n","(1200,) (450,) (750,)\n"]},{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["new_channels = [0,1,18,2,3,5,4,23,6,7,9,8,15,10,11,12,14,13,\n"," 16,17,18,19,20,22,21,23,24,25,27,26,15,28,29,30,14,31]"],"metadata":{"id":"3MagSfOCk2ib"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["eeg_signal = []\n","valence = []\n","arousal = []\n","window_size = 256\n","no_channels = 32\n","no_new_channels = len(new_channels)\n","no_videos = 40\n","Trsld = 5\n","\n","for person in range(17,18):\n","  print('Person No.' + str(person))\n","  \n","  \n","  # EEG files address\n","  if person < 10 :\n","    address = input_path+'s0'+str(person)+'.dat'\n","  else :\n","    address = input_path+'s'+str(person)+'.dat'\n","\n","  with open(address, 'rb') as file:\n","    data = pkl.load(file, encoding = 'latin1')\n","\n","  eeg = data['data']\n","  label = data['labels']\n","  \n","  # Assigning classes\n","  label[label<Trsld] = 0\n","  label[label>=Trsld] = 1\n","\n","  val = label.T[0] # Valence label\n","  aro = label.T[1] # Arousal label\n","\n","  del data, label\n","  # Iterating through 40 vidoes/trials\n","  for i in range(no_videos):\n","    sig = eeg[i][:no_channels, :]\n","    sig = baseline_remove(sig)\n","    temp = []\n","    for j in new_channels:\n","      temp.append(sig[j, :])\n","    sig = np.reshape(temp,[no_new_channels,-1])\n","    # Segmenting into 2 seconds (256 timesteps) windows without overlap\n","    start = 0\n","    while start + window_size <=sig.shape[1]:\n","      eeg_signal.append(sig[:, start:start+window_size])\n","      valence.append(val[i])\n","      arousal.append(aro[i])\n","      start += window_size \n","  del eeg, val, aro, sig\n","eeg_signal = np.reshape(eeg_signal,[-1,no_new_channels,window_size])\n","data = np.asarray(eeg_signal, dtype = np.float32) # Using 32 bit floating point value to save memory\n","del eeg_signal\n","valence = np.asarray(valence, dtype = np.int8)\n","arousal = np.asarray(arousal, dtype = np.int8)\n","\n","print(data.shape)\n","print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape)\n","print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape)\n","\n","valence = np_utils.to_categorical(valence)\n","arousal = np_utils.to_categorical(arousal)\n","gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZTBWmgp3kxB8","executionInfo":{"status":"ok","timestamp":1651810497657,"user_tz":-360,"elapsed":982,"user":{"displayName":"Md. Sultan Mahmud","userId":"06779944893886852404"}},"outputId":"f19331f8-ed72-4750-cc8b-d1c8a7fc12e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Person No.17\n","(1200, 36, 256)\n","(1200,) (540,) (660,)\n","(1200,) (450,) (750,)\n"]},{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["import statistics\n","from scipy import stats\n","from statistics import variance\n"," \n","feature =[]\n","f_feat = []\n","for k in range(data.shape[0]):\n","  for l in range(data.shape[1]):\n","    feature.append(np.mean(data[k,l,:]))\n","    feature.append(np.median(data[k,l,:]))\n","    feature.append(np.var((data[k,l,:])))\n","    val,counts = np.unique(data[k,l,:], return_counts=True)\n","    index = np.argmax(counts)\n","    feature.append(val[index])\n","    feature.append(np.max(data[k,l,:]))\n","    feature.append(np.min(data[k,l,:]))"],"metadata":{"id":"mOA507h8xERd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["feature = np.array(feature)\n","print(feature.shape)\n","f_feat = np.reshape(feature,[-1,data.shape[1],6])\n","print(feature)\n"," \n"," "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RiO8MDmO9-X3","outputId":"3bd76682-72d8-4fa4-de1f-bdf6f6a15038","executionInfo":{"status":"ok","timestamp":1651810821535,"user_tz":-360,"elapsed":476,"user":{"displayName":"Md. Sultan Mahmud","userId":"06779944893886852404"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(259200,)\n","[-1.6212761e-03  2.6990426e-01  1.2560635e+02 ... -1.0158933e+02\n","  6.2379257e+01 -1.0158933e+02]\n"]}]},{"cell_type":"code","source":["f_feat.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pOuOTnyTmEBc","executionInfo":{"status":"ok","timestamp":1651810825310,"user_tz":-360,"elapsed":518,"user":{"displayName":"Md. Sultan Mahmud","userId":"06779944893886852404"}},"outputId":"3fb7325f-fa6e-4892-9077-f4ff82fadf3b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1200, 36, 6)"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"-VMwwMiur8kW"},"source":["# **Proposed Architecture**"]},{"cell_type":"code","source":["def individual_1D_CNN(x):\n","  x = Reshape((x.shape[1],1))(x)\n","  x1 = Conv1D(filters = 32, kernel_size = 2, strides = 2, padding = 'same', activation='selu')(x)\n","  x1 = Conv1D(filters = 32, kernel_size = 3, strides = 3, padding = 'same', activation='selu')(x1)\n","  x1 = Conv1D(filters = 32, kernel_size = 3, strides = 3, padding = 'same', activation='selu')(x1)\n","  x2 = Conv1D(filters = 32, kernel_size = 3, strides = 3, padding = 'same', activation='selu')(x)\n","  x2 = Conv1D(filters = 32, kernel_size = 2, strides = 2, padding = 'same', activation='selu')(x2)\n","  x2 = Conv1D(filters = 32, kernel_size = 3, strides = 3, padding = 'same', activation='selu')(x2)\n","  x3 = Conv1D(filters = 32, kernel_size = 6, strides = 6, padding = 'same', activation='selu')(x)\n","  x3 = Conv1D(filters = 32, kernel_size = 3, strides = 3, padding = 'same', activation='selu')(x3)\n","  x4 = Conv1D(filters = 32, kernel_size = 9, strides = 9, padding = 'same', activation='selu')(x)\n","  x4 = Conv1D(filters = 32, kernel_size = 2, strides = 2, padding = 'same', activation='selu')(x4)\n","  x5 = Conv1D(filters = 32, kernel_size = 18, strides = 18, padding = 'same', activation='selu')(x)\n","  x = Concatenate(axis=2)([x1, x2, x3, x4, x5])\n","  x = Dropout(0.1)(x)\n","  x = Conv1D(filters = x.shape[2], kernel_size = 2, strides = 2, padding = 'same', activation='selu')(x)\n","  x = Dropout(0.1)(x)\n","  x = Flatten()(x)\n","  x = Dense(128, activation='tanh')(x)\n","  x = Dropout(0.1)(x)\n","  x = Dense(32, activation='relu')(x)\n","  x = Reshape((x.shape[1],1))(x)\n","  return x\n","def simple_1D_CNN(x): \n","  x1 = individual_1D_CNN(x[:,:,0])\n","  x2 = individual_1D_CNN(x[:,:,1])\n","  x3 = individual_1D_CNN(x[:,:,2])\n","  x4 = individual_1D_CNN(x[:,:,3])\n","  x5 = individual_1D_CNN(x[:,:,4])\n","  x6 = individual_1D_CNN(x[:,:,5])\n","  x = Concatenate(axis=2)([x1, x2, x3, x4, x5, x6])\n","  x = Conv1D(filters = 32, kernel_size = 4, strides = 4, padding = 'same', activation='selu')(x)\n","  x = Flatten()(x)\n","  x = Dense(128, activation='tanh')(x)\n","  x = Dropout(0.1)(x)\n","  x = Dense(32, activation='relu')(x)\n","  x = Dense(2, activation='softmax')(x)\n","  return x\n","\n","def get_model(): \n","  input_shape = (f_feat.shape[1], f_feat.shape[2]) \n","  a = Input(input_shape) \n","  out = simple_1D_CNN(a) \n","  model = Model(a, out) \n","  opt = keras.optimizers.Adam(learning_rate=1e-05) \n","  model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt) \n","  return model \n","model = get_model() \n","model.summary() "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2iZxtyyXkQRW","executionInfo":{"status":"ok","timestamp":1651812148725,"user_tz":-360,"elapsed":3445,"user":{"displayName":"Md. Sultan Mahmud","userId":"06779944893886852404"}},"outputId":"11a3a917-ae94-4a34-9e4f-c3ded704e733"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_12\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_16 (InputLayer)          [(None, 36, 6)]      0           []                               \n","                                                                                                  \n"," tf.__operators__.getitem_56 (S  (None, 36)          0           ['input_16[0][0]']               \n"," licingOpLambda)                                                                                  \n","                                                                                                  \n"," tf.__operators__.getitem_57 (S  (None, 36)          0           ['input_16[0][0]']               \n"," licingOpLambda)                                                                                  \n","                                                                                                  \n"," tf.__operators__.getitem_58 (S  (None, 36)          0           ['input_16[0][0]']               \n"," licingOpLambda)                                                                                  \n","                                                                                                  \n"," tf.__operators__.getitem_59 (S  (None, 36)          0           ['input_16[0][0]']               \n"," licingOpLambda)                                                                                  \n","                                                                                                  \n"," tf.__operators__.getitem_60 (S  (None, 36)          0           ['input_16[0][0]']               \n"," licingOpLambda)                                                                                  \n","                                                                                                  \n"," tf.__operators__.getitem_61 (S  (None, 36)          0           ['input_16[0][0]']               \n"," licingOpLambda)                                                                                  \n","                                                                                                  \n"," reshape_78 (Reshape)           (None, 36, 1)        0           ['tf.__operators__.getitem_56[0][\n","                                                                 0]']                             \n","                                                                                                  \n"," reshape_80 (Reshape)           (None, 36, 1)        0           ['tf.__operators__.getitem_57[0][\n","                                                                 0]']                             \n","                                                                                                  \n"," reshape_82 (Reshape)           (None, 36, 1)        0           ['tf.__operators__.getitem_58[0][\n","                                                                 0]']                             \n","                                                                                                  \n"," reshape_84 (Reshape)           (None, 36, 1)        0           ['tf.__operators__.getitem_59[0][\n","                                                                 0]']                             \n","                                                                                                  \n"," reshape_86 (Reshape)           (None, 36, 1)        0           ['tf.__operators__.getitem_60[0][\n","                                                                 0]']                             \n","                                                                                                  \n"," reshape_88 (Reshape)           (None, 36, 1)        0           ['tf.__operators__.getitem_61[0][\n","                                                                 0]']                             \n","                                                                                                  \n"," conv1d_701 (Conv1D)            (None, 18, 32)       96          ['reshape_78[0][0]']             \n","                                                                                                  \n"," conv1d_704 (Conv1D)            (None, 12, 32)       128         ['reshape_78[0][0]']             \n","                                                                                                  \n"," conv1d_713 (Conv1D)            (None, 18, 32)       96          ['reshape_80[0][0]']             \n","                                                                                                  \n"," conv1d_716 (Conv1D)            (None, 12, 32)       128         ['reshape_80[0][0]']             \n","                                                                                                  \n"," conv1d_725 (Conv1D)            (None, 18, 32)       96          ['reshape_82[0][0]']             \n","                                                                                                  \n"," conv1d_728 (Conv1D)            (None, 12, 32)       128         ['reshape_82[0][0]']             \n","                                                                                                  \n"," conv1d_737 (Conv1D)            (None, 18, 32)       96          ['reshape_84[0][0]']             \n","                                                                                                  \n"," conv1d_740 (Conv1D)            (None, 12, 32)       128         ['reshape_84[0][0]']             \n","                                                                                                  \n"," conv1d_749 (Conv1D)            (None, 18, 32)       96          ['reshape_86[0][0]']             \n","                                                                                                  \n"," conv1d_752 (Conv1D)            (None, 12, 32)       128         ['reshape_86[0][0]']             \n","                                                                                                  \n"," conv1d_761 (Conv1D)            (None, 18, 32)       96          ['reshape_88[0][0]']             \n","                                                                                                  \n"," conv1d_764 (Conv1D)            (None, 12, 32)       128         ['reshape_88[0][0]']             \n","                                                                                                  \n"," conv1d_702 (Conv1D)            (None, 6, 32)        3104        ['conv1d_701[0][0]']             \n","                                                                                                  \n"," conv1d_705 (Conv1D)            (None, 6, 32)        2080        ['conv1d_704[0][0]']             \n","                                                                                                  \n"," conv1d_707 (Conv1D)            (None, 6, 32)        224         ['reshape_78[0][0]']             \n","                                                                                                  \n"," conv1d_709 (Conv1D)            (None, 4, 32)        320         ['reshape_78[0][0]']             \n","                                                                                                  \n"," conv1d_714 (Conv1D)            (None, 6, 32)        3104        ['conv1d_713[0][0]']             \n","                                                                                                  \n"," conv1d_717 (Conv1D)            (None, 6, 32)        2080        ['conv1d_716[0][0]']             \n","                                                                                                  \n"," conv1d_719 (Conv1D)            (None, 6, 32)        224         ['reshape_80[0][0]']             \n","                                                                                                  \n"," conv1d_721 (Conv1D)            (None, 4, 32)        320         ['reshape_80[0][0]']             \n","                                                                                                  \n"," conv1d_726 (Conv1D)            (None, 6, 32)        3104        ['conv1d_725[0][0]']             \n","                                                                                                  \n"," conv1d_729 (Conv1D)            (None, 6, 32)        2080        ['conv1d_728[0][0]']             \n","                                                                                                  \n"," conv1d_731 (Conv1D)            (None, 6, 32)        224         ['reshape_82[0][0]']             \n","                                                                                                  \n"," conv1d_733 (Conv1D)            (None, 4, 32)        320         ['reshape_82[0][0]']             \n","                                                                                                  \n"," conv1d_738 (Conv1D)            (None, 6, 32)        3104        ['conv1d_737[0][0]']             \n","                                                                                                  \n"," conv1d_741 (Conv1D)            (None, 6, 32)        2080        ['conv1d_740[0][0]']             \n","                                                                                                  \n"," conv1d_743 (Conv1D)            (None, 6, 32)        224         ['reshape_84[0][0]']             \n","                                                                                                  \n"," conv1d_745 (Conv1D)            (None, 4, 32)        320         ['reshape_84[0][0]']             \n","                                                                                                  \n"," conv1d_750 (Conv1D)            (None, 6, 32)        3104        ['conv1d_749[0][0]']             \n","                                                                                                  \n"," conv1d_753 (Conv1D)            (None, 6, 32)        2080        ['conv1d_752[0][0]']             \n","                                                                                                  \n"," conv1d_755 (Conv1D)            (None, 6, 32)        224         ['reshape_86[0][0]']             \n","                                                                                                  \n"," conv1d_757 (Conv1D)            (None, 4, 32)        320         ['reshape_86[0][0]']             \n","                                                                                                  \n"," conv1d_762 (Conv1D)            (None, 6, 32)        3104        ['conv1d_761[0][0]']             \n","                                                                                                  \n"," conv1d_765 (Conv1D)            (None, 6, 32)        2080        ['conv1d_764[0][0]']             \n","                                                                                                  \n"," conv1d_767 (Conv1D)            (None, 6, 32)        224         ['reshape_88[0][0]']             \n","                                                                                                  \n"," conv1d_769 (Conv1D)            (None, 4, 32)        320         ['reshape_88[0][0]']             \n","                                                                                                  \n"," conv1d_703 (Conv1D)            (None, 2, 32)        3104        ['conv1d_702[0][0]']             \n","                                                                                                  \n"," conv1d_706 (Conv1D)            (None, 2, 32)        3104        ['conv1d_705[0][0]']             \n","                                                                                                  \n"," conv1d_708 (Conv1D)            (None, 2, 32)        3104        ['conv1d_707[0][0]']             \n","                                                                                                  \n"," conv1d_710 (Conv1D)            (None, 2, 32)        2080        ['conv1d_709[0][0]']             \n","                                                                                                  \n"," conv1d_711 (Conv1D)            (None, 2, 32)        608         ['reshape_78[0][0]']             \n","                                                                                                  \n"," conv1d_715 (Conv1D)            (None, 2, 32)        3104        ['conv1d_714[0][0]']             \n","                                                                                                  \n"," conv1d_718 (Conv1D)            (None, 2, 32)        3104        ['conv1d_717[0][0]']             \n","                                                                                                  \n"," conv1d_720 (Conv1D)            (None, 2, 32)        3104        ['conv1d_719[0][0]']             \n","                                                                                                  \n"," conv1d_722 (Conv1D)            (None, 2, 32)        2080        ['conv1d_721[0][0]']             \n","                                                                                                  \n"," conv1d_723 (Conv1D)            (None, 2, 32)        608         ['reshape_80[0][0]']             \n","                                                                                                  \n"," conv1d_727 (Conv1D)            (None, 2, 32)        3104        ['conv1d_726[0][0]']             \n","                                                                                                  \n"," conv1d_730 (Conv1D)            (None, 2, 32)        3104        ['conv1d_729[0][0]']             \n","                                                                                                  \n"," conv1d_732 (Conv1D)            (None, 2, 32)        3104        ['conv1d_731[0][0]']             \n","                                                                                                  \n"," conv1d_734 (Conv1D)            (None, 2, 32)        2080        ['conv1d_733[0][0]']             \n","                                                                                                  \n"," conv1d_735 (Conv1D)            (None, 2, 32)        608         ['reshape_82[0][0]']             \n","                                                                                                  \n"," conv1d_739 (Conv1D)            (None, 2, 32)        3104        ['conv1d_738[0][0]']             \n","                                                                                                  \n"," conv1d_742 (Conv1D)            (None, 2, 32)        3104        ['conv1d_741[0][0]']             \n","                                                                                                  \n"," conv1d_744 (Conv1D)            (None, 2, 32)        3104        ['conv1d_743[0][0]']             \n","                                                                                                  \n"," conv1d_746 (Conv1D)            (None, 2, 32)        2080        ['conv1d_745[0][0]']             \n","                                                                                                  \n"," conv1d_747 (Conv1D)            (None, 2, 32)        608         ['reshape_84[0][0]']             \n","                                                                                                  \n"," conv1d_751 (Conv1D)            (None, 2, 32)        3104        ['conv1d_750[0][0]']             \n","                                                                                                  \n"," conv1d_754 (Conv1D)            (None, 2, 32)        3104        ['conv1d_753[0][0]']             \n","                                                                                                  \n"," conv1d_756 (Conv1D)            (None, 2, 32)        3104        ['conv1d_755[0][0]']             \n","                                                                                                  \n"," conv1d_758 (Conv1D)            (None, 2, 32)        2080        ['conv1d_757[0][0]']             \n","                                                                                                  \n"," conv1d_759 (Conv1D)            (None, 2, 32)        608         ['reshape_86[0][0]']             \n","                                                                                                  \n"," conv1d_763 (Conv1D)            (None, 2, 32)        3104        ['conv1d_762[0][0]']             \n","                                                                                                  \n"," conv1d_766 (Conv1D)            (None, 2, 32)        3104        ['conv1d_765[0][0]']             \n","                                                                                                  \n"," conv1d_768 (Conv1D)            (None, 2, 32)        3104        ['conv1d_767[0][0]']             \n","                                                                                                  \n"," conv1d_770 (Conv1D)            (None, 2, 32)        2080        ['conv1d_769[0][0]']             \n","                                                                                                  \n"," conv1d_771 (Conv1D)            (None, 2, 32)        608         ['reshape_88[0][0]']             \n","                                                                                                  \n"," concatenate_67 (Concatenate)   (None, 2, 160)       0           ['conv1d_703[0][0]',             \n","                                                                  'conv1d_706[0][0]',             \n","                                                                  'conv1d_708[0][0]',             \n","                                                                  'conv1d_710[0][0]',             \n","                                                                  'conv1d_711[0][0]']             \n","                                                                                                  \n"," concatenate_68 (Concatenate)   (None, 2, 160)       0           ['conv1d_715[0][0]',             \n","                                                                  'conv1d_718[0][0]',             \n","                                                                  'conv1d_720[0][0]',             \n","                                                                  'conv1d_722[0][0]',             \n","                                                                  'conv1d_723[0][0]']             \n","                                                                                                  \n"," concatenate_69 (Concatenate)   (None, 2, 160)       0           ['conv1d_727[0][0]',             \n","                                                                  'conv1d_730[0][0]',             \n","                                                                  'conv1d_732[0][0]',             \n","                                                                  'conv1d_734[0][0]',             \n","                                                                  'conv1d_735[0][0]']             \n","                                                                                                  \n"," concatenate_70 (Concatenate)   (None, 2, 160)       0           ['conv1d_739[0][0]',             \n","                                                                  'conv1d_742[0][0]',             \n","                                                                  'conv1d_744[0][0]',             \n","                                                                  'conv1d_746[0][0]',             \n","                                                                  'conv1d_747[0][0]']             \n","                                                                                                  \n"," concatenate_71 (Concatenate)   (None, 2, 160)       0           ['conv1d_751[0][0]',             \n","                                                                  'conv1d_754[0][0]',             \n","                                                                  'conv1d_756[0][0]',             \n","                                                                  'conv1d_758[0][0]',             \n","                                                                  'conv1d_759[0][0]']             \n","                                                                                                  \n"," concatenate_72 (Concatenate)   (None, 2, 160)       0           ['conv1d_763[0][0]',             \n","                                                                  'conv1d_766[0][0]',             \n","                                                                  'conv1d_768[0][0]',             \n","                                                                  'conv1d_770[0][0]',             \n","                                                                  'conv1d_771[0][0]']             \n","                                                                                                  \n"," dropout_177 (Dropout)          (None, 2, 160)       0           ['concatenate_67[0][0]']         \n","                                                                                                  \n"," dropout_180 (Dropout)          (None, 2, 160)       0           ['concatenate_68[0][0]']         \n","                                                                                                  \n"," dropout_183 (Dropout)          (None, 2, 160)       0           ['concatenate_69[0][0]']         \n","                                                                                                  \n"," dropout_186 (Dropout)          (None, 2, 160)       0           ['concatenate_70[0][0]']         \n","                                                                                                  \n"," dropout_189 (Dropout)          (None, 2, 160)       0           ['concatenate_71[0][0]']         \n","                                                                                                  \n"," dropout_192 (Dropout)          (None, 2, 160)       0           ['concatenate_72[0][0]']         \n","                                                                                                  \n"," conv1d_712 (Conv1D)            (None, 1, 160)       51360       ['dropout_177[0][0]']            \n","                                                                                                  \n"," conv1d_724 (Conv1D)            (None, 1, 160)       51360       ['dropout_180[0][0]']            \n","                                                                                                  \n"," conv1d_736 (Conv1D)            (None, 1, 160)       51360       ['dropout_183[0][0]']            \n","                                                                                                  \n"," conv1d_748 (Conv1D)            (None, 1, 160)       51360       ['dropout_186[0][0]']            \n","                                                                                                  \n"," conv1d_760 (Conv1D)            (None, 1, 160)       51360       ['dropout_189[0][0]']            \n","                                                                                                  \n"," conv1d_772 (Conv1D)            (None, 1, 160)       51360       ['dropout_192[0][0]']            \n","                                                                                                  \n"," dropout_178 (Dropout)          (None, 1, 160)       0           ['conv1d_712[0][0]']             \n","                                                                                                  \n"," dropout_181 (Dropout)          (None, 1, 160)       0           ['conv1d_724[0][0]']             \n","                                                                                                  \n"," dropout_184 (Dropout)          (None, 1, 160)       0           ['conv1d_736[0][0]']             \n","                                                                                                  \n"," dropout_187 (Dropout)          (None, 1, 160)       0           ['conv1d_748[0][0]']             \n","                                                                                                  \n"," dropout_190 (Dropout)          (None, 1, 160)       0           ['conv1d_760[0][0]']             \n","                                                                                                  \n"," dropout_193 (Dropout)          (None, 1, 160)       0           ['conv1d_772[0][0]']             \n","                                                                                                  \n"," flatten_59 (Flatten)           (None, 160)          0           ['dropout_178[0][0]']            \n","                                                                                                  \n"," flatten_60 (Flatten)           (None, 160)          0           ['dropout_181[0][0]']            \n","                                                                                                  \n"," flatten_61 (Flatten)           (None, 160)          0           ['dropout_184[0][0]']            \n","                                                                                                  \n"," flatten_62 (Flatten)           (None, 160)          0           ['dropout_187[0][0]']            \n","                                                                                                  \n"," flatten_63 (Flatten)           (None, 160)          0           ['dropout_190[0][0]']            \n","                                                                                                  \n"," flatten_64 (Flatten)           (None, 160)          0           ['dropout_193[0][0]']            \n","                                                                                                  \n"," dense_135 (Dense)              (None, 128)          20608       ['flatten_59[0][0]']             \n","                                                                                                  \n"," dense_137 (Dense)              (None, 128)          20608       ['flatten_60[0][0]']             \n","                                                                                                  \n"," dense_139 (Dense)              (None, 128)          20608       ['flatten_61[0][0]']             \n","                                                                                                  \n"," dense_141 (Dense)              (None, 128)          20608       ['flatten_62[0][0]']             \n","                                                                                                  \n"," dense_143 (Dense)              (None, 128)          20608       ['flatten_63[0][0]']             \n","                                                                                                  \n"," dense_145 (Dense)              (None, 128)          20608       ['flatten_64[0][0]']             \n","                                                                                                  \n"," dropout_179 (Dropout)          (None, 128)          0           ['dense_135[0][0]']              \n","                                                                                                  \n"," dropout_182 (Dropout)          (None, 128)          0           ['dense_137[0][0]']              \n","                                                                                                  \n"," dropout_185 (Dropout)          (None, 128)          0           ['dense_139[0][0]']              \n","                                                                                                  \n"," dropout_188 (Dropout)          (None, 128)          0           ['dense_141[0][0]']              \n","                                                                                                  \n"," dropout_191 (Dropout)          (None, 128)          0           ['dense_143[0][0]']              \n","                                                                                                  \n"," dropout_194 (Dropout)          (None, 128)          0           ['dense_145[0][0]']              \n","                                                                                                  \n"," dense_136 (Dense)              (None, 32)           4128        ['dropout_179[0][0]']            \n","                                                                                                  \n"," dense_138 (Dense)              (None, 32)           4128        ['dropout_182[0][0]']            \n","                                                                                                  \n"," dense_140 (Dense)              (None, 32)           4128        ['dropout_185[0][0]']            \n","                                                                                                  \n"," dense_142 (Dense)              (None, 32)           4128        ['dropout_188[0][0]']            \n","                                                                                                  \n"," dense_144 (Dense)              (None, 32)           4128        ['dropout_191[0][0]']            \n","                                                                                                  \n"," dense_146 (Dense)              (None, 32)           4128        ['dropout_194[0][0]']            \n","                                                                                                  \n"," reshape_79 (Reshape)           (None, 32, 1)        0           ['dense_136[0][0]']              \n","                                                                                                  \n"," reshape_81 (Reshape)           (None, 32, 1)        0           ['dense_138[0][0]']              \n","                                                                                                  \n"," reshape_83 (Reshape)           (None, 32, 1)        0           ['dense_140[0][0]']              \n","                                                                                                  \n"," reshape_85 (Reshape)           (None, 32, 1)        0           ['dense_142[0][0]']              \n","                                                                                                  \n"," reshape_87 (Reshape)           (None, 32, 1)        0           ['dense_144[0][0]']              \n","                                                                                                  \n"," reshape_89 (Reshape)           (None, 32, 1)        0           ['dense_146[0][0]']              \n","                                                                                                  \n"," concatenate_73 (Concatenate)   (None, 32, 6)        0           ['reshape_79[0][0]',             \n","                                                                  'reshape_81[0][0]',             \n","                                                                  'reshape_83[0][0]',             \n","                                                                  'reshape_85[0][0]',             \n","                                                                  'reshape_87[0][0]',             \n","                                                                  'reshape_89[0][0]']             \n","                                                                                                  \n"," conv1d_773 (Conv1D)            (None, 8, 32)        800         ['concatenate_73[0][0]']         \n","                                                                                                  \n"," flatten_65 (Flatten)           (None, 256)          0           ['conv1d_773[0][0]']             \n","                                                                                                  \n"," dense_147 (Dense)              (None, 128)          32896       ['flatten_65[0][0]']             \n","                                                                                                  \n"," dropout_195 (Dropout)          (None, 128)          0           ['dense_147[0][0]']              \n","                                                                                                  \n"," dense_148 (Dense)              (None, 32)           4128        ['dropout_195[0][0]']            \n","                                                                                                  \n"," dense_149 (Dense)              (None, 2)            66          ['dense_148[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 602,178\n","Trainable params: 602,178\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZC6fgR_XrOSw","outputId":"7779af30-cd53-4a35-efd6-665ac531bbca","executionInfo":{"status":"ok","timestamp":1651812149459,"user_tz":-360,"elapsed":5,"user":{"displayName":"Md. Sultan Mahmud","userId":"06779944893886852404"}}},"source":["batch_size = 64\n","epochs = 200\n","kfold = KFold(n_splits=10, random_state=1, shuffle=True)\n","gc.collect()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11948"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"n94Q8iJ4rJsF"},"source":["# **Valence**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wHEnzkdKqgOS","outputId":"ef3249be-38d2-44d5-d934-017812e4bf50","executionInfo":{"status":"ok","timestamp":1651811606249,"user_tz":-360,"elapsed":574,"user":{"displayName":"Md. Sultan Mahmud","userId":"06779944893886852404"}}},"source":["#valence\n","X_train, x_test, Y_train, y_test = train_test_split(f_feat,valence, test_size=0.2, random_state=4)\n","print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(960, 36, 6) (240, 36, 6) (960, 2) (240, 2)\n"]}]},{"cell_type":"code","metadata":{"id":"8tdPOzU7rQRV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ea92445d-f144-4366-dcf1-8a8f91a487f4","executionInfo":{"status":"ok","timestamp":1651813062454,"user_tz":-360,"elapsed":911190,"user":{"displayName":"Md. Sultan Mahmud","userId":"06779944893886852404"}}},"source":["val_res = {'accuracy': [], 'f1_score': [], 'confusion_matrix': []}\n","\n","foldNum=0\n","for train_index, val_index in kfold.split(X_train, Y_train):\n","  foldNum = foldNum + 1\n","  print(\"Results for fold\",foldNum)\n","  x_train, x_val = X_train[train_index], X_train[val_index]\n","  y_train, y_val = Y_train[train_index], Y_train[val_index]\n","  model = get_model()\n","  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n","  acc = model.evaluate(x_test, y_test)\n","  print(acc)\n","  val_res['accuracy'].append(acc)\n","  pred = model.predict(x_test)\n","  val_res['f1_score'].append(f1_score(y_test.argmax(1), pred.argmax(1), average='macro'))\n","  val_res['confusion_matrix'].append(confusion_matrix(y_test.argmax(1), pred.argmax(1)))\n","  gc.collect() # Garbage collecter\n","  del x_train, x_val, y_train, y_val\n","  gc.collect()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Results for fold 1\n","Epoch 1/200\n","14/14 [==============================] - 7s 110ms/step - loss: 0.8250 - accuracy: 0.4525 - val_loss: 0.7511 - val_accuracy: 0.4271\n","Epoch 2/200\n","14/14 [==============================] - 0s 21ms/step - loss: 0.7296 - accuracy: 0.4931 - val_loss: 0.6886 - val_accuracy: 0.5312\n","Epoch 3/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.7305 - accuracy: 0.5000 - val_loss: 0.6840 - val_accuracy: 0.5938\n","Epoch 4/200\n","14/14 [==============================] - 0s 21ms/step - loss: 0.7061 - accuracy: 0.5417 - val_loss: 0.6892 - val_accuracy: 0.5625\n","Epoch 5/200\n","14/14 [==============================] - 0s 21ms/step - loss: 0.7189 - accuracy: 0.5012 - val_loss: 0.6910 - val_accuracy: 0.5625\n","Epoch 6/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.7038 - accuracy: 0.5336 - val_loss: 0.6928 - val_accuracy: 0.5729\n","Epoch 7/200\n","14/14 [==============================] - 0s 21ms/step - loss: 0.7025 - accuracy: 0.5278 - val_loss: 0.6955 - val_accuracy: 0.5521\n","Epoch 8/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6920 - accuracy: 0.5706 - val_loss: 0.6966 - val_accuracy: 0.5625\n","Epoch 9/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6861 - accuracy: 0.5706 - val_loss: 0.6982 - val_accuracy: 0.5521\n","Epoch 10/200\n","14/14 [==============================] - 0s 21ms/step - loss: 0.7063 - accuracy: 0.5127 - val_loss: 0.6982 - val_accuracy: 0.5625\n","Epoch 11/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6924 - accuracy: 0.5475 - val_loss: 0.6986 - val_accuracy: 0.5938\n","Epoch 12/200\n","14/14 [==============================] - 0s 21ms/step - loss: 0.6913 - accuracy: 0.5660 - val_loss: 0.6994 - val_accuracy: 0.5625\n","Epoch 13/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6971 - accuracy: 0.5486 - val_loss: 0.7014 - val_accuracy: 0.5729\n","Epoch 14/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6953 - accuracy: 0.5463 - val_loss: 0.7029 - val_accuracy: 0.5625\n","Epoch 15/200\n","14/14 [==============================] - 0s 21ms/step - loss: 0.6884 - accuracy: 0.5475 - val_loss: 0.7038 - val_accuracy: 0.5938\n","Epoch 16/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6933 - accuracy: 0.5440 - val_loss: 0.7050 - val_accuracy: 0.5729\n","Epoch 17/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6893 - accuracy: 0.5544 - val_loss: 0.7048 - val_accuracy: 0.5833\n","Epoch 18/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6799 - accuracy: 0.5706 - val_loss: 0.7049 - val_accuracy: 0.5521\n","Epoch 19/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6948 - accuracy: 0.5683 - val_loss: 0.7054 - val_accuracy: 0.5521\n","Epoch 20/200\n","14/14 [==============================] - 0s 21ms/step - loss: 0.7019 - accuracy: 0.5509 - val_loss: 0.7038 - val_accuracy: 0.6042\n","Epoch 21/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6927 - accuracy: 0.5521 - val_loss: 0.7014 - val_accuracy: 0.5833\n","Epoch 22/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6876 - accuracy: 0.5602 - val_loss: 0.7007 - val_accuracy: 0.6042\n","Epoch 23/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6890 - accuracy: 0.5590 - val_loss: 0.7022 - val_accuracy: 0.5833\n","Epoch 24/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6793 - accuracy: 0.5822 - val_loss: 0.7030 - val_accuracy: 0.5938\n","Epoch 25/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6827 - accuracy: 0.5637 - val_loss: 0.7016 - val_accuracy: 0.5729\n","Epoch 26/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6958 - accuracy: 0.5347 - val_loss: 0.7029 - val_accuracy: 0.5625\n","Epoch 27/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6954 - accuracy: 0.5648 - val_loss: 0.7032 - val_accuracy: 0.5625\n","Epoch 28/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6960 - accuracy: 0.5521 - val_loss: 0.7011 - val_accuracy: 0.5312\n","Epoch 29/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6963 - accuracy: 0.5567 - val_loss: 0.6998 - val_accuracy: 0.5104\n","Epoch 30/200\n","14/14 [==============================] - 0s 21ms/step - loss: 0.6866 - accuracy: 0.5683 - val_loss: 0.6987 - val_accuracy: 0.5208\n","Epoch 31/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6860 - accuracy: 0.5706 - val_loss: 0.6996 - val_accuracy: 0.5312\n","Epoch 32/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6805 - accuracy: 0.5706 - val_loss: 0.6999 - val_accuracy: 0.5312\n","Epoch 33/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6916 - accuracy: 0.5278 - val_loss: 0.6988 - val_accuracy: 0.5417\n","Epoch 34/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6821 - accuracy: 0.5625 - val_loss: 0.6984 - val_accuracy: 0.5312\n","Epoch 35/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6884 - accuracy: 0.5637 - val_loss: 0.6983 - val_accuracy: 0.5312\n","Epoch 36/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6846 - accuracy: 0.5648 - val_loss: 0.6990 - val_accuracy: 0.5521\n","Epoch 37/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6821 - accuracy: 0.5833 - val_loss: 0.6989 - val_accuracy: 0.5312\n","Epoch 38/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6897 - accuracy: 0.5486 - val_loss: 0.6995 - val_accuracy: 0.5417\n","Epoch 39/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6846 - accuracy: 0.5787 - val_loss: 0.6988 - val_accuracy: 0.5625\n","Epoch 40/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6880 - accuracy: 0.5544 - val_loss: 0.6997 - val_accuracy: 0.5625\n","Epoch 41/200\n","14/14 [==============================] - 0s 21ms/step - loss: 0.6885 - accuracy: 0.5752 - val_loss: 0.6999 - val_accuracy: 0.5625\n","Epoch 42/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6891 - accuracy: 0.5590 - val_loss: 0.6999 - val_accuracy: 0.5833\n","Epoch 43/200\n","14/14 [==============================] - 0s 21ms/step - loss: 0.6760 - accuracy: 0.5752 - val_loss: 0.6996 - val_accuracy: 0.6042\n","Epoch 44/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6975 - accuracy: 0.5567 - val_loss: 0.6994 - val_accuracy: 0.5833\n","Epoch 45/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6882 - accuracy: 0.5625 - val_loss: 0.6995 - val_accuracy: 0.5833\n","Epoch 46/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6801 - accuracy: 0.5810 - val_loss: 0.7004 - val_accuracy: 0.5833\n","Epoch 47/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6870 - accuracy: 0.5625 - val_loss: 0.7020 - val_accuracy: 0.5729\n","Epoch 48/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6847 - accuracy: 0.5579 - val_loss: 0.7034 - val_accuracy: 0.5625\n","Epoch 49/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6818 - accuracy: 0.5567 - val_loss: 0.7031 - val_accuracy: 0.5729\n","Epoch 50/200\n","14/14 [==============================] - 0s 21ms/step - loss: 0.6815 - accuracy: 0.5903 - val_loss: 0.7017 - val_accuracy: 0.5833\n","Epoch 51/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6812 - accuracy: 0.5799 - val_loss: 0.7009 - val_accuracy: 0.5625\n","Epoch 52/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6938 - accuracy: 0.5405 - val_loss: 0.7011 - val_accuracy: 0.5729\n","Epoch 53/200\n","14/14 [==============================] - 0s 21ms/step - loss: 0.6805 - accuracy: 0.5787 - val_loss: 0.7015 - val_accuracy: 0.5833\n","Epoch 54/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6759 - accuracy: 0.5764 - val_loss: 0.7023 - val_accuracy: 0.5729\n","Epoch 55/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6897 - accuracy: 0.5579 - val_loss: 0.7029 - val_accuracy: 0.5521\n","Epoch 56/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6746 - accuracy: 0.5949 - val_loss: 0.7033 - val_accuracy: 0.5521\n","Epoch 57/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6862 - accuracy: 0.5625 - val_loss: 0.7023 - val_accuracy: 0.5521\n","Epoch 58/200\n","14/14 [==============================] - 0s 21ms/step - loss: 0.6758 - accuracy: 0.5752 - val_loss: 0.7015 - val_accuracy: 0.5521\n","Epoch 59/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6769 - accuracy: 0.5810 - val_loss: 0.7017 - val_accuracy: 0.5521\n","Epoch 60/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6864 - accuracy: 0.5521 - val_loss: 0.7020 - val_accuracy: 0.5000\n","Epoch 61/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6937 - accuracy: 0.5556 - val_loss: 0.7009 - val_accuracy: 0.4896\n","Epoch 62/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6872 - accuracy: 0.5671 - val_loss: 0.7006 - val_accuracy: 0.5104\n","Epoch 63/200\n","14/14 [==============================] - 0s 21ms/step - loss: 0.6876 - accuracy: 0.5532 - val_loss: 0.7013 - val_accuracy: 0.5208\n","Epoch 64/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6703 - accuracy: 0.5810 - val_loss: 0.7003 - val_accuracy: 0.5312\n","Epoch 65/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6679 - accuracy: 0.5752 - val_loss: 0.7003 - val_accuracy: 0.5312\n","Epoch 66/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6799 - accuracy: 0.5671 - val_loss: 0.7015 - val_accuracy: 0.5312\n","Epoch 67/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6661 - accuracy: 0.5938 - val_loss: 0.7025 - val_accuracy: 0.5208\n","Epoch 68/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6767 - accuracy: 0.5741 - val_loss: 0.7024 - val_accuracy: 0.5208\n","Epoch 69/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6742 - accuracy: 0.5961 - val_loss: 0.7010 - val_accuracy: 0.5312\n","Epoch 70/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6746 - accuracy: 0.5903 - val_loss: 0.7005 - val_accuracy: 0.5312\n","Epoch 71/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6865 - accuracy: 0.5718 - val_loss: 0.7010 - val_accuracy: 0.5000\n","Epoch 72/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6782 - accuracy: 0.5625 - val_loss: 0.7020 - val_accuracy: 0.4896\n","Epoch 73/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6795 - accuracy: 0.5694 - val_loss: 0.7031 - val_accuracy: 0.5104\n","Epoch 74/200\n","14/14 [==============================] - 0s 21ms/step - loss: 0.6849 - accuracy: 0.5521 - val_loss: 0.7036 - val_accuracy: 0.5000\n","Epoch 75/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6759 - accuracy: 0.5775 - val_loss: 0.7026 - val_accuracy: 0.5104\n","Epoch 76/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6819 - accuracy: 0.5694 - val_loss: 0.7041 - val_accuracy: 0.5104\n","Epoch 77/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6765 - accuracy: 0.5926 - val_loss: 0.7034 - val_accuracy: 0.5104\n","Epoch 78/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6791 - accuracy: 0.5613 - val_loss: 0.7038 - val_accuracy: 0.4896\n","Epoch 79/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6655 - accuracy: 0.6076 - val_loss: 0.7037 - val_accuracy: 0.4688\n","Epoch 80/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6745 - accuracy: 0.5914 - val_loss: 0.7032 - val_accuracy: 0.5312\n","Epoch 81/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6652 - accuracy: 0.5949 - val_loss: 0.7030 - val_accuracy: 0.5000\n","Epoch 82/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6768 - accuracy: 0.5637 - val_loss: 0.7032 - val_accuracy: 0.5000\n","Epoch 83/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6690 - accuracy: 0.5787 - val_loss: 0.7046 - val_accuracy: 0.4792\n","Epoch 84/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6733 - accuracy: 0.5972 - val_loss: 0.7059 - val_accuracy: 0.4688\n","Epoch 85/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6738 - accuracy: 0.5706 - val_loss: 0.7051 - val_accuracy: 0.4792\n","Epoch 86/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6744 - accuracy: 0.5949 - val_loss: 0.7045 - val_accuracy: 0.4896\n","Epoch 87/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6659 - accuracy: 0.5961 - val_loss: 0.7038 - val_accuracy: 0.5000\n","Epoch 88/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6722 - accuracy: 0.5903 - val_loss: 0.7053 - val_accuracy: 0.4896\n","Epoch 89/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6738 - accuracy: 0.5856 - val_loss: 0.7050 - val_accuracy: 0.5208\n","Epoch 90/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6711 - accuracy: 0.5775 - val_loss: 0.7052 - val_accuracy: 0.5000\n","Epoch 91/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6736 - accuracy: 0.5833 - val_loss: 0.7045 - val_accuracy: 0.5104\n","Epoch 92/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6841 - accuracy: 0.5752 - val_loss: 0.7049 - val_accuracy: 0.5104\n","Epoch 93/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6742 - accuracy: 0.5856 - val_loss: 0.7054 - val_accuracy: 0.5000\n","Epoch 94/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6709 - accuracy: 0.5741 - val_loss: 0.7043 - val_accuracy: 0.5000\n","Epoch 95/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6709 - accuracy: 0.5938 - val_loss: 0.7036 - val_accuracy: 0.5208\n","Epoch 96/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6797 - accuracy: 0.5521 - val_loss: 0.7037 - val_accuracy: 0.5208\n","Epoch 97/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6725 - accuracy: 0.5741 - val_loss: 0.7071 - val_accuracy: 0.5104\n","Epoch 98/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6701 - accuracy: 0.6019 - val_loss: 0.7080 - val_accuracy: 0.5104\n","Epoch 99/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6765 - accuracy: 0.5799 - val_loss: 0.7092 - val_accuracy: 0.4792\n","Epoch 100/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6748 - accuracy: 0.5671 - val_loss: 0.7085 - val_accuracy: 0.5000\n","Epoch 101/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6684 - accuracy: 0.5972 - val_loss: 0.7096 - val_accuracy: 0.4896\n","Epoch 102/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6689 - accuracy: 0.5938 - val_loss: 0.7098 - val_accuracy: 0.4896\n","Epoch 103/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6747 - accuracy: 0.5694 - val_loss: 0.7090 - val_accuracy: 0.4896\n","Epoch 104/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6673 - accuracy: 0.6076 - val_loss: 0.7089 - val_accuracy: 0.4896\n","Epoch 105/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6776 - accuracy: 0.5868 - val_loss: 0.7100 - val_accuracy: 0.5000\n","Epoch 106/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6732 - accuracy: 0.6042 - val_loss: 0.7095 - val_accuracy: 0.5000\n","Epoch 107/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6693 - accuracy: 0.5984 - val_loss: 0.7092 - val_accuracy: 0.5000\n","Epoch 108/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6634 - accuracy: 0.5833 - val_loss: 0.7099 - val_accuracy: 0.4896\n","Epoch 109/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6695 - accuracy: 0.5764 - val_loss: 0.7123 - val_accuracy: 0.4896\n","Epoch 110/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6705 - accuracy: 0.6007 - val_loss: 0.7123 - val_accuracy: 0.4896\n","Epoch 111/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6724 - accuracy: 0.5972 - val_loss: 0.7118 - val_accuracy: 0.5000\n","Epoch 112/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6661 - accuracy: 0.5961 - val_loss: 0.7104 - val_accuracy: 0.4896\n","Epoch 113/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6736 - accuracy: 0.5787 - val_loss: 0.7106 - val_accuracy: 0.5000\n","Epoch 114/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6674 - accuracy: 0.5799 - val_loss: 0.7110 - val_accuracy: 0.5000\n","Epoch 115/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6720 - accuracy: 0.5706 - val_loss: 0.7117 - val_accuracy: 0.5000\n","Epoch 116/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6715 - accuracy: 0.5845 - val_loss: 0.7108 - val_accuracy: 0.4896\n","Epoch 117/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6694 - accuracy: 0.5995 - val_loss: 0.7107 - val_accuracy: 0.5000\n","Epoch 118/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6650 - accuracy: 0.6030 - val_loss: 0.7101 - val_accuracy: 0.4896\n","Epoch 119/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6740 - accuracy: 0.5718 - val_loss: 0.7071 - val_accuracy: 0.4896\n","Epoch 120/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6701 - accuracy: 0.5891 - val_loss: 0.7053 - val_accuracy: 0.5208\n","Epoch 121/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6705 - accuracy: 0.5856 - val_loss: 0.7046 - val_accuracy: 0.5208\n","Epoch 122/200\n","14/14 [==============================] - 0s 21ms/step - loss: 0.6761 - accuracy: 0.5486 - val_loss: 0.7061 - val_accuracy: 0.4896\n","Epoch 123/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6651 - accuracy: 0.6007 - val_loss: 0.7062 - val_accuracy: 0.4896\n","Epoch 124/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6632 - accuracy: 0.6030 - val_loss: 0.7076 - val_accuracy: 0.5000\n","Epoch 125/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6688 - accuracy: 0.6042 - val_loss: 0.7094 - val_accuracy: 0.4792\n","Epoch 126/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6726 - accuracy: 0.6019 - val_loss: 0.7098 - val_accuracy: 0.4896\n","Epoch 127/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6700 - accuracy: 0.5799 - val_loss: 0.7070 - val_accuracy: 0.5104\n","Epoch 128/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6683 - accuracy: 0.5961 - val_loss: 0.7060 - val_accuracy: 0.5000\n","Epoch 129/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6686 - accuracy: 0.5938 - val_loss: 0.7055 - val_accuracy: 0.4896\n","Epoch 130/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6582 - accuracy: 0.6065 - val_loss: 0.7059 - val_accuracy: 0.5000\n","Epoch 131/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6668 - accuracy: 0.6042 - val_loss: 0.7036 - val_accuracy: 0.4792\n","Epoch 132/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6755 - accuracy: 0.5706 - val_loss: 0.7025 - val_accuracy: 0.5000\n","Epoch 133/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6636 - accuracy: 0.6100 - val_loss: 0.7031 - val_accuracy: 0.4896\n","Epoch 134/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6578 - accuracy: 0.6296 - val_loss: 0.7030 - val_accuracy: 0.5000\n","Epoch 135/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6592 - accuracy: 0.5903 - val_loss: 0.7030 - val_accuracy: 0.5104\n","Epoch 136/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6646 - accuracy: 0.5868 - val_loss: 0.7029 - val_accuracy: 0.5000\n","Epoch 137/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6709 - accuracy: 0.5949 - val_loss: 0.7037 - val_accuracy: 0.5000\n","Epoch 138/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6674 - accuracy: 0.6019 - val_loss: 0.7031 - val_accuracy: 0.5208\n","Epoch 139/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6617 - accuracy: 0.5822 - val_loss: 0.7034 - val_accuracy: 0.5312\n","Epoch 140/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6708 - accuracy: 0.5833 - val_loss: 0.7038 - val_accuracy: 0.5104\n","Epoch 141/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6672 - accuracy: 0.5903 - val_loss: 0.7049 - val_accuracy: 0.5000\n","Epoch 142/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6667 - accuracy: 0.5926 - val_loss: 0.7056 - val_accuracy: 0.4896\n","Epoch 143/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6716 - accuracy: 0.6088 - val_loss: 0.7058 - val_accuracy: 0.4896\n","Epoch 144/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6657 - accuracy: 0.5845 - val_loss: 0.7068 - val_accuracy: 0.4792\n","Epoch 145/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6592 - accuracy: 0.6204 - val_loss: 0.7076 - val_accuracy: 0.4896\n","Epoch 146/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6657 - accuracy: 0.5961 - val_loss: 0.7082 - val_accuracy: 0.4896\n","Epoch 147/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6663 - accuracy: 0.5938 - val_loss: 0.7077 - val_accuracy: 0.5000\n","Epoch 148/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6615 - accuracy: 0.5949 - val_loss: 0.7078 - val_accuracy: 0.5000\n","Epoch 149/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6612 - accuracy: 0.6053 - val_loss: 0.7087 - val_accuracy: 0.4896\n","Epoch 150/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6591 - accuracy: 0.6076 - val_loss: 0.7066 - val_accuracy: 0.5000\n","Epoch 151/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6820 - accuracy: 0.5544 - val_loss: 0.7048 - val_accuracy: 0.5000\n","Epoch 152/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6673 - accuracy: 0.5799 - val_loss: 0.7055 - val_accuracy: 0.5104\n","Epoch 153/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6629 - accuracy: 0.6157 - val_loss: 0.7069 - val_accuracy: 0.5104\n","Epoch 154/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6634 - accuracy: 0.5995 - val_loss: 0.7074 - val_accuracy: 0.5104\n","Epoch 155/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6596 - accuracy: 0.5949 - val_loss: 0.7080 - val_accuracy: 0.4896\n","Epoch 156/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6596 - accuracy: 0.6053 - val_loss: 0.7078 - val_accuracy: 0.4792\n","Epoch 157/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6590 - accuracy: 0.6030 - val_loss: 0.7074 - val_accuracy: 0.4792\n","Epoch 158/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6642 - accuracy: 0.5914 - val_loss: 0.7080 - val_accuracy: 0.4896\n","Epoch 159/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6610 - accuracy: 0.6019 - val_loss: 0.7083 - val_accuracy: 0.4896\n","Epoch 160/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6661 - accuracy: 0.6019 - val_loss: 0.7092 - val_accuracy: 0.4896\n","Epoch 161/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6556 - accuracy: 0.6065 - val_loss: 0.7092 - val_accuracy: 0.4896\n","Epoch 162/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6733 - accuracy: 0.5694 - val_loss: 0.7080 - val_accuracy: 0.4896\n","Epoch 163/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6666 - accuracy: 0.5949 - val_loss: 0.7088 - val_accuracy: 0.4896\n","Epoch 164/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6613 - accuracy: 0.6181 - val_loss: 0.7076 - val_accuracy: 0.5000\n","Epoch 165/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6558 - accuracy: 0.6030 - val_loss: 0.7054 - val_accuracy: 0.5208\n","Epoch 166/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6518 - accuracy: 0.6181 - val_loss: 0.7057 - val_accuracy: 0.5208\n","Epoch 167/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6590 - accuracy: 0.6053 - val_loss: 0.7070 - val_accuracy: 0.5104\n","Epoch 168/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6598 - accuracy: 0.6042 - val_loss: 0.7076 - val_accuracy: 0.4896\n","Epoch 169/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6567 - accuracy: 0.6157 - val_loss: 0.7079 - val_accuracy: 0.4896\n","Epoch 170/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6575 - accuracy: 0.6146 - val_loss: 0.7066 - val_accuracy: 0.4896\n","Epoch 171/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6639 - accuracy: 0.6181 - val_loss: 0.7071 - val_accuracy: 0.5000\n","Epoch 172/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6704 - accuracy: 0.5752 - val_loss: 0.7076 - val_accuracy: 0.5000\n","Epoch 173/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6540 - accuracy: 0.6308 - val_loss: 0.7071 - val_accuracy: 0.5000\n","Epoch 174/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6554 - accuracy: 0.6146 - val_loss: 0.7079 - val_accuracy: 0.5000\n","Epoch 175/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6702 - accuracy: 0.5972 - val_loss: 0.7063 - val_accuracy: 0.5104\n","Epoch 176/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6526 - accuracy: 0.6354 - val_loss: 0.7057 - val_accuracy: 0.5104\n","Epoch 177/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6507 - accuracy: 0.6204 - val_loss: 0.7070 - val_accuracy: 0.4792\n","Epoch 178/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6586 - accuracy: 0.6146 - val_loss: 0.7082 - val_accuracy: 0.5000\n","Epoch 179/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6613 - accuracy: 0.5926 - val_loss: 0.7054 - val_accuracy: 0.5104\n","Epoch 180/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6601 - accuracy: 0.6262 - val_loss: 0.7047 - val_accuracy: 0.5000\n","Epoch 181/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6639 - accuracy: 0.5949 - val_loss: 0.7031 - val_accuracy: 0.5208\n","Epoch 182/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6533 - accuracy: 0.6204 - val_loss: 0.7054 - val_accuracy: 0.5104\n","Epoch 183/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6473 - accuracy: 0.6146 - val_loss: 0.7076 - val_accuracy: 0.4896\n","Epoch 184/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6556 - accuracy: 0.6111 - val_loss: 0.7105 - val_accuracy: 0.4688\n","Epoch 185/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6560 - accuracy: 0.6389 - val_loss: 0.7124 - val_accuracy: 0.4896\n","Epoch 186/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6553 - accuracy: 0.6215 - val_loss: 0.7116 - val_accuracy: 0.5000\n","Epoch 187/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6586 - accuracy: 0.6030 - val_loss: 0.7128 - val_accuracy: 0.4688\n","Epoch 188/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6534 - accuracy: 0.5984 - val_loss: 0.7130 - val_accuracy: 0.4583\n","Epoch 189/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6581 - accuracy: 0.5995 - val_loss: 0.7124 - val_accuracy: 0.4583\n","Epoch 190/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6555 - accuracy: 0.6262 - val_loss: 0.7128 - val_accuracy: 0.4583\n","Epoch 191/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6583 - accuracy: 0.6100 - val_loss: 0.7125 - val_accuracy: 0.4792\n","Epoch 192/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6535 - accuracy: 0.6019 - val_loss: 0.7134 - val_accuracy: 0.4792\n","Epoch 193/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6604 - accuracy: 0.6053 - val_loss: 0.7117 - val_accuracy: 0.4688\n","Epoch 194/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6606 - accuracy: 0.6076 - val_loss: 0.7116 - val_accuracy: 0.4688\n","Epoch 195/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6514 - accuracy: 0.6030 - val_loss: 0.7110 - val_accuracy: 0.4583\n","Epoch 196/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6505 - accuracy: 0.6262 - val_loss: 0.7145 - val_accuracy: 0.5000\n","Epoch 197/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6522 - accuracy: 0.6123 - val_loss: 0.7139 - val_accuracy: 0.4896\n","Epoch 198/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6421 - accuracy: 0.6285 - val_loss: 0.7151 - val_accuracy: 0.4896\n","Epoch 199/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6401 - accuracy: 0.6424 - val_loss: 0.7139 - val_accuracy: 0.4688\n","Epoch 200/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6593 - accuracy: 0.6319 - val_loss: 0.7132 - val_accuracy: 0.4792\n","8/8 [==============================] - 0s 12ms/step - loss: 0.6824 - accuracy: 0.5667\n","[0.682371973991394, 0.5666666626930237]\n","Results for fold 2\n","Epoch 1/200\n","14/14 [==============================] - 7s 107ms/step - loss: 0.7367 - accuracy: 0.5498 - val_loss: 0.7526 - val_accuracy: 0.5312\n","Epoch 2/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.7276 - accuracy: 0.5637 - val_loss: 0.7281 - val_accuracy: 0.5208\n","Epoch 3/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.7248 - accuracy: 0.5475 - val_loss: 0.7199 - val_accuracy: 0.4792\n","Epoch 4/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.7161 - accuracy: 0.5451 - val_loss: 0.7164 - val_accuracy: 0.5104\n","Epoch 5/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.7221 - accuracy: 0.5197 - val_loss: 0.7120 - val_accuracy: 0.5521\n","Epoch 6/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.7074 - accuracy: 0.5382 - val_loss: 0.7127 - val_accuracy: 0.5417\n","Epoch 7/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.7219 - accuracy: 0.5093 - val_loss: 0.7138 - val_accuracy: 0.5312\n","Epoch 8/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.7068 - accuracy: 0.5312 - val_loss: 0.7132 - val_accuracy: 0.5312\n","Epoch 9/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.7184 - accuracy: 0.5289 - val_loss: 0.7097 - val_accuracy: 0.5417\n","Epoch 10/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.7160 - accuracy: 0.5359 - val_loss: 0.7059 - val_accuracy: 0.5312\n","Epoch 11/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.7090 - accuracy: 0.5359 - val_loss: 0.7055 - val_accuracy: 0.5208\n","Epoch 12/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.7177 - accuracy: 0.5208 - val_loss: 0.7007 - val_accuracy: 0.5417\n","Epoch 13/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6936 - accuracy: 0.5729 - val_loss: 0.6980 - val_accuracy: 0.5417\n","Epoch 14/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.7150 - accuracy: 0.5174 - val_loss: 0.6935 - val_accuracy: 0.5729\n","Epoch 15/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6974 - accuracy: 0.5544 - val_loss: 0.6899 - val_accuracy: 0.5521\n","Epoch 16/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.7113 - accuracy: 0.5278 - val_loss: 0.6876 - val_accuracy: 0.5312\n","Epoch 17/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.7078 - accuracy: 0.5556 - val_loss: 0.6877 - val_accuracy: 0.5417\n","Epoch 18/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.7039 - accuracy: 0.5289 - val_loss: 0.6887 - val_accuracy: 0.5208\n","Epoch 19/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6976 - accuracy: 0.5405 - val_loss: 0.6870 - val_accuracy: 0.5312\n","Epoch 20/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6932 - accuracy: 0.5394 - val_loss: 0.6869 - val_accuracy: 0.5208\n","Epoch 21/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6882 - accuracy: 0.5775 - val_loss: 0.6874 - val_accuracy: 0.5104\n","Epoch 22/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6926 - accuracy: 0.5451 - val_loss: 0.6877 - val_accuracy: 0.5208\n","Epoch 23/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6971 - accuracy: 0.5370 - val_loss: 0.6885 - val_accuracy: 0.5000\n","Epoch 24/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.7010 - accuracy: 0.5544 - val_loss: 0.6896 - val_accuracy: 0.5000\n","Epoch 25/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.7022 - accuracy: 0.5613 - val_loss: 0.6905 - val_accuracy: 0.5104\n","Epoch 26/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.7101 - accuracy: 0.5185 - val_loss: 0.6887 - val_accuracy: 0.5208\n","Epoch 27/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.7032 - accuracy: 0.5289 - val_loss: 0.6872 - val_accuracy: 0.5208\n","Epoch 28/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6780 - accuracy: 0.5729 - val_loss: 0.6860 - val_accuracy: 0.5208\n","Epoch 29/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.7074 - accuracy: 0.5220 - val_loss: 0.6856 - val_accuracy: 0.5312\n","Epoch 30/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6919 - accuracy: 0.5463 - val_loss: 0.6854 - val_accuracy: 0.5312\n","Epoch 31/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6912 - accuracy: 0.5579 - val_loss: 0.6854 - val_accuracy: 0.5208\n","Epoch 32/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6947 - accuracy: 0.5451 - val_loss: 0.6852 - val_accuracy: 0.5312\n","Epoch 33/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6974 - accuracy: 0.5347 - val_loss: 0.6847 - val_accuracy: 0.5312\n","Epoch 34/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6972 - accuracy: 0.5382 - val_loss: 0.6840 - val_accuracy: 0.5312\n","Epoch 35/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6946 - accuracy: 0.5590 - val_loss: 0.6844 - val_accuracy: 0.5417\n","Epoch 36/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6916 - accuracy: 0.5486 - val_loss: 0.6832 - val_accuracy: 0.5625\n","Epoch 37/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6951 - accuracy: 0.5382 - val_loss: 0.6843 - val_accuracy: 0.5417\n","Epoch 38/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.7001 - accuracy: 0.5428 - val_loss: 0.6840 - val_accuracy: 0.5833\n","Epoch 39/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6883 - accuracy: 0.5648 - val_loss: 0.6847 - val_accuracy: 0.5417\n","Epoch 40/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6842 - accuracy: 0.5509 - val_loss: 0.6833 - val_accuracy: 0.5312\n","Epoch 41/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6973 - accuracy: 0.5312 - val_loss: 0.6814 - val_accuracy: 0.5417\n","Epoch 42/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6856 - accuracy: 0.5590 - val_loss: 0.6838 - val_accuracy: 0.5312\n","Epoch 43/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6891 - accuracy: 0.5567 - val_loss: 0.6830 - val_accuracy: 0.5625\n","Epoch 44/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6888 - accuracy: 0.5579 - val_loss: 0.6836 - val_accuracy: 0.5625\n","Epoch 45/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6861 - accuracy: 0.5556 - val_loss: 0.6804 - val_accuracy: 0.5625\n","Epoch 46/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6856 - accuracy: 0.5775 - val_loss: 0.6825 - val_accuracy: 0.5729\n","Epoch 47/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6929 - accuracy: 0.5347 - val_loss: 0.6835 - val_accuracy: 0.5625\n","Epoch 48/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6879 - accuracy: 0.5625 - val_loss: 0.6829 - val_accuracy: 0.5521\n","Epoch 49/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6898 - accuracy: 0.5694 - val_loss: 0.6831 - val_accuracy: 0.5833\n","Epoch 50/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6944 - accuracy: 0.5428 - val_loss: 0.6828 - val_accuracy: 0.5625\n","Epoch 51/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6859 - accuracy: 0.5694 - val_loss: 0.6859 - val_accuracy: 0.5625\n","Epoch 52/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6897 - accuracy: 0.5486 - val_loss: 0.6892 - val_accuracy: 0.5625\n","Epoch 53/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6915 - accuracy: 0.5498 - val_loss: 0.6891 - val_accuracy: 0.5208\n","Epoch 54/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6819 - accuracy: 0.5417 - val_loss: 0.6882 - val_accuracy: 0.5521\n","Epoch 55/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6785 - accuracy: 0.5752 - val_loss: 0.6871 - val_accuracy: 0.5521\n","Epoch 56/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6942 - accuracy: 0.5440 - val_loss: 0.6829 - val_accuracy: 0.5521\n","Epoch 57/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6848 - accuracy: 0.5660 - val_loss: 0.6830 - val_accuracy: 0.5521\n","Epoch 58/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6806 - accuracy: 0.5764 - val_loss: 0.6837 - val_accuracy: 0.5625\n","Epoch 59/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6810 - accuracy: 0.5660 - val_loss: 0.6842 - val_accuracy: 0.5521\n","Epoch 60/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6832 - accuracy: 0.5694 - val_loss: 0.6851 - val_accuracy: 0.5521\n","Epoch 61/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6879 - accuracy: 0.5521 - val_loss: 0.6857 - val_accuracy: 0.5521\n","Epoch 62/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6899 - accuracy: 0.5428 - val_loss: 0.6857 - val_accuracy: 0.5521\n","Epoch 63/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6826 - accuracy: 0.5602 - val_loss: 0.6865 - val_accuracy: 0.5625\n","Epoch 64/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6924 - accuracy: 0.5521 - val_loss: 0.6865 - val_accuracy: 0.5625\n","Epoch 65/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6843 - accuracy: 0.5521 - val_loss: 0.6870 - val_accuracy: 0.5521\n","Epoch 66/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6813 - accuracy: 0.5509 - val_loss: 0.6872 - val_accuracy: 0.5625\n","Epoch 67/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6795 - accuracy: 0.5451 - val_loss: 0.6868 - val_accuracy: 0.5625\n","Epoch 68/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6809 - accuracy: 0.5671 - val_loss: 0.6864 - val_accuracy: 0.5312\n","Epoch 69/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6866 - accuracy: 0.5648 - val_loss: 0.6868 - val_accuracy: 0.5208\n","Epoch 70/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6912 - accuracy: 0.5451 - val_loss: 0.6889 - val_accuracy: 0.5312\n","Epoch 71/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6874 - accuracy: 0.5775 - val_loss: 0.6876 - val_accuracy: 0.5521\n","Epoch 72/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6848 - accuracy: 0.5613 - val_loss: 0.6869 - val_accuracy: 0.5625\n","Epoch 73/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6890 - accuracy: 0.5868 - val_loss: 0.6870 - val_accuracy: 0.5521\n","Epoch 74/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6840 - accuracy: 0.5556 - val_loss: 0.6873 - val_accuracy: 0.5729\n","Epoch 75/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6782 - accuracy: 0.5822 - val_loss: 0.6878 - val_accuracy: 0.5729\n","Epoch 76/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6792 - accuracy: 0.5694 - val_loss: 0.6877 - val_accuracy: 0.5729\n","Epoch 77/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6817 - accuracy: 0.5556 - val_loss: 0.6878 - val_accuracy: 0.5729\n","Epoch 78/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6836 - accuracy: 0.5660 - val_loss: 0.6896 - val_accuracy: 0.5625\n","Epoch 79/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6820 - accuracy: 0.5590 - val_loss: 0.6912 - val_accuracy: 0.5417\n","Epoch 80/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6836 - accuracy: 0.5718 - val_loss: 0.6912 - val_accuracy: 0.5417\n","Epoch 81/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6923 - accuracy: 0.5440 - val_loss: 0.6909 - val_accuracy: 0.5417\n","Epoch 82/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6872 - accuracy: 0.5648 - val_loss: 0.6881 - val_accuracy: 0.5625\n","Epoch 83/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6913 - accuracy: 0.5451 - val_loss: 0.6876 - val_accuracy: 0.5521\n","Epoch 84/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6745 - accuracy: 0.5856 - val_loss: 0.6859 - val_accuracy: 0.5625\n","Epoch 85/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6860 - accuracy: 0.5556 - val_loss: 0.6854 - val_accuracy: 0.5625\n","Epoch 86/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6856 - accuracy: 0.5486 - val_loss: 0.6842 - val_accuracy: 0.5521\n","Epoch 87/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6795 - accuracy: 0.5683 - val_loss: 0.6849 - val_accuracy: 0.5521\n","Epoch 88/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6810 - accuracy: 0.5567 - val_loss: 0.6867 - val_accuracy: 0.5521\n","Epoch 89/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6808 - accuracy: 0.5694 - val_loss: 0.6856 - val_accuracy: 0.5521\n","Epoch 90/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6885 - accuracy: 0.5509 - val_loss: 0.6847 - val_accuracy: 0.5729\n","Epoch 91/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6843 - accuracy: 0.5602 - val_loss: 0.6876 - val_accuracy: 0.5625\n","Epoch 92/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6766 - accuracy: 0.5718 - val_loss: 0.6901 - val_accuracy: 0.5521\n","Epoch 93/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6746 - accuracy: 0.5694 - val_loss: 0.6891 - val_accuracy: 0.5417\n","Epoch 94/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6825 - accuracy: 0.5706 - val_loss: 0.6881 - val_accuracy: 0.5521\n","Epoch 95/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6813 - accuracy: 0.5509 - val_loss: 0.6854 - val_accuracy: 0.5625\n","Epoch 96/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6853 - accuracy: 0.5660 - val_loss: 0.6843 - val_accuracy: 0.5625\n","Epoch 97/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6829 - accuracy: 0.5637 - val_loss: 0.6853 - val_accuracy: 0.5521\n","Epoch 98/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6855 - accuracy: 0.5428 - val_loss: 0.6841 - val_accuracy: 0.5625\n","Epoch 99/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6778 - accuracy: 0.5671 - val_loss: 0.6845 - val_accuracy: 0.5521\n","Epoch 100/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6794 - accuracy: 0.5660 - val_loss: 0.6864 - val_accuracy: 0.5521\n","Epoch 101/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6774 - accuracy: 0.5810 - val_loss: 0.6864 - val_accuracy: 0.5312\n","Epoch 102/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6881 - accuracy: 0.5498 - val_loss: 0.6834 - val_accuracy: 0.5312\n","Epoch 103/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6786 - accuracy: 0.5752 - val_loss: 0.6843 - val_accuracy: 0.5000\n","Epoch 104/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6787 - accuracy: 0.5671 - val_loss: 0.6864 - val_accuracy: 0.5104\n","Epoch 105/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6772 - accuracy: 0.5683 - val_loss: 0.6858 - val_accuracy: 0.5000\n","Epoch 106/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6671 - accuracy: 0.6007 - val_loss: 0.6855 - val_accuracy: 0.5312\n","Epoch 107/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6784 - accuracy: 0.5718 - val_loss: 0.6854 - val_accuracy: 0.5417\n","Epoch 108/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6794 - accuracy: 0.5706 - val_loss: 0.6843 - val_accuracy: 0.5208\n","Epoch 109/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6743 - accuracy: 0.5833 - val_loss: 0.6845 - val_accuracy: 0.5208\n","Epoch 110/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6814 - accuracy: 0.5544 - val_loss: 0.6856 - val_accuracy: 0.5417\n","Epoch 111/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6861 - accuracy: 0.5648 - val_loss: 0.6866 - val_accuracy: 0.5208\n","Epoch 112/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6793 - accuracy: 0.5822 - val_loss: 0.6867 - val_accuracy: 0.5208\n","Epoch 113/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6782 - accuracy: 0.5590 - val_loss: 0.6881 - val_accuracy: 0.5104\n","Epoch 114/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6728 - accuracy: 0.5764 - val_loss: 0.6891 - val_accuracy: 0.5000\n","Epoch 115/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6767 - accuracy: 0.5729 - val_loss: 0.6876 - val_accuracy: 0.4896\n","Epoch 116/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6865 - accuracy: 0.5613 - val_loss: 0.6888 - val_accuracy: 0.5000\n","Epoch 117/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6724 - accuracy: 0.5822 - val_loss: 0.6896 - val_accuracy: 0.5312\n","Epoch 118/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6717 - accuracy: 0.5787 - val_loss: 0.6895 - val_accuracy: 0.5312\n","Epoch 119/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6782 - accuracy: 0.5729 - val_loss: 0.6897 - val_accuracy: 0.5417\n","Epoch 120/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6737 - accuracy: 0.5868 - val_loss: 0.6891 - val_accuracy: 0.5312\n","Epoch 121/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6766 - accuracy: 0.5521 - val_loss: 0.6901 - val_accuracy: 0.5104\n","Epoch 122/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6819 - accuracy: 0.5694 - val_loss: 0.6885 - val_accuracy: 0.4896\n","Epoch 123/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6710 - accuracy: 0.5984 - val_loss: 0.6882 - val_accuracy: 0.4896\n","Epoch 124/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6711 - accuracy: 0.5799 - val_loss: 0.6889 - val_accuracy: 0.5104\n","Epoch 125/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6804 - accuracy: 0.5475 - val_loss: 0.6869 - val_accuracy: 0.5208\n","Epoch 126/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6784 - accuracy: 0.5880 - val_loss: 0.6872 - val_accuracy: 0.5208\n","Epoch 127/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6752 - accuracy: 0.5718 - val_loss: 0.6880 - val_accuracy: 0.5000\n","Epoch 128/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6643 - accuracy: 0.5914 - val_loss: 0.6876 - val_accuracy: 0.5104\n","Epoch 129/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6796 - accuracy: 0.5775 - val_loss: 0.6875 - val_accuracy: 0.5208\n","Epoch 130/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6790 - accuracy: 0.5567 - val_loss: 0.6892 - val_accuracy: 0.5104\n","Epoch 131/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6715 - accuracy: 0.5729 - val_loss: 0.6916 - val_accuracy: 0.4896\n","Epoch 132/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6703 - accuracy: 0.5741 - val_loss: 0.6902 - val_accuracy: 0.4896\n","Epoch 133/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6791 - accuracy: 0.5741 - val_loss: 0.6896 - val_accuracy: 0.5208\n","Epoch 134/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6829 - accuracy: 0.5741 - val_loss: 0.6897 - val_accuracy: 0.5104\n","Epoch 135/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6833 - accuracy: 0.5532 - val_loss: 0.6883 - val_accuracy: 0.5000\n","Epoch 136/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6761 - accuracy: 0.5752 - val_loss: 0.6886 - val_accuracy: 0.5000\n","Epoch 137/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6725 - accuracy: 0.5683 - val_loss: 0.6896 - val_accuracy: 0.4896\n","Epoch 138/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6706 - accuracy: 0.5972 - val_loss: 0.6921 - val_accuracy: 0.4792\n","Epoch 139/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6680 - accuracy: 0.5856 - val_loss: 0.6902 - val_accuracy: 0.4792\n","Epoch 140/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6668 - accuracy: 0.5972 - val_loss: 0.6901 - val_accuracy: 0.4792\n","Epoch 141/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6686 - accuracy: 0.5856 - val_loss: 0.6904 - val_accuracy: 0.4896\n","Epoch 142/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6696 - accuracy: 0.5799 - val_loss: 0.6935 - val_accuracy: 0.5000\n","Epoch 143/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6696 - accuracy: 0.5833 - val_loss: 0.6955 - val_accuracy: 0.4896\n","Epoch 144/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6685 - accuracy: 0.5856 - val_loss: 0.6945 - val_accuracy: 0.4896\n","Epoch 145/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6708 - accuracy: 0.5799 - val_loss: 0.6929 - val_accuracy: 0.5208\n","Epoch 146/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6784 - accuracy: 0.5718 - val_loss: 0.6923 - val_accuracy: 0.4792\n","Epoch 147/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6725 - accuracy: 0.5961 - val_loss: 0.6933 - val_accuracy: 0.5000\n","Epoch 148/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6759 - accuracy: 0.5775 - val_loss: 0.6916 - val_accuracy: 0.5000\n","Epoch 149/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6775 - accuracy: 0.5660 - val_loss: 0.6919 - val_accuracy: 0.5000\n","Epoch 150/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6712 - accuracy: 0.5729 - val_loss: 0.6913 - val_accuracy: 0.5104\n","Epoch 151/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6651 - accuracy: 0.5972 - val_loss: 0.6920 - val_accuracy: 0.5104\n","Epoch 152/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6692 - accuracy: 0.5880 - val_loss: 0.6942 - val_accuracy: 0.5000\n","Epoch 153/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6705 - accuracy: 0.5787 - val_loss: 0.6942 - val_accuracy: 0.4896\n","Epoch 154/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6714 - accuracy: 0.5787 - val_loss: 0.6933 - val_accuracy: 0.4896\n","Epoch 155/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6704 - accuracy: 0.5729 - val_loss: 0.6926 - val_accuracy: 0.5000\n","Epoch 156/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6677 - accuracy: 0.5949 - val_loss: 0.6925 - val_accuracy: 0.5104\n","Epoch 157/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6793 - accuracy: 0.5729 - val_loss: 0.6926 - val_accuracy: 0.5000\n","Epoch 158/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6731 - accuracy: 0.5775 - val_loss: 0.6929 - val_accuracy: 0.5104\n","Epoch 159/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6626 - accuracy: 0.6030 - val_loss: 0.6926 - val_accuracy: 0.5104\n","Epoch 160/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6680 - accuracy: 0.5903 - val_loss: 0.6943 - val_accuracy: 0.5104\n","Epoch 161/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6644 - accuracy: 0.5891 - val_loss: 0.6948 - val_accuracy: 0.5000\n","Epoch 162/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6681 - accuracy: 0.5961 - val_loss: 0.6947 - val_accuracy: 0.5104\n","Epoch 163/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6750 - accuracy: 0.5729 - val_loss: 0.6951 - val_accuracy: 0.5000\n","Epoch 164/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6678 - accuracy: 0.5764 - val_loss: 0.6953 - val_accuracy: 0.5104\n","Epoch 165/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6644 - accuracy: 0.5972 - val_loss: 0.6949 - val_accuracy: 0.5104\n","Epoch 166/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6653 - accuracy: 0.5880 - val_loss: 0.6937 - val_accuracy: 0.5104\n","Epoch 167/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6763 - accuracy: 0.5671 - val_loss: 0.6926 - val_accuracy: 0.5104\n","Epoch 168/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6676 - accuracy: 0.5810 - val_loss: 0.6925 - val_accuracy: 0.4896\n","Epoch 169/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6656 - accuracy: 0.5880 - val_loss: 0.6927 - val_accuracy: 0.5000\n","Epoch 170/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6751 - accuracy: 0.5637 - val_loss: 0.6927 - val_accuracy: 0.4896\n","Epoch 171/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6651 - accuracy: 0.5903 - val_loss: 0.6927 - val_accuracy: 0.5000\n","Epoch 172/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6672 - accuracy: 0.5903 - val_loss: 0.6924 - val_accuracy: 0.5208\n","Epoch 173/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6616 - accuracy: 0.5972 - val_loss: 0.6923 - val_accuracy: 0.5104\n","Epoch 174/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6629 - accuracy: 0.5961 - val_loss: 0.6922 - val_accuracy: 0.5104\n","Epoch 175/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6704 - accuracy: 0.5984 - val_loss: 0.6931 - val_accuracy: 0.5208\n","Epoch 176/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6719 - accuracy: 0.5822 - val_loss: 0.6941 - val_accuracy: 0.5312\n","Epoch 177/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6749 - accuracy: 0.5775 - val_loss: 0.6944 - val_accuracy: 0.5312\n","Epoch 178/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6685 - accuracy: 0.5833 - val_loss: 0.6943 - val_accuracy: 0.5312\n","Epoch 179/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6661 - accuracy: 0.5938 - val_loss: 0.6949 - val_accuracy: 0.5208\n","Epoch 180/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6569 - accuracy: 0.5972 - val_loss: 0.6943 - val_accuracy: 0.5104\n","Epoch 181/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6612 - accuracy: 0.5660 - val_loss: 0.6945 - val_accuracy: 0.5000\n","Epoch 182/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6625 - accuracy: 0.6053 - val_loss: 0.6948 - val_accuracy: 0.5104\n","Epoch 183/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6678 - accuracy: 0.5926 - val_loss: 0.6949 - val_accuracy: 0.5104\n","Epoch 184/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6563 - accuracy: 0.6053 - val_loss: 0.6948 - val_accuracy: 0.5104\n","Epoch 185/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6576 - accuracy: 0.6007 - val_loss: 0.6938 - val_accuracy: 0.5208\n","Epoch 186/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6566 - accuracy: 0.6030 - val_loss: 0.6944 - val_accuracy: 0.5208\n","Epoch 187/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6568 - accuracy: 0.5984 - val_loss: 0.6943 - val_accuracy: 0.5104\n","Epoch 188/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6684 - accuracy: 0.5903 - val_loss: 0.6949 - val_accuracy: 0.5104\n","Epoch 189/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6673 - accuracy: 0.5984 - val_loss: 0.6955 - val_accuracy: 0.5104\n","Epoch 190/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6586 - accuracy: 0.5938 - val_loss: 0.6952 - val_accuracy: 0.5104\n","Epoch 191/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6644 - accuracy: 0.5938 - val_loss: 0.6946 - val_accuracy: 0.5417\n","Epoch 192/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6677 - accuracy: 0.5775 - val_loss: 0.6946 - val_accuracy: 0.5208\n","Epoch 193/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6609 - accuracy: 0.6134 - val_loss: 0.6952 - val_accuracy: 0.5417\n","Epoch 194/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6622 - accuracy: 0.6123 - val_loss: 0.6954 - val_accuracy: 0.5312\n","Epoch 195/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6609 - accuracy: 0.5995 - val_loss: 0.6957 - val_accuracy: 0.5312\n","Epoch 196/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6632 - accuracy: 0.6088 - val_loss: 0.6940 - val_accuracy: 0.5312\n","Epoch 197/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6588 - accuracy: 0.5995 - val_loss: 0.6944 - val_accuracy: 0.5104\n","Epoch 198/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6585 - accuracy: 0.5961 - val_loss: 0.6944 - val_accuracy: 0.5000\n","Epoch 199/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6605 - accuracy: 0.6019 - val_loss: 0.6951 - val_accuracy: 0.5000\n","Epoch 200/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6584 - accuracy: 0.6019 - val_loss: 0.6948 - val_accuracy: 0.5000\n","8/8 [==============================] - 0s 10ms/step - loss: 0.6858 - accuracy: 0.5500\n","[0.6858406066894531, 0.550000011920929]\n","Results for fold 3\n","Epoch 1/200\n","14/14 [==============================] - 7s 109ms/step - loss: 0.7054 - accuracy: 0.5150 - val_loss: 0.6929 - val_accuracy: 0.5417\n","Epoch 2/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.7049 - accuracy: 0.4988 - val_loss: 0.6996 - val_accuracy: 0.5625\n","Epoch 3/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.7000 - accuracy: 0.5266 - val_loss: 0.7028 - val_accuracy: 0.5625\n","Epoch 4/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6982 - accuracy: 0.5394 - val_loss: 0.7050 - val_accuracy: 0.5625\n","Epoch 5/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6963 - accuracy: 0.5197 - val_loss: 0.7049 - val_accuracy: 0.5625\n","Epoch 6/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6941 - accuracy: 0.5336 - val_loss: 0.7035 - val_accuracy: 0.5625\n","Epoch 7/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6964 - accuracy: 0.5301 - val_loss: 0.7036 - val_accuracy: 0.5625\n","Epoch 8/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6876 - accuracy: 0.5532 - val_loss: 0.7021 - val_accuracy: 0.5625\n","Epoch 9/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6997 - accuracy: 0.5197 - val_loss: 0.6992 - val_accuracy: 0.5521\n","Epoch 10/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6977 - accuracy: 0.5278 - val_loss: 0.6984 - val_accuracy: 0.5312\n","Epoch 11/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6951 - accuracy: 0.5394 - val_loss: 0.6968 - val_accuracy: 0.5312\n","Epoch 12/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6937 - accuracy: 0.5498 - val_loss: 0.6944 - val_accuracy: 0.5312\n","Epoch 13/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6921 - accuracy: 0.5509 - val_loss: 0.6945 - val_accuracy: 0.5312\n","Epoch 14/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6894 - accuracy: 0.5532 - val_loss: 0.6967 - val_accuracy: 0.5417\n","Epoch 15/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6903 - accuracy: 0.5208 - val_loss: 0.6974 - val_accuracy: 0.5208\n","Epoch 16/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6882 - accuracy: 0.5463 - val_loss: 0.6976 - val_accuracy: 0.5312\n","Epoch 17/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.7005 - accuracy: 0.5150 - val_loss: 0.6973 - val_accuracy: 0.5208\n","Epoch 18/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6970 - accuracy: 0.5301 - val_loss: 0.6961 - val_accuracy: 0.4896\n","Epoch 19/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6798 - accuracy: 0.5613 - val_loss: 0.6941 - val_accuracy: 0.5104\n","Epoch 20/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6749 - accuracy: 0.5729 - val_loss: 0.6941 - val_accuracy: 0.4896\n","Epoch 21/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6906 - accuracy: 0.5567 - val_loss: 0.6936 - val_accuracy: 0.5104\n","Epoch 22/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6885 - accuracy: 0.5556 - val_loss: 0.6929 - val_accuracy: 0.5104\n","Epoch 23/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6967 - accuracy: 0.5104 - val_loss: 0.6926 - val_accuracy: 0.5104\n","Epoch 24/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6892 - accuracy: 0.5463 - val_loss: 0.6925 - val_accuracy: 0.5312\n","Epoch 25/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6846 - accuracy: 0.5729 - val_loss: 0.6926 - val_accuracy: 0.5312\n","Epoch 26/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6917 - accuracy: 0.5336 - val_loss: 0.6924 - val_accuracy: 0.5417\n","Epoch 27/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6940 - accuracy: 0.5243 - val_loss: 0.6933 - val_accuracy: 0.5312\n","Epoch 28/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6892 - accuracy: 0.5312 - val_loss: 0.6939 - val_accuracy: 0.5208\n","Epoch 29/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6825 - accuracy: 0.5706 - val_loss: 0.6949 - val_accuracy: 0.5312\n","Epoch 30/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6882 - accuracy: 0.5359 - val_loss: 0.6952 - val_accuracy: 0.5208\n","Epoch 31/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6891 - accuracy: 0.5463 - val_loss: 0.6945 - val_accuracy: 0.5417\n","Epoch 32/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6813 - accuracy: 0.5602 - val_loss: 0.6950 - val_accuracy: 0.5312\n","Epoch 33/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6868 - accuracy: 0.5486 - val_loss: 0.6965 - val_accuracy: 0.5312\n","Epoch 34/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6864 - accuracy: 0.5625 - val_loss: 0.6971 - val_accuracy: 0.5312\n","Epoch 35/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6809 - accuracy: 0.5671 - val_loss: 0.6967 - val_accuracy: 0.5104\n","Epoch 36/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6865 - accuracy: 0.5625 - val_loss: 0.6969 - val_accuracy: 0.5208\n","Epoch 37/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6783 - accuracy: 0.5579 - val_loss: 0.6962 - val_accuracy: 0.5000\n","Epoch 38/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6839 - accuracy: 0.5556 - val_loss: 0.6961 - val_accuracy: 0.5000\n","Epoch 39/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6881 - accuracy: 0.5521 - val_loss: 0.6952 - val_accuracy: 0.5000\n","Epoch 40/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6848 - accuracy: 0.5475 - val_loss: 0.6948 - val_accuracy: 0.5208\n","Epoch 41/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6772 - accuracy: 0.5729 - val_loss: 0.6951 - val_accuracy: 0.5104\n","Epoch 42/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6816 - accuracy: 0.5625 - val_loss: 0.6953 - val_accuracy: 0.5208\n","Epoch 43/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6845 - accuracy: 0.5660 - val_loss: 0.6952 - val_accuracy: 0.5104\n","Epoch 44/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6810 - accuracy: 0.5671 - val_loss: 0.6948 - val_accuracy: 0.5312\n","Epoch 45/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6844 - accuracy: 0.5509 - val_loss: 0.6943 - val_accuracy: 0.5312\n","Epoch 46/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6878 - accuracy: 0.5394 - val_loss: 0.6926 - val_accuracy: 0.5312\n","Epoch 47/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6833 - accuracy: 0.5602 - val_loss: 0.6921 - val_accuracy: 0.5417\n","Epoch 48/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6836 - accuracy: 0.5556 - val_loss: 0.6918 - val_accuracy: 0.5208\n","Epoch 49/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6892 - accuracy: 0.5394 - val_loss: 0.6914 - val_accuracy: 0.5104\n","Epoch 50/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6832 - accuracy: 0.5613 - val_loss: 0.6912 - val_accuracy: 0.5208\n","Epoch 51/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6826 - accuracy: 0.5729 - val_loss: 0.6912 - val_accuracy: 0.5208\n","Epoch 52/200\n","14/14 [==============================] - 0s 22ms/step - loss: 0.6849 - accuracy: 0.5451 - val_loss: 0.6911 - val_accuracy: 0.5208\n","Epoch 53/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6843 - accuracy: 0.5532 - val_loss: 0.6912 - val_accuracy: 0.5104\n","Epoch 54/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6824 - accuracy: 0.5590 - val_loss: 0.6918 - val_accuracy: 0.5104\n","Epoch 55/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6903 - accuracy: 0.5498 - val_loss: 0.6918 - val_accuracy: 0.5104\n","Epoch 56/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6824 - accuracy: 0.5810 - val_loss: 0.6920 - val_accuracy: 0.5417\n","Epoch 57/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6849 - accuracy: 0.5498 - val_loss: 0.6931 - val_accuracy: 0.5312\n","Epoch 58/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6778 - accuracy: 0.5602 - val_loss: 0.6938 - val_accuracy: 0.5208\n","Epoch 59/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6765 - accuracy: 0.5868 - val_loss: 0.6930 - val_accuracy: 0.5312\n","Epoch 60/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6861 - accuracy: 0.5694 - val_loss: 0.6919 - val_accuracy: 0.5104\n","Epoch 61/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6825 - accuracy: 0.5741 - val_loss: 0.6916 - val_accuracy: 0.5104\n","Epoch 62/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6875 - accuracy: 0.5417 - val_loss: 0.6913 - val_accuracy: 0.5104\n","Epoch 63/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6827 - accuracy: 0.5706 - val_loss: 0.6907 - val_accuracy: 0.5312\n","Epoch 64/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6868 - accuracy: 0.5544 - val_loss: 0.6902 - val_accuracy: 0.5312\n","Epoch 65/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6785 - accuracy: 0.5521 - val_loss: 0.6911 - val_accuracy: 0.5000\n","Epoch 66/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6895 - accuracy: 0.5336 - val_loss: 0.6913 - val_accuracy: 0.5000\n","Epoch 67/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6775 - accuracy: 0.5880 - val_loss: 0.6916 - val_accuracy: 0.5000\n","Epoch 68/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6828 - accuracy: 0.5637 - val_loss: 0.6916 - val_accuracy: 0.4896\n","Epoch 69/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6743 - accuracy: 0.5637 - val_loss: 0.6918 - val_accuracy: 0.4896\n","Epoch 70/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6828 - accuracy: 0.5822 - val_loss: 0.6912 - val_accuracy: 0.5104\n","Epoch 71/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6850 - accuracy: 0.5509 - val_loss: 0.6908 - val_accuracy: 0.4896\n","Epoch 72/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6807 - accuracy: 0.5579 - val_loss: 0.6908 - val_accuracy: 0.5000\n","Epoch 73/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6788 - accuracy: 0.5845 - val_loss: 0.6902 - val_accuracy: 0.5104\n","Epoch 74/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6796 - accuracy: 0.5683 - val_loss: 0.6897 - val_accuracy: 0.5104\n","Epoch 75/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6837 - accuracy: 0.5613 - val_loss: 0.6899 - val_accuracy: 0.5000\n","Epoch 76/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6828 - accuracy: 0.5752 - val_loss: 0.6908 - val_accuracy: 0.4896\n","Epoch 77/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6799 - accuracy: 0.5822 - val_loss: 0.6916 - val_accuracy: 0.4896\n","Epoch 78/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6749 - accuracy: 0.5752 - val_loss: 0.6915 - val_accuracy: 0.5000\n","Epoch 79/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6780 - accuracy: 0.5752 - val_loss: 0.6916 - val_accuracy: 0.5000\n","Epoch 80/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6774 - accuracy: 0.5810 - val_loss: 0.6901 - val_accuracy: 0.4792\n","Epoch 81/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6771 - accuracy: 0.5741 - val_loss: 0.6894 - val_accuracy: 0.4896\n","Epoch 82/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6795 - accuracy: 0.5741 - val_loss: 0.6902 - val_accuracy: 0.4792\n","Epoch 83/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6761 - accuracy: 0.5729 - val_loss: 0.6902 - val_accuracy: 0.4792\n","Epoch 84/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6736 - accuracy: 0.5833 - val_loss: 0.6902 - val_accuracy: 0.4792\n","Epoch 85/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6797 - accuracy: 0.5683 - val_loss: 0.6901 - val_accuracy: 0.5000\n","Epoch 86/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6757 - accuracy: 0.5694 - val_loss: 0.6907 - val_accuracy: 0.5000\n","Epoch 87/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6766 - accuracy: 0.5775 - val_loss: 0.6903 - val_accuracy: 0.4896\n","Epoch 88/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6831 - accuracy: 0.5660 - val_loss: 0.6891 - val_accuracy: 0.4688\n","Epoch 89/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6778 - accuracy: 0.5949 - val_loss: 0.6888 - val_accuracy: 0.4792\n","Epoch 90/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6806 - accuracy: 0.5613 - val_loss: 0.6892 - val_accuracy: 0.4792\n","Epoch 91/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6792 - accuracy: 0.5810 - val_loss: 0.6898 - val_accuracy: 0.5000\n","Epoch 92/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6825 - accuracy: 0.5775 - val_loss: 0.6904 - val_accuracy: 0.5208\n","Epoch 93/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6861 - accuracy: 0.5637 - val_loss: 0.6897 - val_accuracy: 0.5000\n","Epoch 94/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6804 - accuracy: 0.5694 - val_loss: 0.6897 - val_accuracy: 0.5000\n","Epoch 95/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6771 - accuracy: 0.5718 - val_loss: 0.6892 - val_accuracy: 0.5104\n","Epoch 96/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6800 - accuracy: 0.5590 - val_loss: 0.6894 - val_accuracy: 0.5104\n","Epoch 97/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6728 - accuracy: 0.5718 - val_loss: 0.6895 - val_accuracy: 0.5000\n","Epoch 98/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6786 - accuracy: 0.5544 - val_loss: 0.6899 - val_accuracy: 0.5104\n","Epoch 99/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6818 - accuracy: 0.5625 - val_loss: 0.6900 - val_accuracy: 0.5000\n","Epoch 100/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6769 - accuracy: 0.5856 - val_loss: 0.6894 - val_accuracy: 0.5000\n","Epoch 101/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6735 - accuracy: 0.5775 - val_loss: 0.6892 - val_accuracy: 0.5104\n","Epoch 102/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6734 - accuracy: 0.5868 - val_loss: 0.6888 - val_accuracy: 0.5104\n","Epoch 103/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6788 - accuracy: 0.5660 - val_loss: 0.6888 - val_accuracy: 0.5104\n","Epoch 104/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6840 - accuracy: 0.5509 - val_loss: 0.6884 - val_accuracy: 0.5208\n","Epoch 105/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6733 - accuracy: 0.5775 - val_loss: 0.6886 - val_accuracy: 0.5104\n","Epoch 106/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6791 - accuracy: 0.5741 - val_loss: 0.6894 - val_accuracy: 0.5208\n","Epoch 107/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6776 - accuracy: 0.5706 - val_loss: 0.6894 - val_accuracy: 0.5208\n","Epoch 108/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6744 - accuracy: 0.5706 - val_loss: 0.6888 - val_accuracy: 0.5104\n","Epoch 109/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6787 - accuracy: 0.5590 - val_loss: 0.6884 - val_accuracy: 0.5208\n","Epoch 110/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6791 - accuracy: 0.5741 - val_loss: 0.6876 - val_accuracy: 0.5208\n","Epoch 111/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6647 - accuracy: 0.5914 - val_loss: 0.6877 - val_accuracy: 0.5208\n","Epoch 112/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6743 - accuracy: 0.5764 - val_loss: 0.6872 - val_accuracy: 0.5208\n","Epoch 113/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6794 - accuracy: 0.5613 - val_loss: 0.6864 - val_accuracy: 0.5312\n","Epoch 114/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6733 - accuracy: 0.5822 - val_loss: 0.6858 - val_accuracy: 0.5104\n","Epoch 115/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6750 - accuracy: 0.5718 - val_loss: 0.6859 - val_accuracy: 0.5104\n","Epoch 116/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6725 - accuracy: 0.5845 - val_loss: 0.6866 - val_accuracy: 0.5104\n","Epoch 117/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6747 - accuracy: 0.5845 - val_loss: 0.6874 - val_accuracy: 0.4896\n","Epoch 118/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6772 - accuracy: 0.5694 - val_loss: 0.6864 - val_accuracy: 0.5104\n","Epoch 119/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6727 - accuracy: 0.5914 - val_loss: 0.6863 - val_accuracy: 0.5208\n","Epoch 120/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6836 - accuracy: 0.5532 - val_loss: 0.6861 - val_accuracy: 0.5312\n","Epoch 121/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6722 - accuracy: 0.5914 - val_loss: 0.6864 - val_accuracy: 0.5208\n","Epoch 122/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6787 - accuracy: 0.5856 - val_loss: 0.6861 - val_accuracy: 0.5312\n","Epoch 123/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6688 - accuracy: 0.5625 - val_loss: 0.6861 - val_accuracy: 0.5312\n","Epoch 124/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6715 - accuracy: 0.5856 - val_loss: 0.6860 - val_accuracy: 0.5000\n","Epoch 125/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6845 - accuracy: 0.5521 - val_loss: 0.6871 - val_accuracy: 0.4896\n","Epoch 126/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6713 - accuracy: 0.5891 - val_loss: 0.6876 - val_accuracy: 0.4792\n","Epoch 127/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6749 - accuracy: 0.5833 - val_loss: 0.6884 - val_accuracy: 0.4688\n","Epoch 128/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6725 - accuracy: 0.5984 - val_loss: 0.6878 - val_accuracy: 0.4688\n","Epoch 129/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6772 - accuracy: 0.5903 - val_loss: 0.6887 - val_accuracy: 0.4688\n","Epoch 130/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6757 - accuracy: 0.5752 - val_loss: 0.6887 - val_accuracy: 0.4688\n","Epoch 131/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6702 - accuracy: 0.5880 - val_loss: 0.6878 - val_accuracy: 0.4792\n","Epoch 132/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6751 - accuracy: 0.5718 - val_loss: 0.6875 - val_accuracy: 0.5104\n","Epoch 133/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6765 - accuracy: 0.5706 - val_loss: 0.6871 - val_accuracy: 0.5104\n","Epoch 134/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6787 - accuracy: 0.5787 - val_loss: 0.6872 - val_accuracy: 0.5208\n","Epoch 135/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6746 - accuracy: 0.5810 - val_loss: 0.6870 - val_accuracy: 0.5208\n","Epoch 136/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6808 - accuracy: 0.5752 - val_loss: 0.6874 - val_accuracy: 0.5312\n","Epoch 137/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6697 - accuracy: 0.5822 - val_loss: 0.6884 - val_accuracy: 0.5312\n","Epoch 138/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6693 - accuracy: 0.5891 - val_loss: 0.6884 - val_accuracy: 0.5208\n","Epoch 139/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6743 - accuracy: 0.5752 - val_loss: 0.6891 - val_accuracy: 0.5208\n","Epoch 140/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6682 - accuracy: 0.5833 - val_loss: 0.6898 - val_accuracy: 0.5208\n","Epoch 141/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6743 - accuracy: 0.5787 - val_loss: 0.6911 - val_accuracy: 0.5312\n","Epoch 142/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6680 - accuracy: 0.5799 - val_loss: 0.6923 - val_accuracy: 0.5104\n","Epoch 143/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6723 - accuracy: 0.5752 - val_loss: 0.6914 - val_accuracy: 0.5208\n","Epoch 144/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6713 - accuracy: 0.5787 - val_loss: 0.6907 - val_accuracy: 0.5312\n","Epoch 145/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6703 - accuracy: 0.5706 - val_loss: 0.6907 - val_accuracy: 0.5312\n","Epoch 146/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6734 - accuracy: 0.5833 - val_loss: 0.6909 - val_accuracy: 0.5208\n","Epoch 147/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6686 - accuracy: 0.6076 - val_loss: 0.6923 - val_accuracy: 0.5208\n","Epoch 148/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6677 - accuracy: 0.5868 - val_loss: 0.6929 - val_accuracy: 0.5104\n","Epoch 149/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6742 - accuracy: 0.5764 - val_loss: 0.6934 - val_accuracy: 0.5208\n","Epoch 150/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6676 - accuracy: 0.5822 - val_loss: 0.6937 - val_accuracy: 0.5208\n","Epoch 151/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6753 - accuracy: 0.5752 - val_loss: 0.6932 - val_accuracy: 0.5208\n","Epoch 152/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6669 - accuracy: 0.5833 - val_loss: 0.6930 - val_accuracy: 0.5104\n","Epoch 153/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6699 - accuracy: 0.5903 - val_loss: 0.6923 - val_accuracy: 0.5208\n","Epoch 154/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6693 - accuracy: 0.5706 - val_loss: 0.6924 - val_accuracy: 0.5208\n","Epoch 155/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6708 - accuracy: 0.5810 - val_loss: 0.6913 - val_accuracy: 0.5208\n","Epoch 156/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6688 - accuracy: 0.6019 - val_loss: 0.6911 - val_accuracy: 0.5208\n","Epoch 157/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6638 - accuracy: 0.6111 - val_loss: 0.6905 - val_accuracy: 0.5208\n","Epoch 158/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6651 - accuracy: 0.6007 - val_loss: 0.6905 - val_accuracy: 0.5104\n","Epoch 159/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6602 - accuracy: 0.5903 - val_loss: 0.6910 - val_accuracy: 0.5104\n","Epoch 160/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6680 - accuracy: 0.5856 - val_loss: 0.6915 - val_accuracy: 0.5104\n","Epoch 161/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6693 - accuracy: 0.5880 - val_loss: 0.6912 - val_accuracy: 0.5000\n","Epoch 162/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6735 - accuracy: 0.5683 - val_loss: 0.6907 - val_accuracy: 0.5000\n","Epoch 163/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6687 - accuracy: 0.5903 - val_loss: 0.6900 - val_accuracy: 0.4896\n","Epoch 164/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6627 - accuracy: 0.5880 - val_loss: 0.6896 - val_accuracy: 0.4896\n","Epoch 165/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6675 - accuracy: 0.5903 - val_loss: 0.6898 - val_accuracy: 0.5104\n","Epoch 166/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6672 - accuracy: 0.5741 - val_loss: 0.6906 - val_accuracy: 0.4792\n","Epoch 167/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6716 - accuracy: 0.5694 - val_loss: 0.6905 - val_accuracy: 0.5000\n","Epoch 168/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6694 - accuracy: 0.5833 - val_loss: 0.6904 - val_accuracy: 0.5104\n","Epoch 169/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6698 - accuracy: 0.5775 - val_loss: 0.6904 - val_accuracy: 0.5104\n","Epoch 170/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6691 - accuracy: 0.6007 - val_loss: 0.6919 - val_accuracy: 0.5104\n","Epoch 171/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6657 - accuracy: 0.5938 - val_loss: 0.6908 - val_accuracy: 0.4896\n","Epoch 172/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6691 - accuracy: 0.5822 - val_loss: 0.6913 - val_accuracy: 0.4792\n","Epoch 173/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6672 - accuracy: 0.5972 - val_loss: 0.6922 - val_accuracy: 0.5000\n","Epoch 174/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6688 - accuracy: 0.5938 - val_loss: 0.6927 - val_accuracy: 0.5000\n","Epoch 175/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6686 - accuracy: 0.5775 - val_loss: 0.6921 - val_accuracy: 0.5000\n","Epoch 176/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6637 - accuracy: 0.5961 - val_loss: 0.6911 - val_accuracy: 0.5000\n","Epoch 177/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6653 - accuracy: 0.5949 - val_loss: 0.6906 - val_accuracy: 0.5104\n","Epoch 178/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6610 - accuracy: 0.6042 - val_loss: 0.6897 - val_accuracy: 0.5104\n","Epoch 179/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6647 - accuracy: 0.5914 - val_loss: 0.6893 - val_accuracy: 0.5417\n","Epoch 180/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6648 - accuracy: 0.6007 - val_loss: 0.6894 - val_accuracy: 0.5417\n","Epoch 181/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6672 - accuracy: 0.5868 - val_loss: 0.6895 - val_accuracy: 0.5417\n","Epoch 182/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6647 - accuracy: 0.6007 - val_loss: 0.6887 - val_accuracy: 0.5417\n","Epoch 183/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6645 - accuracy: 0.5775 - val_loss: 0.6898 - val_accuracy: 0.5521\n","Epoch 184/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6708 - accuracy: 0.5729 - val_loss: 0.6886 - val_accuracy: 0.5312\n","Epoch 185/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6647 - accuracy: 0.5926 - val_loss: 0.6886 - val_accuracy: 0.5312\n","Epoch 186/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6707 - accuracy: 0.5741 - val_loss: 0.6882 - val_accuracy: 0.5312\n","Epoch 187/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6620 - accuracy: 0.6007 - val_loss: 0.6879 - val_accuracy: 0.5208\n","Epoch 188/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6629 - accuracy: 0.5961 - val_loss: 0.6879 - val_accuracy: 0.5312\n","Epoch 189/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6625 - accuracy: 0.5961 - val_loss: 0.6875 - val_accuracy: 0.5312\n","Epoch 190/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6683 - accuracy: 0.5972 - val_loss: 0.6884 - val_accuracy: 0.5312\n","Epoch 191/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6604 - accuracy: 0.6238 - val_loss: 0.6875 - val_accuracy: 0.5312\n","Epoch 192/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6609 - accuracy: 0.5880 - val_loss: 0.6884 - val_accuracy: 0.5312\n","Epoch 193/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6635 - accuracy: 0.5868 - val_loss: 0.6884 - val_accuracy: 0.5312\n","Epoch 194/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6726 - accuracy: 0.5764 - val_loss: 0.6883 - val_accuracy: 0.5312\n","Epoch 195/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6613 - accuracy: 0.6007 - val_loss: 0.6867 - val_accuracy: 0.5208\n","Epoch 196/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6637 - accuracy: 0.6088 - val_loss: 0.6869 - val_accuracy: 0.5208\n","Epoch 197/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6664 - accuracy: 0.6157 - val_loss: 0.6865 - val_accuracy: 0.5104\n","Epoch 198/200\n","14/14 [==============================] - 0s 23ms/step - loss: 0.6732 - accuracy: 0.5845 - val_loss: 0.6853 - val_accuracy: 0.5000\n","Epoch 199/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6572 - accuracy: 0.6100 - val_loss: 0.6859 - val_accuracy: 0.5104\n","Epoch 200/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6607 - accuracy: 0.6146 - val_loss: 0.6854 - val_accuracy: 0.5000\n","8/8 [==============================] - 0s 11ms/step - loss: 0.6808 - accuracy: 0.5625\n","[0.6807918548583984, 0.5625]\n","Results for fold 4\n","Epoch 1/200\n","14/14 [==============================] - 7s 110ms/step - loss: 0.7415 - accuracy: 0.4699 - val_loss: 0.7001 - val_accuracy: 0.5000\n","Epoch 2/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.7284 - accuracy: 0.4803 - val_loss: 0.6945 - val_accuracy: 0.5729\n","Epoch 3/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.7177 - accuracy: 0.5046 - val_loss: 0.6950 - val_accuracy: 0.5729\n","Epoch 4/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.7004 - accuracy: 0.5475 - val_loss: 0.6941 - val_accuracy: 0.5729\n","Epoch 5/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.7154 - accuracy: 0.5197 - val_loss: 0.6940 - val_accuracy: 0.5729\n","Epoch 6/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.7202 - accuracy: 0.4954 - val_loss: 0.6906 - val_accuracy: 0.5729\n","Epoch 7/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.7051 - accuracy: 0.5266 - val_loss: 0.6876 - val_accuracy: 0.5729\n","Epoch 8/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.7025 - accuracy: 0.5266 - val_loss: 0.6847 - val_accuracy: 0.5729\n","Epoch 9/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6972 - accuracy: 0.5475 - val_loss: 0.6877 - val_accuracy: 0.5729\n","Epoch 10/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.7067 - accuracy: 0.5440 - val_loss: 0.6869 - val_accuracy: 0.5729\n","Epoch 11/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6988 - accuracy: 0.5347 - val_loss: 0.6845 - val_accuracy: 0.5729\n","Epoch 12/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6993 - accuracy: 0.5347 - val_loss: 0.6839 - val_accuracy: 0.5729\n","Epoch 13/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6909 - accuracy: 0.5602 - val_loss: 0.6831 - val_accuracy: 0.5729\n","Epoch 14/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6932 - accuracy: 0.5567 - val_loss: 0.6841 - val_accuracy: 0.5625\n","Epoch 15/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.7132 - accuracy: 0.5150 - val_loss: 0.6827 - val_accuracy: 0.5625\n","Epoch 16/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.7007 - accuracy: 0.5243 - val_loss: 0.6832 - val_accuracy: 0.5625\n","Epoch 17/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6848 - accuracy: 0.5613 - val_loss: 0.6817 - val_accuracy: 0.5625\n","Epoch 18/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6899 - accuracy: 0.5428 - val_loss: 0.6806 - val_accuracy: 0.5729\n","Epoch 19/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6962 - accuracy: 0.5567 - val_loss: 0.6789 - val_accuracy: 0.5729\n","Epoch 20/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.7032 - accuracy: 0.5590 - val_loss: 0.6783 - val_accuracy: 0.6042\n","Epoch 21/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6995 - accuracy: 0.5405 - val_loss: 0.6780 - val_accuracy: 0.5938\n","Epoch 22/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6885 - accuracy: 0.5451 - val_loss: 0.6777 - val_accuracy: 0.5938\n","Epoch 23/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.7023 - accuracy: 0.5336 - val_loss: 0.6772 - val_accuracy: 0.5938\n","Epoch 24/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6866 - accuracy: 0.5498 - val_loss: 0.6766 - val_accuracy: 0.5938\n","Epoch 25/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.7023 - accuracy: 0.5312 - val_loss: 0.6764 - val_accuracy: 0.6042\n","Epoch 26/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6901 - accuracy: 0.5498 - val_loss: 0.6766 - val_accuracy: 0.6042\n","Epoch 27/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6930 - accuracy: 0.5671 - val_loss: 0.6764 - val_accuracy: 0.5833\n","Epoch 28/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6999 - accuracy: 0.5359 - val_loss: 0.6769 - val_accuracy: 0.5833\n","Epoch 29/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.7001 - accuracy: 0.5405 - val_loss: 0.6749 - val_accuracy: 0.6042\n","Epoch 30/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6931 - accuracy: 0.5428 - val_loss: 0.6753 - val_accuracy: 0.6042\n","Epoch 31/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.7063 - accuracy: 0.5116 - val_loss: 0.6745 - val_accuracy: 0.5833\n","Epoch 32/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6949 - accuracy: 0.5405 - val_loss: 0.6727 - val_accuracy: 0.6042\n","Epoch 33/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6964 - accuracy: 0.5382 - val_loss: 0.6732 - val_accuracy: 0.6042\n","Epoch 34/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6892 - accuracy: 0.5579 - val_loss: 0.6736 - val_accuracy: 0.5729\n","Epoch 35/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6865 - accuracy: 0.5694 - val_loss: 0.6725 - val_accuracy: 0.5729\n","Epoch 36/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6915 - accuracy: 0.5301 - val_loss: 0.6719 - val_accuracy: 0.5729\n","Epoch 37/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6806 - accuracy: 0.5775 - val_loss: 0.6717 - val_accuracy: 0.5729\n","Epoch 38/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6847 - accuracy: 0.5683 - val_loss: 0.6729 - val_accuracy: 0.5729\n","Epoch 39/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6915 - accuracy: 0.5301 - val_loss: 0.6728 - val_accuracy: 0.5729\n","Epoch 40/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6858 - accuracy: 0.5532 - val_loss: 0.6711 - val_accuracy: 0.5833\n","Epoch 41/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6845 - accuracy: 0.5347 - val_loss: 0.6710 - val_accuracy: 0.5729\n","Epoch 42/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6961 - accuracy: 0.5382 - val_loss: 0.6705 - val_accuracy: 0.5833\n","Epoch 43/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6886 - accuracy: 0.5660 - val_loss: 0.6719 - val_accuracy: 0.5833\n","Epoch 44/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6899 - accuracy: 0.5602 - val_loss: 0.6713 - val_accuracy: 0.6146\n","Epoch 45/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6903 - accuracy: 0.5567 - val_loss: 0.6712 - val_accuracy: 0.6042\n","Epoch 46/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6866 - accuracy: 0.5625 - val_loss: 0.6714 - val_accuracy: 0.5938\n","Epoch 47/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6890 - accuracy: 0.5590 - val_loss: 0.6703 - val_accuracy: 0.6146\n","Epoch 48/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6963 - accuracy: 0.5451 - val_loss: 0.6712 - val_accuracy: 0.6042\n","Epoch 49/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6890 - accuracy: 0.5370 - val_loss: 0.6717 - val_accuracy: 0.5833\n","Epoch 50/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6774 - accuracy: 0.5671 - val_loss: 0.6717 - val_accuracy: 0.5833\n","Epoch 51/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6807 - accuracy: 0.5694 - val_loss: 0.6727 - val_accuracy: 0.5729\n","Epoch 52/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6903 - accuracy: 0.5278 - val_loss: 0.6723 - val_accuracy: 0.5833\n","Epoch 53/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6928 - accuracy: 0.5428 - val_loss: 0.6719 - val_accuracy: 0.5833\n","Epoch 54/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6872 - accuracy: 0.5590 - val_loss: 0.6718 - val_accuracy: 0.5833\n","Epoch 55/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6906 - accuracy: 0.5532 - val_loss: 0.6708 - val_accuracy: 0.5938\n","Epoch 56/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6843 - accuracy: 0.5637 - val_loss: 0.6705 - val_accuracy: 0.6146\n","Epoch 57/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6770 - accuracy: 0.5694 - val_loss: 0.6699 - val_accuracy: 0.6146\n","Epoch 58/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6863 - accuracy: 0.5567 - val_loss: 0.6692 - val_accuracy: 0.6146\n","Epoch 59/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6891 - accuracy: 0.5382 - val_loss: 0.6693 - val_accuracy: 0.6146\n","Epoch 60/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6824 - accuracy: 0.5718 - val_loss: 0.6706 - val_accuracy: 0.6042\n","Epoch 61/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6842 - accuracy: 0.5718 - val_loss: 0.6698 - val_accuracy: 0.5938\n","Epoch 62/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6815 - accuracy: 0.5602 - val_loss: 0.6692 - val_accuracy: 0.6146\n","Epoch 63/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6927 - accuracy: 0.5475 - val_loss: 0.6700 - val_accuracy: 0.5833\n","Epoch 64/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6875 - accuracy: 0.5532 - val_loss: 0.6696 - val_accuracy: 0.6042\n","Epoch 65/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6967 - accuracy: 0.5451 - val_loss: 0.6692 - val_accuracy: 0.6042\n","Epoch 66/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6875 - accuracy: 0.5567 - val_loss: 0.6695 - val_accuracy: 0.5938\n","Epoch 67/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6917 - accuracy: 0.5405 - val_loss: 0.6676 - val_accuracy: 0.6250\n","Epoch 68/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6828 - accuracy: 0.5590 - val_loss: 0.6675 - val_accuracy: 0.6146\n","Epoch 69/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6763 - accuracy: 0.5671 - val_loss: 0.6678 - val_accuracy: 0.6042\n","Epoch 70/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6897 - accuracy: 0.5625 - val_loss: 0.6683 - val_accuracy: 0.6250\n","Epoch 71/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6815 - accuracy: 0.5625 - val_loss: 0.6684 - val_accuracy: 0.6146\n","Epoch 72/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6842 - accuracy: 0.5799 - val_loss: 0.6685 - val_accuracy: 0.6146\n","Epoch 73/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6866 - accuracy: 0.5544 - val_loss: 0.6688 - val_accuracy: 0.5833\n","Epoch 74/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6874 - accuracy: 0.5775 - val_loss: 0.6689 - val_accuracy: 0.5833\n","Epoch 75/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6737 - accuracy: 0.5833 - val_loss: 0.6699 - val_accuracy: 0.5833\n","Epoch 76/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6898 - accuracy: 0.5405 - val_loss: 0.6691 - val_accuracy: 0.5938\n","Epoch 77/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6803 - accuracy: 0.5660 - val_loss: 0.6701 - val_accuracy: 0.5833\n","Epoch 78/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6827 - accuracy: 0.5648 - val_loss: 0.6696 - val_accuracy: 0.5938\n","Epoch 79/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6817 - accuracy: 0.5451 - val_loss: 0.6690 - val_accuracy: 0.5938\n","Epoch 80/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6887 - accuracy: 0.5498 - val_loss: 0.6686 - val_accuracy: 0.5938\n","Epoch 81/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6853 - accuracy: 0.5602 - val_loss: 0.6675 - val_accuracy: 0.6042\n","Epoch 82/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6894 - accuracy: 0.5590 - val_loss: 0.6669 - val_accuracy: 0.6042\n","Epoch 83/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6820 - accuracy: 0.5567 - val_loss: 0.6664 - val_accuracy: 0.6042\n","Epoch 84/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6885 - accuracy: 0.5475 - val_loss: 0.6674 - val_accuracy: 0.5833\n","Epoch 85/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6823 - accuracy: 0.5683 - val_loss: 0.6671 - val_accuracy: 0.5938\n","Epoch 86/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6845 - accuracy: 0.5810 - val_loss: 0.6657 - val_accuracy: 0.6042\n","Epoch 87/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6782 - accuracy: 0.5729 - val_loss: 0.6657 - val_accuracy: 0.6146\n","Epoch 88/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6835 - accuracy: 0.5532 - val_loss: 0.6655 - val_accuracy: 0.6250\n","Epoch 89/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6849 - accuracy: 0.5602 - val_loss: 0.6643 - val_accuracy: 0.6250\n","Epoch 90/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6847 - accuracy: 0.5475 - val_loss: 0.6642 - val_accuracy: 0.6250\n","Epoch 91/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6828 - accuracy: 0.5579 - val_loss: 0.6646 - val_accuracy: 0.6250\n","Epoch 92/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6905 - accuracy: 0.5509 - val_loss: 0.6638 - val_accuracy: 0.6146\n","Epoch 93/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6832 - accuracy: 0.5475 - val_loss: 0.6638 - val_accuracy: 0.6146\n","Epoch 94/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6860 - accuracy: 0.5567 - val_loss: 0.6638 - val_accuracy: 0.6146\n","Epoch 95/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6782 - accuracy: 0.5729 - val_loss: 0.6640 - val_accuracy: 0.6146\n","Epoch 96/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6824 - accuracy: 0.5613 - val_loss: 0.6641 - val_accuracy: 0.6146\n","Epoch 97/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6833 - accuracy: 0.5637 - val_loss: 0.6634 - val_accuracy: 0.6250\n","Epoch 98/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6847 - accuracy: 0.5752 - val_loss: 0.6635 - val_accuracy: 0.6354\n","Epoch 99/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6810 - accuracy: 0.5787 - val_loss: 0.6637 - val_accuracy: 0.6458\n","Epoch 100/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6841 - accuracy: 0.5428 - val_loss: 0.6647 - val_accuracy: 0.6354\n","Epoch 101/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6793 - accuracy: 0.5787 - val_loss: 0.6650 - val_accuracy: 0.6250\n","Epoch 102/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6853 - accuracy: 0.5694 - val_loss: 0.6650 - val_accuracy: 0.6354\n","Epoch 103/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6796 - accuracy: 0.5718 - val_loss: 0.6649 - val_accuracy: 0.6354\n","Epoch 104/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6744 - accuracy: 0.5891 - val_loss: 0.6642 - val_accuracy: 0.6458\n","Epoch 105/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6882 - accuracy: 0.5590 - val_loss: 0.6646 - val_accuracy: 0.6458\n","Epoch 106/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6789 - accuracy: 0.5787 - val_loss: 0.6649 - val_accuracy: 0.6458\n","Epoch 107/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6782 - accuracy: 0.5741 - val_loss: 0.6651 - val_accuracy: 0.6458\n","Epoch 108/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6806 - accuracy: 0.5868 - val_loss: 0.6640 - val_accuracy: 0.6458\n","Epoch 109/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6792 - accuracy: 0.5590 - val_loss: 0.6643 - val_accuracy: 0.6250\n","Epoch 110/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6858 - accuracy: 0.5556 - val_loss: 0.6646 - val_accuracy: 0.6250\n","Epoch 111/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6761 - accuracy: 0.5880 - val_loss: 0.6639 - val_accuracy: 0.6562\n","Epoch 112/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6857 - accuracy: 0.5556 - val_loss: 0.6641 - val_accuracy: 0.6146\n","Epoch 113/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6849 - accuracy: 0.5509 - val_loss: 0.6648 - val_accuracy: 0.6042\n","Epoch 114/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6796 - accuracy: 0.5694 - val_loss: 0.6643 - val_accuracy: 0.6250\n","Epoch 115/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6798 - accuracy: 0.5579 - val_loss: 0.6658 - val_accuracy: 0.6042\n","Epoch 116/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6821 - accuracy: 0.5845 - val_loss: 0.6651 - val_accuracy: 0.6146\n","Epoch 117/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6798 - accuracy: 0.5671 - val_loss: 0.6651 - val_accuracy: 0.6146\n","Epoch 118/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6794 - accuracy: 0.5764 - val_loss: 0.6645 - val_accuracy: 0.6250\n","Epoch 119/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6794 - accuracy: 0.5532 - val_loss: 0.6658 - val_accuracy: 0.6250\n","Epoch 120/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6811 - accuracy: 0.5579 - val_loss: 0.6663 - val_accuracy: 0.6146\n","Epoch 121/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6758 - accuracy: 0.5984 - val_loss: 0.6664 - val_accuracy: 0.6042\n","Epoch 122/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6736 - accuracy: 0.5810 - val_loss: 0.6680 - val_accuracy: 0.5833\n","Epoch 123/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6848 - accuracy: 0.5683 - val_loss: 0.6672 - val_accuracy: 0.5938\n","Epoch 124/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6713 - accuracy: 0.5845 - val_loss: 0.6664 - val_accuracy: 0.6042\n","Epoch 125/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6764 - accuracy: 0.5671 - val_loss: 0.6667 - val_accuracy: 0.6146\n","Epoch 126/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6833 - accuracy: 0.5660 - val_loss: 0.6664 - val_accuracy: 0.6146\n","Epoch 127/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6821 - accuracy: 0.5775 - val_loss: 0.6657 - val_accuracy: 0.6146\n","Epoch 128/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6764 - accuracy: 0.5718 - val_loss: 0.6645 - val_accuracy: 0.6250\n","Epoch 129/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6738 - accuracy: 0.5891 - val_loss: 0.6649 - val_accuracy: 0.6146\n","Epoch 130/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6805 - accuracy: 0.5509 - val_loss: 0.6650 - val_accuracy: 0.6042\n","Epoch 131/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6775 - accuracy: 0.5637 - val_loss: 0.6644 - val_accuracy: 0.6042\n","Epoch 132/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6749 - accuracy: 0.5752 - val_loss: 0.6640 - val_accuracy: 0.6250\n","Epoch 133/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6729 - accuracy: 0.5752 - val_loss: 0.6645 - val_accuracy: 0.6250\n","Epoch 134/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6750 - accuracy: 0.5706 - val_loss: 0.6644 - val_accuracy: 0.6250\n","Epoch 135/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6826 - accuracy: 0.5463 - val_loss: 0.6631 - val_accuracy: 0.6250\n","Epoch 136/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6732 - accuracy: 0.5764 - val_loss: 0.6636 - val_accuracy: 0.6250\n","Epoch 137/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6791 - accuracy: 0.5741 - val_loss: 0.6635 - val_accuracy: 0.6354\n","Epoch 138/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6713 - accuracy: 0.5833 - val_loss: 0.6623 - val_accuracy: 0.6562\n","Epoch 139/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6760 - accuracy: 0.5764 - val_loss: 0.6617 - val_accuracy: 0.6458\n","Epoch 140/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6736 - accuracy: 0.5648 - val_loss: 0.6617 - val_accuracy: 0.6562\n","Epoch 141/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6763 - accuracy: 0.5694 - val_loss: 0.6608 - val_accuracy: 0.6458\n","Epoch 142/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6823 - accuracy: 0.5764 - val_loss: 0.6602 - val_accuracy: 0.6458\n","Epoch 143/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6768 - accuracy: 0.5625 - val_loss: 0.6606 - val_accuracy: 0.6562\n","Epoch 144/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6762 - accuracy: 0.5752 - val_loss: 0.6618 - val_accuracy: 0.6562\n","Epoch 145/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6760 - accuracy: 0.5822 - val_loss: 0.6616 - val_accuracy: 0.6458\n","Epoch 146/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6740 - accuracy: 0.5856 - val_loss: 0.6609 - val_accuracy: 0.6458\n","Epoch 147/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6729 - accuracy: 0.5752 - val_loss: 0.6598 - val_accuracy: 0.6354\n","Epoch 148/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6765 - accuracy: 0.5810 - val_loss: 0.6594 - val_accuracy: 0.6354\n","Epoch 149/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6719 - accuracy: 0.5764 - val_loss: 0.6594 - val_accuracy: 0.6354\n","Epoch 150/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6798 - accuracy: 0.5729 - val_loss: 0.6602 - val_accuracy: 0.6250\n","Epoch 151/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6744 - accuracy: 0.5822 - val_loss: 0.6604 - val_accuracy: 0.6458\n","Epoch 152/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6705 - accuracy: 0.5833 - val_loss: 0.6616 - val_accuracy: 0.6458\n","Epoch 153/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6790 - accuracy: 0.5521 - val_loss: 0.6617 - val_accuracy: 0.6354\n","Epoch 154/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6692 - accuracy: 0.5926 - val_loss: 0.6613 - val_accuracy: 0.6458\n","Epoch 155/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6761 - accuracy: 0.5799 - val_loss: 0.6609 - val_accuracy: 0.6458\n","Epoch 156/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6700 - accuracy: 0.5880 - val_loss: 0.6613 - val_accuracy: 0.6562\n","Epoch 157/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6788 - accuracy: 0.5579 - val_loss: 0.6603 - val_accuracy: 0.6146\n","Epoch 158/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6729 - accuracy: 0.5694 - val_loss: 0.6600 - val_accuracy: 0.6458\n","Epoch 159/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6724 - accuracy: 0.5938 - val_loss: 0.6607 - val_accuracy: 0.6146\n","Epoch 160/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6756 - accuracy: 0.5880 - val_loss: 0.6610 - val_accuracy: 0.6250\n","Epoch 161/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6766 - accuracy: 0.5637 - val_loss: 0.6608 - val_accuracy: 0.6042\n","Epoch 162/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6702 - accuracy: 0.5891 - val_loss: 0.6617 - val_accuracy: 0.6250\n","Epoch 163/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6750 - accuracy: 0.5856 - val_loss: 0.6612 - val_accuracy: 0.6042\n","Epoch 164/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6841 - accuracy: 0.5602 - val_loss: 0.6598 - val_accuracy: 0.5938\n","Epoch 165/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6776 - accuracy: 0.5787 - val_loss: 0.6608 - val_accuracy: 0.5938\n","Epoch 166/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6639 - accuracy: 0.6111 - val_loss: 0.6619 - val_accuracy: 0.6146\n","Epoch 167/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6714 - accuracy: 0.5752 - val_loss: 0.6619 - val_accuracy: 0.6354\n","Epoch 168/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6690 - accuracy: 0.5822 - val_loss: 0.6632 - val_accuracy: 0.6250\n","Epoch 169/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6710 - accuracy: 0.5891 - val_loss: 0.6617 - val_accuracy: 0.6146\n","Epoch 170/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6761 - accuracy: 0.5671 - val_loss: 0.6607 - val_accuracy: 0.6042\n","Epoch 171/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6667 - accuracy: 0.6053 - val_loss: 0.6601 - val_accuracy: 0.6354\n","Epoch 172/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6673 - accuracy: 0.6019 - val_loss: 0.6592 - val_accuracy: 0.6250\n","Epoch 173/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6752 - accuracy: 0.5729 - val_loss: 0.6599 - val_accuracy: 0.6042\n","Epoch 174/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6700 - accuracy: 0.5752 - val_loss: 0.6612 - val_accuracy: 0.6042\n","Epoch 175/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6683 - accuracy: 0.5845 - val_loss: 0.6606 - val_accuracy: 0.6146\n","Epoch 176/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6718 - accuracy: 0.5787 - val_loss: 0.6598 - val_accuracy: 0.6042\n","Epoch 177/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6705 - accuracy: 0.5938 - val_loss: 0.6585 - val_accuracy: 0.6146\n","Epoch 178/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6702 - accuracy: 0.6007 - val_loss: 0.6579 - val_accuracy: 0.6042\n","Epoch 179/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6734 - accuracy: 0.5891 - val_loss: 0.6577 - val_accuracy: 0.6250\n","Epoch 180/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6776 - accuracy: 0.5590 - val_loss: 0.6581 - val_accuracy: 0.6146\n","Epoch 181/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6733 - accuracy: 0.5984 - val_loss: 0.6576 - val_accuracy: 0.6250\n","Epoch 182/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6726 - accuracy: 0.5914 - val_loss: 0.6574 - val_accuracy: 0.6146\n","Epoch 183/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6725 - accuracy: 0.5926 - val_loss: 0.6575 - val_accuracy: 0.5938\n","Epoch 184/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6753 - accuracy: 0.5914 - val_loss: 0.6572 - val_accuracy: 0.6146\n","Epoch 185/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6675 - accuracy: 0.5903 - val_loss: 0.6573 - val_accuracy: 0.6042\n","Epoch 186/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6690 - accuracy: 0.6042 - val_loss: 0.6566 - val_accuracy: 0.6146\n","Epoch 187/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6694 - accuracy: 0.5949 - val_loss: 0.6560 - val_accuracy: 0.6146\n","Epoch 188/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6797 - accuracy: 0.5556 - val_loss: 0.6561 - val_accuracy: 0.6042\n","Epoch 189/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6688 - accuracy: 0.5822 - val_loss: 0.6567 - val_accuracy: 0.6354\n","Epoch 190/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6601 - accuracy: 0.6111 - val_loss: 0.6563 - val_accuracy: 0.6250\n","Epoch 191/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6662 - accuracy: 0.5949 - val_loss: 0.6558 - val_accuracy: 0.6146\n","Epoch 192/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6713 - accuracy: 0.5752 - val_loss: 0.6551 - val_accuracy: 0.6146\n","Epoch 193/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6701 - accuracy: 0.5822 - val_loss: 0.6550 - val_accuracy: 0.6146\n","Epoch 194/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6659 - accuracy: 0.5961 - val_loss: 0.6556 - val_accuracy: 0.6250\n","Epoch 195/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6704 - accuracy: 0.5891 - val_loss: 0.6561 - val_accuracy: 0.6250\n","Epoch 196/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6675 - accuracy: 0.5995 - val_loss: 0.6569 - val_accuracy: 0.6354\n","Epoch 197/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6590 - accuracy: 0.5972 - val_loss: 0.6574 - val_accuracy: 0.6250\n","Epoch 198/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6694 - accuracy: 0.5938 - val_loss: 0.6581 - val_accuracy: 0.6146\n","Epoch 199/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6667 - accuracy: 0.5949 - val_loss: 0.6605 - val_accuracy: 0.6042\n","Epoch 200/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6643 - accuracy: 0.5961 - val_loss: 0.6603 - val_accuracy: 0.6146\n","8/8 [==============================] - 0s 12ms/step - loss: 0.6807 - accuracy: 0.5708\n","[0.680705189704895, 0.5708333253860474]\n","Results for fold 5\n","Epoch 1/200\n","14/14 [==============================] - 7s 115ms/step - loss: 0.7428 - accuracy: 0.5336 - val_loss: 0.6499 - val_accuracy: 0.6458\n","Epoch 2/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.7160 - accuracy: 0.5150 - val_loss: 0.6544 - val_accuracy: 0.6354\n","Epoch 3/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.7090 - accuracy: 0.5220 - val_loss: 0.6671 - val_accuracy: 0.6042\n","Epoch 4/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6958 - accuracy: 0.5278 - val_loss: 0.6710 - val_accuracy: 0.6042\n","Epoch 5/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.7010 - accuracy: 0.5405 - val_loss: 0.6750 - val_accuracy: 0.6146\n","Epoch 6/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6973 - accuracy: 0.5428 - val_loss: 0.6800 - val_accuracy: 0.6042\n","Epoch 7/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6909 - accuracy: 0.5301 - val_loss: 0.6795 - val_accuracy: 0.6042\n","Epoch 8/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6966 - accuracy: 0.5185 - val_loss: 0.6806 - val_accuracy: 0.6146\n","Epoch 9/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6946 - accuracy: 0.5625 - val_loss: 0.6796 - val_accuracy: 0.6146\n","Epoch 10/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6984 - accuracy: 0.5312 - val_loss: 0.6794 - val_accuracy: 0.6250\n","Epoch 11/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.7016 - accuracy: 0.5243 - val_loss: 0.6791 - val_accuracy: 0.6146\n","Epoch 12/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6982 - accuracy: 0.5509 - val_loss: 0.6791 - val_accuracy: 0.6146\n","Epoch 13/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6870 - accuracy: 0.5463 - val_loss: 0.6798 - val_accuracy: 0.6250\n","Epoch 14/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6885 - accuracy: 0.5463 - val_loss: 0.6791 - val_accuracy: 0.6146\n","Epoch 15/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6867 - accuracy: 0.5706 - val_loss: 0.6793 - val_accuracy: 0.5938\n","Epoch 16/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6902 - accuracy: 0.5347 - val_loss: 0.6778 - val_accuracy: 0.5833\n","Epoch 17/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6939 - accuracy: 0.5498 - val_loss: 0.6752 - val_accuracy: 0.5833\n","Epoch 18/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6875 - accuracy: 0.5544 - val_loss: 0.6758 - val_accuracy: 0.5729\n","Epoch 19/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6876 - accuracy: 0.5590 - val_loss: 0.6769 - val_accuracy: 0.5729\n","Epoch 20/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6953 - accuracy: 0.5220 - val_loss: 0.6760 - val_accuracy: 0.5938\n","Epoch 21/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6905 - accuracy: 0.5475 - val_loss: 0.6749 - val_accuracy: 0.5833\n","Epoch 22/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6872 - accuracy: 0.5602 - val_loss: 0.6754 - val_accuracy: 0.5938\n","Epoch 23/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6883 - accuracy: 0.5370 - val_loss: 0.6766 - val_accuracy: 0.5938\n","Epoch 24/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6899 - accuracy: 0.5486 - val_loss: 0.6767 - val_accuracy: 0.5729\n","Epoch 25/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6872 - accuracy: 0.5231 - val_loss: 0.6761 - val_accuracy: 0.6146\n","Epoch 26/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6838 - accuracy: 0.5544 - val_loss: 0.6733 - val_accuracy: 0.5938\n","Epoch 27/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6891 - accuracy: 0.5359 - val_loss: 0.6753 - val_accuracy: 0.6250\n","Epoch 28/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6938 - accuracy: 0.5382 - val_loss: 0.6785 - val_accuracy: 0.6042\n","Epoch 29/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6889 - accuracy: 0.5521 - val_loss: 0.6797 - val_accuracy: 0.6042\n","Epoch 30/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6862 - accuracy: 0.5602 - val_loss: 0.6810 - val_accuracy: 0.5938\n","Epoch 31/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6914 - accuracy: 0.5278 - val_loss: 0.6763 - val_accuracy: 0.5938\n","Epoch 32/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6808 - accuracy: 0.5637 - val_loss: 0.6739 - val_accuracy: 0.5938\n","Epoch 33/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6974 - accuracy: 0.5243 - val_loss: 0.6755 - val_accuracy: 0.5938\n","Epoch 34/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6862 - accuracy: 0.5567 - val_loss: 0.6760 - val_accuracy: 0.6042\n","Epoch 35/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6799 - accuracy: 0.5787 - val_loss: 0.6745 - val_accuracy: 0.5833\n","Epoch 36/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6908 - accuracy: 0.5532 - val_loss: 0.6749 - val_accuracy: 0.5938\n","Epoch 37/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6921 - accuracy: 0.5405 - val_loss: 0.6741 - val_accuracy: 0.5833\n","Epoch 38/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6853 - accuracy: 0.5567 - val_loss: 0.6734 - val_accuracy: 0.5833\n","Epoch 39/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6813 - accuracy: 0.5787 - val_loss: 0.6749 - val_accuracy: 0.5938\n","Epoch 40/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6826 - accuracy: 0.5660 - val_loss: 0.6741 - val_accuracy: 0.5833\n","Epoch 41/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6804 - accuracy: 0.5671 - val_loss: 0.6744 - val_accuracy: 0.5938\n","Epoch 42/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6890 - accuracy: 0.5613 - val_loss: 0.6757 - val_accuracy: 0.6250\n","Epoch 43/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6896 - accuracy: 0.5532 - val_loss: 0.6739 - val_accuracy: 0.6042\n","Epoch 44/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6856 - accuracy: 0.5637 - val_loss: 0.6739 - val_accuracy: 0.5938\n","Epoch 45/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6894 - accuracy: 0.5602 - val_loss: 0.6756 - val_accuracy: 0.6042\n","Epoch 46/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6832 - accuracy: 0.5590 - val_loss: 0.6768 - val_accuracy: 0.6042\n","Epoch 47/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6842 - accuracy: 0.5544 - val_loss: 0.6781 - val_accuracy: 0.6042\n","Epoch 48/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6828 - accuracy: 0.5590 - val_loss: 0.6784 - val_accuracy: 0.6146\n","Epoch 49/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6888 - accuracy: 0.5428 - val_loss: 0.6782 - val_accuracy: 0.6146\n","Epoch 50/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6762 - accuracy: 0.5799 - val_loss: 0.6781 - val_accuracy: 0.6042\n","Epoch 51/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6825 - accuracy: 0.5729 - val_loss: 0.6769 - val_accuracy: 0.6146\n","Epoch 52/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6758 - accuracy: 0.5648 - val_loss: 0.6767 - val_accuracy: 0.6250\n","Epoch 53/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6859 - accuracy: 0.5521 - val_loss: 0.6778 - val_accuracy: 0.6250\n","Epoch 54/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6859 - accuracy: 0.5660 - val_loss: 0.6780 - val_accuracy: 0.6250\n","Epoch 55/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6887 - accuracy: 0.5544 - val_loss: 0.6770 - val_accuracy: 0.6146\n","Epoch 56/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6797 - accuracy: 0.5660 - val_loss: 0.6766 - val_accuracy: 0.6042\n","Epoch 57/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6908 - accuracy: 0.5394 - val_loss: 0.6766 - val_accuracy: 0.5833\n","Epoch 58/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6783 - accuracy: 0.5637 - val_loss: 0.6756 - val_accuracy: 0.6042\n","Epoch 59/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6847 - accuracy: 0.5475 - val_loss: 0.6768 - val_accuracy: 0.6146\n","Epoch 60/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6924 - accuracy: 0.5451 - val_loss: 0.6763 - val_accuracy: 0.6146\n","Epoch 61/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6787 - accuracy: 0.5613 - val_loss: 0.6780 - val_accuracy: 0.6250\n","Epoch 62/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6843 - accuracy: 0.5590 - val_loss: 0.6765 - val_accuracy: 0.6250\n","Epoch 63/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6835 - accuracy: 0.5440 - val_loss: 0.6771 - val_accuracy: 0.6250\n","Epoch 64/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6811 - accuracy: 0.5475 - val_loss: 0.6760 - val_accuracy: 0.6250\n","Epoch 65/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6801 - accuracy: 0.5579 - val_loss: 0.6764 - val_accuracy: 0.6250\n","Epoch 66/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6887 - accuracy: 0.5637 - val_loss: 0.6763 - val_accuracy: 0.6250\n","Epoch 67/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6843 - accuracy: 0.5579 - val_loss: 0.6781 - val_accuracy: 0.6354\n","Epoch 68/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6789 - accuracy: 0.5602 - val_loss: 0.6782 - val_accuracy: 0.6354\n","Epoch 69/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6832 - accuracy: 0.5556 - val_loss: 0.6781 - val_accuracy: 0.6250\n","Epoch 70/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6821 - accuracy: 0.5729 - val_loss: 0.6800 - val_accuracy: 0.6146\n","Epoch 71/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6767 - accuracy: 0.5729 - val_loss: 0.6803 - val_accuracy: 0.6146\n","Epoch 72/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6773 - accuracy: 0.5637 - val_loss: 0.6798 - val_accuracy: 0.6146\n","Epoch 73/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6789 - accuracy: 0.5706 - val_loss: 0.6800 - val_accuracy: 0.6146\n","Epoch 74/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6799 - accuracy: 0.5683 - val_loss: 0.6811 - val_accuracy: 0.6250\n","Epoch 75/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6806 - accuracy: 0.5556 - val_loss: 0.6819 - val_accuracy: 0.6250\n","Epoch 76/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6826 - accuracy: 0.5567 - val_loss: 0.6837 - val_accuracy: 0.6250\n","Epoch 77/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6877 - accuracy: 0.5521 - val_loss: 0.6845 - val_accuracy: 0.6042\n","Epoch 78/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6756 - accuracy: 0.5602 - val_loss: 0.6839 - val_accuracy: 0.6250\n","Epoch 79/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6750 - accuracy: 0.5602 - val_loss: 0.6840 - val_accuracy: 0.6250\n","Epoch 80/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6845 - accuracy: 0.5463 - val_loss: 0.6824 - val_accuracy: 0.6250\n","Epoch 81/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6750 - accuracy: 0.5556 - val_loss: 0.6841 - val_accuracy: 0.6250\n","Epoch 82/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6817 - accuracy: 0.5764 - val_loss: 0.6864 - val_accuracy: 0.6042\n","Epoch 83/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6823 - accuracy: 0.5428 - val_loss: 0.6884 - val_accuracy: 0.5729\n","Epoch 84/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6816 - accuracy: 0.5521 - val_loss: 0.6903 - val_accuracy: 0.5625\n","Epoch 85/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6818 - accuracy: 0.5648 - val_loss: 0.6901 - val_accuracy: 0.5625\n","Epoch 86/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6804 - accuracy: 0.5706 - val_loss: 0.6897 - val_accuracy: 0.5729\n","Epoch 87/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6793 - accuracy: 0.5706 - val_loss: 0.6907 - val_accuracy: 0.5625\n","Epoch 88/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6785 - accuracy: 0.5579 - val_loss: 0.6903 - val_accuracy: 0.5417\n","Epoch 89/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6800 - accuracy: 0.5567 - val_loss: 0.6888 - val_accuracy: 0.5729\n","Epoch 90/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6772 - accuracy: 0.5729 - val_loss: 0.6865 - val_accuracy: 0.5833\n","Epoch 91/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6803 - accuracy: 0.5764 - val_loss: 0.6869 - val_accuracy: 0.5833\n","Epoch 92/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6762 - accuracy: 0.5521 - val_loss: 0.6881 - val_accuracy: 0.5938\n","Epoch 93/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6860 - accuracy: 0.5602 - val_loss: 0.6897 - val_accuracy: 0.5833\n","Epoch 94/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6808 - accuracy: 0.5648 - val_loss: 0.6894 - val_accuracy: 0.5729\n","Epoch 95/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6780 - accuracy: 0.5579 - val_loss: 0.6885 - val_accuracy: 0.5833\n","Epoch 96/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6843 - accuracy: 0.5556 - val_loss: 0.6863 - val_accuracy: 0.5938\n","Epoch 97/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6787 - accuracy: 0.5567 - val_loss: 0.6847 - val_accuracy: 0.5938\n","Epoch 98/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6736 - accuracy: 0.5799 - val_loss: 0.6858 - val_accuracy: 0.5833\n","Epoch 99/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6772 - accuracy: 0.5799 - val_loss: 0.6856 - val_accuracy: 0.5833\n","Epoch 100/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6745 - accuracy: 0.5706 - val_loss: 0.6862 - val_accuracy: 0.5833\n","Epoch 101/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6716 - accuracy: 0.5718 - val_loss: 0.6854 - val_accuracy: 0.5833\n","Epoch 102/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6778 - accuracy: 0.5590 - val_loss: 0.6840 - val_accuracy: 0.5938\n","Epoch 103/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6801 - accuracy: 0.5799 - val_loss: 0.6845 - val_accuracy: 0.5938\n","Epoch 104/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6745 - accuracy: 0.5752 - val_loss: 0.6855 - val_accuracy: 0.5729\n","Epoch 105/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6751 - accuracy: 0.5787 - val_loss: 0.6856 - val_accuracy: 0.5625\n","Epoch 106/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6836 - accuracy: 0.5613 - val_loss: 0.6849 - val_accuracy: 0.5833\n","Epoch 107/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6779 - accuracy: 0.5706 - val_loss: 0.6849 - val_accuracy: 0.5833\n","Epoch 108/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6709 - accuracy: 0.5972 - val_loss: 0.6850 - val_accuracy: 0.5938\n","Epoch 109/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6771 - accuracy: 0.5810 - val_loss: 0.6874 - val_accuracy: 0.5729\n","Epoch 110/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6752 - accuracy: 0.5544 - val_loss: 0.6907 - val_accuracy: 0.5521\n","Epoch 111/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6745 - accuracy: 0.5637 - val_loss: 0.6917 - val_accuracy: 0.5729\n","Epoch 112/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6769 - accuracy: 0.5544 - val_loss: 0.6941 - val_accuracy: 0.5521\n","Epoch 113/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6723 - accuracy: 0.5822 - val_loss: 0.6946 - val_accuracy: 0.5521\n","Epoch 114/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6812 - accuracy: 0.5590 - val_loss: 0.6948 - val_accuracy: 0.5521\n","Epoch 115/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6746 - accuracy: 0.5868 - val_loss: 0.6986 - val_accuracy: 0.5417\n","Epoch 116/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6758 - accuracy: 0.5810 - val_loss: 0.6963 - val_accuracy: 0.5521\n","Epoch 117/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6712 - accuracy: 0.5787 - val_loss: 0.6942 - val_accuracy: 0.5521\n","Epoch 118/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6703 - accuracy: 0.5856 - val_loss: 0.6953 - val_accuracy: 0.5417\n","Epoch 119/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6763 - accuracy: 0.5683 - val_loss: 0.6998 - val_accuracy: 0.5208\n","Epoch 120/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6695 - accuracy: 0.6030 - val_loss: 0.6994 - val_accuracy: 0.5208\n","Epoch 121/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6824 - accuracy: 0.5579 - val_loss: 0.6983 - val_accuracy: 0.5312\n","Epoch 122/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6748 - accuracy: 0.5752 - val_loss: 0.6983 - val_accuracy: 0.5104\n","Epoch 123/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6759 - accuracy: 0.5718 - val_loss: 0.6968 - val_accuracy: 0.5000\n","Epoch 124/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6711 - accuracy: 0.5764 - val_loss: 0.6979 - val_accuracy: 0.5104\n","Epoch 125/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6767 - accuracy: 0.5718 - val_loss: 0.6976 - val_accuracy: 0.5104\n","Epoch 126/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6740 - accuracy: 0.5845 - val_loss: 0.6996 - val_accuracy: 0.5104\n","Epoch 127/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6707 - accuracy: 0.5741 - val_loss: 0.6986 - val_accuracy: 0.5312\n","Epoch 128/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6780 - accuracy: 0.5718 - val_loss: 0.6999 - val_accuracy: 0.5208\n","Epoch 129/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6723 - accuracy: 0.5752 - val_loss: 0.6962 - val_accuracy: 0.5104\n","Epoch 130/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6747 - accuracy: 0.5602 - val_loss: 0.6942 - val_accuracy: 0.5521\n","Epoch 131/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6685 - accuracy: 0.5845 - val_loss: 0.6955 - val_accuracy: 0.5208\n","Epoch 132/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6743 - accuracy: 0.5856 - val_loss: 0.6957 - val_accuracy: 0.5417\n","Epoch 133/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6744 - accuracy: 0.5799 - val_loss: 0.6952 - val_accuracy: 0.5417\n","Epoch 134/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6736 - accuracy: 0.5810 - val_loss: 0.6947 - val_accuracy: 0.5417\n","Epoch 135/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6739 - accuracy: 0.5683 - val_loss: 0.6943 - val_accuracy: 0.5625\n","Epoch 136/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6816 - accuracy: 0.5498 - val_loss: 0.6949 - val_accuracy: 0.5625\n","Epoch 137/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6764 - accuracy: 0.5694 - val_loss: 0.6934 - val_accuracy: 0.5625\n","Epoch 138/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6725 - accuracy: 0.5660 - val_loss: 0.6916 - val_accuracy: 0.5729\n","Epoch 139/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6767 - accuracy: 0.5556 - val_loss: 0.6919 - val_accuracy: 0.5729\n","Epoch 140/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6645 - accuracy: 0.5822 - val_loss: 0.6932 - val_accuracy: 0.5625\n","Epoch 141/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6728 - accuracy: 0.5752 - val_loss: 0.6940 - val_accuracy: 0.5625\n","Epoch 142/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6723 - accuracy: 0.5903 - val_loss: 0.6950 - val_accuracy: 0.5521\n","Epoch 143/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6678 - accuracy: 0.5810 - val_loss: 0.6980 - val_accuracy: 0.5208\n","Epoch 144/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6666 - accuracy: 0.5961 - val_loss: 0.6983 - val_accuracy: 0.5104\n","Epoch 145/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6705 - accuracy: 0.5903 - val_loss: 0.6973 - val_accuracy: 0.5417\n","Epoch 146/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6719 - accuracy: 0.5694 - val_loss: 0.6988 - val_accuracy: 0.5000\n","Epoch 147/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6732 - accuracy: 0.5729 - val_loss: 0.7015 - val_accuracy: 0.4896\n","Epoch 148/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6684 - accuracy: 0.5845 - val_loss: 0.7022 - val_accuracy: 0.4896\n","Epoch 149/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6679 - accuracy: 0.5961 - val_loss: 0.7035 - val_accuracy: 0.4896\n","Epoch 150/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6739 - accuracy: 0.5822 - val_loss: 0.7019 - val_accuracy: 0.4896\n","Epoch 151/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6724 - accuracy: 0.5833 - val_loss: 0.7002 - val_accuracy: 0.5104\n","Epoch 152/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6699 - accuracy: 0.5787 - val_loss: 0.7008 - val_accuracy: 0.5000\n","Epoch 153/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6684 - accuracy: 0.5787 - val_loss: 0.6992 - val_accuracy: 0.5208\n","Epoch 154/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6762 - accuracy: 0.5706 - val_loss: 0.7017 - val_accuracy: 0.5104\n","Epoch 155/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6704 - accuracy: 0.5856 - val_loss: 0.7013 - val_accuracy: 0.5000\n","Epoch 156/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6699 - accuracy: 0.5683 - val_loss: 0.7020 - val_accuracy: 0.5104\n","Epoch 157/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6649 - accuracy: 0.5683 - val_loss: 0.7008 - val_accuracy: 0.5104\n","Epoch 158/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6761 - accuracy: 0.5567 - val_loss: 0.7005 - val_accuracy: 0.5000\n","Epoch 159/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6630 - accuracy: 0.6123 - val_loss: 0.7000 - val_accuracy: 0.5104\n","Epoch 160/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6717 - accuracy: 0.5810 - val_loss: 0.7002 - val_accuracy: 0.5208\n","Epoch 161/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6736 - accuracy: 0.5775 - val_loss: 0.6998 - val_accuracy: 0.5104\n","Epoch 162/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6686 - accuracy: 0.5926 - val_loss: 0.6992 - val_accuracy: 0.5104\n","Epoch 163/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6609 - accuracy: 0.5833 - val_loss: 0.6996 - val_accuracy: 0.5104\n","Epoch 164/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6610 - accuracy: 0.5972 - val_loss: 0.6971 - val_accuracy: 0.5417\n","Epoch 165/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6693 - accuracy: 0.5938 - val_loss: 0.6982 - val_accuracy: 0.5312\n","Epoch 166/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6740 - accuracy: 0.5625 - val_loss: 0.7013 - val_accuracy: 0.5208\n","Epoch 167/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6635 - accuracy: 0.5856 - val_loss: 0.7008 - val_accuracy: 0.5208\n","Epoch 168/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6668 - accuracy: 0.5856 - val_loss: 0.7013 - val_accuracy: 0.5208\n","Epoch 169/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6773 - accuracy: 0.5729 - val_loss: 0.7011 - val_accuracy: 0.5208\n","Epoch 170/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6644 - accuracy: 0.6053 - val_loss: 0.6975 - val_accuracy: 0.5417\n","Epoch 171/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6649 - accuracy: 0.5914 - val_loss: 0.6989 - val_accuracy: 0.5417\n","Epoch 172/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6676 - accuracy: 0.5914 - val_loss: 0.6983 - val_accuracy: 0.5312\n","Epoch 173/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6663 - accuracy: 0.5926 - val_loss: 0.6972 - val_accuracy: 0.5417\n","Epoch 174/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6664 - accuracy: 0.5764 - val_loss: 0.6989 - val_accuracy: 0.5417\n","Epoch 175/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6618 - accuracy: 0.5868 - val_loss: 0.7015 - val_accuracy: 0.5208\n","Epoch 176/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6670 - accuracy: 0.5822 - val_loss: 0.7017 - val_accuracy: 0.5208\n","Epoch 177/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6631 - accuracy: 0.6007 - val_loss: 0.7011 - val_accuracy: 0.5312\n","Epoch 178/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6622 - accuracy: 0.6007 - val_loss: 0.7022 - val_accuracy: 0.5104\n","Epoch 179/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6620 - accuracy: 0.5926 - val_loss: 0.7025 - val_accuracy: 0.5000\n","Epoch 180/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6636 - accuracy: 0.5926 - val_loss: 0.7027 - val_accuracy: 0.5104\n","Epoch 181/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6627 - accuracy: 0.6019 - val_loss: 0.6989 - val_accuracy: 0.5312\n","Epoch 182/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6699 - accuracy: 0.5845 - val_loss: 0.6994 - val_accuracy: 0.5208\n","Epoch 183/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6655 - accuracy: 0.5613 - val_loss: 0.6981 - val_accuracy: 0.5208\n","Epoch 184/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6659 - accuracy: 0.5926 - val_loss: 0.6979 - val_accuracy: 0.5208\n","Epoch 185/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6659 - accuracy: 0.5764 - val_loss: 0.6967 - val_accuracy: 0.5417\n","Epoch 186/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6655 - accuracy: 0.6030 - val_loss: 0.6964 - val_accuracy: 0.5312\n","Epoch 187/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6699 - accuracy: 0.5961 - val_loss: 0.6950 - val_accuracy: 0.5625\n","Epoch 188/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6597 - accuracy: 0.5914 - val_loss: 0.6946 - val_accuracy: 0.5521\n","Epoch 189/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6569 - accuracy: 0.6088 - val_loss: 0.6964 - val_accuracy: 0.5521\n","Epoch 190/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6635 - accuracy: 0.5961 - val_loss: 0.6963 - val_accuracy: 0.5521\n","Epoch 191/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6724 - accuracy: 0.5764 - val_loss: 0.6982 - val_accuracy: 0.5521\n","Epoch 192/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6619 - accuracy: 0.5891 - val_loss: 0.7009 - val_accuracy: 0.5208\n","Epoch 193/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6663 - accuracy: 0.5822 - val_loss: 0.7001 - val_accuracy: 0.5312\n","Epoch 194/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6647 - accuracy: 0.6030 - val_loss: 0.6982 - val_accuracy: 0.5521\n","Epoch 195/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6581 - accuracy: 0.6250 - val_loss: 0.6974 - val_accuracy: 0.5729\n","Epoch 196/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6637 - accuracy: 0.5683 - val_loss: 0.6987 - val_accuracy: 0.5521\n","Epoch 197/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6635 - accuracy: 0.5880 - val_loss: 0.6996 - val_accuracy: 0.5625\n","Epoch 198/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6589 - accuracy: 0.6053 - val_loss: 0.6989 - val_accuracy: 0.5417\n","Epoch 199/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6648 - accuracy: 0.5914 - val_loss: 0.6994 - val_accuracy: 0.5625\n","Epoch 200/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6643 - accuracy: 0.5926 - val_loss: 0.6991 - val_accuracy: 0.5729\n","8/8 [==============================] - 0s 12ms/step - loss: 0.6876 - accuracy: 0.5250\n","[0.6875764727592468, 0.5249999761581421]\n","Results for fold 6\n","Epoch 1/200\n","14/14 [==============================] - 7s 112ms/step - loss: 0.7281 - accuracy: 0.5174 - val_loss: 0.6988 - val_accuracy: 0.5417\n","Epoch 2/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.7168 - accuracy: 0.5278 - val_loss: 0.6973 - val_accuracy: 0.5312\n","Epoch 3/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.7172 - accuracy: 0.5289 - val_loss: 0.6969 - val_accuracy: 0.4792\n","Epoch 4/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.7024 - accuracy: 0.5278 - val_loss: 0.6964 - val_accuracy: 0.4792\n","Epoch 5/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6836 - accuracy: 0.5694 - val_loss: 0.6960 - val_accuracy: 0.4896\n","Epoch 6/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.7085 - accuracy: 0.5081 - val_loss: 0.6954 - val_accuracy: 0.4688\n","Epoch 7/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.7062 - accuracy: 0.5093 - val_loss: 0.6925 - val_accuracy: 0.4479\n","Epoch 8/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6980 - accuracy: 0.5324 - val_loss: 0.6903 - val_accuracy: 0.5104\n","Epoch 9/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6952 - accuracy: 0.5347 - val_loss: 0.6900 - val_accuracy: 0.4792\n","Epoch 10/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6898 - accuracy: 0.5567 - val_loss: 0.6863 - val_accuracy: 0.4896\n","Epoch 11/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6871 - accuracy: 0.5394 - val_loss: 0.6835 - val_accuracy: 0.5000\n","Epoch 12/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6990 - accuracy: 0.5289 - val_loss: 0.6795 - val_accuracy: 0.5625\n","Epoch 13/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6965 - accuracy: 0.5359 - val_loss: 0.6755 - val_accuracy: 0.5938\n","Epoch 14/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6958 - accuracy: 0.5324 - val_loss: 0.6747 - val_accuracy: 0.6146\n","Epoch 15/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6911 - accuracy: 0.5382 - val_loss: 0.6768 - val_accuracy: 0.5938\n","Epoch 16/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6881 - accuracy: 0.5752 - val_loss: 0.6761 - val_accuracy: 0.6146\n","Epoch 17/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6789 - accuracy: 0.5671 - val_loss: 0.6752 - val_accuracy: 0.5938\n","Epoch 18/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6920 - accuracy: 0.5440 - val_loss: 0.6757 - val_accuracy: 0.5417\n","Epoch 19/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6863 - accuracy: 0.5440 - val_loss: 0.6743 - val_accuracy: 0.5729\n","Epoch 20/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.7037 - accuracy: 0.5255 - val_loss: 0.6751 - val_accuracy: 0.5521\n","Epoch 21/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6865 - accuracy: 0.5625 - val_loss: 0.6751 - val_accuracy: 0.5729\n","Epoch 22/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6860 - accuracy: 0.5475 - val_loss: 0.6743 - val_accuracy: 0.5729\n","Epoch 23/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6914 - accuracy: 0.5394 - val_loss: 0.6724 - val_accuracy: 0.5833\n","Epoch 24/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6928 - accuracy: 0.5347 - val_loss: 0.6714 - val_accuracy: 0.5938\n","Epoch 25/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6913 - accuracy: 0.5486 - val_loss: 0.6714 - val_accuracy: 0.5938\n","Epoch 26/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6845 - accuracy: 0.5544 - val_loss: 0.6692 - val_accuracy: 0.5938\n","Epoch 27/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6917 - accuracy: 0.5590 - val_loss: 0.6686 - val_accuracy: 0.5833\n","Epoch 28/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6867 - accuracy: 0.5683 - val_loss: 0.6675 - val_accuracy: 0.6146\n","Epoch 29/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6927 - accuracy: 0.5324 - val_loss: 0.6687 - val_accuracy: 0.6146\n","Epoch 30/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6883 - accuracy: 0.5417 - val_loss: 0.6694 - val_accuracy: 0.6042\n","Epoch 31/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6952 - accuracy: 0.5544 - val_loss: 0.6699 - val_accuracy: 0.6250\n","Epoch 32/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6931 - accuracy: 0.5428 - val_loss: 0.6713 - val_accuracy: 0.6042\n","Epoch 33/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6871 - accuracy: 0.5440 - val_loss: 0.6717 - val_accuracy: 0.6042\n","Epoch 34/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6849 - accuracy: 0.5660 - val_loss: 0.6716 - val_accuracy: 0.6146\n","Epoch 35/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6847 - accuracy: 0.5475 - val_loss: 0.6714 - val_accuracy: 0.6146\n","Epoch 36/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6825 - accuracy: 0.5556 - val_loss: 0.6706 - val_accuracy: 0.6146\n","Epoch 37/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6823 - accuracy: 0.5613 - val_loss: 0.6695 - val_accuracy: 0.6146\n","Epoch 38/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6818 - accuracy: 0.5729 - val_loss: 0.6693 - val_accuracy: 0.6146\n","Epoch 39/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6925 - accuracy: 0.5440 - val_loss: 0.6686 - val_accuracy: 0.6250\n","Epoch 40/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6790 - accuracy: 0.5787 - val_loss: 0.6685 - val_accuracy: 0.6250\n","Epoch 41/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6771 - accuracy: 0.5764 - val_loss: 0.6678 - val_accuracy: 0.6042\n","Epoch 42/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6825 - accuracy: 0.5544 - val_loss: 0.6684 - val_accuracy: 0.6042\n","Epoch 43/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6797 - accuracy: 0.5590 - val_loss: 0.6690 - val_accuracy: 0.5729\n","Epoch 44/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6814 - accuracy: 0.5787 - val_loss: 0.6692 - val_accuracy: 0.5833\n","Epoch 45/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6858 - accuracy: 0.5486 - val_loss: 0.6697 - val_accuracy: 0.5833\n","Epoch 46/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6788 - accuracy: 0.5544 - val_loss: 0.6700 - val_accuracy: 0.5938\n","Epoch 47/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6850 - accuracy: 0.5556 - val_loss: 0.6693 - val_accuracy: 0.6146\n","Epoch 48/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6799 - accuracy: 0.5660 - val_loss: 0.6695 - val_accuracy: 0.6250\n","Epoch 49/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6887 - accuracy: 0.5694 - val_loss: 0.6696 - val_accuracy: 0.6042\n","Epoch 50/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6807 - accuracy: 0.5567 - val_loss: 0.6702 - val_accuracy: 0.6042\n","Epoch 51/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6777 - accuracy: 0.5729 - val_loss: 0.6702 - val_accuracy: 0.6042\n","Epoch 52/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6751 - accuracy: 0.5694 - val_loss: 0.6703 - val_accuracy: 0.5729\n","Epoch 53/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6789 - accuracy: 0.5764 - val_loss: 0.6704 - val_accuracy: 0.5625\n","Epoch 54/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6854 - accuracy: 0.5498 - val_loss: 0.6706 - val_accuracy: 0.5833\n","Epoch 55/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6895 - accuracy: 0.5336 - val_loss: 0.6712 - val_accuracy: 0.5833\n","Epoch 56/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6905 - accuracy: 0.5509 - val_loss: 0.6725 - val_accuracy: 0.5625\n","Epoch 57/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6862 - accuracy: 0.5556 - val_loss: 0.6729 - val_accuracy: 0.5625\n","Epoch 58/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6710 - accuracy: 0.5822 - val_loss: 0.6732 - val_accuracy: 0.5625\n","Epoch 59/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6796 - accuracy: 0.5822 - val_loss: 0.6720 - val_accuracy: 0.5833\n","Epoch 60/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6793 - accuracy: 0.5625 - val_loss: 0.6724 - val_accuracy: 0.5729\n","Epoch 61/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6787 - accuracy: 0.5787 - val_loss: 0.6714 - val_accuracy: 0.5625\n","Epoch 62/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6834 - accuracy: 0.5613 - val_loss: 0.6711 - val_accuracy: 0.5833\n","Epoch 63/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6887 - accuracy: 0.5301 - val_loss: 0.6715 - val_accuracy: 0.5833\n","Epoch 64/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6848 - accuracy: 0.5671 - val_loss: 0.6711 - val_accuracy: 0.5833\n","Epoch 65/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6848 - accuracy: 0.5648 - val_loss: 0.6723 - val_accuracy: 0.5729\n","Epoch 66/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6870 - accuracy: 0.5625 - val_loss: 0.6725 - val_accuracy: 0.5729\n","Epoch 67/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6812 - accuracy: 0.5648 - val_loss: 0.6714 - val_accuracy: 0.5833\n","Epoch 68/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6812 - accuracy: 0.5706 - val_loss: 0.6710 - val_accuracy: 0.5833\n","Epoch 69/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6857 - accuracy: 0.5544 - val_loss: 0.6716 - val_accuracy: 0.5833\n","Epoch 70/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6853 - accuracy: 0.5613 - val_loss: 0.6725 - val_accuracy: 0.5833\n","Epoch 71/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6752 - accuracy: 0.5694 - val_loss: 0.6718 - val_accuracy: 0.5833\n","Epoch 72/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6688 - accuracy: 0.5856 - val_loss: 0.6710 - val_accuracy: 0.5833\n","Epoch 73/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6823 - accuracy: 0.5567 - val_loss: 0.6711 - val_accuracy: 0.5833\n","Epoch 74/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6877 - accuracy: 0.5579 - val_loss: 0.6709 - val_accuracy: 0.5833\n","Epoch 75/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6793 - accuracy: 0.5671 - val_loss: 0.6715 - val_accuracy: 0.5729\n","Epoch 76/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6810 - accuracy: 0.5671 - val_loss: 0.6704 - val_accuracy: 0.5729\n","Epoch 77/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6773 - accuracy: 0.5637 - val_loss: 0.6706 - val_accuracy: 0.5729\n","Epoch 78/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6844 - accuracy: 0.5579 - val_loss: 0.6713 - val_accuracy: 0.5729\n","Epoch 79/200\n","14/14 [==============================] - 0s 24ms/step - loss: 0.6748 - accuracy: 0.5822 - val_loss: 0.6709 - val_accuracy: 0.5729\n","Epoch 80/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6805 - accuracy: 0.5694 - val_loss: 0.6700 - val_accuracy: 0.6042\n","Epoch 81/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6784 - accuracy: 0.5706 - val_loss: 0.6705 - val_accuracy: 0.6042\n","Epoch 82/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6743 - accuracy: 0.5764 - val_loss: 0.6703 - val_accuracy: 0.6042\n","Epoch 83/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6755 - accuracy: 0.5891 - val_loss: 0.6702 - val_accuracy: 0.6042\n","Epoch 84/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6800 - accuracy: 0.5718 - val_loss: 0.6707 - val_accuracy: 0.5938\n","Epoch 85/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6798 - accuracy: 0.5822 - val_loss: 0.6700 - val_accuracy: 0.5833\n","Epoch 86/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6716 - accuracy: 0.5926 - val_loss: 0.6695 - val_accuracy: 0.5833\n","Epoch 87/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6833 - accuracy: 0.5428 - val_loss: 0.6694 - val_accuracy: 0.5938\n","Epoch 88/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6770 - accuracy: 0.5822 - val_loss: 0.6702 - val_accuracy: 0.5938\n","Epoch 89/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6721 - accuracy: 0.5833 - val_loss: 0.6711 - val_accuracy: 0.6042\n","Epoch 90/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6843 - accuracy: 0.5914 - val_loss: 0.6717 - val_accuracy: 0.6042\n","Epoch 91/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6855 - accuracy: 0.5521 - val_loss: 0.6718 - val_accuracy: 0.6042\n","Epoch 92/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6700 - accuracy: 0.5683 - val_loss: 0.6718 - val_accuracy: 0.5938\n","Epoch 93/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6763 - accuracy: 0.5787 - val_loss: 0.6714 - val_accuracy: 0.6042\n","Epoch 94/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6809 - accuracy: 0.5405 - val_loss: 0.6708 - val_accuracy: 0.6042\n","Epoch 95/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6758 - accuracy: 0.5579 - val_loss: 0.6704 - val_accuracy: 0.6042\n","Epoch 96/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6858 - accuracy: 0.5683 - val_loss: 0.6700 - val_accuracy: 0.6042\n","Epoch 97/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6832 - accuracy: 0.5648 - val_loss: 0.6702 - val_accuracy: 0.5833\n","Epoch 98/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6790 - accuracy: 0.5729 - val_loss: 0.6712 - val_accuracy: 0.5938\n","Epoch 99/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6721 - accuracy: 0.5845 - val_loss: 0.6714 - val_accuracy: 0.5938\n","Epoch 100/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6773 - accuracy: 0.5799 - val_loss: 0.6716 - val_accuracy: 0.5938\n","Epoch 101/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6751 - accuracy: 0.5845 - val_loss: 0.6717 - val_accuracy: 0.5833\n","Epoch 102/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6797 - accuracy: 0.5706 - val_loss: 0.6714 - val_accuracy: 0.5729\n","Epoch 103/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6798 - accuracy: 0.5764 - val_loss: 0.6712 - val_accuracy: 0.5833\n","Epoch 104/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6717 - accuracy: 0.5938 - val_loss: 0.6716 - val_accuracy: 0.5833\n","Epoch 105/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6725 - accuracy: 0.5856 - val_loss: 0.6722 - val_accuracy: 0.5938\n","Epoch 106/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6787 - accuracy: 0.5799 - val_loss: 0.6724 - val_accuracy: 0.5833\n","Epoch 107/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6754 - accuracy: 0.5718 - val_loss: 0.6734 - val_accuracy: 0.5938\n","Epoch 108/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6796 - accuracy: 0.5764 - val_loss: 0.6734 - val_accuracy: 0.5833\n","Epoch 109/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6709 - accuracy: 0.5961 - val_loss: 0.6729 - val_accuracy: 0.5938\n","Epoch 110/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6751 - accuracy: 0.5810 - val_loss: 0.6722 - val_accuracy: 0.5833\n","Epoch 111/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6761 - accuracy: 0.5822 - val_loss: 0.6721 - val_accuracy: 0.5729\n","Epoch 112/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6730 - accuracy: 0.5718 - val_loss: 0.6726 - val_accuracy: 0.5729\n","Epoch 113/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6699 - accuracy: 0.6042 - val_loss: 0.6730 - val_accuracy: 0.5625\n","Epoch 114/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6763 - accuracy: 0.5741 - val_loss: 0.6739 - val_accuracy: 0.5417\n","Epoch 115/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6755 - accuracy: 0.5718 - val_loss: 0.6738 - val_accuracy: 0.5417\n","Epoch 116/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6800 - accuracy: 0.5671 - val_loss: 0.6750 - val_accuracy: 0.5312\n","Epoch 117/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6742 - accuracy: 0.5984 - val_loss: 0.6754 - val_accuracy: 0.5312\n","Epoch 118/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6710 - accuracy: 0.5914 - val_loss: 0.6750 - val_accuracy: 0.5417\n","Epoch 119/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6648 - accuracy: 0.6042 - val_loss: 0.6748 - val_accuracy: 0.5521\n","Epoch 120/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6726 - accuracy: 0.5671 - val_loss: 0.6751 - val_accuracy: 0.5312\n","Epoch 121/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6685 - accuracy: 0.6030 - val_loss: 0.6749 - val_accuracy: 0.5521\n","Epoch 122/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6776 - accuracy: 0.5903 - val_loss: 0.6758 - val_accuracy: 0.5521\n","Epoch 123/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6688 - accuracy: 0.6100 - val_loss: 0.6764 - val_accuracy: 0.5521\n","Epoch 124/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6768 - accuracy: 0.5741 - val_loss: 0.6768 - val_accuracy: 0.5521\n","Epoch 125/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6749 - accuracy: 0.5706 - val_loss: 0.6768 - val_accuracy: 0.5521\n","Epoch 126/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6690 - accuracy: 0.5926 - val_loss: 0.6750 - val_accuracy: 0.5521\n","Epoch 127/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6597 - accuracy: 0.6042 - val_loss: 0.6728 - val_accuracy: 0.5417\n","Epoch 128/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6652 - accuracy: 0.5995 - val_loss: 0.6723 - val_accuracy: 0.5312\n","Epoch 129/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6672 - accuracy: 0.5972 - val_loss: 0.6732 - val_accuracy: 0.5312\n","Epoch 130/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6734 - accuracy: 0.5741 - val_loss: 0.6734 - val_accuracy: 0.5312\n","Epoch 131/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6762 - accuracy: 0.5741 - val_loss: 0.6734 - val_accuracy: 0.5208\n","Epoch 132/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6731 - accuracy: 0.5868 - val_loss: 0.6725 - val_accuracy: 0.5417\n","Epoch 133/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6730 - accuracy: 0.5833 - val_loss: 0.6722 - val_accuracy: 0.5521\n","Epoch 134/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6748 - accuracy: 0.5718 - val_loss: 0.6730 - val_accuracy: 0.5521\n","Epoch 135/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6699 - accuracy: 0.5833 - val_loss: 0.6737 - val_accuracy: 0.5417\n","Epoch 136/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6674 - accuracy: 0.5926 - val_loss: 0.6736 - val_accuracy: 0.5417\n","Epoch 137/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6716 - accuracy: 0.5914 - val_loss: 0.6731 - val_accuracy: 0.5417\n","Epoch 138/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6657 - accuracy: 0.5995 - val_loss: 0.6740 - val_accuracy: 0.5417\n","Epoch 139/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6728 - accuracy: 0.5880 - val_loss: 0.6745 - val_accuracy: 0.5417\n","Epoch 140/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6720 - accuracy: 0.5845 - val_loss: 0.6755 - val_accuracy: 0.5312\n","Epoch 141/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6693 - accuracy: 0.5984 - val_loss: 0.6758 - val_accuracy: 0.5417\n","Epoch 142/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6707 - accuracy: 0.5845 - val_loss: 0.6754 - val_accuracy: 0.5312\n","Epoch 143/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6682 - accuracy: 0.5903 - val_loss: 0.6746 - val_accuracy: 0.5521\n","Epoch 144/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6703 - accuracy: 0.5868 - val_loss: 0.6745 - val_accuracy: 0.5521\n","Epoch 145/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6710 - accuracy: 0.5984 - val_loss: 0.6746 - val_accuracy: 0.5625\n","Epoch 146/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6685 - accuracy: 0.5914 - val_loss: 0.6747 - val_accuracy: 0.5625\n","Epoch 147/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6698 - accuracy: 0.5984 - val_loss: 0.6743 - val_accuracy: 0.5625\n","Epoch 148/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6640 - accuracy: 0.5984 - val_loss: 0.6736 - val_accuracy: 0.5729\n","Epoch 149/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6703 - accuracy: 0.5868 - val_loss: 0.6734 - val_accuracy: 0.5729\n","Epoch 150/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6667 - accuracy: 0.5926 - val_loss: 0.6723 - val_accuracy: 0.5729\n","Epoch 151/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6561 - accuracy: 0.5972 - val_loss: 0.6724 - val_accuracy: 0.5729\n","Epoch 152/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6731 - accuracy: 0.5810 - val_loss: 0.6722 - val_accuracy: 0.5729\n","Epoch 153/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6695 - accuracy: 0.5914 - val_loss: 0.6725 - val_accuracy: 0.5729\n","Epoch 154/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6635 - accuracy: 0.6123 - val_loss: 0.6726 - val_accuracy: 0.5625\n","Epoch 155/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6658 - accuracy: 0.6007 - val_loss: 0.6731 - val_accuracy: 0.5625\n","Epoch 156/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6652 - accuracy: 0.5961 - val_loss: 0.6728 - val_accuracy: 0.5625\n","Epoch 157/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6663 - accuracy: 0.6088 - val_loss: 0.6718 - val_accuracy: 0.5729\n","Epoch 158/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6617 - accuracy: 0.5926 - val_loss: 0.6732 - val_accuracy: 0.5729\n","Epoch 159/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6685 - accuracy: 0.5752 - val_loss: 0.6726 - val_accuracy: 0.5729\n","Epoch 160/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6629 - accuracy: 0.6157 - val_loss: 0.6715 - val_accuracy: 0.5833\n","Epoch 161/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6727 - accuracy: 0.5637 - val_loss: 0.6704 - val_accuracy: 0.5833\n","Epoch 162/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6664 - accuracy: 0.5995 - val_loss: 0.6699 - val_accuracy: 0.5729\n","Epoch 163/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6604 - accuracy: 0.6238 - val_loss: 0.6703 - val_accuracy: 0.5833\n","Epoch 164/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6704 - accuracy: 0.5891 - val_loss: 0.6708 - val_accuracy: 0.5729\n","Epoch 165/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6711 - accuracy: 0.5949 - val_loss: 0.6710 - val_accuracy: 0.5833\n","Epoch 166/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6640 - accuracy: 0.6019 - val_loss: 0.6709 - val_accuracy: 0.5833\n","Epoch 167/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6683 - accuracy: 0.5949 - val_loss: 0.6710 - val_accuracy: 0.5833\n","Epoch 168/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6658 - accuracy: 0.5938 - val_loss: 0.6703 - val_accuracy: 0.5729\n","Epoch 169/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6632 - accuracy: 0.6019 - val_loss: 0.6699 - val_accuracy: 0.5833\n","Epoch 170/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6686 - accuracy: 0.5972 - val_loss: 0.6700 - val_accuracy: 0.5938\n","Epoch 171/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6628 - accuracy: 0.5891 - val_loss: 0.6708 - val_accuracy: 0.5729\n","Epoch 172/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6603 - accuracy: 0.6134 - val_loss: 0.6707 - val_accuracy: 0.5729\n","Epoch 173/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6649 - accuracy: 0.6123 - val_loss: 0.6699 - val_accuracy: 0.5625\n","Epoch 174/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6575 - accuracy: 0.6123 - val_loss: 0.6689 - val_accuracy: 0.5833\n","Epoch 175/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6680 - accuracy: 0.5891 - val_loss: 0.6691 - val_accuracy: 0.5833\n","Epoch 176/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6624 - accuracy: 0.5938 - val_loss: 0.6698 - val_accuracy: 0.5833\n","Epoch 177/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6620 - accuracy: 0.6111 - val_loss: 0.6711 - val_accuracy: 0.5729\n","Epoch 178/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6703 - accuracy: 0.5752 - val_loss: 0.6719 - val_accuracy: 0.5729\n","Epoch 179/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6582 - accuracy: 0.6204 - val_loss: 0.6723 - val_accuracy: 0.5625\n","Epoch 180/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6575 - accuracy: 0.6215 - val_loss: 0.6721 - val_accuracy: 0.5729\n","Epoch 181/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6658 - accuracy: 0.6019 - val_loss: 0.6726 - val_accuracy: 0.5729\n","Epoch 182/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6544 - accuracy: 0.6181 - val_loss: 0.6719 - val_accuracy: 0.5833\n","Epoch 183/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6549 - accuracy: 0.6192 - val_loss: 0.6723 - val_accuracy: 0.5938\n","Epoch 184/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6702 - accuracy: 0.5995 - val_loss: 0.6725 - val_accuracy: 0.5938\n","Epoch 185/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6585 - accuracy: 0.6157 - val_loss: 0.6721 - val_accuracy: 0.6042\n","Epoch 186/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6655 - accuracy: 0.6111 - val_loss: 0.6725 - val_accuracy: 0.6146\n","Epoch 187/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6577 - accuracy: 0.6181 - val_loss: 0.6724 - val_accuracy: 0.6146\n","Epoch 188/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6512 - accuracy: 0.6343 - val_loss: 0.6730 - val_accuracy: 0.6042\n","Epoch 189/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6610 - accuracy: 0.6065 - val_loss: 0.6730 - val_accuracy: 0.6042\n","Epoch 190/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6556 - accuracy: 0.6053 - val_loss: 0.6728 - val_accuracy: 0.6042\n","Epoch 191/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6594 - accuracy: 0.6088 - val_loss: 0.6731 - val_accuracy: 0.5938\n","Epoch 192/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6585 - accuracy: 0.6134 - val_loss: 0.6764 - val_accuracy: 0.6042\n","Epoch 193/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6545 - accuracy: 0.6065 - val_loss: 0.6765 - val_accuracy: 0.5938\n","Epoch 194/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6476 - accuracy: 0.6227 - val_loss: 0.6773 - val_accuracy: 0.6146\n","Epoch 195/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6532 - accuracy: 0.6100 - val_loss: 0.6780 - val_accuracy: 0.6042\n","Epoch 196/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6510 - accuracy: 0.6238 - val_loss: 0.6769 - val_accuracy: 0.5938\n","Epoch 197/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6479 - accuracy: 0.6319 - val_loss: 0.6766 - val_accuracy: 0.5729\n","Epoch 198/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6429 - accuracy: 0.6528 - val_loss: 0.6774 - val_accuracy: 0.5521\n","Epoch 199/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6558 - accuracy: 0.6285 - val_loss: 0.6764 - val_accuracy: 0.5625\n","Epoch 200/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6561 - accuracy: 0.6146 - val_loss: 0.6756 - val_accuracy: 0.5833\n","8/8 [==============================] - 0s 13ms/step - loss: 0.6802 - accuracy: 0.5875\n","[0.6802413463592529, 0.5874999761581421]\n","Results for fold 7\n","Epoch 1/200\n","14/14 [==============================] - 7s 117ms/step - loss: 0.7323 - accuracy: 0.5035 - val_loss: 0.7103 - val_accuracy: 0.4792\n","Epoch 2/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.7227 - accuracy: 0.5023 - val_loss: 0.7110 - val_accuracy: 0.4583\n","Epoch 3/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.7060 - accuracy: 0.5301 - val_loss: 0.7225 - val_accuracy: 0.4792\n","Epoch 4/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.7091 - accuracy: 0.5243 - val_loss: 0.7256 - val_accuracy: 0.5000\n","Epoch 5/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.7058 - accuracy: 0.5104 - val_loss: 0.7255 - val_accuracy: 0.4896\n","Epoch 6/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.7088 - accuracy: 0.5509 - val_loss: 0.7262 - val_accuracy: 0.4896\n","Epoch 7/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.7054 - accuracy: 0.5162 - val_loss: 0.7293 - val_accuracy: 0.5000\n","Epoch 8/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.7145 - accuracy: 0.5394 - val_loss: 0.7345 - val_accuracy: 0.5208\n","Epoch 9/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.7028 - accuracy: 0.5509 - val_loss: 0.7312 - val_accuracy: 0.5208\n","Epoch 10/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6977 - accuracy: 0.5451 - val_loss: 0.7264 - val_accuracy: 0.4896\n","Epoch 11/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.7069 - accuracy: 0.5475 - val_loss: 0.7247 - val_accuracy: 0.4688\n","Epoch 12/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6976 - accuracy: 0.5556 - val_loss: 0.7228 - val_accuracy: 0.4688\n","Epoch 13/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.7064 - accuracy: 0.5289 - val_loss: 0.7245 - val_accuracy: 0.4583\n","Epoch 14/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.7023 - accuracy: 0.5382 - val_loss: 0.7240 - val_accuracy: 0.4688\n","Epoch 15/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6905 - accuracy: 0.5625 - val_loss: 0.7262 - val_accuracy: 0.4271\n","Epoch 16/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.7043 - accuracy: 0.5544 - val_loss: 0.7252 - val_accuracy: 0.4583\n","Epoch 17/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6988 - accuracy: 0.5428 - val_loss: 0.7247 - val_accuracy: 0.4792\n","Epoch 18/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.7034 - accuracy: 0.5370 - val_loss: 0.7248 - val_accuracy: 0.4688\n","Epoch 19/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6856 - accuracy: 0.5718 - val_loss: 0.7266 - val_accuracy: 0.4792\n","Epoch 20/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6988 - accuracy: 0.5417 - val_loss: 0.7256 - val_accuracy: 0.4792\n","Epoch 21/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6949 - accuracy: 0.5625 - val_loss: 0.7240 - val_accuracy: 0.4792\n","Epoch 22/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6907 - accuracy: 0.5579 - val_loss: 0.7229 - val_accuracy: 0.5104\n","Epoch 23/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6900 - accuracy: 0.5509 - val_loss: 0.7240 - val_accuracy: 0.5000\n","Epoch 24/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6965 - accuracy: 0.5405 - val_loss: 0.7238 - val_accuracy: 0.5208\n","Epoch 25/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6965 - accuracy: 0.5544 - val_loss: 0.7246 - val_accuracy: 0.5312\n","Epoch 26/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6951 - accuracy: 0.5718 - val_loss: 0.7247 - val_accuracy: 0.5208\n","Epoch 27/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6829 - accuracy: 0.5683 - val_loss: 0.7260 - val_accuracy: 0.5312\n","Epoch 28/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6848 - accuracy: 0.5567 - val_loss: 0.7279 - val_accuracy: 0.5312\n","Epoch 29/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6853 - accuracy: 0.5752 - val_loss: 0.7271 - val_accuracy: 0.5312\n","Epoch 30/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6997 - accuracy: 0.5405 - val_loss: 0.7274 - val_accuracy: 0.5208\n","Epoch 31/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6870 - accuracy: 0.5532 - val_loss: 0.7277 - val_accuracy: 0.5208\n","Epoch 32/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6845 - accuracy: 0.5880 - val_loss: 0.7275 - val_accuracy: 0.5312\n","Epoch 33/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6816 - accuracy: 0.5683 - val_loss: 0.7265 - val_accuracy: 0.5208\n","Epoch 34/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6838 - accuracy: 0.5741 - val_loss: 0.7241 - val_accuracy: 0.5312\n","Epoch 35/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6878 - accuracy: 0.5694 - val_loss: 0.7250 - val_accuracy: 0.5312\n","Epoch 36/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6899 - accuracy: 0.5567 - val_loss: 0.7255 - val_accuracy: 0.5208\n","Epoch 37/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6857 - accuracy: 0.5625 - val_loss: 0.7273 - val_accuracy: 0.5417\n","Epoch 38/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6727 - accuracy: 0.5775 - val_loss: 0.7247 - val_accuracy: 0.5521\n","Epoch 39/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6852 - accuracy: 0.5613 - val_loss: 0.7241 - val_accuracy: 0.5312\n","Epoch 40/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6754 - accuracy: 0.5868 - val_loss: 0.7234 - val_accuracy: 0.5208\n","Epoch 41/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6931 - accuracy: 0.5648 - val_loss: 0.7234 - val_accuracy: 0.5208\n","Epoch 42/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6884 - accuracy: 0.5417 - val_loss: 0.7247 - val_accuracy: 0.5312\n","Epoch 43/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6781 - accuracy: 0.5613 - val_loss: 0.7247 - val_accuracy: 0.5104\n","Epoch 44/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6739 - accuracy: 0.5775 - val_loss: 0.7242 - val_accuracy: 0.4896\n","Epoch 45/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6851 - accuracy: 0.5729 - val_loss: 0.7233 - val_accuracy: 0.5104\n","Epoch 46/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6790 - accuracy: 0.5694 - val_loss: 0.7246 - val_accuracy: 0.5104\n","Epoch 47/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6855 - accuracy: 0.5475 - val_loss: 0.7238 - val_accuracy: 0.5104\n","Epoch 48/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6923 - accuracy: 0.5382 - val_loss: 0.7250 - val_accuracy: 0.5208\n","Epoch 49/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6865 - accuracy: 0.5718 - val_loss: 0.7238 - val_accuracy: 0.5104\n","Epoch 50/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6823 - accuracy: 0.5741 - val_loss: 0.7254 - val_accuracy: 0.5104\n","Epoch 51/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6862 - accuracy: 0.5532 - val_loss: 0.7269 - val_accuracy: 0.4896\n","Epoch 52/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6880 - accuracy: 0.5602 - val_loss: 0.7279 - val_accuracy: 0.4896\n","Epoch 53/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6858 - accuracy: 0.5694 - val_loss: 0.7299 - val_accuracy: 0.4896\n","Epoch 54/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6835 - accuracy: 0.5718 - val_loss: 0.7284 - val_accuracy: 0.5000\n","Epoch 55/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6733 - accuracy: 0.5648 - val_loss: 0.7275 - val_accuracy: 0.4896\n","Epoch 56/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6910 - accuracy: 0.5625 - val_loss: 0.7280 - val_accuracy: 0.4896\n","Epoch 57/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6818 - accuracy: 0.5718 - val_loss: 0.7286 - val_accuracy: 0.5000\n","Epoch 58/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6780 - accuracy: 0.5694 - val_loss: 0.7302 - val_accuracy: 0.5104\n","Epoch 59/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6739 - accuracy: 0.5683 - val_loss: 0.7302 - val_accuracy: 0.4896\n","Epoch 60/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6867 - accuracy: 0.5590 - val_loss: 0.7315 - val_accuracy: 0.4896\n","Epoch 61/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6903 - accuracy: 0.5590 - val_loss: 0.7317 - val_accuracy: 0.5000\n","Epoch 62/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6695 - accuracy: 0.5787 - val_loss: 0.7317 - val_accuracy: 0.5000\n","Epoch 63/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6757 - accuracy: 0.5822 - val_loss: 0.7325 - val_accuracy: 0.5208\n","Epoch 64/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6919 - accuracy: 0.5671 - val_loss: 0.7303 - val_accuracy: 0.5000\n","Epoch 65/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6828 - accuracy: 0.5648 - val_loss: 0.7292 - val_accuracy: 0.5000\n","Epoch 66/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6743 - accuracy: 0.5718 - val_loss: 0.7291 - val_accuracy: 0.5000\n","Epoch 67/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6746 - accuracy: 0.5822 - val_loss: 0.7289 - val_accuracy: 0.5000\n","Epoch 68/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6812 - accuracy: 0.5787 - val_loss: 0.7301 - val_accuracy: 0.4896\n","Epoch 69/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6709 - accuracy: 0.5810 - val_loss: 0.7291 - val_accuracy: 0.5104\n","Epoch 70/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6725 - accuracy: 0.5891 - val_loss: 0.7297 - val_accuracy: 0.5104\n","Epoch 71/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6853 - accuracy: 0.5625 - val_loss: 0.7296 - val_accuracy: 0.5104\n","Epoch 72/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6864 - accuracy: 0.5660 - val_loss: 0.7284 - val_accuracy: 0.5104\n","Epoch 73/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6798 - accuracy: 0.5671 - val_loss: 0.7279 - val_accuracy: 0.4896\n","Epoch 74/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6667 - accuracy: 0.5984 - val_loss: 0.7291 - val_accuracy: 0.4792\n","Epoch 75/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6738 - accuracy: 0.5891 - val_loss: 0.7282 - val_accuracy: 0.4792\n","Epoch 76/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6762 - accuracy: 0.5856 - val_loss: 0.7272 - val_accuracy: 0.4896\n","Epoch 77/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6767 - accuracy: 0.5949 - val_loss: 0.7273 - val_accuracy: 0.5000\n","Epoch 78/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6663 - accuracy: 0.5938 - val_loss: 0.7263 - val_accuracy: 0.4792\n","Epoch 79/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6755 - accuracy: 0.5544 - val_loss: 0.7259 - val_accuracy: 0.5000\n","Epoch 80/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6830 - accuracy: 0.5567 - val_loss: 0.7254 - val_accuracy: 0.5000\n","Epoch 81/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6773 - accuracy: 0.5752 - val_loss: 0.7253 - val_accuracy: 0.4688\n","Epoch 82/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6765 - accuracy: 0.5671 - val_loss: 0.7254 - val_accuracy: 0.4688\n","Epoch 83/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6811 - accuracy: 0.5706 - val_loss: 0.7255 - val_accuracy: 0.4583\n","Epoch 84/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6737 - accuracy: 0.5903 - val_loss: 0.7254 - val_accuracy: 0.4583\n","Epoch 85/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6792 - accuracy: 0.5880 - val_loss: 0.7253 - val_accuracy: 0.4479\n","Epoch 86/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6675 - accuracy: 0.5972 - val_loss: 0.7256 - val_accuracy: 0.4479\n","Epoch 87/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6876 - accuracy: 0.5567 - val_loss: 0.7233 - val_accuracy: 0.4583\n","Epoch 88/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6643 - accuracy: 0.6088 - val_loss: 0.7214 - val_accuracy: 0.4792\n","Epoch 89/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6697 - accuracy: 0.5671 - val_loss: 0.7224 - val_accuracy: 0.4375\n","Epoch 90/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6739 - accuracy: 0.5602 - val_loss: 0.7231 - val_accuracy: 0.4479\n","Epoch 91/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6805 - accuracy: 0.5833 - val_loss: 0.7244 - val_accuracy: 0.4688\n","Epoch 92/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6683 - accuracy: 0.5706 - val_loss: 0.7256 - val_accuracy: 0.4479\n","Epoch 93/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6681 - accuracy: 0.5880 - val_loss: 0.7266 - val_accuracy: 0.4688\n","Epoch 94/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6656 - accuracy: 0.5822 - val_loss: 0.7273 - val_accuracy: 0.4792\n","Epoch 95/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6667 - accuracy: 0.6030 - val_loss: 0.7276 - val_accuracy: 0.4792\n","Epoch 96/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6802 - accuracy: 0.5694 - val_loss: 0.7271 - val_accuracy: 0.4896\n","Epoch 97/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6698 - accuracy: 0.5660 - val_loss: 0.7294 - val_accuracy: 0.4792\n","Epoch 98/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6782 - accuracy: 0.5660 - val_loss: 0.7272 - val_accuracy: 0.4896\n","Epoch 99/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6663 - accuracy: 0.5775 - val_loss: 0.7286 - val_accuracy: 0.4792\n","Epoch 100/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6780 - accuracy: 0.5729 - val_loss: 0.7291 - val_accuracy: 0.4583\n","Epoch 101/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6741 - accuracy: 0.5775 - val_loss: 0.7296 - val_accuracy: 0.4792\n","Epoch 102/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6710 - accuracy: 0.5949 - val_loss: 0.7293 - val_accuracy: 0.4896\n","Epoch 103/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6674 - accuracy: 0.5880 - val_loss: 0.7294 - val_accuracy: 0.4688\n","Epoch 104/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6744 - accuracy: 0.5579 - val_loss: 0.7290 - val_accuracy: 0.4688\n","Epoch 105/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6653 - accuracy: 0.5984 - val_loss: 0.7300 - val_accuracy: 0.4688\n","Epoch 106/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6573 - accuracy: 0.6157 - val_loss: 0.7284 - val_accuracy: 0.4375\n","Epoch 107/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6768 - accuracy: 0.5556 - val_loss: 0.7294 - val_accuracy: 0.4896\n","Epoch 108/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6667 - accuracy: 0.5868 - val_loss: 0.7294 - val_accuracy: 0.4688\n","Epoch 109/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6726 - accuracy: 0.5764 - val_loss: 0.7316 - val_accuracy: 0.4792\n","Epoch 110/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6698 - accuracy: 0.5926 - val_loss: 0.7329 - val_accuracy: 0.4792\n","Epoch 111/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6713 - accuracy: 0.5694 - val_loss: 0.7345 - val_accuracy: 0.4792\n","Epoch 112/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6667 - accuracy: 0.6030 - val_loss: 0.7357 - val_accuracy: 0.4583\n","Epoch 113/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6669 - accuracy: 0.5984 - val_loss: 0.7360 - val_accuracy: 0.4792\n","Epoch 114/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6742 - accuracy: 0.5660 - val_loss: 0.7376 - val_accuracy: 0.4792\n","Epoch 115/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6679 - accuracy: 0.5775 - val_loss: 0.7370 - val_accuracy: 0.4688\n","Epoch 116/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6629 - accuracy: 0.5972 - val_loss: 0.7378 - val_accuracy: 0.4375\n","Epoch 117/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6582 - accuracy: 0.6065 - val_loss: 0.7374 - val_accuracy: 0.4479\n","Epoch 118/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6659 - accuracy: 0.6134 - val_loss: 0.7390 - val_accuracy: 0.4583\n","Epoch 119/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6699 - accuracy: 0.5880 - val_loss: 0.7378 - val_accuracy: 0.4479\n","Epoch 120/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6640 - accuracy: 0.5868 - val_loss: 0.7373 - val_accuracy: 0.4479\n","Epoch 121/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6731 - accuracy: 0.5752 - val_loss: 0.7353 - val_accuracy: 0.4375\n","Epoch 122/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6732 - accuracy: 0.5671 - val_loss: 0.7359 - val_accuracy: 0.4375\n","Epoch 123/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6718 - accuracy: 0.5961 - val_loss: 0.7372 - val_accuracy: 0.4271\n","Epoch 124/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6719 - accuracy: 0.5810 - val_loss: 0.7354 - val_accuracy: 0.4271\n","Epoch 125/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6680 - accuracy: 0.5729 - val_loss: 0.7333 - val_accuracy: 0.4375\n","Epoch 126/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6631 - accuracy: 0.5972 - val_loss: 0.7339 - val_accuracy: 0.4479\n","Epoch 127/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6704 - accuracy: 0.5984 - val_loss: 0.7338 - val_accuracy: 0.4271\n","Epoch 128/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6687 - accuracy: 0.5949 - val_loss: 0.7331 - val_accuracy: 0.4167\n","Epoch 129/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6600 - accuracy: 0.5995 - val_loss: 0.7331 - val_accuracy: 0.4375\n","Epoch 130/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6615 - accuracy: 0.5764 - val_loss: 0.7330 - val_accuracy: 0.4375\n","Epoch 131/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6620 - accuracy: 0.5903 - val_loss: 0.7343 - val_accuracy: 0.4375\n","Epoch 132/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6855 - accuracy: 0.5394 - val_loss: 0.7336 - val_accuracy: 0.4479\n","Epoch 133/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6673 - accuracy: 0.5856 - val_loss: 0.7329 - val_accuracy: 0.4167\n","Epoch 134/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6647 - accuracy: 0.5880 - val_loss: 0.7328 - val_accuracy: 0.4271\n","Epoch 135/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6653 - accuracy: 0.6100 - val_loss: 0.7344 - val_accuracy: 0.4271\n","Epoch 136/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6678 - accuracy: 0.5972 - val_loss: 0.7329 - val_accuracy: 0.4375\n","Epoch 137/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6568 - accuracy: 0.6042 - val_loss: 0.7337 - val_accuracy: 0.4479\n","Epoch 138/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6608 - accuracy: 0.5903 - val_loss: 0.7327 - val_accuracy: 0.4375\n","Epoch 139/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6628 - accuracy: 0.6019 - val_loss: 0.7341 - val_accuracy: 0.4375\n","Epoch 140/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6613 - accuracy: 0.5891 - val_loss: 0.7325 - val_accuracy: 0.4583\n","Epoch 141/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6624 - accuracy: 0.6181 - val_loss: 0.7334 - val_accuracy: 0.4271\n","Epoch 142/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6595 - accuracy: 0.6030 - val_loss: 0.7334 - val_accuracy: 0.4271\n","Epoch 143/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6664 - accuracy: 0.5880 - val_loss: 0.7340 - val_accuracy: 0.4375\n","Epoch 144/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6614 - accuracy: 0.5880 - val_loss: 0.7333 - val_accuracy: 0.4688\n","Epoch 145/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6632 - accuracy: 0.6088 - val_loss: 0.7334 - val_accuracy: 0.4479\n","Epoch 146/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6557 - accuracy: 0.6181 - val_loss: 0.7343 - val_accuracy: 0.4375\n","Epoch 147/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6659 - accuracy: 0.5891 - val_loss: 0.7350 - val_accuracy: 0.4375\n","Epoch 148/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6654 - accuracy: 0.5880 - val_loss: 0.7364 - val_accuracy: 0.4375\n","Epoch 149/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6690 - accuracy: 0.5822 - val_loss: 0.7367 - val_accuracy: 0.4375\n","Epoch 150/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6644 - accuracy: 0.6065 - val_loss: 0.7365 - val_accuracy: 0.4479\n","Epoch 151/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6550 - accuracy: 0.5972 - val_loss: 0.7359 - val_accuracy: 0.4583\n","Epoch 152/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6678 - accuracy: 0.5903 - val_loss: 0.7356 - val_accuracy: 0.4583\n","Epoch 153/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6550 - accuracy: 0.6030 - val_loss: 0.7369 - val_accuracy: 0.4479\n","Epoch 154/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6555 - accuracy: 0.6053 - val_loss: 0.7367 - val_accuracy: 0.4583\n","Epoch 155/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6579 - accuracy: 0.6100 - val_loss: 0.7366 - val_accuracy: 0.4479\n","Epoch 156/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6639 - accuracy: 0.6042 - val_loss: 0.7369 - val_accuracy: 0.4583\n","Epoch 157/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6556 - accuracy: 0.5972 - val_loss: 0.7359 - val_accuracy: 0.4896\n","Epoch 158/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6658 - accuracy: 0.6146 - val_loss: 0.7351 - val_accuracy: 0.4792\n","Epoch 159/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6507 - accuracy: 0.6262 - val_loss: 0.7352 - val_accuracy: 0.4792\n","Epoch 160/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6597 - accuracy: 0.6111 - val_loss: 0.7357 - val_accuracy: 0.4896\n","Epoch 161/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6521 - accuracy: 0.6146 - val_loss: 0.7354 - val_accuracy: 0.4688\n","Epoch 162/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6549 - accuracy: 0.6204 - val_loss: 0.7349 - val_accuracy: 0.4896\n","Epoch 163/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6595 - accuracy: 0.6076 - val_loss: 0.7354 - val_accuracy: 0.4896\n","Epoch 164/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6527 - accuracy: 0.6285 - val_loss: 0.7353 - val_accuracy: 0.4896\n","Epoch 165/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6607 - accuracy: 0.6042 - val_loss: 0.7338 - val_accuracy: 0.4896\n","Epoch 166/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6459 - accuracy: 0.6192 - val_loss: 0.7337 - val_accuracy: 0.4896\n","Epoch 167/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6561 - accuracy: 0.6100 - val_loss: 0.7345 - val_accuracy: 0.4896\n","Epoch 168/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6667 - accuracy: 0.5856 - val_loss: 0.7345 - val_accuracy: 0.4792\n","Epoch 169/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6552 - accuracy: 0.6192 - val_loss: 0.7350 - val_accuracy: 0.4792\n","Epoch 170/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6598 - accuracy: 0.6019 - val_loss: 0.7361 - val_accuracy: 0.4688\n","Epoch 171/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6691 - accuracy: 0.5752 - val_loss: 0.7351 - val_accuracy: 0.4792\n","Epoch 172/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6675 - accuracy: 0.5995 - val_loss: 0.7361 - val_accuracy: 0.4792\n","Epoch 173/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6575 - accuracy: 0.5949 - val_loss: 0.7374 - val_accuracy: 0.4792\n","Epoch 174/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6483 - accuracy: 0.6146 - val_loss: 0.7382 - val_accuracy: 0.4792\n","Epoch 175/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6541 - accuracy: 0.6146 - val_loss: 0.7381 - val_accuracy: 0.4896\n","Epoch 176/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6596 - accuracy: 0.6019 - val_loss: 0.7371 - val_accuracy: 0.4896\n","Epoch 177/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6526 - accuracy: 0.6042 - val_loss: 0.7357 - val_accuracy: 0.4792\n","Epoch 178/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6601 - accuracy: 0.6065 - val_loss: 0.7370 - val_accuracy: 0.4896\n","Epoch 179/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6553 - accuracy: 0.6030 - val_loss: 0.7353 - val_accuracy: 0.4896\n","Epoch 180/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6502 - accuracy: 0.6157 - val_loss: 0.7358 - val_accuracy: 0.4792\n","Epoch 181/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6503 - accuracy: 0.6377 - val_loss: 0.7374 - val_accuracy: 0.4583\n","Epoch 182/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6477 - accuracy: 0.6285 - val_loss: 0.7386 - val_accuracy: 0.4583\n","Epoch 183/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6572 - accuracy: 0.5891 - val_loss: 0.7388 - val_accuracy: 0.4583\n","Epoch 184/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6549 - accuracy: 0.5949 - val_loss: 0.7387 - val_accuracy: 0.4583\n","Epoch 185/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6533 - accuracy: 0.5995 - val_loss: 0.7383 - val_accuracy: 0.4583\n","Epoch 186/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6489 - accuracy: 0.6238 - val_loss: 0.7400 - val_accuracy: 0.4688\n","Epoch 187/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6536 - accuracy: 0.6111 - val_loss: 0.7397 - val_accuracy: 0.4583\n","Epoch 188/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6535 - accuracy: 0.6042 - val_loss: 0.7397 - val_accuracy: 0.4479\n","Epoch 189/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6602 - accuracy: 0.6123 - val_loss: 0.7410 - val_accuracy: 0.4583\n","Epoch 190/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6526 - accuracy: 0.6354 - val_loss: 0.7386 - val_accuracy: 0.4479\n","Epoch 191/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6431 - accuracy: 0.6319 - val_loss: 0.7386 - val_accuracy: 0.4688\n","Epoch 192/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6502 - accuracy: 0.6343 - val_loss: 0.7394 - val_accuracy: 0.4479\n","Epoch 193/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6512 - accuracy: 0.6169 - val_loss: 0.7386 - val_accuracy: 0.4479\n","Epoch 194/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6566 - accuracy: 0.5903 - val_loss: 0.7387 - val_accuracy: 0.4583\n","Epoch 195/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6533 - accuracy: 0.6042 - val_loss: 0.7400 - val_accuracy: 0.4792\n","Epoch 196/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6475 - accuracy: 0.6215 - val_loss: 0.7412 - val_accuracy: 0.4688\n","Epoch 197/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6407 - accuracy: 0.6343 - val_loss: 0.7402 - val_accuracy: 0.4688\n","Epoch 198/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6472 - accuracy: 0.6296 - val_loss: 0.7402 - val_accuracy: 0.5000\n","Epoch 199/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6495 - accuracy: 0.6296 - val_loss: 0.7416 - val_accuracy: 0.5000\n","Epoch 200/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6525 - accuracy: 0.6157 - val_loss: 0.7438 - val_accuracy: 0.4792\n","8/8 [==============================] - 0s 12ms/step - loss: 0.6913 - accuracy: 0.5833\n","[0.691333532333374, 0.5833333134651184]\n","Results for fold 8\n","Epoch 1/200\n","14/14 [==============================] - 7s 117ms/step - loss: 0.7213 - accuracy: 0.5081 - val_loss: 0.7185 - val_accuracy: 0.4792\n","Epoch 2/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.7088 - accuracy: 0.5521 - val_loss: 0.7148 - val_accuracy: 0.4896\n","Epoch 3/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.7069 - accuracy: 0.5347 - val_loss: 0.7015 - val_accuracy: 0.5104\n","Epoch 4/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.7113 - accuracy: 0.5289 - val_loss: 0.6956 - val_accuracy: 0.5104\n","Epoch 5/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6936 - accuracy: 0.5637 - val_loss: 0.6869 - val_accuracy: 0.5938\n","Epoch 6/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.7047 - accuracy: 0.5463 - val_loss: 0.6879 - val_accuracy: 0.5625\n","Epoch 7/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.7038 - accuracy: 0.5127 - val_loss: 0.6881 - val_accuracy: 0.6042\n","Epoch 8/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6995 - accuracy: 0.5486 - val_loss: 0.6859 - val_accuracy: 0.6146\n","Epoch 9/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6893 - accuracy: 0.5486 - val_loss: 0.6858 - val_accuracy: 0.5625\n","Epoch 10/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6987 - accuracy: 0.5463 - val_loss: 0.6857 - val_accuracy: 0.5729\n","Epoch 11/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6952 - accuracy: 0.5590 - val_loss: 0.6849 - val_accuracy: 0.5938\n","Epoch 12/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6937 - accuracy: 0.5521 - val_loss: 0.6853 - val_accuracy: 0.5625\n","Epoch 13/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6773 - accuracy: 0.5845 - val_loss: 0.6842 - val_accuracy: 0.5625\n","Epoch 14/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.7067 - accuracy: 0.5451 - val_loss: 0.6841 - val_accuracy: 0.5521\n","Epoch 15/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6857 - accuracy: 0.5428 - val_loss: 0.6841 - val_accuracy: 0.5938\n","Epoch 16/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6970 - accuracy: 0.5405 - val_loss: 0.6851 - val_accuracy: 0.5938\n","Epoch 17/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6972 - accuracy: 0.5532 - val_loss: 0.6889 - val_accuracy: 0.6042\n","Epoch 18/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6809 - accuracy: 0.5556 - val_loss: 0.6901 - val_accuracy: 0.5833\n","Epoch 19/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6952 - accuracy: 0.5486 - val_loss: 0.6893 - val_accuracy: 0.6042\n","Epoch 20/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6907 - accuracy: 0.5417 - val_loss: 0.6908 - val_accuracy: 0.5938\n","Epoch 21/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6909 - accuracy: 0.5475 - val_loss: 0.6912 - val_accuracy: 0.5833\n","Epoch 22/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6847 - accuracy: 0.5532 - val_loss: 0.6930 - val_accuracy: 0.5729\n","Epoch 23/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6851 - accuracy: 0.5613 - val_loss: 0.6944 - val_accuracy: 0.5625\n","Epoch 24/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6784 - accuracy: 0.5752 - val_loss: 0.6946 - val_accuracy: 0.5417\n","Epoch 25/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6881 - accuracy: 0.5637 - val_loss: 0.6958 - val_accuracy: 0.5312\n","Epoch 26/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6831 - accuracy: 0.5498 - val_loss: 0.6931 - val_accuracy: 0.5729\n","Epoch 27/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6909 - accuracy: 0.5475 - val_loss: 0.6938 - val_accuracy: 0.5417\n","Epoch 28/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6785 - accuracy: 0.5729 - val_loss: 0.6925 - val_accuracy: 0.5312\n","Epoch 29/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6891 - accuracy: 0.5544 - val_loss: 0.6944 - val_accuracy: 0.5625\n","Epoch 30/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6794 - accuracy: 0.5579 - val_loss: 0.6960 - val_accuracy: 0.5417\n","Epoch 31/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6840 - accuracy: 0.5799 - val_loss: 0.6970 - val_accuracy: 0.5521\n","Epoch 32/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6840 - accuracy: 0.5602 - val_loss: 0.6983 - val_accuracy: 0.5521\n","Epoch 33/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6737 - accuracy: 0.5787 - val_loss: 0.7013 - val_accuracy: 0.5208\n","Epoch 34/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6963 - accuracy: 0.5289 - val_loss: 0.7025 - val_accuracy: 0.5104\n","Epoch 35/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6844 - accuracy: 0.5556 - val_loss: 0.7030 - val_accuracy: 0.5104\n","Epoch 36/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6833 - accuracy: 0.5590 - val_loss: 0.7040 - val_accuracy: 0.5000\n","Epoch 37/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6847 - accuracy: 0.5671 - val_loss: 0.7036 - val_accuracy: 0.5208\n","Epoch 38/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6834 - accuracy: 0.5637 - val_loss: 0.7045 - val_accuracy: 0.5312\n","Epoch 39/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6782 - accuracy: 0.5718 - val_loss: 0.7056 - val_accuracy: 0.5312\n","Epoch 40/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6789 - accuracy: 0.5706 - val_loss: 0.7057 - val_accuracy: 0.5417\n","Epoch 41/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6752 - accuracy: 0.5868 - val_loss: 0.7018 - val_accuracy: 0.5208\n","Epoch 42/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6767 - accuracy: 0.5752 - val_loss: 0.7017 - val_accuracy: 0.5208\n","Epoch 43/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6783 - accuracy: 0.5706 - val_loss: 0.7032 - val_accuracy: 0.5104\n","Epoch 44/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6844 - accuracy: 0.5463 - val_loss: 0.7034 - val_accuracy: 0.4896\n","Epoch 45/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6768 - accuracy: 0.5602 - val_loss: 0.7078 - val_accuracy: 0.4688\n","Epoch 46/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6819 - accuracy: 0.5613 - val_loss: 0.7109 - val_accuracy: 0.4583\n","Epoch 47/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6842 - accuracy: 0.5625 - val_loss: 0.7099 - val_accuracy: 0.4479\n","Epoch 48/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6781 - accuracy: 0.5660 - val_loss: 0.7090 - val_accuracy: 0.4583\n","Epoch 49/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6715 - accuracy: 0.5938 - val_loss: 0.7088 - val_accuracy: 0.4688\n","Epoch 50/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6777 - accuracy: 0.5706 - val_loss: 0.7070 - val_accuracy: 0.4792\n","Epoch 51/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6810 - accuracy: 0.5521 - val_loss: 0.7085 - val_accuracy: 0.4792\n","Epoch 52/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6874 - accuracy: 0.5475 - val_loss: 0.7109 - val_accuracy: 0.4896\n","Epoch 53/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6827 - accuracy: 0.5764 - val_loss: 0.7138 - val_accuracy: 0.4792\n","Epoch 54/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6784 - accuracy: 0.5556 - val_loss: 0.7119 - val_accuracy: 0.4896\n","Epoch 55/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6759 - accuracy: 0.5683 - val_loss: 0.7097 - val_accuracy: 0.4896\n","Epoch 56/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6739 - accuracy: 0.5845 - val_loss: 0.7078 - val_accuracy: 0.4688\n","Epoch 57/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6765 - accuracy: 0.5660 - val_loss: 0.7074 - val_accuracy: 0.4896\n","Epoch 58/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6790 - accuracy: 0.5775 - val_loss: 0.7087 - val_accuracy: 0.5104\n","Epoch 59/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6816 - accuracy: 0.5660 - val_loss: 0.7109 - val_accuracy: 0.4792\n","Epoch 60/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6882 - accuracy: 0.5590 - val_loss: 0.7120 - val_accuracy: 0.4896\n","Epoch 61/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6772 - accuracy: 0.5671 - val_loss: 0.7090 - val_accuracy: 0.4896\n","Epoch 62/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6803 - accuracy: 0.5579 - val_loss: 0.7091 - val_accuracy: 0.4792\n","Epoch 63/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6840 - accuracy: 0.5648 - val_loss: 0.7097 - val_accuracy: 0.4792\n","Epoch 64/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6733 - accuracy: 0.5926 - val_loss: 0.7109 - val_accuracy: 0.4792\n","Epoch 65/200\n","14/14 [==============================] - 0s 25ms/step - loss: 0.6761 - accuracy: 0.5637 - val_loss: 0.7108 - val_accuracy: 0.4792\n","Epoch 66/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6759 - accuracy: 0.5590 - val_loss: 0.7106 - val_accuracy: 0.4792\n","Epoch 67/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6704 - accuracy: 0.5799 - val_loss: 0.7115 - val_accuracy: 0.4792\n","Epoch 68/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6769 - accuracy: 0.5868 - val_loss: 0.7112 - val_accuracy: 0.4896\n","Epoch 69/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6764 - accuracy: 0.5833 - val_loss: 0.7114 - val_accuracy: 0.4792\n","Epoch 70/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6739 - accuracy: 0.5718 - val_loss: 0.7113 - val_accuracy: 0.5208\n","Epoch 71/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6761 - accuracy: 0.5671 - val_loss: 0.7125 - val_accuracy: 0.5104\n","Epoch 72/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6753 - accuracy: 0.5694 - val_loss: 0.7136 - val_accuracy: 0.4792\n","Epoch 73/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6714 - accuracy: 0.5833 - val_loss: 0.7139 - val_accuracy: 0.4896\n","Epoch 74/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6762 - accuracy: 0.5648 - val_loss: 0.7131 - val_accuracy: 0.4792\n","Epoch 75/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6707 - accuracy: 0.5602 - val_loss: 0.7118 - val_accuracy: 0.5000\n","Epoch 76/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6758 - accuracy: 0.5787 - val_loss: 0.7096 - val_accuracy: 0.4896\n","Epoch 77/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6759 - accuracy: 0.5729 - val_loss: 0.7085 - val_accuracy: 0.5104\n","Epoch 78/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6715 - accuracy: 0.5926 - val_loss: 0.7078 - val_accuracy: 0.5000\n","Epoch 79/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6777 - accuracy: 0.5914 - val_loss: 0.7088 - val_accuracy: 0.5000\n","Epoch 80/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6748 - accuracy: 0.5521 - val_loss: 0.7123 - val_accuracy: 0.4896\n","Epoch 81/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6762 - accuracy: 0.5590 - val_loss: 0.7111 - val_accuracy: 0.5000\n","Epoch 82/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6724 - accuracy: 0.5799 - val_loss: 0.7097 - val_accuracy: 0.5000\n","Epoch 83/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6786 - accuracy: 0.5648 - val_loss: 0.7103 - val_accuracy: 0.5104\n","Epoch 84/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6810 - accuracy: 0.5602 - val_loss: 0.7109 - val_accuracy: 0.5208\n","Epoch 85/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6693 - accuracy: 0.5729 - val_loss: 0.7100 - val_accuracy: 0.5312\n","Epoch 86/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6799 - accuracy: 0.5590 - val_loss: 0.7100 - val_accuracy: 0.5312\n","Epoch 87/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6706 - accuracy: 0.5833 - val_loss: 0.7128 - val_accuracy: 0.5208\n","Epoch 88/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6739 - accuracy: 0.5729 - val_loss: 0.7119 - val_accuracy: 0.5208\n","Epoch 89/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6713 - accuracy: 0.5706 - val_loss: 0.7111 - val_accuracy: 0.4896\n","Epoch 90/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6645 - accuracy: 0.5984 - val_loss: 0.7120 - val_accuracy: 0.5000\n","Epoch 91/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6688 - accuracy: 0.5926 - val_loss: 0.7112 - val_accuracy: 0.4792\n","Epoch 92/200\n","14/14 [==============================] - 0s 26ms/step - loss: 0.6721 - accuracy: 0.5752 - val_loss: 0.7113 - val_accuracy: 0.4896\n","Epoch 93/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6711 - accuracy: 0.5683 - val_loss: 0.7129 - val_accuracy: 0.4688\n","Epoch 94/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6760 - accuracy: 0.5602 - val_loss: 0.7143 - val_accuracy: 0.4792\n","Epoch 95/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6725 - accuracy: 0.5799 - val_loss: 0.7140 - val_accuracy: 0.4583\n","Epoch 96/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6665 - accuracy: 0.5995 - val_loss: 0.7159 - val_accuracy: 0.4583\n","Epoch 97/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6746 - accuracy: 0.5694 - val_loss: 0.7161 - val_accuracy: 0.4583\n","Epoch 98/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6747 - accuracy: 0.5764 - val_loss: 0.7162 - val_accuracy: 0.4792\n","Epoch 99/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6662 - accuracy: 0.5856 - val_loss: 0.7149 - val_accuracy: 0.4688\n","Epoch 100/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6820 - accuracy: 0.5602 - val_loss: 0.7148 - val_accuracy: 0.4896\n","Epoch 101/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6734 - accuracy: 0.5671 - val_loss: 0.7146 - val_accuracy: 0.4688\n","Epoch 102/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6759 - accuracy: 0.5799 - val_loss: 0.7172 - val_accuracy: 0.4792\n","Epoch 103/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6737 - accuracy: 0.5810 - val_loss: 0.7179 - val_accuracy: 0.4688\n","Epoch 104/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6694 - accuracy: 0.5706 - val_loss: 0.7178 - val_accuracy: 0.4792\n","Epoch 105/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6689 - accuracy: 0.5891 - val_loss: 0.7192 - val_accuracy: 0.4792\n","Epoch 106/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6710 - accuracy: 0.5868 - val_loss: 0.7211 - val_accuracy: 0.4896\n","Epoch 107/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6758 - accuracy: 0.5706 - val_loss: 0.7225 - val_accuracy: 0.4479\n","Epoch 108/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6672 - accuracy: 0.5880 - val_loss: 0.7204 - val_accuracy: 0.4688\n","Epoch 109/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6688 - accuracy: 0.5926 - val_loss: 0.7222 - val_accuracy: 0.4583\n","Epoch 110/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6690 - accuracy: 0.5741 - val_loss: 0.7221 - val_accuracy: 0.4792\n","Epoch 111/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6773 - accuracy: 0.5729 - val_loss: 0.7222 - val_accuracy: 0.4688\n","Epoch 112/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6764 - accuracy: 0.5637 - val_loss: 0.7223 - val_accuracy: 0.4792\n","Epoch 113/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6710 - accuracy: 0.5926 - val_loss: 0.7219 - val_accuracy: 0.4479\n","Epoch 114/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6683 - accuracy: 0.5845 - val_loss: 0.7236 - val_accuracy: 0.4583\n","Epoch 115/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6699 - accuracy: 0.5810 - val_loss: 0.7258 - val_accuracy: 0.4583\n","Epoch 116/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6722 - accuracy: 0.5752 - val_loss: 0.7272 - val_accuracy: 0.4479\n","Epoch 117/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6747 - accuracy: 0.5718 - val_loss: 0.7260 - val_accuracy: 0.4375\n","Epoch 118/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6725 - accuracy: 0.5775 - val_loss: 0.7264 - val_accuracy: 0.4271\n","Epoch 119/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6681 - accuracy: 0.5961 - val_loss: 0.7256 - val_accuracy: 0.4375\n","Epoch 120/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6728 - accuracy: 0.5810 - val_loss: 0.7251 - val_accuracy: 0.4479\n","Epoch 121/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6717 - accuracy: 0.5856 - val_loss: 0.7228 - val_accuracy: 0.4479\n","Epoch 122/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6691 - accuracy: 0.5845 - val_loss: 0.7209 - val_accuracy: 0.4375\n","Epoch 123/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6752 - accuracy: 0.5694 - val_loss: 0.7194 - val_accuracy: 0.4479\n","Epoch 124/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6749 - accuracy: 0.5845 - val_loss: 0.7195 - val_accuracy: 0.4375\n","Epoch 125/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6714 - accuracy: 0.5764 - val_loss: 0.7209 - val_accuracy: 0.4479\n","Epoch 126/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6675 - accuracy: 0.5799 - val_loss: 0.7195 - val_accuracy: 0.4583\n","Epoch 127/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6710 - accuracy: 0.5903 - val_loss: 0.7202 - val_accuracy: 0.4583\n","Epoch 128/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6618 - accuracy: 0.5972 - val_loss: 0.7239 - val_accuracy: 0.4479\n","Epoch 129/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6660 - accuracy: 0.5810 - val_loss: 0.7239 - val_accuracy: 0.4375\n","Epoch 130/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6733 - accuracy: 0.5799 - val_loss: 0.7255 - val_accuracy: 0.4271\n","Epoch 131/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6697 - accuracy: 0.5671 - val_loss: 0.7236 - val_accuracy: 0.4375\n","Epoch 132/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6701 - accuracy: 0.5799 - val_loss: 0.7226 - val_accuracy: 0.4375\n","Epoch 133/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6703 - accuracy: 0.5764 - val_loss: 0.7226 - val_accuracy: 0.4479\n","Epoch 134/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6612 - accuracy: 0.6030 - val_loss: 0.7253 - val_accuracy: 0.4271\n","Epoch 135/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6630 - accuracy: 0.5972 - val_loss: 0.7243 - val_accuracy: 0.4271\n","Epoch 136/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6727 - accuracy: 0.5880 - val_loss: 0.7263 - val_accuracy: 0.4479\n","Epoch 137/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6719 - accuracy: 0.5868 - val_loss: 0.7257 - val_accuracy: 0.4479\n","Epoch 138/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6647 - accuracy: 0.5787 - val_loss: 0.7264 - val_accuracy: 0.4271\n","Epoch 139/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6701 - accuracy: 0.5833 - val_loss: 0.7246 - val_accuracy: 0.4271\n","Epoch 140/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6660 - accuracy: 0.5949 - val_loss: 0.7225 - val_accuracy: 0.4375\n","Epoch 141/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6727 - accuracy: 0.5637 - val_loss: 0.7200 - val_accuracy: 0.4479\n","Epoch 142/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6685 - accuracy: 0.5822 - val_loss: 0.7202 - val_accuracy: 0.4271\n","Epoch 143/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6669 - accuracy: 0.5764 - val_loss: 0.7201 - val_accuracy: 0.4375\n","Epoch 144/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6570 - accuracy: 0.6192 - val_loss: 0.7205 - val_accuracy: 0.4479\n","Epoch 145/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6681 - accuracy: 0.5868 - val_loss: 0.7233 - val_accuracy: 0.4792\n","Epoch 146/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6606 - accuracy: 0.6065 - val_loss: 0.7271 - val_accuracy: 0.4375\n","Epoch 147/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6681 - accuracy: 0.5764 - val_loss: 0.7279 - val_accuracy: 0.4375\n","Epoch 148/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6666 - accuracy: 0.5972 - val_loss: 0.7244 - val_accuracy: 0.4375\n","Epoch 149/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6614 - accuracy: 0.5729 - val_loss: 0.7238 - val_accuracy: 0.4375\n","Epoch 150/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6594 - accuracy: 0.6146 - val_loss: 0.7211 - val_accuracy: 0.4375\n","Epoch 151/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6583 - accuracy: 0.6007 - val_loss: 0.7212 - val_accuracy: 0.4583\n","Epoch 152/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6695 - accuracy: 0.5799 - val_loss: 0.7217 - val_accuracy: 0.4583\n","Epoch 153/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6657 - accuracy: 0.5868 - val_loss: 0.7202 - val_accuracy: 0.4688\n","Epoch 154/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6634 - accuracy: 0.5775 - val_loss: 0.7206 - val_accuracy: 0.4479\n","Epoch 155/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6620 - accuracy: 0.5914 - val_loss: 0.7217 - val_accuracy: 0.4583\n","Epoch 156/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6738 - accuracy: 0.5567 - val_loss: 0.7213 - val_accuracy: 0.4583\n","Epoch 157/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6617 - accuracy: 0.5972 - val_loss: 0.7214 - val_accuracy: 0.4583\n","Epoch 158/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6618 - accuracy: 0.5938 - val_loss: 0.7220 - val_accuracy: 0.4479\n","Epoch 159/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6650 - accuracy: 0.5891 - val_loss: 0.7233 - val_accuracy: 0.4479\n","Epoch 160/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6704 - accuracy: 0.5914 - val_loss: 0.7240 - val_accuracy: 0.4583\n","Epoch 161/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6691 - accuracy: 0.5961 - val_loss: 0.7245 - val_accuracy: 0.4583\n","Epoch 162/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6589 - accuracy: 0.5741 - val_loss: 0.7235 - val_accuracy: 0.4583\n","Epoch 163/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6619 - accuracy: 0.5914 - val_loss: 0.7201 - val_accuracy: 0.4479\n","Epoch 164/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6638 - accuracy: 0.5961 - val_loss: 0.7182 - val_accuracy: 0.4583\n","Epoch 165/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6650 - accuracy: 0.5810 - val_loss: 0.7199 - val_accuracy: 0.4479\n","Epoch 166/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6601 - accuracy: 0.6019 - val_loss: 0.7210 - val_accuracy: 0.4583\n","Epoch 167/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6631 - accuracy: 0.6007 - val_loss: 0.7215 - val_accuracy: 0.4688\n","Epoch 168/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6659 - accuracy: 0.5752 - val_loss: 0.7208 - val_accuracy: 0.4688\n","Epoch 169/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6731 - accuracy: 0.5764 - val_loss: 0.7228 - val_accuracy: 0.4583\n","Epoch 170/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6631 - accuracy: 0.5833 - val_loss: 0.7266 - val_accuracy: 0.4271\n","Epoch 171/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6540 - accuracy: 0.6053 - val_loss: 0.7236 - val_accuracy: 0.4583\n","Epoch 172/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6633 - accuracy: 0.5972 - val_loss: 0.7229 - val_accuracy: 0.4479\n","Epoch 173/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6629 - accuracy: 0.6100 - val_loss: 0.7219 - val_accuracy: 0.4583\n","Epoch 174/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6636 - accuracy: 0.5833 - val_loss: 0.7211 - val_accuracy: 0.4583\n","Epoch 175/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6609 - accuracy: 0.6076 - val_loss: 0.7210 - val_accuracy: 0.4583\n","Epoch 176/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6609 - accuracy: 0.6053 - val_loss: 0.7220 - val_accuracy: 0.4583\n","Epoch 177/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6589 - accuracy: 0.5868 - val_loss: 0.7213 - val_accuracy: 0.4479\n","Epoch 178/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6565 - accuracy: 0.6042 - val_loss: 0.7231 - val_accuracy: 0.4271\n","Epoch 179/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6607 - accuracy: 0.5938 - val_loss: 0.7219 - val_accuracy: 0.4583\n","Epoch 180/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6632 - accuracy: 0.5764 - val_loss: 0.7214 - val_accuracy: 0.4375\n","Epoch 181/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6671 - accuracy: 0.5880 - val_loss: 0.7199 - val_accuracy: 0.4271\n","Epoch 182/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6612 - accuracy: 0.6030 - val_loss: 0.7220 - val_accuracy: 0.4271\n","Epoch 183/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6641 - accuracy: 0.5891 - val_loss: 0.7207 - val_accuracy: 0.4271\n","Epoch 184/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6538 - accuracy: 0.5914 - val_loss: 0.7196 - val_accuracy: 0.4271\n","Epoch 185/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6643 - accuracy: 0.6157 - val_loss: 0.7179 - val_accuracy: 0.4583\n","Epoch 186/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6488 - accuracy: 0.5995 - val_loss: 0.7191 - val_accuracy: 0.4479\n","Epoch 187/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6550 - accuracy: 0.5984 - val_loss: 0.7224 - val_accuracy: 0.4583\n","Epoch 188/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6582 - accuracy: 0.6065 - val_loss: 0.7236 - val_accuracy: 0.4583\n","Epoch 189/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6514 - accuracy: 0.6169 - val_loss: 0.7229 - val_accuracy: 0.4583\n","Epoch 190/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6640 - accuracy: 0.5845 - val_loss: 0.7230 - val_accuracy: 0.4583\n","Epoch 191/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6587 - accuracy: 0.6065 - val_loss: 0.7215 - val_accuracy: 0.4792\n","Epoch 192/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6589 - accuracy: 0.6111 - val_loss: 0.7186 - val_accuracy: 0.4896\n","Epoch 193/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6600 - accuracy: 0.6019 - val_loss: 0.7194 - val_accuracy: 0.4792\n","Epoch 194/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6679 - accuracy: 0.5810 - val_loss: 0.7202 - val_accuracy: 0.4688\n","Epoch 195/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6573 - accuracy: 0.6100 - val_loss: 0.7189 - val_accuracy: 0.4479\n","Epoch 196/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6498 - accuracy: 0.6192 - val_loss: 0.7198 - val_accuracy: 0.4583\n","Epoch 197/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6605 - accuracy: 0.6042 - val_loss: 0.7188 - val_accuracy: 0.4583\n","Epoch 198/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6649 - accuracy: 0.5938 - val_loss: 0.7225 - val_accuracy: 0.4479\n","Epoch 199/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6544 - accuracy: 0.5914 - val_loss: 0.7234 - val_accuracy: 0.4479\n","Epoch 200/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6579 - accuracy: 0.5972 - val_loss: 0.7220 - val_accuracy: 0.4688\n","8/8 [==============================] - 0s 12ms/step - loss: 0.6824 - accuracy: 0.5208\n","[0.6824229955673218, 0.5208333134651184]\n","Results for fold 9\n","Epoch 1/200\n","14/14 [==============================] - 7s 116ms/step - loss: 0.9561 - accuracy: 0.5428 - val_loss: 0.8366 - val_accuracy: 0.5833\n","Epoch 2/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.8612 - accuracy: 0.5475 - val_loss: 0.7245 - val_accuracy: 0.5833\n","Epoch 3/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.7731 - accuracy: 0.5521 - val_loss: 0.6707 - val_accuracy: 0.5833\n","Epoch 4/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.7413 - accuracy: 0.5382 - val_loss: 0.6644 - val_accuracy: 0.6042\n","Epoch 5/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.7273 - accuracy: 0.5324 - val_loss: 0.6750 - val_accuracy: 0.6354\n","Epoch 6/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.7242 - accuracy: 0.5359 - val_loss: 0.6891 - val_accuracy: 0.5000\n","Epoch 7/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.7144 - accuracy: 0.5312 - val_loss: 0.7027 - val_accuracy: 0.4792\n","Epoch 8/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.7168 - accuracy: 0.5255 - val_loss: 0.7014 - val_accuracy: 0.5000\n","Epoch 9/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.7195 - accuracy: 0.5405 - val_loss: 0.6939 - val_accuracy: 0.5417\n","Epoch 10/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.7068 - accuracy: 0.5347 - val_loss: 0.6919 - val_accuracy: 0.5625\n","Epoch 11/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.7052 - accuracy: 0.5486 - val_loss: 0.6885 - val_accuracy: 0.5521\n","Epoch 12/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.7177 - accuracy: 0.5266 - val_loss: 0.6860 - val_accuracy: 0.5104\n","Epoch 13/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.7107 - accuracy: 0.5185 - val_loss: 0.6842 - val_accuracy: 0.5104\n","Epoch 14/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.7280 - accuracy: 0.4931 - val_loss: 0.6821 - val_accuracy: 0.5104\n","Epoch 15/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.7009 - accuracy: 0.5532 - val_loss: 0.6813 - val_accuracy: 0.5312\n","Epoch 16/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.7050 - accuracy: 0.5590 - val_loss: 0.6824 - val_accuracy: 0.5312\n","Epoch 17/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6905 - accuracy: 0.5648 - val_loss: 0.6841 - val_accuracy: 0.5312\n","Epoch 18/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.7027 - accuracy: 0.5556 - val_loss: 0.6850 - val_accuracy: 0.5312\n","Epoch 19/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.7206 - accuracy: 0.5324 - val_loss: 0.6826 - val_accuracy: 0.5521\n","Epoch 20/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6944 - accuracy: 0.5521 - val_loss: 0.6819 - val_accuracy: 0.5625\n","Epoch 21/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.7089 - accuracy: 0.5440 - val_loss: 0.6794 - val_accuracy: 0.5521\n","Epoch 22/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.7003 - accuracy: 0.5463 - val_loss: 0.6746 - val_accuracy: 0.5729\n","Epoch 23/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.7191 - accuracy: 0.5440 - val_loss: 0.6733 - val_accuracy: 0.5729\n","Epoch 24/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6933 - accuracy: 0.5625 - val_loss: 0.6697 - val_accuracy: 0.5729\n","Epoch 25/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.7048 - accuracy: 0.5440 - val_loss: 0.6686 - val_accuracy: 0.5833\n","Epoch 26/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.7069 - accuracy: 0.5463 - val_loss: 0.6647 - val_accuracy: 0.5938\n","Epoch 27/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6925 - accuracy: 0.5532 - val_loss: 0.6683 - val_accuracy: 0.5938\n","Epoch 28/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6908 - accuracy: 0.5567 - val_loss: 0.6726 - val_accuracy: 0.5729\n","Epoch 29/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6873 - accuracy: 0.5579 - val_loss: 0.6728 - val_accuracy: 0.5938\n","Epoch 30/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.7039 - accuracy: 0.5347 - val_loss: 0.6699 - val_accuracy: 0.5833\n","Epoch 31/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6969 - accuracy: 0.5625 - val_loss: 0.6663 - val_accuracy: 0.5833\n","Epoch 32/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.7037 - accuracy: 0.5359 - val_loss: 0.6641 - val_accuracy: 0.6042\n","Epoch 33/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6979 - accuracy: 0.5532 - val_loss: 0.6640 - val_accuracy: 0.6250\n","Epoch 34/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.7100 - accuracy: 0.5289 - val_loss: 0.6634 - val_accuracy: 0.6458\n","Epoch 35/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6908 - accuracy: 0.5428 - val_loss: 0.6643 - val_accuracy: 0.6562\n","Epoch 36/200\n","14/14 [==============================] - 0s 32ms/step - loss: 0.6917 - accuracy: 0.5475 - val_loss: 0.6645 - val_accuracy: 0.6354\n","Epoch 37/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6980 - accuracy: 0.5370 - val_loss: 0.6648 - val_accuracy: 0.6146\n","Epoch 38/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6895 - accuracy: 0.5579 - val_loss: 0.6658 - val_accuracy: 0.6354\n","Epoch 39/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6980 - accuracy: 0.5266 - val_loss: 0.6666 - val_accuracy: 0.6354\n","Epoch 40/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.7025 - accuracy: 0.5347 - val_loss: 0.6658 - val_accuracy: 0.6354\n","Epoch 41/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6876 - accuracy: 0.5694 - val_loss: 0.6645 - val_accuracy: 0.6458\n","Epoch 42/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6922 - accuracy: 0.5498 - val_loss: 0.6638 - val_accuracy: 0.6458\n","Epoch 43/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6982 - accuracy: 0.5405 - val_loss: 0.6636 - val_accuracy: 0.6250\n","Epoch 44/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6912 - accuracy: 0.5394 - val_loss: 0.6635 - val_accuracy: 0.6250\n","Epoch 45/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6771 - accuracy: 0.5833 - val_loss: 0.6618 - val_accuracy: 0.6458\n","Epoch 46/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6878 - accuracy: 0.5694 - val_loss: 0.6605 - val_accuracy: 0.6146\n","Epoch 47/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6808 - accuracy: 0.5613 - val_loss: 0.6613 - val_accuracy: 0.6667\n","Epoch 48/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6973 - accuracy: 0.5451 - val_loss: 0.6638 - val_accuracy: 0.6562\n","Epoch 49/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6957 - accuracy: 0.5324 - val_loss: 0.6636 - val_accuracy: 0.6354\n","Epoch 50/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6965 - accuracy: 0.5417 - val_loss: 0.6629 - val_accuracy: 0.6042\n","Epoch 51/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6803 - accuracy: 0.5694 - val_loss: 0.6619 - val_accuracy: 0.6250\n","Epoch 52/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6918 - accuracy: 0.5567 - val_loss: 0.6630 - val_accuracy: 0.5938\n","Epoch 53/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6851 - accuracy: 0.5579 - val_loss: 0.6636 - val_accuracy: 0.6042\n","Epoch 54/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6909 - accuracy: 0.5451 - val_loss: 0.6636 - val_accuracy: 0.6354\n","Epoch 55/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6860 - accuracy: 0.5579 - val_loss: 0.6638 - val_accuracy: 0.6250\n","Epoch 56/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6901 - accuracy: 0.5602 - val_loss: 0.6658 - val_accuracy: 0.6146\n","Epoch 57/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6815 - accuracy: 0.5683 - val_loss: 0.6666 - val_accuracy: 0.6250\n","Epoch 58/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6822 - accuracy: 0.5729 - val_loss: 0.6669 - val_accuracy: 0.6146\n","Epoch 59/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6878 - accuracy: 0.5486 - val_loss: 0.6676 - val_accuracy: 0.6250\n","Epoch 60/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6927 - accuracy: 0.5336 - val_loss: 0.6669 - val_accuracy: 0.6354\n","Epoch 61/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6884 - accuracy: 0.5637 - val_loss: 0.6668 - val_accuracy: 0.6458\n","Epoch 62/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6857 - accuracy: 0.5613 - val_loss: 0.6676 - val_accuracy: 0.5938\n","Epoch 63/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6870 - accuracy: 0.5613 - val_loss: 0.6685 - val_accuracy: 0.6146\n","Epoch 64/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6824 - accuracy: 0.5567 - val_loss: 0.6676 - val_accuracy: 0.6354\n","Epoch 65/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6943 - accuracy: 0.5509 - val_loss: 0.6676 - val_accuracy: 0.6354\n","Epoch 66/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6763 - accuracy: 0.5856 - val_loss: 0.6675 - val_accuracy: 0.6354\n","Epoch 67/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6888 - accuracy: 0.5567 - val_loss: 0.6677 - val_accuracy: 0.6458\n","Epoch 68/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6941 - accuracy: 0.5347 - val_loss: 0.6663 - val_accuracy: 0.6354\n","Epoch 69/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6899 - accuracy: 0.5544 - val_loss: 0.6657 - val_accuracy: 0.6354\n","Epoch 70/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6780 - accuracy: 0.5648 - val_loss: 0.6662 - val_accuracy: 0.6354\n","Epoch 71/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6957 - accuracy: 0.5370 - val_loss: 0.6665 - val_accuracy: 0.6354\n","Epoch 72/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6807 - accuracy: 0.5683 - val_loss: 0.6654 - val_accuracy: 0.6354\n","Epoch 73/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6819 - accuracy: 0.5718 - val_loss: 0.6660 - val_accuracy: 0.6354\n","Epoch 74/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6814 - accuracy: 0.5613 - val_loss: 0.6677 - val_accuracy: 0.6354\n","Epoch 75/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6837 - accuracy: 0.5556 - val_loss: 0.6691 - val_accuracy: 0.6146\n","Epoch 76/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6914 - accuracy: 0.5486 - val_loss: 0.6699 - val_accuracy: 0.6354\n","Epoch 77/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6863 - accuracy: 0.5532 - val_loss: 0.6703 - val_accuracy: 0.6146\n","Epoch 78/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6928 - accuracy: 0.5324 - val_loss: 0.6699 - val_accuracy: 0.6354\n","Epoch 79/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6853 - accuracy: 0.5625 - val_loss: 0.6699 - val_accuracy: 0.6354\n","Epoch 80/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6810 - accuracy: 0.5556 - val_loss: 0.6698 - val_accuracy: 0.6354\n","Epoch 81/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6808 - accuracy: 0.5544 - val_loss: 0.6700 - val_accuracy: 0.6354\n","Epoch 82/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6861 - accuracy: 0.5475 - val_loss: 0.6702 - val_accuracy: 0.6354\n","Epoch 83/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6942 - accuracy: 0.5301 - val_loss: 0.6698 - val_accuracy: 0.6354\n","Epoch 84/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6796 - accuracy: 0.5648 - val_loss: 0.6707 - val_accuracy: 0.6250\n","Epoch 85/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6849 - accuracy: 0.5764 - val_loss: 0.6713 - val_accuracy: 0.6354\n","Epoch 86/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6811 - accuracy: 0.5729 - val_loss: 0.6694 - val_accuracy: 0.6146\n","Epoch 87/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6758 - accuracy: 0.5810 - val_loss: 0.6703 - val_accuracy: 0.6354\n","Epoch 88/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6858 - accuracy: 0.5613 - val_loss: 0.6691 - val_accuracy: 0.6354\n","Epoch 89/200\n","14/14 [==============================] - 0s 32ms/step - loss: 0.6788 - accuracy: 0.5752 - val_loss: 0.6679 - val_accuracy: 0.6250\n","Epoch 90/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6865 - accuracy: 0.5486 - val_loss: 0.6678 - val_accuracy: 0.6146\n","Epoch 91/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6797 - accuracy: 0.5683 - val_loss: 0.6688 - val_accuracy: 0.6146\n","Epoch 92/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6895 - accuracy: 0.5579 - val_loss: 0.6676 - val_accuracy: 0.6354\n","Epoch 93/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6780 - accuracy: 0.5752 - val_loss: 0.6670 - val_accuracy: 0.6250\n","Epoch 94/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6909 - accuracy: 0.5509 - val_loss: 0.6670 - val_accuracy: 0.6250\n","Epoch 95/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6915 - accuracy: 0.5521 - val_loss: 0.6667 - val_accuracy: 0.6354\n","Epoch 96/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6750 - accuracy: 0.5532 - val_loss: 0.6671 - val_accuracy: 0.6458\n","Epoch 97/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6901 - accuracy: 0.5567 - val_loss: 0.6670 - val_accuracy: 0.6354\n","Epoch 98/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6820 - accuracy: 0.5394 - val_loss: 0.6669 - val_accuracy: 0.6250\n","Epoch 99/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6873 - accuracy: 0.5567 - val_loss: 0.6683 - val_accuracy: 0.6250\n","Epoch 100/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6849 - accuracy: 0.5509 - val_loss: 0.6689 - val_accuracy: 0.6354\n","Epoch 101/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6808 - accuracy: 0.5602 - val_loss: 0.6691 - val_accuracy: 0.6146\n","Epoch 102/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6733 - accuracy: 0.5799 - val_loss: 0.6698 - val_accuracy: 0.6250\n","Epoch 103/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6761 - accuracy: 0.5810 - val_loss: 0.6702 - val_accuracy: 0.6354\n","Epoch 104/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6805 - accuracy: 0.5660 - val_loss: 0.6695 - val_accuracy: 0.6250\n","Epoch 105/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6815 - accuracy: 0.5845 - val_loss: 0.6695 - val_accuracy: 0.6146\n","Epoch 106/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6769 - accuracy: 0.5613 - val_loss: 0.6691 - val_accuracy: 0.6042\n","Epoch 107/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6803 - accuracy: 0.5729 - val_loss: 0.6693 - val_accuracy: 0.6146\n","Epoch 108/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6810 - accuracy: 0.5521 - val_loss: 0.6691 - val_accuracy: 0.6146\n","Epoch 109/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6781 - accuracy: 0.5718 - val_loss: 0.6689 - val_accuracy: 0.6146\n","Epoch 110/200\n","14/14 [==============================] - 0s 33ms/step - loss: 0.6849 - accuracy: 0.5567 - val_loss: 0.6691 - val_accuracy: 0.6042\n","Epoch 111/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6761 - accuracy: 0.5775 - val_loss: 0.6694 - val_accuracy: 0.6042\n","Epoch 112/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6812 - accuracy: 0.5579 - val_loss: 0.6701 - val_accuracy: 0.6146\n","Epoch 113/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6822 - accuracy: 0.5486 - val_loss: 0.6699 - val_accuracy: 0.6146\n","Epoch 114/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6744 - accuracy: 0.5903 - val_loss: 0.6705 - val_accuracy: 0.6042\n","Epoch 115/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6788 - accuracy: 0.5567 - val_loss: 0.6718 - val_accuracy: 0.6042\n","Epoch 116/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6805 - accuracy: 0.5683 - val_loss: 0.6722 - val_accuracy: 0.6042\n","Epoch 117/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6838 - accuracy: 0.5613 - val_loss: 0.6727 - val_accuracy: 0.6146\n","Epoch 118/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6687 - accuracy: 0.5903 - val_loss: 0.6732 - val_accuracy: 0.6042\n","Epoch 119/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6744 - accuracy: 0.5694 - val_loss: 0.6742 - val_accuracy: 0.5938\n","Epoch 120/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6785 - accuracy: 0.5880 - val_loss: 0.6746 - val_accuracy: 0.6042\n","Epoch 121/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6756 - accuracy: 0.5810 - val_loss: 0.6737 - val_accuracy: 0.6042\n","Epoch 122/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6746 - accuracy: 0.5914 - val_loss: 0.6726 - val_accuracy: 0.6042\n","Epoch 123/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6769 - accuracy: 0.5880 - val_loss: 0.6724 - val_accuracy: 0.6146\n","Epoch 124/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6731 - accuracy: 0.6007 - val_loss: 0.6718 - val_accuracy: 0.6042\n","Epoch 125/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6778 - accuracy: 0.5694 - val_loss: 0.6729 - val_accuracy: 0.6354\n","Epoch 126/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6730 - accuracy: 0.5822 - val_loss: 0.6733 - val_accuracy: 0.6250\n","Epoch 127/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6822 - accuracy: 0.5440 - val_loss: 0.6737 - val_accuracy: 0.6354\n","Epoch 128/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6718 - accuracy: 0.5775 - val_loss: 0.6739 - val_accuracy: 0.6354\n","Epoch 129/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6814 - accuracy: 0.5625 - val_loss: 0.6751 - val_accuracy: 0.6458\n","Epoch 130/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6857 - accuracy: 0.5752 - val_loss: 0.6765 - val_accuracy: 0.6354\n","Epoch 131/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6699 - accuracy: 0.5799 - val_loss: 0.6754 - val_accuracy: 0.6250\n","Epoch 132/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6884 - accuracy: 0.5579 - val_loss: 0.6748 - val_accuracy: 0.6146\n","Epoch 133/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6803 - accuracy: 0.5613 - val_loss: 0.6754 - val_accuracy: 0.6146\n","Epoch 134/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6815 - accuracy: 0.5694 - val_loss: 0.6756 - val_accuracy: 0.6250\n","Epoch 135/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6771 - accuracy: 0.5579 - val_loss: 0.6759 - val_accuracy: 0.6354\n","Epoch 136/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6777 - accuracy: 0.5683 - val_loss: 0.6757 - val_accuracy: 0.6354\n","Epoch 137/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6692 - accuracy: 0.5891 - val_loss: 0.6756 - val_accuracy: 0.6250\n","Epoch 138/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6803 - accuracy: 0.5729 - val_loss: 0.6747 - val_accuracy: 0.6354\n","Epoch 139/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6811 - accuracy: 0.5718 - val_loss: 0.6756 - val_accuracy: 0.6250\n","Epoch 140/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6775 - accuracy: 0.5671 - val_loss: 0.6754 - val_accuracy: 0.6250\n","Epoch 141/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6738 - accuracy: 0.5822 - val_loss: 0.6743 - val_accuracy: 0.6250\n","Epoch 142/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6866 - accuracy: 0.5417 - val_loss: 0.6743 - val_accuracy: 0.6250\n","Epoch 143/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6814 - accuracy: 0.5602 - val_loss: 0.6750 - val_accuracy: 0.6250\n","Epoch 144/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6778 - accuracy: 0.5799 - val_loss: 0.6751 - val_accuracy: 0.6250\n","Epoch 145/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6733 - accuracy: 0.5741 - val_loss: 0.6758 - val_accuracy: 0.6250\n","Epoch 146/200\n","14/14 [==============================] - 0s 32ms/step - loss: 0.6732 - accuracy: 0.5822 - val_loss: 0.6757 - val_accuracy: 0.6354\n","Epoch 147/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6795 - accuracy: 0.5683 - val_loss: 0.6750 - val_accuracy: 0.6354\n","Epoch 148/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6779 - accuracy: 0.5729 - val_loss: 0.6748 - val_accuracy: 0.6458\n","Epoch 149/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6686 - accuracy: 0.5949 - val_loss: 0.6739 - val_accuracy: 0.6458\n","Epoch 150/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6778 - accuracy: 0.5891 - val_loss: 0.6748 - val_accuracy: 0.6354\n","Epoch 151/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6735 - accuracy: 0.5891 - val_loss: 0.6755 - val_accuracy: 0.6250\n","Epoch 152/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6753 - accuracy: 0.5694 - val_loss: 0.6746 - val_accuracy: 0.6354\n","Epoch 153/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6651 - accuracy: 0.6042 - val_loss: 0.6744 - val_accuracy: 0.6354\n","Epoch 154/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6720 - accuracy: 0.5718 - val_loss: 0.6750 - val_accuracy: 0.6354\n","Epoch 155/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6769 - accuracy: 0.5718 - val_loss: 0.6757 - val_accuracy: 0.6354\n","Epoch 156/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6697 - accuracy: 0.5775 - val_loss: 0.6759 - val_accuracy: 0.6562\n","Epoch 157/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6801 - accuracy: 0.5741 - val_loss: 0.6735 - val_accuracy: 0.6354\n","Epoch 158/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.6802 - accuracy: 0.5741 - val_loss: 0.6747 - val_accuracy: 0.6042\n","Epoch 159/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6682 - accuracy: 0.6007 - val_loss: 0.6747 - val_accuracy: 0.6042\n","Epoch 160/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6734 - accuracy: 0.6065 - val_loss: 0.6748 - val_accuracy: 0.6146\n","Epoch 161/200\n","14/14 [==============================] - 0s 32ms/step - loss: 0.6697 - accuracy: 0.5810 - val_loss: 0.6751 - val_accuracy: 0.6250\n","Epoch 162/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6746 - accuracy: 0.5822 - val_loss: 0.6747 - val_accuracy: 0.6250\n","Epoch 163/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6635 - accuracy: 0.6065 - val_loss: 0.6763 - val_accuracy: 0.6146\n","Epoch 164/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6735 - accuracy: 0.5810 - val_loss: 0.6757 - val_accuracy: 0.6354\n","Epoch 165/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6725 - accuracy: 0.6053 - val_loss: 0.6784 - val_accuracy: 0.6146\n","Epoch 166/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6605 - accuracy: 0.6146 - val_loss: 0.6769 - val_accuracy: 0.6146\n","Epoch 167/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6670 - accuracy: 0.5833 - val_loss: 0.6777 - val_accuracy: 0.6250\n","Epoch 168/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6799 - accuracy: 0.5706 - val_loss: 0.6796 - val_accuracy: 0.6250\n","Epoch 169/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6796 - accuracy: 0.5729 - val_loss: 0.6799 - val_accuracy: 0.6354\n","Epoch 170/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6707 - accuracy: 0.5752 - val_loss: 0.6795 - val_accuracy: 0.6250\n","Epoch 171/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6732 - accuracy: 0.5880 - val_loss: 0.6786 - val_accuracy: 0.6250\n","Epoch 172/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6698 - accuracy: 0.5764 - val_loss: 0.6782 - val_accuracy: 0.6146\n","Epoch 173/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6655 - accuracy: 0.5972 - val_loss: 0.6781 - val_accuracy: 0.5938\n","Epoch 174/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6738 - accuracy: 0.5544 - val_loss: 0.6762 - val_accuracy: 0.6042\n","Epoch 175/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6720 - accuracy: 0.5799 - val_loss: 0.6756 - val_accuracy: 0.6042\n","Epoch 176/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6632 - accuracy: 0.6134 - val_loss: 0.6760 - val_accuracy: 0.6042\n","Epoch 177/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6690 - accuracy: 0.5949 - val_loss: 0.6766 - val_accuracy: 0.6146\n","Epoch 178/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6653 - accuracy: 0.6134 - val_loss: 0.6773 - val_accuracy: 0.6250\n","Epoch 179/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6678 - accuracy: 0.5961 - val_loss: 0.6784 - val_accuracy: 0.6146\n","Epoch 180/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6716 - accuracy: 0.5914 - val_loss: 0.6784 - val_accuracy: 0.6146\n","Epoch 181/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6682 - accuracy: 0.5833 - val_loss: 0.6778 - val_accuracy: 0.6042\n","Epoch 182/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6762 - accuracy: 0.5729 - val_loss: 0.6786 - val_accuracy: 0.5833\n","Epoch 183/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6771 - accuracy: 0.5729 - val_loss: 0.6785 - val_accuracy: 0.5938\n","Epoch 184/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6663 - accuracy: 0.5891 - val_loss: 0.6788 - val_accuracy: 0.6042\n","Epoch 185/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6683 - accuracy: 0.5972 - val_loss: 0.6803 - val_accuracy: 0.6042\n","Epoch 186/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6757 - accuracy: 0.5810 - val_loss: 0.6804 - val_accuracy: 0.6042\n","Epoch 187/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6763 - accuracy: 0.5995 - val_loss: 0.6791 - val_accuracy: 0.6042\n","Epoch 188/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6703 - accuracy: 0.5949 - val_loss: 0.6802 - val_accuracy: 0.6042\n","Epoch 189/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6610 - accuracy: 0.6007 - val_loss: 0.6816 - val_accuracy: 0.5833\n","Epoch 190/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6737 - accuracy: 0.5706 - val_loss: 0.6815 - val_accuracy: 0.5833\n","Epoch 191/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6658 - accuracy: 0.5995 - val_loss: 0.6813 - val_accuracy: 0.5833\n","Epoch 192/200\n","14/14 [==============================] - 0s 33ms/step - loss: 0.6780 - accuracy: 0.5671 - val_loss: 0.6826 - val_accuracy: 0.6042\n","Epoch 193/200\n","14/14 [==============================] - 0s 32ms/step - loss: 0.6694 - accuracy: 0.5833 - val_loss: 0.6833 - val_accuracy: 0.5833\n","Epoch 194/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6829 - accuracy: 0.5694 - val_loss: 0.6822 - val_accuracy: 0.5938\n","Epoch 195/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6772 - accuracy: 0.5880 - val_loss: 0.6827 - val_accuracy: 0.5729\n","Epoch 196/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6684 - accuracy: 0.6030 - val_loss: 0.6826 - val_accuracy: 0.5729\n","Epoch 197/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6612 - accuracy: 0.6088 - val_loss: 0.6837 - val_accuracy: 0.5729\n","Epoch 198/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6690 - accuracy: 0.5972 - val_loss: 0.6852 - val_accuracy: 0.5833\n","Epoch 199/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6703 - accuracy: 0.6019 - val_loss: 0.6859 - val_accuracy: 0.5938\n","Epoch 200/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6544 - accuracy: 0.6100 - val_loss: 0.6875 - val_accuracy: 0.5729\n","8/8 [==============================] - 0s 11ms/step - loss: 0.6934 - accuracy: 0.5333\n","[0.6934247612953186, 0.5333333611488342]\n","Results for fold 10\n","Epoch 1/200\n","14/14 [==============================] - 7s 118ms/step - loss: 0.7881 - accuracy: 0.5590 - val_loss: 0.7333 - val_accuracy: 0.5417\n","Epoch 2/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.7404 - accuracy: 0.5359 - val_loss: 0.6860 - val_accuracy: 0.5625\n","Epoch 3/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.7478 - accuracy: 0.5150 - val_loss: 0.6810 - val_accuracy: 0.5729\n","Epoch 4/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.7280 - accuracy: 0.5116 - val_loss: 0.6766 - val_accuracy: 0.5833\n","Epoch 5/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.7171 - accuracy: 0.5012 - val_loss: 0.6692 - val_accuracy: 0.5938\n","Epoch 6/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.7238 - accuracy: 0.5231 - val_loss: 0.6645 - val_accuracy: 0.5729\n","Epoch 7/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.7263 - accuracy: 0.5046 - val_loss: 0.6622 - val_accuracy: 0.5833\n","Epoch 8/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.7148 - accuracy: 0.5382 - val_loss: 0.6614 - val_accuracy: 0.6146\n","Epoch 9/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.7251 - accuracy: 0.5081 - val_loss: 0.6612 - val_accuracy: 0.6042\n","Epoch 10/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.7081 - accuracy: 0.5359 - val_loss: 0.6607 - val_accuracy: 0.6042\n","Epoch 11/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.7322 - accuracy: 0.5197 - val_loss: 0.6597 - val_accuracy: 0.6042\n","Epoch 12/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.7045 - accuracy: 0.5475 - val_loss: 0.6613 - val_accuracy: 0.6146\n","Epoch 13/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.7136 - accuracy: 0.5394 - val_loss: 0.6595 - val_accuracy: 0.6458\n","Epoch 14/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6967 - accuracy: 0.5440 - val_loss: 0.6615 - val_accuracy: 0.6042\n","Epoch 15/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.7101 - accuracy: 0.5405 - val_loss: 0.6646 - val_accuracy: 0.5938\n","Epoch 16/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.7063 - accuracy: 0.5324 - val_loss: 0.6631 - val_accuracy: 0.6250\n","Epoch 17/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.7075 - accuracy: 0.5336 - val_loss: 0.6608 - val_accuracy: 0.6250\n","Epoch 18/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6945 - accuracy: 0.5637 - val_loss: 0.6609 - val_accuracy: 0.6354\n","Epoch 19/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.7148 - accuracy: 0.5243 - val_loss: 0.6602 - val_accuracy: 0.6250\n","Epoch 20/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.7020 - accuracy: 0.5405 - val_loss: 0.6624 - val_accuracy: 0.6250\n","Epoch 21/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.7053 - accuracy: 0.5324 - val_loss: 0.6619 - val_accuracy: 0.6042\n","Epoch 22/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.7124 - accuracy: 0.5208 - val_loss: 0.6607 - val_accuracy: 0.5938\n","Epoch 23/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6946 - accuracy: 0.5590 - val_loss: 0.6596 - val_accuracy: 0.6042\n","Epoch 24/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.7007 - accuracy: 0.5417 - val_loss: 0.6596 - val_accuracy: 0.6146\n","Epoch 25/200\n","14/14 [==============================] - 0s 27ms/step - loss: 0.7102 - accuracy: 0.5255 - val_loss: 0.6603 - val_accuracy: 0.6146\n","Epoch 26/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.7032 - accuracy: 0.5382 - val_loss: 0.6623 - val_accuracy: 0.6354\n","Epoch 27/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.7059 - accuracy: 0.5301 - val_loss: 0.6619 - val_accuracy: 0.6354\n","Epoch 28/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.7102 - accuracy: 0.5150 - val_loss: 0.6616 - val_accuracy: 0.6146\n","Epoch 29/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6966 - accuracy: 0.5671 - val_loss: 0.6617 - val_accuracy: 0.6458\n","Epoch 30/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6910 - accuracy: 0.5567 - val_loss: 0.6602 - val_accuracy: 0.6458\n","Epoch 31/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.7023 - accuracy: 0.5359 - val_loss: 0.6607 - val_accuracy: 0.6354\n","Epoch 32/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.7064 - accuracy: 0.5174 - val_loss: 0.6609 - val_accuracy: 0.6250\n","Epoch 33/200\n","14/14 [==============================] - 0s 32ms/step - loss: 0.6962 - accuracy: 0.5370 - val_loss: 0.6620 - val_accuracy: 0.6250\n","Epoch 34/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.7041 - accuracy: 0.5255 - val_loss: 0.6640 - val_accuracy: 0.6146\n","Epoch 35/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.7044 - accuracy: 0.5301 - val_loss: 0.6641 - val_accuracy: 0.5833\n","Epoch 36/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.7033 - accuracy: 0.5278 - val_loss: 0.6643 - val_accuracy: 0.5833\n","Epoch 37/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6991 - accuracy: 0.5602 - val_loss: 0.6626 - val_accuracy: 0.5833\n","Epoch 38/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.7046 - accuracy: 0.5289 - val_loss: 0.6643 - val_accuracy: 0.5833\n","Epoch 39/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6898 - accuracy: 0.5544 - val_loss: 0.6651 - val_accuracy: 0.5833\n","Epoch 40/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6961 - accuracy: 0.5370 - val_loss: 0.6675 - val_accuracy: 0.5729\n","Epoch 41/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.7046 - accuracy: 0.5301 - val_loss: 0.6669 - val_accuracy: 0.5833\n","Epoch 42/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6992 - accuracy: 0.5567 - val_loss: 0.6681 - val_accuracy: 0.5625\n","Epoch 43/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6905 - accuracy: 0.5451 - val_loss: 0.6666 - val_accuracy: 0.5938\n","Epoch 44/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.7044 - accuracy: 0.5521 - val_loss: 0.6634 - val_accuracy: 0.6146\n","Epoch 45/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6985 - accuracy: 0.5197 - val_loss: 0.6630 - val_accuracy: 0.6354\n","Epoch 46/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6791 - accuracy: 0.5718 - val_loss: 0.6630 - val_accuracy: 0.6146\n","Epoch 47/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.7001 - accuracy: 0.5174 - val_loss: 0.6625 - val_accuracy: 0.6250\n","Epoch 48/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.7010 - accuracy: 0.5208 - val_loss: 0.6639 - val_accuracy: 0.6042\n","Epoch 49/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6896 - accuracy: 0.5625 - val_loss: 0.6654 - val_accuracy: 0.5938\n","Epoch 50/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6906 - accuracy: 0.5440 - val_loss: 0.6653 - val_accuracy: 0.6042\n","Epoch 51/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6834 - accuracy: 0.5613 - val_loss: 0.6655 - val_accuracy: 0.6042\n","Epoch 52/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6948 - accuracy: 0.5359 - val_loss: 0.6636 - val_accuracy: 0.5938\n","Epoch 53/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6886 - accuracy: 0.5428 - val_loss: 0.6638 - val_accuracy: 0.6042\n","Epoch 54/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6946 - accuracy: 0.5243 - val_loss: 0.6644 - val_accuracy: 0.5938\n","Epoch 55/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6840 - accuracy: 0.5602 - val_loss: 0.6644 - val_accuracy: 0.5938\n","Epoch 56/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6915 - accuracy: 0.5370 - val_loss: 0.6638 - val_accuracy: 0.6146\n","Epoch 57/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6899 - accuracy: 0.5312 - val_loss: 0.6634 - val_accuracy: 0.6146\n","Epoch 58/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6848 - accuracy: 0.5683 - val_loss: 0.6649 - val_accuracy: 0.6042\n","Epoch 59/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6951 - accuracy: 0.5451 - val_loss: 0.6647 - val_accuracy: 0.5833\n","Epoch 60/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6864 - accuracy: 0.5567 - val_loss: 0.6653 - val_accuracy: 0.6042\n","Epoch 61/200\n","14/14 [==============================] - 0s 32ms/step - loss: 0.6878 - accuracy: 0.5718 - val_loss: 0.6648 - val_accuracy: 0.6042\n","Epoch 62/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6899 - accuracy: 0.5590 - val_loss: 0.6652 - val_accuracy: 0.6042\n","Epoch 63/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6876 - accuracy: 0.5544 - val_loss: 0.6651 - val_accuracy: 0.6042\n","Epoch 64/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6969 - accuracy: 0.5324 - val_loss: 0.6649 - val_accuracy: 0.5938\n","Epoch 65/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6894 - accuracy: 0.5521 - val_loss: 0.6635 - val_accuracy: 0.5938\n","Epoch 66/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6843 - accuracy: 0.5637 - val_loss: 0.6636 - val_accuracy: 0.5938\n","Epoch 67/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6867 - accuracy: 0.5613 - val_loss: 0.6640 - val_accuracy: 0.6146\n","Epoch 68/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6905 - accuracy: 0.5463 - val_loss: 0.6623 - val_accuracy: 0.6354\n","Epoch 69/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6905 - accuracy: 0.5706 - val_loss: 0.6618 - val_accuracy: 0.6354\n","Epoch 70/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6885 - accuracy: 0.5440 - val_loss: 0.6624 - val_accuracy: 0.6354\n","Epoch 71/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6888 - accuracy: 0.5405 - val_loss: 0.6620 - val_accuracy: 0.6354\n","Epoch 72/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6820 - accuracy: 0.5729 - val_loss: 0.6620 - val_accuracy: 0.6354\n","Epoch 73/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6872 - accuracy: 0.5451 - val_loss: 0.6632 - val_accuracy: 0.6250\n","Epoch 74/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6914 - accuracy: 0.5417 - val_loss: 0.6639 - val_accuracy: 0.6146\n","Epoch 75/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6897 - accuracy: 0.5475 - val_loss: 0.6635 - val_accuracy: 0.6146\n","Epoch 76/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6916 - accuracy: 0.5509 - val_loss: 0.6642 - val_accuracy: 0.6354\n","Epoch 77/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6833 - accuracy: 0.5660 - val_loss: 0.6647 - val_accuracy: 0.6042\n","Epoch 78/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6857 - accuracy: 0.5509 - val_loss: 0.6640 - val_accuracy: 0.6354\n","Epoch 79/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6901 - accuracy: 0.5394 - val_loss: 0.6641 - val_accuracy: 0.6250\n","Epoch 80/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6861 - accuracy: 0.5637 - val_loss: 0.6638 - val_accuracy: 0.6146\n","Epoch 81/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6849 - accuracy: 0.5532 - val_loss: 0.6632 - val_accuracy: 0.6250\n","Epoch 82/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6873 - accuracy: 0.5532 - val_loss: 0.6620 - val_accuracy: 0.6458\n","Epoch 83/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6843 - accuracy: 0.5648 - val_loss: 0.6620 - val_accuracy: 0.6354\n","Epoch 84/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6893 - accuracy: 0.5509 - val_loss: 0.6622 - val_accuracy: 0.6042\n","Epoch 85/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6855 - accuracy: 0.5532 - val_loss: 0.6634 - val_accuracy: 0.6042\n","Epoch 86/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6802 - accuracy: 0.5590 - val_loss: 0.6637 - val_accuracy: 0.6146\n","Epoch 87/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6932 - accuracy: 0.5498 - val_loss: 0.6639 - val_accuracy: 0.6042\n","Epoch 88/200\n","14/14 [==============================] - 0s 32ms/step - loss: 0.6907 - accuracy: 0.5359 - val_loss: 0.6618 - val_accuracy: 0.6354\n","Epoch 89/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6845 - accuracy: 0.5590 - val_loss: 0.6636 - val_accuracy: 0.6146\n","Epoch 90/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6900 - accuracy: 0.5532 - val_loss: 0.6622 - val_accuracy: 0.6042\n","Epoch 91/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6858 - accuracy: 0.5648 - val_loss: 0.6626 - val_accuracy: 0.5938\n","Epoch 92/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6935 - accuracy: 0.5278 - val_loss: 0.6639 - val_accuracy: 0.6042\n","Epoch 93/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6895 - accuracy: 0.5625 - val_loss: 0.6637 - val_accuracy: 0.5938\n","Epoch 94/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6817 - accuracy: 0.5648 - val_loss: 0.6645 - val_accuracy: 0.5938\n","Epoch 95/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6857 - accuracy: 0.5590 - val_loss: 0.6641 - val_accuracy: 0.6146\n","Epoch 96/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6884 - accuracy: 0.5532 - val_loss: 0.6635 - val_accuracy: 0.5938\n","Epoch 97/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6703 - accuracy: 0.5856 - val_loss: 0.6634 - val_accuracy: 0.5833\n","Epoch 98/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6806 - accuracy: 0.5799 - val_loss: 0.6625 - val_accuracy: 0.6042\n","Epoch 99/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6921 - accuracy: 0.5440 - val_loss: 0.6623 - val_accuracy: 0.6042\n","Epoch 100/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6831 - accuracy: 0.5567 - val_loss: 0.6622 - val_accuracy: 0.6146\n","Epoch 101/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6813 - accuracy: 0.5671 - val_loss: 0.6616 - val_accuracy: 0.6042\n","Epoch 102/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6913 - accuracy: 0.5463 - val_loss: 0.6628 - val_accuracy: 0.5729\n","Epoch 103/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6852 - accuracy: 0.5590 - val_loss: 0.6634 - val_accuracy: 0.6042\n","Epoch 104/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6856 - accuracy: 0.5417 - val_loss: 0.6626 - val_accuracy: 0.6042\n","Epoch 105/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6779 - accuracy: 0.5706 - val_loss: 0.6616 - val_accuracy: 0.5833\n","Epoch 106/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6856 - accuracy: 0.5498 - val_loss: 0.6623 - val_accuracy: 0.5729\n","Epoch 107/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6862 - accuracy: 0.5509 - val_loss: 0.6622 - val_accuracy: 0.5938\n","Epoch 108/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6834 - accuracy: 0.5590 - val_loss: 0.6611 - val_accuracy: 0.5938\n","Epoch 109/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6830 - accuracy: 0.5718 - val_loss: 0.6609 - val_accuracy: 0.5833\n","Epoch 110/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6898 - accuracy: 0.5532 - val_loss: 0.6608 - val_accuracy: 0.5938\n","Epoch 111/200\n","14/14 [==============================] - 0s 32ms/step - loss: 0.6808 - accuracy: 0.5556 - val_loss: 0.6621 - val_accuracy: 0.5729\n","Epoch 112/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6766 - accuracy: 0.5903 - val_loss: 0.6634 - val_accuracy: 0.5833\n","Epoch 113/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6814 - accuracy: 0.5625 - val_loss: 0.6628 - val_accuracy: 0.5833\n","Epoch 114/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6878 - accuracy: 0.5602 - val_loss: 0.6629 - val_accuracy: 0.6042\n","Epoch 115/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6819 - accuracy: 0.5683 - val_loss: 0.6631 - val_accuracy: 0.6042\n","Epoch 116/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6775 - accuracy: 0.5775 - val_loss: 0.6632 - val_accuracy: 0.6042\n","Epoch 117/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6885 - accuracy: 0.5625 - val_loss: 0.6619 - val_accuracy: 0.6042\n","Epoch 118/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6843 - accuracy: 0.5706 - val_loss: 0.6633 - val_accuracy: 0.5729\n","Epoch 119/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6850 - accuracy: 0.5648 - val_loss: 0.6635 - val_accuracy: 0.5938\n","Epoch 120/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6934 - accuracy: 0.5498 - val_loss: 0.6637 - val_accuracy: 0.5938\n","Epoch 121/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6778 - accuracy: 0.5718 - val_loss: 0.6623 - val_accuracy: 0.6042\n","Epoch 122/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6869 - accuracy: 0.5579 - val_loss: 0.6622 - val_accuracy: 0.6042\n","Epoch 123/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6853 - accuracy: 0.5683 - val_loss: 0.6644 - val_accuracy: 0.5833\n","Epoch 124/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6808 - accuracy: 0.5787 - val_loss: 0.6651 - val_accuracy: 0.5833\n","Epoch 125/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6762 - accuracy: 0.5637 - val_loss: 0.6654 - val_accuracy: 0.5833\n","Epoch 126/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6834 - accuracy: 0.5926 - val_loss: 0.6645 - val_accuracy: 0.6146\n","Epoch 127/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6809 - accuracy: 0.5741 - val_loss: 0.6641 - val_accuracy: 0.6042\n","Epoch 128/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6846 - accuracy: 0.5590 - val_loss: 0.6655 - val_accuracy: 0.5938\n","Epoch 129/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6794 - accuracy: 0.5706 - val_loss: 0.6663 - val_accuracy: 0.5729\n","Epoch 130/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6867 - accuracy: 0.5567 - val_loss: 0.6661 - val_accuracy: 0.5833\n","Epoch 131/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6836 - accuracy: 0.5822 - val_loss: 0.6643 - val_accuracy: 0.5833\n","Epoch 132/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6871 - accuracy: 0.5625 - val_loss: 0.6651 - val_accuracy: 0.5729\n","Epoch 133/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6800 - accuracy: 0.5718 - val_loss: 0.6660 - val_accuracy: 0.5729\n","Epoch 134/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6783 - accuracy: 0.5660 - val_loss: 0.6666 - val_accuracy: 0.5729\n","Epoch 135/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6773 - accuracy: 0.5706 - val_loss: 0.6669 - val_accuracy: 0.5625\n","Epoch 136/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6692 - accuracy: 0.5926 - val_loss: 0.6678 - val_accuracy: 0.5729\n","Epoch 137/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6864 - accuracy: 0.5567 - val_loss: 0.6658 - val_accuracy: 0.5729\n","Epoch 138/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6865 - accuracy: 0.5509 - val_loss: 0.6651 - val_accuracy: 0.5729\n","Epoch 139/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6853 - accuracy: 0.5590 - val_loss: 0.6650 - val_accuracy: 0.5833\n","Epoch 140/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6764 - accuracy: 0.5810 - val_loss: 0.6646 - val_accuracy: 0.5833\n","Epoch 141/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6789 - accuracy: 0.5486 - val_loss: 0.6644 - val_accuracy: 0.5833\n","Epoch 142/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6813 - accuracy: 0.5718 - val_loss: 0.6640 - val_accuracy: 0.5938\n","Epoch 143/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6841 - accuracy: 0.5486 - val_loss: 0.6655 - val_accuracy: 0.5938\n","Epoch 144/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6773 - accuracy: 0.5683 - val_loss: 0.6661 - val_accuracy: 0.5729\n","Epoch 145/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6768 - accuracy: 0.5868 - val_loss: 0.6663 - val_accuracy: 0.5833\n","Epoch 146/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6800 - accuracy: 0.5683 - val_loss: 0.6657 - val_accuracy: 0.5729\n","Epoch 147/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6738 - accuracy: 0.5752 - val_loss: 0.6667 - val_accuracy: 0.5833\n","Epoch 148/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6838 - accuracy: 0.5451 - val_loss: 0.6656 - val_accuracy: 0.6042\n","Epoch 149/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6814 - accuracy: 0.5532 - val_loss: 0.6655 - val_accuracy: 0.6146\n","Epoch 150/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6834 - accuracy: 0.5637 - val_loss: 0.6661 - val_accuracy: 0.5833\n","Epoch 151/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6845 - accuracy: 0.5567 - val_loss: 0.6661 - val_accuracy: 0.5729\n","Epoch 152/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6857 - accuracy: 0.5521 - val_loss: 0.6654 - val_accuracy: 0.6146\n","Epoch 153/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6758 - accuracy: 0.5602 - val_loss: 0.6650 - val_accuracy: 0.6042\n","Epoch 154/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6787 - accuracy: 0.5810 - val_loss: 0.6649 - val_accuracy: 0.5938\n","Epoch 155/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6789 - accuracy: 0.5764 - val_loss: 0.6642 - val_accuracy: 0.6458\n","Epoch 156/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6774 - accuracy: 0.5775 - val_loss: 0.6635 - val_accuracy: 0.6354\n","Epoch 157/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6753 - accuracy: 0.5856 - val_loss: 0.6632 - val_accuracy: 0.6354\n","Epoch 158/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6859 - accuracy: 0.5382 - val_loss: 0.6636 - val_accuracy: 0.6458\n","Epoch 159/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6818 - accuracy: 0.5579 - val_loss: 0.6640 - val_accuracy: 0.6458\n","Epoch 160/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6744 - accuracy: 0.5856 - val_loss: 0.6636 - val_accuracy: 0.6250\n","Epoch 161/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6768 - accuracy: 0.5683 - val_loss: 0.6636 - val_accuracy: 0.6146\n","Epoch 162/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6726 - accuracy: 0.5787 - val_loss: 0.6636 - val_accuracy: 0.6042\n","Epoch 163/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6720 - accuracy: 0.5984 - val_loss: 0.6635 - val_accuracy: 0.6042\n","Epoch 164/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6717 - accuracy: 0.5706 - val_loss: 0.6628 - val_accuracy: 0.5833\n","Epoch 165/200\n","14/14 [==============================] - 0s 32ms/step - loss: 0.6846 - accuracy: 0.5521 - val_loss: 0.6624 - val_accuracy: 0.5938\n","Epoch 166/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6805 - accuracy: 0.5752 - val_loss: 0.6622 - val_accuracy: 0.6042\n","Epoch 167/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6760 - accuracy: 0.5752 - val_loss: 0.6622 - val_accuracy: 0.6146\n","Epoch 168/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6687 - accuracy: 0.5729 - val_loss: 0.6627 - val_accuracy: 0.6146\n","Epoch 169/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6767 - accuracy: 0.5718 - val_loss: 0.6635 - val_accuracy: 0.6042\n","Epoch 170/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6763 - accuracy: 0.5787 - val_loss: 0.6638 - val_accuracy: 0.6250\n","Epoch 171/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6788 - accuracy: 0.5625 - val_loss: 0.6638 - val_accuracy: 0.6042\n","Epoch 172/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6693 - accuracy: 0.5972 - val_loss: 0.6641 - val_accuracy: 0.6146\n","Epoch 173/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6788 - accuracy: 0.5718 - val_loss: 0.6636 - val_accuracy: 0.5938\n","Epoch 174/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6725 - accuracy: 0.5891 - val_loss: 0.6639 - val_accuracy: 0.5938\n","Epoch 175/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6730 - accuracy: 0.5868 - val_loss: 0.6651 - val_accuracy: 0.6042\n","Epoch 176/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6771 - accuracy: 0.5648 - val_loss: 0.6656 - val_accuracy: 0.5938\n","Epoch 177/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6802 - accuracy: 0.5637 - val_loss: 0.6663 - val_accuracy: 0.6042\n","Epoch 178/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6751 - accuracy: 0.5868 - val_loss: 0.6663 - val_accuracy: 0.6042\n","Epoch 179/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6721 - accuracy: 0.5938 - val_loss: 0.6661 - val_accuracy: 0.6042\n","Epoch 180/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6742 - accuracy: 0.5787 - val_loss: 0.6654 - val_accuracy: 0.6042\n","Epoch 181/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6763 - accuracy: 0.5822 - val_loss: 0.6646 - val_accuracy: 0.6042\n","Epoch 182/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6722 - accuracy: 0.5914 - val_loss: 0.6643 - val_accuracy: 0.5625\n","Epoch 183/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6660 - accuracy: 0.6053 - val_loss: 0.6653 - val_accuracy: 0.5938\n","Epoch 184/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6705 - accuracy: 0.5891 - val_loss: 0.6649 - val_accuracy: 0.5833\n","Epoch 185/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6707 - accuracy: 0.6030 - val_loss: 0.6645 - val_accuracy: 0.5833\n","Epoch 186/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6742 - accuracy: 0.5880 - val_loss: 0.6640 - val_accuracy: 0.5938\n","Epoch 187/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6686 - accuracy: 0.5938 - val_loss: 0.6644 - val_accuracy: 0.5833\n","Epoch 188/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6704 - accuracy: 0.5868 - val_loss: 0.6639 - val_accuracy: 0.5833\n","Epoch 189/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6829 - accuracy: 0.5648 - val_loss: 0.6625 - val_accuracy: 0.5833\n","Epoch 190/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6771 - accuracy: 0.5683 - val_loss: 0.6628 - val_accuracy: 0.5833\n","Epoch 191/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6714 - accuracy: 0.5810 - val_loss: 0.6628 - val_accuracy: 0.5729\n","Epoch 192/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6729 - accuracy: 0.5799 - val_loss: 0.6629 - val_accuracy: 0.5729\n","Epoch 193/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6741 - accuracy: 0.5856 - val_loss: 0.6620 - val_accuracy: 0.5833\n","Epoch 194/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6750 - accuracy: 0.5914 - val_loss: 0.6625 - val_accuracy: 0.5729\n","Epoch 195/200\n","14/14 [==============================] - 0s 32ms/step - loss: 0.6698 - accuracy: 0.5926 - val_loss: 0.6628 - val_accuracy: 0.5729\n","Epoch 196/200\n","14/14 [==============================] - 0s 29ms/step - loss: 0.6676 - accuracy: 0.6088 - val_loss: 0.6633 - val_accuracy: 0.5833\n","Epoch 197/200\n","14/14 [==============================] - 0s 28ms/step - loss: 0.6723 - accuracy: 0.5775 - val_loss: 0.6638 - val_accuracy: 0.5833\n","Epoch 198/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6729 - accuracy: 0.5694 - val_loss: 0.6625 - val_accuracy: 0.5625\n","Epoch 199/200\n","14/14 [==============================] - 0s 30ms/step - loss: 0.6709 - accuracy: 0.6042 - val_loss: 0.6623 - val_accuracy: 0.5833\n","Epoch 200/200\n","14/14 [==============================] - 0s 31ms/step - loss: 0.6682 - accuracy: 0.5880 - val_loss: 0.6623 - val_accuracy: 0.5521\n","8/8 [==============================] - 0s 12ms/step - loss: 0.6901 - accuracy: 0.5625\n","[0.6900599002838135, 0.5625]\n"]}]},{"cell_type":"code","metadata":{"id":"CAnc2SJa3o9f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651813072931,"user_tz":-360,"elapsed":594,"user":{"displayName":"Md. Sultan Mahmud","userId":"06779944893886852404"}},"outputId":"aac905fd-84eb-45a7-d5b9-1dbea915cb00"},"source":["print(\"Accuracy : \")\n","accr=[]\n","Fscr=[]\n","for i in val_res['accuracy']:\n","  print(round(i[1]*100, 2)) # Rounding off to two decimal places\n","  accr.append(round(i[1]*100, 2))\n","print(np.array(accr).mean()) \n","print(\"......................\")\n","print(\"F1 Score : \")\n","for i in val_res['f1_score']:\n","  print(round(i*100, 2)) # Rounding off to two decimal places\n","  Fscr.append(round(i*100, 2))\n","print(np.array(Fscr).mean()) \n","print(\"......................\")\n","print(\"Confusion Matrix\")\n","for i in val_res['confusion_matrix']:\n","  print(i)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy : \n","56.67\n","55.0\n","56.25\n","57.08\n","52.5\n","58.75\n","58.33\n","52.08\n","53.33\n","56.25\n","55.624\n","......................\n","F1 Score : \n","56.07\n","50.27\n","55.41\n","52.97\n","52.38\n","54.54\n","56.6\n","50.64\n","49.76\n","51.23\n","52.987\n","......................\n","Confusion Matrix\n","[[54 54]\n"," [50 82]]\n","[[ 29  79]\n"," [ 29 103]]\n","[[51 57]\n"," [48 84]]\n","[[ 33  75]\n"," [ 28 104]]\n","[[57 51]\n"," [63 69]]\n","[[ 34  74]\n"," [ 25 107]]\n","[[46 62]\n"," [38 94]]\n","[[42 66]\n"," [49 83]]\n","[[32 76]\n"," [36 96]]\n","[[ 29  79]\n"," [ 26 106]]\n"]}]},{"cell_type":"code","source":["#50 epochs\n","acrc = np.array(val_res['accuracy']).mean(axis=0)\n","f1scr = np.array(val_res['f1_score']).mean(axis=0)\n","print(\"Accuracy  : {}\".format(acrc[1]))\n","print(\"F1_Score  : {}\".format(f1scr))\n","cmatrix = np.array(val_res['confusion_matrix']).mean(axis=0)\n","c_matrix = cmatrix/np.sum(cmatrix, axis=1).reshape(2,1)\n","import seaborn as sns\n","figure = plt.figure(figsize=(9, 9))\n","sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n","plt.tight_layout()\n","plt.ylabel('True label')\n","plt.xlabel('Predicted label')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":706},"id":"MNroGTRBu5yw","executionInfo":{"status":"ok","timestamp":1651813100566,"user_tz":-360,"elapsed":595,"user":{"displayName":"Md. Sultan Mahmud","userId":"06779944893886852404"}},"outputId":"a1615142-cf17-4584-e198-49a13fa6e880"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy  : 0.5562499940395356\n","F1_Score  : 0.5298715100829045\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 648x648 with 2 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAm8AAAKOCAYAAADwLv6vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de7RddXkv/O+TBEQEPSAQ5R402IKeKiJaPOWgVYj1LejxUtTzvtqjTfWItnpqC6MttvHYem37HsXaqKhtRby1Gisl1SrekQTFS2KREFQSFBTiPVyS/M4fe2WvxSbZeyew954zfD5jzOGatzV/e42R4cP3mb85q7UWAAD6Yd5cDwAAgOlTvAEA9IjiDQCgRxRvAAA9ongDAOgRxRsAQI8smOsB7MxXr/upZ5jAHuC0P79krocA3I1uePszai6ue+9HnD1ndcHmr7x5Tv7mnZG8AQDcBVW1pKquqqp1VXXODvb/dVVdOVi+VVU/Gtn33Kq6erA8dzrX62zyBgDQdVU1P8n5SZ6YZEOSVVW1orW2dvsxrbWXjRz/kiSPGHw+MMkrk5yYpCW5YnDupsmuKXkDALqv5s3dMrmTkqxrra1vrd2W5KIkZ05y/LOSvHfw+fQkH2+t3Two2D6eZMlUF1S8AQBMoqqWVtXqkWXpyO7Dklw3sr5hsG1H33NUkkVJPrmr547SNgUAuq/mbs5Aa215kuV3w1edleSDrbWtd+VLJG8AALtvY5IjRtYPH2zbkbMybJnu6rnjFG8AQPd19563VUkWV9Wiqto7YwXaijsNv+qXkhyQ5Isjm1cmOa2qDqiqA5KcNtg2KW1TAIDd1FrbUlVnZ6zomp/kgtbamqpalmR1a217IXdWkotaa23k3Jur6lUZKwCTZFlr7eaprql4AwC4C1prFye5eMK28yas/9lOzr0gyQW7cj3FGwDQfXM4YaFr3PMGANAjkjcAoPumnjhwj+GXAADoEcUbAECPaJsCAN1nwsI4yRsAQI9I3gCA7jNhYZxfAgCgRyRvAED3uedtnOQNAKBHFG8AAD2ibQoAdJ8JC+P8EgAAPSJ5AwC6z4SFcZI3AIAekbwBAN3nnrdxfgkAgB5RvAEA9Ii2KQDQfSYsjJO8AQD0iOQNAOg+ExbG+SUAAHpE8QYA0CPapgBA92mbjvNLAAD0iOQNAOi+eR4Vsp3kDQCgRyRvAED3uedtnF8CAKBHFG8AAD2ibQoAdJ93m46TvAEA9IjkDQDoPhMWxvklAAB6RPIGAHSfe97GSd4AAHpE8QYA0CPapgBA95mwMM4vAQDQI5I3AKD7TFgYJ3kDAOgRxRsAQI9omwIA3WfCwji/BABAj0jeAIDuM2FhnOQNAKBHJG8AQPe5522cXwIAoEcUbwAAPaJtCgB0nwkL4yRvAAA9InkDALrPhIVxfgkAgB6RvAEA3Sd5G+eXAADoEcUbAECPaJsCAN3nUSHjJG8AAD0ieQMAus+EhXF+CQCAHlG8AQD0iLYpANB9JiyMk7wBAPSI5A0A6D4TFsb5JQAAekTxBgB0X9XcLVMOrZZU1VVVta6qztnJMc+sqrVVtaaqLhzZvrWqrhwsK6bzU2ibAgDspqqan+T8JE9MsiHJqqpa0VpbO3LM4iTnJnlsa21TVR0y8hWbW2sP35VrSt4AAHbfSUnWtdbWt9ZuS3JRkjMnHPM7Sc5vrW1KktbajXflgoo3AKDzqmoul6VVtXpkWToytMOSXDeyvmGwbdSxSY6tqs9X1WVVtWRk3z6D77ysqp4ynd9C2xQAYBKtteVJlt+Fr1iQZHGSU5McnuQzVfWw1tqPkhzVWttYVcck+WRVfb21ds1UXwYA0GnV3Yf0bkxyxMj64YNtozYk+VJr7fYk11bVtzJWzK1qrW1Mktba+qq6NMkjkkxavGmbAgDsvlVJFlfVoqraO8lZSSbOGv1wxlK3VNVBGWujrq+qA6rqXiPbH5tkbaYgeQMA2E2ttS1VdXaSlUnmJ7mgtbamqpYlWd1aWzHYd1pVrU2yNckrWms3VdXJSf6uqrZlLFB7zegs1Z1RvAEA3dfZrmnSWrs4ycUTtp038rkleflgGT3mC0ketqvX0zYFAOgRyRsA0HkdnrAw6yRvAAA9InkDADpP8jYkeQMA6BHFGwBAj2ibAgCdp206JHkDAOgRyRsA0HmStyHJGwBAj0jeAIDuE7yNk7wBAPSI4g0AoEe0TQGAzjNhYUjyBgDQI5I3AKDzJG9DkjcAgB5RvAEA9Ii2KQDQedqmQ5I3AIAekbwBAJ0neRuSvAEA9IjkDQDoPsHbOMkbAECPKN4AAHpE2xQA6DwTFoYkbwAAPSJ5AwA6T/I2JHkDAOgRyRsA0HmStyHJGwBAjyjeAAB6RNsUAOg+XdNxkjcAgB6RvAEAnWfCwpDkDQCgRxRvAAA9om0KAHSetumQ5A0AoEckbwBA50nehiRvAAA9InkDADpP8jYkeQMA6BHFGwBAj2ibAgDdp2s6TvIGANAjkjcAoPNMWBiSvAEA9IjkDQDoPMnbkOQNAKBHFG8AAD2ibQoAdJ626ZDkDQCgRyRvAED3Cd7GSd4AAHpE8QYA0CPapgBA55mwMCR5AwDoEckbANB5krchyRsAQI9I3gCAzpO8DUneAAB6RPLGjLny8i/knW95Q7Zt25Zff9JT8pRnPe8O+//tox/Myo98IPPmz88++9w7v/vyP87hRx2TLVu25K1vfFWuvfo/sm3b1pzyhCfnqc/+7bn5I4A87viF+d/PekTmz6u857Pr86Z/vepOx5xx4uH5gzOOT2stazf8OC9625dy/BH3y+v++yOz3z4Lsq21/M3HvpmPrNowB38B7FkUb8yIbVu35h1vem3+5LXn5/4HL8y5L/7/cuLJp+Two44ZP+a/PH5JTvvNpydJVn/h03n33/51/vg1b8pln/5Ettx+W9749vfl1ltuycuf/4w89vGn55AHHDpXfw7cY82r5DXPOSHP/KvP5PpNv8jKP3lCVl55fb71vZ+OH7PokP3y0t/4pfzmaz6ZH//i9hy0/72SJJtv25qz33F5rr3xZ1l4v33y8T99Qj71jRvyk823z9WfQ49pmw5pmzIj1l21Jg849IgsPPTwLNhrr5x86mlZ9flP3+GYfe+z3/jnW27ZPPyHWcktt9ySrVu35LZbb8mCBXtl333vM5vDBwZOWHRgrr3xZ/nOD3+e27e2fPjy67Lk4Yfd4Zj/fsqivPNT1+THvxgryn7401uTJOtv+FmuvfFnSZIbfnxLfvjTW3P/QWEH7D7JGzPi5h/emPsfsnB8/f4HH5Kr/+Mbdzruko+8Px/74HuyZcuWnPf6v02SPOaUJ2T1Fz6dpc9ckttuvSXPfeHLs9997zdrYweGHnDAvXP9pl+Mr1+/6Rc54Zj73+GYBy3cP0ny0XMel/lVef2KNfnUmhvucMwjFh2QvRbMy7d/8LOZHzR7JsHbuBlL3qrql6rqj6rq/wyWP6qqX56p69FPS858Zt70Dx/Jc17wknzoPe9Ikqz7j29k3rz5+bv3XZI3/8OKfPSD/5gbrnefDHTVgnmVYw7ZP099/aV54dsuyxufe2Lue++9xvcfcr998ubnPzq//85VaW0OBwozpKqWVNVVVbWuqs7ZyTHPrKq1VbWmqi4c2f7cqrp6sDx3OtebkeKtqv4oyUUZq5MvHyyV5L07+6MG5y2tqtVVtfqD73nnTAyNWXLgQYfkphuH/+V90w9uzIH3P2Snx5/8uNOy6vOXJkk+98mVefijfjULFizI/Q44MA85/ldyzbe+OdNDBnbg+5s259AD9h1fP/SAffP9TZvvcMz1mzZn5Vevz5atLd/94S+y/oaf5piFY7dF7LfPgrznpf8lf/nPX88V62+e1bHDbKiq+UnOT/KkJMcleVZVHTfhmMVJzk3y2Nba8Ul+f7D9wCSvTPLoJCcleWVVHTDVNWcqeXt+kke11l7TWvvHwfKawcCev7OTWmvLW2snttZOfPpzzC7sswc95Lh8b+N1ufF7G7Pl9tvzhUv/LSeefModjvnehu+Of/7ylz6XBx5+ZJLkoEMW5htXrk6S3LJ5c67+5jdy2JFHz9rYgaGvfHtTjlm4X448aN/sNb/ylJOOyMqvXn+HY/71Kxtz8kMOTpIcuN/eOWbh/vnOD36eveZX3vXik/OBL34n/3LFxrkYPnuQqpqzZQonJVnXWlvfWrstY+HVmROO+Z0k57fWNiVJa+3GwfbTk3y8tXbzYN/HkyyZ6oIzdc/btiSHJvnOhO0PHOxjDzd//oL8j5e8Iq8+5yXZtm1rHrfkjBxx9IPyvne9NQ869pdz4sn/NZd85P35+pcvz/wFC7LffvvnxX/4Z0nGWqlvef2f5+XPf2Zaa3nc6b+Zo45ZPLd/ENxDbd3Wcu6FX8lFv39K5s+rvPfz1+aq63+SPzzz+Hz12zdn5Ve/l0+tuSGnHv+AfGbZ6dm2rWXZB76WTT+/LU97zJF5zOKDc8B97pXfOvnoJMlL33l51lz347n9o2AXVdXSJEtHNi1vrS0ffD4syXUj+zZkLEkbdezgez6fZH6SP2utXbKTcw/LFKrNwA0IVbUkyZuTXD0yqCOTPDjJ2YMBT+qr1/3UnRGwBzjtz6f85w70yA1vf8acTB140P/61zmrC65545N2+jdX1dOTLGmtvWCw/v8meXRr7eyRY/4lye1Jnpnk8CSfSfKwJC9Isk9r7X8PjvvTJJtba2+YbDwzkry11i6pqmMzFiVuryA3JlnVWts6E9cEAJgDG5McMbJ++GDbqA1JvtRauz3JtVX1rSSLB8edOuHcS6e64Iw9KqS1ti3JZTP1/QDAPUeHn9G7KsniqlqUsWLsrCTPnnDMh5M8K8k7q+qgjLVR1ye5JslfjExSOC1jExsm5TlvAAC7qbW2parOTrIyY/ezXdBaW1NVy5Ksbq2tGOw7rarWJtma5BWttZuSpKpelbECMEmWtdamnJateAMAuAtaaxcnuXjCtvNGPrckLx8sE8+9IMkFu3I9xRsA0HnebTrk3aYAAD0ieQMAOk/wNiR5AwDoEckbANB57nkbkrwBAPSI4g0AoEe0TQGAztM1HZK8AQD0iOQNAOi8efNEb9tJ3gAAekTxBgDQI9qmAEDnmbAwJHkDAOgRyRsA0HnesDAkeQMA6BHJGwDQeYK3IckbAECPKN4AAHpE2xQA6DwTFoYkbwAAPSJ5AwA6T/I2JHkDAOgRyRsA0HmCtyHJGwBAjyjeAAB6RNsUAOg8ExaGJG8AAD0ieQMAOk/wNiR5AwDoEcUbAECPaJsCAJ1nwsKQ5A0AoEckbwBA5wnehiRvAAA9InkDADrPPW9DkjcAgB5RvAEA9Ii2KQDQebqmQ5I3AIAekbwBAJ1nwsKQ5A0AoEckbwBA5wnehiRvAAA9ongDAOgRbVMAoPNMWBiSvAEA9IjkDQDoPMHbkOQNAKBHFG8AAD2ibQoAdJ4JC0OSNwCAHpG8AQCdJ3gbkrwBAPSI5A0A6Dz3vA1J3gAAekTxBgDQI9qmAEDnaZsOSd4AAHpE8gYAdJ7gbUjyBgDQI4o3AIAe0TYFADrPhIUhyRsAQI9I3gCAzhO8DUneAAB6RPEGAHReVc3ZMo2xLamqq6pqXVWds4P9z6uqH1TVlYPlBSP7to5sXzGd30LbFABgN1XV/CTnJ3likg1JVlXVitba2gmHvq+1dvYOvmJza+3hu3JNyRsAwO47Kcm61tr61tptSS5KcuZMXlDxBgB0XtVcLrW0qlaPLEtHhnZYkutG1jcMtk30tKr6WlV9sKqOGNm+z+A7L6uqp0znt9A2BQCYRGtteZLld+ErPprkva21W6vqd5O8O8njB/uOaq1trKpjknyyqr7eWrtmsi9TvAEAnTevu88K2ZhkNEk7fLBtXGvtppHVtyd53ci+jYP/XV9VlyZ5RJJJizdtUwCA3bcqyeKqWlRVeyc5K8kdZo1W1QNHVs9I8s3B9gOq6l6DzwcleWySiRMd7kTyBgB0XleDt9balqo6O8nKJPOTXNBaW1NVy5Ksbq2tSPLSqjojyZYkNyd53uD0X07yd1W1LWOB2mt2MEv1ThRvAAB3QWvt4iQXT9h23sjnc5Ocu4PzvpDkYbt6PW1TAIAekbwBAJ03nTcd3FNI3gAAekTyBgB03jzB2zjJGwBAjyjeAAB6RNsUAOg8ExaGJG8AAD0ieQMAOk/wNiR5AwDoEckbANB5FdHbdpI3AIAeUbwBAPSItikA0HnesDAkeQMA6BHJGwDQeR7SOyR5AwDoEckbANB5grchyRsAQI8o3gAAekTbFADovHn6puMkbwAAPSJ5AwA6T/A2JHkDAOgRxRsAQI9omwIAnecNC0OSNwCAHpG8AQCdJ3gbkrwBAPSI5A0A6DwP6R2SvAEA9IjiDQCgR7RNAYDO0zQdkrwBAPSI5A0A6DwP6R2SvAEA9IjkDQDovHmCt3GSNwCAHlG8AQD0iLYpANB5JiwMSd4AAHpE8gYAdJ7gbUjyBgDQI4o3AIAe0TYFADrPhIUhyRsAQI9I3gCAzvOGhaGdFm9V9aYkbWf7W2svnZERAQCwU5Mlb6tnbRQAAJNwz9vQTou31tq7R9erat/W2i9mfkgAAOzMlBMWqupXq2ptkv8YrP9KVb1lxkcGAMCdTGe26d8kOT3JTUnSWvtqklNmclAAAKNqDpeumdajQlpr103YtHUGxgIAwBSm86iQ66rq5CStqvZK8ntJvjmzwwIAGJpnwsK46SRvL0zy4iSHJbk+ycMH6wAAzLIpk7fW2g+TPGcWxgIAsEOCt6HpzDY9pqo+WlU/qKobq+ojVXXMbAwOAIA7mk7b9MIk70/ywCSHJvlAkvfO5KAAANix6RRv+7bW/qG1tmWw/GOSfWZ6YAAA21XVnC1dM9m7TQ8cfPzXqjonyUUZe9fpbyW5eBbGBgDABJNNWLgiY8Xa9pLzd0f2tSTnztSgAABGdTAAmzOTvdt00WwOBACAqU3nIb2pqocmOS4j97q11v5+pgYFAMCOTVm8VdUrk5yaseLt4iRPSvK5JIo3AGBWeMPC0HRmmz49ya8n+X5r7beT/EqS+83oqAAA2KHptE03t9a2VdWWqrpvkhuTHDHD4wIAGCd4G5pO8ra6qv5TkrdlbAbql5N8cUZHBQDQE1W1pKquqqp1g8erTdz/vMGbqq4cLC8Y2ffcqrp6sDx3OtebzrtN/+fg41ur6pIk922tfW26fxAAwF3VxYflJklVzU9yfpInJtmQZFVVrWitrZ1w6Ptaa2dPOPfAJK9McmLGHsN2xeDcTZNdc7KH9J4w2b7W2pcn/WsAAPZ8JyVZ11pbnyRVdVGSM5NMLN525PQkH2+t3Tw49+NJlmSK15BOlry9cZJ9LcnjpzGo3faQB+4/k18PzJKfXPHpuR4CcLd6xlwPYNZV1dIkS0c2LW+tLR98PizJdSP7NiR59A6+5mlVdUqSbyV5WWvtup2ce9hU45nsIb2Pm+pkAIDZMJ2b9GfKoFBbPuWBO/fRJO9trd1aVb+b5N25CyHYXP4WAAB9tzF3fArH4YNt41prN7XWbh2svj3JI6d77o4o3gCAzquqOVumsCrJ4qpaVFV7JzkryYoJY3/gyOoZSb45+LwyyWlVdUBVHZDktMG2SU3r9VgAANxZa21LVZ2dsaJrfpILWmtrqmpZktWttRVJXlpVZyTZkuTmJM8bnHtzVb0qYwVgkizbPnlhMtN5PVYleU6SY1pry6rqyCQPaK1dvut/IgDAnqW1dnHGXiE6uu28kc/nJjl3J+dekOSCXbnedJK3tyTZlrEb65Yl+WmSDyV51K5cCABgd83r5mPe5sR0irdHt9ZOqKqvJElrbdOgpwsAwCybTvF2++DpwS1JqurgjCVxAACzQvI2NJ3Zpv8nyT8nOaSqXp3kc0n+YkZHBQDADk3n3abvqaorkvx6kkrylNbaN6c4DQDgbtPVd5vOhenMNj0yyS8y9nTg8W2tte/O5MAAALiz6dzz9rGM3e9WSfZJsijJVUmOn8FxAQCwA9Npmz5sdL2qTkjyP2dsRAAAE5iwMLTLr8dqrX05yaNnYCwAAExhOve8vXxkdV6SE5JcP2MjAgCYwHyFoenc87b/yOctGbsH7kMzMxwAACYzafE2eDjv/q21P5il8QAA3Mk80du4nd7zVlULWmtbkzx2FscDAMAkJkveLs/Y/W1XVtWKJB9I8vPtO1tr/zTDYwMAYILp3PO2T5Kbkjw+w+e9tSSKNwBgVuzy4zH2YJMVb4cMZpp+I8Oibbs2o6MCAGCHJive5ifZL3cs2rZTvAEAs8Z8haHJirfvtdaWzdpIAACY0mQtZDUuAEDHTJa8/fqsjQIAYBKe8za00+SttXbzbA4EAICpTedRIQAAc0rwNuSxKQAAPSJ5AwA6b57kbZzkDQCgRxRvAAA9om0KAHSeR4UMSd4AAHpE8gYAdJ7gbUjyBgDQI5I3AKDzPCpkSPIGANAjijcAgB7RNgUAOq+ib7qd5A0AoEckbwBA55mwMCR5AwDoEcUbAECPaJsCAJ2nbTokeQMA6BHJGwDQeeXlpuMkbwAAPSJ5AwA6zz1vQ5I3AIAeUbwBAPSItikA0HnmKwxJ3gAAekTyBgB03jzR2zjJGwBAj0jeAIDO86iQIckbAECPKN4AAHpE2xQA6DzzFYYkbwAAPSJ5AwA6b15Eb9tJ3gAAekTxBgDQI9qmAEDnmbAwJHkDAOgRyRsA0HnesDAkeQMA6BHJGwDQefPc9DZO8gYA0COKNwCAHtE2BQA6T9d0SPIGANAjijcAoPPmVc3ZMpWqWlJVV1XVuqo6Z5LjnlZVrapOHKwfXVWbq+rKwfLW6fwW2qYAALupquYnOT/JE5NsSLKqqla01tZOOG7/JL+X5EsTvuKa1trDd+WakjcAgN13UpJ1rbX1rbXbklyU5MwdHPeqJK9NcstdvaDiDQDovKq5XGppVa0eWZaODO2wJNeNrG8YbBsZe52Q5IjW2sd28KctqqqvVNWnq+rXpvNbaJsCAEyitbY8yfLdObeq5iX5qyTP28Hu7yU5srV2U1U9MsmHq+r41tpPJvtOxRsA0HkdbhVuTHLEyPrhg23b7Z/koUkurbHJDw9IsqKqzmitrU5ya5K01q6oqmuSHJtk9WQX7PBvAQDQeauSLK6qRVW1d5KzkqzYvrO19uPW2kGttaNba0cnuSzJGa211VV18GDCQ6rqmCSLk6yf6oKSNwCg86qjT+ltrW2pqrOTrEwyP8kFrbU1VbUsyerW2opJTj8lybKquj3JtiQvbK3dPNU1FW8AAHdBa+3iJBdP2HbeTo49deTzh5J8aFevp20KANAjkjcAoPO62TSdG5I3AIAekbwBAJ03nXeM3lNI3gAAekTyBgB0ntxtSPIGANAjijcAgB7RNgUAOs98hSHJGwBAj0jeAIDO6+q7TeeC5A0AoEcUbwAAPaJtCgB0nrRpyG8BANAjkjcAoPNMWBiSvAEA9IjkDQDoPLnbkOQNAKBHFG8AAD2ibQoAdJ4JC0OSNwCAHpG8AQCdJ20a8lsAAPSI5A0A6Dz3vA1J3gAAekTxBgDQI9qmAEDnaZoOSd4AAHpE8gYAdJ75CkOSNwCAHlG8AQD0iLYpANB580xZGCd5AwDoEckbANB5JiwMSd4AAHpE8gYAdF65522c5A0AoEcUbwAAPaJtCgB0ngkLQ5I3AIAekbwBAJ3nIb1DkjcAgB6RvAEAneeetyHJGwBAjyjeAAB6RNsUAOg8bdMhyRsAQI9I3gCAzvNu0yHJGwBAjyjeAAB6RNsUAOi8ebqm4yRvAAA9InkDADrPhIUhyRsAQI9I3gCAzvOQ3iHJGwBAjyjeAAB6RNsUAOg8ExaGJG8AAD0ieQMAOs9DeockbwAAPaJ4AwDoEW1TAKDzTFgYkrwBAPSI5A0A6DxvWBiSvAEA3AVVtaSqrqqqdVV1ziTHPa2qWlWdOLLt3MF5V1XV6dO5nuSNWfH5z34mr33Nq7Nt67Y89WnPyPN/Z+kd9r//fe/N+957YebPm5d777tvzvuzV+VBD37wHI0WmMwTT/7lvOEVT8/8efPyrg9/IW9458fvsP91/+u/5ZRHHZsk2XefvXPwgfvlgaf84VwMlT1IV4O3qpqf5PwkT0yyIcmqqlrRWls74bj9k/xeki+NbDsuyVlJjk9yaJJPVNWxrbWtk11T8caM27p1a/7i1cvyd297ZxYuXJhn/9bTc+rjHn+H4uw3nvybeeZvPStJcukn/z1veN1f5m+Xv2OuhgzsxLx5lb8555l58ovenI03/Cife88r8i+f/nr+Y/33x4/5wzf+0/jnF531X/MrDzl8LoYKs+WkJOtaa+uTpKouSnJmkrUTjntVktcmecXItjOTXNRauzXJtVW1bvB9X5zsgtqmzLhvfP1rOeKIo3L4EUdkr733zpLfeHIu/dS/3+GY/fbbb/zz5s2bU25ugE561EOPzjXX/TDf3nhTbt+yNR9Y+eX8P6f+550e/8wlj8z7L7liFkcId7+qWlpVq0eW0fbRYUmuG1nfMNg2ev4JSY5orX1swldPee6OSN6YcTfecEMe8MAHjK8fsnBhvv61r93puIsufE/+4e/fmdtvvz1vu+DdszlEYJoOPeR+2XDDpvH1jTdsykkPPXqHxx75wANy1KH3z6Wrrpql0bEnmzeH/1HfWlueZPnunFtV85L8VZLn3V3jmfXkrap+e7avST+c9ezn5GOXfCK//7I/yNve+rdzPRzgLnrG6Y/Mh//9ymzb1uZ6KDCTNiY5YmT98MG27fZP8tAkl1bVt5M8JsmKwaSFqc7doblom/75znaMxpLveNtuFbh00CELF+b73xveD3PjDTdk4cKFOz1+yW88OZ/65CdmY2jALrr+xh/n8IUHjK8ftvCAbPzBj3d47NNPf2Tef8nq2Roae7iaw2UKq5IsrqpFVbV3xiYgrNi+s7X249baQa21o1trRye5LMkZrbXVg+POqqp7VdWiJIuTXD7VBWekbVpVd+6JDXYl2en/a4/Gkrdsif9U20Mc/9CH5bvf/XY2bLguCw9ZmEsu/lj+8vVvvHeGdSoAAAx+SURBVMMx3/nOt3PUUUcnST7z6Utz5FFHzcFIgamsXvOdPPjIg3PUoffP9Tf+KM84/YQ879x33em4Y49emAPuu28u++q1sz9ImEWttS1VdXaSlUnmJ7mgtbamqpYlWd1aWzHJuWuq6v0Zm9ywJcmLp5ppmszcPW8Lk5yeZNOE7ZXkCzN0TTpqwYIFOfePz8uLlr4g27ZtzVOe+rQ8+MGLc/6b/v8cf/xDc+rjfz0XXfiPueyLX8xeCxZk//veN6/6i9fO9bCBHdi6dVte9tr356NveXHmz6u8+yOX5Zvrv58/fdGT8+W1383HPv31JGMt0w+sNFGBu1GH57G11i5OcvGEbeft5NhTJ6y/Osmrd+V61drdH3BV1TuSvLO19rkd7Luwtfbsqb5D8gZ7hgMedfZcDwG4G23+ypvnpIy67JofzVld8JgH/adOlY4zkry11p4/yb4pCzcAAHbMo0IAgM6rLvdNZ5mH9AIA9IjkDQDoPC/eGZK8AQD0iOINAKBHtE0BgM7TNR2SvAEA9IjkDQDoPtHbOMkbAECPSN4AgM7zkN4hyRsAQI8o3gAAekTbFADoPG9YGJK8AQD0iOQNAOg8wduQ5A0AoEckbwBA94nexkneAAB6RPEGANAj2qYAQOd5w8KQ5A0AoEckbwBA53lI75DkDQCgRxRvAAA9om0KAHSerumQ5A0AoEckbwBA94nexkneAAB6RPIGAHSeh/QOSd4AAHpE8QYA0CPapgBA53nDwpDkDQCgRyRvAEDnCd6GJG8AAD0ieQMAuk/0Nk7yBgDQI4o3AIAe0TYFADrPGxaGJG8AAD0ieQMAOs9DeockbwAAPaJ4AwDoEW1TAKDzdE2HJG8AAD0ieQMAuk/0Nk7yBgDQI5I3AKDzPKR3SPIGANAjijcAgB7RNgUAOs8bFoYkbwAAPSJ5AwA6T/A2JHkDAOgRxRsAQI9omwIA3advOk7yBgDQI5I3AKDzvGFhSPIGANAjkjcAoPM8pHdI8gYA0COKNwCAHtE2BQA6T9d0SPIGANAjijcAoPtqDpephla1pKquqqp1VXXODva/sKq+XlVXVtXnquq4wfajq2rzYPuVVfXW6fwU2qYAALupquYnOT/JE5NsSLKqqla01taOHHZha+2tg+PPSPJXSZYM9l3TWnv4rlxT8QYAdF6HH9J7UpJ1rbX1SVJVFyU5M8l48dZa+8nI8fdJ0u7KBbVNAQAmUVVLq2r1yLJ0ZPdhSa4bWd8w2DbxO15cVdckeV2Sl47sWlRVX6mqT1fVr01nPJI3AIBJtNaWJ1l+F7/j/CTnV9Wzk/xJkucm+V6SI1trN1XVI5N8uKqOn5DU3YnkDQDovKq5W6awMckRI+uHD7btzEVJnpIkrbVbW2s3DT5fkeSaJMdOdUHFGwDA7luVZHFVLaqqvZOclWTF6AFVtXhk9clJrh5sP3gw4SFVdUySxUnWT3VBbVMAoPO6Ol2htbalqs5OsjLJ/CQXtNbWVNWyJKtbayuSnF1VT0hye5JNGWuZJskpSZZV1e1JtiV5YWvt5qmuWa3dpQkPM+aWLXdtJgbQDQc86uy5HgJwN9r8lTfPSR317R/eMmd1wdEH7dOp2lHbFACgR7RNAYDu61T2NbckbwAAPSJ5AwA6r8NvWJh1kjcAgB6RvAEAnTeNh+XeY0jeAAB6RPEGANAj2qYAQOfpmg5J3gAAekTyBgB0ngkLQ5I3AIAekbwBAD0gettO8gYA0COKNwCAHtE2BQA6z4SFIckbAECPSN4AgM4TvA1J3gAAekTxBgDQI9qmAEDnmbAwJHkDAOgRyRsA0HllysI4yRsAQI9I3gCA7hO8jZO8AQD0iOINAKBHtE0BgM7TNR2SvAEA9IjkDQDoPA/pHZK8AQD0iOQNAOg8D+kdkrwBAPSI4g0AoEe0TQGA7tM1HSd5AwDoEckbANB5grchyRsAQI8o3gAAekTbFADoPG9YGJK8AQD0iOQNAOg8b1gYkrwBAPSI5A0A6Dz3vA1J3gAAekTxBgDQI4o3AIAeUbwBAPSICQsAQOeZsDAkeQMA6BHFGwBAj2ibAgCd5w0LQ5I3AIAekbwBAJ1nwsKQ5A0AoEckbwBA5wnehiRvAAA9ongDAOgRbVMAoPv0TcdJ3gAAekTyBgB0nof0DkneAAB6RPIGAHSeh/QOSd4AAHpE8QYA0CPapgBA5+maDkneAADugqpaUlVXVdW6qjpnB/tfWFVfr6orq+pzVXXcyL5zB+ddVVWnT+d6kjcAoPs6Gr1V1fwk5yd5YpINSVZV1YrW2tqRwy5srb11cPwZSf4qyZJBEXdWkuOTHJrkE1V1bGtt62TXlLwBAOy+k5Ksa62tb63dluSiJGeOHtBa+8nI6n2StMHnM5Nc1Fq7tbV2bZJ1g++blOINAGASVbW0qlaPLEtHdh+W5LqR9Q2DbRO/48VVdU2S1yV56a6cO5G2KQDQeXP5hoXW2vIky+/id5yf5PyqenaSP0ny3N39LskbAMDu25jkiJH1wwfbduaiJE/ZzXOTKN4AgB6omrtlCquSLK6qRVW1d8YmIKy449hr8cjqk5NcPfi8IslZVXWvqlqUZHGSy6e6oLYpAMBuaq1tqaqzk6xMMj/JBa21NVW1LMnq1tqKJGdX1ROS3J5kUwYt08Fx70+yNsmWJC+eaqZpklRrbapjYMZU1dLBvQRAz/n3DLND25S5tnTqQ4Ce8O8ZZoHiDQCgRxRvAAA9onhjrrk/BvYc/j3DLDBhAQCgRyRvAAA9onhjzlTVkqq6qqrWVdU5cz0eYPdU1QVVdWNVfWOuxwL3BIo35kRVzU9yfpInJTkuybOq6ri5HRWwm96VZMlcDwLuKRRvzJWTkqxrra1vrd2WsXe9nTnHYwJ2Q2vtM0lunutxwD2F4o25cliS60bWNwy2AQCTULwBAPSI4o25sjHJESPrhw+2AQCTULwxV1YlWVxVi6pq7yRnJVkxx2MCgM5TvDEnWmtbkpydZGWSbyZ5f2ttzdyOCtgdVfXeJF9M8pCq2lBVz5/rMcGezBsWAAB6RPIGANAjijcAgB5RvAEA9IjiDQCgRxRvAAA9oniDPVBVba2qK6vqG1X1gara9y5817uq6umDz2+vquMmOfbUqjp5N67x7ao6aLrbJxzzs1281p9V1R/s6hgBukLxBnumza21h7fWHprktiQvHN1ZVQt250tbay9ora2d5JBTk+xy8QbA9CneYM/32SQPHqRin62qFUnWVtX8qnp9Va2qqq9V1e8mSY15c1VdVVWfSHLI9i+qqkur6sTB5yVV9eWq+mpV/XtVHZ2xIvFlg9Tv16rq4Kr60OAaq6rqsYNz719V/1ZVa6rq7Ulqqj+iqj5cVVcMzlk6Yd9fD7b/e1UdPNj2oKq6ZHDOZ6vql+6OHxNgru3Wf30D/TBI2J6U5JLBphOSPLS1du2gAPpxa+1RVXWvJJ+vqn9L8ogkD0lyXJKFSdYmuWDC9x6c5G1JThl814GttZur6q1JftZae8PguAuT/HVr7XNVdWTG3qjxy0lemeRzrbVlVfXkJNN5Iv//GFzj3klWVdWHWms3JblPktWttZdV1XmD7z47yfIkL2ytXV1Vj07yliSP342fEaBTFG+wZ7p3VV05+PzZJO/IWDvz8tbatYPtpyX5z9vvZ0tyvySLk5yS5L2tta1Jrq+qT+7g+x+T5DPbv6u1dvNOxvGEJMdVjQdr962q/QbX+G+Dcz9WVZum8Te9tKqeOvh8xGCsNyXZluR9g+3/mOSfBtc4OckHRq59r2lcA6DzFG+wZ9rcWnv46IZBEfPz0U1JXtJaWznhuN+4G8cxL8ljWmu37GAs01ZVp2asEPzV1tovqurSJPvs5PA2uO6PJv4GAHsC97zBPdfKJC+qqr2SpKqOrar7JPlMkt8a3BP3wCSP28G5lyU5paoWDc49cLD9p0n2Hznu35K8ZPtKVW0vpj6T5NmDbU9KcsAUY71fkk2Dwu2XMpb8bTcvyfb08NkZa8f+JMm1VfWMwTWqqn5limsA9ILiDe653p6x+9m+XFXfSPJ3GUvj/znJ1YN9f5/kixNPbK39IMnSjLUov5ph2/KjSZ66fcJCkpcmOXEwIWJthrNe/zxjxd+ajLVPvzvFWC9JsqCqvpnkNRkrHrf7eZKTBn/D45MsG2x/TpLnD8a3JsmZ0/hNADqvWmtzPQYAAKZJ8gYA0COKNwCAHlG8AQD0iOINAKBHFG8AAD2ieAMA6BHFGwBAjyjeAAB65P8CKe0rSiXkOosAAAAASUVORK5CYII=\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"e1ypZ2NnYxes"},"source":["# **Arousal**"]},{"cell_type":"code","metadata":{"id":"B7fcxLuwZpkK"},"source":["#arousal\n","X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n","print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4iz5mTT7Zwcp"},"source":["val_res = {'accuracy': [], 'f1_score': [], 'confusion_matrix': []}\n","\n","foldNum=0\n","for train_index, val_index in kfold.split(X_train, Y_train):\n","  foldNum = foldNum + 1\n","  print(\"Results for fold\",foldNum)\n","  x_train, x_val = X_train[train_index], X_train[val_index]\n","  y_train, y_val = Y_train[train_index], Y_train[val_index]\n","  model = get_model()\n","  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n","  acc = model.evaluate(x_test, y_test)\n","  print(acc)\n","  val_res['accuracy'].append(acc)\n","  pred = model.predict(x_test)\n","  val_res['f1_score'].append(f1_score(y_test.argmax(1), pred.argmax(1), average='macro'))\n","  val_res['confusion_matrix'].append(confusion_matrix(y_test.argmax(1), pred.argmax(1)))\n","  gc.collect() # Garbage collecter\n","  del x_train, x_val, y_train, y_val\n","  gc.collect()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lr-SH0e6flrE"},"source":["print(\"Accuracy : \")\n","accr=[]\n","Fscr=[]\n","for i in val_res['accuracy']:\n","  print(round(i[1]*100, 2)) # Rounding off to two decimal places\n","  accr.append(round(i[1]*100, 2))\n","print(np.array(accr).mean()) \n","print(\"......................\")\n","print(\"F1 Score : \")\n","for i in val_res['f1_score']:\n","  print(round(i*100, 2)) # Rounding off to two decimal places\n","  Fscr.append(round(i*100, 2))\n","print(np.array(Fscr).mean()) \n","print(\"......................\")\n","print(\"Confusion Matrix\")\n","for i in val_res['confusion_matrix']:\n","  print(i)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lJehdYs6ZBcD"},"source":["# **Dominance**"]},{"cell_type":"code","metadata":{"id":"MqwJWlxMZEe6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2d43affe-adab-4cba-f7ab-3ca847607fe1"},"source":["#dominance\n","X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n","print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UljSiW-xZMC_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9572b433-32f6-4cda-e454-69c23d5a847e"},"source":["foldNum=0\n","model = get_model()\n","for train_index, val_index in kfold.split(X_train, Y_train):\n","  foldNum = foldNum + 1\n","  print(\"Results for fold\",foldNum)\n","  x_train, x_val = X_train[train_index], X_train[val_index]\n","  y_train, y_val = Y_train[train_index], Y_train[val_index]\n","  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n","  gc.collect() # Garbage collecter\n","  del x_train, x_val, y_train, y_val\n","  gc.collect()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Results for fold 1\n","Epoch 1/50\n","53/53 [==============================] - 4s 53ms/step - loss: 0.9482 - accuracy: 0.5729 - val_loss: 0.8301 - val_accuracy: 0.6542\n","Epoch 2/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.8373 - accuracy: 0.6235 - val_loss: 0.8019 - val_accuracy: 0.6542\n","Epoch 3/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.8281 - accuracy: 0.6491 - val_loss: 0.7896 - val_accuracy: 0.6542\n","Epoch 4/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.7968 - accuracy: 0.6566 - val_loss: 0.7841 - val_accuracy: 0.6542\n","Epoch 5/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.8122 - accuracy: 0.6519 - val_loss: 0.7851 - val_accuracy: 0.6542\n","Epoch 6/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.8098 - accuracy: 0.6480 - val_loss: 0.7850 - val_accuracy: 0.6542\n","Epoch 7/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.7966 - accuracy: 0.6586 - val_loss: 0.7839 - val_accuracy: 0.6542\n","Epoch 8/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.7892 - accuracy: 0.6526 - val_loss: 0.7883 - val_accuracy: 0.6542\n","Epoch 9/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.7958 - accuracy: 0.6474 - val_loss: 0.7898 - val_accuracy: 0.6542\n","Epoch 10/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.7859 - accuracy: 0.6544 - val_loss: 0.7879 - val_accuracy: 0.6542\n","Epoch 11/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.7927 - accuracy: 0.6454 - val_loss: 0.7905 - val_accuracy: 0.6542\n","Epoch 12/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.7770 - accuracy: 0.6530 - val_loss: 0.7829 - val_accuracy: 0.6542\n","Epoch 13/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.7629 - accuracy: 0.6654 - val_loss: 0.7798 - val_accuracy: 0.6542\n","Epoch 14/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.7800 - accuracy: 0.6524 - val_loss: 0.7700 - val_accuracy: 0.6515\n","Epoch 15/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.7631 - accuracy: 0.6579 - val_loss: 0.7848 - val_accuracy: 0.6542\n","Epoch 16/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.7761 - accuracy: 0.6456 - val_loss: 0.7643 - val_accuracy: 0.6595\n","Epoch 17/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.7517 - accuracy: 0.6685 - val_loss: 0.7867 - val_accuracy: 0.6595\n","Epoch 18/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.7640 - accuracy: 0.6520 - val_loss: 0.7569 - val_accuracy: 0.6595\n","Epoch 19/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.7468 - accuracy: 0.6578 - val_loss: 0.7466 - val_accuracy: 0.6568\n","Epoch 20/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.7448 - accuracy: 0.6635 - val_loss: 0.7525 - val_accuracy: 0.6595\n","Epoch 21/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.7394 - accuracy: 0.6618 - val_loss: 0.7546 - val_accuracy: 0.6595\n","Epoch 22/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.7212 - accuracy: 0.6654 - val_loss: 0.7340 - val_accuracy: 0.6689\n","Epoch 23/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.7215 - accuracy: 0.6714 - val_loss: 0.7293 - val_accuracy: 0.6649\n","Epoch 24/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.7057 - accuracy: 0.6784 - val_loss: 0.7520 - val_accuracy: 0.6676\n","Epoch 25/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.7073 - accuracy: 0.6735 - val_loss: 0.7394 - val_accuracy: 0.6649\n","Epoch 26/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.6850 - accuracy: 0.6889 - val_loss: 0.7008 - val_accuracy: 0.6810\n","Epoch 27/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.6764 - accuracy: 0.6814 - val_loss: 0.6735 - val_accuracy: 0.6850\n","Epoch 28/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.6696 - accuracy: 0.6841 - val_loss: 0.6892 - val_accuracy: 0.6689\n","Epoch 29/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.6478 - accuracy: 0.7011 - val_loss: 0.6961 - val_accuracy: 0.6689\n","Epoch 30/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.6559 - accuracy: 0.6959 - val_loss: 0.6577 - val_accuracy: 0.6890\n","Epoch 31/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.6289 - accuracy: 0.7014 - val_loss: 0.6548 - val_accuracy: 0.6836\n","Epoch 32/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.6171 - accuracy: 0.7112 - val_loss: 0.6455 - val_accuracy: 0.6997\n","Epoch 33/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.5952 - accuracy: 0.7232 - val_loss: 0.5969 - val_accuracy: 0.7131\n","Epoch 34/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.5664 - accuracy: 0.7311 - val_loss: 0.6238 - val_accuracy: 0.7131\n","Epoch 35/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.5379 - accuracy: 0.7491 - val_loss: 0.5727 - val_accuracy: 0.7306\n","Epoch 36/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.5181 - accuracy: 0.7744 - val_loss: 0.5263 - val_accuracy: 0.7520\n","Epoch 37/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.4748 - accuracy: 0.7862 - val_loss: 0.4601 - val_accuracy: 0.7748\n","Epoch 38/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.4816 - accuracy: 0.7918 - val_loss: 0.4379 - val_accuracy: 0.7949\n","Epoch 39/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.4083 - accuracy: 0.8170 - val_loss: 0.3810 - val_accuracy: 0.8284\n","Epoch 40/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.3430 - accuracy: 0.8557 - val_loss: 0.3830 - val_accuracy: 0.8472\n","Epoch 41/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.3310 - accuracy: 0.8659 - val_loss: 0.3620 - val_accuracy: 0.8324\n","Epoch 42/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.3172 - accuracy: 0.8712 - val_loss: 0.2517 - val_accuracy: 0.8954\n","Epoch 43/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.2571 - accuracy: 0.9034 - val_loss: 0.2744 - val_accuracy: 0.8820\n","Epoch 44/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.2758 - accuracy: 0.8851 - val_loss: 0.2215 - val_accuracy: 0.9115\n","Epoch 45/50\n","53/53 [==============================] - 2s 40ms/step - loss: 0.2265 - accuracy: 0.9148 - val_loss: 0.2437 - val_accuracy: 0.8928\n","Epoch 46/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.1874 - accuracy: 0.9338 - val_loss: 0.1819 - val_accuracy: 0.9437\n","Epoch 47/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.1526 - accuracy: 0.9435 - val_loss: 0.1758 - val_accuracy: 0.9357\n","Epoch 48/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.1462 - accuracy: 0.9476 - val_loss: 0.1245 - val_accuracy: 0.9531\n","Epoch 49/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.1435 - accuracy: 0.9503 - val_loss: 0.1157 - val_accuracy: 0.9598\n","Epoch 50/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.1189 - accuracy: 0.9616 - val_loss: 0.2271 - val_accuracy: 0.9263\n","Results for fold 2\n","Epoch 1/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.1508 - accuracy: 0.9484 - val_loss: 0.0133 - val_accuracy: 0.9960\n","Epoch 2/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.1101 - accuracy: 0.9614 - val_loss: 0.0282 - val_accuracy: 0.9946\n","Epoch 3/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.1072 - accuracy: 0.9615 - val_loss: 0.0112 - val_accuracy: 0.9987\n","Epoch 4/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0931 - accuracy: 0.9677 - val_loss: 0.0298 - val_accuracy: 0.9920\n","Epoch 5/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.1015 - accuracy: 0.9657 - val_loss: 0.0087 - val_accuracy: 1.0000\n","Epoch 6/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0784 - accuracy: 0.9733 - val_loss: 0.0253 - val_accuracy: 0.9906\n","Epoch 7/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0821 - accuracy: 0.9739 - val_loss: 0.0105 - val_accuracy: 0.9987\n","Epoch 8/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0686 - accuracy: 0.9790 - val_loss: 0.0131 - val_accuracy: 0.9933\n","Epoch 9/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0704 - accuracy: 0.9788 - val_loss: 0.0138 - val_accuracy: 0.9933\n","Epoch 10/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0726 - accuracy: 0.9753 - val_loss: 0.0121 - val_accuracy: 0.9946\n","Epoch 11/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0693 - accuracy: 0.9785 - val_loss: 0.0100 - val_accuracy: 0.9973\n","Epoch 12/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0599 - accuracy: 0.9806 - val_loss: 0.0146 - val_accuracy: 0.9946\n","Epoch 13/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0633 - accuracy: 0.9797 - val_loss: 0.0085 - val_accuracy: 0.9973\n","Epoch 14/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0473 - accuracy: 0.9860 - val_loss: 0.0111 - val_accuracy: 0.9960\n","Epoch 15/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0585 - accuracy: 0.9802 - val_loss: 0.0078 - val_accuracy: 1.0000\n","Epoch 16/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0549 - accuracy: 0.9824 - val_loss: 0.0040 - val_accuracy: 0.9987\n","Epoch 17/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0467 - accuracy: 0.9846 - val_loss: 0.0025 - val_accuracy: 1.0000\n","Epoch 18/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0442 - accuracy: 0.9849 - val_loss: 0.0212 - val_accuracy: 0.9920\n","Epoch 19/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0602 - accuracy: 0.9818 - val_loss: 0.0039 - val_accuracy: 1.0000\n","Epoch 20/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0379 - accuracy: 0.9891 - val_loss: 0.0093 - val_accuracy: 0.9973\n","Epoch 21/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0355 - accuracy: 0.9888 - val_loss: 0.0135 - val_accuracy: 0.9933\n","Epoch 22/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0504 - accuracy: 0.9836 - val_loss: 0.0104 - val_accuracy: 0.9946\n","Epoch 23/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0434 - accuracy: 0.9860 - val_loss: 0.0055 - val_accuracy: 0.9987\n","Epoch 24/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0296 - accuracy: 0.9906 - val_loss: 0.0084 - val_accuracy: 0.9973\n","Epoch 25/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0368 - accuracy: 0.9897 - val_loss: 0.0190 - val_accuracy: 0.9933\n","Epoch 26/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0461 - accuracy: 0.9863 - val_loss: 0.0047 - val_accuracy: 0.9973\n","Epoch 27/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0434 - accuracy: 0.9869 - val_loss: 0.0145 - val_accuracy: 0.9933\n","Epoch 28/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0375 - accuracy: 0.9872 - val_loss: 0.0090 - val_accuracy: 0.9987\n","Epoch 29/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0351 - accuracy: 0.9894 - val_loss: 0.0208 - val_accuracy: 0.9893\n","Epoch 30/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0355 - accuracy: 0.9900 - val_loss: 0.0104 - val_accuracy: 0.9960\n","Epoch 31/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0439 - accuracy: 0.9866 - val_loss: 0.0232 - val_accuracy: 0.9906\n","Epoch 32/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0417 - accuracy: 0.9875 - val_loss: 0.0110 - val_accuracy: 0.9973\n","Epoch 33/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0341 - accuracy: 0.9884 - val_loss: 0.0072 - val_accuracy: 0.9973\n","Epoch 34/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0371 - accuracy: 0.9891 - val_loss: 0.0098 - val_accuracy: 0.9960\n","Epoch 35/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0318 - accuracy: 0.9911 - val_loss: 0.0099 - val_accuracy: 0.9987\n","Epoch 36/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0235 - accuracy: 0.9921 - val_loss: 0.0064 - val_accuracy: 0.9987\n","Epoch 37/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0342 - accuracy: 0.9888 - val_loss: 0.0099 - val_accuracy: 0.9960\n","Epoch 38/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0328 - accuracy: 0.9885 - val_loss: 0.0112 - val_accuracy: 0.9973\n","Epoch 39/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0238 - accuracy: 0.9930 - val_loss: 0.0081 - val_accuracy: 0.9960\n","Epoch 40/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0331 - accuracy: 0.9881 - val_loss: 0.0092 - val_accuracy: 0.9960\n","Epoch 41/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0213 - accuracy: 0.9936 - val_loss: 0.0107 - val_accuracy: 0.9946\n","Epoch 42/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0235 - accuracy: 0.9933 - val_loss: 0.0094 - val_accuracy: 0.9960\n","Epoch 43/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0259 - accuracy: 0.9917 - val_loss: 0.0163 - val_accuracy: 0.9960\n","Epoch 44/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0195 - accuracy: 0.9946 - val_loss: 0.0125 - val_accuracy: 0.9960\n","Epoch 45/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0473 - accuracy: 0.9855 - val_loss: 0.0162 - val_accuracy: 0.9960\n","Epoch 46/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0239 - accuracy: 0.9924 - val_loss: 0.0067 - val_accuracy: 0.9960\n","Epoch 47/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0227 - accuracy: 0.9925 - val_loss: 0.0194 - val_accuracy: 0.9946\n","Epoch 48/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0300 - accuracy: 0.9912 - val_loss: 0.0096 - val_accuracy: 0.9973\n","Epoch 49/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0229 - accuracy: 0.9936 - val_loss: 0.0111 - val_accuracy: 0.9973\n","Epoch 50/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.0030 - val_accuracy: 0.9987\n","Results for fold 3\n","Epoch 1/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0323 - accuracy: 0.9896 - val_loss: 5.9298e-05 - val_accuracy: 1.0000\n","Epoch 2/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0295 - accuracy: 0.9928 - val_loss: 1.9820e-05 - val_accuracy: 1.0000\n","Epoch 3/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0238 - accuracy: 0.9920 - val_loss: 4.7183e-04 - val_accuracy: 1.0000\n","Epoch 4/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0232 - accuracy: 0.9917 - val_loss: 5.1252e-04 - val_accuracy: 1.0000\n","Epoch 5/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0320 - accuracy: 0.9906 - val_loss: 1.7767e-04 - val_accuracy: 1.0000\n","Epoch 6/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0220 - accuracy: 0.9931 - val_loss: 3.9475e-05 - val_accuracy: 1.0000\n","Epoch 7/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0227 - accuracy: 0.9923 - val_loss: 1.7658e-04 - val_accuracy: 1.0000\n","Epoch 8/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0226 - accuracy: 0.9924 - val_loss: 4.3141e-05 - val_accuracy: 1.0000\n","Epoch 9/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0236 - accuracy: 0.9920 - val_loss: 9.2884e-05 - val_accuracy: 1.0000\n","Epoch 10/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0280 - accuracy: 0.9912 - val_loss: 1.3126e-04 - val_accuracy: 1.0000\n","Epoch 11/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0149 - accuracy: 0.9955 - val_loss: 1.8594e-05 - val_accuracy: 1.0000\n","Epoch 12/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 3.7531e-05 - val_accuracy: 1.0000\n","Epoch 13/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0231 - accuracy: 0.9930 - val_loss: 0.0018 - val_accuracy: 1.0000\n","Epoch 14/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0310 - accuracy: 0.9906 - val_loss: 6.3461e-05 - val_accuracy: 1.0000\n","Epoch 15/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 3.5878e-05 - val_accuracy: 1.0000\n","Epoch 16/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0241 - accuracy: 0.9920 - val_loss: 4.1945e-05 - val_accuracy: 1.0000\n","Epoch 17/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0224 - accuracy: 0.9931 - val_loss: 9.1693e-04 - val_accuracy: 1.0000\n","Epoch 18/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0206 - accuracy: 0.9931 - val_loss: 2.4732e-04 - val_accuracy: 1.0000\n","Epoch 19/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 5.6256e-05 - val_accuracy: 1.0000\n","Epoch 20/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0202 - accuracy: 0.9942 - val_loss: 1.0082e-04 - val_accuracy: 1.0000\n","Epoch 21/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 7.6607e-05 - val_accuracy: 1.0000\n","Epoch 22/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0206 - accuracy: 0.9945 - val_loss: 5.5570e-05 - val_accuracy: 1.0000\n","Epoch 23/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0173 - accuracy: 0.9951 - val_loss: 2.4451e-05 - val_accuracy: 1.0000\n","Epoch 24/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 1.8506e-04 - val_accuracy: 1.0000\n","Epoch 25/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0252 - accuracy: 0.9923 - val_loss: 1.8181e-04 - val_accuracy: 1.0000\n","Epoch 26/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0192 - accuracy: 0.9925 - val_loss: 6.1046e-04 - val_accuracy: 1.0000\n","Epoch 27/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0107 - accuracy: 0.9961 - val_loss: 2.8687e-05 - val_accuracy: 1.0000\n","Epoch 28/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 1.1442e-04 - val_accuracy: 1.0000\n","Epoch 29/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0127 - accuracy: 0.9967 - val_loss: 4.5433e-05 - val_accuracy: 1.0000\n","Epoch 30/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0159 - accuracy: 0.9957 - val_loss: 1.7613e-04 - val_accuracy: 1.0000\n","Epoch 31/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0195 - accuracy: 0.9949 - val_loss: 8.4703e-05 - val_accuracy: 1.0000\n","Epoch 32/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0105 - accuracy: 0.9973 - val_loss: 4.0008e-05 - val_accuracy: 1.0000\n","Epoch 33/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.0032 - val_accuracy: 0.9987\n","Epoch 34/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0301 - accuracy: 0.9905 - val_loss: 1.8420e-04 - val_accuracy: 1.0000\n","Epoch 35/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0134 - accuracy: 0.9961 - val_loss: 9.9161e-06 - val_accuracy: 1.0000\n","Epoch 36/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0284 - accuracy: 0.9917 - val_loss: 5.1334e-04 - val_accuracy: 1.0000\n","Epoch 37/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0216 - accuracy: 0.9931 - val_loss: 3.0460e-05 - val_accuracy: 1.0000\n","Epoch 38/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0229 - accuracy: 0.9943 - val_loss: 9.2764e-05 - val_accuracy: 1.0000\n","Epoch 39/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 8.6478e-04 - val_accuracy: 1.0000\n","Epoch 40/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0174 - accuracy: 0.9949 - val_loss: 0.0026 - val_accuracy: 1.0000\n","Epoch 41/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0188 - accuracy: 0.9948 - val_loss: 3.6452e-04 - val_accuracy: 1.0000\n","Epoch 42/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 1.0809e-04 - val_accuracy: 1.0000\n","Epoch 43/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.0012 - val_accuracy: 0.9987\n","Epoch 44/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0236 - accuracy: 0.9928 - val_loss: 0.0086 - val_accuracy: 0.9946\n","Epoch 45/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0117 - accuracy: 0.9970 - val_loss: 1.1514e-04 - val_accuracy: 1.0000\n","Epoch 46/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0156 - accuracy: 0.9957 - val_loss: 6.4616e-05 - val_accuracy: 1.0000\n","Epoch 47/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0235 - accuracy: 0.9917 - val_loss: 4.9473e-04 - val_accuracy: 1.0000\n","Epoch 48/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 1.4556e-04 - val_accuracy: 1.0000\n","Epoch 49/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0209 - accuracy: 0.9936 - val_loss: 0.0032 - val_accuracy: 0.9973\n","Epoch 50/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0152 - accuracy: 0.9943 - val_loss: 3.0555e-04 - val_accuracy: 1.0000\n","Results for fold 4\n","Epoch 1/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0210 - accuracy: 0.9943 - val_loss: 1.0407e-05 - val_accuracy: 1.0000\n","Epoch 2/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0198 - accuracy: 0.9937 - val_loss: 5.1296e-05 - val_accuracy: 1.0000\n","Epoch 3/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0228 - accuracy: 0.9930 - val_loss: 2.8396e-05 - val_accuracy: 1.0000\n","Epoch 4/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 2.5695e-06 - val_accuracy: 1.0000\n","Epoch 5/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 3.7825e-06 - val_accuracy: 1.0000\n","Epoch 6/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0116 - accuracy: 0.9967 - val_loss: 1.3372e-04 - val_accuracy: 1.0000\n","Epoch 7/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0178 - accuracy: 0.9943 - val_loss: 7.0993e-06 - val_accuracy: 1.0000\n","Epoch 8/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 3.8617e-05 - val_accuracy: 1.0000\n","Epoch 9/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 7.4477e-07 - val_accuracy: 1.0000\n","Epoch 10/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0169 - accuracy: 0.9955 - val_loss: 0.0016 - val_accuracy: 0.9987\n","Epoch 11/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0258 - accuracy: 0.9921 - val_loss: 1.1617e-04 - val_accuracy: 1.0000\n","Epoch 12/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0144 - accuracy: 0.9948 - val_loss: 2.8999e-04 - val_accuracy: 1.0000\n","Epoch 13/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0196 - accuracy: 0.9949 - val_loss: 2.5936e-04 - val_accuracy: 1.0000\n","Epoch 14/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0156 - accuracy: 0.9957 - val_loss: 5.5762e-05 - val_accuracy: 1.0000\n","Epoch 15/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 6.7773e-05 - val_accuracy: 1.0000\n","Epoch 16/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 1.2014e-04 - val_accuracy: 1.0000\n","Epoch 17/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0244 - accuracy: 0.9924 - val_loss: 9.5089e-05 - val_accuracy: 1.0000\n","Epoch 18/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0168 - accuracy: 0.9939 - val_loss: 5.9675e-06 - val_accuracy: 1.0000\n","Epoch 19/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 1.5123e-06 - val_accuracy: 1.0000\n","Epoch 20/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0106 - accuracy: 0.9973 - val_loss: 2.7364e-06 - val_accuracy: 1.0000\n","Epoch 21/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0167 - accuracy: 0.9946 - val_loss: 8.0623e-05 - val_accuracy: 1.0000\n","Epoch 22/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0214 - accuracy: 0.9940 - val_loss: 1.4372e-05 - val_accuracy: 1.0000\n","Epoch 23/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0254 - accuracy: 0.9925 - val_loss: 5.4449e-04 - val_accuracy: 1.0000\n","Epoch 24/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 1.4783e-04 - val_accuracy: 1.0000\n","Epoch 25/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0102 - accuracy: 0.9972 - val_loss: 2.9312e-06 - val_accuracy: 1.0000\n","Epoch 26/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0166 - accuracy: 0.9949 - val_loss: 2.5352e-04 - val_accuracy: 1.0000\n","Epoch 27/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 2.2222e-04 - val_accuracy: 1.0000\n","Epoch 28/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0085 - accuracy: 0.9975 - val_loss: 7.7993e-06 - val_accuracy: 1.0000\n","Epoch 29/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0146 - accuracy: 0.9964 - val_loss: 3.2253e-04 - val_accuracy: 1.0000\n","Epoch 30/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 6.2152e-05 - val_accuracy: 1.0000\n","Epoch 31/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0161 - accuracy: 0.9954 - val_loss: 4.1760e-04 - val_accuracy: 1.0000\n","Epoch 32/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0104 - accuracy: 0.9960 - val_loss: 1.4799e-04 - val_accuracy: 1.0000\n","Epoch 33/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 8.5663e-06 - val_accuracy: 1.0000\n","Epoch 34/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 1.5613e-05 - val_accuracy: 1.0000\n","Epoch 35/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0210 - accuracy: 0.9927 - val_loss: 1.7156e-04 - val_accuracy: 1.0000\n","Epoch 36/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 1.4744e-04 - val_accuracy: 1.0000\n","Epoch 37/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0141 - accuracy: 0.9960 - val_loss: 2.2680e-04 - val_accuracy: 1.0000\n","Epoch 38/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0115 - accuracy: 0.9960 - val_loss: 2.4935e-05 - val_accuracy: 1.0000\n","Epoch 39/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0178 - accuracy: 0.9943 - val_loss: 1.9283e-05 - val_accuracy: 1.0000\n","Epoch 40/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0128 - accuracy: 0.9967 - val_loss: 7.7839e-06 - val_accuracy: 1.0000\n","Epoch 41/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.0029 - val_accuracy: 0.9987\n","Epoch 42/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 1.7880e-04 - val_accuracy: 1.0000\n","Epoch 43/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 2.0472e-06 - val_accuracy: 1.0000\n","Epoch 44/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0051 - accuracy: 0.9978 - val_loss: 5.0079e-06 - val_accuracy: 1.0000\n","Epoch 45/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 2.3477e-05 - val_accuracy: 1.0000\n","Epoch 46/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0058 - accuracy: 0.9978 - val_loss: 1.9823e-06 - val_accuracy: 1.0000\n","Epoch 47/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 5.0927e-05 - val_accuracy: 1.0000\n","Epoch 48/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0155 - accuracy: 0.9954 - val_loss: 3.4527e-04 - val_accuracy: 1.0000\n","Epoch 49/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 3.1072e-04 - val_accuracy: 1.0000\n","Epoch 50/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0263 - accuracy: 0.9937 - val_loss: 0.0021 - val_accuracy: 1.0000\n","Results for fold 5\n","Epoch 1/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0193 - accuracy: 0.9933 - val_loss: 2.8849e-06 - val_accuracy: 1.0000\n","Epoch 2/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0187 - accuracy: 0.9948 - val_loss: 3.9047e-06 - val_accuracy: 1.0000\n","Epoch 3/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 2.0119e-05 - val_accuracy: 1.0000\n","Epoch 4/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 6.7879e-07 - val_accuracy: 1.0000\n","Epoch 5/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 7.2736e-06 - val_accuracy: 1.0000\n","Epoch 6/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0170 - accuracy: 0.9948 - val_loss: 1.9215e-06 - val_accuracy: 1.0000\n","Epoch 7/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0067 - accuracy: 0.9972 - val_loss: 6.2907e-06 - val_accuracy: 1.0000\n","Epoch 8/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 5.7684e-07 - val_accuracy: 1.0000\n","Epoch 9/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 1.7219e-05 - val_accuracy: 1.0000\n","Epoch 10/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0126 - accuracy: 0.9955 - val_loss: 1.9743e-06 - val_accuracy: 1.0000\n","Epoch 11/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0190 - accuracy: 0.9948 - val_loss: 2.2893e-06 - val_accuracy: 1.0000\n","Epoch 12/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0191 - accuracy: 0.9946 - val_loss: 1.6005e-06 - val_accuracy: 1.0000\n","Epoch 13/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0166 - accuracy: 0.9948 - val_loss: 6.4718e-06 - val_accuracy: 1.0000\n","Epoch 14/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0076 - accuracy: 0.9972 - val_loss: 6.9293e-06 - val_accuracy: 1.0000\n","Epoch 15/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 5.8406e-06 - val_accuracy: 1.0000\n","Epoch 16/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 2.6047e-08 - val_accuracy: 1.0000\n","Epoch 17/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 1.4718e-06 - val_accuracy: 1.0000\n","Epoch 18/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0093 - accuracy: 0.9973 - val_loss: 1.4980e-06 - val_accuracy: 1.0000\n","Epoch 19/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 1.7341e-06 - val_accuracy: 1.0000\n","Epoch 20/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0068 - accuracy: 0.9973 - val_loss: 1.5763e-06 - val_accuracy: 1.0000\n","Epoch 21/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0080 - accuracy: 0.9967 - val_loss: 6.6949e-06 - val_accuracy: 1.0000\n","Epoch 22/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 4.3349e-06 - val_accuracy: 1.0000\n","Epoch 23/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 1.0015e-04 - val_accuracy: 1.0000\n","Epoch 24/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 5.5665e-07 - val_accuracy: 1.0000\n","Epoch 25/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 1.0170e-06 - val_accuracy: 1.0000\n","Epoch 26/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 7.4431e-07 - val_accuracy: 1.0000\n","Epoch 27/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 3.5859e-06 - val_accuracy: 1.0000\n","Epoch 28/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 3.5725e-06 - val_accuracy: 1.0000\n","Epoch 29/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 3.1448e-07 - val_accuracy: 1.0000\n","Epoch 30/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 2.2398e-06 - val_accuracy: 1.0000\n","Epoch 31/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 2.5526e-04 - val_accuracy: 1.0000\n","Epoch 32/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0105 - accuracy: 0.9964 - val_loss: 5.9440e-06 - val_accuracy: 1.0000\n","Epoch 33/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 2.1517e-04 - val_accuracy: 1.0000\n","Epoch 34/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0177 - accuracy: 0.9946 - val_loss: 0.0086 - val_accuracy: 0.9987\n","Epoch 35/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0199 - accuracy: 0.9955 - val_loss: 1.9878e-05 - val_accuracy: 1.0000\n","Epoch 36/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0064 - accuracy: 0.9975 - val_loss: 3.0840e-05 - val_accuracy: 1.0000\n","Epoch 37/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 5.4234e-05 - val_accuracy: 1.0000\n","Epoch 38/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0209 - accuracy: 0.9940 - val_loss: 5.6361e-05 - val_accuracy: 1.0000\n","Epoch 39/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 5.7712e-05 - val_accuracy: 1.0000\n","Epoch 40/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 3.0306e-04 - val_accuracy: 1.0000\n","Epoch 41/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 9.2380e-06 - val_accuracy: 1.0000\n","Epoch 42/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 4.2383e-05 - val_accuracy: 1.0000\n","Epoch 43/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 4.3056e-05 - val_accuracy: 1.0000\n","Epoch 44/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 2.7493e-05 - val_accuracy: 1.0000\n","Epoch 45/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 7.5214e-05 - val_accuracy: 1.0000\n","Epoch 46/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 1.0504e-04 - val_accuracy: 1.0000\n","Epoch 47/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 1.1440e-04 - val_accuracy: 1.0000\n","Epoch 48/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 3.2000e-05 - val_accuracy: 1.0000\n","Epoch 49/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0069 - accuracy: 0.9970 - val_loss: 2.6042e-04 - val_accuracy: 1.0000\n","Epoch 50/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0131 - accuracy: 0.9955 - val_loss: 4.7628e-05 - val_accuracy: 1.0000\n","Results for fold 6\n","Epoch 1/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 3.2949e-06 - val_accuracy: 1.0000\n","Epoch 2/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 4.2730e-06 - val_accuracy: 1.0000\n","Epoch 3/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0094 - accuracy: 0.9966 - val_loss: 7.8504e-07 - val_accuracy: 1.0000\n","Epoch 4/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0041 - accuracy: 0.9981 - val_loss: 2.4129e-08 - val_accuracy: 1.0000\n","Epoch 5/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 1.5126e-04 - val_accuracy: 1.0000\n","Epoch 6/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0163 - accuracy: 0.9948 - val_loss: 2.9216e-05 - val_accuracy: 1.0000\n","Epoch 7/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 1.0907e-06 - val_accuracy: 1.0000\n","Epoch 8/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0052 - accuracy: 0.9981 - val_loss: 5.8671e-07 - val_accuracy: 1.0000\n","Epoch 9/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0183 - accuracy: 0.9951 - val_loss: 6.4116e-06 - val_accuracy: 1.0000\n","Epoch 10/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 1.8651e-05 - val_accuracy: 1.0000\n","Epoch 11/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0112 - accuracy: 0.9975 - val_loss: 2.8898e-06 - val_accuracy: 1.0000\n","Epoch 12/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 6.6685e-06 - val_accuracy: 1.0000\n","Epoch 13/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 8.1516e-05 - val_accuracy: 1.0000\n","Epoch 14/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 2.4081e-07 - val_accuracy: 1.0000\n","Epoch 15/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 2.7037e-06 - val_accuracy: 1.0000\n","Epoch 16/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 3.8351e-07 - val_accuracy: 1.0000\n","Epoch 17/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0123 - accuracy: 0.9966 - val_loss: 9.6814e-05 - val_accuracy: 1.0000\n","Epoch 18/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 4.4615e-07 - val_accuracy: 1.0000\n","Epoch 19/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0033 - accuracy: 0.9985 - val_loss: 5.3053e-08 - val_accuracy: 1.0000\n","Epoch 20/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 8.9463e-07 - val_accuracy: 1.0000\n","Epoch 21/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0164 - accuracy: 0.9961 - val_loss: 1.0929e-04 - val_accuracy: 1.0000\n","Epoch 22/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 2.0714e-06 - val_accuracy: 1.0000\n","Epoch 23/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 4.3583e-05 - val_accuracy: 1.0000\n","Epoch 24/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0067 - accuracy: 0.9972 - val_loss: 2.4043e-05 - val_accuracy: 1.0000\n","Epoch 25/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 1.8749e-05 - val_accuracy: 1.0000\n","Epoch 26/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0074 - accuracy: 0.9970 - val_loss: 1.8046e-05 - val_accuracy: 1.0000\n","Epoch 27/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.0037 - val_accuracy: 0.9987\n","Epoch 28/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0094 - accuracy: 0.9978 - val_loss: 1.0562e-05 - val_accuracy: 1.0000\n","Epoch 29/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 2.0961e-04 - val_accuracy: 1.0000\n","Epoch 30/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0061 - accuracy: 0.9978 - val_loss: 1.6293e-06 - val_accuracy: 1.0000\n","Epoch 31/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 2.3659e-06 - val_accuracy: 1.0000\n","Epoch 32/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 5.9003e-06 - val_accuracy: 1.0000\n","Epoch 33/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 3.0372e-06 - val_accuracy: 1.0000\n","Epoch 34/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 1.4649e-05 - val_accuracy: 1.0000\n","Epoch 35/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0081 - accuracy: 0.9970 - val_loss: 5.7255e-06 - val_accuracy: 1.0000\n","Epoch 36/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 2.7073e-05 - val_accuracy: 1.0000\n","Epoch 37/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0224 - accuracy: 0.9924 - val_loss: 3.5017e-04 - val_accuracy: 1.0000\n","Epoch 38/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 8.3377e-06 - val_accuracy: 1.0000\n","Epoch 39/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 2.1110e-06 - val_accuracy: 1.0000\n","Epoch 40/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 1.5862e-05 - val_accuracy: 1.0000\n","Epoch 41/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 5.0223e-06 - val_accuracy: 1.0000\n","Epoch 42/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.0067 - val_accuracy: 0.9987\n","Epoch 43/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0194 - accuracy: 0.9951 - val_loss: 1.1430e-05 - val_accuracy: 1.0000\n","Epoch 44/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 6.9249e-05 - val_accuracy: 1.0000\n","Epoch 45/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 2.5758e-05 - val_accuracy: 1.0000\n","Epoch 46/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 5.8249e-05 - val_accuracy: 1.0000\n","Epoch 47/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 3.9025e-04 - val_accuracy: 1.0000\n","Epoch 48/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 6.2334e-07 - val_accuracy: 1.0000\n","Epoch 49/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 8.4361e-06 - val_accuracy: 1.0000\n","Epoch 50/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0146 - accuracy: 0.9960 - val_loss: 0.0011 - val_accuracy: 1.0000\n","Results for fold 7\n","Epoch 1/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0156 - accuracy: 0.9963 - val_loss: 2.5002e-04 - val_accuracy: 1.0000\n","Epoch 2/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 8.9828e-06 - val_accuracy: 1.0000\n","Epoch 3/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 3.7345e-06 - val_accuracy: 1.0000\n","Epoch 4/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 3.2073e-06 - val_accuracy: 1.0000\n","Epoch 5/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 2.6434e-07 - val_accuracy: 1.0000\n","Epoch 6/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0055 - accuracy: 0.9978 - val_loss: 1.7571e-06 - val_accuracy: 1.0000\n","Epoch 7/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 3.6006e-05 - val_accuracy: 1.0000\n","Epoch 8/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 8.2612e-05 - val_accuracy: 1.0000\n","Epoch 9/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 5.5091e-07 - val_accuracy: 1.0000\n","Epoch 10/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 3.6657e-06 - val_accuracy: 1.0000\n","Epoch 11/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 8.2049e-07 - val_accuracy: 1.0000\n","Epoch 12/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0102 - accuracy: 0.9978 - val_loss: 3.3645e-04 - val_accuracy: 1.0000\n","Epoch 13/50\n","53/53 [==============================] - 2s 41ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 1.3166e-05 - val_accuracy: 1.0000\n","Epoch 14/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 2.0577e-07 - val_accuracy: 1.0000\n","Epoch 15/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 1.5854e-04 - val_accuracy: 1.0000\n","Epoch 16/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 1.6161e-08 - val_accuracy: 1.0000\n","Epoch 17/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0134 - accuracy: 0.9967 - val_loss: 5.5630e-05 - val_accuracy: 1.0000\n","Epoch 18/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 2.1329e-07 - val_accuracy: 1.0000\n","Epoch 19/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0081 - accuracy: 0.9970 - val_loss: 2.2575e-06 - val_accuracy: 1.0000\n","Epoch 20/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0082 - accuracy: 0.9969 - val_loss: 2.3318e-06 - val_accuracy: 1.0000\n","Epoch 21/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 2.6805e-05 - val_accuracy: 1.0000\n","Epoch 22/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 2.4792e-06 - val_accuracy: 1.0000\n","Epoch 23/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 7.0323e-07 - val_accuracy: 1.0000\n","Epoch 24/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 1.9528e-06 - val_accuracy: 1.0000\n","Epoch 25/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 5.5720e-06 - val_accuracy: 1.0000\n","Epoch 26/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 9.7286e-08 - val_accuracy: 1.0000\n","Epoch 27/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 1.3729e-07 - val_accuracy: 1.0000\n","Epoch 28/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 8.8007e-09 - val_accuracy: 1.0000\n","Epoch 29/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 1.6001e-09 - val_accuracy: 1.0000\n","Epoch 30/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 1.9937e-07 - val_accuracy: 1.0000\n","Epoch 31/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 1.4129e-06 - val_accuracy: 1.0000\n","Epoch 32/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0221 - accuracy: 0.9942 - val_loss: 1.4587e-04 - val_accuracy: 1.0000\n","Epoch 33/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 1.4556e-05 - val_accuracy: 1.0000\n","Epoch 34/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0110 - accuracy: 0.9973 - val_loss: 4.0947e-05 - val_accuracy: 1.0000\n","Epoch 35/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 1.3215e-06 - val_accuracy: 1.0000\n","Epoch 36/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 1.4113e-07 - val_accuracy: 1.0000\n","Epoch 37/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 9.8851e-07 - val_accuracy: 1.0000\n","Epoch 38/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 1.2145e-07 - val_accuracy: 1.0000\n","Epoch 39/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 6.4320e-06 - val_accuracy: 1.0000\n","Epoch 40/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0144 - accuracy: 0.9961 - val_loss: 5.6412e-05 - val_accuracy: 1.0000\n","Epoch 41/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 1.2184e-06 - val_accuracy: 1.0000\n","Epoch 42/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 1.1254e-06 - val_accuracy: 1.0000\n","Epoch 43/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0084 - accuracy: 0.9969 - val_loss: 1.2241e-06 - val_accuracy: 1.0000\n","Epoch 44/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 7.6604e-06 - val_accuracy: 1.0000\n","Epoch 45/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 7.3731e-06 - val_accuracy: 1.0000\n","Epoch 46/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 1.4884e-06 - val_accuracy: 1.0000\n","Epoch 47/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 1.2493e-06 - val_accuracy: 1.0000\n","Epoch 48/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 1.2996e-06 - val_accuracy: 1.0000\n","Epoch 49/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 1.8123e-05 - val_accuracy: 1.0000\n","Epoch 50/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 9.5632e-07 - val_accuracy: 1.0000\n","Results for fold 8\n","Epoch 1/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0101 - accuracy: 0.9975 - val_loss: 1.1841e-07 - val_accuracy: 1.0000\n","Epoch 2/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 1.0817e-06 - val_accuracy: 1.0000\n","Epoch 3/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 2.0786e-06 - val_accuracy: 1.0000\n","Epoch 4/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0107 - accuracy: 0.9961 - val_loss: 2.0498e-06 - val_accuracy: 1.0000\n","Epoch 5/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 8.8413e-06 - val_accuracy: 1.0000\n","Epoch 6/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 2.4066e-07 - val_accuracy: 1.0000\n","Epoch 7/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 1.2289e-07 - val_accuracy: 1.0000\n","Epoch 8/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 1.5793e-07 - val_accuracy: 1.0000\n","Epoch 9/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 2.6881e-07 - val_accuracy: 1.0000\n","Epoch 10/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0110 - accuracy: 0.9972 - val_loss: 2.0914e-07 - val_accuracy: 1.0000\n","Epoch 11/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 2.0849e-07 - val_accuracy: 1.0000\n","Epoch 12/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 6.2847e-06 - val_accuracy: 1.0000\n","Epoch 13/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0161 - accuracy: 0.9948 - val_loss: 6.3602e-06 - val_accuracy: 1.0000\n","Epoch 14/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0075 - accuracy: 0.9970 - val_loss: 3.0178e-07 - val_accuracy: 1.0000\n","Epoch 15/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0041 - accuracy: 0.9984 - val_loss: 3.8403e-08 - val_accuracy: 1.0000\n","Epoch 16/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 1.5489e-07 - val_accuracy: 1.0000\n","Epoch 17/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 3.8111e-05 - val_accuracy: 1.0000\n","Epoch 18/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0057 - accuracy: 0.9976 - val_loss: 5.3875e-07 - val_accuracy: 1.0000\n","Epoch 19/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0040 - accuracy: 0.9985 - val_loss: 4.9027e-07 - val_accuracy: 1.0000\n","Epoch 20/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 5.7604e-08 - val_accuracy: 1.0000\n","Epoch 21/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 5.6804e-08 - val_accuracy: 1.0000\n","Epoch 22/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0091 - accuracy: 0.9979 - val_loss: 2.9794e-07 - val_accuracy: 1.0000\n","Epoch 23/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0054 - accuracy: 0.9978 - val_loss: 3.8578e-07 - val_accuracy: 1.0000\n","Epoch 24/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0091 - accuracy: 0.9978 - val_loss: 1.2817e-07 - val_accuracy: 1.0000\n","Epoch 25/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 4.7844e-08 - val_accuracy: 1.0000\n","Epoch 26/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 1.4491e-06 - val_accuracy: 1.0000\n","Epoch 27/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 3.2274e-07 - val_accuracy: 1.0000\n","Epoch 28/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0130 - accuracy: 0.9967 - val_loss: 9.6708e-06 - val_accuracy: 1.0000\n","Epoch 29/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0081 - accuracy: 0.9967 - val_loss: 8.0006e-08 - val_accuracy: 1.0000\n","Epoch 30/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 1.3441e-07 - val_accuracy: 1.0000\n","Epoch 31/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 1.0875e-05 - val_accuracy: 1.0000\n","Epoch 32/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 3.0208e-07 - val_accuracy: 1.0000\n","Epoch 33/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 8.4006e-08 - val_accuracy: 1.0000\n","Epoch 34/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 3.3140e-06 - val_accuracy: 1.0000\n","Epoch 35/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0083 - accuracy: 0.9978 - val_loss: 2.1031e-06 - val_accuracy: 1.0000\n","Epoch 36/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 6.6257e-07 - val_accuracy: 1.0000\n","Epoch 37/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 2.3056e-04 - val_accuracy: 1.0000\n","Epoch 38/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 1.8143e-06 - val_accuracy: 1.0000\n","Epoch 39/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 3.0671e-07 - val_accuracy: 1.0000\n","Epoch 40/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0026 - accuracy: 0.9985 - val_loss: 1.4321e-07 - val_accuracy: 1.0000\n","Epoch 41/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 1.3457e-07 - val_accuracy: 1.0000\n","Epoch 42/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 1.0598e-06 - val_accuracy: 1.0000\n","Epoch 43/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0118 - accuracy: 0.9967 - val_loss: 1.4672e-06 - val_accuracy: 1.0000\n","Epoch 44/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 3.4596e-06 - val_accuracy: 1.0000\n","Epoch 45/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 5.0411e-06 - val_accuracy: 1.0000\n","Epoch 46/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0049 - accuracy: 0.9981 - val_loss: 5.5204e-08 - val_accuracy: 1.0000\n","Epoch 47/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0092 - accuracy: 0.9978 - val_loss: 4.1762e-07 - val_accuracy: 1.0000\n","Epoch 48/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 1.5889e-07 - val_accuracy: 1.0000\n","Epoch 49/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 8.1687e-07 - val_accuracy: 1.0000\n","Epoch 50/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 3.3890e-07 - val_accuracy: 1.0000\n","Results for fold 9\n","Epoch 1/50\n","53/53 [==============================] - 2s 46ms/step - loss: 0.0038 - accuracy: 0.9985 - val_loss: 2.1822e-06 - val_accuracy: 1.0000\n","Epoch 2/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 3.0447e-07 - val_accuracy: 1.0000\n","Epoch 3/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 1.9729e-07 - val_accuracy: 1.0000\n","Epoch 4/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 7.4231e-06 - val_accuracy: 1.0000\n","Epoch 5/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0107 - accuracy: 0.9979 - val_loss: 6.6245e-08 - val_accuracy: 1.0000\n","Epoch 6/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 1.0531e-06 - val_accuracy: 1.0000\n","Epoch 7/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 3.5203e-08 - val_accuracy: 1.0000\n","Epoch 8/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0050 - accuracy: 0.9979 - val_loss: 7.7419e-07 - val_accuracy: 1.0000\n","Epoch 9/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 5.9553e-06 - val_accuracy: 1.0000\n","Epoch 10/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 1.4817e-07 - val_accuracy: 1.0000\n","Epoch 11/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0117 - accuracy: 0.9966 - val_loss: 2.6226e-07 - val_accuracy: 1.0000\n","Epoch 12/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 7.5171e-07 - val_accuracy: 1.0000\n","Epoch 13/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 2.8002e-08 - val_accuracy: 1.0000\n","Epoch 14/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 1.6353e-07 - val_accuracy: 1.0000\n","Epoch 15/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 1.3441e-08 - val_accuracy: 1.0000\n","Epoch 16/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0085 - accuracy: 0.9981 - val_loss: 5.9525e-08 - val_accuracy: 1.0000\n","Epoch 17/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 4.8484e-08 - val_accuracy: 1.0000\n","Epoch 18/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 3.4083e-08 - val_accuracy: 1.0000\n","Epoch 19/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 4.0737e-07 - val_accuracy: 1.0000\n","Epoch 20/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 8.5926e-08 - val_accuracy: 1.0000\n","Epoch 21/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 2.8802e-09 - val_accuracy: 1.0000\n","Epoch 22/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 3.1362e-08 - val_accuracy: 1.0000\n","Epoch 23/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 2.2242e-08 - val_accuracy: 1.0000\n","Epoch 24/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0130 - accuracy: 0.9967 - val_loss: 2.5379e-05 - val_accuracy: 1.0000\n","Epoch 25/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0073 - accuracy: 0.9972 - val_loss: 9.3127e-08 - val_accuracy: 1.0000\n","Epoch 26/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 2.4658e-07 - val_accuracy: 1.0000\n","Epoch 27/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 1.8401e-08 - val_accuracy: 1.0000\n","Epoch 28/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 2.0033e-07 - val_accuracy: 1.0000\n","Epoch 29/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0095 - accuracy: 0.9978 - val_loss: 1.2433e-07 - val_accuracy: 1.0000\n","Epoch 30/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 5.7777e-07 - val_accuracy: 1.0000\n","Epoch 31/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0070 - accuracy: 0.9975 - val_loss: 1.2816e-06 - val_accuracy: 1.0000\n","Epoch 32/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 2.9415e-05 - val_accuracy: 1.0000\n","Epoch 33/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 1.9793e-07 - val_accuracy: 1.0000\n","Epoch 34/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0096 - accuracy: 0.9979 - val_loss: 2.0769e-07 - val_accuracy: 1.0000\n","Epoch 35/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0041 - accuracy: 0.9984 - val_loss: 7.5355e-07 - val_accuracy: 1.0000\n","Epoch 36/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 1.0001e-07 - val_accuracy: 1.0000\n","Epoch 37/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 1.1663e-06 - val_accuracy: 1.0000\n","Epoch 38/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 2.4289e-07 - val_accuracy: 1.0000\n","Epoch 39/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 4.7364e-08 - val_accuracy: 1.0000\n","Epoch 40/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 3.7249e-07 - val_accuracy: 1.0000\n","Epoch 41/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 7.7285e-08 - val_accuracy: 1.0000\n","Epoch 42/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0044 - accuracy: 0.9993 - val_loss: 1.3188e-06 - val_accuracy: 1.0000\n","Epoch 43/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0069 - accuracy: 0.9987 - val_loss: 3.8403e-08 - val_accuracy: 1.0000\n","Epoch 44/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 1.9457e-07 - val_accuracy: 1.0000\n","Epoch 45/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 1.0983e-06 - val_accuracy: 1.0000\n","Epoch 46/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0103 - accuracy: 0.9981 - val_loss: 2.2873e-06 - val_accuracy: 1.0000\n","Epoch 47/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0098 - accuracy: 0.9978 - val_loss: 1.9217e-06 - val_accuracy: 1.0000\n","Epoch 48/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 1.2649e-06 - val_accuracy: 1.0000\n","Epoch 49/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 2.5765e-06 - val_accuracy: 1.0000\n","Epoch 50/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 8.4135e-06 - val_accuracy: 1.0000\n","Results for fold 10\n","Epoch 1/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 4.5283e-08 - val_accuracy: 1.0000\n","Epoch 2/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 1.2465e-05 - val_accuracy: 1.0000\n","Epoch 3/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0117 - accuracy: 0.9973 - val_loss: 1.3019e-06 - val_accuracy: 1.0000\n","Epoch 4/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 1.5364e-06 - val_accuracy: 1.0000\n","Epoch 5/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 1.0321e-07 - val_accuracy: 1.0000\n","Epoch 6/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 9.1366e-08 - val_accuracy: 1.0000\n","Epoch 7/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 5.3124e-08 - val_accuracy: 1.0000\n","Epoch 8/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 9.4407e-09 - val_accuracy: 1.0000\n","Epoch 9/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0013 - accuracy: 0.9993 - val_loss: 8.1124e-08 - val_accuracy: 1.0000\n","Epoch 10/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 1.3441e-08 - val_accuracy: 1.0000\n","Epoch 11/50\n","53/53 [==============================] - 2s 45ms/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 3.0722e-08 - val_accuracy: 1.0000\n","Epoch 12/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0055 - accuracy: 0.9990 - val_loss: 5.0051e-06 - val_accuracy: 1.0000\n","Epoch 13/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 1.0561e-08 - val_accuracy: 1.0000\n","Epoch 14/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0093 - accuracy: 0.9975 - val_loss: 1.4129e-06 - val_accuracy: 1.0000\n","Epoch 15/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 1.5673e-04 - val_accuracy: 1.0000\n","Epoch 16/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 2.5169e-07 - val_accuracy: 1.0000\n","Epoch 17/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 1.3649e-07 - val_accuracy: 1.0000\n","Epoch 18/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 2.5602e-08 - val_accuracy: 1.0000\n","Epoch 19/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 2.0322e-08 - val_accuracy: 1.0000\n","Epoch 20/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 3.5043e-08 - val_accuracy: 1.0000\n","Epoch 21/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 1.4448e-07 - val_accuracy: 1.0000\n","Epoch 22/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 1.3121e-08 - val_accuracy: 1.0000\n","Epoch 23/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 8.4807e-09 - val_accuracy: 1.0000\n","Epoch 24/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 1.7601e-09 - val_accuracy: 1.0000\n","Epoch 25/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 7.6805e-08 - val_accuracy: 1.0000\n","Epoch 26/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 1.1995e-05 - val_accuracy: 1.0000\n","Epoch 27/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 1.6193e-07 - val_accuracy: 1.0000\n","Epoch 28/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 5.8723e-08 - val_accuracy: 1.0000\n","Epoch 29/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 2.7202e-09 - val_accuracy: 1.0000\n","Epoch 30/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 5.8817e-05 - val_accuracy: 1.0000\n","Epoch 31/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 3.7201e-07 - val_accuracy: 1.0000\n","Epoch 32/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 8.1765e-08 - val_accuracy: 1.0000\n","Epoch 33/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 3.5170e-07 - val_accuracy: 1.0000\n","Epoch 34/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 2.7377e-07 - val_accuracy: 1.0000\n","Epoch 35/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 2.7842e-08 - val_accuracy: 1.0000\n","Epoch 36/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 5.7233e-06 - val_accuracy: 1.0000\n","Epoch 37/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 2.2874e-06 - val_accuracy: 1.0000\n","Epoch 38/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 1.7745e-07 - val_accuracy: 1.0000\n","Epoch 39/50\n","53/53 [==============================] - 2s 44ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 6.5604e-08 - val_accuracy: 1.0000\n","Epoch 40/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 6.9481e-06 - val_accuracy: 1.0000\n","Epoch 41/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0038 - accuracy: 0.9985 - val_loss: 1.2997e-06 - val_accuracy: 1.0000\n","Epoch 42/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 1.4716e-04 - val_accuracy: 1.0000\n","Epoch 43/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 5.5551e-07 - val_accuracy: 1.0000\n","Epoch 44/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 6.5605e-09 - val_accuracy: 1.0000\n","Epoch 45/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 2.0833e-07 - val_accuracy: 1.0000\n","Epoch 46/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0121 - accuracy: 0.9972 - val_loss: 1.4896e-06 - val_accuracy: 1.0000\n","Epoch 47/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 4.6753e-06 - val_accuracy: 1.0000\n","Epoch 48/50\n","53/53 [==============================] - 2s 43ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 5.6174e-06 - val_accuracy: 1.0000\n","Epoch 49/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 6.2404e-08 - val_accuracy: 1.0000\n","Epoch 50/50\n","53/53 [==============================] - 2s 42ms/step - loss: 0.0050 - accuracy: 0.9979 - val_loss: 2.3751e-06 - val_accuracy: 1.0000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9_olzDVBZS7u","colab":{"base_uri":"https://localhost:8080/","height":722},"outputId":"18917cba-70eb-41ab-9968-218b22464b93"},"source":["acrc = model.evaluate(x_test, y_test)\n","pred = model.predict(x_test)\n","f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n","c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n","print(\"Accuracy  : {}\".format(acrc[1]))\n","print(\"F1_Score  : {}\".format(f1scr))\n","c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n","import seaborn as sns\n","figure = plt.figure(figsize=(9, 9))\n","sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n","plt.tight_layout()\n","plt.ylabel('True label')\n","plt.xlabel('Predicted label')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["59/59 [==============================] - 0s 8ms/step - loss: 0.0034 - accuracy: 0.9984\n","Accuracy  : 0.9983905553817749\n","F1_Score  : 0.9987261141904896\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 648x648 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}