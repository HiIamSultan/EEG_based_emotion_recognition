{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub10_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "4ef10d81-4196-4597-d848-9941de4fb311"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e3\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  #EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "293fa804-7378-4071-da61-83ce1513f9f6"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(10,11):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.10\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (3029,) (3495,) (2796,)\n",
            "(9320,) (2796,) (3728,) (2796,)\n",
            "(9320,) (2330,) (3728,) (3262,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "f38b72ac-688d-4af4-81b7-8c4c05052837"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "1532f40f-f44d-47f6-e3f4-206d3fcf2e15"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "622"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "9339c070-9f94-4a73-f809-86efa7f09ccd"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7299a8f-699b-441c-95c3-ce512d4f1811"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 23s 63ms/step - loss: 1.1972 - accuracy: 0.3587 - val_loss: 1.0947 - val_accuracy: 0.3820\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0936 - accuracy: 0.3790 - val_loss: 1.0876 - val_accuracy: 0.3874\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0902 - accuracy: 0.3776 - val_loss: 1.0771 - val_accuracy: 0.3981\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0806 - accuracy: 0.3976 - val_loss: 1.0717 - val_accuracy: 0.4021\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0797 - accuracy: 0.3943 - val_loss: 1.0722 - val_accuracy: 0.4048\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0658 - accuracy: 0.4065 - val_loss: 1.0802 - val_accuracy: 0.4008\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0638 - accuracy: 0.4018 - val_loss: 1.0743 - val_accuracy: 0.4008\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0462 - accuracy: 0.4165 - val_loss: 1.0669 - val_accuracy: 0.4182\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0650 - accuracy: 0.4161 - val_loss: 1.0633 - val_accuracy: 0.4182\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0433 - accuracy: 0.4229 - val_loss: 1.0441 - val_accuracy: 0.4330\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0372 - accuracy: 0.4340 - val_loss: 1.0316 - val_accuracy: 0.4437\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0467 - accuracy: 0.4287 - val_loss: 1.0281 - val_accuracy: 0.4424\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0327 - accuracy: 0.4318 - val_loss: 1.0448 - val_accuracy: 0.4303\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0181 - accuracy: 0.4467 - val_loss: 1.0508 - val_accuracy: 0.4370\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0295 - accuracy: 0.4247 - val_loss: 1.0309 - val_accuracy: 0.4531\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0171 - accuracy: 0.4563 - val_loss: 1.0158 - val_accuracy: 0.4584\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0166 - accuracy: 0.4438 - val_loss: 1.0170 - val_accuracy: 0.4611\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0187 - accuracy: 0.4443 - val_loss: 1.0380 - val_accuracy: 0.4223\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0108 - accuracy: 0.4414 - val_loss: 1.0326 - val_accuracy: 0.4812\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0168 - accuracy: 0.4362 - val_loss: 1.0093 - val_accuracy: 0.4920\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0160 - accuracy: 0.4478 - val_loss: 1.0131 - val_accuracy: 0.4692\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0039 - accuracy: 0.4472 - val_loss: 1.0156 - val_accuracy: 0.4625\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0028 - accuracy: 0.4618 - val_loss: 1.0058 - val_accuracy: 0.4611\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9906 - accuracy: 0.4774 - val_loss: 1.0100 - val_accuracy: 0.4692\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9991 - accuracy: 0.4538 - val_loss: 1.0052 - val_accuracy: 0.4638\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0036 - accuracy: 0.4615 - val_loss: 1.0081 - val_accuracy: 0.4692\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9969 - accuracy: 0.4656 - val_loss: 1.0056 - val_accuracy: 0.4611\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9870 - accuracy: 0.4712 - val_loss: 1.0070 - val_accuracy: 0.4718\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9907 - accuracy: 0.4663 - val_loss: 0.9977 - val_accuracy: 0.4866\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9812 - accuracy: 0.4867 - val_loss: 1.0168 - val_accuracy: 0.4558\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.9908 - accuracy: 0.4687 - val_loss: 0.9785 - val_accuracy: 0.4826\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9894 - accuracy: 0.4733 - val_loss: 0.9661 - val_accuracy: 0.4786\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9780 - accuracy: 0.4802 - val_loss: 0.9824 - val_accuracy: 0.4812\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9733 - accuracy: 0.4848 - val_loss: 0.9739 - val_accuracy: 0.4853\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9792 - accuracy: 0.4844 - val_loss: 0.9582 - val_accuracy: 0.4826\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9610 - accuracy: 0.4899 - val_loss: 0.9731 - val_accuracy: 0.5054\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9602 - accuracy: 0.4867 - val_loss: 0.9514 - val_accuracy: 0.5040\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9635 - accuracy: 0.4835 - val_loss: 0.9666 - val_accuracy: 0.4812\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9521 - accuracy: 0.4973 - val_loss: 0.9402 - val_accuracy: 0.5054\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9446 - accuracy: 0.5107 - val_loss: 0.9604 - val_accuracy: 0.4879\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9451 - accuracy: 0.4999 - val_loss: 0.9502 - val_accuracy: 0.5295\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9329 - accuracy: 0.5000 - val_loss: 0.9550 - val_accuracy: 0.5241\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9293 - accuracy: 0.5143 - val_loss: 0.9238 - val_accuracy: 0.5308\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9058 - accuracy: 0.5264 - val_loss: 0.9017 - val_accuracy: 0.5509\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9038 - accuracy: 0.5259 - val_loss: 0.8980 - val_accuracy: 0.5523\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8819 - accuracy: 0.5387 - val_loss: 0.9039 - val_accuracy: 0.5483\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8655 - accuracy: 0.5493 - val_loss: 0.9417 - val_accuracy: 0.5201\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8621 - accuracy: 0.5571 - val_loss: 0.8461 - val_accuracy: 0.5751\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8497 - accuracy: 0.5528 - val_loss: 0.8675 - val_accuracy: 0.5483\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8248 - accuracy: 0.5712 - val_loss: 0.8234 - val_accuracy: 0.5992\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8079 - accuracy: 0.5689 - val_loss: 0.8584 - val_accuracy: 0.5818\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8027 - accuracy: 0.5748 - val_loss: 0.8787 - val_accuracy: 0.5617\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7658 - accuracy: 0.6043 - val_loss: 0.8833 - val_accuracy: 0.5831\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7661 - accuracy: 0.5972 - val_loss: 0.7658 - val_accuracy: 0.5925\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7232 - accuracy: 0.6265 - val_loss: 0.7485 - val_accuracy: 0.6139\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7200 - accuracy: 0.6204 - val_loss: 0.7768 - val_accuracy: 0.6072\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6914 - accuracy: 0.6463 - val_loss: 0.7972 - val_accuracy: 0.5938\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7044 - accuracy: 0.6453 - val_loss: 0.8639 - val_accuracy: 0.5791\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6658 - accuracy: 0.6644 - val_loss: 0.6803 - val_accuracy: 0.6796\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6448 - accuracy: 0.6668 - val_loss: 0.8214 - val_accuracy: 0.6113\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6612 - accuracy: 0.6748 - val_loss: 0.5466 - val_accuracy: 0.7292\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6331 - accuracy: 0.6873 - val_loss: 0.5108 - val_accuracy: 0.7440\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6038 - accuracy: 0.7033 - val_loss: 0.5298 - val_accuracy: 0.7225\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5739 - accuracy: 0.7198 - val_loss: 0.5513 - val_accuracy: 0.7051\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5604 - accuracy: 0.7350 - val_loss: 0.5861 - val_accuracy: 0.6836\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5513 - accuracy: 0.7373 - val_loss: 0.4890 - val_accuracy: 0.7627\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5226 - accuracy: 0.7529 - val_loss: 0.4581 - val_accuracy: 0.7909\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5230 - accuracy: 0.7596 - val_loss: 0.4361 - val_accuracy: 0.7949\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4756 - accuracy: 0.7800 - val_loss: 0.4260 - val_accuracy: 0.7802\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4668 - accuracy: 0.7925 - val_loss: 0.4214 - val_accuracy: 0.7708\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4294 - accuracy: 0.8082 - val_loss: 0.4426 - val_accuracy: 0.7909\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4154 - accuracy: 0.8218 - val_loss: 0.3708 - val_accuracy: 0.8244\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3984 - accuracy: 0.8295 - val_loss: 0.3843 - val_accuracy: 0.8110\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4011 - accuracy: 0.8364 - val_loss: 0.4044 - val_accuracy: 0.7976\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3640 - accuracy: 0.8495 - val_loss: 0.3475 - val_accuracy: 0.8391\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3765 - accuracy: 0.8477 - val_loss: 0.3725 - val_accuracy: 0.8338\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3201 - accuracy: 0.8712 - val_loss: 0.3551 - val_accuracy: 0.8284\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3358 - accuracy: 0.8639 - val_loss: 0.3428 - val_accuracy: 0.8378\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2965 - accuracy: 0.8852 - val_loss: 0.2957 - val_accuracy: 0.8740\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2995 - accuracy: 0.8833 - val_loss: 0.2951 - val_accuracy: 0.8686\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2752 - accuracy: 0.8930 - val_loss: 0.3541 - val_accuracy: 0.8405\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2624 - accuracy: 0.8990 - val_loss: 0.2762 - val_accuracy: 0.8928\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2693 - accuracy: 0.8975 - val_loss: 0.2595 - val_accuracy: 0.8928\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2593 - accuracy: 0.8978 - val_loss: 0.2234 - val_accuracy: 0.9209\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2353 - accuracy: 0.9164 - val_loss: 0.2207 - val_accuracy: 0.9276\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2211 - accuracy: 0.9210 - val_loss: 0.2070 - val_accuracy: 0.9276\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1986 - accuracy: 0.9301 - val_loss: 0.2752 - val_accuracy: 0.8874\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2008 - accuracy: 0.9274 - val_loss: 0.2036 - val_accuracy: 0.9290\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2056 - accuracy: 0.9258 - val_loss: 0.1661 - val_accuracy: 0.9517\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1788 - accuracy: 0.9361 - val_loss: 0.2121 - val_accuracy: 0.9276\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2155 - accuracy: 0.9264 - val_loss: 0.0282 - val_accuracy: 0.9893\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1829 - accuracy: 0.9379 - val_loss: 0.0304 - val_accuracy: 0.9879\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1996 - accuracy: 0.9317 - val_loss: 0.0413 - val_accuracy: 0.9853\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1890 - accuracy: 0.9323 - val_loss: 0.0382 - val_accuracy: 0.9920\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1658 - accuracy: 0.9425 - val_loss: 0.0480 - val_accuracy: 0.9839\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1729 - accuracy: 0.9419 - val_loss: 0.0440 - val_accuracy: 0.9893\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1560 - accuracy: 0.9441 - val_loss: 0.0301 - val_accuracy: 0.9879\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1430 - accuracy: 0.9519 - val_loss: 0.0420 - val_accuracy: 0.9866\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1505 - accuracy: 0.9508 - val_loss: 0.0383 - val_accuracy: 0.9826\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1404 - accuracy: 0.9508 - val_loss: 0.0398 - val_accuracy: 0.9866\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1469 - accuracy: 0.9492 - val_loss: 0.0281 - val_accuracy: 0.9893\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1149 - accuracy: 0.9645 - val_loss: 0.0257 - val_accuracy: 0.9906\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1363 - accuracy: 0.9539 - val_loss: 0.0264 - val_accuracy: 0.9920\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1402 - accuracy: 0.9513 - val_loss: 0.0286 - val_accuracy: 0.9866\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1249 - accuracy: 0.9572 - val_loss: 0.0399 - val_accuracy: 0.9812\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1084 - accuracy: 0.9657 - val_loss: 0.0245 - val_accuracy: 0.9906\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1044 - accuracy: 0.9642 - val_loss: 0.0250 - val_accuracy: 0.9879\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1228 - accuracy: 0.9613 - val_loss: 0.0383 - val_accuracy: 0.9826\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0926 - accuracy: 0.9708 - val_loss: 0.0290 - val_accuracy: 0.9906\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0980 - accuracy: 0.9699 - val_loss: 0.0320 - val_accuracy: 0.9906\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0970 - accuracy: 0.9666 - val_loss: 0.0328 - val_accuracy: 0.9879\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0944 - accuracy: 0.9674 - val_loss: 0.0367 - val_accuracy: 0.9866\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1140 - accuracy: 0.9641 - val_loss: 0.0302 - val_accuracy: 0.9879\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1137 - accuracy: 0.9608 - val_loss: 0.0404 - val_accuracy: 0.9812\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1011 - accuracy: 0.9653 - val_loss: 0.0383 - val_accuracy: 0.9866\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0869 - accuracy: 0.9717 - val_loss: 0.0402 - val_accuracy: 0.9853\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0989 - accuracy: 0.9693 - val_loss: 0.0312 - val_accuracy: 0.9853\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0908 - accuracy: 0.9692 - val_loss: 0.0353 - val_accuracy: 0.9839\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0949 - accuracy: 0.9683 - val_loss: 0.0360 - val_accuracy: 0.9772\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0852 - accuracy: 0.9705 - val_loss: 0.0228 - val_accuracy: 0.9906\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0795 - accuracy: 0.9741 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0946 - accuracy: 0.9663 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0995 - accuracy: 0.9693 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0842 - accuracy: 0.9735 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0837 - accuracy: 0.9712 - val_loss: 9.5734e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0761 - accuracy: 0.9739 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0954 - accuracy: 0.9714 - val_loss: 0.0071 - val_accuracy: 0.9960\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0730 - accuracy: 0.9757 - val_loss: 8.0177e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0819 - accuracy: 0.9733 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0784 - accuracy: 0.9738 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0671 - accuracy: 0.9765 - val_loss: 7.7521e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0779 - accuracy: 0.9751 - val_loss: 0.0017 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0825 - accuracy: 0.9742 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0756 - accuracy: 0.9760 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0705 - accuracy: 0.9751 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0632 - accuracy: 0.9791 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0532 - accuracy: 0.9800 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0674 - accuracy: 0.9768 - val_loss: 9.7292e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0709 - accuracy: 0.9770 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0695 - accuracy: 0.9778 - val_loss: 0.0071 - val_accuracy: 0.9973\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0611 - accuracy: 0.9809 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0671 - accuracy: 0.9793 - val_loss: 0.0065 - val_accuracy: 0.9973\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0795 - accuracy: 0.9732 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0537 - accuracy: 0.9836 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0620 - accuracy: 0.9796 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0680 - accuracy: 0.9766 - val_loss: 0.0062 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0676 - accuracy: 0.9770 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0623 - accuracy: 0.9802 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0560 - accuracy: 0.9826 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0516 - accuracy: 0.9854 - val_loss: 0.0057 - val_accuracy: 0.9973\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0788 - accuracy: 0.9744 - val_loss: 3.9852e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0526 - accuracy: 0.9826 - val_loss: 1.0111e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0440 - accuracy: 0.9836 - val_loss: 1.8586e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0630 - accuracy: 0.9805 - val_loss: 0.0033 - val_accuracy: 0.9987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0646 - accuracy: 0.9768 - val_loss: 6.0557e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0596 - accuracy: 0.9806 - val_loss: 5.0310e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0626 - accuracy: 0.9787 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0534 - accuracy: 0.9836 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0843 - accuracy: 0.9741 - val_loss: 0.0103 - val_accuracy: 0.9946\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0780 - accuracy: 0.9742 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0534 - accuracy: 0.9823 - val_loss: 8.3390e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0563 - accuracy: 0.9832 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0439 - accuracy: 0.9854 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0589 - accuracy: 0.9809 - val_loss: 6.1184e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0522 - accuracy: 0.9848 - val_loss: 2.5434e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0547 - accuracy: 0.9839 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0429 - accuracy: 0.9858 - val_loss: 9.0029e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0519 - accuracy: 0.9814 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0573 - accuracy: 0.9815 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0524 - accuracy: 0.9839 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0492 - accuracy: 0.9849 - val_loss: 0.0085 - val_accuracy: 0.9973\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0519 - accuracy: 0.9844 - val_loss: 6.5123e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0484 - accuracy: 0.9836 - val_loss: 8.2745e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0496 - accuracy: 0.9827 - val_loss: 3.2247e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0559 - accuracy: 0.9824 - val_loss: 5.4909e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0583 - accuracy: 0.9849 - val_loss: 0.0023 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0384 - accuracy: 0.9884 - val_loss: 0.0033 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0399 - accuracy: 0.9863 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0563 - accuracy: 0.9841 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0347 - accuracy: 0.9891 - val_loss: 0.0024 - val_accuracy: 0.9987\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 48ms/step - loss: 0.0494 - accuracy: 0.9847 - val_loss: 2.2949e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0495 - accuracy: 0.9848 - val_loss: 4.6908e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0509 - accuracy: 0.9844 - val_loss: 1.5059e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0647 - accuracy: 0.9805 - val_loss: 1.1997e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0427 - accuracy: 0.9869 - val_loss: 2.0563e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0440 - accuracy: 0.9864 - val_loss: 8.1662e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0427 - accuracy: 0.9873 - val_loss: 1.1288e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0374 - accuracy: 0.9881 - val_loss: 7.2095e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0505 - accuracy: 0.9847 - val_loss: 1.3152e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0366 - accuracy: 0.9887 - val_loss: 7.5586e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0614 - accuracy: 0.9833 - val_loss: 2.2918e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0475 - accuracy: 0.9854 - val_loss: 6.5172e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0348 - accuracy: 0.9893 - val_loss: 9.2622e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0345 - accuracy: 0.9884 - val_loss: 0.0031 - val_accuracy: 0.9973\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0604 - accuracy: 0.9826 - val_loss: 5.6988e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0576 - accuracy: 0.9817 - val_loss: 3.8823e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0307 - accuracy: 0.9912 - val_loss: 1.0091e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0355 - accuracy: 0.9905 - val_loss: 1.2640e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0512 - accuracy: 0.9852 - val_loss: 1.6112e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0488 - accuracy: 0.9847 - val_loss: 3.5521e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0415 - accuracy: 0.9884 - val_loss: 6.9174e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0508 - accuracy: 0.9836 - val_loss: 3.5919e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0525 - accuracy: 0.9845 - val_loss: 5.3755e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0505 - accuracy: 0.9842 - val_loss: 5.0533e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0516 - accuracy: 0.9844 - val_loss: 4.8166e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0369 - accuracy: 0.9899 - val_loss: 2.0163e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0451 - accuracy: 0.9860 - val_loss: 0.0029 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0522 - accuracy: 0.9827 - val_loss: 0.0027 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0372 - accuracy: 0.9881 - val_loss: 7.1033e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0432 - accuracy: 0.9852 - val_loss: 2.9418e-04 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0442 - accuracy: 0.9869 - val_loss: 5.0937e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0541 - accuracy: 0.9806 - val_loss: 7.1116e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0405 - accuracy: 0.9875 - val_loss: 5.3473e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0336 - accuracy: 0.9882 - val_loss: 8.8198e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0392 - accuracy: 0.9879 - val_loss: 9.3508e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0392 - accuracy: 0.9873 - val_loss: 1.0764e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0426 - accuracy: 0.9866 - val_loss: 1.0182e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0410 - accuracy: 0.9873 - val_loss: 1.4986e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0340 - accuracy: 0.9890 - val_loss: 8.1045e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0337 - accuracy: 0.9896 - val_loss: 2.0284e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0377 - accuracy: 0.9873 - val_loss: 1.6717e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0342 - accuracy: 0.9900 - val_loss: 7.1100e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0287 - accuracy: 0.9915 - val_loss: 2.2907e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0492 - accuracy: 0.9851 - val_loss: 2.3193e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0483 - accuracy: 0.9855 - val_loss: 2.9745e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0392 - accuracy: 0.9884 - val_loss: 1.8736e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0349 - accuracy: 0.9891 - val_loss: 0.0012 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0432 - accuracy: 0.9869 - val_loss: 4.3907e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0304 - accuracy: 0.9912 - val_loss: 0.0015 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0326 - accuracy: 0.9906 - val_loss: 6.0350e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0517 - accuracy: 0.9851 - val_loss: 9.5500e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0373 - accuracy: 0.9875 - val_loss: 6.0419e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0334 - accuracy: 0.9903 - val_loss: 4.7841e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0318 - accuracy: 0.9909 - val_loss: 4.3392e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0263 - accuracy: 0.9912 - val_loss: 1.8924e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0289 - accuracy: 0.9917 - val_loss: 4.5082e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0364 - accuracy: 0.9890 - val_loss: 0.0020 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0316 - accuracy: 0.9882 - val_loss: 5.7793e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0370 - accuracy: 0.9876 - val_loss: 0.0026 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0335 - accuracy: 0.9908 - val_loss: 0.0014 - val_accuracy: 0.9987\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0380 - accuracy: 0.9888 - val_loss: 2.2937e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0374 - accuracy: 0.9894 - val_loss: 9.7879e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0417 - accuracy: 0.9869 - val_loss: 2.2236e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0306 - accuracy: 0.9917 - val_loss: 0.0022 - val_accuracy: 0.9987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0408 - accuracy: 0.9864 - val_loss: 3.0788e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0484 - accuracy: 0.9845 - val_loss: 2.5460e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0455 - accuracy: 0.9867 - val_loss: 2.4143e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0321 - accuracy: 0.9900 - val_loss: 3.3042e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0366 - accuracy: 0.9890 - val_loss: 5.8653e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0300 - accuracy: 0.9911 - val_loss: 2.5058e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0278 - accuracy: 0.9924 - val_loss: 3.3083e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0355 - accuracy: 0.9897 - val_loss: 3.6097e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0414 - accuracy: 0.9866 - val_loss: 2.1215e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0343 - accuracy: 0.9884 - val_loss: 3.2322e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0416 - accuracy: 0.9860 - val_loss: 5.8726e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0304 - accuracy: 0.9917 - val_loss: 3.1555e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0400 - accuracy: 0.9872 - val_loss: 0.0038 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0319 - accuracy: 0.9902 - val_loss: 1.0500e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0286 - accuracy: 0.9906 - val_loss: 3.0321e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0303 - accuracy: 0.9908 - val_loss: 6.0313e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0393 - accuracy: 0.9876 - val_loss: 3.7563e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0357 - accuracy: 0.9911 - val_loss: 4.7202e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0272 - accuracy: 0.9923 - val_loss: 3.5895e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0277 - accuracy: 0.9914 - val_loss: 8.0932e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0249 - accuracy: 0.9928 - val_loss: 1.0654e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0345 - accuracy: 0.9894 - val_loss: 9.2278e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0390 - accuracy: 0.9881 - val_loss: 1.9267e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0197 - accuracy: 0.9931 - val_loss: 3.0027e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0220 - accuracy: 0.9925 - val_loss: 2.5021e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0358 - accuracy: 0.9893 - val_loss: 0.0021 - val_accuracy: 0.9987\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0370 - accuracy: 0.9881 - val_loss: 4.9237e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0368 - accuracy: 0.9900 - val_loss: 1.9760e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0247 - accuracy: 0.9917 - val_loss: 3.7036e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0338 - accuracy: 0.9893 - val_loss: 3.0020e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0253 - accuracy: 0.9942 - val_loss: 1.5564e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0286 - accuracy: 0.9921 - val_loss: 9.3243e-06 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0275 - accuracy: 0.9920 - val_loss: 3.6080e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0280 - accuracy: 0.9917 - val_loss: 2.0884e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0269 - accuracy: 0.9915 - val_loss: 1.2684e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0253 - accuracy: 0.9917 - val_loss: 1.5910e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0272 - accuracy: 0.9917 - val_loss: 1.1655e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0251 - accuracy: 0.9933 - val_loss: 3.4357e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0220 - accuracy: 0.9930 - val_loss: 3.6874e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0248 - accuracy: 0.9915 - val_loss: 1.8871e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0311 - accuracy: 0.9903 - val_loss: 8.1629e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0520 - accuracy: 0.9839 - val_loss: 1.6294e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0445 - accuracy: 0.9861 - val_loss: 1.0578e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0269 - accuracy: 0.9906 - val_loss: 0.0017 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0321 - accuracy: 0.9905 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0221 - accuracy: 0.9930 - val_loss: 1.2848e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0225 - accuracy: 0.9937 - val_loss: 2.3951e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0301 - accuracy: 0.9912 - val_loss: 0.0076 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0241 - accuracy: 0.9917 - val_loss: 3.3978e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0325 - accuracy: 0.9899 - val_loss: 2.8183e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0406 - accuracy: 0.9863 - val_loss: 1.0060e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0335 - accuracy: 0.9902 - val_loss: 6.3437e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0377 - accuracy: 0.9876 - val_loss: 4.3113e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0432 - accuracy: 0.9872 - val_loss: 4.0532e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0315 - accuracy: 0.9884 - val_loss: 9.3443e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0291 - accuracy: 0.9911 - val_loss: 3.9694e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "CAnc2SJa3o9f",
        "outputId": "e3d2eeb0-7449-4132-b8a9-4d89a8ba9430"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 8ms/step - loss: 0.0282 - accuracy: 0.9893\n",
            "Accuracy  : 0.9892703890800476\n",
            "F1_Score  : 0.989398334857876\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7fcxLuwZpkK",
        "outputId": "ce160269-d1fc-4008-b2d5-68cf0a3638cd"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "98b744d1-60f4-4725-dfd2-733c6de47d7f"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 54ms/step - loss: 1.2221 - accuracy: 0.3691 - val_loss: 1.0957 - val_accuracy: 0.4102\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0888 - accuracy: 0.4080 - val_loss: 1.0885 - val_accuracy: 0.4102\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0926 - accuracy: 0.4003 - val_loss: 1.0868 - val_accuracy: 0.4102\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0869 - accuracy: 0.4075 - val_loss: 1.0860 - val_accuracy: 0.4102\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0913 - accuracy: 0.4025 - val_loss: 1.0864 - val_accuracy: 0.4102\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0910 - accuracy: 0.3981 - val_loss: 1.0839 - val_accuracy: 0.4102\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0861 - accuracy: 0.4122 - val_loss: 1.0856 - val_accuracy: 0.4102\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0924 - accuracy: 0.3897 - val_loss: 1.0845 - val_accuracy: 0.4102\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0873 - accuracy: 0.4000 - val_loss: 1.0846 - val_accuracy: 0.4102\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0873 - accuracy: 0.4039 - val_loss: 1.0848 - val_accuracy: 0.4102\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0879 - accuracy: 0.3994 - val_loss: 1.0821 - val_accuracy: 0.4102\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0875 - accuracy: 0.3999 - val_loss: 1.0844 - val_accuracy: 0.4102\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0857 - accuracy: 0.4016 - val_loss: 1.0824 - val_accuracy: 0.4102\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0811 - accuracy: 0.4063 - val_loss: 1.0853 - val_accuracy: 0.4102\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0863 - accuracy: 0.4019 - val_loss: 1.0822 - val_accuracy: 0.4102\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0841 - accuracy: 0.4062 - val_loss: 1.0822 - val_accuracy: 0.4102\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0859 - accuracy: 0.4066 - val_loss: 1.0816 - val_accuracy: 0.4102\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0817 - accuracy: 0.4182 - val_loss: 1.0813 - val_accuracy: 0.4102\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0846 - accuracy: 0.4099 - val_loss: 1.0824 - val_accuracy: 0.4102\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0824 - accuracy: 0.4123 - val_loss: 1.0822 - val_accuracy: 0.4102\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0843 - accuracy: 0.4079 - val_loss: 1.0823 - val_accuracy: 0.4102\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0872 - accuracy: 0.4004 - val_loss: 1.0824 - val_accuracy: 0.4102\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0863 - accuracy: 0.4062 - val_loss: 1.0816 - val_accuracy: 0.4102\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0834 - accuracy: 0.4035 - val_loss: 1.0829 - val_accuracy: 0.4102\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0797 - accuracy: 0.4167 - val_loss: 1.0811 - val_accuracy: 0.4102\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0869 - accuracy: 0.4014 - val_loss: 1.0815 - val_accuracy: 0.4102\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0818 - accuracy: 0.4126 - val_loss: 1.0798 - val_accuracy: 0.4102\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0850 - accuracy: 0.4018 - val_loss: 1.0790 - val_accuracy: 0.4102\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0853 - accuracy: 0.4067 - val_loss: 1.0799 - val_accuracy: 0.4102\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0800 - accuracy: 0.4172 - val_loss: 1.0722 - val_accuracy: 0.4263\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 1.0829 - accuracy: 0.4109 - val_loss: 1.0684 - val_accuracy: 0.4370\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0819 - accuracy: 0.4121 - val_loss: 1.0689 - val_accuracy: 0.4424\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0829 - accuracy: 0.4098 - val_loss: 1.0696 - val_accuracy: 0.4437\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0812 - accuracy: 0.4177 - val_loss: 1.0668 - val_accuracy: 0.4491\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0811 - accuracy: 0.4170 - val_loss: 1.0704 - val_accuracy: 0.4397\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0794 - accuracy: 0.4152 - val_loss: 1.0690 - val_accuracy: 0.4437\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0778 - accuracy: 0.4158 - val_loss: 1.0667 - val_accuracy: 0.4437\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0792 - accuracy: 0.4158 - val_loss: 1.0644 - val_accuracy: 0.4504\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0783 - accuracy: 0.4154 - val_loss: 1.0638 - val_accuracy: 0.4517\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0802 - accuracy: 0.4167 - val_loss: 1.0640 - val_accuracy: 0.4477\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0783 - accuracy: 0.4137 - val_loss: 1.0652 - val_accuracy: 0.4504\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0771 - accuracy: 0.4164 - val_loss: 1.0639 - val_accuracy: 0.4424\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0755 - accuracy: 0.4185 - val_loss: 1.0611 - val_accuracy: 0.4437\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0746 - accuracy: 0.4195 - val_loss: 1.0651 - val_accuracy: 0.4450\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0740 - accuracy: 0.4218 - val_loss: 1.0629 - val_accuracy: 0.4571\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0757 - accuracy: 0.4183 - val_loss: 1.0595 - val_accuracy: 0.4544\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0709 - accuracy: 0.4241 - val_loss: 1.0559 - val_accuracy: 0.4611\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0704 - accuracy: 0.4209 - val_loss: 1.0572 - val_accuracy: 0.4558\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0687 - accuracy: 0.4206 - val_loss: 1.0573 - val_accuracy: 0.4584\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0685 - accuracy: 0.4250 - val_loss: 1.0534 - val_accuracy: 0.4665\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0690 - accuracy: 0.4267 - val_loss: 1.0632 - val_accuracy: 0.4491\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0749 - accuracy: 0.4221 - val_loss: 1.0573 - val_accuracy: 0.4584\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0728 - accuracy: 0.4232 - val_loss: 1.0589 - val_accuracy: 0.4544\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0687 - accuracy: 0.4152 - val_loss: 1.0484 - val_accuracy: 0.4705\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0701 - accuracy: 0.4250 - val_loss: 1.0461 - val_accuracy: 0.4718\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0652 - accuracy: 0.4295 - val_loss: 1.0471 - val_accuracy: 0.4651\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0647 - accuracy: 0.4301 - val_loss: 1.0474 - val_accuracy: 0.4678\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0636 - accuracy: 0.4294 - val_loss: 1.0520 - val_accuracy: 0.4678\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0634 - accuracy: 0.4316 - val_loss: 1.0446 - val_accuracy: 0.4718\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0674 - accuracy: 0.4277 - val_loss: 1.0530 - val_accuracy: 0.4625\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0646 - accuracy: 0.4362 - val_loss: 1.0659 - val_accuracy: 0.4276\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0617 - accuracy: 0.4386 - val_loss: 1.0657 - val_accuracy: 0.4343\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0572 - accuracy: 0.4387 - val_loss: 1.0735 - val_accuracy: 0.4209\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0580 - accuracy: 0.4392 - val_loss: 1.0578 - val_accuracy: 0.4343\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0573 - accuracy: 0.4399 - val_loss: 1.0538 - val_accuracy: 0.4316\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0531 - accuracy: 0.4435 - val_loss: 1.0563 - val_accuracy: 0.4370\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0545 - accuracy: 0.4441 - val_loss: 1.0520 - val_accuracy: 0.4383\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0551 - accuracy: 0.4414 - val_loss: 1.0545 - val_accuracy: 0.4343\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0547 - accuracy: 0.4411 - val_loss: 1.0525 - val_accuracy: 0.4397\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0530 - accuracy: 0.4437 - val_loss: 1.0595 - val_accuracy: 0.4343\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0516 - accuracy: 0.4480 - val_loss: 1.0569 - val_accuracy: 0.4357\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0471 - accuracy: 0.4493 - val_loss: 1.0502 - val_accuracy: 0.4397\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0519 - accuracy: 0.4463 - val_loss: 1.0656 - val_accuracy: 0.4330\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0536 - accuracy: 0.4419 - val_loss: 1.0493 - val_accuracy: 0.4357\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0524 - accuracy: 0.4481 - val_loss: 1.0499 - val_accuracy: 0.4370\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0469 - accuracy: 0.4504 - val_loss: 1.0534 - val_accuracy: 0.4343\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0500 - accuracy: 0.4525 - val_loss: 1.0530 - val_accuracy: 0.4397\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0472 - accuracy: 0.4475 - val_loss: 1.0551 - val_accuracy: 0.4370\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0473 - accuracy: 0.4446 - val_loss: 1.0499 - val_accuracy: 0.4383\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0464 - accuracy: 0.4517 - val_loss: 1.0570 - val_accuracy: 0.4343\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0481 - accuracy: 0.4508 - val_loss: 1.0501 - val_accuracy: 0.4383\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0500 - accuracy: 0.4461 - val_loss: 1.0573 - val_accuracy: 0.4330\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0420 - accuracy: 0.4538 - val_loss: 1.0500 - val_accuracy: 0.4370\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0452 - accuracy: 0.4510 - val_loss: 1.0467 - val_accuracy: 0.4410\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0431 - accuracy: 0.4502 - val_loss: 1.0482 - val_accuracy: 0.4410\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0460 - accuracy: 0.4493 - val_loss: 1.0447 - val_accuracy: 0.4424\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0383 - accuracy: 0.4614 - val_loss: 1.0472 - val_accuracy: 0.4437\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0370 - accuracy: 0.4613 - val_loss: 1.0425 - val_accuracy: 0.4450\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0406 - accuracy: 0.4572 - val_loss: 1.0443 - val_accuracy: 0.4383\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0328 - accuracy: 0.4630 - val_loss: 1.0399 - val_accuracy: 0.4477\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0395 - accuracy: 0.4563 - val_loss: 1.0274 - val_accuracy: 0.4665\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0364 - accuracy: 0.4581 - val_loss: 1.0301 - val_accuracy: 0.4638\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0362 - accuracy: 0.4602 - val_loss: 1.0266 - val_accuracy: 0.4611\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0314 - accuracy: 0.4614 - val_loss: 1.0369 - val_accuracy: 0.4598\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0313 - accuracy: 0.4617 - val_loss: 1.0357 - val_accuracy: 0.4611\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0292 - accuracy: 0.4630 - val_loss: 1.0310 - val_accuracy: 0.4598\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0253 - accuracy: 0.4663 - val_loss: 1.0346 - val_accuracy: 0.4638\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0321 - accuracy: 0.4580 - val_loss: 1.0379 - val_accuracy: 0.4517\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0233 - accuracy: 0.4672 - val_loss: 1.0262 - val_accuracy: 0.4638\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0213 - accuracy: 0.4677 - val_loss: 1.0279 - val_accuracy: 0.4651\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0213 - accuracy: 0.4703 - val_loss: 1.0366 - val_accuracy: 0.4611\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0149 - accuracy: 0.4769 - val_loss: 1.0272 - val_accuracy: 0.4611\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0247 - accuracy: 0.4659 - val_loss: 1.0349 - val_accuracy: 0.4611\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0258 - accuracy: 0.4672 - val_loss: 1.0266 - val_accuracy: 0.4692\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0162 - accuracy: 0.4723 - val_loss: 1.0334 - val_accuracy: 0.4598\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0206 - accuracy: 0.4711 - val_loss: 1.0352 - val_accuracy: 0.4598\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0164 - accuracy: 0.4690 - val_loss: 1.0313 - val_accuracy: 0.4651\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0169 - accuracy: 0.4735 - val_loss: 1.0237 - val_accuracy: 0.4718\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0135 - accuracy: 0.4747 - val_loss: 1.0152 - val_accuracy: 0.4826\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0085 - accuracy: 0.4765 - val_loss: 1.0145 - val_accuracy: 0.4879\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0000 - accuracy: 0.4854 - val_loss: 1.0134 - val_accuracy: 0.4826\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0033 - accuracy: 0.4851 - val_loss: 1.0160 - val_accuracy: 0.4812\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0050 - accuracy: 0.4842 - val_loss: 1.0211 - val_accuracy: 0.4786\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0052 - accuracy: 0.4784 - val_loss: 1.0140 - val_accuracy: 0.4826\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0042 - accuracy: 0.4815 - val_loss: 1.0074 - val_accuracy: 0.4879\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0056 - accuracy: 0.4796 - val_loss: 1.0046 - val_accuracy: 0.4826\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9908 - accuracy: 0.4917 - val_loss: 0.9984 - val_accuracy: 0.4946\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9932 - accuracy: 0.4817 - val_loss: 1.0007 - val_accuracy: 0.4893\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9914 - accuracy: 0.4925 - val_loss: 0.9969 - val_accuracy: 0.4893\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9951 - accuracy: 0.4841 - val_loss: 1.0252 - val_accuracy: 0.4718\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 1.0053 - accuracy: 0.4829 - val_loss: 0.9583 - val_accuracy: 0.4987\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9948 - accuracy: 0.4914 - val_loss: 0.9741 - val_accuracy: 0.4893\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9888 - accuracy: 0.4952 - val_loss: 0.9546 - val_accuracy: 0.5013\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9814 - accuracy: 0.4952 - val_loss: 0.9546 - val_accuracy: 0.4920\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9753 - accuracy: 0.5033 - val_loss: 0.9737 - val_accuracy: 0.4920\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9743 - accuracy: 0.5058 - val_loss: 0.9572 - val_accuracy: 0.4973\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9769 - accuracy: 0.5018 - val_loss: 0.9572 - val_accuracy: 0.5013\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9743 - accuracy: 0.5022 - val_loss: 0.9477 - val_accuracy: 0.5094\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9590 - accuracy: 0.5113 - val_loss: 0.9531 - val_accuracy: 0.5013\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9626 - accuracy: 0.5104 - val_loss: 0.9440 - val_accuracy: 0.5067\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9674 - accuracy: 0.5131 - val_loss: 0.9456 - val_accuracy: 0.5080\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9597 - accuracy: 0.5146 - val_loss: 0.9391 - val_accuracy: 0.5094\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9444 - accuracy: 0.5265 - val_loss: 0.9358 - val_accuracy: 0.5121\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9491 - accuracy: 0.5258 - val_loss: 0.9358 - val_accuracy: 0.5188\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9371 - accuracy: 0.5277 - val_loss: 0.9236 - val_accuracy: 0.5214\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9299 - accuracy: 0.5297 - val_loss: 0.9336 - val_accuracy: 0.5067\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9257 - accuracy: 0.5393 - val_loss: 0.9384 - val_accuracy: 0.5054\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9251 - accuracy: 0.5401 - val_loss: 0.9153 - val_accuracy: 0.5282\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9372 - accuracy: 0.5268 - val_loss: 0.9324 - val_accuracy: 0.5067\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9185 - accuracy: 0.5368 - val_loss: 0.9143 - val_accuracy: 0.5228\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9047 - accuracy: 0.5490 - val_loss: 0.9067 - val_accuracy: 0.5282\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8944 - accuracy: 0.5507 - val_loss: 0.8908 - val_accuracy: 0.5362\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9018 - accuracy: 0.5483 - val_loss: 0.8854 - val_accuracy: 0.5429\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8775 - accuracy: 0.5644 - val_loss: 0.8872 - val_accuracy: 0.5469\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8677 - accuracy: 0.5705 - val_loss: 0.8996 - val_accuracy: 0.5362\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8729 - accuracy: 0.5675 - val_loss: 0.9019 - val_accuracy: 0.5389\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8489 - accuracy: 0.5842 - val_loss: 0.8831 - val_accuracy: 0.5456\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8503 - accuracy: 0.5815 - val_loss: 0.8640 - val_accuracy: 0.5576\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8466 - accuracy: 0.5823 - val_loss: 0.8595 - val_accuracy: 0.5737\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8277 - accuracy: 0.5940 - val_loss: 0.8446 - val_accuracy: 0.5657\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8398 - accuracy: 0.5860 - val_loss: 0.7181 - val_accuracy: 0.6609\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8160 - accuracy: 0.6055 - val_loss: 0.6944 - val_accuracy: 0.6877\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7962 - accuracy: 0.6146 - val_loss: 0.6887 - val_accuracy: 0.6582\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7922 - accuracy: 0.6133 - val_loss: 0.7003 - val_accuracy: 0.6595\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7876 - accuracy: 0.6145 - val_loss: 0.7056 - val_accuracy: 0.6649\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7848 - accuracy: 0.6186 - val_loss: 0.6710 - val_accuracy: 0.6729\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7713 - accuracy: 0.6310 - val_loss: 0.6781 - val_accuracy: 0.6769\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7568 - accuracy: 0.6404 - val_loss: 0.6751 - val_accuracy: 0.6702\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7382 - accuracy: 0.6411 - val_loss: 0.6587 - val_accuracy: 0.6702\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7276 - accuracy: 0.6449 - val_loss: 0.6597 - val_accuracy: 0.6836\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7200 - accuracy: 0.6583 - val_loss: 0.6310 - val_accuracy: 0.6890\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7121 - accuracy: 0.6630 - val_loss: 0.6199 - val_accuracy: 0.7024\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6840 - accuracy: 0.6765 - val_loss: 0.6178 - val_accuracy: 0.7131\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6842 - accuracy: 0.6745 - val_loss: 0.6265 - val_accuracy: 0.6971\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6788 - accuracy: 0.6763 - val_loss: 0.5886 - val_accuracy: 0.7158\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6410 - accuracy: 0.7007 - val_loss: 0.5769 - val_accuracy: 0.7212\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6406 - accuracy: 0.6920 - val_loss: 0.6034 - val_accuracy: 0.7212\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6419 - accuracy: 0.7006 - val_loss: 0.6117 - val_accuracy: 0.6984\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6302 - accuracy: 0.7063 - val_loss: 0.5731 - val_accuracy: 0.7359\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5969 - accuracy: 0.7246 - val_loss: 0.5564 - val_accuracy: 0.7131\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5849 - accuracy: 0.7282 - val_loss: 0.5835 - val_accuracy: 0.7319\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5845 - accuracy: 0.7297 - val_loss: 0.5276 - val_accuracy: 0.7520\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5737 - accuracy: 0.7358 - val_loss: 0.5456 - val_accuracy: 0.7520\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5507 - accuracy: 0.7480 - val_loss: 0.5553 - val_accuracy: 0.7212\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5331 - accuracy: 0.7493 - val_loss: 0.5196 - val_accuracy: 0.7601\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5287 - accuracy: 0.7659 - val_loss: 0.5572 - val_accuracy: 0.7681\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5410 - accuracy: 0.7629 - val_loss: 0.4988 - val_accuracy: 0.7654\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5011 - accuracy: 0.7808 - val_loss: 0.4800 - val_accuracy: 0.7775\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4937 - accuracy: 0.7836 - val_loss: 0.4829 - val_accuracy: 0.7855\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4845 - accuracy: 0.7879 - val_loss: 0.4657 - val_accuracy: 0.7882\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4934 - accuracy: 0.7880 - val_loss: 0.2531 - val_accuracy: 0.9034\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4635 - accuracy: 0.8017 - val_loss: 0.2876 - val_accuracy: 0.8805\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4705 - accuracy: 0.8069 - val_loss: 0.2721 - val_accuracy: 0.9007\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4565 - accuracy: 0.8093 - val_loss: 0.2505 - val_accuracy: 0.9047\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4362 - accuracy: 0.8249 - val_loss: 0.2582 - val_accuracy: 0.9114\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4105 - accuracy: 0.8340 - val_loss: 0.2609 - val_accuracy: 0.8940\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4236 - accuracy: 0.8274 - val_loss: 0.2404 - val_accuracy: 0.9114\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4094 - accuracy: 0.8321 - val_loss: 0.2601 - val_accuracy: 0.8926\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3917 - accuracy: 0.8382 - val_loss: 0.2767 - val_accuracy: 0.8913\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3733 - accuracy: 0.8468 - val_loss: 0.2222 - val_accuracy: 0.9181\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3729 - accuracy: 0.8510 - val_loss: 0.2082 - val_accuracy: 0.9356\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3492 - accuracy: 0.8575 - val_loss: 0.2170 - val_accuracy: 0.9221\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3472 - accuracy: 0.8605 - val_loss: 0.2421 - val_accuracy: 0.9034\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3221 - accuracy: 0.8796 - val_loss: 0.2035 - val_accuracy: 0.9181\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3059 - accuracy: 0.8802 - val_loss: 0.2108 - val_accuracy: 0.9168\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3156 - accuracy: 0.8771 - val_loss: 0.2356 - val_accuracy: 0.8980\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2993 - accuracy: 0.8857 - val_loss: 0.2020 - val_accuracy: 0.9235\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2981 - accuracy: 0.8909 - val_loss: 0.1959 - val_accuracy: 0.9208\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2884 - accuracy: 0.8911 - val_loss: 0.2003 - val_accuracy: 0.9154\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2894 - accuracy: 0.8924 - val_loss: 0.1773 - val_accuracy: 0.9383\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2837 - accuracy: 0.8951 - val_loss: 0.1723 - val_accuracy: 0.9302\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2525 - accuracy: 0.9079 - val_loss: 0.1792 - val_accuracy: 0.9369\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2589 - accuracy: 0.9033 - val_loss: 0.1975 - val_accuracy: 0.9262\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2491 - accuracy: 0.9049 - val_loss: 0.1736 - val_accuracy: 0.9356\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2418 - accuracy: 0.9082 - val_loss: 0.1734 - val_accuracy: 0.9356\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2340 - accuracy: 0.9157 - val_loss: 0.1557 - val_accuracy: 0.9396\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2270 - accuracy: 0.9161 - val_loss: 0.1661 - val_accuracy: 0.9342\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2137 - accuracy: 0.9233 - val_loss: 0.1453 - val_accuracy: 0.9490\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2217 - accuracy: 0.9203 - val_loss: 0.1732 - val_accuracy: 0.9369\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2137 - accuracy: 0.9236 - val_loss: 0.1679 - val_accuracy: 0.9315\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2451 - accuracy: 0.9125 - val_loss: 0.0405 - val_accuracy: 0.9933\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2331 - accuracy: 0.9151 - val_loss: 0.0448 - val_accuracy: 0.9893\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2189 - accuracy: 0.9239 - val_loss: 0.0360 - val_accuracy: 0.9960\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2040 - accuracy: 0.9291 - val_loss: 0.0335 - val_accuracy: 0.9960\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1951 - accuracy: 0.9304 - val_loss: 0.0362 - val_accuracy: 0.9906\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1888 - accuracy: 0.9377 - val_loss: 0.0404 - val_accuracy: 0.9879\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1919 - accuracy: 0.9332 - val_loss: 0.0477 - val_accuracy: 0.9879\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1808 - accuracy: 0.9365 - val_loss: 0.0337 - val_accuracy: 0.9919\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1913 - accuracy: 0.9329 - val_loss: 0.0371 - val_accuracy: 0.9919\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1523 - accuracy: 0.9471 - val_loss: 0.0329 - val_accuracy: 0.9933\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1669 - accuracy: 0.9435 - val_loss: 0.0353 - val_accuracy: 0.9906\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1736 - accuracy: 0.9395 - val_loss: 0.0383 - val_accuracy: 0.9919\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1678 - accuracy: 0.9449 - val_loss: 0.0500 - val_accuracy: 0.9879\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1511 - accuracy: 0.9426 - val_loss: 0.0380 - val_accuracy: 0.9866\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1508 - accuracy: 0.9474 - val_loss: 0.0270 - val_accuracy: 0.9919\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1455 - accuracy: 0.9526 - val_loss: 0.0379 - val_accuracy: 0.9893\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1515 - accuracy: 0.9504 - val_loss: 0.0440 - val_accuracy: 0.9866\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1419 - accuracy: 0.9522 - val_loss: 0.0374 - val_accuracy: 0.9866\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1445 - accuracy: 0.9507 - val_loss: 0.0299 - val_accuracy: 0.9946\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1405 - accuracy: 0.9514 - val_loss: 0.0399 - val_accuracy: 0.9879\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1207 - accuracy: 0.9598 - val_loss: 0.0291 - val_accuracy: 0.9906\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1408 - accuracy: 0.9554 - val_loss: 0.0345 - val_accuracy: 0.9933\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1382 - accuracy: 0.9520 - val_loss: 0.0394 - val_accuracy: 0.9879\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1223 - accuracy: 0.9575 - val_loss: 0.0403 - val_accuracy: 0.9866\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1224 - accuracy: 0.9616 - val_loss: 0.0473 - val_accuracy: 0.9826\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1242 - accuracy: 0.9605 - val_loss: 0.0513 - val_accuracy: 0.9812\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1248 - accuracy: 0.9596 - val_loss: 0.0456 - val_accuracy: 0.9879\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1155 - accuracy: 0.9580 - val_loss: 0.0554 - val_accuracy: 0.9799\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1220 - accuracy: 0.9620 - val_loss: 0.0414 - val_accuracy: 0.9893\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1091 - accuracy: 0.9636 - val_loss: 0.0412 - val_accuracy: 0.9826\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1255 - accuracy: 0.9575 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1421 - accuracy: 0.9546 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1169 - accuracy: 0.9632 - val_loss: 0.0077 - val_accuracy: 0.9973\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1242 - accuracy: 0.9590 - val_loss: 0.0056 - val_accuracy: 0.9987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1417 - accuracy: 0.9486 - val_loss: 0.0062 - val_accuracy: 0.9973\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1095 - accuracy: 0.9622 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1141 - accuracy: 0.9616 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1322 - accuracy: 0.9586 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1163 - accuracy: 0.9586 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1087 - accuracy: 0.9638 - val_loss: 0.0055 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1029 - accuracy: 0.9700 - val_loss: 0.0066 - val_accuracy: 0.9987\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1020 - accuracy: 0.9662 - val_loss: 0.0070 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1116 - accuracy: 0.9639 - val_loss: 0.0062 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0971 - accuracy: 0.9690 - val_loss: 0.0053 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1056 - accuracy: 0.9642 - val_loss: 0.0054 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0960 - accuracy: 0.9718 - val_loss: 0.0094 - val_accuracy: 0.9973\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1033 - accuracy: 0.9662 - val_loss: 0.0045 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1004 - accuracy: 0.9677 - val_loss: 0.0057 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1048 - accuracy: 0.9680 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0879 - accuracy: 0.9720 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0926 - accuracy: 0.9689 - val_loss: 0.0180 - val_accuracy: 0.9919\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0921 - accuracy: 0.9718 - val_loss: 0.0061 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0896 - accuracy: 0.9715 - val_loss: 0.0057 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1150 - accuracy: 0.9671 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0843 - accuracy: 0.9735 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0944 - accuracy: 0.9698 - val_loss: 0.0093 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0927 - accuracy: 0.9692 - val_loss: 0.0063 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0983 - accuracy: 0.9677 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0847 - accuracy: 0.9717 - val_loss: 0.0127 - val_accuracy: 0.9960\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0914 - accuracy: 0.9717 - val_loss: 0.0100 - val_accuracy: 0.9960\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0877 - accuracy: 0.9711 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0883 - accuracy: 0.9724 - val_loss: 7.8268e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0894 - accuracy: 0.9717 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0718 - accuracy: 0.9753 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0793 - accuracy: 0.9727 - val_loss: 8.1723e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0716 - accuracy: 0.9753 - val_loss: 4.4470e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0878 - accuracy: 0.9693 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0789 - accuracy: 0.9738 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0863 - accuracy: 0.9715 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0838 - accuracy: 0.9706 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0754 - accuracy: 0.9760 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0629 - accuracy: 0.9797 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0852 - accuracy: 0.9727 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0800 - accuracy: 0.9730 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0724 - accuracy: 0.9750 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0730 - accuracy: 0.9779 - val_loss: 8.3155e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0763 - accuracy: 0.9762 - val_loss: 0.0025 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0781 - accuracy: 0.9762 - val_loss: 0.0130 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0599 - accuracy: 0.9811 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0700 - accuracy: 0.9768 - val_loss: 0.0034 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0593 - accuracy: 0.9802 - val_loss: 7.9617e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0877 - accuracy: 0.9723 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0865 - accuracy: 0.9718 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0719 - accuracy: 0.9788 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0617 - accuracy: 0.9790 - val_loss: 0.0053 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0746 - accuracy: 0.9778 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0655 - accuracy: 0.9774 - val_loss: 8.5794e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0638 - accuracy: 0.9784 - val_loss: 0.0033 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0729 - accuracy: 0.9779 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0727 - accuracy: 0.9794 - val_loss: 0.0027 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "3866a694-3e94-4d63-957c-24d4486165ea"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 7ms/step - loss: 0.1156 - accuracy: 0.9657\n",
            "Accuracy  : 0.9656652212142944\n",
            "F1_Score  : 0.9656738852428678\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "605cb84c-77e5-406c-b52e-bb912efb84b8"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'#dominance\\nX_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\\nprint(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "03d7947e-3ff2-4f8d-b033-dc4dd8912491"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'foldNum=0\\nmodel = get_model()\\nfor train_index, val_index in kfold.split(X_train, Y_train):\\n  foldNum = foldNum + 1\\n  print(\"Results for fold\",foldNum)\\n  x_train, x_val = X_train[train_index], X_train[val_index]\\n  y_train, y_val = Y_train[train_index], Y_train[val_index]\\n  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\\n  gc.collect() # Garbage collecter\\n  del x_train, x_val, y_train, y_val\\n  gc.collect()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "8608ed8a-4a15-47cf-f863-b1e6f14854f7"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'acrc = model.evaluate(x_test, y_test)\\npred = model.predict(x_test)\\nf1scr = f1_score(y_test.argmax(1), pred.argmax(1), average=\\'macro\\')\\nc_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\\nprint(\"Accuracy  : {}\".format(acrc[1]))\\nprint(\"F1_Score  : {}\".format(f1scr))\\nc_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\\nimport seaborn as sns\\nfigure = plt.figure(figsize=(9, 9))\\nsns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\\nplt.tight_layout()\\nplt.ylabel(\\'True label\\')\\nplt.xlabel(\\'Predicted label\\')\\nplt.show()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}