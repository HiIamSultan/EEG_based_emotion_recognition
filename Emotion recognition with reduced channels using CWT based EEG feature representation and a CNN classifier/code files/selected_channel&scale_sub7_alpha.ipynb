{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub7_theta.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "1d0a5d68-60ce-4a8d-a2b5-1f7d3f691e3a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e5\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  #EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "85579cf4-5aaa-4ba8-b2aa-9c46e0de84ed"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(7,8):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.7\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (2097,) (1398,) (5825,)\n",
            "(9320,) (2330,) (2563,) (4427,)\n",
            "(9320,) (4194,) (1398,) (3728,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "a1a66a4d-9cbc-482e-8f00-ab5dbd7f168e"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "add00b3d-c059-44ef-ed57-f12da45bee69"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "622"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "779dbb18-4eb6-474e-bfc2-cd5e36aa02fe"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79839aa2-4885-4e71-d5d9-0429724be8fd"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 50s 60ms/step - loss: 1.0471 - accuracy: 0.5571 - val_loss: 0.9412 - val_accuracy: 0.6247\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9249 - accuracy: 0.6283 - val_loss: 0.8900 - val_accuracy: 0.6247\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9197 - accuracy: 0.6122 - val_loss: 0.8688 - val_accuracy: 0.6247\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9112 - accuracy: 0.6207 - val_loss: 0.8708 - val_accuracy: 0.6247\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8998 - accuracy: 0.6187 - val_loss: 0.8986 - val_accuracy: 0.6247\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8926 - accuracy: 0.6265 - val_loss: 0.8578 - val_accuracy: 0.6247\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.8928 - accuracy: 0.6218 - val_loss: 0.8556 - val_accuracy: 0.6247\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8899 - accuracy: 0.6255 - val_loss: 0.8564 - val_accuracy: 0.6247\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8867 - accuracy: 0.6212 - val_loss: 0.8931 - val_accuracy: 0.6247\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8736 - accuracy: 0.6246 - val_loss: 0.8963 - val_accuracy: 0.6247\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8700 - accuracy: 0.6186 - val_loss: 0.9605 - val_accuracy: 0.6247\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8764 - accuracy: 0.6168 - val_loss: 0.8599 - val_accuracy: 0.6247\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8652 - accuracy: 0.6282 - val_loss: 0.8649 - val_accuracy: 0.6247\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8532 - accuracy: 0.6277 - val_loss: 0.8226 - val_accuracy: 0.6247\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.8472 - accuracy: 0.6274 - val_loss: 0.8355 - val_accuracy: 0.6247\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8476 - accuracy: 0.6252 - val_loss: 0.8708 - val_accuracy: 0.6260\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8426 - accuracy: 0.6354 - val_loss: 0.8372 - val_accuracy: 0.6287\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8382 - accuracy: 0.6214 - val_loss: 0.8634 - val_accuracy: 0.6287\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8215 - accuracy: 0.6318 - val_loss: 0.8181 - val_accuracy: 0.6260\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8291 - accuracy: 0.6277 - val_loss: 0.8093 - val_accuracy: 0.6314\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.8311 - accuracy: 0.6189 - val_loss: 0.8897 - val_accuracy: 0.6273\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8139 - accuracy: 0.6355 - val_loss: 0.7707 - val_accuracy: 0.6340\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8196 - accuracy: 0.6257 - val_loss: 0.7936 - val_accuracy: 0.6354\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7887 - accuracy: 0.6414 - val_loss: 0.7776 - val_accuracy: 0.6340\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7737 - accuracy: 0.6444 - val_loss: 0.7974 - val_accuracy: 0.6354\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7672 - accuracy: 0.6424 - val_loss: 0.7699 - val_accuracy: 0.6354\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7692 - accuracy: 0.6487 - val_loss: 0.7697 - val_accuracy: 0.6434\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7601 - accuracy: 0.6466 - val_loss: 0.8828 - val_accuracy: 0.6300\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7447 - accuracy: 0.6591 - val_loss: 0.7500 - val_accuracy: 0.6528\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7207 - accuracy: 0.6702 - val_loss: 0.7391 - val_accuracy: 0.6448\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.7232 - accuracy: 0.6607 - val_loss: 0.6946 - val_accuracy: 0.6890\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7068 - accuracy: 0.6732 - val_loss: 0.6886 - val_accuracy: 0.6796\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6923 - accuracy: 0.6717 - val_loss: 0.6514 - val_accuracy: 0.6944\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6824 - accuracy: 0.6838 - val_loss: 0.6462 - val_accuracy: 0.7158\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6595 - accuracy: 0.6891 - val_loss: 0.6711 - val_accuracy: 0.7064\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6419 - accuracy: 0.7013 - val_loss: 0.6090 - val_accuracy: 0.7359\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6182 - accuracy: 0.7115 - val_loss: 0.6042 - val_accuracy: 0.7359\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5919 - accuracy: 0.7259 - val_loss: 0.6400 - val_accuracy: 0.7051\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5784 - accuracy: 0.7329 - val_loss: 0.5523 - val_accuracy: 0.7721\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5626 - accuracy: 0.7465 - val_loss: 0.5689 - val_accuracy: 0.7413\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5309 - accuracy: 0.7590 - val_loss: 0.5360 - val_accuracy: 0.7587\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4861 - accuracy: 0.7799 - val_loss: 0.5726 - val_accuracy: 0.7668\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4654 - accuracy: 0.7960 - val_loss: 0.5799 - val_accuracy: 0.7426\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4578 - accuracy: 0.7997 - val_loss: 0.5161 - val_accuracy: 0.7936\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4224 - accuracy: 0.8218 - val_loss: 0.5030 - val_accuracy: 0.7949\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3866 - accuracy: 0.8431 - val_loss: 0.4165 - val_accuracy: 0.8405\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3653 - accuracy: 0.8526 - val_loss: 0.4132 - val_accuracy: 0.8244\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3535 - accuracy: 0.8620 - val_loss: 0.4062 - val_accuracy: 0.8351\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3084 - accuracy: 0.8836 - val_loss: 0.3775 - val_accuracy: 0.8552\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2795 - accuracy: 0.8954 - val_loss: 0.3700 - val_accuracy: 0.8633\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2651 - accuracy: 0.9021 - val_loss: 0.3618 - val_accuracy: 0.8566\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2459 - accuracy: 0.9092 - val_loss: 0.3095 - val_accuracy: 0.8901\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2307 - accuracy: 0.9174 - val_loss: 0.3102 - val_accuracy: 0.8887\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2026 - accuracy: 0.9279 - val_loss: 0.3059 - val_accuracy: 0.8954\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1855 - accuracy: 0.9328 - val_loss: 0.2586 - val_accuracy: 0.9129\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1648 - accuracy: 0.9440 - val_loss: 0.2656 - val_accuracy: 0.9223\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1582 - accuracy: 0.9420 - val_loss: 0.3406 - val_accuracy: 0.8847\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1532 - accuracy: 0.9487 - val_loss: 0.2427 - val_accuracy: 0.9155\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1469 - accuracy: 0.9498 - val_loss: 0.2135 - val_accuracy: 0.9303\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1342 - accuracy: 0.9537 - val_loss: 0.3140 - val_accuracy: 0.9075\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1664 - accuracy: 0.9441 - val_loss: 0.0179 - val_accuracy: 0.9960\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1517 - accuracy: 0.9474 - val_loss: 0.0186 - val_accuracy: 0.9987\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1363 - accuracy: 0.9578 - val_loss: 0.0196 - val_accuracy: 0.9960\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1198 - accuracy: 0.9580 - val_loss: 0.0389 - val_accuracy: 0.9826\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1236 - accuracy: 0.9589 - val_loss: 0.0194 - val_accuracy: 0.9920\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0994 - accuracy: 0.9665 - val_loss: 0.0134 - val_accuracy: 0.9973\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0964 - accuracy: 0.9693 - val_loss: 0.0184 - val_accuracy: 0.9933\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0827 - accuracy: 0.9742 - val_loss: 0.0169 - val_accuracy: 0.9946\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0987 - accuracy: 0.9669 - val_loss: 0.0232 - val_accuracy: 0.9893\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0804 - accuracy: 0.9732 - val_loss: 0.0214 - val_accuracy: 0.9933\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0701 - accuracy: 0.9772 - val_loss: 0.0141 - val_accuracy: 0.9973\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0774 - accuracy: 0.9739 - val_loss: 0.0166 - val_accuracy: 0.9920\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0738 - accuracy: 0.9775 - val_loss: 0.0174 - val_accuracy: 0.9920\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0668 - accuracy: 0.9776 - val_loss: 0.0132 - val_accuracy: 0.9946\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0508 - accuracy: 0.9852 - val_loss: 0.0198 - val_accuracy: 0.9946\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0736 - accuracy: 0.9759 - val_loss: 0.0087 - val_accuracy: 0.9973\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0681 - accuracy: 0.9794 - val_loss: 0.0245 - val_accuracy: 0.9920\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0536 - accuracy: 0.9823 - val_loss: 0.0120 - val_accuracy: 0.9946\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0584 - accuracy: 0.9811 - val_loss: 0.0347 - val_accuracy: 0.9893\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0756 - accuracy: 0.9760 - val_loss: 0.0573 - val_accuracy: 0.9799\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0693 - accuracy: 0.9778 - val_loss: 0.0213 - val_accuracy: 0.9920\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0506 - accuracy: 0.9826 - val_loss: 0.0279 - val_accuracy: 0.9906\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0580 - accuracy: 0.9833 - val_loss: 0.0230 - val_accuracy: 0.9933\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0431 - accuracy: 0.9857 - val_loss: 0.0606 - val_accuracy: 0.9812\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0610 - accuracy: 0.9787 - val_loss: 0.0144 - val_accuracy: 0.9933\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0480 - accuracy: 0.9845 - val_loss: 0.0293 - val_accuracy: 0.9893\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0413 - accuracy: 0.9873 - val_loss: 0.0260 - val_accuracy: 0.9893\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0460 - accuracy: 0.9860 - val_loss: 0.0317 - val_accuracy: 0.9933\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0524 - accuracy: 0.9836 - val_loss: 0.0204 - val_accuracy: 0.9933\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0496 - accuracy: 0.9846 - val_loss: 0.0269 - val_accuracy: 0.9906\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0635 - accuracy: 0.9806 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0688 - accuracy: 0.9772 - val_loss: 0.0050 - val_accuracy: 0.9987\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0459 - accuracy: 0.9842 - val_loss: 3.8056e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0519 - accuracy: 0.9844 - val_loss: 4.1457e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0404 - accuracy: 0.9870 - val_loss: 0.0025 - val_accuracy: 0.9987\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0336 - accuracy: 0.9879 - val_loss: 2.8428e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0480 - accuracy: 0.9833 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0402 - accuracy: 0.9875 - val_loss: 0.0016 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0354 - accuracy: 0.9866 - val_loss: 0.0018 - val_accuracy: 0.9987\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0426 - accuracy: 0.9869 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0349 - accuracy: 0.9897 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0418 - accuracy: 0.9869 - val_loss: 0.0074 - val_accuracy: 0.9973\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0428 - accuracy: 0.9866 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0333 - accuracy: 0.9893 - val_loss: 6.7429e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0329 - accuracy: 0.9906 - val_loss: 9.0689e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0319 - accuracy: 0.9906 - val_loss: 3.2092e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0333 - accuracy: 0.9893 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0344 - accuracy: 0.9900 - val_loss: 0.0019 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0265 - accuracy: 0.9905 - val_loss: 1.7530e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0270 - accuracy: 0.9920 - val_loss: 2.0404e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0287 - accuracy: 0.9900 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0345 - accuracy: 0.9894 - val_loss: 3.8514e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0300 - accuracy: 0.9911 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0316 - accuracy: 0.9909 - val_loss: 0.0018 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0258 - accuracy: 0.9923 - val_loss: 2.0866e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0255 - accuracy: 0.9921 - val_loss: 4.3919e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0302 - accuracy: 0.9897 - val_loss: 3.9075e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0306 - accuracy: 0.9911 - val_loss: 0.0014 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0581 - accuracy: 0.9812 - val_loss: 0.0044 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0323 - accuracy: 0.9902 - val_loss: 0.0032 - val_accuracy: 0.9987\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0236 - accuracy: 0.9933 - val_loss: 9.7868e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0366 - accuracy: 0.9896 - val_loss: 0.0018 - val_accuracy: 0.9987\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0350 - accuracy: 0.9905 - val_loss: 2.5715e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0372 - accuracy: 0.9890 - val_loss: 8.8398e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0244 - accuracy: 0.9915 - val_loss: 2.9388e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0326 - accuracy: 0.9891 - val_loss: 2.5222e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0320 - accuracy: 0.9927 - val_loss: 2.5447e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0239 - accuracy: 0.9914 - val_loss: 8.4840e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0260 - accuracy: 0.9921 - val_loss: 3.0307e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0318 - accuracy: 0.9887 - val_loss: 4.6227e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0307 - accuracy: 0.9906 - val_loss: 5.7691e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0276 - accuracy: 0.9921 - val_loss: 1.5830e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0171 - accuracy: 0.9954 - val_loss: 4.8473e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0212 - accuracy: 0.9939 - val_loss: 9.9216e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0255 - accuracy: 0.9927 - val_loss: 1.7671e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0258 - accuracy: 0.9924 - val_loss: 5.3467e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0287 - accuracy: 0.9905 - val_loss: 1.1509e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0271 - accuracy: 0.9918 - val_loss: 7.2313e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0211 - accuracy: 0.9939 - val_loss: 4.7612e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0259 - accuracy: 0.9920 - val_loss: 5.2545e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0216 - accuracy: 0.9928 - val_loss: 3.9094e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0342 - accuracy: 0.9903 - val_loss: 0.0030 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0231 - accuracy: 0.9918 - val_loss: 5.8119e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0231 - accuracy: 0.9931 - val_loss: 5.9161e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0309 - accuracy: 0.9914 - val_loss: 8.7379e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0278 - accuracy: 0.9925 - val_loss: 4.4799e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0256 - accuracy: 0.9912 - val_loss: 6.3335e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0281 - accuracy: 0.9920 - val_loss: 5.8077e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0282 - accuracy: 0.9909 - val_loss: 8.4128e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 3.1284e-04 - val_accuracy: 1.0000\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0343 - accuracy: 0.9891 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0311 - accuracy: 0.9896 - val_loss: 7.5037e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0257 - accuracy: 0.9918 - val_loss: 4.4851e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0140 - accuracy: 0.9951 - val_loss: 1.6098e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 6.8864e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0178 - accuracy: 0.9946 - val_loss: 5.7380e-06 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0207 - accuracy: 0.9942 - val_loss: 5.8464e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0201 - accuracy: 0.9925 - val_loss: 2.7509e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0294 - accuracy: 0.9914 - val_loss: 4.3810e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0275 - accuracy: 0.9915 - val_loss: 4.5763e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0195 - accuracy: 0.9946 - val_loss: 1.7153e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0184 - accuracy: 0.9933 - val_loss: 6.2611e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0302 - accuracy: 0.9899 - val_loss: 1.5640e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 3.4332e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 5.3741e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0235 - accuracy: 0.9943 - val_loss: 2.6505e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0166 - accuracy: 0.9952 - val_loss: 5.4296e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 5.7450e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0257 - accuracy: 0.9927 - val_loss: 5.1170e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0141 - accuracy: 0.9970 - val_loss: 5.0110e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0149 - accuracy: 0.9948 - val_loss: 2.7000e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0207 - accuracy: 0.9942 - val_loss: 1.0372e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0307 - accuracy: 0.9918 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0191 - accuracy: 0.9945 - val_loss: 4.9163e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0275 - accuracy: 0.9924 - val_loss: 2.9589e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 1.1356e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0144 - accuracy: 0.9952 - val_loss: 6.6311e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0166 - accuracy: 0.9957 - val_loss: 1.5250e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0172 - accuracy: 0.9952 - val_loss: 1.7352e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0123 - accuracy: 0.9955 - val_loss: 6.0083e-05 - val_accuracy: 1.0000\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 48ms/step - loss: 0.0207 - accuracy: 0.9942 - val_loss: 2.0968e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0165 - accuracy: 0.9939 - val_loss: 2.6056e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 3.2548e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0164 - accuracy: 0.9952 - val_loss: 0.0019 - val_accuracy: 0.9987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 1.9623e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0148 - accuracy: 0.9948 - val_loss: 2.1621e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0385 - accuracy: 0.9891 - val_loss: 5.0355e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0192 - accuracy: 0.9943 - val_loss: 1.7584e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 6.8241e-06 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0256 - accuracy: 0.9928 - val_loss: 1.8400e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0100 - accuracy: 0.9964 - val_loss: 2.9261e-06 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0170 - accuracy: 0.9937 - val_loss: 9.1740e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0280 - accuracy: 0.9914 - val_loss: 3.8780e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0142 - accuracy: 0.9963 - val_loss: 1.7148e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0199 - accuracy: 0.9940 - val_loss: 0.0043 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0143 - accuracy: 0.9955 - val_loss: 1.0723e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0165 - accuracy: 0.9952 - val_loss: 5.5734e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 6.0972e-06 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 5.9088e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0163 - accuracy: 0.9940 - val_loss: 3.5384e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0143 - accuracy: 0.9961 - val_loss: 1.2593e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 3.8540e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0189 - accuracy: 0.9945 - val_loss: 6.3236e-06 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 1.5462e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0204 - accuracy: 0.9936 - val_loss: 1.5744e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 6.2675e-06 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0140 - accuracy: 0.9963 - val_loss: 4.7644e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0147 - accuracy: 0.9946 - val_loss: 2.3713e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0157 - accuracy: 0.9943 - val_loss: 2.8821e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0114 - accuracy: 0.9957 - val_loss: 1.3744e-04 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0239 - accuracy: 0.9934 - val_loss: 8.6762e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 2.7348e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 2.5089e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 1.4139e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0085 - accuracy: 0.9978 - val_loss: 9.5999e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 2.4792e-06 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0098 - accuracy: 0.9973 - val_loss: 1.5836e-06 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0250 - accuracy: 0.9918 - val_loss: 2.4156e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 1.3065e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0140 - accuracy: 0.9960 - val_loss: 2.8819e-06 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0171 - accuracy: 0.9948 - val_loss: 6.7438e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0224 - accuracy: 0.9940 - val_loss: 9.8090e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 2.1888e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0141 - accuracy: 0.9949 - val_loss: 3.1054e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0203 - accuracy: 0.9940 - val_loss: 8.2384e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0141 - accuracy: 0.9961 - val_loss: 1.1201e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0153 - accuracy: 0.9964 - val_loss: 0.0073 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0222 - accuracy: 0.9925 - val_loss: 0.0092 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0234 - accuracy: 0.9931 - val_loss: 1.0103e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 3.0188e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 4.6009e-06 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 3.0335e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 2.1182e-06 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0167 - accuracy: 0.9951 - val_loss: 9.0932e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 2.1494e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0154 - accuracy: 0.9957 - val_loss: 5.1955e-06 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 1.9553e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 1.0034e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0163 - accuracy: 0.9957 - val_loss: 0.0030 - val_accuracy: 0.9973\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0196 - accuracy: 0.9948 - val_loss: 1.0380e-05 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0159 - accuracy: 0.9958 - val_loss: 4.0935e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0166 - accuracy: 0.9948 - val_loss: 9.5308e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0320 - accuracy: 0.9912 - val_loss: 1.0320e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 3.2105e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0159 - accuracy: 0.9969 - val_loss: 7.8836e-07 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 2.5708e-06 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 1.1643e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0139 - accuracy: 0.9961 - val_loss: 7.0709e-07 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 3.2887e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 5.5474e-06 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 2.3553e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0140 - accuracy: 0.9955 - val_loss: 1.8701e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 6.4465e-06 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 2.0161e-07 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0161 - accuracy: 0.9958 - val_loss: 2.6719e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0167 - accuracy: 0.9942 - val_loss: 2.9576e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 3.6760e-06 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0136 - accuracy: 0.9960 - val_loss: 3.9632e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0141 - accuracy: 0.9966 - val_loss: 6.5993e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0079 - accuracy: 0.9978 - val_loss: 1.0397e-06 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0129 - accuracy: 0.9952 - val_loss: 3.0076e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0145 - accuracy: 0.9963 - val_loss: 5.1717e-06 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0177 - accuracy: 0.9951 - val_loss: 1.3073e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 3.2750e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 1.1275e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0171 - accuracy: 0.9948 - val_loss: 0.0020 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 1.5926e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 2.9918e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0061 - accuracy: 0.9978 - val_loss: 1.4618e-06 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 1.2532e-04 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0208 - accuracy: 0.9942 - val_loss: 1.1268e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0071 - accuracy: 0.9973 - val_loss: 2.0714e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0129 - accuracy: 0.9976 - val_loss: 1.6728e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0137 - accuracy: 0.9955 - val_loss: 5.3684e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0173 - accuracy: 0.9945 - val_loss: 1.1074e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 1.1051e-06 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 9.1529e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 1.3476e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 1.2718e-06 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0163 - accuracy: 0.9955 - val_loss: 1.7764e-06 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 5.2706e-07 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 7.4752e-07 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 1.1591e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 1.1737e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0145 - accuracy: 0.9961 - val_loss: 7.9095e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0181 - accuracy: 0.9958 - val_loss: 1.0282e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0094 - accuracy: 0.9975 - val_loss: 0.0038 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 6.2126e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0143 - accuracy: 0.9960 - val_loss: 1.0141e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 2.0794e-06 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 6.7538e-06 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 1.5210e-06 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 1.6999e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 3.2888e-06 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0143 - accuracy: 0.9964 - val_loss: 2.9824e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0218 - accuracy: 0.9933 - val_loss: 4.7144e-06 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 4.6684e-06 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 9.2785e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0077 - accuracy: 0.9978 - val_loss: 1.0358e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 1.6783e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "CAnc2SJa3o9f",
        "outputId": "4e566791-8b1a-430c-8376-800e790004e2"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 7ms/step - loss: 0.0437 - accuracy: 0.9936\n",
            "Accuracy  : 0.9935622215270996\n",
            "F1_Score  : 0.9923790259523808\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7fcxLuwZpkK",
        "outputId": "fbef6e65-4e7f-4406-e2cb-b4091ff1b223"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "f6222c41-0ea1-4a23-ae4c-747cfa8d6735"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 52ms/step - loss: 1.1981 - accuracy: 0.4219 - val_loss: 1.0735 - val_accuracy: 0.4625\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0627 - accuracy: 0.4801 - val_loss: 1.0668 - val_accuracy: 0.4625\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0623 - accuracy: 0.4686 - val_loss: 1.0623 - val_accuracy: 0.4625\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0615 - accuracy: 0.4806 - val_loss: 1.0615 - val_accuracy: 0.4625\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0583 - accuracy: 0.4800 - val_loss: 1.0573 - val_accuracy: 0.4625\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0523 - accuracy: 0.4823 - val_loss: 1.0587 - val_accuracy: 0.4625\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0506 - accuracy: 0.4865 - val_loss: 1.0585 - val_accuracy: 0.4625\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0458 - accuracy: 0.4873 - val_loss: 1.0552 - val_accuracy: 0.4625\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0496 - accuracy: 0.4775 - val_loss: 1.0544 - val_accuracy: 0.4625\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0419 - accuracy: 0.4771 - val_loss: 1.0517 - val_accuracy: 0.4625\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0496 - accuracy: 0.4735 - val_loss: 1.0511 - val_accuracy: 0.4625\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0483 - accuracy: 0.4736 - val_loss: 1.0478 - val_accuracy: 0.4625\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0397 - accuracy: 0.4809 - val_loss: 1.0456 - val_accuracy: 0.4625\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0342 - accuracy: 0.4811 - val_loss: 1.0445 - val_accuracy: 0.4625\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0250 - accuracy: 0.4911 - val_loss: 1.0426 - val_accuracy: 0.4638\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0380 - accuracy: 0.4798 - val_loss: 1.0541 - val_accuracy: 0.4651\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0326 - accuracy: 0.4863 - val_loss: 1.0399 - val_accuracy: 0.4651\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0286 - accuracy: 0.4860 - val_loss: 1.0468 - val_accuracy: 0.4625\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0166 - accuracy: 0.4956 - val_loss: 1.0275 - val_accuracy: 0.4705\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0211 - accuracy: 0.4924 - val_loss: 1.0380 - val_accuracy: 0.4678\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0122 - accuracy: 0.4993 - val_loss: 1.0382 - val_accuracy: 0.4718\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0103 - accuracy: 0.4976 - val_loss: 1.0048 - val_accuracy: 0.4906\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0081 - accuracy: 0.4981 - val_loss: 1.0139 - val_accuracy: 0.4692\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9937 - accuracy: 0.5041 - val_loss: 1.0154 - val_accuracy: 0.4718\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9927 - accuracy: 0.5073 - val_loss: 1.0031 - val_accuracy: 0.4732\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9950 - accuracy: 0.5032 - val_loss: 1.0182 - val_accuracy: 0.4732\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9836 - accuracy: 0.5119 - val_loss: 0.9575 - val_accuracy: 0.4906\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9798 - accuracy: 0.5166 - val_loss: 0.9837 - val_accuracy: 0.4893\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9775 - accuracy: 0.5115 - val_loss: 0.9631 - val_accuracy: 0.5013\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9581 - accuracy: 0.5297 - val_loss: 1.0076 - val_accuracy: 0.4786\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9612 - accuracy: 0.5186 - val_loss: 0.9231 - val_accuracy: 0.5590\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9542 - accuracy: 0.5222 - val_loss: 0.9081 - val_accuracy: 0.5657\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9363 - accuracy: 0.5325 - val_loss: 0.9030 - val_accuracy: 0.5938\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9308 - accuracy: 0.5301 - val_loss: 0.8850 - val_accuracy: 0.6099\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9159 - accuracy: 0.5440 - val_loss: 0.8571 - val_accuracy: 0.6153\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9079 - accuracy: 0.5455 - val_loss: 0.8507 - val_accuracy: 0.5965\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8885 - accuracy: 0.5493 - val_loss: 0.8824 - val_accuracy: 0.5871\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8841 - accuracy: 0.5648 - val_loss: 0.8938 - val_accuracy: 0.5697\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8867 - accuracy: 0.5641 - val_loss: 0.8518 - val_accuracy: 0.5845\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8493 - accuracy: 0.5814 - val_loss: 0.8095 - val_accuracy: 0.6528\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8531 - accuracy: 0.5772 - val_loss: 0.8365 - val_accuracy: 0.5818\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8219 - accuracy: 0.5955 - val_loss: 0.8130 - val_accuracy: 0.6206\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8088 - accuracy: 0.6124 - val_loss: 0.8274 - val_accuracy: 0.6287\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7877 - accuracy: 0.6244 - val_loss: 0.7767 - val_accuracy: 0.6327\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7657 - accuracy: 0.6389 - val_loss: 0.7509 - val_accuracy: 0.6542\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7216 - accuracy: 0.6584 - val_loss: 0.7576 - val_accuracy: 0.6689\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7124 - accuracy: 0.6705 - val_loss: 0.6836 - val_accuracy: 0.6971\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6880 - accuracy: 0.6835 - val_loss: 0.7121 - val_accuracy: 0.6595\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6656 - accuracy: 0.7048 - val_loss: 0.6717 - val_accuracy: 0.7011\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6245 - accuracy: 0.7240 - val_loss: 0.6490 - val_accuracy: 0.7131\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6061 - accuracy: 0.7392 - val_loss: 0.6998 - val_accuracy: 0.7091\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5649 - accuracy: 0.7660 - val_loss: 0.5419 - val_accuracy: 0.7735\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5037 - accuracy: 0.7930 - val_loss: 0.5715 - val_accuracy: 0.7574\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4601 - accuracy: 0.8173 - val_loss: 0.4534 - val_accuracy: 0.8217\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4442 - accuracy: 0.8179 - val_loss: 0.5285 - val_accuracy: 0.7962\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3936 - accuracy: 0.8501 - val_loss: 0.4205 - val_accuracy: 0.8284\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3657 - accuracy: 0.8639 - val_loss: 0.3887 - val_accuracy: 0.8391\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3300 - accuracy: 0.8824 - val_loss: 0.4102 - val_accuracy: 0.8271\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3337 - accuracy: 0.8718 - val_loss: 0.3183 - val_accuracy: 0.8753\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2918 - accuracy: 0.8937 - val_loss: 0.3716 - val_accuracy: 0.8566\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2902 - accuracy: 0.8967 - val_loss: 0.0861 - val_accuracy: 0.9759\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2495 - accuracy: 0.9094 - val_loss: 0.0822 - val_accuracy: 0.9732\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2213 - accuracy: 0.9215 - val_loss: 0.0595 - val_accuracy: 0.9853\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2141 - accuracy: 0.9270 - val_loss: 0.0655 - val_accuracy: 0.9866\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2196 - accuracy: 0.9218 - val_loss: 0.0693 - val_accuracy: 0.9826\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2122 - accuracy: 0.9297 - val_loss: 0.0731 - val_accuracy: 0.9745\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1595 - accuracy: 0.9455 - val_loss: 0.0529 - val_accuracy: 0.9853\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1696 - accuracy: 0.9419 - val_loss: 0.0629 - val_accuracy: 0.9799\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1656 - accuracy: 0.9413 - val_loss: 0.0515 - val_accuracy: 0.9839\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1502 - accuracy: 0.9481 - val_loss: 0.0383 - val_accuracy: 0.9893\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1291 - accuracy: 0.9587 - val_loss: 0.0525 - val_accuracy: 0.9839\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1179 - accuracy: 0.9624 - val_loss: 0.0364 - val_accuracy: 0.9853\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1148 - accuracy: 0.9599 - val_loss: 0.0439 - val_accuracy: 0.9853\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1094 - accuracy: 0.9630 - val_loss: 0.0362 - val_accuracy: 0.9879\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0958 - accuracy: 0.9660 - val_loss: 0.0400 - val_accuracy: 0.9826\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1036 - accuracy: 0.9641 - val_loss: 0.0272 - val_accuracy: 0.9893\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0907 - accuracy: 0.9694 - val_loss: 0.0337 - val_accuracy: 0.9879\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0858 - accuracy: 0.9723 - val_loss: 0.0274 - val_accuracy: 0.9866\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1033 - accuracy: 0.9657 - val_loss: 0.0491 - val_accuracy: 0.9745\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1038 - accuracy: 0.9669 - val_loss: 0.0451 - val_accuracy: 0.9826\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0866 - accuracy: 0.9714 - val_loss: 0.0554 - val_accuracy: 0.9812\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0938 - accuracy: 0.9705 - val_loss: 0.0537 - val_accuracy: 0.9839\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0916 - accuracy: 0.9692 - val_loss: 0.0583 - val_accuracy: 0.9799\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0926 - accuracy: 0.9735 - val_loss: 0.0255 - val_accuracy: 0.9920\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0679 - accuracy: 0.9785 - val_loss: 0.0382 - val_accuracy: 0.9866\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0724 - accuracy: 0.9766 - val_loss: 0.0227 - val_accuracy: 0.9906\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0635 - accuracy: 0.9812 - val_loss: 0.0301 - val_accuracy: 0.9853\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0645 - accuracy: 0.9799 - val_loss: 0.0428 - val_accuracy: 0.9826\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 47ms/step - loss: 0.0603 - accuracy: 0.9811 - val_loss: 0.0208 - val_accuracy: 0.9933\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0587 - accuracy: 0.9814 - val_loss: 0.0461 - val_accuracy: 0.9799\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0745 - accuracy: 0.9790 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0576 - accuracy: 0.9814 - val_loss: 4.4999e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0659 - accuracy: 0.9779 - val_loss: 8.0233e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0660 - accuracy: 0.9785 - val_loss: 8.8397e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0529 - accuracy: 0.9844 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0783 - accuracy: 0.9769 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0565 - accuracy: 0.9794 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0658 - accuracy: 0.9775 - val_loss: 5.3550e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0520 - accuracy: 0.9845 - val_loss: 8.2728e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0514 - accuracy: 0.9858 - val_loss: 9.9960e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0445 - accuracy: 0.9858 - val_loss: 0.0059 - val_accuracy: 0.9973\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0533 - accuracy: 0.9808 - val_loss: 0.0027 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0451 - accuracy: 0.9855 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0522 - accuracy: 0.9832 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0441 - accuracy: 0.9846 - val_loss: 0.0038 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0520 - accuracy: 0.9820 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0576 - accuracy: 0.9793 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0420 - accuracy: 0.9867 - val_loss: 5.7560e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0558 - accuracy: 0.9824 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0481 - accuracy: 0.9846 - val_loss: 4.2134e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0319 - accuracy: 0.9902 - val_loss: 3.4434e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0443 - accuracy: 0.9857 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0454 - accuracy: 0.9857 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0372 - accuracy: 0.9876 - val_loss: 7.9277e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0389 - accuracy: 0.9876 - val_loss: 0.0035 - val_accuracy: 0.9973\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0431 - accuracy: 0.9870 - val_loss: 0.0020 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0375 - accuracy: 0.9882 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0328 - accuracy: 0.9894 - val_loss: 0.0078 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0383 - accuracy: 0.9885 - val_loss: 8.6052e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0418 - accuracy: 0.9869 - val_loss: 4.3911e-04 - val_accuracy: 1.0000\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0306 - accuracy: 0.9906 - val_loss: 1.6964e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0562 - accuracy: 0.9814 - val_loss: 6.8179e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0436 - accuracy: 0.9854 - val_loss: 1.3682e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0376 - accuracy: 0.9884 - val_loss: 1.9809e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0513 - accuracy: 0.9830 - val_loss: 2.3376e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0386 - accuracy: 0.9869 - val_loss: 5.7826e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0400 - accuracy: 0.9876 - val_loss: 1.7302e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0352 - accuracy: 0.9891 - val_loss: 6.0948e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0559 - accuracy: 0.9829 - val_loss: 1.1087e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0318 - accuracy: 0.9902 - val_loss: 3.1325e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0340 - accuracy: 0.9884 - val_loss: 1.4904e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0346 - accuracy: 0.9888 - val_loss: 1.3138e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0269 - accuracy: 0.9915 - val_loss: 4.2722e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0264 - accuracy: 0.9928 - val_loss: 1.4362e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0299 - accuracy: 0.9908 - val_loss: 7.4195e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0365 - accuracy: 0.9897 - val_loss: 5.5662e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0341 - accuracy: 0.9912 - val_loss: 0.0080 - val_accuracy: 0.9973\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0314 - accuracy: 0.9902 - val_loss: 3.3384e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0302 - accuracy: 0.9917 - val_loss: 1.9930e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0321 - accuracy: 0.9902 - val_loss: 4.4610e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0375 - accuracy: 0.9879 - val_loss: 5.6001e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0331 - accuracy: 0.9902 - val_loss: 3.1533e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0323 - accuracy: 0.9879 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0398 - accuracy: 0.9881 - val_loss: 2.8407e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0371 - accuracy: 0.9897 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0285 - accuracy: 0.9914 - val_loss: 0.0023 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0278 - accuracy: 0.9893 - val_loss: 8.7125e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0335 - accuracy: 0.9903 - val_loss: 1.0413e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0302 - accuracy: 0.9900 - val_loss: 2.2855e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0333 - accuracy: 0.9905 - val_loss: 5.3255e-04 - val_accuracy: 1.0000\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0381 - accuracy: 0.9866 - val_loss: 5.2075e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0350 - accuracy: 0.9894 - val_loss: 3.8334e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0287 - accuracy: 0.9906 - val_loss: 1.1452e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0257 - accuracy: 0.9933 - val_loss: 2.9580e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0256 - accuracy: 0.9923 - val_loss: 7.9299e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0332 - accuracy: 0.9900 - val_loss: 1.7775e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0254 - accuracy: 0.9925 - val_loss: 3.8517e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0235 - accuracy: 0.9924 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0332 - accuracy: 0.9884 - val_loss: 2.1998e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0267 - accuracy: 0.9912 - val_loss: 6.7896e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0277 - accuracy: 0.9921 - val_loss: 8.5084e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0408 - accuracy: 0.9876 - val_loss: 7.6471e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0326 - accuracy: 0.9911 - val_loss: 1.9735e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0276 - accuracy: 0.9894 - val_loss: 1.7175e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0445 - accuracy: 0.9864 - val_loss: 9.8092e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0315 - accuracy: 0.9905 - val_loss: 7.3279e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0196 - accuracy: 0.9934 - val_loss: 2.2265e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0210 - accuracy: 0.9936 - val_loss: 7.9388e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0312 - accuracy: 0.9908 - val_loss: 3.7071e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0304 - accuracy: 0.9911 - val_loss: 1.5855e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0240 - accuracy: 0.9923 - val_loss: 3.6880e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0285 - accuracy: 0.9912 - val_loss: 8.1475e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0229 - accuracy: 0.9928 - val_loss: 4.4441e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0241 - accuracy: 0.9921 - val_loss: 3.5882e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0214 - accuracy: 0.9939 - val_loss: 2.9715e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0189 - accuracy: 0.9931 - val_loss: 1.1040e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0158 - accuracy: 0.9949 - val_loss: 0.0078 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0217 - accuracy: 0.9936 - val_loss: 0.0015 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0293 - accuracy: 0.9918 - val_loss: 5.8108e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 4.4826e-05 - val_accuracy: 1.0000\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0220 - accuracy: 0.9924 - val_loss: 6.0777e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0293 - accuracy: 0.9911 - val_loss: 2.0684e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0233 - accuracy: 0.9924 - val_loss: 3.6525e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0266 - accuracy: 0.9915 - val_loss: 1.8907e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0314 - accuracy: 0.9902 - val_loss: 1.3086e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0284 - accuracy: 0.9908 - val_loss: 3.5769e-06 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0234 - accuracy: 0.9931 - val_loss: 4.4486e-06 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0155 - accuracy: 0.9945 - val_loss: 2.9737e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0323 - accuracy: 0.9902 - val_loss: 1.7925e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0277 - accuracy: 0.9906 - val_loss: 1.2634e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0223 - accuracy: 0.9925 - val_loss: 1.3344e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0300 - accuracy: 0.9900 - val_loss: 9.1028e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0345 - accuracy: 0.9890 - val_loss: 1.0722e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0201 - accuracy: 0.9942 - val_loss: 1.1027e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 1.0977e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0342 - accuracy: 0.9897 - val_loss: 5.0335e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0202 - accuracy: 0.9936 - val_loss: 1.0526e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 5.4729e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0174 - accuracy: 0.9942 - val_loss: 5.2419e-06 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0174 - accuracy: 0.9949 - val_loss: 4.1762e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0240 - accuracy: 0.9928 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0349 - accuracy: 0.9903 - val_loss: 9.6095e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0227 - accuracy: 0.9915 - val_loss: 1.7303e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0111 - accuracy: 0.9960 - val_loss: 2.5357e-06 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0141 - accuracy: 0.9949 - val_loss: 0.0013 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0278 - accuracy: 0.9902 - val_loss: 1.3514e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0278 - accuracy: 0.9914 - val_loss: 4.4170e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0250 - accuracy: 0.9927 - val_loss: 2.8368e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0240 - accuracy: 0.9934 - val_loss: 1.9265e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 8.9299e-06 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0237 - accuracy: 0.9927 - val_loss: 1.0704e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0226 - accuracy: 0.9915 - val_loss: 7.6507e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0190 - accuracy: 0.9942 - val_loss: 1.5581e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0203 - accuracy: 0.9934 - val_loss: 6.6872e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0178 - accuracy: 0.9945 - val_loss: 4.9820e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0244 - accuracy: 0.9930 - val_loss: 5.9260e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0249 - accuracy: 0.9927 - val_loss: 1.1709e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 7.9126e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0209 - accuracy: 0.9931 - val_loss: 7.2250e-06 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0197 - accuracy: 0.9946 - val_loss: 2.1649e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 8.5794e-06 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0271 - accuracy: 0.9925 - val_loss: 5.8082e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0265 - accuracy: 0.9917 - val_loss: 6.2880e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0214 - accuracy: 0.9934 - val_loss: 4.8241e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0245 - accuracy: 0.9917 - val_loss: 8.3090e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0254 - accuracy: 0.9923 - val_loss: 1.2480e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0208 - accuracy: 0.9942 - val_loss: 3.6699e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0172 - accuracy: 0.9937 - val_loss: 3.3231e-06 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0228 - accuracy: 0.9933 - val_loss: 0.0020 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0230 - accuracy: 0.9927 - val_loss: 8.5395e-06 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 4.0996e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 1.3489e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0138 - accuracy: 0.9952 - val_loss: 1.8756e-06 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0097 - accuracy: 0.9973 - val_loss: 2.7992e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0178 - accuracy: 0.9945 - val_loss: 1.7290e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 4.2802e-06 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0272 - accuracy: 0.9925 - val_loss: 1.9084e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0155 - accuracy: 0.9948 - val_loss: 5.5934e-06 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 6.3034e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0304 - accuracy: 0.9920 - val_loss: 0.0077 - val_accuracy: 0.9960\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0291 - accuracy: 0.9925 - val_loss: 3.6692e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0218 - accuracy: 0.9948 - val_loss: 1.3693e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0237 - accuracy: 0.9923 - val_loss: 2.2037e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0272 - accuracy: 0.9920 - val_loss: 6.5871e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0195 - accuracy: 0.9942 - val_loss: 7.6642e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0240 - accuracy: 0.9925 - val_loss: 2.8482e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0155 - accuracy: 0.9943 - val_loss: 8.5973e-07 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0173 - accuracy: 0.9949 - val_loss: 6.8921e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0199 - accuracy: 0.9931 - val_loss: 5.1706e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0139 - accuracy: 0.9954 - val_loss: 4.4167e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0104 - accuracy: 0.9964 - val_loss: 6.0850e-06 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0190 - accuracy: 0.9945 - val_loss: 2.9787e-06 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0206 - accuracy: 0.9939 - val_loss: 1.6690e-06 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 1.9664e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0182 - accuracy: 0.9945 - val_loss: 8.5226e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0223 - accuracy: 0.9937 - val_loss: 5.3933e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0175 - accuracy: 0.9937 - val_loss: 1.4208e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 2.2075e-06 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0179 - accuracy: 0.9957 - val_loss: 6.3074e-06 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0156 - accuracy: 0.9958 - val_loss: 8.7955e-06 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 9.7102e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0178 - accuracy: 0.9936 - val_loss: 5.9643e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0180 - accuracy: 0.9949 - val_loss: 3.4647e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0152 - accuracy: 0.9961 - val_loss: 5.9474e-06 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0184 - accuracy: 0.9948 - val_loss: 8.2481e-06 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0200 - accuracy: 0.9928 - val_loss: 5.5476e-06 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0189 - accuracy: 0.9930 - val_loss: 1.6243e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0135 - accuracy: 0.9964 - val_loss: 6.3576e-06 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0255 - accuracy: 0.9937 - val_loss: 2.1032e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0208 - accuracy: 0.9940 - val_loss: 2.5287e-05 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0162 - accuracy: 0.9958 - val_loss: 7.9300e-07 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0145 - accuracy: 0.9960 - val_loss: 3.1778e-07 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 2.3160e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 6.4339e-07 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 1.8721e-07 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0156 - accuracy: 0.9948 - val_loss: 1.2405e-06 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 1.9449e-06 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0197 - accuracy: 0.9940 - val_loss: 1.0811e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0195 - accuracy: 0.9949 - val_loss: 5.4163e-07 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0120 - accuracy: 0.9955 - val_loss: 3.1042e-07 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0150 - accuracy: 0.9958 - val_loss: 8.5901e-07 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 1.8273e-07 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0272 - accuracy: 0.9921 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0237 - accuracy: 0.9937 - val_loss: 1.8467e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0172 - accuracy: 0.9937 - val_loss: 2.2341e-06 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 6.5798e-06 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 2.7687e-06 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0182 - accuracy: 0.9952 - val_loss: 9.3727e-06 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0151 - accuracy: 0.9940 - val_loss: 1.5315e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 0.0023 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0224 - accuracy: 0.9930 - val_loss: 4.3564e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 1.2115e-06 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0172 - accuracy: 0.9945 - val_loss: 3.3515e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0105 - accuracy: 0.9978 - val_loss: 2.9130e-06 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0172 - accuracy: 0.9931 - val_loss: 2.5522e-06 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0209 - accuracy: 0.9939 - val_loss: 6.2254e-06 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0165 - accuracy: 0.9966 - val_loss: 1.7712e-06 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0156 - accuracy: 0.9966 - val_loss: 3.2549e-06 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 1.3021e-06 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0142 - accuracy: 0.9960 - val_loss: 5.2931e-06 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "b0134524-03dc-4192-dc6e-75aa6fda0288"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 7ms/step - loss: 0.0193 - accuracy: 0.9925\n",
            "Accuracy  : 0.9924892783164978\n",
            "F1_Score  : 0.9917753131277448\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}