{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub19_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "dba56556-6cc6-4215-a9ad-ea4a08663a60"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e5\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  #EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "de7cb941-2ef6-4d29-eac2-e8671d0fcd14"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(19,20):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.19\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (2796,) (2796,) (3728,)\n",
            "(9320,) (2563,) (2563,) (4194,)\n",
            "(9320,) (2563,) (4660,) (2097,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "63f8ce6b-f9b8-4d92-f302-037971179d17"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "5fe572e4-1a29-4ea4-fe95-209627b75d7c"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "547"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "67655e54-ca70-4507-d74f-ffd39689d50b"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8335d227-db7a-4418-a89f-e89791a29b3b"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 20s 59ms/step - loss: 1.1726 - accuracy: 0.4073 - val_loss: 1.1205 - val_accuracy: 0.4021\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0773 - accuracy: 0.4257 - val_loss: 1.0675 - val_accuracy: 0.4088\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0772 - accuracy: 0.4240 - val_loss: 1.0584 - val_accuracy: 0.4397\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0751 - accuracy: 0.4386 - val_loss: 1.0645 - val_accuracy: 0.4504\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0678 - accuracy: 0.4411 - val_loss: 1.0711 - val_accuracy: 0.4249\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0663 - accuracy: 0.4464 - val_loss: 1.0697 - val_accuracy: 0.4316\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0708 - accuracy: 0.4204 - val_loss: 1.0618 - val_accuracy: 0.4343\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0637 - accuracy: 0.4393 - val_loss: 1.1064 - val_accuracy: 0.3271\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0635 - accuracy: 0.4345 - val_loss: 1.0544 - val_accuracy: 0.4397\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0644 - accuracy: 0.4414 - val_loss: 1.0714 - val_accuracy: 0.4142\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0602 - accuracy: 0.4411 - val_loss: 1.1305 - val_accuracy: 0.3298\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0590 - accuracy: 0.4524 - val_loss: 1.0625 - val_accuracy: 0.4383\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0585 - accuracy: 0.4371 - val_loss: 1.0793 - val_accuracy: 0.4075\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0469 - accuracy: 0.4675 - val_loss: 1.0854 - val_accuracy: 0.4048\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0415 - accuracy: 0.4798 - val_loss: 1.0551 - val_accuracy: 0.4491\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0408 - accuracy: 0.4650 - val_loss: 1.0352 - val_accuracy: 0.4437\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0492 - accuracy: 0.4576 - val_loss: 1.0379 - val_accuracy: 0.4531\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0475 - accuracy: 0.4648 - val_loss: 1.0479 - val_accuracy: 0.4571\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0391 - accuracy: 0.4805 - val_loss: 1.0520 - val_accuracy: 0.4383\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0307 - accuracy: 0.4616 - val_loss: 1.0319 - val_accuracy: 0.4410\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 39ms/step - loss: 1.0309 - accuracy: 0.4696 - val_loss: 1.0311 - val_accuracy: 0.4598\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0250 - accuracy: 0.4812 - val_loss: 1.0226 - val_accuracy: 0.4464\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0282 - accuracy: 0.4732 - val_loss: 1.0253 - val_accuracy: 0.4236\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0180 - accuracy: 0.4723 - val_loss: 1.0222 - val_accuracy: 0.4531\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0300 - accuracy: 0.4655 - val_loss: 1.0268 - val_accuracy: 0.4410\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0142 - accuracy: 0.4740 - val_loss: 1.0028 - val_accuracy: 0.4678\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9975 - accuracy: 0.5002 - val_loss: 0.9880 - val_accuracy: 0.4705\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9927 - accuracy: 0.4928 - val_loss: 0.9780 - val_accuracy: 0.4786\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9776 - accuracy: 0.5002 - val_loss: 0.9902 - val_accuracy: 0.4812\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9829 - accuracy: 0.4897 - val_loss: 0.9827 - val_accuracy: 0.4651\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9733 - accuracy: 0.4984 - val_loss: 0.9615 - val_accuracy: 0.4906\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9778 - accuracy: 0.4897 - val_loss: 0.9600 - val_accuracy: 0.5442\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9750 - accuracy: 0.4987 - val_loss: 0.9499 - val_accuracy: 0.5094\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9574 - accuracy: 0.5018 - val_loss: 0.9517 - val_accuracy: 0.5201\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9524 - accuracy: 0.5136 - val_loss: 0.9347 - val_accuracy: 0.5335\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9573 - accuracy: 0.5045 - val_loss: 0.9334 - val_accuracy: 0.5362\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9363 - accuracy: 0.5268 - val_loss: 0.9180 - val_accuracy: 0.5362\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9208 - accuracy: 0.5432 - val_loss: 0.9161 - val_accuracy: 0.5375\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9253 - accuracy: 0.5362 - val_loss: 0.9082 - val_accuracy: 0.5389\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9122 - accuracy: 0.5502 - val_loss: 0.8994 - val_accuracy: 0.5402\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8996 - accuracy: 0.5636 - val_loss: 0.9368 - val_accuracy: 0.5080\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8925 - accuracy: 0.5680 - val_loss: 0.8905 - val_accuracy: 0.5375\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.8674 - accuracy: 0.5784 - val_loss: 0.8594 - val_accuracy: 0.5710\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.8683 - accuracy: 0.5790 - val_loss: 0.8684 - val_accuracy: 0.5509\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.8429 - accuracy: 0.5972 - val_loss: 0.8635 - val_accuracy: 0.5483\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.8295 - accuracy: 0.6092 - val_loss: 0.8428 - val_accuracy: 0.5697\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.8197 - accuracy: 0.6210 - val_loss: 0.8287 - val_accuracy: 0.5871\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8000 - accuracy: 0.6274 - val_loss: 0.8375 - val_accuracy: 0.5965\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7918 - accuracy: 0.6276 - val_loss: 0.8382 - val_accuracy: 0.5764\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7632 - accuracy: 0.6490 - val_loss: 0.8091 - val_accuracy: 0.6220\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7725 - accuracy: 0.6472 - val_loss: 0.7952 - val_accuracy: 0.6059\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7244 - accuracy: 0.6715 - val_loss: 0.7605 - val_accuracy: 0.6434\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7295 - accuracy: 0.6776 - val_loss: 0.8580 - val_accuracy: 0.5737\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7051 - accuracy: 0.6869 - val_loss: 0.8789 - val_accuracy: 0.5643\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.6762 - accuracy: 0.6976 - val_loss: 0.7753 - val_accuracy: 0.6340\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6728 - accuracy: 0.7018 - val_loss: 0.8176 - val_accuracy: 0.6139\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6439 - accuracy: 0.7179 - val_loss: 0.7299 - val_accuracy: 0.6622\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6144 - accuracy: 0.7370 - val_loss: 0.7347 - val_accuracy: 0.6890\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5918 - accuracy: 0.7492 - val_loss: 0.8547 - val_accuracy: 0.6233\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6001 - accuracy: 0.7411 - val_loss: 0.6811 - val_accuracy: 0.6944\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5933 - accuracy: 0.7484 - val_loss: 0.3757 - val_accuracy: 0.8418\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5604 - accuracy: 0.7659 - val_loss: 0.3773 - val_accuracy: 0.8458\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.5489 - accuracy: 0.7772 - val_loss: 0.4893 - val_accuracy: 0.7909\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5134 - accuracy: 0.7939 - val_loss: 0.3311 - val_accuracy: 0.8807\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4952 - accuracy: 0.7909 - val_loss: 0.3599 - val_accuracy: 0.8485\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4759 - accuracy: 0.8067 - val_loss: 0.2978 - val_accuracy: 0.8820\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4697 - accuracy: 0.8076 - val_loss: 0.3494 - val_accuracy: 0.8472\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4233 - accuracy: 0.8307 - val_loss: 0.2750 - val_accuracy: 0.8941\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4131 - accuracy: 0.8352 - val_loss: 0.2751 - val_accuracy: 0.8928\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3917 - accuracy: 0.8484 - val_loss: 0.2546 - val_accuracy: 0.8874\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3751 - accuracy: 0.8557 - val_loss: 0.2244 - val_accuracy: 0.9155\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3680 - accuracy: 0.8560 - val_loss: 0.2685 - val_accuracy: 0.8794\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3461 - accuracy: 0.8671 - val_loss: 0.2251 - val_accuracy: 0.9021\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3073 - accuracy: 0.8799 - val_loss: 0.2096 - val_accuracy: 0.9142\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3114 - accuracy: 0.8809 - val_loss: 0.2490 - val_accuracy: 0.8981\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3210 - accuracy: 0.8779 - val_loss: 0.2025 - val_accuracy: 0.9115\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2790 - accuracy: 0.8957 - val_loss: 0.1807 - val_accuracy: 0.9303\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2593 - accuracy: 0.9025 - val_loss: 0.1796 - val_accuracy: 0.9343\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2650 - accuracy: 0.9030 - val_loss: 0.1931 - val_accuracy: 0.9330\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2285 - accuracy: 0.9179 - val_loss: 0.1833 - val_accuracy: 0.9263\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2378 - accuracy: 0.9130 - val_loss: 0.2080 - val_accuracy: 0.9169\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2268 - accuracy: 0.9185 - val_loss: 0.1801 - val_accuracy: 0.9196\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2276 - accuracy: 0.9200 - val_loss: 0.1818 - val_accuracy: 0.9370\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2018 - accuracy: 0.9294 - val_loss: 0.1417 - val_accuracy: 0.9517\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1792 - accuracy: 0.9371 - val_loss: 0.1503 - val_accuracy: 0.9424\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1868 - accuracy: 0.9361 - val_loss: 0.1364 - val_accuracy: 0.9437\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1855 - accuracy: 0.9308 - val_loss: 0.1877 - val_accuracy: 0.9290\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1665 - accuracy: 0.9420 - val_loss: 0.1458 - val_accuracy: 0.9450\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1699 - accuracy: 0.9425 - val_loss: 0.1411 - val_accuracy: 0.9517\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1508 - accuracy: 0.9496 - val_loss: 0.1531 - val_accuracy: 0.9450\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1894 - accuracy: 0.9325 - val_loss: 0.0258 - val_accuracy: 0.9960\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.1691 - accuracy: 0.9456 - val_loss: 0.0129 - val_accuracy: 0.9973\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1540 - accuracy: 0.9466 - val_loss: 0.0202 - val_accuracy: 0.9987\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1673 - accuracy: 0.9441 - val_loss: 0.0193 - val_accuracy: 0.9960\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1558 - accuracy: 0.9450 - val_loss: 0.0123 - val_accuracy: 0.9987\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1327 - accuracy: 0.9538 - val_loss: 0.0179 - val_accuracy: 0.9946\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1443 - accuracy: 0.9507 - val_loss: 0.0133 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1310 - accuracy: 0.9565 - val_loss: 0.0112 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1288 - accuracy: 0.9563 - val_loss: 0.0149 - val_accuracy: 0.9973\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1232 - accuracy: 0.9601 - val_loss: 0.0109 - val_accuracy: 0.9973\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1362 - accuracy: 0.9553 - val_loss: 0.0411 - val_accuracy: 0.9893\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1197 - accuracy: 0.9595 - val_loss: 0.0106 - val_accuracy: 0.9973\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1185 - accuracy: 0.9623 - val_loss: 0.0237 - val_accuracy: 0.9933\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1065 - accuracy: 0.9642 - val_loss: 0.0121 - val_accuracy: 0.9960\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1094 - accuracy: 0.9642 - val_loss: 0.0136 - val_accuracy: 0.9960\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0946 - accuracy: 0.9706 - val_loss: 0.0127 - val_accuracy: 0.9973\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1198 - accuracy: 0.9627 - val_loss: 0.0095 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0935 - accuracy: 0.9689 - val_loss: 0.0131 - val_accuracy: 0.9960\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1090 - accuracy: 0.9615 - val_loss: 0.0379 - val_accuracy: 0.9906\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1025 - accuracy: 0.9653 - val_loss: 0.0190 - val_accuracy: 0.9946\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1061 - accuracy: 0.9681 - val_loss: 0.0226 - val_accuracy: 0.9920\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0862 - accuracy: 0.9711 - val_loss: 0.0122 - val_accuracy: 0.9973\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0780 - accuracy: 0.9739 - val_loss: 0.0445 - val_accuracy: 0.9826\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1080 - accuracy: 0.9648 - val_loss: 0.0186 - val_accuracy: 0.9920\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0756 - accuracy: 0.9753 - val_loss: 0.0088 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0888 - accuracy: 0.9709 - val_loss: 0.0152 - val_accuracy: 0.9973\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0918 - accuracy: 0.9669 - val_loss: 0.0144 - val_accuracy: 0.9946\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0883 - accuracy: 0.9714 - val_loss: 0.0191 - val_accuracy: 0.9946\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0877 - accuracy: 0.9736 - val_loss: 0.0098 - val_accuracy: 0.9973\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0689 - accuracy: 0.9785 - val_loss: 0.0115 - val_accuracy: 0.9946\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0923 - accuracy: 0.9683 - val_loss: 4.8432e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0938 - accuracy: 0.9696 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0906 - accuracy: 0.9721 - val_loss: 7.7177e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0786 - accuracy: 0.9738 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0755 - accuracy: 0.9748 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0854 - accuracy: 0.9726 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0688 - accuracy: 0.9768 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0795 - accuracy: 0.9753 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0778 - accuracy: 0.9762 - val_loss: 9.4446e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0723 - accuracy: 0.9778 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0800 - accuracy: 0.9739 - val_loss: 0.0031 - val_accuracy: 0.9987\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0756 - accuracy: 0.9747 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0523 - accuracy: 0.9835 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0589 - accuracy: 0.9814 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0499 - accuracy: 0.9844 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0701 - accuracy: 0.9782 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0549 - accuracy: 0.9820 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0631 - accuracy: 0.9796 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0682 - accuracy: 0.9781 - val_loss: 0.0025 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0609 - accuracy: 0.9809 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0581 - accuracy: 0.9806 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0587 - accuracy: 0.9833 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0530 - accuracy: 0.9809 - val_loss: 0.0032 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0631 - accuracy: 0.9829 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0612 - accuracy: 0.9814 - val_loss: 0.0127 - val_accuracy: 0.9973\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0606 - accuracy: 0.9818 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0486 - accuracy: 0.9852 - val_loss: 0.0076 - val_accuracy: 0.9960\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0525 - accuracy: 0.9841 - val_loss: 7.9711e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0557 - accuracy: 0.9826 - val_loss: 0.0024 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0594 - accuracy: 0.9808 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0596 - accuracy: 0.9805 - val_loss: 1.0241e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0618 - accuracy: 0.9794 - val_loss: 6.0981e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0636 - accuracy: 0.9788 - val_loss: 3.3470e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0542 - accuracy: 0.9818 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0571 - accuracy: 0.9808 - val_loss: 2.0208e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0527 - accuracy: 0.9832 - val_loss: 0.0036 - val_accuracy: 0.9987\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0679 - accuracy: 0.9788 - val_loss: 2.4862e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0432 - accuracy: 0.9858 - val_loss: 1.4883e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0504 - accuracy: 0.9829 - val_loss: 6.4427e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0678 - accuracy: 0.9788 - val_loss: 9.2950e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0536 - accuracy: 0.9830 - val_loss: 4.8193e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0520 - accuracy: 0.9848 - val_loss: 2.9531e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0522 - accuracy: 0.9820 - val_loss: 0.0017 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0522 - accuracy: 0.9830 - val_loss: 4.4884e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0508 - accuracy: 0.9846 - val_loss: 3.3524e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0426 - accuracy: 0.9866 - val_loss: 4.4245e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0462 - accuracy: 0.9852 - val_loss: 0.0018 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0476 - accuracy: 0.9845 - val_loss: 4.3080e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0442 - accuracy: 0.9855 - val_loss: 8.7713e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0489 - accuracy: 0.9849 - val_loss: 5.5666e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0409 - accuracy: 0.9863 - val_loss: 0.0026 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0539 - accuracy: 0.9844 - val_loss: 0.0033 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0449 - accuracy: 0.9872 - val_loss: 9.6595e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0479 - accuracy: 0.9858 - val_loss: 0.0078 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0569 - accuracy: 0.9821 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0415 - accuracy: 0.9879 - val_loss: 1.3536e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0350 - accuracy: 0.9878 - val_loss: 8.8116e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0406 - accuracy: 0.9873 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0551 - accuracy: 0.9809 - val_loss: 0.0023 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0525 - accuracy: 0.9833 - val_loss: 2.2836e-04 - val_accuracy: 1.0000\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 50ms/step - loss: 0.0370 - accuracy: 0.9891 - val_loss: 4.5888e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0383 - accuracy: 0.9890 - val_loss: 5.3485e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0530 - accuracy: 0.9835 - val_loss: 1.2476e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0486 - accuracy: 0.9842 - val_loss: 2.0370e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0398 - accuracy: 0.9872 - val_loss: 6.3329e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0367 - accuracy: 0.9893 - val_loss: 1.5879e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0359 - accuracy: 0.9893 - val_loss: 1.0374e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0511 - accuracy: 0.9847 - val_loss: 3.9128e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0399 - accuracy: 0.9872 - val_loss: 7.2992e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0393 - accuracy: 0.9855 - val_loss: 1.1759e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0417 - accuracy: 0.9851 - val_loss: 1.0742e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0373 - accuracy: 0.9887 - val_loss: 5.6856e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0387 - accuracy: 0.9863 - val_loss: 1.1089e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0419 - accuracy: 0.9861 - val_loss: 2.4187e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0523 - accuracy: 0.9824 - val_loss: 7.5747e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0356 - accuracy: 0.9885 - val_loss: 6.8183e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0418 - accuracy: 0.9857 - val_loss: 1.5582e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0231 - accuracy: 0.9927 - val_loss: 4.8970e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0396 - accuracy: 0.9881 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0457 - accuracy: 0.9858 - val_loss: 4.1913e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0446 - accuracy: 0.9861 - val_loss: 8.8918e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0436 - accuracy: 0.9866 - val_loss: 1.5101e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0399 - accuracy: 0.9873 - val_loss: 6.9501e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0322 - accuracy: 0.9894 - val_loss: 2.8753e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0307 - accuracy: 0.9902 - val_loss: 5.2481e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0313 - accuracy: 0.9903 - val_loss: 1.6580e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0287 - accuracy: 0.9902 - val_loss: 3.7948e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0380 - accuracy: 0.9887 - val_loss: 1.1388e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0387 - accuracy: 0.9867 - val_loss: 4.0540e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0524 - accuracy: 0.9827 - val_loss: 0.0042 - val_accuracy: 0.9987\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0466 - accuracy: 0.9869 - val_loss: 2.5872e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0422 - accuracy: 0.9875 - val_loss: 3.9038e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0326 - accuracy: 0.9900 - val_loss: 4.7262e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0388 - accuracy: 0.9890 - val_loss: 2.0094e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0311 - accuracy: 0.9900 - val_loss: 1.5685e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0325 - accuracy: 0.9900 - val_loss: 4.8218e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0366 - accuracy: 0.9897 - val_loss: 1.3363e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0323 - accuracy: 0.9891 - val_loss: 1.1149e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0284 - accuracy: 0.9924 - val_loss: 2.8685e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0390 - accuracy: 0.9873 - val_loss: 5.0579e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0285 - accuracy: 0.9900 - val_loss: 4.1567e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0372 - accuracy: 0.9893 - val_loss: 9.8895e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0432 - accuracy: 0.9866 - val_loss: 4.3578e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0419 - accuracy: 0.9884 - val_loss: 5.0128e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0411 - accuracy: 0.9876 - val_loss: 4.0798e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0285 - accuracy: 0.9909 - val_loss: 4.2629e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0309 - accuracy: 0.9890 - val_loss: 2.6447e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0431 - accuracy: 0.9857 - val_loss: 1.2036e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 1.3055e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0264 - accuracy: 0.9909 - val_loss: 5.9010e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0367 - accuracy: 0.9896 - val_loss: 1.3381e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0345 - accuracy: 0.9884 - val_loss: 2.7155e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0259 - accuracy: 0.9917 - val_loss: 1.7876e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0237 - accuracy: 0.9914 - val_loss: 4.2229e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0237 - accuracy: 0.9928 - val_loss: 5.9279e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0296 - accuracy: 0.9914 - val_loss: 9.9206e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0389 - accuracy: 0.9876 - val_loss: 4.6066e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0361 - accuracy: 0.9894 - val_loss: 9.9796e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0243 - accuracy: 0.9915 - val_loss: 1.0315e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0235 - accuracy: 0.9921 - val_loss: 2.1413e-05 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0261 - accuracy: 0.9909 - val_loss: 0.0010 - val_accuracy: 0.9987\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0454 - accuracy: 0.9855 - val_loss: 1.7465e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0402 - accuracy: 0.9876 - val_loss: 6.2533e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0338 - accuracy: 0.9888 - val_loss: 1.7855e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0253 - accuracy: 0.9915 - val_loss: 4.1058e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0250 - accuracy: 0.9903 - val_loss: 6.5004e-06 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0354 - accuracy: 0.9906 - val_loss: 3.9286e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0313 - accuracy: 0.9902 - val_loss: 1.1520e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0246 - accuracy: 0.9931 - val_loss: 1.1597e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0255 - accuracy: 0.9921 - val_loss: 2.7205e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0348 - accuracy: 0.9881 - val_loss: 1.2931e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0466 - accuracy: 0.9866 - val_loss: 1.1913e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0367 - accuracy: 0.9893 - val_loss: 8.1546e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0285 - accuracy: 0.9920 - val_loss: 1.9282e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0224 - accuracy: 0.9939 - val_loss: 1.6392e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0315 - accuracy: 0.9909 - val_loss: 4.8463e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0437 - accuracy: 0.9878 - val_loss: 5.7344e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0352 - accuracy: 0.9881 - val_loss: 1.2189e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0229 - accuracy: 0.9933 - val_loss: 2.2539e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 5.1976e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0390 - accuracy: 0.9888 - val_loss: 6.5144e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0296 - accuracy: 0.9923 - val_loss: 2.8095e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0271 - accuracy: 0.9943 - val_loss: 6.7494e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0233 - accuracy: 0.9923 - val_loss: 2.7094e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0308 - accuracy: 0.9897 - val_loss: 2.8238e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0177 - accuracy: 0.9940 - val_loss: 4.4072e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0336 - accuracy: 0.9896 - val_loss: 2.1953e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0162 - accuracy: 0.9955 - val_loss: 7.1984e-06 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0247 - accuracy: 0.9933 - val_loss: 1.7287e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0271 - accuracy: 0.9914 - val_loss: 8.8123e-05 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0392 - accuracy: 0.9882 - val_loss: 3.1679e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0372 - accuracy: 0.9881 - val_loss: 1.1413e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0288 - accuracy: 0.9902 - val_loss: 6.4903e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0251 - accuracy: 0.9920 - val_loss: 4.0221e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0303 - accuracy: 0.9914 - val_loss: 1.9800e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0275 - accuracy: 0.9923 - val_loss: 3.6254e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0364 - accuracy: 0.9885 - val_loss: 2.1650e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0442 - accuracy: 0.9861 - val_loss: 7.0421e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0238 - accuracy: 0.9917 - val_loss: 3.2808e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0275 - accuracy: 0.9908 - val_loss: 2.2392e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0300 - accuracy: 0.9903 - val_loss: 7.3456e-06 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0165 - accuracy: 0.9952 - val_loss: 0.0043 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 1.2582e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0216 - accuracy: 0.9931 - val_loss: 2.3265e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0242 - accuracy: 0.9927 - val_loss: 5.5469e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0165 - accuracy: 0.9942 - val_loss: 1.6488e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0228 - accuracy: 0.9934 - val_loss: 4.4575e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0252 - accuracy: 0.9933 - val_loss: 3.7000e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0203 - accuracy: 0.9928 - val_loss: 3.6715e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0208 - accuracy: 0.9939 - val_loss: 3.0296e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0299 - accuracy: 0.9891 - val_loss: 2.9670e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0335 - accuracy: 0.9891 - val_loss: 5.4603e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 1.5720e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0274 - accuracy: 0.9906 - val_loss: 8.8949e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0263 - accuracy: 0.9911 - val_loss: 4.1337e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0175 - accuracy: 0.9951 - val_loss: 6.7339e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0166 - accuracy: 0.9948 - val_loss: 8.0344e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0145 - accuracy: 0.9961 - val_loss: 1.5769e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0259 - accuracy: 0.9925 - val_loss: 0.0031 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0551 - accuracy: 0.9836 - val_loss: 4.7724e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "CAnc2SJa3o9f",
        "outputId": "e94870c6-14cd-4992-92f8-1ad4ccdc30d7"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 7ms/step - loss: 0.0344 - accuracy: 0.9887\n",
            "Accuracy  : 0.9887338876724243\n",
            "F1_Score  : 0.9885924168326824\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7fcxLuwZpkK",
        "outputId": "4af0f0b9-d4d5-4ec4-d9db-72dc1b2c38a7"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "d74f60c4-b96d-4e10-9784-38778718cdba"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 53ms/step - loss: 1.2023 - accuracy: 0.3972 - val_loss: 1.0631 - val_accuracy: 0.4558\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0838 - accuracy: 0.4428 - val_loss: 1.0612 - val_accuracy: 0.4558\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0765 - accuracy: 0.4500 - val_loss: 1.0625 - val_accuracy: 0.4558\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0751 - accuracy: 0.4428 - val_loss: 1.0610 - val_accuracy: 0.4558\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0654 - accuracy: 0.4534 - val_loss: 1.0612 - val_accuracy: 0.4558\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0652 - accuracy: 0.4501 - val_loss: 1.0614 - val_accuracy: 0.4558\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0619 - accuracy: 0.4573 - val_loss: 1.0603 - val_accuracy: 0.4558\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0609 - accuracy: 0.4549 - val_loss: 1.0687 - val_accuracy: 0.4558\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0635 - accuracy: 0.4556 - val_loss: 1.0587 - val_accuracy: 0.4558\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0558 - accuracy: 0.4533 - val_loss: 1.0519 - val_accuracy: 0.4558\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0537 - accuracy: 0.4535 - val_loss: 1.0555 - val_accuracy: 0.4558\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0540 - accuracy: 0.4534 - val_loss: 1.0556 - val_accuracy: 0.4558\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0544 - accuracy: 0.4513 - val_loss: 1.0579 - val_accuracy: 0.4558\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0514 - accuracy: 0.4588 - val_loss: 1.0373 - val_accuracy: 0.4558\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0531 - accuracy: 0.4538 - val_loss: 1.0398 - val_accuracy: 0.4558\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0412 - accuracy: 0.4585 - val_loss: 1.0574 - val_accuracy: 0.4558\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0459 - accuracy: 0.4488 - val_loss: 1.0313 - val_accuracy: 0.4558\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0479 - accuracy: 0.4544 - val_loss: 1.0433 - val_accuracy: 0.4558\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0442 - accuracy: 0.4485 - val_loss: 1.0339 - val_accuracy: 0.4571\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0416 - accuracy: 0.4576 - val_loss: 1.0389 - val_accuracy: 0.4558\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0398 - accuracy: 0.4557 - val_loss: 1.0580 - val_accuracy: 0.4558\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0326 - accuracy: 0.4525 - val_loss: 1.0650 - val_accuracy: 0.4558\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0362 - accuracy: 0.4536 - val_loss: 1.0409 - val_accuracy: 0.4558\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0332 - accuracy: 0.4489 - val_loss: 1.0550 - val_accuracy: 0.4558\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0327 - accuracy: 0.4548 - val_loss: 1.0495 - val_accuracy: 0.4558\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0173 - accuracy: 0.4582 - val_loss: 1.0411 - val_accuracy: 0.4558\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0243 - accuracy: 0.4565 - val_loss: 1.0213 - val_accuracy: 0.4558\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0163 - accuracy: 0.4625 - val_loss: 1.0219 - val_accuracy: 0.4692\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0188 - accuracy: 0.4437 - val_loss: 1.0295 - val_accuracy: 0.4571\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0094 - accuracy: 0.4614 - val_loss: 0.9922 - val_accuracy: 0.4558\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0008 - accuracy: 0.4559 - val_loss: 1.0611 - val_accuracy: 0.4531\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9891 - accuracy: 0.4768 - val_loss: 0.9579 - val_accuracy: 0.5000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9857 - accuracy: 0.5054 - val_loss: 0.9432 - val_accuracy: 0.5174\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9814 - accuracy: 0.5055 - val_loss: 0.9957 - val_accuracy: 0.4906\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9752 - accuracy: 0.5001 - val_loss: 0.9807 - val_accuracy: 0.4960\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9525 - accuracy: 0.5310 - val_loss: 0.9366 - val_accuracy: 0.5107\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9472 - accuracy: 0.5362 - val_loss: 0.9264 - val_accuracy: 0.5174\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9272 - accuracy: 0.5508 - val_loss: 0.9486 - val_accuracy: 0.5107\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9096 - accuracy: 0.5602 - val_loss: 0.9120 - val_accuracy: 0.5550\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8996 - accuracy: 0.5684 - val_loss: 0.8657 - val_accuracy: 0.5912\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8784 - accuracy: 0.5842 - val_loss: 0.8705 - val_accuracy: 0.5563\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8569 - accuracy: 0.5990 - val_loss: 0.8494 - val_accuracy: 0.5871\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8320 - accuracy: 0.6183 - val_loss: 0.8845 - val_accuracy: 0.5871\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8120 - accuracy: 0.6213 - val_loss: 0.8348 - val_accuracy: 0.6367\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7643 - accuracy: 0.6550 - val_loss: 0.7799 - val_accuracy: 0.6609\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7365 - accuracy: 0.6727 - val_loss: 0.7079 - val_accuracy: 0.6836\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6865 - accuracy: 0.7019 - val_loss: 0.6842 - val_accuracy: 0.7011\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6619 - accuracy: 0.7118 - val_loss: 0.8251 - val_accuracy: 0.5992\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6295 - accuracy: 0.7311 - val_loss: 0.6646 - val_accuracy: 0.7172\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5894 - accuracy: 0.7589 - val_loss: 0.5516 - val_accuracy: 0.7842\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5484 - accuracy: 0.7781 - val_loss: 0.5918 - val_accuracy: 0.7775\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5011 - accuracy: 0.7990 - val_loss: 0.4440 - val_accuracy: 0.8324\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4342 - accuracy: 0.8373 - val_loss: 0.4605 - val_accuracy: 0.8123\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4213 - accuracy: 0.8343 - val_loss: 0.4328 - val_accuracy: 0.8271\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3710 - accuracy: 0.8611 - val_loss: 0.5445 - val_accuracy: 0.7668\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3512 - accuracy: 0.8657 - val_loss: 0.3317 - val_accuracy: 0.8807\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2957 - accuracy: 0.8906 - val_loss: 0.3950 - val_accuracy: 0.8378\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2934 - accuracy: 0.8927 - val_loss: 0.2851 - val_accuracy: 0.8968\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2712 - accuracy: 0.9054 - val_loss: 0.2826 - val_accuracy: 0.8847\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2416 - accuracy: 0.9148 - val_loss: 0.2673 - val_accuracy: 0.8968\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2501 - accuracy: 0.9152 - val_loss: 0.0603 - val_accuracy: 0.9812\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1982 - accuracy: 0.9320 - val_loss: 0.0334 - val_accuracy: 0.9879\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1921 - accuracy: 0.9350 - val_loss: 0.0669 - val_accuracy: 0.9705\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1709 - accuracy: 0.9446 - val_loss: 0.0656 - val_accuracy: 0.9732\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1853 - accuracy: 0.9358 - val_loss: 0.0359 - val_accuracy: 0.9893\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1508 - accuracy: 0.9478 - val_loss: 0.0202 - val_accuracy: 0.9987\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1485 - accuracy: 0.9526 - val_loss: 0.0220 - val_accuracy: 0.9906\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1368 - accuracy: 0.9545 - val_loss: 0.0222 - val_accuracy: 0.9973\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1581 - accuracy: 0.9477 - val_loss: 0.0242 - val_accuracy: 0.9973\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1098 - accuracy: 0.9660 - val_loss: 0.0188 - val_accuracy: 0.9960\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1262 - accuracy: 0.9593 - val_loss: 0.0151 - val_accuracy: 0.9960\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1175 - accuracy: 0.9638 - val_loss: 0.0159 - val_accuracy: 0.9933\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0978 - accuracy: 0.9672 - val_loss: 0.0112 - val_accuracy: 0.9973\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0988 - accuracy: 0.9677 - val_loss: 0.0161 - val_accuracy: 0.9946\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0963 - accuracy: 0.9697 - val_loss: 0.0142 - val_accuracy: 0.9946\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0801 - accuracy: 0.9742 - val_loss: 0.0091 - val_accuracy: 0.9973\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0851 - accuracy: 0.9711 - val_loss: 0.0074 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0878 - accuracy: 0.9711 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0728 - accuracy: 0.9788 - val_loss: 0.0153 - val_accuracy: 0.9946\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0809 - accuracy: 0.9772 - val_loss: 0.0090 - val_accuracy: 0.9973\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0753 - accuracy: 0.9766 - val_loss: 0.0200 - val_accuracy: 0.9933\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0771 - accuracy: 0.9754 - val_loss: 0.0095 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0709 - accuracy: 0.9753 - val_loss: 0.0091 - val_accuracy: 0.9973\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0666 - accuracy: 0.9814 - val_loss: 0.0110 - val_accuracy: 0.9973\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0520 - accuracy: 0.9849 - val_loss: 0.0127 - val_accuracy: 0.9960\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0552 - accuracy: 0.9815 - val_loss: 0.0069 - val_accuracy: 0.9973\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0814 - accuracy: 0.9720 - val_loss: 0.0095 - val_accuracy: 0.9973\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0700 - accuracy: 0.9778 - val_loss: 0.0111 - val_accuracy: 0.9946\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0579 - accuracy: 0.9817 - val_loss: 0.0108 - val_accuracy: 0.9960\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0650 - accuracy: 0.9800 - val_loss: 0.0158 - val_accuracy: 0.9946\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0788 - accuracy: 0.9718 - val_loss: 2.4894e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0552 - accuracy: 0.9829 - val_loss: 5.4984e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0548 - accuracy: 0.9820 - val_loss: 3.7569e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0606 - accuracy: 0.9808 - val_loss: 0.0023 - val_accuracy: 0.9987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0487 - accuracy: 0.9846 - val_loss: 6.6580e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0543 - accuracy: 0.9821 - val_loss: 0.0059 - val_accuracy: 0.9987\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0523 - accuracy: 0.9826 - val_loss: 4.0579e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0535 - accuracy: 0.9826 - val_loss: 3.3487e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0598 - accuracy: 0.9812 - val_loss: 8.9663e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0679 - accuracy: 0.9794 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0502 - accuracy: 0.9827 - val_loss: 2.3127e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0437 - accuracy: 0.9866 - val_loss: 0.0017 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0521 - accuracy: 0.9838 - val_loss: 1.8314e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0459 - accuracy: 0.9851 - val_loss: 6.1741e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0511 - accuracy: 0.9863 - val_loss: 0.0054 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0395 - accuracy: 0.9858 - val_loss: 8.8802e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0445 - accuracy: 0.9870 - val_loss: 0.0020 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0470 - accuracy: 0.9879 - val_loss: 8.6668e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0373 - accuracy: 0.9891 - val_loss: 8.2924e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0392 - accuracy: 0.9894 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0488 - accuracy: 0.9830 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0440 - accuracy: 0.9848 - val_loss: 3.5309e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0352 - accuracy: 0.9884 - val_loss: 2.1933e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0386 - accuracy: 0.9884 - val_loss: 3.0397e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0389 - accuracy: 0.9884 - val_loss: 7.7330e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0420 - accuracy: 0.9846 - val_loss: 8.7548e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0397 - accuracy: 0.9881 - val_loss: 8.7665e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0336 - accuracy: 0.9897 - val_loss: 0.0027 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0395 - accuracy: 0.9876 - val_loss: 3.7035e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0348 - accuracy: 0.9897 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0443 - accuracy: 0.9844 - val_loss: 3.4857e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0517 - accuracy: 0.9841 - val_loss: 6.4194e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0387 - accuracy: 0.9887 - val_loss: 1.5260e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0350 - accuracy: 0.9890 - val_loss: 2.8577e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0345 - accuracy: 0.9893 - val_loss: 5.6683e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0320 - accuracy: 0.9896 - val_loss: 5.2252e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0441 - accuracy: 0.9870 - val_loss: 3.4182e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0361 - accuracy: 0.9885 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0342 - accuracy: 0.9882 - val_loss: 3.4975e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0478 - accuracy: 0.9863 - val_loss: 2.0759e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0477 - accuracy: 0.9858 - val_loss: 9.7822e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0437 - accuracy: 0.9870 - val_loss: 2.8985e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0287 - accuracy: 0.9912 - val_loss: 3.7841e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0323 - accuracy: 0.9894 - val_loss: 0.0030 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0434 - accuracy: 0.9844 - val_loss: 2.0977e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0233 - accuracy: 0.9931 - val_loss: 4.6609e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0381 - accuracy: 0.9890 - val_loss: 2.8020e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0352 - accuracy: 0.9891 - val_loss: 2.0338e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0340 - accuracy: 0.9902 - val_loss: 6.2729e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0273 - accuracy: 0.9909 - val_loss: 8.5895e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0253 - accuracy: 0.9925 - val_loss: 2.8965e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0411 - accuracy: 0.9870 - val_loss: 2.6248e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0435 - accuracy: 0.9873 - val_loss: 1.8216e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0278 - accuracy: 0.9897 - val_loss: 1.9091e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0287 - accuracy: 0.9899 - val_loss: 2.7779e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0280 - accuracy: 0.9915 - val_loss: 4.2396e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0364 - accuracy: 0.9884 - val_loss: 6.9125e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0213 - accuracy: 0.9946 - val_loss: 3.1276e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0261 - accuracy: 0.9917 - val_loss: 6.4219e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0234 - accuracy: 0.9918 - val_loss: 1.8216e-04 - val_accuracy: 1.0000\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0253 - accuracy: 0.9906 - val_loss: 1.4424e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0404 - accuracy: 0.9879 - val_loss: 3.4522e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0281 - accuracy: 0.9931 - val_loss: 4.1414e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0387 - accuracy: 0.9887 - val_loss: 2.1808e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0350 - accuracy: 0.9896 - val_loss: 6.8482e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0191 - accuracy: 0.9933 - val_loss: 4.0677e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0371 - accuracy: 0.9884 - val_loss: 3.0119e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 3.3754e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0306 - accuracy: 0.9899 - val_loss: 3.8063e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0297 - accuracy: 0.9909 - val_loss: 7.6807e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0200 - accuracy: 0.9942 - val_loss: 4.0639e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0252 - accuracy: 0.9924 - val_loss: 2.1370e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0323 - accuracy: 0.9897 - val_loss: 1.6667e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0243 - accuracy: 0.9933 - val_loss: 2.8090e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0241 - accuracy: 0.9914 - val_loss: 9.4868e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.0027 - val_accuracy: 0.9987\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0396 - accuracy: 0.9870 - val_loss: 0.0035 - val_accuracy: 0.9973\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0473 - accuracy: 0.9852 - val_loss: 0.0096 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0310 - accuracy: 0.9920 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 2.3765e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0274 - accuracy: 0.9908 - val_loss: 2.1020e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0285 - accuracy: 0.9911 - val_loss: 2.7266e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0240 - accuracy: 0.9933 - val_loss: 1.6226e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0269 - accuracy: 0.9920 - val_loss: 5.8442e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0231 - accuracy: 0.9928 - val_loss: 5.8343e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0280 - accuracy: 0.9912 - val_loss: 5.7895e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0222 - accuracy: 0.9939 - val_loss: 6.7104e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0224 - accuracy: 0.9933 - val_loss: 7.8834e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0215 - accuracy: 0.9930 - val_loss: 3.1765e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0233 - accuracy: 0.9923 - val_loss: 2.5373e-05 - val_accuracy: 1.0000\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0180 - accuracy: 0.9939 - val_loss: 1.9536e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0331 - accuracy: 0.9897 - val_loss: 6.9455e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0285 - accuracy: 0.9906 - val_loss: 1.0582e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0218 - accuracy: 0.9940 - val_loss: 2.4005e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0280 - accuracy: 0.9905 - val_loss: 5.2238e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 4.4931e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0214 - accuracy: 0.9928 - val_loss: 2.0844e-06 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0207 - accuracy: 0.9940 - val_loss: 6.6372e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0202 - accuracy: 0.9943 - val_loss: 4.1024e-06 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0211 - accuracy: 0.9948 - val_loss: 3.9116e-06 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0204 - accuracy: 0.9940 - val_loss: 7.6470e-06 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 7.0828e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0226 - accuracy: 0.9925 - val_loss: 2.1931e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 3.1750e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0226 - accuracy: 0.9914 - val_loss: 7.3556e-06 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0214 - accuracy: 0.9934 - val_loss: 3.0431e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0226 - accuracy: 0.9934 - val_loss: 1.0785e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0242 - accuracy: 0.9924 - val_loss: 1.4671e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0226 - accuracy: 0.9940 - val_loss: 8.8046e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0212 - accuracy: 0.9925 - val_loss: 1.5665e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0199 - accuracy: 0.9934 - val_loss: 7.6962e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0235 - accuracy: 0.9933 - val_loss: 5.0781e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0235 - accuracy: 0.9933 - val_loss: 7.0710e-06 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0263 - accuracy: 0.9925 - val_loss: 3.3188e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0222 - accuracy: 0.9920 - val_loss: 1.0841e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0267 - accuracy: 0.9924 - val_loss: 7.7460e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0176 - accuracy: 0.9946 - val_loss: 5.3280e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 9.1688e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0232 - accuracy: 0.9936 - val_loss: 6.1749e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0131 - accuracy: 0.9967 - val_loss: 3.4864e-05 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0179 - accuracy: 0.9948 - val_loss: 7.3573e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0231 - accuracy: 0.9936 - val_loss: 4.1337e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0321 - accuracy: 0.9906 - val_loss: 4.1413e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0259 - accuracy: 0.9931 - val_loss: 6.2610e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0234 - accuracy: 0.9928 - val_loss: 1.4213e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0144 - accuracy: 0.9958 - val_loss: 9.5758e-06 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0112 - accuracy: 0.9972 - val_loss: 2.6178e-06 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0144 - accuracy: 0.9964 - val_loss: 5.9637e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0296 - accuracy: 0.9920 - val_loss: 4.2917e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0252 - accuracy: 0.9920 - val_loss: 7.4154e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0201 - accuracy: 0.9946 - val_loss: 1.1605e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0213 - accuracy: 0.9928 - val_loss: 1.7056e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 1.5279e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0160 - accuracy: 0.9954 - val_loss: 1.2361e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0189 - accuracy: 0.9937 - val_loss: 2.3771e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0214 - accuracy: 0.9939 - val_loss: 5.8284e-06 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0182 - accuracy: 0.9940 - val_loss: 5.6285e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0220 - accuracy: 0.9943 - val_loss: 4.5211e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0272 - accuracy: 0.9925 - val_loss: 4.7095e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0225 - accuracy: 0.9933 - val_loss: 2.6139e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 4.6599e-06 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 1.1421e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 2.3863e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 4.0932e-06 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0265 - accuracy: 0.9918 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0199 - accuracy: 0.9925 - val_loss: 1.2778e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0238 - accuracy: 0.9930 - val_loss: 3.3961e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 5.3320e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0228 - accuracy: 0.9923 - val_loss: 6.6809e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0180 - accuracy: 0.9945 - val_loss: 1.9777e-04 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0227 - accuracy: 0.9931 - val_loss: 2.7981e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0266 - accuracy: 0.9915 - val_loss: 7.3136e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0239 - accuracy: 0.9936 - val_loss: 5.9770e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0183 - accuracy: 0.9937 - val_loss: 6.7917e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0180 - accuracy: 0.9937 - val_loss: 1.0547e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0298 - accuracy: 0.9908 - val_loss: 4.2857e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0196 - accuracy: 0.9946 - val_loss: 4.0983e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 2.1134e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0191 - accuracy: 0.9955 - val_loss: 1.1487e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0249 - accuracy: 0.9925 - val_loss: 2.4072e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0158 - accuracy: 0.9954 - val_loss: 1.5287e-06 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 2.2033e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0227 - accuracy: 0.9931 - val_loss: 6.5834e-06 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 1.4182e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 8.2939e-06 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0218 - accuracy: 0.9937 - val_loss: 7.8420e-06 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0102 - accuracy: 0.9975 - val_loss: 7.5989e-07 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 1.7829e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 1.3874e-06 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0185 - accuracy: 0.9952 - val_loss: 4.3128e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0216 - accuracy: 0.9927 - val_loss: 1.9370e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 9.1366e-06 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0119 - accuracy: 0.9969 - val_loss: 5.1883e-06 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 7.1321e-06 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0199 - accuracy: 0.9958 - val_loss: 1.8310e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0171 - accuracy: 0.9952 - val_loss: 6.3618e-06 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0200 - accuracy: 0.9940 - val_loss: 1.2584e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0159 - accuracy: 0.9952 - val_loss: 9.4084e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0256 - accuracy: 0.9930 - val_loss: 9.5760e-06 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 1.6159e-06 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0159 - accuracy: 0.9954 - val_loss: 3.5666e-07 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0280 - accuracy: 0.9925 - val_loss: 8.6937e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0169 - accuracy: 0.9963 - val_loss: 2.5818e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 3.9858e-07 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 5.7053e-07 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 8.1074e-07 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0154 - accuracy: 0.9958 - val_loss: 6.3215e-07 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0129 - accuracy: 0.9967 - val_loss: 1.6210e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0184 - accuracy: 0.9937 - val_loss: 8.7781e-06 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0222 - accuracy: 0.9923 - val_loss: 9.9984e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 7.9885e-06 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0239 - accuracy: 0.9949 - val_loss: 1.1556e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0286 - accuracy: 0.9923 - val_loss: 5.9975e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0218 - accuracy: 0.9928 - val_loss: 3.7888e-06 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 8.9216e-07 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 8.3969e-07 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 2.6759e-06 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 3.4753e-06 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 5.4432e-06 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0319 - accuracy: 0.9905 - val_loss: 0.0012 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 4.4889e-06 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0148 - accuracy: 0.9955 - val_loss: 8.0762e-06 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0271 - accuracy: 0.9930 - val_loss: 3.6380e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0115 - accuracy: 0.9957 - val_loss: 1.1749e-06 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0158 - accuracy: 0.9948 - val_loss: 3.9872e-06 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0131 - accuracy: 0.9964 - val_loss: 8.8928e-07 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 1.4277e-06 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0148 - accuracy: 0.9958 - val_loss: 3.2468e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0169 - accuracy: 0.9946 - val_loss: 5.7241e-06 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0208 - accuracy: 0.9942 - val_loss: 6.6524e-06 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "caaf4c39-5bf0-4dce-91e3-5a677f69f134"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 6ms/step - loss: 0.0253 - accuracy: 0.9941\n",
            "Accuracy  : 0.9940987229347229\n",
            "F1_Score  : 0.9941525406452669\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ed691fdb-9182-4396-905d-b0841c23f80f"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'#dominance\\nX_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\\nprint(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "c35f386e-357c-4435-e3f5-8b0e0c485b9e"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'foldNum=0\\nmodel = get_model()\\nfor train_index, val_index in kfold.split(X_train, Y_train):\\n  foldNum = foldNum + 1\\n  print(\"Results for fold\",foldNum)\\n  x_train, x_val = X_train[train_index], X_train[val_index]\\n  y_train, y_val = Y_train[train_index], Y_train[val_index]\\n  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\\n  gc.collect() # Garbage collecter\\n  del x_train, x_val, y_train, y_val\\n  gc.collect()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "9bf71af2-29a8-4636-b701-118370f0a5ac"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'acrc = model.evaluate(x_test, y_test)\\npred = model.predict(x_test)\\nf1scr = f1_score(y_test.argmax(1), pred.argmax(1), average=\\'macro\\')\\nc_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\\nprint(\"Accuracy  : {}\".format(acrc[1]))\\nprint(\"F1_Score  : {}\".format(f1scr))\\nc_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\\nimport seaborn as sns\\nfigure = plt.figure(figsize=(9, 9))\\nsns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\\nplt.tight_layout()\\nplt.ylabel(\\'True label\\')\\nplt.xlabel(\\'Predicted label\\')\\nplt.show()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}