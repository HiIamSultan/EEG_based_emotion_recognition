{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub15_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "ce5d8e33-aedc-457f-8796-2b8d7416f3e5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e3\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  #EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "dea05cbb-5239-4fb4-94a7-19fae0e98b77"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(15,16):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.15\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (2796,) (2563,) (3961,)\n",
            "(9320,) (2330,) (4893,) (2097,)\n",
            "(9320,) (2796,) (2563,) (3961,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "130f3270-3126-47be-d91a-778c4b51f861"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "f7ba5311-1bb8-4802-f618-000d04897669"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "622"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "066be902-65a4-4b06-fadc-946ca79237bb"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62ede0f8-5eef-4a19-8060-9fff50ec7a39"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 49s 73ms/step - loss: 1.1334 - accuracy: 0.3958 - val_loss: 1.0654 - val_accuracy: 0.4290\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 1.0704 - accuracy: 0.4321 - val_loss: 1.0395 - val_accuracy: 0.4383\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0606 - accuracy: 0.4268 - val_loss: 1.0332 - val_accuracy: 0.4330\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0505 - accuracy: 0.4298 - val_loss: 1.0633 - val_accuracy: 0.4464\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0377 - accuracy: 0.4296 - val_loss: 1.0346 - val_accuracy: 0.4169\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 1.0155 - accuracy: 0.4425 - val_loss: 1.0309 - val_accuracy: 0.4424\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0216 - accuracy: 0.4371 - val_loss: 1.0152 - val_accuracy: 0.4424\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0214 - accuracy: 0.4470 - val_loss: 1.0079 - val_accuracy: 0.4571\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0203 - accuracy: 0.4526 - val_loss: 1.0166 - val_accuracy: 0.4705\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0070 - accuracy: 0.4609 - val_loss: 1.0096 - val_accuracy: 0.4651\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0010 - accuracy: 0.4678 - val_loss: 1.0357 - val_accuracy: 0.4196\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 1.0050 - accuracy: 0.4681 - val_loss: 0.9898 - val_accuracy: 0.5013\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9951 - accuracy: 0.4759 - val_loss: 1.0021 - val_accuracy: 0.4772\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9940 - accuracy: 0.4760 - val_loss: 0.9901 - val_accuracy: 0.4906\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9935 - accuracy: 0.4784 - val_loss: 0.9900 - val_accuracy: 0.4866\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.9840 - accuracy: 0.4921 - val_loss: 1.0008 - val_accuracy: 0.4625\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9686 - accuracy: 0.4949 - val_loss: 0.9949 - val_accuracy: 0.4799\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9743 - accuracy: 0.4794 - val_loss: 0.9804 - val_accuracy: 0.4920\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9799 - accuracy: 0.4946 - val_loss: 0.9721 - val_accuracy: 0.5054\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9660 - accuracy: 0.5005 - val_loss: 0.9766 - val_accuracy: 0.4960\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9697 - accuracy: 0.4839 - val_loss: 0.9544 - val_accuracy: 0.5214\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9575 - accuracy: 0.5079 - val_loss: 0.9598 - val_accuracy: 0.5308\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9506 - accuracy: 0.5073 - val_loss: 0.9556 - val_accuracy: 0.4879\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9560 - accuracy: 0.5200 - val_loss: 0.9548 - val_accuracy: 0.5094\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9571 - accuracy: 0.4999 - val_loss: 0.9505 - val_accuracy: 0.4906\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9362 - accuracy: 0.5256 - val_loss: 0.9495 - val_accuracy: 0.5349\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9416 - accuracy: 0.5071 - val_loss: 0.9636 - val_accuracy: 0.5255\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9435 - accuracy: 0.5061 - val_loss: 0.9359 - val_accuracy: 0.5268\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9343 - accuracy: 0.5182 - val_loss: 0.9254 - val_accuracy: 0.5389\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9199 - accuracy: 0.5248 - val_loss: 0.9347 - val_accuracy: 0.5362\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.9291 - accuracy: 0.5273 - val_loss: 0.9265 - val_accuracy: 0.5349\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9210 - accuracy: 0.5250 - val_loss: 0.8977 - val_accuracy: 0.5402\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.9223 - accuracy: 0.5161 - val_loss: 0.8913 - val_accuracy: 0.5684\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.9113 - accuracy: 0.5297 - val_loss: 0.8765 - val_accuracy: 0.5670\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.8974 - accuracy: 0.5361 - val_loss: 0.9191 - val_accuracy: 0.5657\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.8907 - accuracy: 0.5463 - val_loss: 0.8505 - val_accuracy: 0.5751\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.8887 - accuracy: 0.5373 - val_loss: 0.8604 - val_accuracy: 0.5885\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8768 - accuracy: 0.5660 - val_loss: 0.8652 - val_accuracy: 0.5804\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8710 - accuracy: 0.5528 - val_loss: 0.8568 - val_accuracy: 0.5979\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8636 - accuracy: 0.5708 - val_loss: 0.8809 - val_accuracy: 0.5751\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8719 - accuracy: 0.5708 - val_loss: 0.8352 - val_accuracy: 0.5845\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8491 - accuracy: 0.5790 - val_loss: 0.8369 - val_accuracy: 0.5885\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8526 - accuracy: 0.5775 - val_loss: 0.8761 - val_accuracy: 0.5563\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8225 - accuracy: 0.5960 - val_loss: 0.7905 - val_accuracy: 0.6394\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8074 - accuracy: 0.6027 - val_loss: 0.7942 - val_accuracy: 0.6180\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7997 - accuracy: 0.6057 - val_loss: 0.7769 - val_accuracy: 0.6193\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.7763 - accuracy: 0.6285 - val_loss: 0.8021 - val_accuracy: 0.6005\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7672 - accuracy: 0.6349 - val_loss: 0.7670 - val_accuracy: 0.6381\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7446 - accuracy: 0.6466 - val_loss: 0.7690 - val_accuracy: 0.6461\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.7362 - accuracy: 0.6537 - val_loss: 0.7707 - val_accuracy: 0.6340\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.7255 - accuracy: 0.6638 - val_loss: 0.7131 - val_accuracy: 0.6877\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.7032 - accuracy: 0.6784 - val_loss: 0.6846 - val_accuracy: 0.6729\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.7021 - accuracy: 0.6808 - val_loss: 0.7361 - val_accuracy: 0.6381\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.6554 - accuracy: 0.7118 - val_loss: 0.6629 - val_accuracy: 0.7292\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.6219 - accuracy: 0.7298 - val_loss: 0.6752 - val_accuracy: 0.6997\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.6214 - accuracy: 0.7311 - val_loss: 0.6721 - val_accuracy: 0.7091\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.6018 - accuracy: 0.7414 - val_loss: 0.6226 - val_accuracy: 0.7319\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.5814 - accuracy: 0.7516 - val_loss: 0.6814 - val_accuracy: 0.7038\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.5406 - accuracy: 0.7732 - val_loss: 0.5698 - val_accuracy: 0.7654\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.5448 - accuracy: 0.7773 - val_loss: 0.5594 - val_accuracy: 0.7654\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.5337 - accuracy: 0.7775 - val_loss: 0.2854 - val_accuracy: 0.9062\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.5207 - accuracy: 0.7838 - val_loss: 0.3256 - val_accuracy: 0.8914\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.4749 - accuracy: 0.8075 - val_loss: 0.3323 - val_accuracy: 0.9088\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.4522 - accuracy: 0.8255 - val_loss: 0.2795 - val_accuracy: 0.9048\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.4358 - accuracy: 0.8291 - val_loss: 0.2667 - val_accuracy: 0.9062\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.4166 - accuracy: 0.8390 - val_loss: 0.2796 - val_accuracy: 0.9008\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3816 - accuracy: 0.8556 - val_loss: 0.2744 - val_accuracy: 0.8981\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3846 - accuracy: 0.8519 - val_loss: 0.3190 - val_accuracy: 0.8753\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3822 - accuracy: 0.8522 - val_loss: 0.1962 - val_accuracy: 0.9303\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3496 - accuracy: 0.8724 - val_loss: 0.1968 - val_accuracy: 0.9290\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3185 - accuracy: 0.8811 - val_loss: 0.1855 - val_accuracy: 0.9223\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.3135 - accuracy: 0.8824 - val_loss: 0.2152 - val_accuracy: 0.9062\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3034 - accuracy: 0.8906 - val_loss: 0.1853 - val_accuracy: 0.9276\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2818 - accuracy: 0.8960 - val_loss: 0.2283 - val_accuracy: 0.9075\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2874 - accuracy: 0.8945 - val_loss: 0.1574 - val_accuracy: 0.9410\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2621 - accuracy: 0.9039 - val_loss: 0.1308 - val_accuracy: 0.9531\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2498 - accuracy: 0.9079 - val_loss: 0.1507 - val_accuracy: 0.9410\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2389 - accuracy: 0.9177 - val_loss: 0.1282 - val_accuracy: 0.9504\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2394 - accuracy: 0.9167 - val_loss: 0.1546 - val_accuracy: 0.9491\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2110 - accuracy: 0.9249 - val_loss: 0.1439 - val_accuracy: 0.9357\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2268 - accuracy: 0.9186 - val_loss: 0.1491 - val_accuracy: 0.9424\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1937 - accuracy: 0.9323 - val_loss: 0.1682 - val_accuracy: 0.9424\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2102 - accuracy: 0.9301 - val_loss: 0.1637 - val_accuracy: 0.9357\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1762 - accuracy: 0.9389 - val_loss: 0.1172 - val_accuracy: 0.9571\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1842 - accuracy: 0.9335 - val_loss: 0.1235 - val_accuracy: 0.9491\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1583 - accuracy: 0.9462 - val_loss: 0.1434 - val_accuracy: 0.9517\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1619 - accuracy: 0.9428 - val_loss: 0.1274 - val_accuracy: 0.9504\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1702 - accuracy: 0.9417 - val_loss: 0.1091 - val_accuracy: 0.9571\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1719 - accuracy: 0.9413 - val_loss: 0.2035 - val_accuracy: 0.9263\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1635 - accuracy: 0.9437 - val_loss: 0.0988 - val_accuracy: 0.9665\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2010 - accuracy: 0.9325 - val_loss: 0.0138 - val_accuracy: 0.9987\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1765 - accuracy: 0.9396 - val_loss: 0.0178 - val_accuracy: 0.9973\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1730 - accuracy: 0.9407 - val_loss: 0.0164 - val_accuracy: 0.9987\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1535 - accuracy: 0.9486 - val_loss: 0.0147 - val_accuracy: 0.9973\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1437 - accuracy: 0.9539 - val_loss: 0.0161 - val_accuracy: 0.9973\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1545 - accuracy: 0.9469 - val_loss: 0.0159 - val_accuracy: 0.9960\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1480 - accuracy: 0.9508 - val_loss: 0.0151 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1310 - accuracy: 0.9581 - val_loss: 0.0133 - val_accuracy: 0.9960\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1267 - accuracy: 0.9539 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1381 - accuracy: 0.9542 - val_loss: 0.0248 - val_accuracy: 0.9893\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1366 - accuracy: 0.9532 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1075 - accuracy: 0.9641 - val_loss: 0.0229 - val_accuracy: 0.9933\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1233 - accuracy: 0.9577 - val_loss: 0.0158 - val_accuracy: 0.9973\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1063 - accuracy: 0.9642 - val_loss: 0.0196 - val_accuracy: 0.9933\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1283 - accuracy: 0.9575 - val_loss: 0.0117 - val_accuracy: 0.9973\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1107 - accuracy: 0.9598 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0915 - accuracy: 0.9729 - val_loss: 0.0089 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.1210 - accuracy: 0.9589 - val_loss: 0.0301 - val_accuracy: 0.9879\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1127 - accuracy: 0.9608 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.1198 - accuracy: 0.9608 - val_loss: 0.0140 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.1071 - accuracy: 0.9656 - val_loss: 0.0264 - val_accuracy: 0.9920\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.1014 - accuracy: 0.9662 - val_loss: 0.0124 - val_accuracy: 0.9946\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0916 - accuracy: 0.9709 - val_loss: 0.0088 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1039 - accuracy: 0.9636 - val_loss: 0.0103 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0967 - accuracy: 0.9677 - val_loss: 0.0163 - val_accuracy: 0.9960\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1080 - accuracy: 0.9621 - val_loss: 0.0189 - val_accuracy: 0.9946\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1248 - accuracy: 0.9584 - val_loss: 0.0502 - val_accuracy: 0.9812\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1056 - accuracy: 0.9620 - val_loss: 0.0178 - val_accuracy: 0.9933\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0899 - accuracy: 0.9687 - val_loss: 0.0124 - val_accuracy: 0.9960\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0949 - accuracy: 0.9656 - val_loss: 0.0186 - val_accuracy: 0.9960\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1090 - accuracy: 0.9656 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1090 - accuracy: 0.9654 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0823 - accuracy: 0.9736 - val_loss: 9.4530e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0874 - accuracy: 0.9715 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0991 - accuracy: 0.9689 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0866 - accuracy: 0.9739 - val_loss: 0.0027 - val_accuracy: 0.9987\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0777 - accuracy: 0.9748 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0803 - accuracy: 0.9727 - val_loss: 0.0026 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0919 - accuracy: 0.9699 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0880 - accuracy: 0.9735 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0812 - accuracy: 0.9721 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0825 - accuracy: 0.9735 - val_loss: 0.0058 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0880 - accuracy: 0.9709 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0646 - accuracy: 0.9796 - val_loss: 0.0079 - val_accuracy: 0.9973\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0921 - accuracy: 0.9726 - val_loss: 0.0057 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0826 - accuracy: 0.9726 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0784 - accuracy: 0.9760 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0691 - accuracy: 0.9784 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0677 - accuracy: 0.9787 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0719 - accuracy: 0.9753 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0804 - accuracy: 0.9748 - val_loss: 0.0094 - val_accuracy: 0.9973\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0855 - accuracy: 0.9712 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0751 - accuracy: 0.9766 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0665 - accuracy: 0.9797 - val_loss: 0.0024 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0737 - accuracy: 0.9748 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0668 - accuracy: 0.9769 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0686 - accuracy: 0.9763 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0634 - accuracy: 0.9787 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0652 - accuracy: 0.9794 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0919 - accuracy: 0.9723 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1022 - accuracy: 0.9656 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0642 - accuracy: 0.9811 - val_loss: 3.5481e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0746 - accuracy: 0.9754 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0718 - accuracy: 0.9769 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0597 - accuracy: 0.9799 - val_loss: 8.5017e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0568 - accuracy: 0.9820 - val_loss: 2.1700e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0569 - accuracy: 0.9818 - val_loss: 0.0038 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0663 - accuracy: 0.9779 - val_loss: 5.1384e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0688 - accuracy: 0.9785 - val_loss: 9.9933e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0473 - accuracy: 0.9855 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0569 - accuracy: 0.9809 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0584 - accuracy: 0.9799 - val_loss: 9.7083e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0543 - accuracy: 0.9821 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0553 - accuracy: 0.9826 - val_loss: 6.8516e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0558 - accuracy: 0.9830 - val_loss: 0.0018 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0772 - accuracy: 0.9770 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0628 - accuracy: 0.9797 - val_loss: 5.2331e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0534 - accuracy: 0.9839 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0706 - accuracy: 0.9791 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0479 - accuracy: 0.9836 - val_loss: 5.7046e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0596 - accuracy: 0.9829 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0530 - accuracy: 0.9832 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0547 - accuracy: 0.9851 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0557 - accuracy: 0.9829 - val_loss: 9.0162e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0592 - accuracy: 0.9805 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0441 - accuracy: 0.9866 - val_loss: 0.0070 - val_accuracy: 0.9973\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0600 - accuracy: 0.9800 - val_loss: 6.8162e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0580 - accuracy: 0.9814 - val_loss: 0.0035 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0536 - accuracy: 0.9841 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1140 - accuracy: 0.9650 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 60ms/step - loss: 0.0657 - accuracy: 0.9815 - val_loss: 1.8213e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0512 - accuracy: 0.9830 - val_loss: 1.6978e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0529 - accuracy: 0.9836 - val_loss: 1.6575e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0644 - accuracy: 0.9778 - val_loss: 1.7696e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0522 - accuracy: 0.9827 - val_loss: 1.6926e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0567 - accuracy: 0.9808 - val_loss: 1.0299e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0466 - accuracy: 0.9860 - val_loss: 1.1314e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0542 - accuracy: 0.9809 - val_loss: 1.1092e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0507 - accuracy: 0.9827 - val_loss: 1.5456e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0435 - accuracy: 0.9863 - val_loss: 5.4007e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0547 - accuracy: 0.9821 - val_loss: 6.1950e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0426 - accuracy: 0.9863 - val_loss: 1.3183e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0662 - accuracy: 0.9788 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0407 - accuracy: 0.9875 - val_loss: 1.2687e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0537 - accuracy: 0.9826 - val_loss: 2.7286e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0394 - accuracy: 0.9863 - val_loss: 8.0873e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0463 - accuracy: 0.9864 - val_loss: 5.1923e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0443 - accuracy: 0.9873 - val_loss: 2.7375e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0518 - accuracy: 0.9829 - val_loss: 4.3736e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0584 - accuracy: 0.9830 - val_loss: 2.9949e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0867 - accuracy: 0.9736 - val_loss: 0.0017 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0749 - accuracy: 0.9768 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0566 - accuracy: 0.9818 - val_loss: 7.6106e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0456 - accuracy: 0.9864 - val_loss: 3.4218e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0476 - accuracy: 0.9841 - val_loss: 5.7398e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0487 - accuracy: 0.9841 - val_loss: 6.5217e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0425 - accuracy: 0.9869 - val_loss: 3.8404e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0457 - accuracy: 0.9867 - val_loss: 3.7109e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0375 - accuracy: 0.9888 - val_loss: 5.1890e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0601 - accuracy: 0.9809 - val_loss: 2.0678e-04 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0466 - accuracy: 0.9866 - val_loss: 1.8904e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0471 - accuracy: 0.9860 - val_loss: 4.7118e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0361 - accuracy: 0.9897 - val_loss: 4.5874e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0499 - accuracy: 0.9851 - val_loss: 1.9526e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0648 - accuracy: 0.9805 - val_loss: 1.4064e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0552 - accuracy: 0.9818 - val_loss: 1.8303e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0466 - accuracy: 0.9875 - val_loss: 6.5802e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0547 - accuracy: 0.9845 - val_loss: 9.7818e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0360 - accuracy: 0.9884 - val_loss: 1.7361e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0341 - accuracy: 0.9881 - val_loss: 8.0901e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0895 - accuracy: 0.9759 - val_loss: 3.3201e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0396 - accuracy: 0.9847 - val_loss: 1.9535e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0367 - accuracy: 0.9879 - val_loss: 6.0291e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0397 - accuracy: 0.9873 - val_loss: 3.4760e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0355 - accuracy: 0.9899 - val_loss: 2.0720e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0305 - accuracy: 0.9893 - val_loss: 4.3381e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0420 - accuracy: 0.9866 - val_loss: 3.5680e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0375 - accuracy: 0.9888 - val_loss: 3.1509e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0489 - accuracy: 0.9850 - val_loss: 2.6119e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0489 - accuracy: 0.9838 - val_loss: 6.0444e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0322 - accuracy: 0.9902 - val_loss: 8.8042e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0502 - accuracy: 0.9830 - val_loss: 7.5554e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0297 - accuracy: 0.9897 - val_loss: 1.4018e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0533 - accuracy: 0.9821 - val_loss: 1.6955e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0529 - accuracy: 0.9830 - val_loss: 7.8170e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0473 - accuracy: 0.9850 - val_loss: 0.0033 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0399 - accuracy: 0.9860 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0316 - accuracy: 0.9906 - val_loss: 5.0215e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0286 - accuracy: 0.9906 - val_loss: 0.0043 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0395 - accuracy: 0.9888 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 61ms/step - loss: 0.0393 - accuracy: 0.9870 - val_loss: 3.5852e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0433 - accuracy: 0.9861 - val_loss: 5.9935e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0337 - accuracy: 0.9888 - val_loss: 3.2800e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0312 - accuracy: 0.9917 - val_loss: 1.7183e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0388 - accuracy: 0.9888 - val_loss: 2.0494e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0369 - accuracy: 0.9869 - val_loss: 1.5928e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0432 - accuracy: 0.9858 - val_loss: 1.6587e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0356 - accuracy: 0.9875 - val_loss: 9.6143e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0338 - accuracy: 0.9881 - val_loss: 2.2278e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0344 - accuracy: 0.9893 - val_loss: 2.5669e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0481 - accuracy: 0.9857 - val_loss: 4.1014e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0465 - accuracy: 0.9867 - val_loss: 1.7037e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0351 - accuracy: 0.9881 - val_loss: 8.2948e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0374 - accuracy: 0.9893 - val_loss: 1.4612e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0367 - accuracy: 0.9903 - val_loss: 9.1665e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0396 - accuracy: 0.9884 - val_loss: 2.9947e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0483 - accuracy: 0.9857 - val_loss: 2.2043e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0521 - accuracy: 0.9836 - val_loss: 4.7160e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0367 - accuracy: 0.9885 - val_loss: 5.9929e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0357 - accuracy: 0.9878 - val_loss: 3.6846e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0435 - accuracy: 0.9867 - val_loss: 1.1720e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0321 - accuracy: 0.9890 - val_loss: 8.8619e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0303 - accuracy: 0.9915 - val_loss: 5.2976e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0285 - accuracy: 0.9911 - val_loss: 1.4311e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0468 - accuracy: 0.9857 - val_loss: 1.6768e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0252 - accuracy: 0.9928 - val_loss: 4.3736e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0281 - accuracy: 0.9914 - val_loss: 0.0013 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0353 - accuracy: 0.9882 - val_loss: 9.5590e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0317 - accuracy: 0.9903 - val_loss: 0.0025 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0374 - accuracy: 0.9893 - val_loss: 6.3872e-04 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0292 - accuracy: 0.9903 - val_loss: 8.0520e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0502 - accuracy: 0.9838 - val_loss: 2.6871e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0384 - accuracy: 0.9875 - val_loss: 1.1134e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0473 - accuracy: 0.9852 - val_loss: 1.1972e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0395 - accuracy: 0.9888 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0403 - accuracy: 0.9878 - val_loss: 1.2980e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0301 - accuracy: 0.9902 - val_loss: 1.6888e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0304 - accuracy: 0.9900 - val_loss: 1.9875e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0331 - accuracy: 0.9905 - val_loss: 4.4967e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0369 - accuracy: 0.9894 - val_loss: 7.7511e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0273 - accuracy: 0.9917 - val_loss: 2.0294e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0431 - accuracy: 0.9866 - val_loss: 2.6802e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0414 - accuracy: 0.9869 - val_loss: 1.2444e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0230 - accuracy: 0.9927 - val_loss: 3.7282e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0353 - accuracy: 0.9894 - val_loss: 3.4008e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0369 - accuracy: 0.9876 - val_loss: 1.7822e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0570 - accuracy: 0.9841 - val_loss: 1.9554e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0452 - accuracy: 0.9848 - val_loss: 2.6568e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0294 - accuracy: 0.9920 - val_loss: 3.1529e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0322 - accuracy: 0.9896 - val_loss: 8.0868e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0325 - accuracy: 0.9909 - val_loss: 2.3808e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0282 - accuracy: 0.9912 - val_loss: 8.2562e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0392 - accuracy: 0.9869 - val_loss: 1.2817e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0368 - accuracy: 0.9879 - val_loss: 3.2543e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0301 - accuracy: 0.9894 - val_loss: 3.3861e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0302 - accuracy: 0.9920 - val_loss: 0.0014 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0302 - accuracy: 0.9915 - val_loss: 7.8932e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0312 - accuracy: 0.9897 - val_loss: 2.5295e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0265 - accuracy: 0.9927 - val_loss: 2.4775e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0239 - accuracy: 0.9924 - val_loss: 7.4422e-04 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAnc2SJa3o9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "ce891ea2-0937-4a37-c7bc-707ea62a92c5"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 8ms/step - loss: 0.0775 - accuracy: 0.9855\n",
            "Accuracy  : 0.9855149984359741\n",
            "F1_Score  : 0.9850685228972639\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7fcxLuwZpkK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3543bd9-8ad7-47c8-b960-bd507d7c5902"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "dd6f5e31-49b8-426c-c64e-0e5d2e120181"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 5s 64ms/step - loss: 1.1201 - accuracy: 0.4708 - val_loss: 1.0445 - val_accuracy: 0.5241\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0471 - accuracy: 0.5172 - val_loss: 1.0249 - val_accuracy: 0.5241\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0384 - accuracy: 0.5173 - val_loss: 1.0249 - val_accuracy: 0.5241\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0414 - accuracy: 0.5131 - val_loss: 1.0183 - val_accuracy: 0.5241\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0205 - accuracy: 0.5336 - val_loss: 1.0254 - val_accuracy: 0.5241\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0192 - accuracy: 0.5190 - val_loss: 1.0255 - val_accuracy: 0.5241\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0140 - accuracy: 0.5240 - val_loss: 1.0266 - val_accuracy: 0.5241\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0113 - accuracy: 0.5286 - val_loss: 1.0121 - val_accuracy: 0.5241\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0160 - accuracy: 0.5180 - val_loss: 1.0069 - val_accuracy: 0.5241\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0137 - accuracy: 0.5209 - val_loss: 1.0011 - val_accuracy: 0.5295\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0047 - accuracy: 0.5261 - val_loss: 0.9988 - val_accuracy: 0.5295\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9972 - accuracy: 0.5292 - val_loss: 1.0081 - val_accuracy: 0.5282\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0062 - accuracy: 0.5291 - val_loss: 1.0029 - val_accuracy: 0.5389\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0005 - accuracy: 0.5277 - val_loss: 0.9899 - val_accuracy: 0.5308\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9952 - accuracy: 0.5330 - val_loss: 0.9913 - val_accuracy: 0.5228\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9964 - accuracy: 0.5259 - val_loss: 0.9899 - val_accuracy: 0.5349\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9953 - accuracy: 0.5321 - val_loss: 0.9910 - val_accuracy: 0.5282\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9848 - accuracy: 0.5314 - val_loss: 0.9804 - val_accuracy: 0.5282\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9786 - accuracy: 0.5426 - val_loss: 0.9920 - val_accuracy: 0.5416\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9881 - accuracy: 0.5282 - val_loss: 0.9793 - val_accuracy: 0.5295\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9921 - accuracy: 0.5277 - val_loss: 0.9986 - val_accuracy: 0.5188\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9892 - accuracy: 0.5246 - val_loss: 0.9620 - val_accuracy: 0.5429\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9791 - accuracy: 0.5351 - val_loss: 0.9617 - val_accuracy: 0.5335\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9691 - accuracy: 0.5422 - val_loss: 0.9598 - val_accuracy: 0.5442\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9735 - accuracy: 0.5371 - val_loss: 0.9593 - val_accuracy: 0.5429\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9565 - accuracy: 0.5432 - val_loss: 0.9535 - val_accuracy: 0.5509\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9666 - accuracy: 0.5376 - val_loss: 0.9825 - val_accuracy: 0.5308\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9522 - accuracy: 0.5501 - val_loss: 0.9407 - val_accuracy: 0.5536\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9488 - accuracy: 0.5536 - val_loss: 0.9533 - val_accuracy: 0.5335\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9599 - accuracy: 0.5455 - val_loss: 0.9753 - val_accuracy: 0.5416\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9514 - accuracy: 0.5523 - val_loss: 0.9598 - val_accuracy: 0.5362\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9480 - accuracy: 0.5522 - val_loss: 0.9431 - val_accuracy: 0.5657\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9487 - accuracy: 0.5489 - val_loss: 0.9534 - val_accuracy: 0.5295\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9453 - accuracy: 0.5531 - val_loss: 0.9358 - val_accuracy: 0.5590\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9450 - accuracy: 0.5532 - val_loss: 0.9645 - val_accuracy: 0.5483\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9237 - accuracy: 0.5614 - val_loss: 0.9464 - val_accuracy: 0.5442\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9230 - accuracy: 0.5681 - val_loss: 0.9368 - val_accuracy: 0.5764\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9172 - accuracy: 0.5723 - val_loss: 0.9224 - val_accuracy: 0.5617\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9199 - accuracy: 0.5666 - val_loss: 0.9290 - val_accuracy: 0.5416\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9221 - accuracy: 0.5674 - val_loss: 0.9180 - val_accuracy: 0.5724\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9049 - accuracy: 0.5772 - val_loss: 0.9678 - val_accuracy: 0.5362\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8993 - accuracy: 0.5878 - val_loss: 0.9022 - val_accuracy: 0.5764\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8938 - accuracy: 0.5920 - val_loss: 0.8926 - val_accuracy: 0.5831\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8908 - accuracy: 0.5948 - val_loss: 0.9067 - val_accuracy: 0.5724\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8713 - accuracy: 0.5979 - val_loss: 0.8892 - val_accuracy: 0.5925\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.8724 - accuracy: 0.6077 - val_loss: 0.8845 - val_accuracy: 0.5831\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8550 - accuracy: 0.6106 - val_loss: 0.8746 - val_accuracy: 0.5925\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8559 - accuracy: 0.6119 - val_loss: 0.8575 - val_accuracy: 0.6032\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8252 - accuracy: 0.6295 - val_loss: 0.8621 - val_accuracy: 0.5952\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8142 - accuracy: 0.6314 - val_loss: 0.8409 - val_accuracy: 0.6059\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8101 - accuracy: 0.6410 - val_loss: 0.8488 - val_accuracy: 0.6046\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8008 - accuracy: 0.6414 - val_loss: 0.8415 - val_accuracy: 0.5938\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.7708 - accuracy: 0.6562 - val_loss: 0.8576 - val_accuracy: 0.5764\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.7653 - accuracy: 0.6620 - val_loss: 0.8324 - val_accuracy: 0.6072\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.7340 - accuracy: 0.6708 - val_loss: 0.7692 - val_accuracy: 0.6501\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7285 - accuracy: 0.6775 - val_loss: 0.7837 - val_accuracy: 0.6287\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.6907 - accuracy: 0.6981 - val_loss: 0.7060 - val_accuracy: 0.6729\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.6822 - accuracy: 0.7043 - val_loss: 0.6852 - val_accuracy: 0.6877\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.6534 - accuracy: 0.7215 - val_loss: 0.7295 - val_accuracy: 0.6609\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.6227 - accuracy: 0.7389 - val_loss: 0.6914 - val_accuracy: 0.6877\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.6455 - accuracy: 0.7240 - val_loss: 0.5011 - val_accuracy: 0.7815\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.5922 - accuracy: 0.7522 - val_loss: 0.4746 - val_accuracy: 0.8351\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.5712 - accuracy: 0.7587 - val_loss: 0.4578 - val_accuracy: 0.8043\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.5475 - accuracy: 0.7772 - val_loss: 0.4215 - val_accuracy: 0.8150\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.4966 - accuracy: 0.8018 - val_loss: 0.4408 - val_accuracy: 0.8029\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.4692 - accuracy: 0.8077 - val_loss: 0.3594 - val_accuracy: 0.8673\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.4460 - accuracy: 0.8265 - val_loss: 0.3374 - val_accuracy: 0.8834\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.4144 - accuracy: 0.8373 - val_loss: 0.2779 - val_accuracy: 0.9008\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.4116 - accuracy: 0.8419 - val_loss: 0.2950 - val_accuracy: 0.8874\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.3813 - accuracy: 0.8575 - val_loss: 0.3438 - val_accuracy: 0.8727\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.3617 - accuracy: 0.8618 - val_loss: 0.2563 - val_accuracy: 0.8995\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3137 - accuracy: 0.8814 - val_loss: 0.2668 - val_accuracy: 0.8995\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2855 - accuracy: 0.9000 - val_loss: 0.2601 - val_accuracy: 0.8995\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3191 - accuracy: 0.8869 - val_loss: 0.2411 - val_accuracy: 0.9142\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2815 - accuracy: 0.9019 - val_loss: 0.2016 - val_accuracy: 0.9209\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2506 - accuracy: 0.9085 - val_loss: 0.2150 - val_accuracy: 0.9236\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2345 - accuracy: 0.9168 - val_loss: 0.1986 - val_accuracy: 0.9249\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2205 - accuracy: 0.9195 - val_loss: 0.2083 - val_accuracy: 0.9249\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2275 - accuracy: 0.9192 - val_loss: 0.1696 - val_accuracy: 0.9464\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2094 - accuracy: 0.9270 - val_loss: 0.1807 - val_accuracy: 0.9357\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.2102 - accuracy: 0.9261 - val_loss: 0.1383 - val_accuracy: 0.9558\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2044 - accuracy: 0.9283 - val_loss: 0.1418 - val_accuracy: 0.9517\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1803 - accuracy: 0.9362 - val_loss: 0.1416 - val_accuracy: 0.9477\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1706 - accuracy: 0.9404 - val_loss: 0.1678 - val_accuracy: 0.9491\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1578 - accuracy: 0.9486 - val_loss: 0.1416 - val_accuracy: 0.9450\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1686 - accuracy: 0.9401 - val_loss: 0.1405 - val_accuracy: 0.9437\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1585 - accuracy: 0.9446 - val_loss: 0.1207 - val_accuracy: 0.9638\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1550 - accuracy: 0.9444 - val_loss: 0.1333 - val_accuracy: 0.9571\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1433 - accuracy: 0.9538 - val_loss: 0.1167 - val_accuracy: 0.9598\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1446 - accuracy: 0.9529 - val_loss: 0.1779 - val_accuracy: 0.9290\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1742 - accuracy: 0.9399 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1457 - accuracy: 0.9490 - val_loss: 0.0139 - val_accuracy: 0.9973\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1578 - accuracy: 0.9474 - val_loss: 0.0233 - val_accuracy: 0.9933\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1447 - accuracy: 0.9528 - val_loss: 0.0202 - val_accuracy: 0.9960\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1814 - accuracy: 0.9387 - val_loss: 0.0167 - val_accuracy: 0.9987\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1184 - accuracy: 0.9608 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1193 - accuracy: 0.9580 - val_loss: 0.0116 - val_accuracy: 0.9973\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1038 - accuracy: 0.9657 - val_loss: 0.0133 - val_accuracy: 0.9973\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1280 - accuracy: 0.9572 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1111 - accuracy: 0.9650 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0994 - accuracy: 0.9668 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1101 - accuracy: 0.9635 - val_loss: 0.0102 - val_accuracy: 0.9973\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0984 - accuracy: 0.9669 - val_loss: 0.0126 - val_accuracy: 0.9960\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1328 - accuracy: 0.9566 - val_loss: 0.0170 - val_accuracy: 0.9973\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0966 - accuracy: 0.9712 - val_loss: 0.0106 - val_accuracy: 0.9973\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0887 - accuracy: 0.9687 - val_loss: 0.0098 - val_accuracy: 0.9973\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1012 - accuracy: 0.9677 - val_loss: 0.0101 - val_accuracy: 0.9973\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0960 - accuracy: 0.9681 - val_loss: 0.0099 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0997 - accuracy: 0.9675 - val_loss: 0.0072 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0904 - accuracy: 0.9705 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0825 - accuracy: 0.9735 - val_loss: 0.0094 - val_accuracy: 0.9973\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0757 - accuracy: 0.9765 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0752 - accuracy: 0.9754 - val_loss: 0.0070 - val_accuracy: 0.9973\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0820 - accuracy: 0.9744 - val_loss: 0.0097 - val_accuracy: 0.9973\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1424 - accuracy: 0.9511 - val_loss: 0.0111 - val_accuracy: 0.9973\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0913 - accuracy: 0.9696 - val_loss: 0.0071 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0721 - accuracy: 0.9750 - val_loss: 0.0200 - val_accuracy: 0.9946\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0893 - accuracy: 0.9714 - val_loss: 0.0234 - val_accuracy: 0.9933\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0675 - accuracy: 0.9765 - val_loss: 0.0064 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0589 - accuracy: 0.9820 - val_loss: 0.0090 - val_accuracy: 0.9987\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0782 - accuracy: 0.9745 - val_loss: 5.2176e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1034 - accuracy: 0.9674 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0627 - accuracy: 0.9793 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0804 - accuracy: 0.9745 - val_loss: 0.0060 - val_accuracy: 0.9973\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0941 - accuracy: 0.9678 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0677 - accuracy: 0.9785 - val_loss: 0.0026 - val_accuracy: 0.9987\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0519 - accuracy: 0.9833 - val_loss: 3.8648e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0726 - accuracy: 0.9753 - val_loss: 4.5463e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0755 - accuracy: 0.9765 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0645 - accuracy: 0.9787 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0618 - accuracy: 0.9800 - val_loss: 9.5731e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0696 - accuracy: 0.9763 - val_loss: 8.1054e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0482 - accuracy: 0.9812 - val_loss: 2.5788e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0551 - accuracy: 0.9823 - val_loss: 5.6162e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0666 - accuracy: 0.9799 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0745 - accuracy: 0.9751 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1094 - accuracy: 0.9684 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0604 - accuracy: 0.9815 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0922 - accuracy: 0.9709 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0500 - accuracy: 0.9844 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0588 - accuracy: 0.9812 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0617 - accuracy: 0.9797 - val_loss: 6.8723e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0605 - accuracy: 0.9794 - val_loss: 8.8594e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0561 - accuracy: 0.9818 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0619 - accuracy: 0.9809 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0551 - accuracy: 0.9809 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0791 - accuracy: 0.9742 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 60ms/step - loss: 0.0582 - accuracy: 0.9805 - val_loss: 0.0021 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0598 - accuracy: 0.9808 - val_loss: 5.8460e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0534 - accuracy: 0.9849 - val_loss: 0.0031 - val_accuracy: 0.9987\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0575 - accuracy: 0.9800 - val_loss: 3.9640e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0406 - accuracy: 0.9875 - val_loss: 1.7837e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0563 - accuracy: 0.9829 - val_loss: 1.6636e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0742 - accuracy: 0.9753 - val_loss: 6.1682e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0465 - accuracy: 0.9841 - val_loss: 5.7691e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0617 - accuracy: 0.9814 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0465 - accuracy: 0.9842 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0663 - accuracy: 0.9800 - val_loss: 3.8921e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0577 - accuracy: 0.9824 - val_loss: 7.3682e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0468 - accuracy: 0.9844 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0414 - accuracy: 0.9866 - val_loss: 2.6861e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0444 - accuracy: 0.9866 - val_loss: 3.8269e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0420 - accuracy: 0.9855 - val_loss: 4.1816e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0463 - accuracy: 0.9846 - val_loss: 6.8648e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0409 - accuracy: 0.9863 - val_loss: 7.1292e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0463 - accuracy: 0.9869 - val_loss: 1.4291e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0479 - accuracy: 0.9866 - val_loss: 3.0145e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0404 - accuracy: 0.9867 - val_loss: 8.8644e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0507 - accuracy: 0.9821 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0473 - accuracy: 0.9846 - val_loss: 6.1190e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0489 - accuracy: 0.9841 - val_loss: 1.8514e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0403 - accuracy: 0.9879 - val_loss: 4.3373e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0587 - accuracy: 0.9835 - val_loss: 0.0017 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0497 - accuracy: 0.9836 - val_loss: 8.5065e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0709 - accuracy: 0.9781 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0540 - accuracy: 0.9832 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0529 - accuracy: 0.9824 - val_loss: 0.0026 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0872 - accuracy: 0.9726 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0420 - accuracy: 0.9861 - val_loss: 4.5737e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0392 - accuracy: 0.9872 - val_loss: 5.0507e-04 - val_accuracy: 1.0000\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0469 - accuracy: 0.9851 - val_loss: 1.4011e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0594 - accuracy: 0.9818 - val_loss: 6.9101e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0514 - accuracy: 0.9857 - val_loss: 2.7950e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0446 - accuracy: 0.9861 - val_loss: 8.4430e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0466 - accuracy: 0.9858 - val_loss: 1.5187e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0459 - accuracy: 0.9841 - val_loss: 1.5371e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0556 - accuracy: 0.9823 - val_loss: 1.5852e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0460 - accuracy: 0.9848 - val_loss: 4.3878e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0456 - accuracy: 0.9860 - val_loss: 1.7449e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0322 - accuracy: 0.9903 - val_loss: 7.8862e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0461 - accuracy: 0.9875 - val_loss: 6.6004e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0362 - accuracy: 0.9893 - val_loss: 4.7354e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0298 - accuracy: 0.9900 - val_loss: 3.4246e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0410 - accuracy: 0.9870 - val_loss: 8.2104e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0517 - accuracy: 0.9850 - val_loss: 0.0013 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0434 - accuracy: 0.9863 - val_loss: 2.7647e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0320 - accuracy: 0.9885 - val_loss: 1.0791e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0424 - accuracy: 0.9855 - val_loss: 4.5273e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0326 - accuracy: 0.9891 - val_loss: 2.0153e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0618 - accuracy: 0.9817 - val_loss: 2.0902e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0321 - accuracy: 0.9899 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0364 - accuracy: 0.9884 - val_loss: 9.3001e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0417 - accuracy: 0.9852 - val_loss: 2.4456e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0441 - accuracy: 0.9869 - val_loss: 4.6624e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0322 - accuracy: 0.9894 - val_loss: 0.0027 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0431 - accuracy: 0.9869 - val_loss: 1.6104e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0334 - accuracy: 0.9890 - val_loss: 1.6992e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0378 - accuracy: 0.9887 - val_loss: 0.0015 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0349 - accuracy: 0.9894 - val_loss: 6.8169e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0349 - accuracy: 0.9891 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0334 - accuracy: 0.9885 - val_loss: 3.8674e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0350 - accuracy: 0.9902 - val_loss: 1.8465e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0438 - accuracy: 0.9850 - val_loss: 8.0975e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0521 - accuracy: 0.9854 - val_loss: 2.4859e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0376 - accuracy: 0.9875 - val_loss: 3.5391e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0283 - accuracy: 0.9909 - val_loss: 1.7706e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0327 - accuracy: 0.9879 - val_loss: 6.1019e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0383 - accuracy: 0.9884 - val_loss: 2.5278e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0295 - accuracy: 0.9902 - val_loss: 2.8381e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0407 - accuracy: 0.9864 - val_loss: 4.0193e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0367 - accuracy: 0.9888 - val_loss: 6.6398e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0447 - accuracy: 0.9847 - val_loss: 9.0782e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0337 - accuracy: 0.9882 - val_loss: 2.3302e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0285 - accuracy: 0.9896 - val_loss: 4.3924e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0220 - accuracy: 0.9931 - val_loss: 1.5627e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0443 - accuracy: 0.9852 - val_loss: 2.1595e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0333 - accuracy: 0.9887 - val_loss: 2.8346e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0750 - accuracy: 0.9781 - val_loss: 4.9050e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0471 - accuracy: 0.9854 - val_loss: 1.4093e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0402 - accuracy: 0.9876 - val_loss: 4.5472e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0311 - accuracy: 0.9917 - val_loss: 6.8192e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0298 - accuracy: 0.9899 - val_loss: 3.9405e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0274 - accuracy: 0.9925 - val_loss: 3.4383e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0375 - accuracy: 0.9875 - val_loss: 5.3047e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0264 - accuracy: 0.9917 - val_loss: 1.3434e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0234 - accuracy: 0.9930 - val_loss: 1.2767e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0252 - accuracy: 0.9921 - val_loss: 7.4612e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0349 - accuracy: 0.9881 - val_loss: 5.0490e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0342 - accuracy: 0.9893 - val_loss: 1.1020e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0343 - accuracy: 0.9875 - val_loss: 8.3926e-05 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0295 - accuracy: 0.9911 - val_loss: 1.3381e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0327 - accuracy: 0.9891 - val_loss: 2.8129e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0422 - accuracy: 0.9878 - val_loss: 3.7407e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0354 - accuracy: 0.9876 - val_loss: 3.3719e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0240 - accuracy: 0.9933 - val_loss: 6.9152e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0288 - accuracy: 0.9908 - val_loss: 1.8530e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0282 - accuracy: 0.9928 - val_loss: 2.1879e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0346 - accuracy: 0.9890 - val_loss: 3.6581e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0309 - accuracy: 0.9911 - val_loss: 4.3728e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0316 - accuracy: 0.9894 - val_loss: 1.6681e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0362 - accuracy: 0.9872 - val_loss: 1.1879e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0215 - accuracy: 0.9928 - val_loss: 2.3019e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0279 - accuracy: 0.9903 - val_loss: 3.9499e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0330 - accuracy: 0.9899 - val_loss: 0.0025 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0318 - accuracy: 0.9906 - val_loss: 4.0539e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0228 - accuracy: 0.9923 - val_loss: 5.4951e-06 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0281 - accuracy: 0.9903 - val_loss: 0.0018 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0387 - accuracy: 0.9884 - val_loss: 2.4511e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0408 - accuracy: 0.9872 - val_loss: 1.1283e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0380 - accuracy: 0.9885 - val_loss: 0.0038 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0297 - accuracy: 0.9906 - val_loss: 1.9297e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0350 - accuracy: 0.9879 - val_loss: 5.6516e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0337 - accuracy: 0.9891 - val_loss: 7.0411e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0238 - accuracy: 0.9928 - val_loss: 1.5571e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0202 - accuracy: 0.9931 - val_loss: 1.1246e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0276 - accuracy: 0.9917 - val_loss: 9.3884e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0288 - accuracy: 0.9908 - val_loss: 1.6716e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0249 - accuracy: 0.9920 - val_loss: 3.3866e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0245 - accuracy: 0.9925 - val_loss: 4.9274e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0214 - accuracy: 0.9931 - val_loss: 3.6503e-05 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0262 - accuracy: 0.9925 - val_loss: 1.5779e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0334 - accuracy: 0.9909 - val_loss: 2.4774e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0253 - accuracy: 0.9912 - val_loss: 2.9993e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0244 - accuracy: 0.9933 - val_loss: 1.2541e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0248 - accuracy: 0.9927 - val_loss: 2.7860e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0296 - accuracy: 0.9905 - val_loss: 2.9449e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0380 - accuracy: 0.9879 - val_loss: 3.4738e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0284 - accuracy: 0.9894 - val_loss: 7.2310e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0434 - accuracy: 0.9861 - val_loss: 1.7432e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0309 - accuracy: 0.9900 - val_loss: 5.7397e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0287 - accuracy: 0.9920 - val_loss: 1.4862e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0278 - accuracy: 0.9899 - val_loss: 6.3203e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0305 - accuracy: 0.9911 - val_loss: 1.5190e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0282 - accuracy: 0.9902 - val_loss: 7.9301e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0330 - accuracy: 0.9899 - val_loss: 2.7490e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0336 - accuracy: 0.9903 - val_loss: 8.7178e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0325 - accuracy: 0.9887 - val_loss: 2.2691e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0288 - accuracy: 0.9918 - val_loss: 9.4996e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0261 - accuracy: 0.9921 - val_loss: 2.0215e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0198 - accuracy: 0.9942 - val_loss: 1.2866e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0265 - accuracy: 0.9906 - val_loss: 3.5281e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0329 - accuracy: 0.9891 - val_loss: 1.3301e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0316 - accuracy: 0.9915 - val_loss: 7.1589e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0292 - accuracy: 0.9908 - val_loss: 1.5616e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0256 - accuracy: 0.9912 - val_loss: 2.5768e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0248 - accuracy: 0.9925 - val_loss: 4.5126e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0237 - accuracy: 0.9930 - val_loss: 2.1227e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0349 - accuracy: 0.9896 - val_loss: 2.1297e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0326 - accuracy: 0.9893 - val_loss: 2.5439e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0232 - accuracy: 0.9923 - val_loss: 2.0929e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "b34f5bf6-1859-42de-82a6-05bd5a19db46"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 8ms/step - loss: 0.0394 - accuracy: 0.9930\n",
            "Accuracy  : 0.9930257797241211\n",
            "F1_Score  : 0.9923533130500344\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "332b7138-1d09-4e8c-a213-3535a3d67795"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'#dominance\\nX_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\\nprint(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "6e094535-8767-4f8b-cfaa-cc6f49a6cdb8"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'foldNum=0\\nmodel = get_model()\\nfor train_index, val_index in kfold.split(X_train, Y_train):\\n  foldNum = foldNum + 1\\n  print(\"Results for fold\",foldNum)\\n  x_train, x_val = X_train[train_index], X_train[val_index]\\n  y_train, y_val = Y_train[train_index], Y_train[val_index]\\n  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\\n  gc.collect() # Garbage collecter\\n  del x_train, x_val, y_train, y_val\\n  gc.collect()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "8b7f2a34-85d9-4edb-f778-fab59a1c4532"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'acrc = model.evaluate(x_test, y_test)\\npred = model.predict(x_test)\\nf1scr = f1_score(y_test.argmax(1), pred.argmax(1), average=\\'macro\\')\\nc_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\\nprint(\"Accuracy  : {}\".format(acrc[1]))\\nprint(\"F1_Score  : {}\".format(f1scr))\\nc_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\\nimport seaborn as sns\\nfigure = plt.figure(figsize=(9, 9))\\nsns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\\nplt.tight_layout()\\nplt.ylabel(\\'True label\\')\\nplt.xlabel(\\'Predicted label\\')\\nplt.show()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}