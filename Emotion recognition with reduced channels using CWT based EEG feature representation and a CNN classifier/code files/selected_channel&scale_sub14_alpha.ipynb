{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub14_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "22075df1-4a6f-46da-fa0d-91923ceb4286"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e3\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "708030d8-0876-42ec-e518-f432e740d479"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(14,15):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.14\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (4427,) (466,) (4427,)\n",
            "(9320,) (2563,) (2330,) (4427,)\n",
            "(9320,) (3728,) (1864,) (3728,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "00b594ec-c131-4616-e225-9db433642ed0"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "aba64208-c1bb-4489-92f1-d463783f071f"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "809"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "7fc203b3-2e86-4e60-d1f9-71d3d8cb51ac"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f410e53-29e9-4e13-df74-d75dff37e17b"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 24s 62ms/step - loss: 0.9795 - accuracy: 0.5062 - val_loss: 0.8865 - val_accuracy: 0.4772\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8817 - accuracy: 0.5267 - val_loss: 0.8760 - val_accuracy: 0.5469\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8726 - accuracy: 0.5458 - val_loss: 0.8576 - val_accuracy: 0.5536\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8664 - accuracy: 0.5375 - val_loss: 0.8530 - val_accuracy: 0.5630\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8653 - accuracy: 0.5581 - val_loss: 0.8594 - val_accuracy: 0.5710\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8507 - accuracy: 0.5654 - val_loss: 0.8581 - val_accuracy: 0.5630\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8521 - accuracy: 0.5649 - val_loss: 0.8622 - val_accuracy: 0.5617\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8450 - accuracy: 0.5583 - val_loss: 0.8935 - val_accuracy: 0.5228\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8364 - accuracy: 0.5525 - val_loss: 0.8624 - val_accuracy: 0.5469\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8550 - accuracy: 0.5478 - val_loss: 0.8556 - val_accuracy: 0.5657\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8327 - accuracy: 0.5688 - val_loss: 0.8654 - val_accuracy: 0.5429\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8453 - accuracy: 0.5639 - val_loss: 0.9231 - val_accuracy: 0.5228\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8397 - accuracy: 0.5596 - val_loss: 0.8707 - val_accuracy: 0.5456\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8393 - accuracy: 0.5591 - val_loss: 0.8503 - val_accuracy: 0.5496\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8381 - accuracy: 0.5654 - val_loss: 0.8824 - val_accuracy: 0.5375\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8222 - accuracy: 0.5746 - val_loss: 0.8596 - val_accuracy: 0.5456\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8248 - accuracy: 0.5735 - val_loss: 0.8966 - val_accuracy: 0.5282\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8291 - accuracy: 0.5657 - val_loss: 0.8856 - val_accuracy: 0.5509\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8264 - accuracy: 0.5659 - val_loss: 0.8453 - val_accuracy: 0.5697\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8197 - accuracy: 0.5723 - val_loss: 0.8565 - val_accuracy: 0.5643\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8301 - accuracy: 0.5539 - val_loss: 0.8329 - val_accuracy: 0.5684\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8147 - accuracy: 0.5630 - val_loss: 0.8777 - val_accuracy: 0.5550\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8132 - accuracy: 0.5871 - val_loss: 0.8452 - val_accuracy: 0.5563\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8130 - accuracy: 0.5871 - val_loss: 0.8500 - val_accuracy: 0.5697\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8048 - accuracy: 0.5859 - val_loss: 0.8318 - val_accuracy: 0.5764\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8126 - accuracy: 0.5838 - val_loss: 0.8515 - val_accuracy: 0.5536\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8057 - accuracy: 0.5844 - val_loss: 0.8375 - val_accuracy: 0.5818\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8082 - accuracy: 0.5822 - val_loss: 0.8554 - val_accuracy: 0.5603\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8003 - accuracy: 0.5787 - val_loss: 0.8535 - val_accuracy: 0.5818\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8048 - accuracy: 0.5928 - val_loss: 0.8536 - val_accuracy: 0.5643\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7936 - accuracy: 0.6016 - val_loss: 0.7459 - val_accuracy: 0.6019\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7945 - accuracy: 0.5987 - val_loss: 0.7530 - val_accuracy: 0.5912\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7816 - accuracy: 0.6100 - val_loss: 0.7412 - val_accuracy: 0.6166\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7611 - accuracy: 0.6216 - val_loss: 0.7421 - val_accuracy: 0.6126\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7665 - accuracy: 0.6194 - val_loss: 0.7069 - val_accuracy: 0.6287\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7411 - accuracy: 0.6352 - val_loss: 0.7051 - val_accuracy: 0.6340\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7258 - accuracy: 0.6466 - val_loss: 0.6975 - val_accuracy: 0.6287\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7038 - accuracy: 0.6565 - val_loss: 0.6729 - val_accuracy: 0.6582\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6832 - accuracy: 0.6729 - val_loss: 0.6468 - val_accuracy: 0.6649\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6484 - accuracy: 0.6942 - val_loss: 0.6574 - val_accuracy: 0.6555\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6448 - accuracy: 0.6888 - val_loss: 0.7074 - val_accuracy: 0.6340\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5884 - accuracy: 0.7288 - val_loss: 0.7509 - val_accuracy: 0.6475\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5791 - accuracy: 0.7458 - val_loss: 0.7066 - val_accuracy: 0.6568\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5466 - accuracy: 0.7511 - val_loss: 0.4756 - val_accuracy: 0.7976\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5038 - accuracy: 0.7768 - val_loss: 0.5147 - val_accuracy: 0.7574\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4476 - accuracy: 0.8072 - val_loss: 0.5074 - val_accuracy: 0.7882\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3994 - accuracy: 0.8396 - val_loss: 0.5046 - val_accuracy: 0.7721\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4044 - accuracy: 0.8359 - val_loss: 0.3759 - val_accuracy: 0.8633\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3309 - accuracy: 0.8677 - val_loss: 0.3279 - val_accuracy: 0.8807\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3333 - accuracy: 0.8681 - val_loss: 0.3461 - val_accuracy: 0.8753\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3281 - accuracy: 0.8703 - val_loss: 0.3082 - val_accuracy: 0.8847\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2853 - accuracy: 0.8873 - val_loss: 0.4734 - val_accuracy: 0.8056\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2534 - accuracy: 0.9033 - val_loss: 0.3454 - val_accuracy: 0.8633\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2370 - accuracy: 0.9097 - val_loss: 0.2404 - val_accuracy: 0.9021\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2387 - accuracy: 0.9128 - val_loss: 0.2646 - val_accuracy: 0.9048\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2116 - accuracy: 0.9203 - val_loss: 0.1770 - val_accuracy: 0.9397\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2010 - accuracy: 0.9230 - val_loss: 0.1891 - val_accuracy: 0.9290\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1820 - accuracy: 0.9329 - val_loss: 0.2139 - val_accuracy: 0.9290\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1656 - accuracy: 0.9407 - val_loss: 0.1474 - val_accuracy: 0.9517\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1495 - accuracy: 0.9483 - val_loss: 0.1388 - val_accuracy: 0.9544\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1676 - accuracy: 0.9440 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1537 - accuracy: 0.9452 - val_loss: 0.0257 - val_accuracy: 0.9920\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2144 - accuracy: 0.9274 - val_loss: 0.8564 - val_accuracy: 0.7735\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1677 - accuracy: 0.9411 - val_loss: 0.0160 - val_accuracy: 0.9960\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1243 - accuracy: 0.9583 - val_loss: 0.0141 - val_accuracy: 0.9960\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1127 - accuracy: 0.9617 - val_loss: 0.0161 - val_accuracy: 0.9906\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1147 - accuracy: 0.9615 - val_loss: 0.0168 - val_accuracy: 0.9960\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1130 - accuracy: 0.9617 - val_loss: 0.0143 - val_accuracy: 0.9973\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1075 - accuracy: 0.9651 - val_loss: 0.0113 - val_accuracy: 0.9973\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0994 - accuracy: 0.9671 - val_loss: 0.0105 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1071 - accuracy: 0.9629 - val_loss: 0.0166 - val_accuracy: 0.9960\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0933 - accuracy: 0.9690 - val_loss: 0.0125 - val_accuracy: 0.9960\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0859 - accuracy: 0.9720 - val_loss: 0.0252 - val_accuracy: 0.9933\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0916 - accuracy: 0.9681 - val_loss: 0.0205 - val_accuracy: 0.9906\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0920 - accuracy: 0.9724 - val_loss: 0.0107 - val_accuracy: 0.9973\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0756 - accuracy: 0.9747 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0810 - accuracy: 0.9724 - val_loss: 0.0107 - val_accuracy: 0.9960\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0965 - accuracy: 0.9684 - val_loss: 0.0181 - val_accuracy: 0.9933\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0643 - accuracy: 0.9776 - val_loss: 0.0232 - val_accuracy: 0.9893\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0687 - accuracy: 0.9762 - val_loss: 0.0079 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0704 - accuracy: 0.9768 - val_loss: 0.0110 - val_accuracy: 0.9960\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0658 - accuracy: 0.9773 - val_loss: 0.0125 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0773 - accuracy: 0.9742 - val_loss: 0.0113 - val_accuracy: 0.9973\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0641 - accuracy: 0.9791 - val_loss: 0.0062 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0563 - accuracy: 0.9805 - val_loss: 0.0088 - val_accuracy: 0.9960\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0481 - accuracy: 0.9845 - val_loss: 0.0221 - val_accuracy: 0.9933\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0716 - accuracy: 0.9769 - val_loss: 0.0204 - val_accuracy: 0.9946\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0546 - accuracy: 0.9811 - val_loss: 0.0135 - val_accuracy: 0.9933\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0520 - accuracy: 0.9836 - val_loss: 0.0089 - val_accuracy: 0.9973\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0539 - accuracy: 0.9808 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0752 - accuracy: 0.9739 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0577 - accuracy: 0.9809 - val_loss: 4.5251e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0582 - accuracy: 0.9820 - val_loss: 3.4103e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0738 - accuracy: 0.9772 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0558 - accuracy: 0.9820 - val_loss: 4.9013e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0415 - accuracy: 0.9875 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0493 - accuracy: 0.9848 - val_loss: 8.8819e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0699 - accuracy: 0.9763 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0598 - accuracy: 0.9806 - val_loss: 9.8703e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0386 - accuracy: 0.9863 - val_loss: 3.7487e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0485 - accuracy: 0.9849 - val_loss: 5.5251e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0410 - accuracy: 0.9879 - val_loss: 2.6841e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0440 - accuracy: 0.9863 - val_loss: 9.9609e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0539 - accuracy: 0.9820 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0493 - accuracy: 0.9841 - val_loss: 0.0071 - val_accuracy: 0.9973\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0434 - accuracy: 0.9873 - val_loss: 0.0033 - val_accuracy: 0.9987\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0340 - accuracy: 0.9903 - val_loss: 4.3058e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0515 - accuracy: 0.9849 - val_loss: 0.0024 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0345 - accuracy: 0.9885 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0488 - accuracy: 0.9842 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0332 - accuracy: 0.9900 - val_loss: 0.0019 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0367 - accuracy: 0.9869 - val_loss: 0.0029 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0934 - accuracy: 0.9714 - val_loss: 0.0591 - val_accuracy: 0.9786\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0444 - accuracy: 0.9860 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0368 - accuracy: 0.9891 - val_loss: 6.5787e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0417 - accuracy: 0.9867 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0431 - accuracy: 0.9845 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0515 - accuracy: 0.9821 - val_loss: 0.0016 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0391 - accuracy: 0.9875 - val_loss: 0.0070 - val_accuracy: 0.9960\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0422 - accuracy: 0.9869 - val_loss: 8.9633e-04 - val_accuracy: 1.0000\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0380 - accuracy: 0.9890 - val_loss: 9.4893e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0438 - accuracy: 0.9869 - val_loss: 3.7693e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0670 - accuracy: 0.9769 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0605 - accuracy: 0.9811 - val_loss: 1.0321e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0324 - accuracy: 0.9908 - val_loss: 2.5869e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0376 - accuracy: 0.9882 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0390 - accuracy: 0.9878 - val_loss: 7.8552e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0385 - accuracy: 0.9873 - val_loss: 1.7587e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0315 - accuracy: 0.9896 - val_loss: 9.3846e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0316 - accuracy: 0.9903 - val_loss: 2.0197e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0330 - accuracy: 0.9912 - val_loss: 1.6525e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0353 - accuracy: 0.9896 - val_loss: 1.6111e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0316 - accuracy: 0.9903 - val_loss: 6.7879e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0307 - accuracy: 0.9888 - val_loss: 1.5402e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1431 - accuracy: 0.9615 - val_loss: 0.0109 - val_accuracy: 0.9973\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0494 - accuracy: 0.9845 - val_loss: 4.8480e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0458 - accuracy: 0.9852 - val_loss: 9.5859e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0442 - accuracy: 0.9878 - val_loss: 5.4068e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0555 - accuracy: 0.9827 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0399 - accuracy: 0.9884 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0365 - accuracy: 0.9894 - val_loss: 7.8321e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0229 - accuracy: 0.9928 - val_loss: 2.5169e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0297 - accuracy: 0.9906 - val_loss: 2.7772e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0210 - accuracy: 0.9930 - val_loss: 1.9721e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0292 - accuracy: 0.9897 - val_loss: 0.0027 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0326 - accuracy: 0.9905 - val_loss: 8.8897e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0192 - accuracy: 0.9942 - val_loss: 7.1757e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0246 - accuracy: 0.9921 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0374 - accuracy: 0.9866 - val_loss: 1.3325e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0338 - accuracy: 0.9899 - val_loss: 9.8390e-04 - val_accuracy: 1.0000\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0294 - accuracy: 0.9908 - val_loss: 6.4600e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0311 - accuracy: 0.9909 - val_loss: 3.3453e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0293 - accuracy: 0.9905 - val_loss: 1.5533e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0266 - accuracy: 0.9912 - val_loss: 2.0288e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0294 - accuracy: 0.9909 - val_loss: 7.3993e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0325 - accuracy: 0.9906 - val_loss: 5.0187e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0250 - accuracy: 0.9915 - val_loss: 4.4274e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0228 - accuracy: 0.9940 - val_loss: 1.4446e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0330 - accuracy: 0.9890 - val_loss: 1.8192e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0275 - accuracy: 0.9900 - val_loss: 3.8388e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0336 - accuracy: 0.9894 - val_loss: 1.7518e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0227 - accuracy: 0.9920 - val_loss: 1.6226e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0560 - accuracy: 0.9827 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0341 - accuracy: 0.9899 - val_loss: 2.4454e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0256 - accuracy: 0.9920 - val_loss: 4.1705e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0237 - accuracy: 0.9928 - val_loss: 0.0045 - val_accuracy: 0.9987\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0393 - accuracy: 0.9867 - val_loss: 9.6127e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0279 - accuracy: 0.9914 - val_loss: 1.2347e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0273 - accuracy: 0.9915 - val_loss: 6.0874e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0293 - accuracy: 0.9902 - val_loss: 7.4351e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0241 - accuracy: 0.9928 - val_loss: 3.0349e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0238 - accuracy: 0.9921 - val_loss: 2.4388e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0243 - accuracy: 0.9917 - val_loss: 1.0903e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0239 - accuracy: 0.9914 - val_loss: 7.1926e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0216 - accuracy: 0.9928 - val_loss: 1.2668e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0235 - accuracy: 0.9917 - val_loss: 5.3989e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0256 - accuracy: 0.9908 - val_loss: 8.9491e-06 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0388 - accuracy: 0.9888 - val_loss: 7.6742e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 1.8771e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0180 - accuracy: 0.9948 - val_loss: 2.2310e-05 - val_accuracy: 1.0000\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 50ms/step - loss: 0.0280 - accuracy: 0.9927 - val_loss: 6.1129e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0362 - accuracy: 0.9885 - val_loss: 9.2194e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0265 - accuracy: 0.9924 - val_loss: 6.6555e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0247 - accuracy: 0.9923 - val_loss: 2.8750e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 1.2025e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0233 - accuracy: 0.9933 - val_loss: 6.9712e-06 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0334 - accuracy: 0.9894 - val_loss: 1.6671e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0376 - accuracy: 0.9888 - val_loss: 7.5003e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0231 - accuracy: 0.9917 - val_loss: 1.2572e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0302 - accuracy: 0.9902 - val_loss: 2.1120e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0248 - accuracy: 0.9923 - val_loss: 1.0236e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 2.0577e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0273 - accuracy: 0.9925 - val_loss: 1.1793e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0282 - accuracy: 0.9912 - val_loss: 1.5456e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0263 - accuracy: 0.9917 - val_loss: 2.7210e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 5.8974e-06 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0191 - accuracy: 0.9936 - val_loss: 1.1259e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0316 - accuracy: 0.9903 - val_loss: 7.1130e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1055 - accuracy: 0.9708 - val_loss: 0.1100 - val_accuracy: 0.9409\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0330 - accuracy: 0.9906 - val_loss: 8.2825e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0265 - accuracy: 0.9925 - val_loss: 8.4951e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0241 - accuracy: 0.9933 - val_loss: 8.1720e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0196 - accuracy: 0.9942 - val_loss: 7.0594e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0204 - accuracy: 0.9924 - val_loss: 4.1606e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0162 - accuracy: 0.9955 - val_loss: 1.9381e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0258 - accuracy: 0.9911 - val_loss: 3.6619e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0178 - accuracy: 0.9939 - val_loss: 2.8610e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0211 - accuracy: 0.9943 - val_loss: 2.5303e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0159 - accuracy: 0.9954 - val_loss: 2.2004e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0266 - accuracy: 0.9927 - val_loss: 2.3704e-05 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0191 - accuracy: 0.9942 - val_loss: 3.7652e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0149 - accuracy: 0.9961 - val_loss: 2.1938e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 5.4701e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0191 - accuracy: 0.9943 - val_loss: 2.9290e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0221 - accuracy: 0.9918 - val_loss: 6.5834e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0268 - accuracy: 0.9927 - val_loss: 1.0529e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0549 - accuracy: 0.9821 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0315 - accuracy: 0.9908 - val_loss: 5.5587e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0270 - accuracy: 0.9914 - val_loss: 5.0270e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0243 - accuracy: 0.9924 - val_loss: 5.8512e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0213 - accuracy: 0.9936 - val_loss: 1.1405e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 8.5267e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 3.4163e-06 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0250 - accuracy: 0.9925 - val_loss: 2.5654e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0222 - accuracy: 0.9915 - val_loss: 1.2414e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 4.1063e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0318 - accuracy: 0.9900 - val_loss: 2.4903e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0238 - accuracy: 0.9918 - val_loss: 9.7879e-06 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0312 - accuracy: 0.9906 - val_loss: 3.6138e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0171 - accuracy: 0.9946 - val_loss: 5.4916e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0134 - accuracy: 0.9952 - val_loss: 1.6913e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 1.5193e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 4.4356e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0249 - accuracy: 0.9923 - val_loss: 7.8775e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0277 - accuracy: 0.9918 - val_loss: 6.8218e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0198 - accuracy: 0.9942 - val_loss: 2.2388e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0254 - accuracy: 0.9930 - val_loss: 8.1404e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0198 - accuracy: 0.9940 - val_loss: 6.8542e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0229 - accuracy: 0.9936 - val_loss: 7.3461e-06 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0165 - accuracy: 0.9940 - val_loss: 5.8026e-05 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0242 - accuracy: 0.9931 - val_loss: 1.1172e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0258 - accuracy: 0.9924 - val_loss: 1.8663e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0228 - accuracy: 0.9931 - val_loss: 5.9141e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0227 - accuracy: 0.9925 - val_loss: 1.3903e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0223 - accuracy: 0.9918 - val_loss: 5.4185e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0240 - accuracy: 0.9928 - val_loss: 1.0998e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0200 - accuracy: 0.9945 - val_loss: 5.1654e-06 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0300 - accuracy: 0.9900 - val_loss: 3.6242e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0288 - accuracy: 0.9912 - val_loss: 4.4890e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0258 - accuracy: 0.9918 - val_loss: 9.3856e-06 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0156 - accuracy: 0.9946 - val_loss: 7.0176e-06 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0248 - accuracy: 0.9918 - val_loss: 1.4469e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0164 - accuracy: 0.9939 - val_loss: 2.9219e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0244 - accuracy: 0.9928 - val_loss: 2.9726e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 1.2302e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 1.2933e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0154 - accuracy: 0.9945 - val_loss: 1.3793e-06 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0197 - accuracy: 0.9933 - val_loss: 1.7787e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0165 - accuracy: 0.9946 - val_loss: 5.1347e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 2.4165e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0174 - accuracy: 0.9955 - val_loss: 4.6251e-06 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0168 - accuracy: 0.9946 - val_loss: 6.6101e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0190 - accuracy: 0.9948 - val_loss: 9.0745e-06 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0185 - accuracy: 0.9951 - val_loss: 4.1005e-06 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 4.6391e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0143 - accuracy: 0.9952 - val_loss: 8.3054e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0372 - accuracy: 0.9891 - val_loss: 0.0019 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0413 - accuracy: 0.9876 - val_loss: 4.6932e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0170 - accuracy: 0.9940 - val_loss: 1.2766e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0138 - accuracy: 0.9964 - val_loss: 1.5042e-05 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0208 - accuracy: 0.9948 - val_loss: 3.4071e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 1.6391e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0090 - accuracy: 0.9978 - val_loss: 8.8771e-07 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0198 - accuracy: 0.9954 - val_loss: 8.7398e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0214 - accuracy: 0.9934 - val_loss: 4.6898e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 7.3616e-06 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0081 - accuracy: 0.9970 - val_loss: 1.8605e-06 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 6.8800e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0187 - accuracy: 0.9931 - val_loss: 3.3562e-06 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0143 - accuracy: 0.9961 - val_loss: 4.3553e-06 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0235 - accuracy: 0.9943 - val_loss: 4.0260e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0180 - accuracy: 0.9945 - val_loss: 5.9534e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0182 - accuracy: 0.9954 - val_loss: 4.0223e-06 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0238 - accuracy: 0.9930 - val_loss: 1.6215e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 1.1790e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0121 - accuracy: 0.9966 - val_loss: 6.2319e-06 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0210 - accuracy: 0.9936 - val_loss: 6.0359e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0174 - accuracy: 0.9933 - val_loss: 1.1043e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0197 - accuracy: 0.9946 - val_loss: 6.4260e-06 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0134 - accuracy: 0.9951 - val_loss: 8.7323e-06 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 1.6767e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0173 - accuracy: 0.9949 - val_loss: 1.1181e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0204 - accuracy: 0.9927 - val_loss: 7.1723e-06 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0175 - accuracy: 0.9946 - val_loss: 1.0858e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 3.6933e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0139 - accuracy: 0.9960 - val_loss: 2.1009e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0154 - accuracy: 0.9966 - val_loss: 5.8128e-06 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0192 - accuracy: 0.9945 - val_loss: 5.0687e-06 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0163 - accuracy: 0.9963 - val_loss: 4.6342e-06 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 5.7243e-06 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "CAnc2SJa3o9f",
        "outputId": "0c0127f6-c5e3-43b2-8428-e861b64ff280"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 8ms/step - loss: 0.0105 - accuracy: 0.9973\n",
            "Accuracy  : 0.9973176121711731\n",
            "F1_Score  : 0.9965404473624667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7fcxLuwZpkK",
        "outputId": "62a62e5a-6f27-422b-a70f-814cd31d009c"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "0eff5f62-db68-40e6-c29f-253bec6fa01f"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 5s 55ms/step - loss: 1.1317 - accuracy: 0.4395 - val_loss: 1.0845 - val_accuracy: 0.4062\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0807 - accuracy: 0.4568 - val_loss: 1.0652 - val_accuracy: 0.4625\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0650 - accuracy: 0.4832 - val_loss: 1.0599 - val_accuracy: 0.4625\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0586 - accuracy: 0.4878 - val_loss: 1.0607 - val_accuracy: 0.4625\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0568 - accuracy: 0.4764 - val_loss: 1.0562 - val_accuracy: 0.4625\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0470 - accuracy: 0.4890 - val_loss: 1.0588 - val_accuracy: 0.4625\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0558 - accuracy: 0.4749 - val_loss: 1.0600 - val_accuracy: 0.4625\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0553 - accuracy: 0.4773 - val_loss: 1.0558 - val_accuracy: 0.4625\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0545 - accuracy: 0.4774 - val_loss: 1.0569 - val_accuracy: 0.4625\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0435 - accuracy: 0.4924 - val_loss: 1.0558 - val_accuracy: 0.4625\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0485 - accuracy: 0.4839 - val_loss: 1.0548 - val_accuracy: 0.4625\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0492 - accuracy: 0.4830 - val_loss: 1.0564 - val_accuracy: 0.4625\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 1.0470 - accuracy: 0.4884 - val_loss: 1.0567 - val_accuracy: 0.4625\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0495 - accuracy: 0.4781 - val_loss: 1.0550 - val_accuracy: 0.4625\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0488 - accuracy: 0.4777 - val_loss: 1.0555 - val_accuracy: 0.4625\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0519 - accuracy: 0.4767 - val_loss: 1.0572 - val_accuracy: 0.4625\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0405 - accuracy: 0.4903 - val_loss: 1.0569 - val_accuracy: 0.4625\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0446 - accuracy: 0.4850 - val_loss: 1.0565 - val_accuracy: 0.4625\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0461 - accuracy: 0.4819 - val_loss: 1.0557 - val_accuracy: 0.4625\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0407 - accuracy: 0.4928 - val_loss: 1.0565 - val_accuracy: 0.4625\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0521 - accuracy: 0.4760 - val_loss: 1.0558 - val_accuracy: 0.4625\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0489 - accuracy: 0.4746 - val_loss: 1.0569 - val_accuracy: 0.4625\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0468 - accuracy: 0.4829 - val_loss: 1.0583 - val_accuracy: 0.4625\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0468 - accuracy: 0.4804 - val_loss: 1.0582 - val_accuracy: 0.4625\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0409 - accuracy: 0.4864 - val_loss: 1.0546 - val_accuracy: 0.4625\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0434 - accuracy: 0.4830 - val_loss: 1.0537 - val_accuracy: 0.4625\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0481 - accuracy: 0.4792 - val_loss: 1.0515 - val_accuracy: 0.4625\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0433 - accuracy: 0.4867 - val_loss: 1.0543 - val_accuracy: 0.4625\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0466 - accuracy: 0.4801 - val_loss: 1.0502 - val_accuracy: 0.4625\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0458 - accuracy: 0.4805 - val_loss: 1.0563 - val_accuracy: 0.4625\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 1.0470 - accuracy: 0.4775 - val_loss: 1.0423 - val_accuracy: 0.5040\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0440 - accuracy: 0.4775 - val_loss: 1.0236 - val_accuracy: 0.5040\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0445 - accuracy: 0.4775 - val_loss: 1.0330 - val_accuracy: 0.5040\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0434 - accuracy: 0.4776 - val_loss: 1.0231 - val_accuracy: 0.5040\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0446 - accuracy: 0.4773 - val_loss: 1.0271 - val_accuracy: 0.5040\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0434 - accuracy: 0.4778 - val_loss: 1.0472 - val_accuracy: 0.5040\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0422 - accuracy: 0.4772 - val_loss: 1.0370 - val_accuracy: 0.5040\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0426 - accuracy: 0.4769 - val_loss: 1.0247 - val_accuracy: 0.5040\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0417 - accuracy: 0.4765 - val_loss: 1.0417 - val_accuracy: 0.5040\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0414 - accuracy: 0.4766 - val_loss: 1.0196 - val_accuracy: 0.5040\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0422 - accuracy: 0.4773 - val_loss: 1.0503 - val_accuracy: 0.5040\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0407 - accuracy: 0.4775 - val_loss: 1.0507 - val_accuracy: 0.5040\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0394 - accuracy: 0.4772 - val_loss: 1.0237 - val_accuracy: 0.5040\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0347 - accuracy: 0.4776 - val_loss: 1.0225 - val_accuracy: 0.5040\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0374 - accuracy: 0.4773 - val_loss: 1.0315 - val_accuracy: 0.5040\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 1.0331 - accuracy: 0.4779 - val_loss: 1.0360 - val_accuracy: 0.4799\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0361 - accuracy: 0.4769 - val_loss: 1.0347 - val_accuracy: 0.5040\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0350 - accuracy: 0.4772 - val_loss: 1.0196 - val_accuracy: 0.5040\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0324 - accuracy: 0.4776 - val_loss: 1.0232 - val_accuracy: 0.5040\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0306 - accuracy: 0.4775 - val_loss: 1.0214 - val_accuracy: 0.5040\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0306 - accuracy: 0.4773 - val_loss: 1.0154 - val_accuracy: 0.5040\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0328 - accuracy: 0.4759 - val_loss: 1.0348 - val_accuracy: 0.5040\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0316 - accuracy: 0.4776 - val_loss: 1.0336 - val_accuracy: 0.5040\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0286 - accuracy: 0.4773 - val_loss: 1.0156 - val_accuracy: 0.5040\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0252 - accuracy: 0.4775 - val_loss: 1.0305 - val_accuracy: 0.5040\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0272 - accuracy: 0.4775 - val_loss: 1.0348 - val_accuracy: 0.5040\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0203 - accuracy: 0.4772 - val_loss: 1.0078 - val_accuracy: 0.5040\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0201 - accuracy: 0.4775 - val_loss: 1.0369 - val_accuracy: 0.5040\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 1.0201 - accuracy: 0.4772 - val_loss: 1.0218 - val_accuracy: 0.5040\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0180 - accuracy: 0.4775 - val_loss: 1.0169 - val_accuracy: 0.5040\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0128 - accuracy: 0.4799 - val_loss: 0.9841 - val_accuracy: 0.4826\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 1.0144 - accuracy: 0.4812 - val_loss: 0.9922 - val_accuracy: 0.4839\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0038 - accuracy: 0.4788 - val_loss: 0.9861 - val_accuracy: 0.4812\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0072 - accuracy: 0.4797 - val_loss: 0.9899 - val_accuracy: 0.4812\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9951 - accuracy: 0.4787 - val_loss: 0.9858 - val_accuracy: 0.4826\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9980 - accuracy: 0.4809 - val_loss: 1.0411 - val_accuracy: 0.4826\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0039 - accuracy: 0.4826 - val_loss: 0.9762 - val_accuracy: 0.4812\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9873 - accuracy: 0.4830 - val_loss: 0.9647 - val_accuracy: 0.4893\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9743 - accuracy: 0.4841 - val_loss: 0.9545 - val_accuracy: 0.4906\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9705 - accuracy: 0.4830 - val_loss: 0.9469 - val_accuracy: 0.4893\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9789 - accuracy: 0.4835 - val_loss: 0.9528 - val_accuracy: 0.4973\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.9663 - accuracy: 0.4854 - val_loss: 0.9353 - val_accuracy: 0.4946\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9525 - accuracy: 0.4949 - val_loss: 0.9349 - val_accuracy: 0.5402\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9372 - accuracy: 0.5341 - val_loss: 0.9229 - val_accuracy: 0.5697\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9308 - accuracy: 0.5328 - val_loss: 0.9515 - val_accuracy: 0.5456\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9277 - accuracy: 0.5386 - val_loss: 0.8941 - val_accuracy: 0.5791\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9118 - accuracy: 0.5484 - val_loss: 0.8742 - val_accuracy: 0.5912\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8921 - accuracy: 0.5694 - val_loss: 0.9099 - val_accuracy: 0.5617\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8826 - accuracy: 0.5641 - val_loss: 0.8487 - val_accuracy: 0.6153\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8509 - accuracy: 0.5851 - val_loss: 0.8099 - val_accuracy: 0.6273\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8433 - accuracy: 0.5930 - val_loss: 0.8129 - val_accuracy: 0.6206\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8221 - accuracy: 0.6012 - val_loss: 0.7869 - val_accuracy: 0.6421\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8199 - accuracy: 0.6091 - val_loss: 0.7430 - val_accuracy: 0.6756\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7897 - accuracy: 0.6301 - val_loss: 0.7679 - val_accuracy: 0.6622\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7711 - accuracy: 0.6399 - val_loss: 0.6901 - val_accuracy: 0.6997\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7368 - accuracy: 0.6595 - val_loss: 0.6820 - val_accuracy: 0.7252\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7337 - accuracy: 0.6629 - val_loss: 0.6708 - val_accuracy: 0.7118\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6999 - accuracy: 0.6861 - val_loss: 0.6828 - val_accuracy: 0.7051\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6651 - accuracy: 0.7067 - val_loss: 0.6739 - val_accuracy: 0.7024\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6571 - accuracy: 0.7085 - val_loss: 0.5914 - val_accuracy: 0.7440\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.6373 - accuracy: 0.7252 - val_loss: 0.4035 - val_accuracy: 0.8539\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5863 - accuracy: 0.7508 - val_loss: 0.3616 - val_accuracy: 0.8539\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.5844 - accuracy: 0.7578 - val_loss: 0.3750 - val_accuracy: 0.8673\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5398 - accuracy: 0.7827 - val_loss: 0.3413 - val_accuracy: 0.8780\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4964 - accuracy: 0.8010 - val_loss: 0.3170 - val_accuracy: 0.8767\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5055 - accuracy: 0.7982 - val_loss: 0.3194 - val_accuracy: 0.8968\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4501 - accuracy: 0.8261 - val_loss: 0.2367 - val_accuracy: 0.9303\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3970 - accuracy: 0.8492 - val_loss: 0.2507 - val_accuracy: 0.9075\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3933 - accuracy: 0.8545 - val_loss: 0.2266 - val_accuracy: 0.9196\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3683 - accuracy: 0.8596 - val_loss: 0.2037 - val_accuracy: 0.9357\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3717 - accuracy: 0.8632 - val_loss: 0.2140 - val_accuracy: 0.9129\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3417 - accuracy: 0.8700 - val_loss: 0.1675 - val_accuracy: 0.9424\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3116 - accuracy: 0.8845 - val_loss: 0.1619 - val_accuracy: 0.9397\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2998 - accuracy: 0.8875 - val_loss: 0.1739 - val_accuracy: 0.9343\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2742 - accuracy: 0.9022 - val_loss: 0.1545 - val_accuracy: 0.9450\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2797 - accuracy: 0.8958 - val_loss: 0.1195 - val_accuracy: 0.9625\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2434 - accuracy: 0.9124 - val_loss: 0.1204 - val_accuracy: 0.9558\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2427 - accuracy: 0.9137 - val_loss: 0.1362 - val_accuracy: 0.9558\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2361 - accuracy: 0.9162 - val_loss: 0.1177 - val_accuracy: 0.9611\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2220 - accuracy: 0.9182 - val_loss: 0.1259 - val_accuracy: 0.9531\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1952 - accuracy: 0.9323 - val_loss: 0.0773 - val_accuracy: 0.9718\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1986 - accuracy: 0.9320 - val_loss: 0.1265 - val_accuracy: 0.9491\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1938 - accuracy: 0.9331 - val_loss: 0.0955 - val_accuracy: 0.9651\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1753 - accuracy: 0.9377 - val_loss: 0.1049 - val_accuracy: 0.9651\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1682 - accuracy: 0.9396 - val_loss: 0.0811 - val_accuracy: 0.9732\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1662 - accuracy: 0.9417 - val_loss: 0.1306 - val_accuracy: 0.9558\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1617 - accuracy: 0.9466 - val_loss: 0.0902 - val_accuracy: 0.9692\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1413 - accuracy: 0.9513 - val_loss: 0.0899 - val_accuracy: 0.9718\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1375 - accuracy: 0.9529 - val_loss: 0.0887 - val_accuracy: 0.9705\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1387 - accuracy: 0.9575 - val_loss: 0.0845 - val_accuracy: 0.9692\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1665 - accuracy: 0.9444 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1661 - accuracy: 0.9396 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1304 - accuracy: 0.9550 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1430 - accuracy: 0.9522 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1411 - accuracy: 0.9535 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1285 - accuracy: 0.9550 - val_loss: 0.0072 - val_accuracy: 0.9987\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1133 - accuracy: 0.9627 - val_loss: 0.0056 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1138 - accuracy: 0.9607 - val_loss: 0.0071 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1225 - accuracy: 0.9572 - val_loss: 0.0060 - val_accuracy: 0.9973\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1089 - accuracy: 0.9675 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1068 - accuracy: 0.9621 - val_loss: 0.0065 - val_accuracy: 0.9987\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1100 - accuracy: 0.9636 - val_loss: 0.0127 - val_accuracy: 0.9973\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0981 - accuracy: 0.9687 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0945 - accuracy: 0.9689 - val_loss: 0.0083 - val_accuracy: 0.9973\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1176 - accuracy: 0.9633 - val_loss: 0.0138 - val_accuracy: 0.9933\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0909 - accuracy: 0.9714 - val_loss: 0.0064 - val_accuracy: 0.9973\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0805 - accuracy: 0.9745 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0771 - accuracy: 0.9754 - val_loss: 0.0072 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0813 - accuracy: 0.9748 - val_loss: 0.0092 - val_accuracy: 0.9960\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0823 - accuracy: 0.9741 - val_loss: 0.0100 - val_accuracy: 0.9960\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0947 - accuracy: 0.9697 - val_loss: 0.0103 - val_accuracy: 0.9973\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0832 - accuracy: 0.9726 - val_loss: 0.0082 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0715 - accuracy: 0.9757 - val_loss: 0.0056 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0737 - accuracy: 0.9776 - val_loss: 0.0227 - val_accuracy: 0.9960\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0769 - accuracy: 0.9742 - val_loss: 0.0119 - val_accuracy: 0.9973\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0754 - accuracy: 0.9769 - val_loss: 0.0093 - val_accuracy: 0.9960\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0808 - accuracy: 0.9747 - val_loss: 0.0225 - val_accuracy: 0.9893\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0745 - accuracy: 0.9726 - val_loss: 0.0068 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0763 - accuracy: 0.9736 - val_loss: 0.0087 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0712 - accuracy: 0.9797 - val_loss: 0.0228 - val_accuracy: 0.9920\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0794 - accuracy: 0.9738 - val_loss: 3.5813e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0798 - accuracy: 0.9726 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0743 - accuracy: 0.9760 - val_loss: 5.3984e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0685 - accuracy: 0.9782 - val_loss: 3.7471e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0645 - accuracy: 0.9794 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0707 - accuracy: 0.9784 - val_loss: 2.8463e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0714 - accuracy: 0.9773 - val_loss: 2.5028e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0597 - accuracy: 0.9814 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0816 - accuracy: 0.9735 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0612 - accuracy: 0.9806 - val_loss: 2.5734e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0685 - accuracy: 0.9805 - val_loss: 6.1639e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0682 - accuracy: 0.9791 - val_loss: 2.9128e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0630 - accuracy: 0.9806 - val_loss: 9.0819e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0577 - accuracy: 0.9830 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0654 - accuracy: 0.9794 - val_loss: 8.0383e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0543 - accuracy: 0.9833 - val_loss: 8.8028e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0685 - accuracy: 0.9793 - val_loss: 6.8499e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0544 - accuracy: 0.9848 - val_loss: 3.8421e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0600 - accuracy: 0.9824 - val_loss: 4.7589e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0615 - accuracy: 0.9791 - val_loss: 0.0045 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0640 - accuracy: 0.9790 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0574 - accuracy: 0.9803 - val_loss: 5.8629e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0562 - accuracy: 0.9836 - val_loss: 3.3239e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0567 - accuracy: 0.9817 - val_loss: 4.3091e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0570 - accuracy: 0.9846 - val_loss: 3.4773e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0493 - accuracy: 0.9838 - val_loss: 0.0011 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0520 - accuracy: 0.9842 - val_loss: 2.2616e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0507 - accuracy: 0.9835 - val_loss: 8.1211e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0568 - accuracy: 0.9817 - val_loss: 2.8172e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0467 - accuracy: 0.9858 - val_loss: 5.4788e-04 - val_accuracy: 1.0000\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0614 - accuracy: 0.9817 - val_loss: 3.8402e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0630 - accuracy: 0.9812 - val_loss: 5.2450e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0704 - accuracy: 0.9771 - val_loss: 1.1837e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0507 - accuracy: 0.9815 - val_loss: 6.8606e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0564 - accuracy: 0.9841 - val_loss: 3.1754e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0451 - accuracy: 0.9851 - val_loss: 6.7950e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0486 - accuracy: 0.9866 - val_loss: 1.2957e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0539 - accuracy: 0.9817 - val_loss: 9.8513e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0537 - accuracy: 0.9829 - val_loss: 9.6630e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0455 - accuracy: 0.9863 - val_loss: 4.8786e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0376 - accuracy: 0.9879 - val_loss: 3.3756e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0453 - accuracy: 0.9863 - val_loss: 1.1623e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0455 - accuracy: 0.9842 - val_loss: 1.6162e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0507 - accuracy: 0.9844 - val_loss: 1.0913e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0663 - accuracy: 0.9802 - val_loss: 2.0615e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0946 - accuracy: 0.9717 - val_loss: 0.0136 - val_accuracy: 0.9960\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0593 - accuracy: 0.9818 - val_loss: 1.8749e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0480 - accuracy: 0.9848 - val_loss: 1.1176e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0639 - accuracy: 0.9785 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0576 - accuracy: 0.9818 - val_loss: 2.0912e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0483 - accuracy: 0.9839 - val_loss: 1.3854e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0400 - accuracy: 0.9888 - val_loss: 5.7735e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0425 - accuracy: 0.9870 - val_loss: 7.0237e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0394 - accuracy: 0.9888 - val_loss: 9.8192e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0407 - accuracy: 0.9867 - val_loss: 1.2070e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0575 - accuracy: 0.9836 - val_loss: 1.2411e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0543 - accuracy: 0.9839 - val_loss: 7.7850e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0360 - accuracy: 0.9885 - val_loss: 9.1694e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0353 - accuracy: 0.9900 - val_loss: 8.7257e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0415 - accuracy: 0.9875 - val_loss: 1.2340e-04 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0407 - accuracy: 0.9896 - val_loss: 1.4157e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0432 - accuracy: 0.9855 - val_loss: 1.2189e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0368 - accuracy: 0.9891 - val_loss: 6.6110e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0379 - accuracy: 0.9887 - val_loss: 2.2995e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0552 - accuracy: 0.9857 - val_loss: 3.7048e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0468 - accuracy: 0.9864 - val_loss: 3.5738e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0331 - accuracy: 0.9890 - val_loss: 2.7165e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0372 - accuracy: 0.9897 - val_loss: 1.3748e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0429 - accuracy: 0.9851 - val_loss: 3.5776e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0441 - accuracy: 0.9869 - val_loss: 1.0843e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0392 - accuracy: 0.9885 - val_loss: 6.0702e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0461 - accuracy: 0.9852 - val_loss: 9.3038e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0329 - accuracy: 0.9896 - val_loss: 5.2646e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0395 - accuracy: 0.9870 - val_loss: 1.4202e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0454 - accuracy: 0.9860 - val_loss: 5.4926e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0308 - accuracy: 0.9903 - val_loss: 2.8666e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0369 - accuracy: 0.9896 - val_loss: 3.8945e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0431 - accuracy: 0.9867 - val_loss: 1.4671e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0787 - accuracy: 0.9766 - val_loss: 3.0962e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0325 - accuracy: 0.9894 - val_loss: 6.3615e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0363 - accuracy: 0.9879 - val_loss: 2.8304e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0452 - accuracy: 0.9847 - val_loss: 1.0040e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0385 - accuracy: 0.9881 - val_loss: 7.0800e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0439 - accuracy: 0.9858 - val_loss: 5.4563e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0448 - accuracy: 0.9860 - val_loss: 6.7830e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0342 - accuracy: 0.9903 - val_loss: 2.6466e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0449 - accuracy: 0.9864 - val_loss: 1.3293e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0534 - accuracy: 0.9841 - val_loss: 1.6483e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0398 - accuracy: 0.9878 - val_loss: 5.3316e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0348 - accuracy: 0.9882 - val_loss: 5.0783e-05 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0416 - accuracy: 0.9882 - val_loss: 1.0293e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0440 - accuracy: 0.9873 - val_loss: 9.3848e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0265 - accuracy: 0.9934 - val_loss: 6.9491e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0291 - accuracy: 0.9909 - val_loss: 7.4807e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0314 - accuracy: 0.9899 - val_loss: 2.3751e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0380 - accuracy: 0.9897 - val_loss: 1.4698e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0349 - accuracy: 0.9893 - val_loss: 1.0238e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0327 - accuracy: 0.9905 - val_loss: 2.2960e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0333 - accuracy: 0.9879 - val_loss: 6.8279e-06 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0338 - accuracy: 0.9878 - val_loss: 7.6182e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0328 - accuracy: 0.9917 - val_loss: 1.1044e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0399 - accuracy: 0.9884 - val_loss: 1.3166e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0343 - accuracy: 0.9884 - val_loss: 3.4810e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0430 - accuracy: 0.9869 - val_loss: 1.3551e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0366 - accuracy: 0.9878 - val_loss: 7.6811e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0359 - accuracy: 0.9893 - val_loss: 2.0856e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0353 - accuracy: 0.9875 - val_loss: 1.4044e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0298 - accuracy: 0.9918 - val_loss: 2.5698e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0358 - accuracy: 0.9897 - val_loss: 3.1766e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0309 - accuracy: 0.9894 - val_loss: 2.2622e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0335 - accuracy: 0.9893 - val_loss: 3.2380e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0333 - accuracy: 0.9915 - val_loss: 2.5797e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0423 - accuracy: 0.9869 - val_loss: 5.8753e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0346 - accuracy: 0.9888 - val_loss: 1.1365e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0429 - accuracy: 0.9861 - val_loss: 2.1634e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0504 - accuracy: 0.9845 - val_loss: 7.4191e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0371 - accuracy: 0.9897 - val_loss: 2.7326e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0284 - accuracy: 0.9920 - val_loss: 2.2845e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0328 - accuracy: 0.9884 - val_loss: 6.2282e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0400 - accuracy: 0.9878 - val_loss: 1.3880e-05 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0489 - accuracy: 0.9870 - val_loss: 6.9929e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0466 - accuracy: 0.9847 - val_loss: 1.1651e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0354 - accuracy: 0.9891 - val_loss: 2.5513e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0360 - accuracy: 0.9867 - val_loss: 3.4747e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0274 - accuracy: 0.9914 - val_loss: 1.8140e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0309 - accuracy: 0.9909 - val_loss: 3.0454e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0413 - accuracy: 0.9878 - val_loss: 1.5419e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0255 - accuracy: 0.9911 - val_loss: 6.6020e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0453 - accuracy: 0.9864 - val_loss: 3.9143e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0394 - accuracy: 0.9891 - val_loss: 1.0170e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0236 - accuracy: 0.9928 - val_loss: 1.2922e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0305 - accuracy: 0.9903 - val_loss: 3.0195e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0332 - accuracy: 0.9896 - val_loss: 2.0194e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0249 - accuracy: 0.9915 - val_loss: 1.9947e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0241 - accuracy: 0.9930 - val_loss: 1.7734e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0363 - accuracy: 0.9887 - val_loss: 8.3358e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0356 - accuracy: 0.9914 - val_loss: 1.0909e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0205 - accuracy: 0.9928 - val_loss: 7.5606e-06 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0269 - accuracy: 0.9921 - val_loss: 2.7121e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0379 - accuracy: 0.9894 - val_loss: 4.6783e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0313 - accuracy: 0.9906 - val_loss: 1.0853e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0351 - accuracy: 0.9896 - val_loss: 7.1369e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0257 - accuracy: 0.9923 - val_loss: 2.0704e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0233 - accuracy: 0.9925 - val_loss: 5.3762e-06 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0282 - accuracy: 0.9918 - val_loss: 4.5977e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0447 - accuracy: 0.9860 - val_loss: 7.7052e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0264 - accuracy: 0.9921 - val_loss: 5.3135e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0269 - accuracy: 0.9920 - val_loss: 6.1798e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0303 - accuracy: 0.9909 - val_loss: 1.1339e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0286 - accuracy: 0.9914 - val_loss: 1.0650e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "830a823d-2fc9-424f-c4b0-bd5b7255ba6e"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 9ms/step - loss: 0.0169 - accuracy: 0.9941\n",
            "Accuracy  : 0.9940987229347229\n",
            "F1_Score  : 0.9940944701973325\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "58f61919-9307-4ddd-987a-c1d16976d21e"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'#dominance\\nX_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\\nprint(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "d229ffdf-028a-4b45-8d41-4e4c553ea7f7"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'foldNum=0\\nmodel = get_model()\\nfor train_index, val_index in kfold.split(X_train, Y_train):\\n  foldNum = foldNum + 1\\n  print(\"Results for fold\",foldNum)\\n  x_train, x_val = X_train[train_index], X_train[val_index]\\n  y_train, y_val = Y_train[train_index], Y_train[val_index]\\n  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\\n  gc.collect() # Garbage collecter\\n  del x_train, x_val, y_train, y_val\\n  gc.collect()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "427ed40e-296f-466c-ee3a-7c767da1aaac"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'acrc = model.evaluate(x_test, y_test)\\npred = model.predict(x_test)\\nf1scr = f1_score(y_test.argmax(1), pred.argmax(1), average=\\'macro\\')\\nc_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\\nprint(\"Accuracy  : {}\".format(acrc[1]))\\nprint(\"F1_Score  : {}\".format(f1scr))\\nc_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\\nimport seaborn as sns\\nfigure = plt.figure(figsize=(9, 9))\\nsns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\\nplt.tight_layout()\\nplt.ylabel(\\'True label\\')\\nplt.xlabel(\\'Predicted label\\')\\nplt.show()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}