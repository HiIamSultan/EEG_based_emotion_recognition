{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub32_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "fc0262b5-4487-44f5-cde0-69ac37966f0a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e3\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  #EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "ebbcb8f7-7269-46f3-afd9-bf2d21d399d9"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(32,33):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.32\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (2330,) (3029,) (3961,)\n",
            "(9320,) (1631,) (2796,) (4893,)\n",
            "(9320,) (0,) (1398,) (7922,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "47eacbd5-8cea-40d8-c7b6-2b5631f1915d"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "f9e20239-831c-4015-ccf5-9c1da14d3f6f"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "706"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "67364b59-6a50-4b5c-d065-c96e99e26c06"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d23178af-c5a6-4b37-81d5-ce80127e7fac"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 30s 60ms/step - loss: 1.1630 - accuracy: 0.4044 - val_loss: 1.0968 - val_accuracy: 0.3981\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0837 - accuracy: 0.4381 - val_loss: 1.0718 - val_accuracy: 0.4571\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0725 - accuracy: 0.4453 - val_loss: 1.0670 - val_accuracy: 0.4584\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0709 - accuracy: 0.4491 - val_loss: 1.0600 - val_accuracy: 0.4584\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0744 - accuracy: 0.4373 - val_loss: 1.0575 - val_accuracy: 0.4598\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0639 - accuracy: 0.4510 - val_loss: 1.0578 - val_accuracy: 0.4651\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0655 - accuracy: 0.4536 - val_loss: 1.0575 - val_accuracy: 0.4678\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0682 - accuracy: 0.4395 - val_loss: 1.0551 - val_accuracy: 0.4598\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0672 - accuracy: 0.4469 - val_loss: 1.0568 - val_accuracy: 0.4692\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0643 - accuracy: 0.4451 - val_loss: 1.0560 - val_accuracy: 0.4611\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0695 - accuracy: 0.4403 - val_loss: 1.0577 - val_accuracy: 0.4571\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0624 - accuracy: 0.4595 - val_loss: 1.0614 - val_accuracy: 0.4491\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0579 - accuracy: 0.4613 - val_loss: 1.0543 - val_accuracy: 0.4611\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0590 - accuracy: 0.4535 - val_loss: 1.0536 - val_accuracy: 0.4638\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0610 - accuracy: 0.4433 - val_loss: 1.0612 - val_accuracy: 0.4437\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0569 - accuracy: 0.4674 - val_loss: 1.0565 - val_accuracy: 0.4584\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0540 - accuracy: 0.4626 - val_loss: 1.0569 - val_accuracy: 0.4504\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0575 - accuracy: 0.4539 - val_loss: 1.0532 - val_accuracy: 0.4759\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0554 - accuracy: 0.4644 - val_loss: 1.0573 - val_accuracy: 0.4651\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0543 - accuracy: 0.4664 - val_loss: 1.0557 - val_accuracy: 0.4692\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0548 - accuracy: 0.4677 - val_loss: 1.0546 - val_accuracy: 0.4638\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0597 - accuracy: 0.4580 - val_loss: 1.0514 - val_accuracy: 0.4786\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0555 - accuracy: 0.4609 - val_loss: 1.0533 - val_accuracy: 0.4732\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0598 - accuracy: 0.4550 - val_loss: 1.0553 - val_accuracy: 0.4611\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0567 - accuracy: 0.4608 - val_loss: 1.0529 - val_accuracy: 0.4598\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0584 - accuracy: 0.4517 - val_loss: 1.0571 - val_accuracy: 0.4544\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0597 - accuracy: 0.4544 - val_loss: 1.0634 - val_accuracy: 0.4450\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0545 - accuracy: 0.4683 - val_loss: 1.0540 - val_accuracy: 0.4692\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0565 - accuracy: 0.4623 - val_loss: 1.0561 - val_accuracy: 0.4491\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0538 - accuracy: 0.4598 - val_loss: 1.0503 - val_accuracy: 0.4839\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0563 - accuracy: 0.4575 - val_loss: 1.0527 - val_accuracy: 0.4638\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0575 - accuracy: 0.4584 - val_loss: 1.0557 - val_accuracy: 0.4383\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0570 - accuracy: 0.4544 - val_loss: 1.0488 - val_accuracy: 0.4718\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0537 - accuracy: 0.4602 - val_loss: 1.0450 - val_accuracy: 0.4718\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0565 - accuracy: 0.4568 - val_loss: 1.0539 - val_accuracy: 0.4584\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0551 - accuracy: 0.4604 - val_loss: 1.0476 - val_accuracy: 0.4678\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0537 - accuracy: 0.4632 - val_loss: 1.0564 - val_accuracy: 0.4638\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0570 - accuracy: 0.4589 - val_loss: 1.0504 - val_accuracy: 0.4584\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0508 - accuracy: 0.4659 - val_loss: 1.0485 - val_accuracy: 0.4718\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0511 - accuracy: 0.4623 - val_loss: 1.0463 - val_accuracy: 0.4598\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0504 - accuracy: 0.4653 - val_loss: 1.0506 - val_accuracy: 0.4651\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0492 - accuracy: 0.4711 - val_loss: 1.0508 - val_accuracy: 0.4625\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0530 - accuracy: 0.4648 - val_loss: 1.0564 - val_accuracy: 0.4531\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0508 - accuracy: 0.4641 - val_loss: 1.0532 - val_accuracy: 0.4638\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0458 - accuracy: 0.4690 - val_loss: 1.0410 - val_accuracy: 0.4705\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0472 - accuracy: 0.4696 - val_loss: 1.0522 - val_accuracy: 0.4705\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0504 - accuracy: 0.4629 - val_loss: 1.0467 - val_accuracy: 0.4705\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0516 - accuracy: 0.4615 - val_loss: 1.0458 - val_accuracy: 0.4665\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0460 - accuracy: 0.4666 - val_loss: 1.0487 - val_accuracy: 0.4705\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0471 - accuracy: 0.4659 - val_loss: 1.0419 - val_accuracy: 0.4718\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0415 - accuracy: 0.4700 - val_loss: 1.0480 - val_accuracy: 0.4571\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0473 - accuracy: 0.4697 - val_loss: 1.0435 - val_accuracy: 0.4705\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0422 - accuracy: 0.4684 - val_loss: 1.0437 - val_accuracy: 0.4732\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0379 - accuracy: 0.4702 - val_loss: 1.0397 - val_accuracy: 0.4678\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0402 - accuracy: 0.4694 - val_loss: 1.0433 - val_accuracy: 0.4732\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0386 - accuracy: 0.4702 - val_loss: 1.0445 - val_accuracy: 0.4705\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0381 - accuracy: 0.4687 - val_loss: 1.0474 - val_accuracy: 0.4786\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0451 - accuracy: 0.4689 - val_loss: 1.0517 - val_accuracy: 0.4759\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0385 - accuracy: 0.4773 - val_loss: 1.0417 - val_accuracy: 0.4598\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0344 - accuracy: 0.4723 - val_loss: 1.0414 - val_accuracy: 0.4799\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0434 - accuracy: 0.4660 - val_loss: 1.0505 - val_accuracy: 0.4692\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0336 - accuracy: 0.4717 - val_loss: 1.0458 - val_accuracy: 0.4571\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0326 - accuracy: 0.4738 - val_loss: 1.0342 - val_accuracy: 0.4638\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0325 - accuracy: 0.4677 - val_loss: 1.0700 - val_accuracy: 0.4196\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0222 - accuracy: 0.4781 - val_loss: 1.0421 - val_accuracy: 0.4316\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0182 - accuracy: 0.4806 - val_loss: 1.0299 - val_accuracy: 0.4692\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0254 - accuracy: 0.4799 - val_loss: 1.0224 - val_accuracy: 0.4745\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0241 - accuracy: 0.4787 - val_loss: 1.0332 - val_accuracy: 0.4665\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0155 - accuracy: 0.4770 - val_loss: 1.0231 - val_accuracy: 0.4705\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0183 - accuracy: 0.4768 - val_loss: 1.0315 - val_accuracy: 0.4692\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0161 - accuracy: 0.4809 - val_loss: 1.0402 - val_accuracy: 0.4464\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0171 - accuracy: 0.4769 - val_loss: 1.0199 - val_accuracy: 0.4665\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0050 - accuracy: 0.4821 - val_loss: 1.0386 - val_accuracy: 0.4598\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9985 - accuracy: 0.4894 - val_loss: 1.0275 - val_accuracy: 0.4625\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9940 - accuracy: 0.4897 - val_loss: 1.0123 - val_accuracy: 0.4531\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9927 - accuracy: 0.4885 - val_loss: 1.0103 - val_accuracy: 0.4839\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9810 - accuracy: 0.4976 - val_loss: 0.9973 - val_accuracy: 0.4772\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9856 - accuracy: 0.4936 - val_loss: 0.9994 - val_accuracy: 0.4866\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9822 - accuracy: 0.4961 - val_loss: 1.0063 - val_accuracy: 0.4920\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9744 - accuracy: 0.4976 - val_loss: 0.9874 - val_accuracy: 0.5080\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9655 - accuracy: 0.5082 - val_loss: 0.9923 - val_accuracy: 0.4853\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9653 - accuracy: 0.5051 - val_loss: 0.9654 - val_accuracy: 0.5214\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9464 - accuracy: 0.5130 - val_loss: 0.9575 - val_accuracy: 0.5121\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9459 - accuracy: 0.5200 - val_loss: 0.9632 - val_accuracy: 0.4973\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9415 - accuracy: 0.5235 - val_loss: 0.9627 - val_accuracy: 0.5000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9155 - accuracy: 0.5374 - val_loss: 0.9501 - val_accuracy: 0.5214\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9191 - accuracy: 0.5338 - val_loss: 0.9415 - val_accuracy: 0.5214\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9077 - accuracy: 0.5405 - val_loss: 0.9237 - val_accuracy: 0.5402\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8881 - accuracy: 0.5572 - val_loss: 0.9136 - val_accuracy: 0.5550\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8891 - accuracy: 0.5531 - val_loss: 0.9230 - val_accuracy: 0.5389\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8923 - accuracy: 0.5568 - val_loss: 0.8405 - val_accuracy: 0.6059\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8621 - accuracy: 0.5641 - val_loss: 0.8357 - val_accuracy: 0.5576\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8781 - accuracy: 0.5678 - val_loss: 0.8357 - val_accuracy: 0.5764\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8545 - accuracy: 0.5791 - val_loss: 0.8211 - val_accuracy: 0.5912\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8329 - accuracy: 0.5863 - val_loss: 0.8118 - val_accuracy: 0.5992\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8070 - accuracy: 0.6006 - val_loss: 0.7891 - val_accuracy: 0.6314\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8118 - accuracy: 0.6015 - val_loss: 0.7569 - val_accuracy: 0.6032\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8063 - accuracy: 0.6072 - val_loss: 0.7602 - val_accuracy: 0.6327\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7973 - accuracy: 0.6058 - val_loss: 0.7628 - val_accuracy: 0.6461\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7634 - accuracy: 0.6358 - val_loss: 0.7515 - val_accuracy: 0.6501\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7702 - accuracy: 0.6271 - val_loss: 0.7756 - val_accuracy: 0.6408\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7623 - accuracy: 0.6279 - val_loss: 0.7307 - val_accuracy: 0.6394\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7564 - accuracy: 0.6404 - val_loss: 0.7443 - val_accuracy: 0.6421\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7407 - accuracy: 0.6516 - val_loss: 0.7161 - val_accuracy: 0.6609\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7090 - accuracy: 0.6574 - val_loss: 0.7223 - val_accuracy: 0.6568\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7249 - accuracy: 0.6624 - val_loss: 0.7379 - val_accuracy: 0.6394\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7078 - accuracy: 0.6656 - val_loss: 0.7044 - val_accuracy: 0.6501\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6802 - accuracy: 0.6721 - val_loss: 0.6751 - val_accuracy: 0.6863\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6665 - accuracy: 0.6860 - val_loss: 0.6607 - val_accuracy: 0.6796\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6562 - accuracy: 0.6852 - val_loss: 0.6758 - val_accuracy: 0.6689\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6478 - accuracy: 0.6934 - val_loss: 0.6532 - val_accuracy: 0.6836\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6380 - accuracy: 0.6978 - val_loss: 0.6422 - val_accuracy: 0.6810\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6389 - accuracy: 0.6909 - val_loss: 0.6334 - val_accuracy: 0.7131\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6056 - accuracy: 0.7115 - val_loss: 0.6111 - val_accuracy: 0.7011\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7921 - accuracy: 0.6538 - val_loss: 1.5585 - val_accuracy: 0.3686\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6710 - accuracy: 0.6857 - val_loss: 0.6468 - val_accuracy: 0.7105\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6071 - accuracy: 0.7152 - val_loss: 0.6273 - val_accuracy: 0.6877\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5870 - accuracy: 0.7283 - val_loss: 0.6090 - val_accuracy: 0.7145\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5787 - accuracy: 0.7322 - val_loss: 0.5961 - val_accuracy: 0.7158\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5669 - accuracy: 0.7395 - val_loss: 0.5538 - val_accuracy: 0.7386\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.5831 - accuracy: 0.7314 - val_loss: 0.3525 - val_accuracy: 0.8365\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5701 - accuracy: 0.7463 - val_loss: 0.3624 - val_accuracy: 0.8405\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5416 - accuracy: 0.7556 - val_loss: 0.3538 - val_accuracy: 0.8298\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5502 - accuracy: 0.7544 - val_loss: 0.3494 - val_accuracy: 0.8378\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5214 - accuracy: 0.7654 - val_loss: 0.3194 - val_accuracy: 0.8606\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5300 - accuracy: 0.7614 - val_loss: 0.3541 - val_accuracy: 0.8432\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5183 - accuracy: 0.7610 - val_loss: 0.3131 - val_accuracy: 0.8820\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5089 - accuracy: 0.7711 - val_loss: 0.3341 - val_accuracy: 0.8633\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4979 - accuracy: 0.7714 - val_loss: 0.3185 - val_accuracy: 0.8740\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5171 - accuracy: 0.7760 - val_loss: 0.3550 - val_accuracy: 0.8365\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4903 - accuracy: 0.7866 - val_loss: 0.2971 - val_accuracy: 0.8780\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4686 - accuracy: 0.8007 - val_loss: 0.2836 - val_accuracy: 0.9035\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4724 - accuracy: 0.7951 - val_loss: 0.2818 - val_accuracy: 0.8820\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4498 - accuracy: 0.8045 - val_loss: 0.2736 - val_accuracy: 0.8995\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4430 - accuracy: 0.8033 - val_loss: 0.2725 - val_accuracy: 0.8954\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4490 - accuracy: 0.8013 - val_loss: 0.2698 - val_accuracy: 0.8914\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4192 - accuracy: 0.8149 - val_loss: 0.2670 - val_accuracy: 0.8887\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4486 - accuracy: 0.8024 - val_loss: 0.2772 - val_accuracy: 0.8767\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4282 - accuracy: 0.8151 - val_loss: 0.2633 - val_accuracy: 0.8847\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4104 - accuracy: 0.8230 - val_loss: 0.2548 - val_accuracy: 0.8928\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4114 - accuracy: 0.8267 - val_loss: 0.2530 - val_accuracy: 0.8941\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3969 - accuracy: 0.8230 - val_loss: 0.2720 - val_accuracy: 0.8887\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4034 - accuracy: 0.8311 - val_loss: 0.2816 - val_accuracy: 0.8847\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3828 - accuracy: 0.8364 - val_loss: 0.2513 - val_accuracy: 0.8914\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3924 - accuracy: 0.8303 - val_loss: 0.2468 - val_accuracy: 0.9048\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3777 - accuracy: 0.8469 - val_loss: 0.2451 - val_accuracy: 0.9048\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3668 - accuracy: 0.8425 - val_loss: 0.2342 - val_accuracy: 0.9021\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3662 - accuracy: 0.8462 - val_loss: 0.2838 - val_accuracy: 0.8807\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3953 - accuracy: 0.8365 - val_loss: 0.2653 - val_accuracy: 0.9062\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3522 - accuracy: 0.8487 - val_loss: 0.2195 - val_accuracy: 0.9088\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.3440 - accuracy: 0.8635 - val_loss: 0.1278 - val_accuracy: 0.9812\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3481 - accuracy: 0.8607 - val_loss: 0.1348 - val_accuracy: 0.9638\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3306 - accuracy: 0.8668 - val_loss: 0.1151 - val_accuracy: 0.9772\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3444 - accuracy: 0.8614 - val_loss: 0.1231 - val_accuracy: 0.9705\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3230 - accuracy: 0.8718 - val_loss: 0.1123 - val_accuracy: 0.9705\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3214 - accuracy: 0.8730 - val_loss: 0.1067 - val_accuracy: 0.9839\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3524 - accuracy: 0.8656 - val_loss: 0.1277 - val_accuracy: 0.9812\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3081 - accuracy: 0.8815 - val_loss: 0.1261 - val_accuracy: 0.9692\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3009 - accuracy: 0.8824 - val_loss: 0.1171 - val_accuracy: 0.9718\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3114 - accuracy: 0.8762 - val_loss: 0.1214 - val_accuracy: 0.9598\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2834 - accuracy: 0.8905 - val_loss: 0.1223 - val_accuracy: 0.9571\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3150 - accuracy: 0.8762 - val_loss: 0.1450 - val_accuracy: 0.9625\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2897 - accuracy: 0.8833 - val_loss: 0.0995 - val_accuracy: 0.9786\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2517 - accuracy: 0.9051 - val_loss: 0.0800 - val_accuracy: 0.9853\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2850 - accuracy: 0.8920 - val_loss: 0.0933 - val_accuracy: 0.9786\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2502 - accuracy: 0.9055 - val_loss: 0.0797 - val_accuracy: 0.9826\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2495 - accuracy: 0.9021 - val_loss: 0.1065 - val_accuracy: 0.9718\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2868 - accuracy: 0.8942 - val_loss: 0.1168 - val_accuracy: 0.9678\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2641 - accuracy: 0.9054 - val_loss: 0.0780 - val_accuracy: 0.9826\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2318 - accuracy: 0.9149 - val_loss: 0.0761 - val_accuracy: 0.9839\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2341 - accuracy: 0.9146 - val_loss: 0.0802 - val_accuracy: 0.9812\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3987 - accuracy: 0.8528 - val_loss: 0.3934 - val_accuracy: 0.8271\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2659 - accuracy: 0.9007 - val_loss: 0.1153 - val_accuracy: 0.9705\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2184 - accuracy: 0.9224 - val_loss: 0.1007 - val_accuracy: 0.9732\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2022 - accuracy: 0.9267 - val_loss: 0.0768 - val_accuracy: 0.9812\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2103 - accuracy: 0.9261 - val_loss: 0.0959 - val_accuracy: 0.9692\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2470 - accuracy: 0.9119 - val_loss: 0.0885 - val_accuracy: 0.9759\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2347 - accuracy: 0.9180 - val_loss: 0.0760 - val_accuracy: 0.9812\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2022 - accuracy: 0.9271 - val_loss: 0.0794 - val_accuracy: 0.9772\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1838 - accuracy: 0.9349 - val_loss: 0.0663 - val_accuracy: 0.9799\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 49ms/step - loss: 0.2020 - accuracy: 0.9289 - val_loss: 0.0292 - val_accuracy: 0.9960\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2106 - accuracy: 0.9261 - val_loss: 0.0319 - val_accuracy: 0.9960\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1940 - accuracy: 0.9310 - val_loss: 0.0338 - val_accuracy: 0.9919\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2120 - accuracy: 0.9246 - val_loss: 0.0379 - val_accuracy: 0.9933\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1797 - accuracy: 0.9365 - val_loss: 0.0263 - val_accuracy: 0.9973\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1854 - accuracy: 0.9355 - val_loss: 0.0293 - val_accuracy: 0.9960\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2135 - accuracy: 0.9279 - val_loss: 0.0585 - val_accuracy: 0.9893\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1908 - accuracy: 0.9300 - val_loss: 0.0308 - val_accuracy: 0.9973\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1979 - accuracy: 0.9274 - val_loss: 0.0303 - val_accuracy: 0.9960\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2082 - accuracy: 0.9273 - val_loss: 0.0443 - val_accuracy: 0.9906\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1935 - accuracy: 0.9344 - val_loss: 0.0365 - val_accuracy: 0.9933\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1865 - accuracy: 0.9361 - val_loss: 0.0345 - val_accuracy: 0.9960\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1790 - accuracy: 0.9388 - val_loss: 0.0466 - val_accuracy: 0.9879\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1917 - accuracy: 0.9364 - val_loss: 0.0469 - val_accuracy: 0.9879\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1914 - accuracy: 0.9365 - val_loss: 0.0514 - val_accuracy: 0.9946\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1706 - accuracy: 0.9408 - val_loss: 0.0366 - val_accuracy: 0.9933\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1554 - accuracy: 0.9449 - val_loss: 0.0259 - val_accuracy: 0.9960\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1533 - accuracy: 0.9464 - val_loss: 0.0207 - val_accuracy: 0.9973\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1368 - accuracy: 0.9554 - val_loss: 0.0217 - val_accuracy: 0.9960\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1504 - accuracy: 0.9493 - val_loss: 0.0274 - val_accuracy: 0.9933\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1629 - accuracy: 0.9464 - val_loss: 0.0333 - val_accuracy: 0.9933\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1701 - accuracy: 0.9422 - val_loss: 0.0322 - val_accuracy: 0.9919\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1449 - accuracy: 0.9505 - val_loss: 0.0295 - val_accuracy: 0.9906\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1425 - accuracy: 0.9523 - val_loss: 0.0271 - val_accuracy: 0.9973\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1311 - accuracy: 0.9537 - val_loss: 0.0175 - val_accuracy: 0.9973\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1425 - accuracy: 0.9516 - val_loss: 0.0285 - val_accuracy: 0.9973\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1507 - accuracy: 0.9462 - val_loss: 0.0356 - val_accuracy: 0.9879\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2771 - accuracy: 0.9091 - val_loss: 0.0634 - val_accuracy: 0.9866\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1729 - accuracy: 0.9425 - val_loss: 0.0284 - val_accuracy: 0.9960\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1457 - accuracy: 0.9478 - val_loss: 0.0238 - val_accuracy: 0.9933\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1238 - accuracy: 0.9602 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1397 - accuracy: 0.9523 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1330 - accuracy: 0.9534 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1301 - accuracy: 0.9568 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1313 - accuracy: 0.9540 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1284 - accuracy: 0.9571 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1164 - accuracy: 0.9627 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1194 - accuracy: 0.9613 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1337 - accuracy: 0.9546 - val_loss: 0.0088 - val_accuracy: 0.9987\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1219 - accuracy: 0.9587 - val_loss: 0.0055 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1409 - accuracy: 0.9484 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1106 - accuracy: 0.9638 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1163 - accuracy: 0.9619 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1023 - accuracy: 0.9690 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1219 - accuracy: 0.9620 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1093 - accuracy: 0.9617 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1221 - accuracy: 0.9583 - val_loss: 0.0091 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1133 - accuracy: 0.9642 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1013 - accuracy: 0.9662 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0989 - accuracy: 0.9696 - val_loss: 0.0060 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0923 - accuracy: 0.9696 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1067 - accuracy: 0.9638 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0890 - accuracy: 0.9692 - val_loss: 0.0045 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1101 - accuracy: 0.9626 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1172 - accuracy: 0.9639 - val_loss: 0.0077 - val_accuracy: 0.9973\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0740 - accuracy: 0.9787 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1025 - accuracy: 0.9660 - val_loss: 0.0050 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0885 - accuracy: 0.9705 - val_loss: 0.0038 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0957 - accuracy: 0.9712 - val_loss: 0.0071 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1034 - accuracy: 0.9645 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0972 - accuracy: 0.9692 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2203 - accuracy: 0.9306 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1223 - accuracy: 0.9572 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1034 - accuracy: 0.9635 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0961 - accuracy: 0.9695 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1035 - accuracy: 0.9659 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1111 - accuracy: 0.9647 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1126 - accuracy: 0.9632 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1007 - accuracy: 0.9639 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1156 - accuracy: 0.9616 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1077 - accuracy: 0.9627 - val_loss: 0.0074 - val_accuracy: 0.9987\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1081 - accuracy: 0.9638 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0933 - accuracy: 0.9684 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0922 - accuracy: 0.9665 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0971 - accuracy: 0.9662 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0978 - accuracy: 0.9675 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1015 - accuracy: 0.9650 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1342 - accuracy: 0.9569 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1295 - accuracy: 0.9589 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0974 - accuracy: 0.9666 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0938 - accuracy: 0.9687 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1011 - accuracy: 0.9647 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0837 - accuracy: 0.9718 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1009 - accuracy: 0.9653 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1135 - accuracy: 0.9551 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0850 - accuracy: 0.9700 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0986 - accuracy: 0.9660 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1061 - accuracy: 0.9648 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0913 - accuracy: 0.9687 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0908 - accuracy: 0.9703 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0788 - accuracy: 0.9735 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0830 - accuracy: 0.9712 - val_loss: 6.3041e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0913 - accuracy: 0.9698 - val_loss: 9.1072e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0970 - accuracy: 0.9639 - val_loss: 5.6331e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0931 - accuracy: 0.9680 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0902 - accuracy: 0.9684 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0813 - accuracy: 0.9717 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1028 - accuracy: 0.9659 - val_loss: 0.0060 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1407 - accuracy: 0.9510 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0960 - accuracy: 0.9684 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0960 - accuracy: 0.9699 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1000 - accuracy: 0.9645 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0812 - accuracy: 0.9684 - val_loss: 8.5872e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0754 - accuracy: 0.9762 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0791 - accuracy: 0.9720 - val_loss: 6.7089e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0948 - accuracy: 0.9686 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0913 - accuracy: 0.9696 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0800 - accuracy: 0.9741 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0752 - accuracy: 0.9718 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1033 - accuracy: 0.9630 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0812 - accuracy: 0.9742 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0829 - accuracy: 0.9738 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0825 - accuracy: 0.9727 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0755 - accuracy: 0.9747 - val_loss: 6.1984e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0778 - accuracy: 0.9742 - val_loss: 6.9220e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0756 - accuracy: 0.9736 - val_loss: 8.7630e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0695 - accuracy: 0.9763 - val_loss: 7.4261e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0793 - accuracy: 0.9747 - val_loss: 9.9198e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0846 - accuracy: 0.9702 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0715 - accuracy: 0.9754 - val_loss: 0.0035 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "CAnc2SJa3o9f",
        "outputId": "39876b1d-38e1-45c3-84d8-2b949ecbed6a"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 8ms/step - loss: 0.1029 - accuracy: 0.9748\n",
            "Accuracy  : 0.9747853875160217\n",
            "F1_Score  : 0.9723365021437487\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7fcxLuwZpkK",
        "outputId": "185cd2b5-feb5-4b57-f52a-8cd59cd35618"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "a4c50644-2ed5-4575-dc03-bae41e00a09d"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 53ms/step - loss: 1.1685 - accuracy: 0.4478 - val_loss: 1.0420 - val_accuracy: 0.5268\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0342 - accuracy: 0.5188 - val_loss: 1.0175 - val_accuracy: 0.5268\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0390 - accuracy: 0.5161 - val_loss: 1.0181 - val_accuracy: 0.5268\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0291 - accuracy: 0.5146 - val_loss: 1.0013 - val_accuracy: 0.5268\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0285 - accuracy: 0.5209 - val_loss: 1.0011 - val_accuracy: 0.5268\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0181 - accuracy: 0.5246 - val_loss: 1.0007 - val_accuracy: 0.5268\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0065 - accuracy: 0.5328 - val_loss: 1.0062 - val_accuracy: 0.5268\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0220 - accuracy: 0.5187 - val_loss: 0.9998 - val_accuracy: 0.5268\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0125 - accuracy: 0.5222 - val_loss: 0.9979 - val_accuracy: 0.5268\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0038 - accuracy: 0.5293 - val_loss: 0.9974 - val_accuracy: 0.5268\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0093 - accuracy: 0.5208 - val_loss: 0.9966 - val_accuracy: 0.5268\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0083 - accuracy: 0.5183 - val_loss: 0.9941 - val_accuracy: 0.5268\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0158 - accuracy: 0.5145 - val_loss: 0.9928 - val_accuracy: 0.5268\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0175 - accuracy: 0.5101 - val_loss: 0.9934 - val_accuracy: 0.5268\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0027 - accuracy: 0.5225 - val_loss: 0.9944 - val_accuracy: 0.5268\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0105 - accuracy: 0.5148 - val_loss: 0.9920 - val_accuracy: 0.5268\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0011 - accuracy: 0.5214 - val_loss: 0.9947 - val_accuracy: 0.5268\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0001 - accuracy: 0.5281 - val_loss: 0.9953 - val_accuracy: 0.5268\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0160 - accuracy: 0.5037 - val_loss: 0.9932 - val_accuracy: 0.5268\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0066 - accuracy: 0.5177 - val_loss: 0.9929 - val_accuracy: 0.5268\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0133 - accuracy: 0.5147 - val_loss: 0.9934 - val_accuracy: 0.5268\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0012 - accuracy: 0.5227 - val_loss: 0.9940 - val_accuracy: 0.5268\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0036 - accuracy: 0.5211 - val_loss: 0.9955 - val_accuracy: 0.5268\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0015 - accuracy: 0.5224 - val_loss: 0.9948 - val_accuracy: 0.5268\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0054 - accuracy: 0.5151 - val_loss: 0.9937 - val_accuracy: 0.5268\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0049 - accuracy: 0.5242 - val_loss: 0.9959 - val_accuracy: 0.5268\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0035 - accuracy: 0.5242 - val_loss: 0.9950 - val_accuracy: 0.5268\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9997 - accuracy: 0.5288 - val_loss: 0.9939 - val_accuracy: 0.5268\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0025 - accuracy: 0.5198 - val_loss: 0.9931 - val_accuracy: 0.5268\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0047 - accuracy: 0.5182 - val_loss: 0.9934 - val_accuracy: 0.5268\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0055 - accuracy: 0.5213 - val_loss: 0.9823 - val_accuracy: 0.5416\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0048 - accuracy: 0.5213 - val_loss: 0.9826 - val_accuracy: 0.5416\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0027 - accuracy: 0.5213 - val_loss: 0.9825 - val_accuracy: 0.5416\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0047 - accuracy: 0.5213 - val_loss: 0.9870 - val_accuracy: 0.5416\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0046 - accuracy: 0.5212 - val_loss: 0.9838 - val_accuracy: 0.5416\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0023 - accuracy: 0.5213 - val_loss: 0.9809 - val_accuracy: 0.5416\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0018 - accuracy: 0.5213 - val_loss: 0.9854 - val_accuracy: 0.5416\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0040 - accuracy: 0.5219 - val_loss: 0.9816 - val_accuracy: 0.5416\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0044 - accuracy: 0.5203 - val_loss: 0.9812 - val_accuracy: 0.5416\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0023 - accuracy: 0.5213 - val_loss: 0.9851 - val_accuracy: 0.5416\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0038 - accuracy: 0.5212 - val_loss: 0.9839 - val_accuracy: 0.5416\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0034 - accuracy: 0.5213 - val_loss: 0.9801 - val_accuracy: 0.5416\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0030 - accuracy: 0.5213 - val_loss: 0.9794 - val_accuracy: 0.5416\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0022 - accuracy: 0.5213 - val_loss: 0.9804 - val_accuracy: 0.5416\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0030 - accuracy: 0.5213 - val_loss: 0.9786 - val_accuracy: 0.5416\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0026 - accuracy: 0.5213 - val_loss: 0.9792 - val_accuracy: 0.5416\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0022 - accuracy: 0.5215 - val_loss: 0.9789 - val_accuracy: 0.5416\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0023 - accuracy: 0.5213 - val_loss: 0.9827 - val_accuracy: 0.5416\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0041 - accuracy: 0.5213 - val_loss: 0.9799 - val_accuracy: 0.5416\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0029 - accuracy: 0.5213 - val_loss: 0.9796 - val_accuracy: 0.5416\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0021 - accuracy: 0.5213 - val_loss: 0.9792 - val_accuracy: 0.5416\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0021 - accuracy: 0.5213 - val_loss: 0.9770 - val_accuracy: 0.5416\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0015 - accuracy: 0.5206 - val_loss: 0.9805 - val_accuracy: 0.5416\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9991 - accuracy: 0.5237 - val_loss: 0.9773 - val_accuracy: 0.5536\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0005 - accuracy: 0.5237 - val_loss: 0.9837 - val_accuracy: 0.5416\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0005 - accuracy: 0.5231 - val_loss: 0.9779 - val_accuracy: 0.5456\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0014 - accuracy: 0.5215 - val_loss: 0.9766 - val_accuracy: 0.5429\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9988 - accuracy: 0.5261 - val_loss: 0.9771 - val_accuracy: 0.5442\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0005 - accuracy: 0.5253 - val_loss: 0.9808 - val_accuracy: 0.5416\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9972 - accuracy: 0.5268 - val_loss: 0.9756 - val_accuracy: 0.5496\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9933 - accuracy: 0.5259 - val_loss: 1.0196 - val_accuracy: 0.5040\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9926 - accuracy: 0.5288 - val_loss: 1.0197 - val_accuracy: 0.5027\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9935 - accuracy: 0.5289 - val_loss: 1.0234 - val_accuracy: 0.5040\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9942 - accuracy: 0.5265 - val_loss: 1.0187 - val_accuracy: 0.5027\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9918 - accuracy: 0.5295 - val_loss: 1.0115 - val_accuracy: 0.5161\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9932 - accuracy: 0.5304 - val_loss: 1.0131 - val_accuracy: 0.5241\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9927 - accuracy: 0.5285 - val_loss: 1.0098 - val_accuracy: 0.5161\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9940 - accuracy: 0.5271 - val_loss: 1.0125 - val_accuracy: 0.5161\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9866 - accuracy: 0.5328 - val_loss: 1.0202 - val_accuracy: 0.5080\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9882 - accuracy: 0.5323 - val_loss: 1.0103 - val_accuracy: 0.5134\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9883 - accuracy: 0.5306 - val_loss: 1.0168 - val_accuracy: 0.5147\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9890 - accuracy: 0.5314 - val_loss: 1.0148 - val_accuracy: 0.5188\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9887 - accuracy: 0.5313 - val_loss: 1.0095 - val_accuracy: 0.5228\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9871 - accuracy: 0.5338 - val_loss: 1.0074 - val_accuracy: 0.5241\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9882 - accuracy: 0.5288 - val_loss: 1.0106 - val_accuracy: 0.5188\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9854 - accuracy: 0.5356 - val_loss: 1.0063 - val_accuracy: 0.5174\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9852 - accuracy: 0.5361 - val_loss: 1.0070 - val_accuracy: 0.5268\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9864 - accuracy: 0.5314 - val_loss: 1.0061 - val_accuracy: 0.5188\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9833 - accuracy: 0.5300 - val_loss: 1.0096 - val_accuracy: 0.5121\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9825 - accuracy: 0.5344 - val_loss: 1.0091 - val_accuracy: 0.5201\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9849 - accuracy: 0.5373 - val_loss: 0.9983 - val_accuracy: 0.5282\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9870 - accuracy: 0.5338 - val_loss: 1.0026 - val_accuracy: 0.5161\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9856 - accuracy: 0.5362 - val_loss: 1.0118 - val_accuracy: 0.5228\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9862 - accuracy: 0.5311 - val_loss: 1.0024 - val_accuracy: 0.5201\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9816 - accuracy: 0.5364 - val_loss: 1.0080 - val_accuracy: 0.5174\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9816 - accuracy: 0.5352 - val_loss: 1.0003 - val_accuracy: 0.5282\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9824 - accuracy: 0.5335 - val_loss: 1.0008 - val_accuracy: 0.5228\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9803 - accuracy: 0.5411 - val_loss: 1.0015 - val_accuracy: 0.5255\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9796 - accuracy: 0.5376 - val_loss: 1.0012 - val_accuracy: 0.5214\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9784 - accuracy: 0.5370 - val_loss: 1.0007 - val_accuracy: 0.5188\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9787 - accuracy: 0.5380 - val_loss: 0.9847 - val_accuracy: 0.5335\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9797 - accuracy: 0.5368 - val_loss: 0.9755 - val_accuracy: 0.5375\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9801 - accuracy: 0.5341 - val_loss: 0.9861 - val_accuracy: 0.5308\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9765 - accuracy: 0.5389 - val_loss: 0.9880 - val_accuracy: 0.5362\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9788 - accuracy: 0.5377 - val_loss: 0.9972 - val_accuracy: 0.5295\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9779 - accuracy: 0.5405 - val_loss: 0.9819 - val_accuracy: 0.5416\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9766 - accuracy: 0.5417 - val_loss: 0.9861 - val_accuracy: 0.5375\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9719 - accuracy: 0.5419 - val_loss: 0.9803 - val_accuracy: 0.5349\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9682 - accuracy: 0.5450 - val_loss: 0.9773 - val_accuracy: 0.5362\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9678 - accuracy: 0.5434 - val_loss: 0.9798 - val_accuracy: 0.5389\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9635 - accuracy: 0.5492 - val_loss: 0.9806 - val_accuracy: 0.5375\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9566 - accuracy: 0.5484 - val_loss: 0.9743 - val_accuracy: 0.5456\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9656 - accuracy: 0.5471 - val_loss: 0.9788 - val_accuracy: 0.5375\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9577 - accuracy: 0.5507 - val_loss: 0.9673 - val_accuracy: 0.5509\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9592 - accuracy: 0.5441 - val_loss: 0.9746 - val_accuracy: 0.5550\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9598 - accuracy: 0.5458 - val_loss: 0.9782 - val_accuracy: 0.5389\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9552 - accuracy: 0.5489 - val_loss: 0.9745 - val_accuracy: 0.5509\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9507 - accuracy: 0.5523 - val_loss: 0.9826 - val_accuracy: 0.5496\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9503 - accuracy: 0.5535 - val_loss: 0.9704 - val_accuracy: 0.5389\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9469 - accuracy: 0.5539 - val_loss: 0.9760 - val_accuracy: 0.5456\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9414 - accuracy: 0.5559 - val_loss: 0.9506 - val_accuracy: 0.5670\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9341 - accuracy: 0.5590 - val_loss: 0.9542 - val_accuracy: 0.5576\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9293 - accuracy: 0.5620 - val_loss: 0.9642 - val_accuracy: 0.5496\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9261 - accuracy: 0.5645 - val_loss: 0.9359 - val_accuracy: 0.5643\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9208 - accuracy: 0.5703 - val_loss: 0.9505 - val_accuracy: 0.5523\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9192 - accuracy: 0.5650 - val_loss: 0.9348 - val_accuracy: 0.5590\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9208 - accuracy: 0.5650 - val_loss: 0.9427 - val_accuracy: 0.5550\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9060 - accuracy: 0.5729 - val_loss: 0.9374 - val_accuracy: 0.5590\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9134 - accuracy: 0.5711 - val_loss: 0.9246 - val_accuracy: 0.5670\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9043 - accuracy: 0.5744 - val_loss: 0.9450 - val_accuracy: 0.5751\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9076 - accuracy: 0.5772 - val_loss: 0.8365 - val_accuracy: 0.6072\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8994 - accuracy: 0.5776 - val_loss: 0.8464 - val_accuracy: 0.5992\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8862 - accuracy: 0.5842 - val_loss: 0.8338 - val_accuracy: 0.6046\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8863 - accuracy: 0.5838 - val_loss: 0.8453 - val_accuracy: 0.5898\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8794 - accuracy: 0.5891 - val_loss: 0.8528 - val_accuracy: 0.5979\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8739 - accuracy: 0.5882 - val_loss: 0.8291 - val_accuracy: 0.6019\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8789 - accuracy: 0.5902 - val_loss: 0.8589 - val_accuracy: 0.5912\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8521 - accuracy: 0.5981 - val_loss: 0.8387 - val_accuracy: 0.5912\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8538 - accuracy: 0.5976 - val_loss: 0.8097 - val_accuracy: 0.6072\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8473 - accuracy: 0.6000 - val_loss: 0.8030 - val_accuracy: 0.6046\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8378 - accuracy: 0.6098 - val_loss: 0.8006 - val_accuracy: 0.6193\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8335 - accuracy: 0.6067 - val_loss: 0.8341 - val_accuracy: 0.6046\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8353 - accuracy: 0.6118 - val_loss: 0.7810 - val_accuracy: 0.6260\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8252 - accuracy: 0.6140 - val_loss: 0.7639 - val_accuracy: 0.6260\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8013 - accuracy: 0.6241 - val_loss: 0.8045 - val_accuracy: 0.6032\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8116 - accuracy: 0.6225 - val_loss: 0.7964 - val_accuracy: 0.6046\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8057 - accuracy: 0.6258 - val_loss: 0.7683 - val_accuracy: 0.6394\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7857 - accuracy: 0.6291 - val_loss: 0.7609 - val_accuracy: 0.6300\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7726 - accuracy: 0.6376 - val_loss: 0.7595 - val_accuracy: 0.6394\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7659 - accuracy: 0.6456 - val_loss: 0.7528 - val_accuracy: 0.6434\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7716 - accuracy: 0.6383 - val_loss: 0.8188 - val_accuracy: 0.6408\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7521 - accuracy: 0.6496 - val_loss: 0.7397 - val_accuracy: 0.6528\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7527 - accuracy: 0.6502 - val_loss: 0.7643 - val_accuracy: 0.6381\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7352 - accuracy: 0.6559 - val_loss: 0.7109 - val_accuracy: 0.6542\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7235 - accuracy: 0.6653 - val_loss: 0.7207 - val_accuracy: 0.6649\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7264 - accuracy: 0.6645 - val_loss: 0.7041 - val_accuracy: 0.6743\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7109 - accuracy: 0.6686 - val_loss: 0.7144 - val_accuracy: 0.6649\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7027 - accuracy: 0.6775 - val_loss: 0.7136 - val_accuracy: 0.6729\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6847 - accuracy: 0.6808 - val_loss: 0.6876 - val_accuracy: 0.6863\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6921 - accuracy: 0.6803 - val_loss: 0.7182 - val_accuracy: 0.6662\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7046 - accuracy: 0.6742 - val_loss: 0.5561 - val_accuracy: 0.7466\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6873 - accuracy: 0.6776 - val_loss: 0.5934 - val_accuracy: 0.7306\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6770 - accuracy: 0.6894 - val_loss: 0.5488 - val_accuracy: 0.7359\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6749 - accuracy: 0.6864 - val_loss: 0.5377 - val_accuracy: 0.7520\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6388 - accuracy: 0.7010 - val_loss: 0.5726 - val_accuracy: 0.7359\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6425 - accuracy: 0.7057 - val_loss: 0.6247 - val_accuracy: 0.7158\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6332 - accuracy: 0.7069 - val_loss: 0.5255 - val_accuracy: 0.7654\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6167 - accuracy: 0.7154 - val_loss: 0.5474 - val_accuracy: 0.7547\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6171 - accuracy: 0.7192 - val_loss: 0.5013 - val_accuracy: 0.7601\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6021 - accuracy: 0.7183 - val_loss: 0.5555 - val_accuracy: 0.7453\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6081 - accuracy: 0.7227 - val_loss: 0.5065 - val_accuracy: 0.7694\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5968 - accuracy: 0.7279 - val_loss: 0.5333 - val_accuracy: 0.7466\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5850 - accuracy: 0.7349 - val_loss: 0.5084 - val_accuracy: 0.7788\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5789 - accuracy: 0.7423 - val_loss: 0.5071 - val_accuracy: 0.7614\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5652 - accuracy: 0.7462 - val_loss: 0.4760 - val_accuracy: 0.7815\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5529 - accuracy: 0.7492 - val_loss: 0.5191 - val_accuracy: 0.7614\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5463 - accuracy: 0.7547 - val_loss: 0.4792 - val_accuracy: 0.7694\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5499 - accuracy: 0.7522 - val_loss: 0.4965 - val_accuracy: 0.7627\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5334 - accuracy: 0.7650 - val_loss: 0.4437 - val_accuracy: 0.7842\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5330 - accuracy: 0.7610 - val_loss: 0.4630 - val_accuracy: 0.7909\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5135 - accuracy: 0.7677 - val_loss: 0.4649 - val_accuracy: 0.7869\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5129 - accuracy: 0.7666 - val_loss: 0.4403 - val_accuracy: 0.7936\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5014 - accuracy: 0.7750 - val_loss: 0.4253 - val_accuracy: 0.8003\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4942 - accuracy: 0.7852 - val_loss: 0.4434 - val_accuracy: 0.8016\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4945 - accuracy: 0.7803 - val_loss: 0.4258 - val_accuracy: 0.8083\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4980 - accuracy: 0.7833 - val_loss: 0.5342 - val_accuracy: 0.7627\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4878 - accuracy: 0.7928 - val_loss: 0.4229 - val_accuracy: 0.8097\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4630 - accuracy: 0.7963 - val_loss: 0.4740 - val_accuracy: 0.7855\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4409 - accuracy: 0.8075 - val_loss: 0.4370 - val_accuracy: 0.8003\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4333 - accuracy: 0.8182 - val_loss: 0.3980 - val_accuracy: 0.8338\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4545 - accuracy: 0.8052 - val_loss: 0.3066 - val_accuracy: 0.8591\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4512 - accuracy: 0.8076 - val_loss: 0.3018 - val_accuracy: 0.8644\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4382 - accuracy: 0.8161 - val_loss: 0.2921 - val_accuracy: 0.8779\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4451 - accuracy: 0.8112 - val_loss: 0.2862 - val_accuracy: 0.8819\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4300 - accuracy: 0.8209 - val_loss: 0.3007 - val_accuracy: 0.8698\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4220 - accuracy: 0.8194 - val_loss: 0.2856 - val_accuracy: 0.8711\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3879 - accuracy: 0.8377 - val_loss: 0.2730 - val_accuracy: 0.8886\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4033 - accuracy: 0.8330 - val_loss: 0.2917 - val_accuracy: 0.8658\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3706 - accuracy: 0.8438 - val_loss: 0.2722 - val_accuracy: 0.8779\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3686 - accuracy: 0.8488 - val_loss: 0.2620 - val_accuracy: 0.8926\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3886 - accuracy: 0.8435 - val_loss: 0.2735 - val_accuracy: 0.8725\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3849 - accuracy: 0.8473 - val_loss: 0.2719 - val_accuracy: 0.8926\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3880 - accuracy: 0.8367 - val_loss: 0.2650 - val_accuracy: 0.8886\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3497 - accuracy: 0.8555 - val_loss: 0.2798 - val_accuracy: 0.8752\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3468 - accuracy: 0.8629 - val_loss: 0.2321 - val_accuracy: 0.9007\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3337 - accuracy: 0.8707 - val_loss: 0.2397 - val_accuracy: 0.9114\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3037 - accuracy: 0.8827 - val_loss: 0.2481 - val_accuracy: 0.8926\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2908 - accuracy: 0.8875 - val_loss: 0.2327 - val_accuracy: 0.8993\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3056 - accuracy: 0.8796 - val_loss: 0.2206 - val_accuracy: 0.9114\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3180 - accuracy: 0.8744 - val_loss: 0.2864 - val_accuracy: 0.8765\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2992 - accuracy: 0.8839 - val_loss: 0.2647 - val_accuracy: 0.8953\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3019 - accuracy: 0.8792 - val_loss: 0.1979 - val_accuracy: 0.9221\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2815 - accuracy: 0.8912 - val_loss: 0.2038 - val_accuracy: 0.9168\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2917 - accuracy: 0.8885 - val_loss: 0.2157 - val_accuracy: 0.9141\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2595 - accuracy: 0.9005 - val_loss: 0.1749 - val_accuracy: 0.9302\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2773 - accuracy: 0.8944 - val_loss: 0.3007 - val_accuracy: 0.8711\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3389 - accuracy: 0.8610 - val_loss: 0.4152 - val_accuracy: 0.7960\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2534 - accuracy: 0.9018 - val_loss: 0.1877 - val_accuracy: 0.9315\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2516 - accuracy: 0.9012 - val_loss: 0.1867 - val_accuracy: 0.9248\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2655 - accuracy: 0.8982 - val_loss: 0.1971 - val_accuracy: 0.9168\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2446 - accuracy: 0.9122 - val_loss: 0.0707 - val_accuracy: 0.9799\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2641 - accuracy: 0.9060 - val_loss: 0.1013 - val_accuracy: 0.9718\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2399 - accuracy: 0.9106 - val_loss: 0.0675 - val_accuracy: 0.9758\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2352 - accuracy: 0.9094 - val_loss: 0.1050 - val_accuracy: 0.9557\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2489 - accuracy: 0.9082 - val_loss: 0.0988 - val_accuracy: 0.9691\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2141 - accuracy: 0.9209 - val_loss: 0.0680 - val_accuracy: 0.9799\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2182 - accuracy: 0.9201 - val_loss: 0.0511 - val_accuracy: 0.9852\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2129 - accuracy: 0.9224 - val_loss: 0.0622 - val_accuracy: 0.9879\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2044 - accuracy: 0.9291 - val_loss: 0.0557 - val_accuracy: 0.9893\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2178 - accuracy: 0.9157 - val_loss: 0.0563 - val_accuracy: 0.9919\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2061 - accuracy: 0.9295 - val_loss: 0.0527 - val_accuracy: 0.9919\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1960 - accuracy: 0.9334 - val_loss: 0.0537 - val_accuracy: 0.9866\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1752 - accuracy: 0.9371 - val_loss: 0.0530 - val_accuracy: 0.9839\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1939 - accuracy: 0.9294 - val_loss: 0.0609 - val_accuracy: 0.9852\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1817 - accuracy: 0.9326 - val_loss: 0.0584 - val_accuracy: 0.9839\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2491 - accuracy: 0.9104 - val_loss: 0.1165 - val_accuracy: 0.9570\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1717 - accuracy: 0.9374 - val_loss: 0.0495 - val_accuracy: 0.9879\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1930 - accuracy: 0.9338 - val_loss: 0.0595 - val_accuracy: 0.9852\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1546 - accuracy: 0.9453 - val_loss: 0.0380 - val_accuracy: 0.9919\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1935 - accuracy: 0.9340 - val_loss: 0.0512 - val_accuracy: 0.9919\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1616 - accuracy: 0.9447 - val_loss: 0.0345 - val_accuracy: 0.9906\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1446 - accuracy: 0.9490 - val_loss: 0.0393 - val_accuracy: 0.9879\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1517 - accuracy: 0.9459 - val_loss: 0.0260 - val_accuracy: 0.9960\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1394 - accuracy: 0.9504 - val_loss: 0.0350 - val_accuracy: 0.9893\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1521 - accuracy: 0.9487 - val_loss: 0.0879 - val_accuracy: 0.9705\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1434 - accuracy: 0.9496 - val_loss: 0.0469 - val_accuracy: 0.9866\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1464 - accuracy: 0.9511 - val_loss: 0.0311 - val_accuracy: 0.9906\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1517 - accuracy: 0.9492 - val_loss: 0.0242 - val_accuracy: 0.9960\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1522 - accuracy: 0.9504 - val_loss: 0.0288 - val_accuracy: 0.9919\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1383 - accuracy: 0.9507 - val_loss: 0.0345 - val_accuracy: 0.9893\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2366 - accuracy: 0.9192 - val_loss: 0.0379 - val_accuracy: 0.9960\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1679 - accuracy: 0.9392 - val_loss: 0.0319 - val_accuracy: 0.9987\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1424 - accuracy: 0.9531 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1629 - accuracy: 0.9496 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1462 - accuracy: 0.9470 - val_loss: 0.0185 - val_accuracy: 0.9987\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1327 - accuracy: 0.9557 - val_loss: 0.0340 - val_accuracy: 0.9866\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1579 - accuracy: 0.9422 - val_loss: 0.0163 - val_accuracy: 0.9960\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1392 - accuracy: 0.9526 - val_loss: 0.0200 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1963 - accuracy: 0.9352 - val_loss: 0.2112 - val_accuracy: 0.9020\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1528 - accuracy: 0.9516 - val_loss: 0.0237 - val_accuracy: 0.9960\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1427 - accuracy: 0.9498 - val_loss: 0.0111 - val_accuracy: 0.9987\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1306 - accuracy: 0.9559 - val_loss: 0.0182 - val_accuracy: 0.9973\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1267 - accuracy: 0.9563 - val_loss: 0.0346 - val_accuracy: 0.9946\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1245 - accuracy: 0.9554 - val_loss: 0.0319 - val_accuracy: 0.9946\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1214 - accuracy: 0.9560 - val_loss: 0.0200 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1372 - accuracy: 0.9507 - val_loss: 0.0225 - val_accuracy: 0.9973\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1309 - accuracy: 0.9504 - val_loss: 0.1013 - val_accuracy: 0.9570\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1094 - accuracy: 0.9648 - val_loss: 0.0228 - val_accuracy: 0.9946\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1261 - accuracy: 0.9575 - val_loss: 0.0349 - val_accuracy: 0.9906\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1313 - accuracy: 0.9559 - val_loss: 0.0132 - val_accuracy: 0.9973\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1002 - accuracy: 0.9677 - val_loss: 0.0314 - val_accuracy: 0.9866\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1079 - accuracy: 0.9616 - val_loss: 0.0102 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1145 - accuracy: 0.9611 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1241 - accuracy: 0.9559 - val_loss: 0.0287 - val_accuracy: 0.9906\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1403 - accuracy: 0.9522 - val_loss: 0.0125 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1239 - accuracy: 0.9605 - val_loss: 0.0148 - val_accuracy: 0.9946\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1134 - accuracy: 0.9636 - val_loss: 0.0131 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0999 - accuracy: 0.9644 - val_loss: 0.0242 - val_accuracy: 0.9960\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1157 - accuracy: 0.9599 - val_loss: 0.0252 - val_accuracy: 0.9946\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1070 - accuracy: 0.9648 - val_loss: 0.0101 - val_accuracy: 0.9987\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1137 - accuracy: 0.9602 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0973 - accuracy: 0.9663 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1315 - accuracy: 0.9525 - val_loss: 0.0321 - val_accuracy: 0.9933\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1161 - accuracy: 0.9624 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1125 - accuracy: 0.9641 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0961 - accuracy: 0.9671 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0985 - accuracy: 0.9665 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0981 - accuracy: 0.9662 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1007 - accuracy: 0.9653 - val_loss: 7.6295e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1342 - accuracy: 0.9583 - val_loss: 0.0600 - val_accuracy: 0.9758\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1278 - accuracy: 0.9562 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0894 - accuracy: 0.9712 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1079 - accuracy: 0.9627 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0971 - accuracy: 0.9677 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0920 - accuracy: 0.9680 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1145 - accuracy: 0.9627 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1030 - accuracy: 0.9654 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0867 - accuracy: 0.9711 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1154 - accuracy: 0.9589 - val_loss: 0.0310 - val_accuracy: 0.9879\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1062 - accuracy: 0.9613 - val_loss: 0.0135 - val_accuracy: 0.9960\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1066 - accuracy: 0.9641 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0796 - accuracy: 0.9712 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0935 - accuracy: 0.9674 - val_loss: 0.0265 - val_accuracy: 0.9946\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1259 - accuracy: 0.9596 - val_loss: 0.0508 - val_accuracy: 0.9852\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1049 - accuracy: 0.9620 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1073 - accuracy: 0.9624 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1031 - accuracy: 0.9636 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1001 - accuracy: 0.9632 - val_loss: 0.0084 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0760 - accuracy: 0.9735 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0798 - accuracy: 0.9745 - val_loss: 0.0053 - val_accuracy: 0.9987\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "7b9f7db2-660d-40b6-b21f-61e4c186b145"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.9683\n",
            "Accuracy  : 0.9683476686477661\n",
            "F1_Score  : 0.9676787938319888\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ad0f10cc-641c-4ffb-c17b-71934b860003"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'#dominance\\nX_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\\nprint(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "8bba7a45-152d-4571-ad2b-56775705aa5c"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'foldNum=0\\nmodel = get_model()\\nfor train_index, val_index in kfold.split(X_train, Y_train):\\n  foldNum = foldNum + 1\\n  print(\"Results for fold\",foldNum)\\n  x_train, x_val = X_train[train_index], X_train[val_index]\\n  y_train, y_val = Y_train[train_index], Y_train[val_index]\\n  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\\n  gc.collect() # Garbage collecter\\n  del x_train, x_val, y_train, y_val\\n  gc.collect()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "7c709687-8b54-430f-bcb3-c5253bdb0fd6"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'acrc = model.evaluate(x_test, y_test)\\npred = model.predict(x_test)\\nf1scr = f1_score(y_test.argmax(1), pred.argmax(1), average=\\'macro\\')\\nc_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\\nprint(\"Accuracy  : {}\".format(acrc[1]))\\nprint(\"F1_Score  : {}\".format(f1scr))\\nc_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\\nimport seaborn as sns\\nfigure = plt.figure(figsize=(9, 9))\\nsns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\\nplt.tight_layout()\\nplt.ylabel(\\'True label\\')\\nplt.xlabel(\\'Predicted label\\')\\nplt.show()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}