{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub23_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "583082cb-f5dc-47cd-a09d-64fb228774db"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e3\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  #EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "0e1c9280-d31a-430a-e02a-e0782d4f8423"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(23,24):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)\n",
        "print(valence.shape)\n",
        "print(arousal.shape)\n",
        "print(dominance.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.23\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (1398,) (3495,) (4427,)\n",
            "(9320,) (5359,) (2097,) (1864,)\n",
            "(9320,) (699,) (3262,) (5359,)\n",
            "(9320, 3)\n",
            "(9320, 3)\n",
            "(9320, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "ba89b317-c23a-44ab-964a-d59cb69e93c8"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "93593ba1-dd6b-4d21-f92b-e7dcec03d8c2"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "706"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "1e9959db-f393-4de9-f044-de9d8b32ef5d"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9086dc7-9cc4-40e9-ce73-a453c489e6f5"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 48s 69ms/step - loss: 1.0786 - accuracy: 0.4408 - val_loss: 1.0392 - val_accuracy: 0.4772\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0094 - accuracy: 0.4776 - val_loss: 0.9859 - val_accuracy: 0.5080\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9922 - accuracy: 0.4919 - val_loss: 0.9565 - val_accuracy: 0.5214\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.9740 - accuracy: 0.5143 - val_loss: 0.9401 - val_accuracy: 0.5335\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9687 - accuracy: 0.5097 - val_loss: 0.9363 - val_accuracy: 0.5308\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9528 - accuracy: 0.5288 - val_loss: 0.9227 - val_accuracy: 0.5536\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9538 - accuracy: 0.5208 - val_loss: 0.9323 - val_accuracy: 0.5442\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9569 - accuracy: 0.5226 - val_loss: 0.9261 - val_accuracy: 0.5429\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9461 - accuracy: 0.5397 - val_loss: 0.9498 - val_accuracy: 0.5094\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9354 - accuracy: 0.5349 - val_loss: 0.9658 - val_accuracy: 0.5174\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9371 - accuracy: 0.5316 - val_loss: 0.9023 - val_accuracy: 0.5617\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9208 - accuracy: 0.5486 - val_loss: 0.9601 - val_accuracy: 0.5054\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9150 - accuracy: 0.5458 - val_loss: 0.9114 - val_accuracy: 0.5523\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9134 - accuracy: 0.5509 - val_loss: 0.9515 - val_accuracy: 0.4906\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9061 - accuracy: 0.5550 - val_loss: 0.8976 - val_accuracy: 0.5456\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8842 - accuracy: 0.5695 - val_loss: 0.8753 - val_accuracy: 0.5791\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8946 - accuracy: 0.5581 - val_loss: 0.8951 - val_accuracy: 0.5442\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8891 - accuracy: 0.5630 - val_loss: 0.8565 - val_accuracy: 0.5858\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8655 - accuracy: 0.5774 - val_loss: 0.8685 - val_accuracy: 0.5670\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8594 - accuracy: 0.5736 - val_loss: 0.8510 - val_accuracy: 0.6046\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8522 - accuracy: 0.5774 - val_loss: 0.8399 - val_accuracy: 0.6072\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8470 - accuracy: 0.5841 - val_loss: 0.9231 - val_accuracy: 0.6072\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.8368 - accuracy: 0.5802 - val_loss: 0.8416 - val_accuracy: 0.6072\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8369 - accuracy: 0.5883 - val_loss: 0.8797 - val_accuracy: 0.6099\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.8100 - accuracy: 0.6017 - val_loss: 0.7928 - val_accuracy: 0.6367\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7896 - accuracy: 0.6162 - val_loss: 0.8142 - val_accuracy: 0.6193\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.7796 - accuracy: 0.6215 - val_loss: 0.8307 - val_accuracy: 0.6568\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.7480 - accuracy: 0.6295 - val_loss: 0.9593 - val_accuracy: 0.5777\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7534 - accuracy: 0.6383 - val_loss: 0.8058 - val_accuracy: 0.6300\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7126 - accuracy: 0.6668 - val_loss: 0.7710 - val_accuracy: 0.6756\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.6990 - accuracy: 0.6745 - val_loss: 0.6312 - val_accuracy: 0.6903\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.6585 - accuracy: 0.6976 - val_loss: 0.6631 - val_accuracy: 0.6930\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.6315 - accuracy: 0.7055 - val_loss: 0.6709 - val_accuracy: 0.6917\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.6080 - accuracy: 0.7313 - val_loss: 0.5477 - val_accuracy: 0.7560\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.5540 - accuracy: 0.7592 - val_loss: 0.5597 - val_accuracy: 0.7373\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.5983 - accuracy: 0.7344 - val_loss: 0.5534 - val_accuracy: 0.7520\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.4865 - accuracy: 0.7869 - val_loss: 0.5305 - val_accuracy: 0.7828\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.4557 - accuracy: 0.8083 - val_loss: 0.4293 - val_accuracy: 0.8097\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.4208 - accuracy: 0.8212 - val_loss: 0.5252 - val_accuracy: 0.7895\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.3834 - accuracy: 0.8440 - val_loss: 0.3926 - val_accuracy: 0.8405\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.3640 - accuracy: 0.8553 - val_loss: 0.3234 - val_accuracy: 0.8713\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.3255 - accuracy: 0.8744 - val_loss: 0.3838 - val_accuracy: 0.8512\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3022 - accuracy: 0.8845 - val_loss: 0.3295 - val_accuracy: 0.8686\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3021 - accuracy: 0.8851 - val_loss: 0.3456 - val_accuracy: 0.8660\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2949 - accuracy: 0.8923 - val_loss: 0.3171 - val_accuracy: 0.8874\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2805 - accuracy: 0.9010 - val_loss: 0.2956 - val_accuracy: 0.8727\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.2142 - accuracy: 0.9271 - val_loss: 0.3438 - val_accuracy: 0.8700\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.2077 - accuracy: 0.9264 - val_loss: 0.2890 - val_accuracy: 0.9048\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2007 - accuracy: 0.9310 - val_loss: 0.2253 - val_accuracy: 0.9169\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1887 - accuracy: 0.9326 - val_loss: 0.2591 - val_accuracy: 0.9035\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1654 - accuracy: 0.9411 - val_loss: 0.2170 - val_accuracy: 0.9102\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1604 - accuracy: 0.9471 - val_loss: 0.2158 - val_accuracy: 0.9276\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1487 - accuracy: 0.9505 - val_loss: 0.1994 - val_accuracy: 0.9236\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1374 - accuracy: 0.9535 - val_loss: 0.2664 - val_accuracy: 0.9115\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1335 - accuracy: 0.9554 - val_loss: 0.1739 - val_accuracy: 0.9370\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.1139 - accuracy: 0.9626 - val_loss: 0.3291 - val_accuracy: 0.8914\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1147 - accuracy: 0.9623 - val_loss: 0.1417 - val_accuracy: 0.9464\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1014 - accuracy: 0.9686 - val_loss: 0.1274 - val_accuracy: 0.9504\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1318 - accuracy: 0.9523 - val_loss: 0.4429 - val_accuracy: 0.8727\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1091 - accuracy: 0.9659 - val_loss: 0.2713 - val_accuracy: 0.9196\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1283 - accuracy: 0.9586 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1116 - accuracy: 0.9630 - val_loss: 0.0606 - val_accuracy: 0.9759\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.1164 - accuracy: 0.9638 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1015 - accuracy: 0.9660 - val_loss: 0.0234 - val_accuracy: 0.9906\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1093 - accuracy: 0.9627 - val_loss: 0.0383 - val_accuracy: 0.9853\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0851 - accuracy: 0.9721 - val_loss: 0.0112 - val_accuracy: 0.9987\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0885 - accuracy: 0.9714 - val_loss: 0.0150 - val_accuracy: 0.9973\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0875 - accuracy: 0.9738 - val_loss: 0.0098 - val_accuracy: 0.9973\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0752 - accuracy: 0.9742 - val_loss: 0.0201 - val_accuracy: 0.9920\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0994 - accuracy: 0.9703 - val_loss: 0.0288 - val_accuracy: 0.9906\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.1430 - accuracy: 0.9532 - val_loss: 0.0189 - val_accuracy: 0.9946\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0725 - accuracy: 0.9773 - val_loss: 0.0310 - val_accuracy: 0.9866\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0616 - accuracy: 0.9802 - val_loss: 0.0104 - val_accuracy: 0.9960\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0652 - accuracy: 0.9788 - val_loss: 0.0150 - val_accuracy: 0.9973\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0646 - accuracy: 0.9806 - val_loss: 0.0106 - val_accuracy: 0.9946\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0672 - accuracy: 0.9782 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0605 - accuracy: 0.9808 - val_loss: 0.0072 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0649 - accuracy: 0.9779 - val_loss: 0.0120 - val_accuracy: 0.9973\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0846 - accuracy: 0.9729 - val_loss: 0.0140 - val_accuracy: 0.9946\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0596 - accuracy: 0.9799 - val_loss: 0.0283 - val_accuracy: 0.9933\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0462 - accuracy: 0.9860 - val_loss: 0.0097 - val_accuracy: 0.9973\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0783 - accuracy: 0.9742 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0555 - accuracy: 0.9832 - val_loss: 0.0853 - val_accuracy: 0.9692\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 52ms/step - loss: 0.0594 - accuracy: 0.9823 - val_loss: 0.0196 - val_accuracy: 0.9960\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0692 - accuracy: 0.9769 - val_loss: 0.0075 - val_accuracy: 0.9973\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0516 - accuracy: 0.9836 - val_loss: 0.0040 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0490 - accuracy: 0.9854 - val_loss: 0.0160 - val_accuracy: 0.9973\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0396 - accuracy: 0.9870 - val_loss: 0.0247 - val_accuracy: 0.9906\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0423 - accuracy: 0.9860 - val_loss: 0.0088 - val_accuracy: 0.9973\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0472 - accuracy: 0.9848 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0844 - accuracy: 0.9739 - val_loss: 0.0110 - val_accuracy: 0.9946\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0591 - accuracy: 0.9812 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0387 - accuracy: 0.9870 - val_loss: 1.7020e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0417 - accuracy: 0.9867 - val_loss: 2.3321e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0458 - accuracy: 0.9861 - val_loss: 0.0190 - val_accuracy: 0.9933\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0525 - accuracy: 0.9818 - val_loss: 0.0023 - val_accuracy: 0.9987\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0522 - accuracy: 0.9841 - val_loss: 8.7046e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0477 - accuracy: 0.9848 - val_loss: 3.7917e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0426 - accuracy: 0.9872 - val_loss: 3.3925e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0484 - accuracy: 0.9848 - val_loss: 0.0038 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0481 - accuracy: 0.9872 - val_loss: 5.7147e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0456 - accuracy: 0.9864 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0615 - accuracy: 0.9809 - val_loss: 0.0028 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0527 - accuracy: 0.9838 - val_loss: 6.0475e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0533 - accuracy: 0.9838 - val_loss: 6.0920e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0394 - accuracy: 0.9908 - val_loss: 6.0218e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0636 - accuracy: 0.9791 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0367 - accuracy: 0.9891 - val_loss: 2.9529e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0285 - accuracy: 0.9909 - val_loss: 3.5029e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0445 - accuracy: 0.9867 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0294 - accuracy: 0.9911 - val_loss: 2.3490e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0415 - accuracy: 0.9875 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0466 - accuracy: 0.9852 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0339 - accuracy: 0.9902 - val_loss: 0.0033 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0451 - accuracy: 0.9863 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0356 - accuracy: 0.9885 - val_loss: 8.1696e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0429 - accuracy: 0.9867 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0400 - accuracy: 0.9879 - val_loss: 6.0668e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0445 - accuracy: 0.9870 - val_loss: 0.0017 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0346 - accuracy: 0.9905 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0442 - accuracy: 0.9854 - val_loss: 2.9627e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0338 - accuracy: 0.9882 - val_loss: 1.9172e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0399 - accuracy: 0.9863 - val_loss: 2.6792e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0477 - accuracy: 0.9864 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0437 - accuracy: 0.9851 - val_loss: 1.7435e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0374 - accuracy: 0.9872 - val_loss: 3.8116e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0319 - accuracy: 0.9888 - val_loss: 3.1752e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0282 - accuracy: 0.9896 - val_loss: 0.0325 - val_accuracy: 0.9920\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0456 - accuracy: 0.9858 - val_loss: 8.8847e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0408 - accuracy: 0.9876 - val_loss: 3.7357e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0257 - accuracy: 0.9917 - val_loss: 1.2612e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0663 - accuracy: 0.9779 - val_loss: 0.0276 - val_accuracy: 0.9906\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0335 - accuracy: 0.9905 - val_loss: 6.1310e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0332 - accuracy: 0.9915 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0251 - accuracy: 0.9939 - val_loss: 5.6557e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0268 - accuracy: 0.9933 - val_loss: 0.0022 - val_accuracy: 0.9987\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0529 - accuracy: 0.9842 - val_loss: 5.3515e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0384 - accuracy: 0.9882 - val_loss: 7.2463e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0277 - accuracy: 0.9918 - val_loss: 0.0019 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0261 - accuracy: 0.9917 - val_loss: 4.5716e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0286 - accuracy: 0.9930 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0347 - accuracy: 0.9900 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0281 - accuracy: 0.9915 - val_loss: 2.8158e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0245 - accuracy: 0.9924 - val_loss: 9.2427e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0304 - accuracy: 0.9891 - val_loss: 0.0016 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0238 - accuracy: 0.9927 - val_loss: 4.0844e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0395 - accuracy: 0.9887 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0851 - accuracy: 0.9759 - val_loss: 0.0174 - val_accuracy: 0.9920\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0382 - accuracy: 0.9878 - val_loss: 0.0530 - val_accuracy: 0.9839\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0314 - accuracy: 0.9894 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0204 - accuracy: 0.9931 - val_loss: 4.9908e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0311 - accuracy: 0.9921 - val_loss: 1.9130e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0267 - accuracy: 0.9912 - val_loss: 1.9943e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0233 - accuracy: 0.9931 - val_loss: 3.5938e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0222 - accuracy: 0.9927 - val_loss: 6.1000e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0309 - accuracy: 0.9911 - val_loss: 4.2647e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0289 - accuracy: 0.9909 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0332 - accuracy: 0.9903 - val_loss: 3.2556e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0266 - accuracy: 0.9914 - val_loss: 5.7555e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0268 - accuracy: 0.9923 - val_loss: 4.2067e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0170 - accuracy: 0.9954 - val_loss: 1.3629e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0289 - accuracy: 0.9899 - val_loss: 2.0969e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0292 - accuracy: 0.9908 - val_loss: 1.5810e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0168 - accuracy: 0.9943 - val_loss: 2.5866e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0171 - accuracy: 0.9940 - val_loss: 1.7677e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0326 - accuracy: 0.9912 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0234 - accuracy: 0.9937 - val_loss: 3.2861e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0213 - accuracy: 0.9940 - val_loss: 1.3032e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0213 - accuracy: 0.9936 - val_loss: 4.2319e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0269 - accuracy: 0.9920 - val_loss: 2.3718e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0293 - accuracy: 0.9911 - val_loss: 1.4235e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 9.9849e-06 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0209 - accuracy: 0.9927 - val_loss: 4.6136e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0238 - accuracy: 0.9933 - val_loss: 1.1197e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0250 - accuracy: 0.9915 - val_loss: 1.5363e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0269 - accuracy: 0.9925 - val_loss: 5.6672e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0272 - accuracy: 0.9908 - val_loss: 1.2737e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0396 - accuracy: 0.9888 - val_loss: 0.0076 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0313 - accuracy: 0.9908 - val_loss: 7.6903e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0446 - accuracy: 0.9863 - val_loss: 0.0033 - val_accuracy: 0.9987\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 60ms/step - loss: 0.0399 - accuracy: 0.9873 - val_loss: 6.5403e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0355 - accuracy: 0.9887 - val_loss: 1.0225e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0160 - accuracy: 0.9942 - val_loss: 2.0812e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0237 - accuracy: 0.9939 - val_loss: 1.6611e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0254 - accuracy: 0.9930 - val_loss: 9.2290e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0276 - accuracy: 0.9897 - val_loss: 6.0374e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0240 - accuracy: 0.9934 - val_loss: 5.0073e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0200 - accuracy: 0.9943 - val_loss: 1.2633e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 1.4425e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0195 - accuracy: 0.9948 - val_loss: 2.4103e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 1.5426e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0183 - accuracy: 0.9945 - val_loss: 1.5195e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0320 - accuracy: 0.9903 - val_loss: 0.0019 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2033 - accuracy: 0.9572 - val_loss: 0.0745 - val_accuracy: 0.9651\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1009 - accuracy: 0.9614 - val_loss: 0.0262 - val_accuracy: 0.9879\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0356 - accuracy: 0.9882 - val_loss: 8.2065e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0272 - accuracy: 0.9930 - val_loss: 9.7117e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0269 - accuracy: 0.9924 - val_loss: 8.0119e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 6.0927e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 2.0590e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0246 - accuracy: 0.9934 - val_loss: 1.9567e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0217 - accuracy: 0.9937 - val_loss: 4.1728e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0256 - accuracy: 0.9928 - val_loss: 4.9587e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0219 - accuracy: 0.9939 - val_loss: 1.5588e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0189 - accuracy: 0.9939 - val_loss: 2.7237e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 2.4262e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0144 - accuracy: 0.9960 - val_loss: 2.4510e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0273 - accuracy: 0.9921 - val_loss: 2.9296e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0277 - accuracy: 0.9911 - val_loss: 2.1801e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0141 - accuracy: 0.9967 - val_loss: 2.8507e-05 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0142 - accuracy: 0.9952 - val_loss: 1.8076e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 4.8832e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 1.3979e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0161 - accuracy: 0.9940 - val_loss: 1.2463e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0149 - accuracy: 0.9948 - val_loss: 4.0234e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 6.1950e-06 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0141 - accuracy: 0.9966 - val_loss: 4.0798e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 1.0530e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0230 - accuracy: 0.9936 - val_loss: 2.4828e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0534 - accuracy: 0.9860 - val_loss: 2.6091e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0348 - accuracy: 0.9896 - val_loss: 2.1344e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 4.5500e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0185 - accuracy: 0.9948 - val_loss: 1.2500e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0223 - accuracy: 0.9928 - val_loss: 4.9677e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0235 - accuracy: 0.9923 - val_loss: 0.0026 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0215 - accuracy: 0.9942 - val_loss: 1.7385e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0142 - accuracy: 0.9964 - val_loss: 0.0028 - val_accuracy: 0.9973\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 9.5177e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0189 - accuracy: 0.9951 - val_loss: 0.0045 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0159 - accuracy: 0.9957 - val_loss: 3.8184e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0177 - accuracy: 0.9957 - val_loss: 0.0015 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0334 - accuracy: 0.9906 - val_loss: 3.0598e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0194 - accuracy: 0.9939 - val_loss: 1.7243e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0253 - accuracy: 0.9909 - val_loss: 3.5227e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0185 - accuracy: 0.9943 - val_loss: 9.7544e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0173 - accuracy: 0.9957 - val_loss: 3.5696e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0139 - accuracy: 0.9961 - val_loss: 0.0014 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0213 - accuracy: 0.9940 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0144 - accuracy: 0.9946 - val_loss: 1.6584e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0125 - accuracy: 0.9967 - val_loss: 1.0135e-04 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 2.9883e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 7.4455e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 1.7185e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0226 - accuracy: 0.9930 - val_loss: 5.2013e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 1.9175e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0234 - accuracy: 0.9927 - val_loss: 1.6288e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0272 - accuracy: 0.9914 - val_loss: 5.7018e-06 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0119 - accuracy: 0.9969 - val_loss: 8.6879e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 1.2704e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0144 - accuracy: 0.9949 - val_loss: 3.7752e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 2.6604e-06 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 5.0899e-07 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 3.4673e-06 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0178 - accuracy: 0.9954 - val_loss: 4.7933e-06 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0180 - accuracy: 0.9954 - val_loss: 3.2349e-06 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 1.3382e-06 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0154 - accuracy: 0.9949 - val_loss: 1.0037e-06 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0189 - accuracy: 0.9931 - val_loss: 1.4382e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 7.3056e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0151 - accuracy: 0.9957 - val_loss: 6.7943e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0191 - accuracy: 0.9940 - val_loss: 5.3390e-06 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0210 - accuracy: 0.9936 - val_loss: 6.0151e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0193 - accuracy: 0.9937 - val_loss: 7.8939e-06 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0147 - accuracy: 0.9961 - val_loss: 3.6715e-06 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0366 - accuracy: 0.9891 - val_loss: 2.7245e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0209 - accuracy: 0.9936 - val_loss: 3.2055e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0106 - accuracy: 0.9960 - val_loss: 8.7850e-06 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0157 - accuracy: 0.9957 - val_loss: 4.0524e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 1.8519e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0177 - accuracy: 0.9934 - val_loss: 7.6956e-04 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0163 - accuracy: 0.9952 - val_loss: 1.0273e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0152 - accuracy: 0.9960 - val_loss: 1.3374e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0150 - accuracy: 0.9948 - val_loss: 1.5180e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0193 - accuracy: 0.9943 - val_loss: 4.2703e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0537 - accuracy: 0.9847 - val_loss: 3.3194e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 1.9786e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0346 - accuracy: 0.9894 - val_loss: 1.9456e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0202 - accuracy: 0.9954 - val_loss: 6.8907e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 1.8055e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0194 - accuracy: 0.9946 - val_loss: 2.9056e-06 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0187 - accuracy: 0.9948 - val_loss: 4.1036e-06 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0196 - accuracy: 0.9943 - val_loss: 3.9348e-06 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 2.5074e-06 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 1.7690e-06 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 6.2110e-06 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 61ms/step - loss: 0.0194 - accuracy: 0.9948 - val_loss: 5.8869e-06 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 4.2557e-06 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0142 - accuracy: 0.9952 - val_loss: 1.6604e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0190 - accuracy: 0.9936 - val_loss: 1.2243e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0297 - accuracy: 0.9933 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0280 - accuracy: 0.9927 - val_loss: 4.1635e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 9.3948e-06 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 4.7077e-06 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0146 - accuracy: 0.9945 - val_loss: 2.6869e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0247 - accuracy: 0.9911 - val_loss: 8.1856e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0198 - accuracy: 0.9928 - val_loss: 2.4295e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0168 - accuracy: 0.9955 - val_loss: 1.2600e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 5.7673e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 3.2324e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 4.9186e-06 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "CAnc2SJa3o9f",
        "outputId": "e1379ca6-1dfe-46cc-abfe-b31c0ceb4e0e"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 8ms/step - loss: 0.0240 - accuracy: 0.9930\n",
            "Accuracy  : 0.9930257797241211\n",
            "F1_Score  : 0.9924250958322446\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7fcxLuwZpkK",
        "outputId": "6c82b7f2-1358-4d95-8383-4a21f26e791b"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "8d3b3265-05ec-4ecb-a90f-25268f0838e7"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 5s 63ms/step - loss: 1.0795 - accuracy: 0.5192 - val_loss: 0.9667 - val_accuracy: 0.5737\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9871 - accuracy: 0.5573 - val_loss: 0.9597 - val_accuracy: 0.5737\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9510 - accuracy: 0.5718 - val_loss: 0.9194 - val_accuracy: 0.5737\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9464 - accuracy: 0.5652 - val_loss: 0.9095 - val_accuracy: 0.5737\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9412 - accuracy: 0.5630 - val_loss: 0.9104 - val_accuracy: 0.5737\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9152 - accuracy: 0.5797 - val_loss: 0.9043 - val_accuracy: 0.5737\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9219 - accuracy: 0.5683 - val_loss: 0.9270 - val_accuracy: 0.5737\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9239 - accuracy: 0.5762 - val_loss: 0.8906 - val_accuracy: 0.5737\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9025 - accuracy: 0.5695 - val_loss: 0.9417 - val_accuracy: 0.5737\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8909 - accuracy: 0.5838 - val_loss: 1.0029 - val_accuracy: 0.5737\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8964 - accuracy: 0.5737 - val_loss: 0.8734 - val_accuracy: 0.5777\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8891 - accuracy: 0.5740 - val_loss: 0.8915 - val_accuracy: 0.5818\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8865 - accuracy: 0.5807 - val_loss: 0.8825 - val_accuracy: 0.5724\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8783 - accuracy: 0.5801 - val_loss: 0.9449 - val_accuracy: 0.5804\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8614 - accuracy: 0.5893 - val_loss: 0.9140 - val_accuracy: 0.5818\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8696 - accuracy: 0.5874 - val_loss: 0.8492 - val_accuracy: 0.5912\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8671 - accuracy: 0.5892 - val_loss: 0.8765 - val_accuracy: 0.5885\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8515 - accuracy: 0.5941 - val_loss: 0.8389 - val_accuracy: 0.6059\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8570 - accuracy: 0.5938 - val_loss: 0.8556 - val_accuracy: 0.5831\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8492 - accuracy: 0.5945 - val_loss: 0.8293 - val_accuracy: 0.5965\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8335 - accuracy: 0.5999 - val_loss: 0.8087 - val_accuracy: 0.6005\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8178 - accuracy: 0.6157 - val_loss: 0.8222 - val_accuracy: 0.6193\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8064 - accuracy: 0.6219 - val_loss: 0.7931 - val_accuracy: 0.6273\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8078 - accuracy: 0.6139 - val_loss: 0.7850 - val_accuracy: 0.6340\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7999 - accuracy: 0.6170 - val_loss: 0.8022 - val_accuracy: 0.6059\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7980 - accuracy: 0.6261 - val_loss: 0.7752 - val_accuracy: 0.6233\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7822 - accuracy: 0.6316 - val_loss: 0.7563 - val_accuracy: 0.6340\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.7857 - accuracy: 0.6245 - val_loss: 0.7933 - val_accuracy: 0.6300\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7716 - accuracy: 0.6164 - val_loss: 0.7501 - val_accuracy: 0.6287\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7379 - accuracy: 0.6558 - val_loss: 0.7641 - val_accuracy: 0.6300\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.7358 - accuracy: 0.6481 - val_loss: 0.7717 - val_accuracy: 0.6555\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7312 - accuracy: 0.6580 - val_loss: 0.7382 - val_accuracy: 0.6756\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7043 - accuracy: 0.6581 - val_loss: 0.7123 - val_accuracy: 0.7078\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.6937 - accuracy: 0.6754 - val_loss: 0.7518 - val_accuracy: 0.6528\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.6935 - accuracy: 0.6692 - val_loss: 0.7187 - val_accuracy: 0.6823\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.6767 - accuracy: 0.6845 - val_loss: 0.7702 - val_accuracy: 0.6475\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.6615 - accuracy: 0.6933 - val_loss: 0.6908 - val_accuracy: 0.6944\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.6555 - accuracy: 0.7007 - val_loss: 0.6698 - val_accuracy: 0.7064\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.6114 - accuracy: 0.7198 - val_loss: 0.6567 - val_accuracy: 0.7051\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.6041 - accuracy: 0.7255 - val_loss: 0.6258 - val_accuracy: 0.7319\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.5862 - accuracy: 0.7382 - val_loss: 0.6892 - val_accuracy: 0.6850\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.5613 - accuracy: 0.7450 - val_loss: 0.6269 - val_accuracy: 0.7440\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.5272 - accuracy: 0.7671 - val_loss: 0.6052 - val_accuracy: 0.7480\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.5198 - accuracy: 0.7748 - val_loss: 0.6036 - val_accuracy: 0.7399\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.4982 - accuracy: 0.7902 - val_loss: 0.5963 - val_accuracy: 0.7480\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.4671 - accuracy: 0.8052 - val_loss: 0.6197 - val_accuracy: 0.7158\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.4560 - accuracy: 0.8070 - val_loss: 0.6114 - val_accuracy: 0.7185\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.4296 - accuracy: 0.8225 - val_loss: 0.6227 - val_accuracy: 0.7426\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.3925 - accuracy: 0.8399 - val_loss: 0.5033 - val_accuracy: 0.7735\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.3667 - accuracy: 0.8522 - val_loss: 0.4711 - val_accuracy: 0.8123\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.3854 - accuracy: 0.8438 - val_loss: 0.4870 - val_accuracy: 0.8003\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.3301 - accuracy: 0.8675 - val_loss: 0.4443 - val_accuracy: 0.8097\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.3153 - accuracy: 0.8781 - val_loss: 0.5786 - val_accuracy: 0.7534\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.2947 - accuracy: 0.8903 - val_loss: 0.4179 - val_accuracy: 0.8432\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.2849 - accuracy: 0.8967 - val_loss: 0.3587 - val_accuracy: 0.8485\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.2529 - accuracy: 0.9034 - val_loss: 0.3734 - val_accuracy: 0.8539\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2349 - accuracy: 0.9103 - val_loss: 0.3795 - val_accuracy: 0.8633\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.2113 - accuracy: 0.9232 - val_loss: 0.4063 - val_accuracy: 0.8552\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.2380 - accuracy: 0.9106 - val_loss: 0.2617 - val_accuracy: 0.9115\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.2682 - accuracy: 0.9061 - val_loss: 0.3401 - val_accuracy: 0.8820\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2267 - accuracy: 0.9180 - val_loss: 0.0609 - val_accuracy: 0.9933\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1992 - accuracy: 0.9294 - val_loss: 0.0543 - val_accuracy: 0.9960\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1913 - accuracy: 0.9334 - val_loss: 0.0584 - val_accuracy: 0.9772\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1672 - accuracy: 0.9434 - val_loss: 0.0360 - val_accuracy: 0.9933\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1870 - accuracy: 0.9364 - val_loss: 0.0778 - val_accuracy: 0.9705\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1502 - accuracy: 0.9504 - val_loss: 0.0441 - val_accuracy: 0.9906\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1911 - accuracy: 0.9334 - val_loss: 0.0813 - val_accuracy: 0.9611\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.1424 - accuracy: 0.9496 - val_loss: 0.0649 - val_accuracy: 0.9812\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1519 - accuracy: 0.9501 - val_loss: 0.4365 - val_accuracy: 0.8217\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1615 - accuracy: 0.9450 - val_loss: 0.0571 - val_accuracy: 0.9772\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1359 - accuracy: 0.9550 - val_loss: 0.1030 - val_accuracy: 0.9598\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1339 - accuracy: 0.9566 - val_loss: 0.0319 - val_accuracy: 0.9933\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1212 - accuracy: 0.9586 - val_loss: 0.0542 - val_accuracy: 0.9839\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1315 - accuracy: 0.9563 - val_loss: 0.0683 - val_accuracy: 0.9759\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1226 - accuracy: 0.9584 - val_loss: 0.0319 - val_accuracy: 0.9893\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1037 - accuracy: 0.9648 - val_loss: 0.0324 - val_accuracy: 0.9893\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1042 - accuracy: 0.9660 - val_loss: 0.0979 - val_accuracy: 0.9558\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1026 - accuracy: 0.9669 - val_loss: 0.0686 - val_accuracy: 0.9759\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0927 - accuracy: 0.9687 - val_loss: 0.0773 - val_accuracy: 0.9745\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0805 - accuracy: 0.9757 - val_loss: 0.0320 - val_accuracy: 0.9906\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1068 - accuracy: 0.9641 - val_loss: 0.0430 - val_accuracy: 0.9826\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0801 - accuracy: 0.9715 - val_loss: 0.0739 - val_accuracy: 0.9678\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0859 - accuracy: 0.9711 - val_loss: 0.0170 - val_accuracy: 0.9933\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0708 - accuracy: 0.9778 - val_loss: 0.0600 - val_accuracy: 0.9786\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0791 - accuracy: 0.9739 - val_loss: 0.0281 - val_accuracy: 0.9893\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0745 - accuracy: 0.9765 - val_loss: 0.0268 - val_accuracy: 0.9920\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0803 - accuracy: 0.9738 - val_loss: 0.0381 - val_accuracy: 0.9920\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1449 - accuracy: 0.9547 - val_loss: 0.0684 - val_accuracy: 0.9826\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0897 - accuracy: 0.9714 - val_loss: 0.0705 - val_accuracy: 0.9799\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0631 - accuracy: 0.9793 - val_loss: 0.0315 - val_accuracy: 0.9893\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0813 - accuracy: 0.9759 - val_loss: 0.0144 - val_accuracy: 0.9946\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0697 - accuracy: 0.9797 - val_loss: 0.0038 - val_accuracy: 0.9987\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0624 - accuracy: 0.9800 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0660 - accuracy: 0.9791 - val_loss: 0.0062 - val_accuracy: 0.9987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0603 - accuracy: 0.9815 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0748 - accuracy: 0.9765 - val_loss: 0.0168 - val_accuracy: 0.9973\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0806 - accuracy: 0.9760 - val_loss: 0.0281 - val_accuracy: 0.9893\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0756 - accuracy: 0.9744 - val_loss: 0.0375 - val_accuracy: 0.9879\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0752 - accuracy: 0.9751 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0584 - accuracy: 0.9817 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0578 - accuracy: 0.9814 - val_loss: 0.0033 - val_accuracy: 0.9987\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0676 - accuracy: 0.9776 - val_loss: 0.0554 - val_accuracy: 0.9812\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0821 - accuracy: 0.9730 - val_loss: 0.0155 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 60ms/step - loss: 0.0492 - accuracy: 0.9854 - val_loss: 0.0030 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0671 - accuracy: 0.9808 - val_loss: 0.0023 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0738 - accuracy: 0.9733 - val_loss: 0.0060 - val_accuracy: 0.9987\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0607 - accuracy: 0.9823 - val_loss: 0.0096 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0601 - accuracy: 0.9817 - val_loss: 0.0063 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0470 - accuracy: 0.9852 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0481 - accuracy: 0.9858 - val_loss: 0.0023 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0522 - accuracy: 0.9833 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0636 - accuracy: 0.9800 - val_loss: 0.0103 - val_accuracy: 0.9960\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0490 - accuracy: 0.9861 - val_loss: 0.0165 - val_accuracy: 0.9933\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0406 - accuracy: 0.9891 - val_loss: 0.0064 - val_accuracy: 0.9973\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0615 - accuracy: 0.9800 - val_loss: 0.0317 - val_accuracy: 0.9906\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0439 - accuracy: 0.9851 - val_loss: 0.0032 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0549 - accuracy: 0.9841 - val_loss: 0.0041 - val_accuracy: 0.9973\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.0417 - accuracy: 0.9881 - val_loss: 0.0303 - val_accuracy: 0.9920\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0400 - accuracy: 0.9887 - val_loss: 0.0110 - val_accuracy: 0.9960\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0531 - accuracy: 0.9841 - val_loss: 0.0070 - val_accuracy: 0.9960\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0497 - accuracy: 0.9844 - val_loss: 4.8291e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0451 - accuracy: 0.9855 - val_loss: 2.2450e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0410 - accuracy: 0.9858 - val_loss: 9.4391e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0421 - accuracy: 0.9863 - val_loss: 0.0031 - val_accuracy: 0.9987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0420 - accuracy: 0.9864 - val_loss: 9.9602e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0421 - accuracy: 0.9866 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0492 - accuracy: 0.9838 - val_loss: 0.0078 - val_accuracy: 0.9973\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0611 - accuracy: 0.9815 - val_loss: 0.0053 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0535 - accuracy: 0.9839 - val_loss: 4.9529e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0355 - accuracy: 0.9899 - val_loss: 4.3744e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0336 - accuracy: 0.9899 - val_loss: 4.3995e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0372 - accuracy: 0.9866 - val_loss: 9.1285e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0340 - accuracy: 0.9909 - val_loss: 0.0059 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0474 - accuracy: 0.9852 - val_loss: 5.9754e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0492 - accuracy: 0.9842 - val_loss: 0.0772 - val_accuracy: 0.9705\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0366 - accuracy: 0.9888 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0386 - accuracy: 0.9885 - val_loss: 5.8941e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0356 - accuracy: 0.9879 - val_loss: 4.5412e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0349 - accuracy: 0.9890 - val_loss: 5.4475e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0324 - accuracy: 0.9890 - val_loss: 8.8354e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0392 - accuracy: 0.9872 - val_loss: 0.0071 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0350 - accuracy: 0.9878 - val_loss: 1.9789e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0416 - accuracy: 0.9878 - val_loss: 0.0050 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0371 - accuracy: 0.9882 - val_loss: 0.0114 - val_accuracy: 0.9946\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0334 - accuracy: 0.9905 - val_loss: 0.0058 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0366 - accuracy: 0.9894 - val_loss: 0.0169 - val_accuracy: 0.9960\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0194 - accuracy: 0.9945 - val_loss: 0.0038 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0355 - accuracy: 0.9891 - val_loss: 0.0059 - val_accuracy: 0.9973\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0355 - accuracy: 0.9893 - val_loss: 0.0244 - val_accuracy: 0.9933\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0349 - accuracy: 0.9896 - val_loss: 0.0032 - val_accuracy: 0.9987\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0364 - accuracy: 0.9891 - val_loss: 1.1496e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0275 - accuracy: 0.9900 - val_loss: 1.8442e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0409 - accuracy: 0.9873 - val_loss: 1.2600e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0315 - accuracy: 0.9909 - val_loss: 0.0027 - val_accuracy: 0.9987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0237 - accuracy: 0.9923 - val_loss: 2.1783e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0449 - accuracy: 0.9864 - val_loss: 8.3253e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0241 - accuracy: 0.9918 - val_loss: 7.8206e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0331 - accuracy: 0.9899 - val_loss: 1.1592e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0459 - accuracy: 0.9863 - val_loss: 7.9033e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0387 - accuracy: 0.9888 - val_loss: 6.2175e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0299 - accuracy: 0.9918 - val_loss: 0.0012 - val_accuracy: 0.9987\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0290 - accuracy: 0.9923 - val_loss: 1.2762e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0326 - accuracy: 0.9900 - val_loss: 0.0113 - val_accuracy: 0.9960\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0339 - accuracy: 0.9909 - val_loss: 6.3605e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0280 - accuracy: 0.9900 - val_loss: 4.2424e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0219 - accuracy: 0.9936 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0234 - accuracy: 0.9933 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0249 - accuracy: 0.9909 - val_loss: 1.2179e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0403 - accuracy: 0.9867 - val_loss: 2.1000e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0472 - accuracy: 0.9873 - val_loss: 9.6088e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0339 - accuracy: 0.9903 - val_loss: 5.5868e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0266 - accuracy: 0.9936 - val_loss: 1.2594e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0225 - accuracy: 0.9943 - val_loss: 9.8835e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0301 - accuracy: 0.9896 - val_loss: 5.5031e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.0276 - accuracy: 0.9914 - val_loss: 0.0069 - val_accuracy: 0.9973\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0434 - accuracy: 0.9869 - val_loss: 7.8394e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0377 - accuracy: 0.9900 - val_loss: 3.5973e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0304 - accuracy: 0.9896 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0191 - accuracy: 0.9951 - val_loss: 2.1864e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0237 - accuracy: 0.9928 - val_loss: 0.0055 - val_accuracy: 0.9987\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0262 - accuracy: 0.9900 - val_loss: 1.4288e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0225 - accuracy: 0.9912 - val_loss: 3.2121e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0281 - accuracy: 0.9921 - val_loss: 3.0406e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0322 - accuracy: 0.9884 - val_loss: 4.5093e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0225 - accuracy: 0.9921 - val_loss: 1.3621e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0232 - accuracy: 0.9936 - val_loss: 6.6810e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0237 - accuracy: 0.9934 - val_loss: 4.2421e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0321 - accuracy: 0.9906 - val_loss: 5.1562e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0343 - accuracy: 0.9885 - val_loss: 1.1060e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0271 - accuracy: 0.9917 - val_loss: 0.0014 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0195 - accuracy: 0.9928 - val_loss: 2.7496e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0258 - accuracy: 0.9915 - val_loss: 3.6210e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0333 - accuracy: 0.9891 - val_loss: 2.8074e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0236 - accuracy: 0.9936 - val_loss: 4.6558e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0275 - accuracy: 0.9924 - val_loss: 3.5178e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0376 - accuracy: 0.9893 - val_loss: 0.0014 - val_accuracy: 0.9987\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0242 - accuracy: 0.9942 - val_loss: 6.1636e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0322 - accuracy: 0.9917 - val_loss: 0.0079 - val_accuracy: 0.9973\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0237 - accuracy: 0.9917 - val_loss: 9.1000e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0409 - accuracy: 0.9873 - val_loss: 0.0087 - val_accuracy: 0.9973\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0229 - accuracy: 0.9924 - val_loss: 8.1894e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0267 - accuracy: 0.9924 - val_loss: 0.0070 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0221 - accuracy: 0.9928 - val_loss: 0.0209 - val_accuracy: 0.9960\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0156 - accuracy: 0.9957 - val_loss: 1.3671e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0197 - accuracy: 0.9942 - val_loss: 0.0094 - val_accuracy: 0.9973\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0285 - accuracy: 0.9914 - val_loss: 3.5898e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0213 - accuracy: 0.9933 - val_loss: 0.0062 - val_accuracy: 0.9960\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0291 - accuracy: 0.9923 - val_loss: 0.0058 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0302 - accuracy: 0.9906 - val_loss: 0.0015 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.1236 - accuracy: 0.9715 - val_loss: 0.0236 - val_accuracy: 0.9919\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0389 - accuracy: 0.9888 - val_loss: 1.4168e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0219 - accuracy: 0.9918 - val_loss: 6.8290e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0243 - accuracy: 0.9912 - val_loss: 7.7881e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0321 - accuracy: 0.9900 - val_loss: 2.7126e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0182 - accuracy: 0.9945 - val_loss: 3.2776e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0219 - accuracy: 0.9943 - val_loss: 0.0056 - val_accuracy: 0.9987\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0229 - accuracy: 0.9942 - val_loss: 7.0782e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0269 - accuracy: 0.9918 - val_loss: 3.9502e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0211 - accuracy: 0.9939 - val_loss: 1.1420e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0200 - accuracy: 0.9933 - val_loss: 6.1112e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0198 - accuracy: 0.9957 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 1.7518e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0268 - accuracy: 0.9915 - val_loss: 1.8748e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 2.2559e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 1.4442e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0164 - accuracy: 0.9955 - val_loss: 1.2585e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0217 - accuracy: 0.9936 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0192 - accuracy: 0.9934 - val_loss: 2.3944e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0209 - accuracy: 0.9940 - val_loss: 4.2707e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0243 - accuracy: 0.9927 - val_loss: 1.3075e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0241 - accuracy: 0.9934 - val_loss: 0.0012 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0158 - accuracy: 0.9948 - val_loss: 9.7426e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0304 - accuracy: 0.9909 - val_loss: 0.0042 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0195 - accuracy: 0.9942 - val_loss: 1.7719e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0166 - accuracy: 0.9952 - val_loss: 1.6051e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0284 - accuracy: 0.9918 - val_loss: 5.9342e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0296 - accuracy: 0.9933 - val_loss: 1.8494e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0162 - accuracy: 0.9948 - val_loss: 8.8942e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0174 - accuracy: 0.9948 - val_loss: 3.6977e-04 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0206 - accuracy: 0.9931 - val_loss: 2.6863e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0249 - accuracy: 0.9921 - val_loss: 4.3596e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0234 - accuracy: 0.9931 - val_loss: 2.4420e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0225 - accuracy: 0.9934 - val_loss: 1.1211e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 1.7670e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 1.1584e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0504 - accuracy: 0.9858 - val_loss: 3.3718e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0386 - accuracy: 0.9878 - val_loss: 0.0096 - val_accuracy: 0.9973\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0149 - accuracy: 0.9952 - val_loss: 2.8531e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0168 - accuracy: 0.9946 - val_loss: 2.7623e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0185 - accuracy: 0.9946 - val_loss: 1.6343e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0195 - accuracy: 0.9934 - val_loss: 7.1202e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0245 - accuracy: 0.9928 - val_loss: 0.0020 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 2.1576e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 2.0650e-06 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 6.8932e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.0024 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0160 - accuracy: 0.9952 - val_loss: 1.6689e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 2.7982e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0168 - accuracy: 0.9958 - val_loss: 0.0025 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0149 - accuracy: 0.9958 - val_loss: 6.5535e-06 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 1.0374e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0498 - accuracy: 0.9876 - val_loss: 2.0189e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0263 - accuracy: 0.9921 - val_loss: 4.3590e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 1.4758e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 1.1569e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0212 - accuracy: 0.9931 - val_loss: 2.8565e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 6.1936e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 1.9375e-05 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0255 - accuracy: 0.9918 - val_loss: 2.8400e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0243 - accuracy: 0.9930 - val_loss: 4.7620e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 60ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 1.5294e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0236 - accuracy: 0.9918 - val_loss: 5.5341e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0206 - accuracy: 0.9934 - val_loss: 2.8890e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0224 - accuracy: 0.9937 - val_loss: 8.3814e-06 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0160 - accuracy: 0.9952 - val_loss: 7.4896e-06 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0215 - accuracy: 0.9925 - val_loss: 8.8095e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0235 - accuracy: 0.9923 - val_loss: 1.9029e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0243 - accuracy: 0.9925 - val_loss: 1.8743e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0346 - accuracy: 0.9894 - val_loss: 6.0354e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0161 - accuracy: 0.9954 - val_loss: 3.2541e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0193 - accuracy: 0.9949 - val_loss: 2.0522e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 3.1854e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 1.0910e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 8.0652e-06 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0228 - accuracy: 0.9927 - val_loss: 2.3004e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0305 - accuracy: 0.9900 - val_loss: 6.6209e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 2.8617e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0154 - accuracy: 0.9955 - val_loss: 6.1377e-06 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0126 - accuracy: 0.9960 - val_loss: 2.4958e-06 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0195 - accuracy: 0.9942 - val_loss: 6.0324e-06 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0220 - accuracy: 0.9933 - val_loss: 3.8065e-06 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0179 - accuracy: 0.9946 - val_loss: 6.2335e-06 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0163 - accuracy: 0.9943 - val_loss: 0.0024 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0171 - accuracy: 0.9952 - val_loss: 5.7012e-06 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 4.2652e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0191 - accuracy: 0.9931 - val_loss: 2.5593e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 4.0228e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 1.7032e-06 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "299676c6-6558-46e4-cb4b-dac5997aa90e"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 8ms/step - loss: 0.0305 - accuracy: 0.9925\n",
            "Accuracy  : 0.9924892783164978\n",
            "F1_Score  : 0.9915196303154868\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4e178bd9-9fad-4dea-c3b3-1e64f986f44c"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'#dominance\\nX_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\\nprint(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "d9bc4a83-c510-4395-e903-d1a6683ebf4c"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'foldNum=0\\nmodel = get_model()\\nfor train_index, val_index in kfold.split(X_train, Y_train):\\n  foldNum = foldNum + 1\\n  print(\"Results for fold\",foldNum)\\n  x_train, x_val = X_train[train_index], X_train[val_index]\\n  y_train, y_val = Y_train[train_index], Y_train[val_index]\\n  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\\n  gc.collect() # Garbage collecter\\n  del x_train, x_val, y_train, y_val\\n  gc.collect()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "63c0dd22-1b32-4829-a42a-0d1346eb3d27"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'acrc = model.evaluate(x_test, y_test)\\npred = model.predict(x_test)\\nf1scr = f1_score(y_test.argmax(1), pred.argmax(1), average=\\'macro\\')\\nc_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\\nprint(\"Accuracy  : {}\".format(acrc[1]))\\nprint(\"F1_Score  : {}\".format(f1scr))\\nc_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\\nimport seaborn as sns\\nfigure = plt.figure(figsize=(9, 9))\\nsns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\\nplt.tight_layout()\\nplt.ylabel(\\'True label\\')\\nplt.xlabel(\\'Predicted label\\')\\nplt.show()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}