{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub17_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "d68a489a-ec55-47fc-cff1-35c935a6f202"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e3\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  #EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "76721d9f-7854-4325-9111-f782cc144246"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(17,18):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.17\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (2097,) (3495,) (3728,)\n",
            "(9320,) (2330,) (4194,) (2796,)\n",
            "(9320,) (0,) (9087,) (233,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "3b58d8df-1f6d-4b9b-a702-f6abd0647c9f"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "ae9f829b-1cc6-4a4b-ab95-2c0bb2a3384a"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "622"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "187d5b23-58bf-46d4-971c-a959cef3b21f"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fca1b7b2-628b-4693-ac20-183fc13fca58"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 51s 61ms/step - loss: 1.2404 - accuracy: 0.3736 - val_loss: 1.0799 - val_accuracy: 0.3807\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0746 - accuracy: 0.4044 - val_loss: 1.0733 - val_accuracy: 0.3820\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0709 - accuracy: 0.4118 - val_loss: 1.0739 - val_accuracy: 0.3834\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0744 - accuracy: 0.4119 - val_loss: 1.0719 - val_accuracy: 0.4129\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0745 - accuracy: 0.4194 - val_loss: 1.0717 - val_accuracy: 0.4102\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0670 - accuracy: 0.4155 - val_loss: 1.0715 - val_accuracy: 0.4129\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0702 - accuracy: 0.4181 - val_loss: 1.0715 - val_accuracy: 0.4115\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0661 - accuracy: 0.4074 - val_loss: 1.0729 - val_accuracy: 0.4115\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0681 - accuracy: 0.4130 - val_loss: 1.0713 - val_accuracy: 0.4115\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0606 - accuracy: 0.4208 - val_loss: 1.0728 - val_accuracy: 0.4129\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0665 - accuracy: 0.4218 - val_loss: 1.0711 - val_accuracy: 0.4115\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0618 - accuracy: 0.4311 - val_loss: 1.0704 - val_accuracy: 0.4115\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0616 - accuracy: 0.4252 - val_loss: 1.0709 - val_accuracy: 0.4102\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0659 - accuracy: 0.4204 - val_loss: 1.0701 - val_accuracy: 0.4142\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0612 - accuracy: 0.4199 - val_loss: 1.0697 - val_accuracy: 0.4088\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0627 - accuracy: 0.4236 - val_loss: 1.0710 - val_accuracy: 0.4048\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0634 - accuracy: 0.4218 - val_loss: 1.0706 - val_accuracy: 0.4129\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0619 - accuracy: 0.4189 - val_loss: 1.0707 - val_accuracy: 0.4075\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0632 - accuracy: 0.4157 - val_loss: 1.0699 - val_accuracy: 0.4115\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0636 - accuracy: 0.4185 - val_loss: 1.0698 - val_accuracy: 0.4129\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0611 - accuracy: 0.4278 - val_loss: 1.0695 - val_accuracy: 0.4129\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0609 - accuracy: 0.4233 - val_loss: 1.0692 - val_accuracy: 0.4048\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0649 - accuracy: 0.4225 - val_loss: 1.0695 - val_accuracy: 0.4102\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0572 - accuracy: 0.4329 - val_loss: 1.0695 - val_accuracy: 0.4102\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0603 - accuracy: 0.4176 - val_loss: 1.0692 - val_accuracy: 0.4129\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0590 - accuracy: 0.4307 - val_loss: 1.0708 - val_accuracy: 0.4075\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0604 - accuracy: 0.4136 - val_loss: 1.0717 - val_accuracy: 0.4115\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0600 - accuracy: 0.4220 - val_loss: 1.0699 - val_accuracy: 0.4075\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0532 - accuracy: 0.4296 - val_loss: 1.0704 - val_accuracy: 0.4102\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0577 - accuracy: 0.4226 - val_loss: 1.0715 - val_accuracy: 0.4008\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 1.0621 - accuracy: 0.4230 - val_loss: 1.0494 - val_accuracy: 0.4370\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0626 - accuracy: 0.4230 - val_loss: 1.0510 - val_accuracy: 0.4209\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0616 - accuracy: 0.4201 - val_loss: 1.0506 - val_accuracy: 0.4249\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0611 - accuracy: 0.4210 - val_loss: 1.0492 - val_accuracy: 0.4357\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0616 - accuracy: 0.4201 - val_loss: 1.0536 - val_accuracy: 0.4155\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0627 - accuracy: 0.4183 - val_loss: 1.0551 - val_accuracy: 0.4155\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0628 - accuracy: 0.4207 - val_loss: 1.0618 - val_accuracy: 0.3901\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0626 - accuracy: 0.4159 - val_loss: 1.0498 - val_accuracy: 0.4276\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0617 - accuracy: 0.4183 - val_loss: 1.0541 - val_accuracy: 0.4196\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0606 - accuracy: 0.4224 - val_loss: 1.0497 - val_accuracy: 0.4303\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0608 - accuracy: 0.4206 - val_loss: 1.0671 - val_accuracy: 0.4196\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0623 - accuracy: 0.4174 - val_loss: 1.0554 - val_accuracy: 0.4142\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0597 - accuracy: 0.4210 - val_loss: 1.0491 - val_accuracy: 0.4236\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0601 - accuracy: 0.4174 - val_loss: 1.0477 - val_accuracy: 0.4343\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0608 - accuracy: 0.4174 - val_loss: 1.0550 - val_accuracy: 0.4236\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0611 - accuracy: 0.4232 - val_loss: 1.0570 - val_accuracy: 0.4142\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0615 - accuracy: 0.4189 - val_loss: 1.0517 - val_accuracy: 0.4290\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0598 - accuracy: 0.4174 - val_loss: 1.0567 - val_accuracy: 0.4088\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0591 - accuracy: 0.4170 - val_loss: 1.0519 - val_accuracy: 0.4223\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0590 - accuracy: 0.4154 - val_loss: 1.0561 - val_accuracy: 0.4249\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0611 - accuracy: 0.4195 - val_loss: 1.0508 - val_accuracy: 0.4370\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0586 - accuracy: 0.4213 - val_loss: 1.0657 - val_accuracy: 0.4021\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0581 - accuracy: 0.4216 - val_loss: 1.0498 - val_accuracy: 0.4370\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0584 - accuracy: 0.4232 - val_loss: 1.0489 - val_accuracy: 0.4424\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0603 - accuracy: 0.4165 - val_loss: 1.0514 - val_accuracy: 0.4249\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0590 - accuracy: 0.4213 - val_loss: 1.0590 - val_accuracy: 0.4008\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0604 - accuracy: 0.4201 - val_loss: 1.0470 - val_accuracy: 0.4397\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0566 - accuracy: 0.4186 - val_loss: 1.0828 - val_accuracy: 0.4062\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0597 - accuracy: 0.4244 - val_loss: 1.0544 - val_accuracy: 0.4169\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0606 - accuracy: 0.4170 - val_loss: 1.0588 - val_accuracy: 0.4088\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 1.0554 - accuracy: 0.4215 - val_loss: 1.0568 - val_accuracy: 0.4196\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0550 - accuracy: 0.4279 - val_loss: 1.0792 - val_accuracy: 0.4517\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0595 - accuracy: 0.4255 - val_loss: 1.0571 - val_accuracy: 0.4249\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0554 - accuracy: 0.4206 - val_loss: 1.0644 - val_accuracy: 0.4343\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0516 - accuracy: 0.4289 - val_loss: 1.0670 - val_accuracy: 0.4290\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0517 - accuracy: 0.4311 - val_loss: 1.0508 - val_accuracy: 0.4330\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0531 - accuracy: 0.4341 - val_loss: 1.0517 - val_accuracy: 0.4343\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0519 - accuracy: 0.4288 - val_loss: 1.0508 - val_accuracy: 0.4249\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0497 - accuracy: 0.4310 - val_loss: 1.0575 - val_accuracy: 0.4115\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0543 - accuracy: 0.4218 - val_loss: 1.0695 - val_accuracy: 0.4316\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0572 - accuracy: 0.4241 - val_loss: 1.0542 - val_accuracy: 0.4290\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 1.0525 - accuracy: 0.4317 - val_loss: 1.0617 - val_accuracy: 0.4102\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0521 - accuracy: 0.4337 - val_loss: 1.0732 - val_accuracy: 0.4236\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0499 - accuracy: 0.4346 - val_loss: 1.0666 - val_accuracy: 0.4410\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0492 - accuracy: 0.4267 - val_loss: 1.0524 - val_accuracy: 0.4182\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0490 - accuracy: 0.4322 - val_loss: 1.0505 - val_accuracy: 0.4611\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0471 - accuracy: 0.4335 - val_loss: 1.0543 - val_accuracy: 0.4437\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0459 - accuracy: 0.4341 - val_loss: 1.0541 - val_accuracy: 0.4236\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0473 - accuracy: 0.4353 - val_loss: 1.0434 - val_accuracy: 0.4410\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0401 - accuracy: 0.4465 - val_loss: 1.0412 - val_accuracy: 0.4517\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0392 - accuracy: 0.4478 - val_loss: 1.0445 - val_accuracy: 0.4410\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 1.0415 - accuracy: 0.4422 - val_loss: 1.0405 - val_accuracy: 0.4491\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0373 - accuracy: 0.4456 - val_loss: 1.0577 - val_accuracy: 0.4450\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0309 - accuracy: 0.4554 - val_loss: 1.0826 - val_accuracy: 0.4504\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0334 - accuracy: 0.4502 - val_loss: 1.0295 - val_accuracy: 0.4625\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0309 - accuracy: 0.4539 - val_loss: 1.0596 - val_accuracy: 0.4410\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0269 - accuracy: 0.4593 - val_loss: 1.0282 - val_accuracy: 0.4946\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0234 - accuracy: 0.4617 - val_loss: 1.0268 - val_accuracy: 0.4718\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0152 - accuracy: 0.4678 - val_loss: 1.0558 - val_accuracy: 0.4464\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0147 - accuracy: 0.4823 - val_loss: 1.0396 - val_accuracy: 0.4759\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0178 - accuracy: 0.4727 - val_loss: 1.0170 - val_accuracy: 0.4946\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0157 - accuracy: 0.4705 - val_loss: 0.9721 - val_accuracy: 0.5282\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0137 - accuracy: 0.4744 - val_loss: 0.9964 - val_accuracy: 0.4946\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9979 - accuracy: 0.4957 - val_loss: 0.9761 - val_accuracy: 0.5080\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0024 - accuracy: 0.4808 - val_loss: 0.9834 - val_accuracy: 0.5054\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9957 - accuracy: 0.4896 - val_loss: 0.9719 - val_accuracy: 0.5161\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9819 - accuracy: 0.5015 - val_loss: 0.9447 - val_accuracy: 0.5389\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9778 - accuracy: 0.5075 - val_loss: 0.9917 - val_accuracy: 0.5107\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9752 - accuracy: 0.5069 - val_loss: 1.0069 - val_accuracy: 0.5054\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9677 - accuracy: 0.5109 - val_loss: 0.9304 - val_accuracy: 0.5349\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9623 - accuracy: 0.5209 - val_loss: 0.9332 - val_accuracy: 0.5617\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9512 - accuracy: 0.5283 - val_loss: 0.9640 - val_accuracy: 0.5322\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9384 - accuracy: 0.5389 - val_loss: 0.9395 - val_accuracy: 0.5349\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9285 - accuracy: 0.5516 - val_loss: 1.0494 - val_accuracy: 0.4906\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9181 - accuracy: 0.5463 - val_loss: 0.9501 - val_accuracy: 0.5161\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.8988 - accuracy: 0.5696 - val_loss: 0.9579 - val_accuracy: 0.5241\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8924 - accuracy: 0.5697 - val_loss: 0.8731 - val_accuracy: 0.5737\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.8787 - accuracy: 0.5839 - val_loss: 0.9071 - val_accuracy: 0.5483\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8675 - accuracy: 0.5936 - val_loss: 0.8733 - val_accuracy: 0.5657\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8433 - accuracy: 0.6063 - val_loss: 0.8028 - val_accuracy: 0.6126\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8251 - accuracy: 0.6283 - val_loss: 0.8124 - val_accuracy: 0.6166\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8176 - accuracy: 0.6225 - val_loss: 0.8389 - val_accuracy: 0.5965\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7978 - accuracy: 0.6347 - val_loss: 0.8030 - val_accuracy: 0.6340\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7695 - accuracy: 0.6496 - val_loss: 0.7440 - val_accuracy: 0.6542\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7628 - accuracy: 0.6617 - val_loss: 0.7701 - val_accuracy: 0.6408\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7366 - accuracy: 0.6724 - val_loss: 0.7109 - val_accuracy: 0.6769\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7230 - accuracy: 0.6763 - val_loss: 0.7306 - val_accuracy: 0.6716\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7100 - accuracy: 0.6946 - val_loss: 0.6803 - val_accuracy: 0.6890\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6760 - accuracy: 0.7051 - val_loss: 0.6529 - val_accuracy: 0.7292\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6467 - accuracy: 0.7206 - val_loss: 0.6500 - val_accuracy: 0.7332\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.6587 - accuracy: 0.7161 - val_loss: 0.4599 - val_accuracy: 0.8150\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6603 - accuracy: 0.7165 - val_loss: 0.4281 - val_accuracy: 0.8231\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6104 - accuracy: 0.7419 - val_loss: 0.4640 - val_accuracy: 0.8298\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6112 - accuracy: 0.7469 - val_loss: 0.3718 - val_accuracy: 0.8365\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5817 - accuracy: 0.7542 - val_loss: 0.4101 - val_accuracy: 0.8204\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.5557 - accuracy: 0.7736 - val_loss: 0.3706 - val_accuracy: 0.8432\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5550 - accuracy: 0.7772 - val_loss: 0.3530 - val_accuracy: 0.8606\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5103 - accuracy: 0.7957 - val_loss: 0.4560 - val_accuracy: 0.7989\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5103 - accuracy: 0.7948 - val_loss: 0.3229 - val_accuracy: 0.8633\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4833 - accuracy: 0.8067 - val_loss: 0.3075 - val_accuracy: 0.8740\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4795 - accuracy: 0.8094 - val_loss: 0.3464 - val_accuracy: 0.8472\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4643 - accuracy: 0.8182 - val_loss: 0.3034 - val_accuracy: 0.8686\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.4374 - accuracy: 0.8286 - val_loss: 0.3849 - val_accuracy: 0.8592\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4322 - accuracy: 0.8332 - val_loss: 0.4010 - val_accuracy: 0.8445\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.4190 - accuracy: 0.8337 - val_loss: 0.3077 - val_accuracy: 0.8794\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4055 - accuracy: 0.8407 - val_loss: 0.2449 - val_accuracy: 0.8914\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3884 - accuracy: 0.8459 - val_loss: 0.2418 - val_accuracy: 0.9048\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3724 - accuracy: 0.8571 - val_loss: 0.2758 - val_accuracy: 0.8834\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3726 - accuracy: 0.8627 - val_loss: 0.3244 - val_accuracy: 0.9008\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3484 - accuracy: 0.8712 - val_loss: 0.2661 - val_accuracy: 0.8901\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3328 - accuracy: 0.8735 - val_loss: 0.2205 - val_accuracy: 0.9048\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3313 - accuracy: 0.8748 - val_loss: 0.2178 - val_accuracy: 0.9048\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3246 - accuracy: 0.8790 - val_loss: 0.2438 - val_accuracy: 0.9021\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3259 - accuracy: 0.8730 - val_loss: 0.2762 - val_accuracy: 0.8861\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2906 - accuracy: 0.8923 - val_loss: 0.2166 - val_accuracy: 0.9021\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2905 - accuracy: 0.8912 - val_loss: 0.1860 - val_accuracy: 0.9169\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2976 - accuracy: 0.8863 - val_loss: 0.1889 - val_accuracy: 0.9276\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2819 - accuracy: 0.8917 - val_loss: 0.2158 - val_accuracy: 0.9142\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2795 - accuracy: 0.8927 - val_loss: 0.1899 - val_accuracy: 0.9209\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2765 - accuracy: 0.8963 - val_loss: 0.3443 - val_accuracy: 0.8928\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2927 - accuracy: 0.8893 - val_loss: 0.0828 - val_accuracy: 0.9665\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2741 - accuracy: 0.8985 - val_loss: 0.0700 - val_accuracy: 0.9772\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2637 - accuracy: 0.9021 - val_loss: 0.0670 - val_accuracy: 0.9826\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2651 - accuracy: 0.8990 - val_loss: 0.0874 - val_accuracy: 0.9651\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2578 - accuracy: 0.9055 - val_loss: 0.1033 - val_accuracy: 0.9491\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2469 - accuracy: 0.9100 - val_loss: 0.0662 - val_accuracy: 0.9772\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2388 - accuracy: 0.9110 - val_loss: 0.0676 - val_accuracy: 0.9718\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2458 - accuracy: 0.9118 - val_loss: 0.0811 - val_accuracy: 0.9759\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2299 - accuracy: 0.9159 - val_loss: 0.0751 - val_accuracy: 0.9625\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2126 - accuracy: 0.9188 - val_loss: 0.0619 - val_accuracy: 0.9786\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2359 - accuracy: 0.9100 - val_loss: 0.0722 - val_accuracy: 0.9759\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2168 - accuracy: 0.9210 - val_loss: 0.0581 - val_accuracy: 0.9772\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1988 - accuracy: 0.9252 - val_loss: 0.0738 - val_accuracy: 0.9705\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2173 - accuracy: 0.9182 - val_loss: 0.0584 - val_accuracy: 0.9786\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1960 - accuracy: 0.9279 - val_loss: 0.0598 - val_accuracy: 0.9799\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1896 - accuracy: 0.9285 - val_loss: 0.0639 - val_accuracy: 0.9759\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1997 - accuracy: 0.9280 - val_loss: 0.0642 - val_accuracy: 0.9772\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1945 - accuracy: 0.9265 - val_loss: 0.0664 - val_accuracy: 0.9772\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1915 - accuracy: 0.9291 - val_loss: 0.0773 - val_accuracy: 0.9759\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1894 - accuracy: 0.9298 - val_loss: 0.0886 - val_accuracy: 0.9584\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1753 - accuracy: 0.9307 - val_loss: 0.0527 - val_accuracy: 0.9772\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1807 - accuracy: 0.9337 - val_loss: 0.0725 - val_accuracy: 0.9759\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1901 - accuracy: 0.9320 - val_loss: 0.0668 - val_accuracy: 0.9812\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1718 - accuracy: 0.9344 - val_loss: 0.0581 - val_accuracy: 0.9812\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1734 - accuracy: 0.9361 - val_loss: 0.0539 - val_accuracy: 0.9826\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1789 - accuracy: 0.9349 - val_loss: 0.0562 - val_accuracy: 0.9799\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1757 - accuracy: 0.9329 - val_loss: 0.0559 - val_accuracy: 0.9745\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1628 - accuracy: 0.9396 - val_loss: 0.0799 - val_accuracy: 0.9584\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1732 - accuracy: 0.9347 - val_loss: 0.0554 - val_accuracy: 0.9799\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1599 - accuracy: 0.9452 - val_loss: 0.0574 - val_accuracy: 0.9772\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 48ms/step - loss: 0.1584 - accuracy: 0.9404 - val_loss: 0.0428 - val_accuracy: 0.9826\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1735 - accuracy: 0.9389 - val_loss: 0.0642 - val_accuracy: 0.9826\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1775 - accuracy: 0.9370 - val_loss: 0.0636 - val_accuracy: 0.9826\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1677 - accuracy: 0.9353 - val_loss: 0.0734 - val_accuracy: 0.9812\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1683 - accuracy: 0.9380 - val_loss: 0.0584 - val_accuracy: 0.9705\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1560 - accuracy: 0.9416 - val_loss: 0.0980 - val_accuracy: 0.9530\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1698 - accuracy: 0.9380 - val_loss: 0.0500 - val_accuracy: 0.9826\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1452 - accuracy: 0.9486 - val_loss: 0.0432 - val_accuracy: 0.9852\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1650 - accuracy: 0.9413 - val_loss: 0.0492 - val_accuracy: 0.9812\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1471 - accuracy: 0.9447 - val_loss: 0.0489 - val_accuracy: 0.9893\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1415 - accuracy: 0.9470 - val_loss: 0.0466 - val_accuracy: 0.9826\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1486 - accuracy: 0.9464 - val_loss: 0.0401 - val_accuracy: 0.9919\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1498 - accuracy: 0.9444 - val_loss: 0.0421 - val_accuracy: 0.9826\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1388 - accuracy: 0.9520 - val_loss: 0.0437 - val_accuracy: 0.9879\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1385 - accuracy: 0.9470 - val_loss: 0.0442 - val_accuracy: 0.9933\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1295 - accuracy: 0.9523 - val_loss: 0.0517 - val_accuracy: 0.9812\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1460 - accuracy: 0.9459 - val_loss: 0.0492 - val_accuracy: 0.9839\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1565 - accuracy: 0.9435 - val_loss: 0.0574 - val_accuracy: 0.9718\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1305 - accuracy: 0.9534 - val_loss: 0.0561 - val_accuracy: 0.9732\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1351 - accuracy: 0.9498 - val_loss: 0.0467 - val_accuracy: 0.9852\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1405 - accuracy: 0.9474 - val_loss: 0.0461 - val_accuracy: 0.9866\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1447 - accuracy: 0.9470 - val_loss: 0.0487 - val_accuracy: 0.9852\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1294 - accuracy: 0.9507 - val_loss: 0.0387 - val_accuracy: 0.9839\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1306 - accuracy: 0.9517 - val_loss: 0.0461 - val_accuracy: 0.9852\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1397 - accuracy: 0.9528 - val_loss: 0.0447 - val_accuracy: 0.9839\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1249 - accuracy: 0.9557 - val_loss: 0.0463 - val_accuracy: 0.9826\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1399 - accuracy: 0.9475 - val_loss: 0.0669 - val_accuracy: 0.9597\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1266 - accuracy: 0.9540 - val_loss: 0.0361 - val_accuracy: 0.9893\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1168 - accuracy: 0.9580 - val_loss: 0.0858 - val_accuracy: 0.9530\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1263 - accuracy: 0.9547 - val_loss: 0.0346 - val_accuracy: 0.9893\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.1248 - accuracy: 0.9543 - val_loss: 0.0247 - val_accuracy: 0.9919\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1310 - accuracy: 0.9535 - val_loss: 0.0220 - val_accuracy: 0.9933\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1255 - accuracy: 0.9553 - val_loss: 0.0410 - val_accuracy: 0.9799\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1311 - accuracy: 0.9553 - val_loss: 0.0296 - val_accuracy: 0.9852\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1111 - accuracy: 0.9586 - val_loss: 0.0235 - val_accuracy: 0.9906\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1361 - accuracy: 0.9499 - val_loss: 0.0347 - val_accuracy: 0.9839\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1081 - accuracy: 0.9599 - val_loss: 0.0171 - val_accuracy: 0.9933\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1171 - accuracy: 0.9584 - val_loss: 0.0192 - val_accuracy: 0.9919\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1120 - accuracy: 0.9604 - val_loss: 0.0231 - val_accuracy: 0.9879\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1186 - accuracy: 0.9568 - val_loss: 0.0261 - val_accuracy: 0.9879\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1195 - accuracy: 0.9563 - val_loss: 0.0274 - val_accuracy: 0.9852\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1231 - accuracy: 0.9568 - val_loss: 0.0212 - val_accuracy: 0.9906\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1197 - accuracy: 0.9584 - val_loss: 0.0327 - val_accuracy: 0.9866\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1228 - accuracy: 0.9556 - val_loss: 0.0209 - val_accuracy: 0.9933\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1073 - accuracy: 0.9604 - val_loss: 0.0447 - val_accuracy: 0.9866\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1088 - accuracy: 0.9581 - val_loss: 0.0214 - val_accuracy: 0.9946\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1138 - accuracy: 0.9577 - val_loss: 0.0185 - val_accuracy: 0.9933\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1050 - accuracy: 0.9642 - val_loss: 0.0571 - val_accuracy: 0.9852\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1149 - accuracy: 0.9593 - val_loss: 0.0207 - val_accuracy: 0.9919\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1003 - accuracy: 0.9635 - val_loss: 0.0299 - val_accuracy: 0.9906\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1176 - accuracy: 0.9593 - val_loss: 0.0221 - val_accuracy: 0.9919\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1094 - accuracy: 0.9613 - val_loss: 0.0196 - val_accuracy: 0.9919\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0937 - accuracy: 0.9674 - val_loss: 0.0213 - val_accuracy: 0.9933\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1012 - accuracy: 0.9627 - val_loss: 0.0312 - val_accuracy: 0.9852\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1077 - accuracy: 0.9642 - val_loss: 0.0213 - val_accuracy: 0.9919\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1077 - accuracy: 0.9635 - val_loss: 0.0277 - val_accuracy: 0.9906\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1058 - accuracy: 0.9589 - val_loss: 0.0383 - val_accuracy: 0.9879\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1001 - accuracy: 0.9650 - val_loss: 0.0257 - val_accuracy: 0.9893\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1004 - accuracy: 0.9639 - val_loss: 0.0195 - val_accuracy: 0.9919\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0883 - accuracy: 0.9715 - val_loss: 0.0174 - val_accuracy: 0.9933\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1039 - accuracy: 0.9641 - val_loss: 0.0133 - val_accuracy: 0.9973\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1058 - accuracy: 0.9656 - val_loss: 0.0356 - val_accuracy: 0.9772\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0982 - accuracy: 0.9662 - val_loss: 0.0700 - val_accuracy: 0.9678\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0984 - accuracy: 0.9648 - val_loss: 0.0126 - val_accuracy: 0.9973\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0882 - accuracy: 0.9681 - val_loss: 0.0150 - val_accuracy: 0.9960\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1019 - accuracy: 0.9626 - val_loss: 0.0136 - val_accuracy: 0.9973\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0973 - accuracy: 0.9666 - val_loss: 0.0157 - val_accuracy: 0.9919\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0903 - accuracy: 0.9672 - val_loss: 0.0160 - val_accuracy: 0.9960\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0992 - accuracy: 0.9665 - val_loss: 0.0177 - val_accuracy: 0.9973\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0921 - accuracy: 0.9675 - val_loss: 0.0198 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1082 - accuracy: 0.9610 - val_loss: 0.0152 - val_accuracy: 0.9933\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0910 - accuracy: 0.9677 - val_loss: 0.0175 - val_accuracy: 0.9933\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1036 - accuracy: 0.9657 - val_loss: 0.0125 - val_accuracy: 0.9973\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0982 - accuracy: 0.9642 - val_loss: 0.0157 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1036 - accuracy: 0.9656 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0891 - accuracy: 0.9696 - val_loss: 0.0235 - val_accuracy: 0.9879\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0879 - accuracy: 0.9709 - val_loss: 0.0142 - val_accuracy: 0.9946\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0752 - accuracy: 0.9721 - val_loss: 0.0170 - val_accuracy: 0.9933\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0833 - accuracy: 0.9729 - val_loss: 0.0123 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0958 - accuracy: 0.9686 - val_loss: 0.0320 - val_accuracy: 0.9839\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0810 - accuracy: 0.9718 - val_loss: 0.0597 - val_accuracy: 0.9691\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0834 - accuracy: 0.9717 - val_loss: 0.0244 - val_accuracy: 0.9906\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0899 - accuracy: 0.9698 - val_loss: 0.0105 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0948 - accuracy: 0.9692 - val_loss: 0.0164 - val_accuracy: 0.9946\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0847 - accuracy: 0.9681 - val_loss: 0.0194 - val_accuracy: 0.9973\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0997 - accuracy: 0.9665 - val_loss: 0.0512 - val_accuracy: 0.9758\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0929 - accuracy: 0.9686 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0807 - accuracy: 0.9702 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0763 - accuracy: 0.9754 - val_loss: 0.0362 - val_accuracy: 0.9893\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0825 - accuracy: 0.9706 - val_loss: 0.0156 - val_accuracy: 0.9960\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0914 - accuracy: 0.9692 - val_loss: 0.0100 - val_accuracy: 0.9987\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0906 - accuracy: 0.9695 - val_loss: 0.0097 - val_accuracy: 0.9973\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0856 - accuracy: 0.9696 - val_loss: 0.0095 - val_accuracy: 0.9973\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0735 - accuracy: 0.9744 - val_loss: 0.0100 - val_accuracy: 0.9960\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0869 - accuracy: 0.9703 - val_loss: 0.0090 - val_accuracy: 0.9973\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0801 - accuracy: 0.9735 - val_loss: 0.0093 - val_accuracy: 0.9960\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0856 - accuracy: 0.9708 - val_loss: 0.0148 - val_accuracy: 0.9946\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0775 - accuracy: 0.9718 - val_loss: 0.0142 - val_accuracy: 0.9960\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0861 - accuracy: 0.9712 - val_loss: 0.0402 - val_accuracy: 0.9799\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0816 - accuracy: 0.9750 - val_loss: 0.0116 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0796 - accuracy: 0.9706 - val_loss: 0.0147 - val_accuracy: 0.9960\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0731 - accuracy: 0.9753 - val_loss: 0.0146 - val_accuracy: 0.9973\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0784 - accuracy: 0.9747 - val_loss: 0.0091 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0813 - accuracy: 0.9717 - val_loss: 0.0340 - val_accuracy: 0.9826\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0767 - accuracy: 0.9748 - val_loss: 0.0125 - val_accuracy: 0.9973\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0612 - accuracy: 0.9802 - val_loss: 0.0175 - val_accuracy: 0.9946\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0753 - accuracy: 0.9745 - val_loss: 0.0123 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0718 - accuracy: 0.9772 - val_loss: 0.0137 - val_accuracy: 0.9960\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0850 - accuracy: 0.9709 - val_loss: 0.0137 - val_accuracy: 0.9973\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0871 - accuracy: 0.9738 - val_loss: 0.0147 - val_accuracy: 0.9960\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0726 - accuracy: 0.9750 - val_loss: 0.0106 - val_accuracy: 0.9973\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0700 - accuracy: 0.9772 - val_loss: 0.0117 - val_accuracy: 0.9973\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0783 - accuracy: 0.9733 - val_loss: 0.0142 - val_accuracy: 0.9973\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0705 - accuracy: 0.9772 - val_loss: 0.0109 - val_accuracy: 0.9973\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0786 - accuracy: 0.9753 - val_loss: 0.0138 - val_accuracy: 0.9960\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0800 - accuracy: 0.9714 - val_loss: 0.0129 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0754 - accuracy: 0.9711 - val_loss: 0.0097 - val_accuracy: 0.9973\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0697 - accuracy: 0.9769 - val_loss: 0.0109 - val_accuracy: 0.9973\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0695 - accuracy: 0.9768 - val_loss: 0.0227 - val_accuracy: 0.9946\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0757 - accuracy: 0.9750 - val_loss: 0.0135 - val_accuracy: 0.9973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAnc2SJa3o9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "28a6349f-4664-40c2-99a4-0f39dc45bb38"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 8ms/step - loss: 0.0614 - accuracy: 0.9759\n",
            "Accuracy  : 0.9758583903312683\n",
            "F1_Score  : 0.9759914448424304\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7fcxLuwZpkK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94941398-0c12-45f7-c929-c0bfd1705d8a"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "51a1c733-6729-44a2-ddd5-e6a5da8c8482"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 54ms/step - loss: 1.1620 - accuracy: 0.3861 - val_loss: 1.0685 - val_accuracy: 0.4491\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0801 - accuracy: 0.4377 - val_loss: 1.0621 - val_accuracy: 0.4370\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0647 - accuracy: 0.4513 - val_loss: 1.0656 - val_accuracy: 0.4491\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0700 - accuracy: 0.4503 - val_loss: 1.0616 - val_accuracy: 0.4491\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0666 - accuracy: 0.4505 - val_loss: 1.0599 - val_accuracy: 0.4491\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0681 - accuracy: 0.4417 - val_loss: 1.0592 - val_accuracy: 0.4491\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0679 - accuracy: 0.4421 - val_loss: 1.0611 - val_accuracy: 0.4491\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0630 - accuracy: 0.4434 - val_loss: 1.0594 - val_accuracy: 0.4357\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0649 - accuracy: 0.4426 - val_loss: 1.0592 - val_accuracy: 0.4491\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0664 - accuracy: 0.4409 - val_loss: 1.0565 - val_accuracy: 0.4491\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0579 - accuracy: 0.4493 - val_loss: 1.0596 - val_accuracy: 0.4491\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0636 - accuracy: 0.4418 - val_loss: 1.0591 - val_accuracy: 0.4370\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0562 - accuracy: 0.4550 - val_loss: 1.0574 - val_accuracy: 0.4450\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0602 - accuracy: 0.4511 - val_loss: 1.0820 - val_accuracy: 0.4383\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0605 - accuracy: 0.4488 - val_loss: 1.0583 - val_accuracy: 0.4370\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0579 - accuracy: 0.4505 - val_loss: 1.0586 - val_accuracy: 0.4491\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0592 - accuracy: 0.4535 - val_loss: 1.0604 - val_accuracy: 0.4491\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0552 - accuracy: 0.4591 - val_loss: 1.0595 - val_accuracy: 0.4397\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0594 - accuracy: 0.4557 - val_loss: 1.0609 - val_accuracy: 0.4437\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0630 - accuracy: 0.4424 - val_loss: 1.0572 - val_accuracy: 0.4491\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0601 - accuracy: 0.4479 - val_loss: 1.0587 - val_accuracy: 0.4491\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0552 - accuracy: 0.4590 - val_loss: 1.0788 - val_accuracy: 0.4062\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0620 - accuracy: 0.4441 - val_loss: 1.0565 - val_accuracy: 0.4491\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0605 - accuracy: 0.4444 - val_loss: 1.0599 - val_accuracy: 0.4491\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0536 - accuracy: 0.4574 - val_loss: 1.0610 - val_accuracy: 0.4491\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0610 - accuracy: 0.4461 - val_loss: 1.0621 - val_accuracy: 0.4491\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0626 - accuracy: 0.4455 - val_loss: 1.0846 - val_accuracy: 0.4558\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0619 - accuracy: 0.4422 - val_loss: 1.0549 - val_accuracy: 0.4410\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0623 - accuracy: 0.4381 - val_loss: 1.0569 - val_accuracy: 0.4424\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0578 - accuracy: 0.4522 - val_loss: 1.0564 - val_accuracy: 0.4491\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0597 - accuracy: 0.4477 - val_loss: 1.0487 - val_accuracy: 0.4544\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0581 - accuracy: 0.4489 - val_loss: 1.0480 - val_accuracy: 0.4544\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0603 - accuracy: 0.4455 - val_loss: 1.0618 - val_accuracy: 0.4437\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0580 - accuracy: 0.4501 - val_loss: 1.0566 - val_accuracy: 0.4544\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0563 - accuracy: 0.4499 - val_loss: 1.0471 - val_accuracy: 0.4477\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0599 - accuracy: 0.4441 - val_loss: 1.0464 - val_accuracy: 0.4544\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0545 - accuracy: 0.4478 - val_loss: 1.0476 - val_accuracy: 0.4544\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0550 - accuracy: 0.4501 - val_loss: 1.0658 - val_accuracy: 0.4544\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0519 - accuracy: 0.4469 - val_loss: 1.0443 - val_accuracy: 0.4558\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0505 - accuracy: 0.4505 - val_loss: 1.0377 - val_accuracy: 0.4357\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0444 - accuracy: 0.4486 - val_loss: 1.0318 - val_accuracy: 0.4517\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0476 - accuracy: 0.4504 - val_loss: 1.0527 - val_accuracy: 0.4544\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0468 - accuracy: 0.4514 - val_loss: 1.0275 - val_accuracy: 0.4517\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0454 - accuracy: 0.4519 - val_loss: 1.0388 - val_accuracy: 0.4598\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0400 - accuracy: 0.4466 - val_loss: 1.0261 - val_accuracy: 0.4558\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0398 - accuracy: 0.4474 - val_loss: 1.0228 - val_accuracy: 0.4558\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0423 - accuracy: 0.4505 - val_loss: 1.0508 - val_accuracy: 0.4531\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0369 - accuracy: 0.4501 - val_loss: 1.0188 - val_accuracy: 0.4491\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0312 - accuracy: 0.4519 - val_loss: 1.0223 - val_accuracy: 0.4558\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0301 - accuracy: 0.4496 - val_loss: 1.0148 - val_accuracy: 0.4544\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0267 - accuracy: 0.4529 - val_loss: 1.0149 - val_accuracy: 0.4531\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0264 - accuracy: 0.4525 - val_loss: 1.0126 - val_accuracy: 0.4424\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0250 - accuracy: 0.4535 - val_loss: 1.0028 - val_accuracy: 0.4584\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0188 - accuracy: 0.4569 - val_loss: 1.0069 - val_accuracy: 0.4558\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0134 - accuracy: 0.4477 - val_loss: 0.9905 - val_accuracy: 0.4638\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0100 - accuracy: 0.4539 - val_loss: 1.0139 - val_accuracy: 0.4611\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0118 - accuracy: 0.4517 - val_loss: 0.9833 - val_accuracy: 0.4517\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0032 - accuracy: 0.4545 - val_loss: 1.0042 - val_accuracy: 0.4665\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0018 - accuracy: 0.4537 - val_loss: 0.9872 - val_accuracy: 0.4718\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9973 - accuracy: 0.4547 - val_loss: 1.0330 - val_accuracy: 0.4544\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.9960 - accuracy: 0.4550 - val_loss: 0.9799 - val_accuracy: 0.4866\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9889 - accuracy: 0.4858 - val_loss: 0.9621 - val_accuracy: 0.5000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9791 - accuracy: 0.4963 - val_loss: 0.9616 - val_accuracy: 0.4973\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9833 - accuracy: 0.4945 - val_loss: 0.9640 - val_accuracy: 0.5147\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9731 - accuracy: 0.4994 - val_loss: 0.9992 - val_accuracy: 0.4692\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9692 - accuracy: 0.4985 - val_loss: 0.9388 - val_accuracy: 0.5161\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9613 - accuracy: 0.5067 - val_loss: 0.9326 - val_accuracy: 0.5201\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9576 - accuracy: 0.5113 - val_loss: 0.9291 - val_accuracy: 0.5349\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9377 - accuracy: 0.5323 - val_loss: 1.0192 - val_accuracy: 0.5161\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9420 - accuracy: 0.5221 - val_loss: 0.9415 - val_accuracy: 0.5349\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9270 - accuracy: 0.5404 - val_loss: 0.9256 - val_accuracy: 0.5228\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9170 - accuracy: 0.5456 - val_loss: 0.9221 - val_accuracy: 0.5335\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9082 - accuracy: 0.5463 - val_loss: 0.9165 - val_accuracy: 0.5456\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8896 - accuracy: 0.5551 - val_loss: 0.9637 - val_accuracy: 0.4531\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8806 - accuracy: 0.5671 - val_loss: 0.8848 - val_accuracy: 0.5550\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8624 - accuracy: 0.5846 - val_loss: 0.9442 - val_accuracy: 0.5804\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8518 - accuracy: 0.5885 - val_loss: 0.9093 - val_accuracy: 0.5147\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8383 - accuracy: 0.6022 - val_loss: 0.9154 - val_accuracy: 0.5054\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8097 - accuracy: 0.6118 - val_loss: 0.8259 - val_accuracy: 0.6113\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8051 - accuracy: 0.6154 - val_loss: 0.8273 - val_accuracy: 0.5885\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7778 - accuracy: 0.6301 - val_loss: 0.7872 - val_accuracy: 0.6166\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7563 - accuracy: 0.6496 - val_loss: 0.7615 - val_accuracy: 0.6421\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7374 - accuracy: 0.6598 - val_loss: 0.7137 - val_accuracy: 0.6662\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7200 - accuracy: 0.6706 - val_loss: 0.7436 - val_accuracy: 0.6528\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6892 - accuracy: 0.6882 - val_loss: 0.7044 - val_accuracy: 0.6810\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6825 - accuracy: 0.6881 - val_loss: 0.6777 - val_accuracy: 0.7078\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6647 - accuracy: 0.7067 - val_loss: 0.6876 - val_accuracy: 0.7011\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6378 - accuracy: 0.7159 - val_loss: 0.6318 - val_accuracy: 0.7373\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6431 - accuracy: 0.7191 - val_loss: 0.6141 - val_accuracy: 0.7158\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6150 - accuracy: 0.7313 - val_loss: 0.6172 - val_accuracy: 0.7319\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.6093 - accuracy: 0.7389 - val_loss: 0.3712 - val_accuracy: 0.8780\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5884 - accuracy: 0.7429 - val_loss: 0.3901 - val_accuracy: 0.8485\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5736 - accuracy: 0.7492 - val_loss: 0.3853 - val_accuracy: 0.8458\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5680 - accuracy: 0.7614 - val_loss: 0.3751 - val_accuracy: 0.8472\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5568 - accuracy: 0.7665 - val_loss: 0.3037 - val_accuracy: 0.8834\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5373 - accuracy: 0.7733 - val_loss: 0.3889 - val_accuracy: 0.8351\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5001 - accuracy: 0.7888 - val_loss: 0.3441 - val_accuracy: 0.8646\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4897 - accuracy: 0.7975 - val_loss: 0.3366 - val_accuracy: 0.8619\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4850 - accuracy: 0.7972 - val_loss: 0.2785 - val_accuracy: 0.8834\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4561 - accuracy: 0.8164 - val_loss: 0.3367 - val_accuracy: 0.8499\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4576 - accuracy: 0.8164 - val_loss: 0.2862 - val_accuracy: 0.8861\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4316 - accuracy: 0.8282 - val_loss: 0.2611 - val_accuracy: 0.8820\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4495 - accuracy: 0.8168 - val_loss: 0.3195 - val_accuracy: 0.8686\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4414 - accuracy: 0.8191 - val_loss: 0.2818 - val_accuracy: 0.8834\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3804 - accuracy: 0.8447 - val_loss: 0.2127 - val_accuracy: 0.9129\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3952 - accuracy: 0.8410 - val_loss: 0.2787 - val_accuracy: 0.8740\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3717 - accuracy: 0.8528 - val_loss: 0.2092 - val_accuracy: 0.9276\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3529 - accuracy: 0.8617 - val_loss: 0.2018 - val_accuracy: 0.9102\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3679 - accuracy: 0.8539 - val_loss: 0.2236 - val_accuracy: 0.9209\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.3610 - accuracy: 0.8617 - val_loss: 0.2358 - val_accuracy: 0.9062\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3504 - accuracy: 0.8689 - val_loss: 0.2889 - val_accuracy: 0.8928\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.3414 - accuracy: 0.8668 - val_loss: 0.3394 - val_accuracy: 0.8499\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3306 - accuracy: 0.8708 - val_loss: 0.2163 - val_accuracy: 0.9142\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3118 - accuracy: 0.8812 - val_loss: 0.2048 - val_accuracy: 0.9021\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2925 - accuracy: 0.8911 - val_loss: 0.1851 - val_accuracy: 0.9276\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2945 - accuracy: 0.8855 - val_loss: 0.2049 - val_accuracy: 0.9249\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2994 - accuracy: 0.8836 - val_loss: 0.2328 - val_accuracy: 0.8995\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3101 - accuracy: 0.8838 - val_loss: 0.1965 - val_accuracy: 0.9290\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2640 - accuracy: 0.8994 - val_loss: 0.1769 - val_accuracy: 0.9290\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2710 - accuracy: 0.8963 - val_loss: 0.1955 - val_accuracy: 0.9223\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.3099 - accuracy: 0.8803 - val_loss: 0.0920 - val_accuracy: 0.9678\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2828 - accuracy: 0.8955 - val_loss: 0.0816 - val_accuracy: 0.9718\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2788 - accuracy: 0.8966 - val_loss: 0.0858 - val_accuracy: 0.9678\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2764 - accuracy: 0.8993 - val_loss: 0.0762 - val_accuracy: 0.9745\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2730 - accuracy: 0.9016 - val_loss: 0.0877 - val_accuracy: 0.9665\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2469 - accuracy: 0.9070 - val_loss: 0.0875 - val_accuracy: 0.9718\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2362 - accuracy: 0.9133 - val_loss: 0.0765 - val_accuracy: 0.9745\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2471 - accuracy: 0.9067 - val_loss: 0.0878 - val_accuracy: 0.9745\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2328 - accuracy: 0.9127 - val_loss: 0.0839 - val_accuracy: 0.9665\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2327 - accuracy: 0.9109 - val_loss: 0.0786 - val_accuracy: 0.9678\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2254 - accuracy: 0.9158 - val_loss: 0.0746 - val_accuracy: 0.9705\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2044 - accuracy: 0.9222 - val_loss: 0.0990 - val_accuracy: 0.9517\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2434 - accuracy: 0.9095 - val_loss: 0.0978 - val_accuracy: 0.9625\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2139 - accuracy: 0.9216 - val_loss: 0.0745 - val_accuracy: 0.9745\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2176 - accuracy: 0.9192 - val_loss: 0.0941 - val_accuracy: 0.9651\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2185 - accuracy: 0.9171 - val_loss: 0.0869 - val_accuracy: 0.9651\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1987 - accuracy: 0.9271 - val_loss: 0.0781 - val_accuracy: 0.9759\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2171 - accuracy: 0.9174 - val_loss: 0.0804 - val_accuracy: 0.9772\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2134 - accuracy: 0.9201 - val_loss: 0.0717 - val_accuracy: 0.9692\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2012 - accuracy: 0.9231 - val_loss: 0.0832 - val_accuracy: 0.9625\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2018 - accuracy: 0.9270 - val_loss: 0.0868 - val_accuracy: 0.9692\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1912 - accuracy: 0.9328 - val_loss: 0.0666 - val_accuracy: 0.9732\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1888 - accuracy: 0.9329 - val_loss: 0.1000 - val_accuracy: 0.9531\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1867 - accuracy: 0.9319 - val_loss: 0.0781 - val_accuracy: 0.9598\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1824 - accuracy: 0.9289 - val_loss: 0.0643 - val_accuracy: 0.9772\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1838 - accuracy: 0.9341 - val_loss: 0.0708 - val_accuracy: 0.9705\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1758 - accuracy: 0.9374 - val_loss: 0.0737 - val_accuracy: 0.9692\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1715 - accuracy: 0.9383 - val_loss: 0.0718 - val_accuracy: 0.9759\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1805 - accuracy: 0.9300 - val_loss: 0.0763 - val_accuracy: 0.9759\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1634 - accuracy: 0.9411 - val_loss: 0.1128 - val_accuracy: 0.9464\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1907 - accuracy: 0.9280 - val_loss: 0.0325 - val_accuracy: 0.9853\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1761 - accuracy: 0.9367 - val_loss: 0.0337 - val_accuracy: 0.9839\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1701 - accuracy: 0.9355 - val_loss: 0.0358 - val_accuracy: 0.9853\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1695 - accuracy: 0.9420 - val_loss: 0.0356 - val_accuracy: 0.9799\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1745 - accuracy: 0.9379 - val_loss: 0.0439 - val_accuracy: 0.9799\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1607 - accuracy: 0.9437 - val_loss: 0.0354 - val_accuracy: 0.9879\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1752 - accuracy: 0.9353 - val_loss: 0.0560 - val_accuracy: 0.9718\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1533 - accuracy: 0.9435 - val_loss: 0.0342 - val_accuracy: 0.9879\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1621 - accuracy: 0.9398 - val_loss: 0.0333 - val_accuracy: 0.9839\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1634 - accuracy: 0.9407 - val_loss: 0.0701 - val_accuracy: 0.9678\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1566 - accuracy: 0.9410 - val_loss: 0.0398 - val_accuracy: 0.9812\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1577 - accuracy: 0.9440 - val_loss: 0.0296 - val_accuracy: 0.9853\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1453 - accuracy: 0.9462 - val_loss: 0.0430 - val_accuracy: 0.9772\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1636 - accuracy: 0.9389 - val_loss: 0.0644 - val_accuracy: 0.9692\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1384 - accuracy: 0.9483 - val_loss: 0.0367 - val_accuracy: 0.9879\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1319 - accuracy: 0.9526 - val_loss: 0.0394 - val_accuracy: 0.9826\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1491 - accuracy: 0.9443 - val_loss: 0.0398 - val_accuracy: 0.9799\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1352 - accuracy: 0.9537 - val_loss: 0.0532 - val_accuracy: 0.9718\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1462 - accuracy: 0.9465 - val_loss: 0.0427 - val_accuracy: 0.9826\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1383 - accuracy: 0.9472 - val_loss: 0.0339 - val_accuracy: 0.9839\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1568 - accuracy: 0.9419 - val_loss: 0.0370 - val_accuracy: 0.9853\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1347 - accuracy: 0.9507 - val_loss: 0.0344 - val_accuracy: 0.9853\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1298 - accuracy: 0.9526 - val_loss: 0.0468 - val_accuracy: 0.9745\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1290 - accuracy: 0.9547 - val_loss: 0.0379 - val_accuracy: 0.9786\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1356 - accuracy: 0.9495 - val_loss: 0.0398 - val_accuracy: 0.9839\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1350 - accuracy: 0.9511 - val_loss: 0.0588 - val_accuracy: 0.9678\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1459 - accuracy: 0.9484 - val_loss: 0.0431 - val_accuracy: 0.9799\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1382 - accuracy: 0.9483 - val_loss: 0.0338 - val_accuracy: 0.9799\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1401 - accuracy: 0.9465 - val_loss: 0.0446 - val_accuracy: 0.9759\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1334 - accuracy: 0.9538 - val_loss: 0.0390 - val_accuracy: 0.9786\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1305 - accuracy: 0.9546 - val_loss: 0.0357 - val_accuracy: 0.9866\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1297 - accuracy: 0.9532 - val_loss: 0.0333 - val_accuracy: 0.9893\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1317 - accuracy: 0.9551 - val_loss: 0.0446 - val_accuracy: 0.9852\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1556 - accuracy: 0.9462 - val_loss: 0.0393 - val_accuracy: 0.9785\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1341 - accuracy: 0.9517 - val_loss: 0.0386 - val_accuracy: 0.9852\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1293 - accuracy: 0.9501 - val_loss: 0.0417 - val_accuracy: 0.9785\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1298 - accuracy: 0.9525 - val_loss: 0.0409 - val_accuracy: 0.9772\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1395 - accuracy: 0.9492 - val_loss: 0.0383 - val_accuracy: 0.9852\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1283 - accuracy: 0.9517 - val_loss: 0.0419 - val_accuracy: 0.9812\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1356 - accuracy: 0.9501 - val_loss: 0.0394 - val_accuracy: 0.9879\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1343 - accuracy: 0.9526 - val_loss: 0.0370 - val_accuracy: 0.9893\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1348 - accuracy: 0.9490 - val_loss: 0.0388 - val_accuracy: 0.9826\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1189 - accuracy: 0.9599 - val_loss: 0.0379 - val_accuracy: 0.9879\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1177 - accuracy: 0.9599 - val_loss: 0.0555 - val_accuracy: 0.9785\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1240 - accuracy: 0.9572 - val_loss: 0.0432 - val_accuracy: 0.9799\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1150 - accuracy: 0.9620 - val_loss: 0.0326 - val_accuracy: 0.9906\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1122 - accuracy: 0.9617 - val_loss: 0.0421 - val_accuracy: 0.9785\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1197 - accuracy: 0.9574 - val_loss: 0.0404 - val_accuracy: 0.9799\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1066 - accuracy: 0.9617 - val_loss: 0.0389 - val_accuracy: 0.9852\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1067 - accuracy: 0.9614 - val_loss: 0.0438 - val_accuracy: 0.9812\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1119 - accuracy: 0.9587 - val_loss: 0.0395 - val_accuracy: 0.9852\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1105 - accuracy: 0.9602 - val_loss: 0.0417 - val_accuracy: 0.9785\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1060 - accuracy: 0.9607 - val_loss: 0.0395 - val_accuracy: 0.9852\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1137 - accuracy: 0.9605 - val_loss: 0.0419 - val_accuracy: 0.9785\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1125 - accuracy: 0.9610 - val_loss: 0.0401 - val_accuracy: 0.9839\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1030 - accuracy: 0.9651 - val_loss: 0.0443 - val_accuracy: 0.9826\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1065 - accuracy: 0.9611 - val_loss: 0.0597 - val_accuracy: 0.9718\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0960 - accuracy: 0.9663 - val_loss: 0.0438 - val_accuracy: 0.9852\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1120 - accuracy: 0.9617 - val_loss: 0.0470 - val_accuracy: 0.9826\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1127 - accuracy: 0.9586 - val_loss: 0.0443 - val_accuracy: 0.9826\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.1201 - accuracy: 0.9559 - val_loss: 0.0154 - val_accuracy: 0.9946\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1086 - accuracy: 0.9604 - val_loss: 0.0185 - val_accuracy: 0.9933\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1037 - accuracy: 0.9659 - val_loss: 0.0141 - val_accuracy: 0.9946\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1185 - accuracy: 0.9571 - val_loss: 0.0153 - val_accuracy: 0.9960\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1041 - accuracy: 0.9607 - val_loss: 0.0161 - val_accuracy: 0.9919\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1211 - accuracy: 0.9572 - val_loss: 0.0149 - val_accuracy: 0.9933\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0990 - accuracy: 0.9657 - val_loss: 0.0180 - val_accuracy: 0.9906\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1576 - accuracy: 0.9443 - val_loss: 0.0203 - val_accuracy: 0.9906\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1123 - accuracy: 0.9613 - val_loss: 0.0266 - val_accuracy: 0.9879\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1027 - accuracy: 0.9680 - val_loss: 0.0183 - val_accuracy: 0.9919\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0969 - accuracy: 0.9662 - val_loss: 0.0221 - val_accuracy: 0.9919\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0990 - accuracy: 0.9656 - val_loss: 0.0188 - val_accuracy: 0.9919\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1009 - accuracy: 0.9632 - val_loss: 0.0147 - val_accuracy: 0.9973\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1081 - accuracy: 0.9624 - val_loss: 0.0136 - val_accuracy: 0.9973\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1072 - accuracy: 0.9607 - val_loss: 0.0181 - val_accuracy: 0.9933\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0970 - accuracy: 0.9654 - val_loss: 0.0182 - val_accuracy: 0.9946\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1185 - accuracy: 0.9574 - val_loss: 0.0158 - val_accuracy: 0.9933\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0956 - accuracy: 0.9639 - val_loss: 0.0178 - val_accuracy: 0.9893\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0984 - accuracy: 0.9626 - val_loss: 0.0197 - val_accuracy: 0.9919\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1075 - accuracy: 0.9614 - val_loss: 0.0181 - val_accuracy: 0.9933\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0946 - accuracy: 0.9692 - val_loss: 0.0155 - val_accuracy: 0.9960\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0987 - accuracy: 0.9669 - val_loss: 0.0160 - val_accuracy: 0.9946\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0940 - accuracy: 0.9660 - val_loss: 0.0160 - val_accuracy: 0.9933\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0845 - accuracy: 0.9705 - val_loss: 0.0144 - val_accuracy: 0.9946\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0890 - accuracy: 0.9686 - val_loss: 0.0141 - val_accuracy: 0.9946\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0995 - accuracy: 0.9659 - val_loss: 0.0141 - val_accuracy: 0.9933\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1042 - accuracy: 0.9632 - val_loss: 0.0253 - val_accuracy: 0.9879\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0992 - accuracy: 0.9654 - val_loss: 0.0188 - val_accuracy: 0.9933\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1036 - accuracy: 0.9669 - val_loss: 0.0168 - val_accuracy: 0.9906\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0950 - accuracy: 0.9695 - val_loss: 0.0193 - val_accuracy: 0.9919\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0992 - accuracy: 0.9632 - val_loss: 0.0207 - val_accuracy: 0.9866\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1006 - accuracy: 0.9648 - val_loss: 0.0200 - val_accuracy: 0.9919\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0971 - accuracy: 0.9680 - val_loss: 0.0210 - val_accuracy: 0.9893\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0940 - accuracy: 0.9690 - val_loss: 0.0202 - val_accuracy: 0.9866\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1055 - accuracy: 0.9644 - val_loss: 0.0232 - val_accuracy: 0.9960\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0737 - accuracy: 0.9744 - val_loss: 0.0183 - val_accuracy: 0.9919\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0981 - accuracy: 0.9666 - val_loss: 0.0187 - val_accuracy: 0.9919\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0962 - accuracy: 0.9656 - val_loss: 0.0267 - val_accuracy: 0.9852\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0790 - accuracy: 0.9706 - val_loss: 0.0213 - val_accuracy: 0.9879\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0937 - accuracy: 0.9668 - val_loss: 0.0198 - val_accuracy: 0.9946\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0935 - accuracy: 0.9668 - val_loss: 0.0225 - val_accuracy: 0.9893\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0891 - accuracy: 0.9690 - val_loss: 0.0313 - val_accuracy: 0.9866\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0976 - accuracy: 0.9695 - val_loss: 0.0222 - val_accuracy: 0.9879\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0873 - accuracy: 0.9693 - val_loss: 0.0186 - val_accuracy: 0.9919\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0859 - accuracy: 0.9683 - val_loss: 0.0192 - val_accuracy: 0.9946\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1004 - accuracy: 0.9654 - val_loss: 0.0194 - val_accuracy: 0.9919\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0990 - accuracy: 0.9653 - val_loss: 0.0239 - val_accuracy: 0.9866\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0849 - accuracy: 0.9699 - val_loss: 0.0234 - val_accuracy: 0.9866\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0839 - accuracy: 0.9700 - val_loss: 0.0219 - val_accuracy: 0.9893\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0861 - accuracy: 0.9718 - val_loss: 0.0192 - val_accuracy: 0.9906\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0845 - accuracy: 0.9708 - val_loss: 0.0234 - val_accuracy: 0.9866\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0848 - accuracy: 0.9711 - val_loss: 0.0180 - val_accuracy: 0.9933\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0747 - accuracy: 0.9738 - val_loss: 0.0274 - val_accuracy: 0.9852\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0739 - accuracy: 0.9744 - val_loss: 0.0183 - val_accuracy: 0.9919\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0845 - accuracy: 0.9680 - val_loss: 0.0155 - val_accuracy: 0.9960\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0861 - accuracy: 0.9700 - val_loss: 0.0275 - val_accuracy: 0.9852\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0781 - accuracy: 0.9717 - val_loss: 0.0190 - val_accuracy: 0.9933\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0799 - accuracy: 0.9726 - val_loss: 0.0166 - val_accuracy: 0.9933\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0766 - accuracy: 0.9747 - val_loss: 0.0240 - val_accuracy: 0.9866\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0842 - accuracy: 0.9732 - val_loss: 0.0175 - val_accuracy: 0.9946\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0838 - accuracy: 0.9702 - val_loss: 0.0113 - val_accuracy: 0.9960\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0888 - accuracy: 0.9678 - val_loss: 0.0151 - val_accuracy: 0.9960\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0916 - accuracy: 0.9680 - val_loss: 0.0161 - val_accuracy: 0.9946\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0963 - accuracy: 0.9677 - val_loss: 0.0133 - val_accuracy: 0.9960\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0795 - accuracy: 0.9718 - val_loss: 0.0130 - val_accuracy: 0.9960\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0730 - accuracy: 0.9738 - val_loss: 0.0200 - val_accuracy: 0.9919\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0924 - accuracy: 0.9675 - val_loss: 0.0191 - val_accuracy: 0.9946\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0829 - accuracy: 0.9718 - val_loss: 0.0127 - val_accuracy: 0.9946\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0841 - accuracy: 0.9695 - val_loss: 0.0133 - val_accuracy: 0.9973\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0863 - accuracy: 0.9711 - val_loss: 0.0140 - val_accuracy: 0.9960\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0891 - accuracy: 0.9699 - val_loss: 0.0300 - val_accuracy: 0.9866\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0780 - accuracy: 0.9754 - val_loss: 0.0134 - val_accuracy: 0.9946\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0889 - accuracy: 0.9702 - val_loss: 0.0183 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0751 - accuracy: 0.9750 - val_loss: 0.0134 - val_accuracy: 0.9960\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0885 - accuracy: 0.9714 - val_loss: 0.0135 - val_accuracy: 0.9960\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0843 - accuracy: 0.9712 - val_loss: 0.0141 - val_accuracy: 0.9960\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0766 - accuracy: 0.9729 - val_loss: 0.0229 - val_accuracy: 0.9919\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0768 - accuracy: 0.9739 - val_loss: 0.0116 - val_accuracy: 0.9946\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0700 - accuracy: 0.9760 - val_loss: 0.0117 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0699 - accuracy: 0.9778 - val_loss: 0.0130 - val_accuracy: 0.9960\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0859 - accuracy: 0.9709 - val_loss: 0.0123 - val_accuracy: 0.9973\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0757 - accuracy: 0.9742 - val_loss: 0.0219 - val_accuracy: 0.9893\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0768 - accuracy: 0.9718 - val_loss: 0.0166 - val_accuracy: 0.9946\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0849 - accuracy: 0.9717 - val_loss: 0.0148 - val_accuracy: 0.9973\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0634 - accuracy: 0.9781 - val_loss: 0.0180 - val_accuracy: 0.9946\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0654 - accuracy: 0.9765 - val_loss: 0.0127 - val_accuracy: 0.9960\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0858 - accuracy: 0.9706 - val_loss: 0.0128 - val_accuracy: 0.9960\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0698 - accuracy: 0.9738 - val_loss: 0.0233 - val_accuracy: 0.9906\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0666 - accuracy: 0.9779 - val_loss: 0.0155 - val_accuracy: 0.9933\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0622 - accuracy: 0.9775 - val_loss: 0.0169 - val_accuracy: 0.9960\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "3e94ed7f-0e7a-4acc-8304-6150fbe9b231"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 8ms/step - loss: 0.0576 - accuracy: 0.9791\n",
            "Accuracy  : 0.9790772795677185\n",
            "F1_Score  : 0.9791259919848571\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "7190124a-9dc6-4ca0-99e9-83e4cc300b7c"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'#dominance\\nX_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\\nprint(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "80886f8d-80fe-45e6-cc0d-ef1ee5d21e6a"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'foldNum=0\\nmodel = get_model()\\nfor train_index, val_index in kfold.split(X_train, Y_train):\\n  foldNum = foldNum + 1\\n  print(\"Results for fold\",foldNum)\\n  x_train, x_val = X_train[train_index], X_train[val_index]\\n  y_train, y_val = Y_train[train_index], Y_train[val_index]\\n  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\\n  gc.collect() # Garbage collecter\\n  del x_train, x_val, y_train, y_val\\n  gc.collect()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "c31d98be-f600-43b9-8894-dc23ab050d9d"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'acrc = model.evaluate(x_test, y_test)\\npred = model.predict(x_test)\\nf1scr = f1_score(y_test.argmax(1), pred.argmax(1), average=\\'macro\\')\\nc_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\\nprint(\"Accuracy  : {}\".format(acrc[1]))\\nprint(\"F1_Score  : {}\".format(f1scr))\\nc_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\\nimport seaborn as sns\\nfigure = plt.figure(figsize=(9, 9))\\nsns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\\nplt.tight_layout()\\nplt.ylabel(\\'True label\\')\\nplt.xlabel(\\'Predicted label\\')\\nplt.show()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}