{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub31_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "eca8d45d-e45f-4983-88bf-eac39984f2e8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e3\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  #EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "11a556f1-6479-418a-deb4-127f7936a652"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(31,32):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)\n",
        "print(valence.shape)\n",
        "print(arousal.shape)\n",
        "print(dominance.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.31\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (1864,) (3262,) (4194,)\n",
            "(9320,) (3728,) (2097,) (3495,)\n",
            "(9320,) (3495,) (1398,) (4427,)\n",
            "(9320, 3)\n",
            "(9320, 3)\n",
            "(9320, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "6910eb1a-06ca-4090-ee4b-72ddba648814"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "61e6092e-3e43-4f95-eb5a-899a29e45456"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "706"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "8f2a4ec6-8f61-45d8-81f3-b9ce13823f19"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c9905cd-3b3b-414d-904d-0317b03230df"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 46s 72ms/step - loss: 1.1744 - accuracy: 0.3995 - val_loss: 1.0493 - val_accuracy: 0.4370\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0691 - accuracy: 0.4433 - val_loss: 1.0355 - val_accuracy: 0.4370\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0455 - accuracy: 0.4573 - val_loss: 1.0244 - val_accuracy: 0.4370\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0345 - accuracy: 0.4494 - val_loss: 1.0202 - val_accuracy: 0.4370\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0335 - accuracy: 0.4528 - val_loss: 1.0159 - val_accuracy: 0.4370\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0375 - accuracy: 0.4482 - val_loss: 1.0113 - val_accuracy: 0.4370\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0344 - accuracy: 0.4506 - val_loss: 1.0116 - val_accuracy: 0.4370\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0315 - accuracy: 0.4463 - val_loss: 1.0178 - val_accuracy: 0.4370\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0269 - accuracy: 0.4559 - val_loss: 1.0212 - val_accuracy: 0.4370\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0218 - accuracy: 0.4460 - val_loss: 1.0221 - val_accuracy: 0.4370\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0200 - accuracy: 0.4586 - val_loss: 1.0363 - val_accuracy: 0.4370\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0317 - accuracy: 0.4414 - val_loss: 1.0116 - val_accuracy: 0.4370\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0322 - accuracy: 0.4411 - val_loss: 1.0103 - val_accuracy: 0.4370\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0231 - accuracy: 0.4524 - val_loss: 1.0139 - val_accuracy: 0.4370\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0174 - accuracy: 0.4583 - val_loss: 1.0120 - val_accuracy: 0.4370\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0075 - accuracy: 0.4551 - val_loss: 1.0092 - val_accuracy: 0.4370\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0165 - accuracy: 0.4578 - val_loss: 1.0080 - val_accuracy: 0.4370\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0133 - accuracy: 0.4544 - val_loss: 1.0098 - val_accuracy: 0.4370\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0155 - accuracy: 0.4528 - val_loss: 1.0093 - val_accuracy: 0.4370\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0204 - accuracy: 0.4495 - val_loss: 1.0135 - val_accuracy: 0.4370\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0241 - accuracy: 0.4507 - val_loss: 1.0074 - val_accuracy: 0.4370\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0265 - accuracy: 0.4411 - val_loss: 1.0034 - val_accuracy: 0.4370\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0141 - accuracy: 0.4557 - val_loss: 1.0127 - val_accuracy: 0.4397\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0164 - accuracy: 0.4427 - val_loss: 1.0155 - val_accuracy: 0.4370\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0094 - accuracy: 0.4623 - val_loss: 1.0099 - val_accuracy: 0.4370\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0066 - accuracy: 0.4601 - val_loss: 0.9996 - val_accuracy: 0.4383\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0181 - accuracy: 0.4447 - val_loss: 1.0047 - val_accuracy: 0.4343\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0003 - accuracy: 0.4606 - val_loss: 1.0216 - val_accuracy: 0.4330\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0141 - accuracy: 0.4436 - val_loss: 1.0097 - val_accuracy: 0.4370\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0035 - accuracy: 0.4543 - val_loss: 1.0016 - val_accuracy: 0.4370\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0046 - accuracy: 0.4455 - val_loss: 0.9969 - val_accuracy: 0.4799\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9998 - accuracy: 0.4466 - val_loss: 0.9849 - val_accuracy: 0.4906\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0009 - accuracy: 0.4516 - val_loss: 0.9868 - val_accuracy: 0.4786\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9986 - accuracy: 0.4505 - val_loss: 0.9844 - val_accuracy: 0.4772\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0024 - accuracy: 0.4489 - val_loss: 0.9917 - val_accuracy: 0.4786\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9983 - accuracy: 0.4538 - val_loss: 0.9903 - val_accuracy: 0.4893\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9970 - accuracy: 0.4484 - val_loss: 1.0037 - val_accuracy: 0.4786\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9993 - accuracy: 0.4510 - val_loss: 0.9966 - val_accuracy: 0.4772\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9925 - accuracy: 0.4544 - val_loss: 0.9882 - val_accuracy: 0.4906\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9923 - accuracy: 0.4574 - val_loss: 0.9983 - val_accuracy: 0.4893\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9886 - accuracy: 0.4565 - val_loss: 0.9808 - val_accuracy: 0.4839\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9854 - accuracy: 0.4584 - val_loss: 0.9855 - val_accuracy: 0.4826\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9826 - accuracy: 0.4556 - val_loss: 0.9738 - val_accuracy: 0.4853\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9782 - accuracy: 0.4601 - val_loss: 0.9750 - val_accuracy: 0.4920\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9780 - accuracy: 0.4602 - val_loss: 0.9870 - val_accuracy: 0.4839\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9805 - accuracy: 0.4618 - val_loss: 0.9631 - val_accuracy: 0.4973\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9697 - accuracy: 0.4653 - val_loss: 0.9707 - val_accuracy: 0.4960\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9742 - accuracy: 0.4611 - val_loss: 0.9660 - val_accuracy: 0.4759\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9692 - accuracy: 0.4645 - val_loss: 0.9795 - val_accuracy: 0.4893\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9669 - accuracy: 0.4653 - val_loss: 0.9606 - val_accuracy: 0.4745\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9717 - accuracy: 0.4663 - val_loss: 0.9573 - val_accuracy: 0.4826\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9722 - accuracy: 0.4665 - val_loss: 0.9596 - val_accuracy: 0.4879\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9715 - accuracy: 0.4674 - val_loss: 0.9670 - val_accuracy: 0.4906\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9571 - accuracy: 0.4720 - val_loss: 0.9563 - val_accuracy: 0.4853\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9494 - accuracy: 0.4760 - val_loss: 0.9501 - val_accuracy: 0.4987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9559 - accuracy: 0.4747 - val_loss: 0.9678 - val_accuracy: 0.4987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9483 - accuracy: 0.4818 - val_loss: 0.9560 - val_accuracy: 0.5054\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9473 - accuracy: 0.4796 - val_loss: 0.9724 - val_accuracy: 0.4933\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9439 - accuracy: 0.4814 - val_loss: 0.9465 - val_accuracy: 0.4987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9362 - accuracy: 0.4839 - val_loss: 0.9679 - val_accuracy: 0.5013\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9390 - accuracy: 0.4876 - val_loss: 0.9455 - val_accuracy: 0.4946\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9386 - accuracy: 0.4863 - val_loss: 0.9397 - val_accuracy: 0.5000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9350 - accuracy: 0.4911 - val_loss: 0.9193 - val_accuracy: 0.5040\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9226 - accuracy: 0.4918 - val_loss: 0.9065 - val_accuracy: 0.4987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9220 - accuracy: 0.4930 - val_loss: 0.9225 - val_accuracy: 0.5040\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9127 - accuracy: 0.4963 - val_loss: 0.9241 - val_accuracy: 0.5080\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9205 - accuracy: 0.4991 - val_loss: 0.9227 - val_accuracy: 0.4866\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9105 - accuracy: 0.5013 - val_loss: 0.9072 - val_accuracy: 0.4933\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9091 - accuracy: 0.5043 - val_loss: 0.9069 - val_accuracy: 0.4920\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9007 - accuracy: 0.5019 - val_loss: 0.8945 - val_accuracy: 0.5161\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8951 - accuracy: 0.5069 - val_loss: 0.9017 - val_accuracy: 0.4839\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8869 - accuracy: 0.5142 - val_loss: 0.9036 - val_accuracy: 0.5308\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8741 - accuracy: 0.5328 - val_loss: 0.9119 - val_accuracy: 0.5282\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8597 - accuracy: 0.5374 - val_loss: 0.8613 - val_accuracy: 0.5684\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8671 - accuracy: 0.5411 - val_loss: 0.8611 - val_accuracy: 0.5724\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8437 - accuracy: 0.5490 - val_loss: 0.8747 - val_accuracy: 0.5308\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8386 - accuracy: 0.5541 - val_loss: 0.8558 - val_accuracy: 0.5523\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8158 - accuracy: 0.5689 - val_loss: 0.8295 - val_accuracy: 0.5777\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.8120 - accuracy: 0.5738 - val_loss: 0.8125 - val_accuracy: 0.5831\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7970 - accuracy: 0.5817 - val_loss: 0.8387 - val_accuracy: 0.5845\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8076 - accuracy: 0.5794 - val_loss: 0.8015 - val_accuracy: 0.5925\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7964 - accuracy: 0.5891 - val_loss: 0.7955 - val_accuracy: 0.6233\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7740 - accuracy: 0.6021 - val_loss: 0.7938 - val_accuracy: 0.6139\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.7676 - accuracy: 0.6149 - val_loss: 0.8440 - val_accuracy: 0.5603\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7520 - accuracy: 0.6273 - val_loss: 0.7835 - val_accuracy: 0.6139\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.7352 - accuracy: 0.6261 - val_loss: 0.7281 - val_accuracy: 0.6408\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.7191 - accuracy: 0.6456 - val_loss: 0.7121 - val_accuracy: 0.6501\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.6856 - accuracy: 0.6620 - val_loss: 0.7795 - val_accuracy: 0.6354\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.6842 - accuracy: 0.6620 - val_loss: 0.6951 - val_accuracy: 0.6515\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.6786 - accuracy: 0.6687 - val_loss: 0.7136 - val_accuracy: 0.6568\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.6725 - accuracy: 0.6738 - val_loss: 0.6496 - val_accuracy: 0.6528\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.6839 - accuracy: 0.6686 - val_loss: 0.5895 - val_accuracy: 0.7185\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.6265 - accuracy: 0.7037 - val_loss: 0.5586 - val_accuracy: 0.7252\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.6283 - accuracy: 0.6982 - val_loss: 0.5363 - val_accuracy: 0.7574\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.6249 - accuracy: 0.7058 - val_loss: 0.5152 - val_accuracy: 0.7761\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.5663 - accuracy: 0.7450 - val_loss: 0.5380 - val_accuracy: 0.7654\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.5490 - accuracy: 0.7478 - val_loss: 0.4575 - val_accuracy: 0.8003\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.5362 - accuracy: 0.7556 - val_loss: 0.4486 - val_accuracy: 0.8029\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.5199 - accuracy: 0.7694 - val_loss: 0.4195 - val_accuracy: 0.8298\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.4958 - accuracy: 0.7772 - val_loss: 0.4294 - val_accuracy: 0.8190\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.4951 - accuracy: 0.7876 - val_loss: 0.4192 - val_accuracy: 0.8257\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.4616 - accuracy: 0.8003 - val_loss: 0.3960 - val_accuracy: 0.8257\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.4621 - accuracy: 0.8006 - val_loss: 0.3986 - val_accuracy: 0.8257\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.4277 - accuracy: 0.8177 - val_loss: 0.3560 - val_accuracy: 0.8499\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3962 - accuracy: 0.8380 - val_loss: 0.2903 - val_accuracy: 0.8847\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.3783 - accuracy: 0.8431 - val_loss: 0.3332 - val_accuracy: 0.8713\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.3714 - accuracy: 0.8505 - val_loss: 0.2835 - val_accuracy: 0.8941\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.3540 - accuracy: 0.8559 - val_loss: 0.2838 - val_accuracy: 0.8928\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.3363 - accuracy: 0.8639 - val_loss: 0.3002 - val_accuracy: 0.8928\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.3324 - accuracy: 0.8665 - val_loss: 0.2847 - val_accuracy: 0.8780\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.3252 - accuracy: 0.8757 - val_loss: 0.2294 - val_accuracy: 0.9088\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.3046 - accuracy: 0.8817 - val_loss: 0.2651 - val_accuracy: 0.8995\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2727 - accuracy: 0.8920 - val_loss: 0.2303 - val_accuracy: 0.9223\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2690 - accuracy: 0.9021 - val_loss: 0.2371 - val_accuracy: 0.9008\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2526 - accuracy: 0.9045 - val_loss: 0.1921 - val_accuracy: 0.9209\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2353 - accuracy: 0.9143 - val_loss: 0.1944 - val_accuracy: 0.9303\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2412 - accuracy: 0.9112 - val_loss: 0.2013 - val_accuracy: 0.9169\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2209 - accuracy: 0.9185 - val_loss: 0.1426 - val_accuracy: 0.9517\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2217 - accuracy: 0.9194 - val_loss: 0.1789 - val_accuracy: 0.9370\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1901 - accuracy: 0.9291 - val_loss: 0.1857 - val_accuracy: 0.9249\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2462 - accuracy: 0.9130 - val_loss: 0.0348 - val_accuracy: 0.9920\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2140 - accuracy: 0.9247 - val_loss: 0.0421 - val_accuracy: 0.9879\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1797 - accuracy: 0.9393 - val_loss: 0.0421 - val_accuracy: 0.9879\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1984 - accuracy: 0.9303 - val_loss: 0.0461 - val_accuracy: 0.9866\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1728 - accuracy: 0.9402 - val_loss: 0.0279 - val_accuracy: 0.9920\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1606 - accuracy: 0.9440 - val_loss: 0.0173 - val_accuracy: 0.9946\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1572 - accuracy: 0.9434 - val_loss: 0.0398 - val_accuracy: 0.9866\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1577 - accuracy: 0.9469 - val_loss: 0.0438 - val_accuracy: 0.9853\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1500 - accuracy: 0.9516 - val_loss: 0.0174 - val_accuracy: 0.9960\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1293 - accuracy: 0.9572 - val_loss: 0.0282 - val_accuracy: 0.9906\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1334 - accuracy: 0.9563 - val_loss: 0.0310 - val_accuracy: 0.9920\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1249 - accuracy: 0.9572 - val_loss: 0.0214 - val_accuracy: 0.9933\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1245 - accuracy: 0.9556 - val_loss: 0.0207 - val_accuracy: 0.9933\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1224 - accuracy: 0.9578 - val_loss: 0.0236 - val_accuracy: 0.9946\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1201 - accuracy: 0.9607 - val_loss: 0.0201 - val_accuracy: 0.9933\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1025 - accuracy: 0.9671 - val_loss: 0.0185 - val_accuracy: 0.9933\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.1172 - accuracy: 0.9627 - val_loss: 0.0209 - val_accuracy: 0.9946\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1072 - accuracy: 0.9660 - val_loss: 0.0127 - val_accuracy: 0.9973\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0861 - accuracy: 0.9708 - val_loss: 0.0138 - val_accuracy: 0.9946\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1031 - accuracy: 0.9694 - val_loss: 0.0205 - val_accuracy: 0.9933\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1095 - accuracy: 0.9627 - val_loss: 0.0279 - val_accuracy: 0.9906\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1032 - accuracy: 0.9665 - val_loss: 0.0129 - val_accuracy: 0.9960\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0867 - accuracy: 0.9709 - val_loss: 0.0263 - val_accuracy: 0.9920\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0908 - accuracy: 0.9690 - val_loss: 0.0158 - val_accuracy: 0.9946\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0840 - accuracy: 0.9745 - val_loss: 0.0087 - val_accuracy: 0.9973\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0752 - accuracy: 0.9754 - val_loss: 0.0288 - val_accuracy: 0.9839\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0867 - accuracy: 0.9714 - val_loss: 0.0339 - val_accuracy: 0.9879\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0722 - accuracy: 0.9765 - val_loss: 0.0070 - val_accuracy: 0.9960\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0883 - accuracy: 0.9733 - val_loss: 0.0316 - val_accuracy: 0.9866\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0895 - accuracy: 0.9706 - val_loss: 0.0232 - val_accuracy: 0.9933\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0791 - accuracy: 0.9756 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0947 - accuracy: 0.9686 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0971 - accuracy: 0.9693 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0848 - accuracy: 0.9729 - val_loss: 9.4219e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0687 - accuracy: 0.9775 - val_loss: 6.8773e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0711 - accuracy: 0.9763 - val_loss: 0.0031 - val_accuracy: 0.9987\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0749 - accuracy: 0.9742 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0740 - accuracy: 0.9739 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0625 - accuracy: 0.9788 - val_loss: 7.7038e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0670 - accuracy: 0.9799 - val_loss: 9.7452e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0706 - accuracy: 0.9775 - val_loss: 7.1428e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0891 - accuracy: 0.9751 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0731 - accuracy: 0.9787 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0720 - accuracy: 0.9770 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0704 - accuracy: 0.9778 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0689 - accuracy: 0.9776 - val_loss: 0.0052 - val_accuracy: 0.9973\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0556 - accuracy: 0.9818 - val_loss: 0.0086 - val_accuracy: 0.9973\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0721 - accuracy: 0.9776 - val_loss: 0.0043 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0550 - accuracy: 0.9821 - val_loss: 7.5768e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0502 - accuracy: 0.9820 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0671 - accuracy: 0.9790 - val_loss: 0.0031 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0527 - accuracy: 0.9838 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0644 - accuracy: 0.9809 - val_loss: 6.4212e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0708 - accuracy: 0.9778 - val_loss: 0.0050 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0605 - accuracy: 0.9815 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.0501 - accuracy: 0.9846 - val_loss: 0.0036 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0465 - accuracy: 0.9848 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0611 - accuracy: 0.9806 - val_loss: 0.0315 - val_accuracy: 0.9866\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0558 - accuracy: 0.9815 - val_loss: 0.0031 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0551 - accuracy: 0.9829 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 61ms/step - loss: 0.0525 - accuracy: 0.9839 - val_loss: 2.7533e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0670 - accuracy: 0.9791 - val_loss: 1.2526e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0586 - accuracy: 0.9817 - val_loss: 5.2141e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0474 - accuracy: 0.9847 - val_loss: 1.6538e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0523 - accuracy: 0.9842 - val_loss: 2.6589e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0510 - accuracy: 0.9829 - val_loss: 7.1051e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0495 - accuracy: 0.9861 - val_loss: 3.8566e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0497 - accuracy: 0.9842 - val_loss: 5.4185e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0523 - accuracy: 0.9842 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0448 - accuracy: 0.9839 - val_loss: 3.5493e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0455 - accuracy: 0.9851 - val_loss: 1.4169e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0422 - accuracy: 0.9855 - val_loss: 9.6072e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0445 - accuracy: 0.9844 - val_loss: 1.0299e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0465 - accuracy: 0.9841 - val_loss: 1.6942e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0553 - accuracy: 0.9845 - val_loss: 2.5940e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0407 - accuracy: 0.9878 - val_loss: 4.1899e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0447 - accuracy: 0.9860 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0321 - accuracy: 0.9902 - val_loss: 3.1943e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0502 - accuracy: 0.9832 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0434 - accuracy: 0.9869 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0499 - accuracy: 0.9851 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0435 - accuracy: 0.9863 - val_loss: 2.0378e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0420 - accuracy: 0.9881 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0417 - accuracy: 0.9873 - val_loss: 2.1200e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0395 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0426 - accuracy: 0.9864 - val_loss: 7.3743e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0406 - accuracy: 0.9875 - val_loss: 8.9620e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0378 - accuracy: 0.9887 - val_loss: 6.6958e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0354 - accuracy: 0.9902 - val_loss: 4.4240e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0394 - accuracy: 0.9882 - val_loss: 0.0021 - val_accuracy: 0.9987\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0482 - accuracy: 0.9863 - val_loss: 2.2452e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0404 - accuracy: 0.9866 - val_loss: 5.9048e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0378 - accuracy: 0.9885 - val_loss: 2.3565e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0381 - accuracy: 0.9875 - val_loss: 1.4488e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0567 - accuracy: 0.9829 - val_loss: 3.3193e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0379 - accuracy: 0.9882 - val_loss: 4.4465e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0373 - accuracy: 0.9884 - val_loss: 2.2262e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0358 - accuracy: 0.9882 - val_loss: 1.0093e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0426 - accuracy: 0.9873 - val_loss: 1.4238e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0399 - accuracy: 0.9861 - val_loss: 6.4422e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0371 - accuracy: 0.9878 - val_loss: 9.3700e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0367 - accuracy: 0.9887 - val_loss: 1.4345e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0318 - accuracy: 0.9893 - val_loss: 0.0013 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0314 - accuracy: 0.9890 - val_loss: 3.0762e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0326 - accuracy: 0.9899 - val_loss: 7.3588e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0385 - accuracy: 0.9870 - val_loss: 1.7113e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0485 - accuracy: 0.9847 - val_loss: 3.1704e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0418 - accuracy: 0.9870 - val_loss: 1.7372e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0387 - accuracy: 0.9872 - val_loss: 8.9284e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0427 - accuracy: 0.9876 - val_loss: 1.1939e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0267 - accuracy: 0.9924 - val_loss: 8.3612e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0403 - accuracy: 0.9885 - val_loss: 7.7127e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0455 - accuracy: 0.9850 - val_loss: 1.5052e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0304 - accuracy: 0.9908 - val_loss: 6.6810e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0418 - accuracy: 0.9875 - val_loss: 0.0067 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0395 - accuracy: 0.9882 - val_loss: 6.2420e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0298 - accuracy: 0.9903 - val_loss: 6.5681e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0219 - accuracy: 0.9920 - val_loss: 0.0010 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0310 - accuracy: 0.9908 - val_loss: 0.0010 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0400 - accuracy: 0.9881 - val_loss: 1.9050e-04 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0263 - accuracy: 0.9925 - val_loss: 1.0544e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0363 - accuracy: 0.9885 - val_loss: 1.7947e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0230 - accuracy: 0.9923 - val_loss: 1.6286e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0300 - accuracy: 0.9902 - val_loss: 4.7138e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0270 - accuracy: 0.9914 - val_loss: 1.3547e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0319 - accuracy: 0.9903 - val_loss: 2.7927e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0408 - accuracy: 0.9897 - val_loss: 1.3771e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0325 - accuracy: 0.9899 - val_loss: 2.9270e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0288 - accuracy: 0.9906 - val_loss: 7.7145e-06 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0239 - accuracy: 0.9923 - val_loss: 4.0314e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0265 - accuracy: 0.9928 - val_loss: 3.5132e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0323 - accuracy: 0.9909 - val_loss: 1.3095e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0296 - accuracy: 0.9912 - val_loss: 3.5558e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0377 - accuracy: 0.9884 - val_loss: 4.8977e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0201 - accuracy: 0.9940 - val_loss: 2.6309e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0310 - accuracy: 0.9905 - val_loss: 2.7427e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0273 - accuracy: 0.9897 - val_loss: 2.8887e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0390 - accuracy: 0.9878 - val_loss: 1.6839e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0322 - accuracy: 0.9908 - val_loss: 5.4320e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0405 - accuracy: 0.9866 - val_loss: 2.5548e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0431 - accuracy: 0.9882 - val_loss: 9.8216e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0256 - accuracy: 0.9909 - val_loss: 1.2208e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0345 - accuracy: 0.9899 - val_loss: 0.0067 - val_accuracy: 0.9973\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0314 - accuracy: 0.9911 - val_loss: 1.7089e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0225 - accuracy: 0.9921 - val_loss: 4.5515e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0248 - accuracy: 0.9912 - val_loss: 3.3252e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0234 - accuracy: 0.9930 - val_loss: 2.2014e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0364 - accuracy: 0.9888 - val_loss: 1.5845e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0288 - accuracy: 0.9909 - val_loss: 2.5264e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0214 - accuracy: 0.9939 - val_loss: 7.1706e-05 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0307 - accuracy: 0.9914 - val_loss: 8.0379e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0344 - accuracy: 0.9905 - val_loss: 5.5954e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0265 - accuracy: 0.9909 - val_loss: 1.3296e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0278 - accuracy: 0.9918 - val_loss: 3.7908e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0267 - accuracy: 0.9915 - val_loss: 2.1242e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0265 - accuracy: 0.9917 - val_loss: 8.1326e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0359 - accuracy: 0.9903 - val_loss: 9.5323e-06 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0352 - accuracy: 0.9885 - val_loss: 1.2195e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0218 - accuracy: 0.9920 - val_loss: 1.6114e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0254 - accuracy: 0.9924 - val_loss: 1.2906e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0282 - accuracy: 0.9912 - val_loss: 1.5997e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0207 - accuracy: 0.9942 - val_loss: 8.7015e-06 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0243 - accuracy: 0.9914 - val_loss: 1.3836e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0268 - accuracy: 0.9918 - val_loss: 2.3025e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0341 - accuracy: 0.9890 - val_loss: 2.7706e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0273 - accuracy: 0.9905 - val_loss: 1.2044e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0235 - accuracy: 0.9921 - val_loss: 1.5298e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0294 - accuracy: 0.9914 - val_loss: 3.6433e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0330 - accuracy: 0.9905 - val_loss: 3.9592e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0189 - accuracy: 0.9948 - val_loss: 1.0684e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0217 - accuracy: 0.9923 - val_loss: 9.7795e-06 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0262 - accuracy: 0.9927 - val_loss: 1.0568e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0208 - accuracy: 0.9934 - val_loss: 1.2857e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0357 - accuracy: 0.9894 - val_loss: 8.1896e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 7.3533e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0229 - accuracy: 0.9939 - val_loss: 2.8415e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0188 - accuracy: 0.9946 - val_loss: 8.3083e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0348 - accuracy: 0.9912 - val_loss: 6.7169e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0276 - accuracy: 0.9906 - val_loss: 2.1868e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0225 - accuracy: 0.9936 - val_loss: 7.0640e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "id": "CAnc2SJa3o9f",
        "outputId": "81aeb14e-31dc-4701-8bab-b77909a823fa"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 8ms/step - loss: 0.0407 - accuracy: 0.9898\n",
            "Accuracy  : 0.9898068904876709\n",
            "F1_Score  : 0.9884719250246315\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAAKOCAYAAAAS8uXWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZgdVZ038O9Jh4zIDpIOkIjEREGCC4K7LMFAWGQVRWf0ddRh1AEEl5FFGWUUFBl3GGTxBR1FQUCQQMIuywsCorKrURlIJB0HA7Ia0jnvH92EBMkiTuee5H4+Pvd5+tatW3UqlJ1fvr86VaXWGgAA2jGs0wMAAGBRCjQAgMYo0AAAGqNAAwBojAINAKAxwzs9gMVZdcuDTC+l4+bc8NVODwGSJCbc04pVV0npyH5fcUDH/l/w2M++vtyPWYIGANAYBRoAQGOabXECACxQuitT6q6jBQBYASjQAAAao8UJALSvdGTyaMdI0AAAGiNBAwDaZ5IAAACdJEEDANrnGjQAADpJgQYA0BgtTgCgfSYJAADQSRI0AKB9JgkAANBJCjQAgMZocQIA7TNJAACATpKgAQDtM0kAAIBOkqABAO1zDRoAAJ2kQAMAaIwWJwDQPpMEAADoJAkaANA+kwQAAOgkCRoA0D7XoAEA0EkKNACAxmhxAgDtM0kAAIBOkqABAO2ToAEA0EkKNACAxmhxAgDtG+Y+aAAAdJAEDQBon0kCAAB0kgQNAGifZ3ECANBJCjQAgMZocQIA7TNJAACATpKgAQDtM0kAAIBOUqABADRGixMAaJ9JAgAAdJIEDQBon0kCAAB0kgQNAGifa9AAAOgkBRoAQGO0OAGA9pkkAABAJ0nQAID2mSQAAEAnSdAAgPa5Bg0AgE5SoAEANEaLEwBon0kCAAB0kgQNAGifBA0AgE5SoAEANEaLEwBon/ugAQDQSRI0AKB9JgkAANBJEjQAoH2uQQMAoJMUaAAAjdHiBADaZ5IAAACdJEEDANpnkgAAAJ0kQQMAmlckaAAAdJICDQCgMVqcAEDztDgBAOgoCRoA0L7uCtAkaAAArVGgAQA0RosTAGieSQIAAHSUBA0AaJ4EDQCAjpKgAQDNk6ABANBRCjQAgMZocQIAzdPiBACgoyRoAED7uitAk6ABALRGgraCmvS6zXLcR/dOT8+wnHbudTnutEsX+fz5G6yTE//tHXneOqtnzoOP5j2f+HZmzn4gSfKZg3bP5De8JEnyuVOm5QcX/2y5j58Vy7VXX5XPf+6zmd8/P3vts2/e+0/7L/L53Llzc8Rh/5o7b789a629do79jy9lo41GJ0lOPfkbOffsH2RYz7B8/LBP5PVveGOSZOdJE/Pc1VZLz7Bh6RnekzPOPCdJ8p/Hfy1n/+DMrLvOukmSAw/+cN64zbbL8Whp2bXXXJVjFzoX3/O+vzwXP3HYv+bOOwbOxc8ft+i5+MNznjoXX/f6gXPx2986LeeefVZKKRk//kX59GeOyd/93d/lU588PHfcfltqrdn4BZvkqM8ek+c+d7XlfswMcA0azRs2rOTLH983exx4Yl6xz9HZd/Irs+kmoxZZ55iD98x3Lrgxr3rb53P0yVNz1IFvTpJMfsNL8vJNR+fVbz8227zrizn4nROzxmrP6cRhsILo7+/P0Z89KieceErOPX9Kpl54QX4zffoi65x79llZc801c8HUS/IP73p3vvzF45Ikv5k+PVMvnJJzzp+SE75xSo7+zKfT39+/4Hun/N/Tc+Y55y0ozp70zne9O2eec17OPOc8xRkL9Pf355jPHJXj//OUnPPkufibp52L5wyciz+66JL8wzvfna88eS7+ZnqmXTQlZ583JSeceEqO/veBc7Gvry9nfOdb+e73z87ZP7wg/fP7M/WiKUmSj3788Jx5zvk569wfZdQGG+R73/3Ocj9muteQFWillE1LKR8vpXx18PXxUspmQ7W/brL1hI3zmxl/yN0z788T8/pz1rSbs9t2WyyyzqZjR+XHN/4qSfLjG3+d3bYd+HyzsaNyzc2/SX///Dz6+Nzc+uvfZ8fX+c/C4t126y0ZM2bjjB4zJquMGJHJu+yaK6+4bJF1rrj88uy+x15Jkkk77pQbrr8utdZcecVlmbzLrhkxYkRGjx6TMWM2zm233tKJw2AlcNutt2TM8wfPxVVGZKedd82Vly96Ll55+eV58+C5+KYdd8oNPxk8Fy+/LDvtPHAubjR6TMY8/6lzsX9ef/7858czb968PP7Y41l//ZFJktVXXz1JUmvNnx9/PF0W4NBhQ1KglVI+nuR7Gbik74bBV0lyRinl0KHYZzfZcP21M2PWAwvez5z9QDYaudYi69z6q5nZY+LLkiR7THxp1lz9OVl3refmll8NFGSrPmeVrLf2atl2q/EZ3bv2ch0/K5bZfX0ZtcFTCe3I3t709fUtus7svowatUGSZPjw4Vl9jTXywANz0tfXl95RT323d1RvZj/53ZK8/5/em/323Ts/OPP7i2zve9/9Tt6y15tz5CcOy58efHCIjowVzcB5ttD51Nub2bOXci6uPnAuLu67vb29ede735PJb9o+k7Z/Q1ZfY/W87vVvWLDekZ84LDts+/r87ne/zX7veOcQHyFLUkrp2KsThipBe2+SrWutn6u1/tfg63NJXjX42TMqpexfSrmplHLTvP+5bYiG1h0O+9IP88ZXjst13/3XvHHLcZnZ90D6+2suu/6uTL32jlzxfw/J6Uf/n/zklrvTP792erh0odO+fUa+/4Nzc/yJJ+f7Z3wnP73pxiTJW9/29lww9ZKcefZ5WX/9kTnuC5/r8EhZmf3pwQdz5RWXZcq0y3Lx5Vfnsccey5Qfnbfg86M+c0wuueLqbDL2hZk29cIOjpRuM1QF2vwkGz7D8g0GP3tGtdaTaq1b1Vq3Gv68CUM0tBXf7//wQEaPeir12mjk2pk5e9GU4b7/+VP2++ipee07js2/HX9BkuTBhx9Lkhx76sV5zduPzW4fPCGlJL/+79nLb/CscEb29mbWfbMWvJ/dN5A6LLLOyN7MmnVfkmTevHl5+KGHsvba66S3tzd9s576bt+svowc/O6T21hvvfUy8U2TFrSb1nve89LT05Nhw4Zl77fsm9tuvXVIj48Vx8B5ttD51NeXkSOXci4+PHAuLu6711///7LRRqOz7rrrZpVVVskOO+yYn/980YlTPT09mbzzrrnskouH8OhYGgna/46Dk1xWSrmolHLS4GtqksuSfGiI9tk1brr9nowbs3423nDdrDK8J/vutGWm/HjRv8TWW3u1BSfVx94zKaefd32SgQkG66713CTJhPEbZsL4DXPp9Xct3wNghbL5hC1yzz13Z8aMe/PE3LmZeuGUbLv9xEXW2W77iTn/vHOTJJdcPC2vevVrUkrJtttPzNQLp2Tu3LmZMePe3HPP3ZmwxUvz6KOP5pFHHk6SPProo7nu/12bcePGJ0n+8Ien/sFw+aWXZtz48cvpSGndk+fizBn35okn5mbaRX95Lm67/cT8aPBcvPTiadl6oXNx2kUD5+LMhc7FDTbYMLfc8os89thjqbXmJz+5LmPHvjC11txzz38nGbgG7cdXXJ5NNhm73I+Z7jUkt9motU4tpbwoAy3NjQYXz0xyY621f/HfZFn098/PIZ//QX50/AfTM2xYTj//+tz521n55Pt3yc133JMpV92WbV45PkcduFtqTa65+Tc5+HNnJUlWGd6TS089OEny0COP5z2f+Hb6+xcbakKGDx+ew444Mh/Y/32ZP78/e+61T8aNG5/jv/aVbL75hGw3cYfstc9bcsShH8tukydlzbXWyrHHfSlJMm7c+Ow4eefstfsu6enpyeGfODI9PT354/3355CD/iVJMq+/P7vsulte/8ZtkiRf+o8v5Jd33ZVSkg033Cif/NRRHTt22jJ8+PAceviR+cA/vy/z+/uzx+C5eMLXv5KXbD4h222/Q/ba+y054rCP5c07D5yLn//CU+fipJ12zt6775Ke4T057IiBc3GLl74sb5q0U97+1r3S0zM8m266WfbZ922pteaTh388jzzySGqtedGLX5wjPvnpDv8J0E1KrW1ef7Tqlge1OTC6ypwbvtrpIUCSpNFf1XShVVfpzD3913vXGR37f8H933r7cj9m90EDAGiMJwkAAO3rsvvQSdAAABojQQMAmudZnAAAdJQCDQCgMVqcAEDztDgBAOgoBRoA0LyWn8VZSplcSvllKWV6KeXQZ/j8+aWUK0opPyul3FJK2WVp21SgAQA8S6WUniTHJ9k5yUuSvL2U8pKnrfaJJGfWWl+RZL8kJyxtuwo0AIBn71VJptdaf1trnZvke0n2eNo6Ncmagz+vleT3S9uoSQIAQPs6OEeglLJ/kv0XWnRSrfWkwZ83SnLvQp/NSPLqp23iU0kuLqUcmGS1JG9a2j4VaAAASzBYjJ201BUX7+1JTqu1/kcp5bVJvl1KmVBrnb+4LyjQAIDmNXybjZlJxiz0fvTgsoW9N8nkJKm1XldKeU6S5yWZvbiNugYNAODZuzHJ+FLKJqWUERmYBHD+09a5J8kOSVJK2SzJc5L8YUkblaABAM1rNUGrtc4rpRyQZFqSniTfrLXeXko5KslNtdbzk3wkycmllEMyMGHg3bXWuqTtKtAAAP4GtdYLk1z4tGVHLvTzHUle/9dsU4sTAKAxEjQAoHmttjiHigQNAKAxEjQAoHkSNAAAOkqCBgC0r7sCNAkaAEBrFGgAAI3R4gQAmmeSAAAAHSVBAwCaJ0EDAKCjFGgAAI3R4gQAmqfFCQBAR0nQAID2dVeAJkEDAGiNBA0AaJ5r0AAA6CgFGgBAY7Q4AYDmaXECANBREjQAoHkSNAAAOkqCBgA0T4IGAEBHKdAAABqjxQkAtK+7OpwSNACA1kjQAIDmmSQAAEBHKdAAABqjxQkANE+LEwCAjpKgAQDN67IATYIGANAaCRoA0DzXoAEA0FEKNACAxmhxAgDN67IOpwQNAKA1EjQAoHkmCQAA0FEKNACAxmhxAgDN67IOpwQNAKA1EjQAoHnDhnVXhCZBAwBojAQNAGiea9AAAOgoBRoAQGO0OAGA5nmSAAAAHSVBAwCa12UBmgQNAKA1EjQAoHmuQQMAoKMUaAAAjdHiBACap8UJAEBHSdAAgOZ1WYAmQQMAaI0CDQCgMVqcAEDzTBIAAKCjJGgAQPO6LECToAEAtEaCBgA0zzVoAAB0lAINAKAxWpwAQPO6rMMpQQMAaI0EDQBonkkCAAB0lAQNAGhelwVoEjQAgNYo0AAAGqPFCQA0zyQBAAA6qtkEbc4NX+30ECDrbH1Ap4cASZI5N36900OAjuqyAE2CBgDQGgUaAEBjmm1xAgA8ySQBAAA6SoIGADSvywI0CRoAQGskaABA81yDBgBARynQAAAao8UJADSvyzqcEjQAgNZI0ACA5pkkAABARynQAAAao8UJADRPixMAgI6SoAEAzeuyAE2CBgDQGgkaANA816ABANBRCjQAgMZocQIAzeuyDqcEDQCgNRI0AKB5JgkAANBREjQAoHldFqBJ0AAAWqNAAwBojBYnANC8YV3W45SgAQA0RoIGADSvywI0CRoAQGsUaAAAjdHiBACa50kCAAAss1LK5FLKL0sp00sphy5mnbeWUu4opdxeSvnu0rYpQQMAmjes0QCtlNKT5Pgkk5LMSHJjKeX8WusdC60zPslhSV5fa51TShm5tO1K0AAAnr1XJZlea/1trXVuku8l2eNp6/xTkuNrrXOSpNY6e2kblaABAM1r+Bq0jZLcu9D7GUle/bR1XpQkpZRrk/Qk+VStdeqSNqpAAwBYglLK/kn2X2jRSbXWk/6KTQxPMj7JdklGJ7mqlLJFrfWBJX0BAIDFGCzGFleQzUwyZqH3oweXLWxGkp/UWp9I8rtSyq8yULDduLh9ugYNAGheKZ17LcWNScaXUjYppYxIsl+S85+2zg8zkJ6llPK8DLQ8f7ukjSrQAACepVrrvCQHJJmW5M4kZ9Zaby+lHFVK2X1wtWlJ7i+l3JHkiiQfq7Xev6TtanECAM0raXaSQGqtFya58GnLjlzo55rkw4OvZSJBAwBojAQNAGheqzeqHSoSNACAxijQAAAao8UJADSv4ScJDAkJGgBAYyRoAEDzuixAk6ABALRGgQYA0BgtTgCgecO6rMcpQQMAaIwEDQBoXpcFaBI0AIDWSNAAgOa5US0AAB2lQAMAaIwWJwDQvC7rcErQAABaI0EDAJrnRrUAAHSUAg0AoDFanABA87qrwSlBAwBojgQNAGieJwkAANBREjQAoHnDuitAk6ABALRGgQYA0BgtTgCgeSYJAADQURI0AKB5XRagSdAAAFojQQMAmucaNAAAOkqBBgDQGC1OAKB53fYkgcUWaKWUryWpi/u81nrQkIwIAKDLLSlBu2m5jQIAYAm6bZLAYgu0WuvpC78vpTy31vro0A8JAKC7LXWSQCnltaWUO5LcNfj+ZaWUE4Z8ZAAAXWpZZnF+OclOSe5PklrrL5JsM5SDAgBYWOngqxOW6TYbtdZ7n7aofwjGAgBAlu02G/eWUl6XpJZSVknyoSR3Du2wAACeMqzLJgksS4L2/iT/kmSjJL9P8vLB9wAADIGlJmi11v9J8vfLYSwAAM+oywK0ZZrFObaU8qNSyh9KKbNLKeeVUsYuj8EBAHSjZWlxfjfJmUk2SLJhkrOSnDGUgwIA6GbLUqA9t9b67VrrvMHXfyV5zlAPDADgSaWUjr06YUnP4lx38MeLSimHJvleBp7N+bYkFy6HsQEAdKUlTRL4aQYKsidLx39e6LOa5LChGhQAwMK6bZLAkp7FucnyHAgAAAOW5Ua1KaVMSPKSLHTtWa31W0M1KACAhXXbjWqXWqCVUv4tyXYZKNAuTLJzkmuSKNAAAIbAsszifEuSHZLMqrX+Y5KXJVlrSEcFANDFlqVAe6zWOj/JvFLKmklmJxkztMPiSddefVV233Wn7DZ5Uk49+aS/+Hzu3Ln52EcOzm6TJ+Xv99s3M2fOWPDZqSd/I7tNnpTdd90p115z9SLf6+/vz1v32TMHfPCpuR+fPPzQ7LzjxLx17z3y1r33yF13euQqSzbpdZvlF+d+Mred92/56D9O+ovPn7/BOrnwxANzw/cPy7STP5SNRq694LPPHLRHbjrr8Nx01uF5y45bLs9hswIbit+Jf/rTn/KRgw/KHrtNzp5v3jm/+PnPkiQXT7soe+2+a14+YdPcftutQ39wLFEpnXt1wrIUaDeVUtZOcnIGZnbenOS6IR0VSQaKqKM/e1ROOPGUnHv+lEy98IL8Zvr0RdY59+yzsuaaa+aCqZfkH9717nz5i8clSX4zfXqmXjgl55w/JSd845Qc/ZlPp7+/f8H3vvPtb2Xs2Bf+xT4//JF/zZnnnJczzzkvm2622dAeICu0YcNKvnzoW7PHASfkFft8JvtOfmU2HTtqkXWOOWSvfGfKDXnV247J0SddlKMO3D1JMvkNm+flm43Jq/f7XLZ553E5+F07ZI3V3F6RJRuq34nHHvPZvP4Nb8x5F0zNWWefl00GfzeOG/eifOkrX8srt9p6+R4oZBkKtFrrB2utD9RaT0wyKcn/GWx1MsRuu/WWjBmzcUaPGZNVRozI5F12zZVXXLbIOldcfnl232OvJMmkHXfKDddfl1prrrziskzeZdeMGDEio0ePyZgxG+e2W29JkvTNmpWrr7oye+3zluV+TKw8tp7wgvzm3v/J3TPvzxPz+nPWtJuz23YvXWSdTcdukB/f8MskyY9v/FV2226LJMlmY0flmpunp79/fh59fG5u/fXM7Pg6/yBgyYbid+JDDz2Un/70xgW/D1cZMSJrrrlmkmTsC1+YF2ziyYat6LYb1S62QCulbPn0V5J1kwwf/PlZKaUo7pbR7L6+jNrgqURiZG9v+vr6Fl1ndl9GjdogSTJ8+PCsvsYaeeCBOenr60vvqKe+2zuqN7MHv3vs547OIR/5WIYN+8v//F/76pfylr3enC987ujMnTt3KA6LlcSGI9fKjL45C97P7JuTjdZf9PLUW381M3tMfHmSZI+JL8uaq6+adddaLbf8aqAgW/U5q2S9tVfLtlu9KKNHrbNcx8+KZyh+J86cMSPrrLNujjzisLx1nz3zqSOPyKOPPrp8DgiWYEkJ2n8s4XXc37DPTy/ug1LK/qWUm0opNz3TtQX87X585RVZd91185LNJ/zFZwcd8uGcd8HUfPf7Z+fBBx/MN0/x34C/zWFfOjdvfOW4XHfGx/PGV47LzL456e+fn8uuvytTr7kjV5z2kZx+zD/mJ7f8Lv398zs9XLpQf/+83HXnHdl3v7fnzLN/mFVXXdXvPpqwpBvVbv9sN1pKuWVxHyXpXcI+T0pyUpI8Pi/12e5/ZTGytzez7pu14P3svr709i76xzdyZG9mzbovvaNGZd68eXn4oYey9trrpLe3N32znvpu36y+jOztzZVXXJ4rr7w811x9Vf785z/nkUcezmEf/2iO+fxxWX/9kUmSESNGZI+99s7pp31z+RwoK6Tfz34wo3ufSr026l0nM//w4CLr3PeHB7PfR09Jkqy26ojsucPL8+DDjyVJjj11Wo49dVqS5LSj351f3zN7OY2cFdVQ/E7s7R2V3t5ReelLX5YkmbTjZAVao5blovmVyVAdb2+SdyV58zO87h+ifa50Np+wRe655+7MmHFvnpg7N1MvnJJtt5+4yDrbbT8x5593bpLkkoun5VWvfk1KKdl2+4mZeuGUzJ07NzNm3Jt77rk7E7Z4aT50yEdyyeVX5aJLLs/nj/titn71a3LM5wcC0T/8YeAvyFprrrjs0owbN375HjArlJtu/++Me/762XjD9bLK8J7su9OWmXLlov82W2/t1RZcv/Gx9+yU08+7PsnABIN111otSTJh/IaZMH7DXHrdXcv3AFjhDMXvxOetv356R43K3b/7bZLkJ9dfl7Ev/MsJVLC8LdOTBJ6FC5KsXmv9+dM/KKVcOUT7XOkMHz48hx1xZD6w//syf35/9txrn4wbNz7Hf+0r2XzzCdlu4g7Za5+35IhDP5bdJk/KmmutlWOP+1KSZNy48dlx8s7Za/dd0tPTk8M/cWR6enqWuL/D/vWjmTNnTmqtefGmm+aTRy62Gw3p75+fQz5/Zn50wr+kZ1jJ6eddnzt/Oyuf/MCuufmOezLlx7dmm63G56gDd0+tyTU3T8/Bx5yZJFlleE8u/ebBSZKHHn487znidC1Olmqoficeevgnc9jHP5onnngio0ePyVGfOSZJctmll+RzR/975vzxjzngg/+cF794s5x48qkdO/5u16mL9Tul1NpmJ1GLkxass/UBnR4CJEnm3Pj1Tg8BkiTPGZ6OVEoH/fCujtUFX91z0+V+zMvyqKeS5O+TjK21HlVKeX6SUbXWG4Z8dAAASYZ1V4C2TNegnZDktUnePvj+oSTHD9mIAAC63LJcg/bqWuuWpZSfJUmtdU4pZcQQjwsAoGstS4H2RCmlJxm4JqyUsn4SV/MCAMuNFudf+mqSc5OMLKV8Nsk1SY4e0lEBAHSxpSZotdbvlFJ+mmSHDNxods9a651DPjIAgEHddpuNZZnF+fwkjyb50cLLaq33DOXAAAC61bJcgzYlA9eflSTPSbJJkl8m2XwIxwUA0LWWpcW5xcLvSylbJvngkI0IAOBpTBJYilrrzUlePQRjAQAgy3YN2ocXejssyZZJfj9kIwIAeJoumyOwTNegrbHQz/MycE3a2UMzHAAAlligDd6gdo1a60eX03gAAP7CsC6L0BZ7DVopZXittT/J65fjeAAAut6SErQbMnC92c9LKecnOSvJI09+WGs9Z4jHBgDQlZblGrTnJLk/ycQ8dT+0mkSBBgAsF3/1bSdWcEsq0EYOzuC8LU8VZk+qQzoqAIAutqQCrSfJ6lm0MHuSAg0AWG66bI7AEgu0+2qtRy23kQAAkGTJBVqX1aoAQKvcZuMpOyy3UQAAsMBiC7Ra6x+X50AAABiwLLfZAADoqC7rcHbdbUUAAJonQQMAmjdMggYAQCcp0AAAGqPFCQA0z33QAADoKAkaANC8LgvQJGgAAK2RoAEAzXObDQAAOkqBBgDQGC1OAKB5Jd3V45SgAQA0RoIGADTPJAEAADpKggYANE+CBgBARynQAAAao8UJADSvdNnDOCVoAACNkaABAM0zSQAAgI5SoAEANEaLEwBoXpfNEZCgAQC0RoIGADRvWJdFaBI0AIDGSNAAgOa5zQYAAB2lQAMA+BuUUiaXUn5ZSpleSjl0CevtU0qppZStlrZNLU4AoHmtzhEopfQkOT7JpCQzktxYSjm/1nrH09ZbI8mHkvxkWbYrQQMAePZelWR6rfW3tda5Sb6XZI9nWO/fk3w+yePLslEFGgDQvGEpHXuVUvYvpdy00Gv/hYa2UZJ7F3o/Y3DZAqWULZOMqbVOWdbj1eIEAFiCWutJSU56Nt8tpQxL8sUk7/5rvqdAAwCa1+o1aElmJhmz0PvRg8uetEaSCUmuLAMHMSrJ+aWU3WutNy1uo1qcAADP3o1JxpdSNimljEiyX5Lzn/yw1vpgrfV5tdYX1FpfkOT6JEsszhIFGgDAs1ZrnZfkgCTTktyZ5Mxa6+2llKNKKbs/2+1qcQIAzWv5SQK11guTXPi0ZUcuZt3tlmWbEjQAgMZI0ACA5g1reJbAUJCgAQA0RoEGANAYLU4AoHld1uGUoAEAtEaCBgA0zyQBAAA6SoIGADSvywI0CRoAQGsUaAAAjdHiBACa122JUrcdLwBA8yRoAEDzSpfNEpCgAQA0RoEGANAYLU4AoHnd1eCUoAEANEeCBgA0z7M4AQDoKAkaANC87srPJGgAAM1RoAEANEaLEwBoXpfNEZCgAQC0RoIGADTPszgBAOgoCRoA0LxuS5S67XgBAJqnQAMAaIwWJwDQPJMEAADoKAkaANC87srPJGgAAM1RoAEANEaLE5Zgzo1f7/QQIEmyztYHdHoIkCR57Ged+b1okgAAAB0lQQMAmtdtiVK3HS8AQPMkaABA81yDBgBARynQAAAao8UJANuCdnYAABJcSURBVDSvuxqcEjQAgOZI0ACA5nXZHAEJGgBAayRoAEDzhnXZVWgSNACAxijQAAAao8UJADTPJAEAADpKggYANK+YJAAAQCcp0AAAGqPFCQA0zyQBAAA6SoIGADTPkwQAAOgoCRoA0DzXoAEA0FEKNACAxmhxAgDN0+IEAKCjJGgAQPM8ixMAgI5SoAEANEaLEwBo3rDu6nBK0AAAWiNBAwCaZ5IAAAAdJUEDAJrnRrUAAHSUAg0AoDFanABA80wSAACgoyRoAEDz3KgWAICOkqABAM1zDRoAAB2lQAMAaIwWJwDQPE8SAACgoyRoAEDzuixAk6ABALRGgQYA0BgtTgCgecO6bJaABA0AoDESNACged2Vn0nQAACaI0EDANrXZRGaBA0AoDEKNACAxmhxAgDNK13W45SgAQA0RoIGADSvy+5TK0EDAGiNBA0AaF6XBWgSNACA1ijQAAAao8UJALSvy3qcEjQAgMZI0ACA5rlRLQAAHaVAAwBojBYnANA8TxIAAKCjJGgAQPO6LECToAEAtEaCBgC0r8siNAkaAEBjFGgAAI3R4gQAmudJAgAAdJQEDQBonhvVAgCwzEopk0spvyylTC+lHPoMn3+4lHJHKeWWUsplpZSNl7ZNBRoAwLNUSulJcnySnZO8JMnbSykvedpqP0uyVa31pUl+kOTYpW1XgQYANK908LUUr0oyvdb621rr3CTfS7LHwivUWq+otT46+Pb6JKOXtlEFGgDAEpRS9i+l3LTQa/+FPt4oyb0LvZ8xuGxx3pvkoqXt0yQBAKB9HZwkUGs9KclJf+t2Sin/kGSrJNsubV0FGgDAszczyZiF3o8eXLaIUsqbkhyRZNta65+XtlEFGgDQvIZvVHtjkvGllE0yUJjtl+QdC69QSnlFkm8kmVxrnb0sG3UNGgDAs1RrnZfkgCTTktyZ5Mxa6+2llKNKKbsPrvaFJKsnOauU8vNSyvlL264EDQDgb1BrvTDJhU9bduRCP7/pr92mAg0AaJ4nCQAA0FESNACgeV0WoEnQAABaI0EDANrXZRGaBA0AoDEKNACAxmhxAgDNa/hJAkNCggYA0BgJGgDQPDeqpSnXXn1Vdt91p+w2eVJOPfmkv/h87ty5+dhHDs5ukyfl7/fbNzNnzljw2aknfyO7TZ6U3XfdKddec/WC5TtPmph99nxz3rr3Hnn7W/desPyXd92Vd77jbdlnzzfnwA++Pw8//PDQHhwrjP/t83DWffflve9+Z/Z68y7Za/dd851vn/4X2zz9tG/mZZu/OHPm/HHoDoyVxqTXbZZfnPvJ3Hbev+Wj/zjpLz5//gbr5MITD8wN3z8s007+UDYaufaCzz5z0B656azDc9NZh+ctO265PIcNi6VAa1h/f3+O/uxROeHEU3Lu+VMy9cIL8pvp0xdZ59yzz8qaa66ZC6Zekn9417vz5S8elyT5zfTpmXrhlJxz/pSc8I1TcvRnPp3+/v4F3zvl/56eM885L2ecec6CZZ8+8oh86JCP5Owf/igT3/SmnPbNU5bPgdK0oTgPe4b35KP/emjO/dGF+a8zvp/vnfHdRbY56777ct2112aDDTZcrsfKimnYsJIvH/rW7HHACXnFPp/JvpNfmU3HjlpknWMO2SvfmXJDXvW2Y3L0SRflqAMHnmE9+Q2b5+Wbjcmr9/tctnnncTn4XTtkjdWe04nDgEUMWYFWStm0lLJDKWX1py2fPFT7XNncdustGTNm44weMyarjBiRybvsmiuvuGyRda64/PLsvsdeSZJJO+6UG66/LrXWXHnFZZm8y64ZMWJERo8ekzFjNs5tt96yxP3993/fnVdutXWS5LWvfX0uu+TioTkwVihDcR6uv/7IbPaSzZMkq622esaOHZvZs/sWbO8Lnz8mh3zkYynd1tPgWdl6wgvym3v/J3fPvD9PzOvPWdNuzm7bvXSRdTYdu0F+fMMvkyQ/vvFX2W27LZIkm40dlWtunp7+/vl59PG5ufXXM7Pj6zZb7sfA0pUOvjphSAq0UspBSc5LcmCS20opeyz08dFDsc+V0ey+voza4Kl/BY7s7U1fX9+i68zuy6hRGyRJhg8fntXXWCMPPDAnfX196R311Hd7R/Vm9pPfLcn7/+m92W/fvfODM7+/YJ0XjhufKy4f+Iv34mlTM2vWfUN1aKxAhuw8HDRz5ozcdeed2eKlL0uSXHH5pRnZOzIv3nTToTokVjIbjlwrM/rmLHg/s29ONlp/rUXWufVXM7PHxJcnSfaY+LKsufqqWXet1XLLrwYKslWfs0rWW3u1bLvVizJ61DrLdfzwTIZqksA/JXllrfXhUsoLkvyglPKCWutXsoRitJSyf5L9k+TrJ3wj7/2n/YdoeN3ttG+fkd7e3tx///15//v+MZuMHZtXbrV1Pv3vn83njvlsTjrxhGy3/cSsssqITg+VldyjjzySjxx8UD526OFZffXV89hjj+WUk76RE0/+ZqeHxkrmsC+dmy99fN/8w+6vzrU3T8/Mvjnp75+fy66/K6/cfONccdpH8j9zHs5Pbvld+vvnd3q4PJMuC9SHqkAbVmt9OElqrXeXUrbLQJG2cZbwR1xrPSnJSUny+LzUIRrbCmNkb29m3TdrwfvZfX3p7e1ddJ2RvZk16770jhqVefPm5eGHHsraa6+T3t7e9M166rt9s/oycvC7T25jvfXWy8Q3Tcptt96SV261dTYZ+8J8Y/Avxrvv/l2u+vGVQ3yErAiG6jx84okn8uGDD8ouu745b5q0Y5Jkxr33ZObMGXnr3gOhe1/frOz3lr3zne+dleetv/5QHyorqN/PfjCje59KvTbqXScz//DgIuvc94cHs99HB66rXW3VEdlzh5fnwYcfS5Ice+q0HHvqtCTJaUe/O7++Z/ZyGjks3lBdg9ZXSnn5k28Gi7XdkjwvyRZDtM+VzuYTtsg999ydGTPuzRNz52bqhVOy7fYTF1lnu+0n5vzzzk2SXHLxtLzq1a9JKSXbbj8xUy+ckrlz52bGjHtzzz13Z8IWL82jjz6aRx4ZmJ356KOP5rr/d23GjRufJLn//vuTJPPnz8/J3/jP7Pu2/Zbj0dKqoTgPa6351JFHZOzYsXnXu/9xwXbGv+jFufLq63LRJZfnoksuT2/vqHzvB+cozliim27/74x7/vrZeMP1ssrwnuy705aZcuWi19yut/ZqC65p/Nh7dsrp512fZGCCwbprrZYkmTB+w0wYv2Euve6u5XsALJPSwf91wlAlaO9KMm/hBbXWeUneVUr5xhDtc6UzfPjwHHbEkfnA/u/L/Pn92XOvfTJu3Pgc/7WvZPPNJ2S7iTtkr33ekiMO/Vh2mzwpa661Vo497ktJknHjxmfHyTtnr913SU9PTw7/xJHp6enJH++/P4cc9C9Jknn9/dll193y+jdukySZeuEF+d4Z302S7PCmSdlzr306c+A0ZSjOw5t/elMuOP+8jH/RixakZQce/OG8cZttO3morKD6++fnkM+fmR+d8C/pGVZy+nnX587fzsonP7Brbr7jnkz58a3ZZqvxOerA3VNrcs3N03PwMWcmSVYZ3pNLv3lwkuShhx/Pe444XYuTJpRa2+wkanECPGWdrQ/o9BAgSfLYz77ekUjprvse7VhdsOkGz13ux+xJAgBA87rtrjtuVAsA0BgJGgDQvC4L0CRoAACtkaABAO3rsghNggYA0BgFGgBAY7Q4AYDmdeqO/p0iQQMAaIwEDQBonhvVAgDQUQo0AIDGaHECAM3rsg6nBA0AoDUSNACgfV0WoUnQAAAaI0EDAJrnRrUAAHSUAg0AoDFanABA8zxJAACAjpKgAQDN67IATYIGANAaBRoAQGO0OAGA9nVZj1OCBgDQGAkaANA8TxIAAKCjJGgAQPPcqBYAgI5SoAEANEaLEwBoXpd1OCVoAACtkaABAM0zSQAAgI6SoAEAK4DuitAkaAAAjVGgAQA0RosTAGieSQIAAHSUBA0AaF6XBWgSNACA1ijQAAAao8UJADTPJAEAADpKggYANK902TQBCRoAQGMkaABA+7orQJOgAQC0RoEGANAYLU4AoHld1uGUoAEAtEaCBgA0z41qAQDoKAkaANA8N6oFAKCjFGgAAI3R4gQA2tddHU4JGgBAayRoAEDzuixAk6ABALRGgQYA0BgtTgCgeZ4kAABAR0nQAIDmeZIAAAAdJUEDAJrnGjQAADpKgQYA0BgFGgBAYxRoAACNMUkAAGieSQIAAHSUBA0AaJ4b1QIA0FEKNACAxmhxAgDNM0kAAICOkqABAM3rsgBNggYA0BoFGgBAY7Q4AYD2dVmPU4IGANAYCRoA0DxPEgAAoKMkaABA89yoFgCAjlKgAQA0RosTAGhel3U4JWgAAK2RoAEA7euyCE2CBgDQGAUaAEBjtDgBgOZ5kgAAAB0lQQMAmudJAgAAdFSptXZ6DAyRUsr+tdaTOj0OcC7SAuchKxIJ2spt/04PAAY5F2mB85AVhgINAKAxCjQAgMYo0FZurrWgFc5FWuA8ZIVhkgAAQGMkaAAAjVGgAQA0RoG2kiqlTC6l/LKUMr2Ucminx0N3KqV8s5Qyu5RyW6fHQvcqpYwppVxRSrmjlHJ7KeVDnR4TLI1r0FZCpZSeJL9KMinJjCQ3Jnl7rfWOjg6MrlNK2SbJw0m+VWud0Onx0J1KKRsk2aDWenMpZY0kP02yp9+JtEyCtnJ6VZLptdbf1lrnJvlekj06PCa6UK31qiR/7PQ46G611vtqrTcP/vxQkjuTbNTZUcGSKdBWThsluXeh9zPilxFASikvSPKKJD/p7EhgyRRoAHSFUsrqSc5OcnCt9U+dHg8siQJt5TQzyZiF3o8eXAbQlUopq2SgOPtOrfWcTo8HlkaBtnK6Mcn4UsompZQRSfZLcn6HxwTQEaWUkuTUJHfWWr/Y6fHAslCgrYRqrfOSHJBkWgYuhj2z1np7Z0dFNyqlnJHkuiQvLqXMKKW8t9Njoiu9Psk7k0wspfx88LVLpwcFS+I2GwAAjZGgAQA0RoEGANAYBRoAQGMUaAAAjVGgAQA0RoEGK6FSSv/grQRuK6WcVUp57t+wrdNKKW8Z/PmUUspLlrDudqWU1z2LfdxdSnnesi5/2joP/5X7+lQp5aN/7RgBlicFGqycHqu1vrzWOiHJ3CTvX/jDUsrwZ7PRWuv7aq13LGGV7ZL81QUaAItSoMHK7+ok4wbTratLKecnuaOU0lNK+UIp5cZSyi2llH9OBu66Xkr5einll6WUS5OMfHJDpZQrSylbDf48uZRycynlF6WUywYfQv3+JIcMpndvLKWsX0o5e3AfN5ZSXj/43fVKKReXUm4vpZySpCztIEopPyyl/HTwO/s/7bMvDS6/rJSy/uCyF5ZSpg5+5+pSyqb/G3+YAMvDs/pXNLBiGEzKdk4ydXDRlkkm1Fp/N1jkPFhr3bqU8ndJri2lXJzkFUlenOQlSXqT3JHkm0/b7vpJTk6yzeC21q21/rGUcmKSh2utxw2u990kX6q1XlNKeX4Gnm6xWZJ/S3JNrfWoUsquSZblCQPvGdzHqkluLKWcXWu9P8lqSW6qtR5SSjlycNsHJDkpyftrrb8upbw6yQlJJj6LP0aA5U6BBiunVUspPx/8+eoMPIfwdUluqLX+bnD5jkle+uT1ZUnWSjI+yTZJzqi19if5fSnl8mfY/muSXPXktmqtf1zMON6U5CUDj0JMkqxZSll9cB97D353SillzjIc00GllL0Gfx4zONb7k8xP8v3B5f+V5JzBfbwuyVkL7fvvlmEfAE1QoMHK6bFa68sXXjBYqDyy8KIkB9Zapz1tvf/NZxQOS/KaWuvjzzCWZVZK2S4Dxd5ra62PllKuTPKcxaxeB/f7wNP/DABWFK5Bg+41LckHSimrJEkp5UWllNWSXJXkbYPXqG2QZPtn+O71SbYppWwy+N11B5c/lGSNhda7OMmBT74ppTxZMF2V5B2Dy3ZOss5SxrpWkjmDxdmmGUjwnjQsyZMp4Dsy0Dr9U5LflVL2HdxHKaW8bCn7AGiGAg261ykZuL7s5lLKbUm+kYFU/dwkvx787FtJrnv6F2utf0iyfwbaib/IUy3GHyXZ68lJAkkOSrLV4CSEO/LUbNJPZ6DAuz0Drc57ljLWqUmGl1LuTPK5DBSIT3okyasGj2FikqMGl/99kvcOju/2JHssw58JQBNKrbXTYwAAYCESNACAxijQAAAao0ADAGiMAg0AoDEKNACAxijQAAAao0ADAGjM/wfy6YyUl8KC3wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7fcxLuwZpkK",
        "outputId": "d6f7c03f-0164-4941-9d18-7fa642c8ddc7"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "d37b5f84-b885-43b8-992a-b5eb9710a87e"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 5s 64ms/step - loss: 1.1836 - accuracy: 0.3873 - val_loss: 1.0644 - val_accuracy: 0.3968\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0799 - accuracy: 0.3932 - val_loss: 1.0609 - val_accuracy: 0.4155\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0738 - accuracy: 0.4013 - val_loss: 1.0439 - val_accuracy: 0.4571\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0629 - accuracy: 0.4332 - val_loss: 1.0406 - val_accuracy: 0.4491\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0626 - accuracy: 0.4316 - val_loss: 1.0376 - val_accuracy: 0.4799\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0630 - accuracy: 0.4345 - val_loss: 1.0454 - val_accuracy: 0.4692\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0507 - accuracy: 0.4349 - val_loss: 1.0372 - val_accuracy: 0.4853\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0493 - accuracy: 0.4566 - val_loss: 1.0296 - val_accuracy: 0.4826\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0465 - accuracy: 0.4515 - val_loss: 1.0378 - val_accuracy: 0.4464\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0494 - accuracy: 0.4378 - val_loss: 1.0305 - val_accuracy: 0.4799\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0441 - accuracy: 0.4625 - val_loss: 1.0218 - val_accuracy: 0.4786\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0364 - accuracy: 0.4669 - val_loss: 1.0294 - val_accuracy: 0.4799\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0509 - accuracy: 0.4525 - val_loss: 1.0228 - val_accuracy: 0.4786\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0328 - accuracy: 0.4722 - val_loss: 1.0221 - val_accuracy: 0.4759\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0308 - accuracy: 0.4767 - val_loss: 1.0161 - val_accuracy: 0.4879\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 52ms/step - loss: 1.0306 - accuracy: 0.4774 - val_loss: 1.0133 - val_accuracy: 0.4759\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0310 - accuracy: 0.4713 - val_loss: 1.0253 - val_accuracy: 0.4464\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0346 - accuracy: 0.4741 - val_loss: 1.0165 - val_accuracy: 0.4678\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0306 - accuracy: 0.4682 - val_loss: 1.0157 - val_accuracy: 0.4651\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0259 - accuracy: 0.4792 - val_loss: 1.0323 - val_accuracy: 0.4611\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0301 - accuracy: 0.4794 - val_loss: 1.0172 - val_accuracy: 0.4625\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0251 - accuracy: 0.4768 - val_loss: 1.0098 - val_accuracy: 0.4786\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0203 - accuracy: 0.4766 - val_loss: 1.0091 - val_accuracy: 0.4866\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0159 - accuracy: 0.4829 - val_loss: 1.0002 - val_accuracy: 0.4893\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0283 - accuracy: 0.4745 - val_loss: 0.9999 - val_accuracy: 0.4879\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0237 - accuracy: 0.4802 - val_loss: 1.0087 - val_accuracy: 0.4625\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0207 - accuracy: 0.4777 - val_loss: 1.0210 - val_accuracy: 0.4732\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0114 - accuracy: 0.4870 - val_loss: 0.9986 - val_accuracy: 0.4879\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0075 - accuracy: 0.4883 - val_loss: 0.9926 - val_accuracy: 0.4879\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0093 - accuracy: 0.4883 - val_loss: 1.0222 - val_accuracy: 0.4410\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0149 - accuracy: 0.4841 - val_loss: 1.0168 - val_accuracy: 0.4920\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0054 - accuracy: 0.4891 - val_loss: 0.9974 - val_accuracy: 0.5013\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0011 - accuracy: 0.4933 - val_loss: 0.9833 - val_accuracy: 0.5241\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0010 - accuracy: 0.4912 - val_loss: 0.9872 - val_accuracy: 0.4987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9954 - accuracy: 0.4920 - val_loss: 0.9794 - val_accuracy: 0.5174\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9911 - accuracy: 0.4976 - val_loss: 1.0137 - val_accuracy: 0.4853\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9939 - accuracy: 0.4925 - val_loss: 0.9839 - val_accuracy: 0.5161\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9967 - accuracy: 0.4991 - val_loss: 0.9826 - val_accuracy: 0.5107\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9900 - accuracy: 0.4988 - val_loss: 0.9744 - val_accuracy: 0.5349\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 52ms/step - loss: 0.9836 - accuracy: 0.5010 - val_loss: 0.9609 - val_accuracy: 0.5268\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9844 - accuracy: 0.5003 - val_loss: 0.9803 - val_accuracy: 0.5362\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 52ms/step - loss: 0.9791 - accuracy: 0.5036 - val_loss: 0.9638 - val_accuracy: 0.5147\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9682 - accuracy: 0.5171 - val_loss: 0.9643 - val_accuracy: 0.5402\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9752 - accuracy: 0.5101 - val_loss: 0.9794 - val_accuracy: 0.5322\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9735 - accuracy: 0.5085 - val_loss: 0.9632 - val_accuracy: 0.5389\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9832 - accuracy: 0.5031 - val_loss: 0.9696 - val_accuracy: 0.5121\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9675 - accuracy: 0.5152 - val_loss: 0.9613 - val_accuracy: 0.5174\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9686 - accuracy: 0.5107 - val_loss: 0.9414 - val_accuracy: 0.5429\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9484 - accuracy: 0.5276 - val_loss: 0.9749 - val_accuracy: 0.5214\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9555 - accuracy: 0.5261 - val_loss: 0.9464 - val_accuracy: 0.5389\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9477 - accuracy: 0.5207 - val_loss: 0.9275 - val_accuracy: 0.5550\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9331 - accuracy: 0.5374 - val_loss: 0.9973 - val_accuracy: 0.4906\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9363 - accuracy: 0.5367 - val_loss: 0.9076 - val_accuracy: 0.5684\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9242 - accuracy: 0.5443 - val_loss: 0.9228 - val_accuracy: 0.5442\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9130 - accuracy: 0.5480 - val_loss: 0.9316 - val_accuracy: 0.5536\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9074 - accuracy: 0.5507 - val_loss: 0.9208 - val_accuracy: 0.5536\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9054 - accuracy: 0.5659 - val_loss: 0.8955 - val_accuracy: 0.5831\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8957 - accuracy: 0.5647 - val_loss: 0.9514 - val_accuracy: 0.5335\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8801 - accuracy: 0.5844 - val_loss: 0.8945 - val_accuracy: 0.5536\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8684 - accuracy: 0.5778 - val_loss: 0.8749 - val_accuracy: 0.5697\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8610 - accuracy: 0.5981 - val_loss: 0.8532 - val_accuracy: 0.5965\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8606 - accuracy: 0.5917 - val_loss: 0.7606 - val_accuracy: 0.6609\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.8464 - accuracy: 0.6018 - val_loss: 0.7755 - val_accuracy: 0.6649\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8294 - accuracy: 0.6109 - val_loss: 0.7674 - val_accuracy: 0.6434\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8067 - accuracy: 0.6264 - val_loss: 0.7947 - val_accuracy: 0.6555\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7767 - accuracy: 0.6428 - val_loss: 0.7395 - val_accuracy: 0.6769\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7719 - accuracy: 0.6519 - val_loss: 0.8586 - val_accuracy: 0.5871\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7504 - accuracy: 0.6624 - val_loss: 0.6447 - val_accuracy: 0.7386\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.7342 - accuracy: 0.6736 - val_loss: 0.7576 - val_accuracy: 0.6622\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.7105 - accuracy: 0.6905 - val_loss: 0.6192 - val_accuracy: 0.7534\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.6786 - accuracy: 0.7082 - val_loss: 0.6950 - val_accuracy: 0.6702\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.6378 - accuracy: 0.7222 - val_loss: 0.5900 - val_accuracy: 0.7480\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.6085 - accuracy: 0.7444 - val_loss: 0.5744 - val_accuracy: 0.7560\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.5926 - accuracy: 0.7511 - val_loss: 0.5280 - val_accuracy: 0.7694\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.5704 - accuracy: 0.7715 - val_loss: 0.5232 - val_accuracy: 0.7842\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.5387 - accuracy: 0.7829 - val_loss: 0.4868 - val_accuracy: 0.7962\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.4848 - accuracy: 0.8039 - val_loss: 0.4392 - val_accuracy: 0.8351\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.4546 - accuracy: 0.8231 - val_loss: 0.3814 - val_accuracy: 0.8566\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.4311 - accuracy: 0.8306 - val_loss: 0.4962 - val_accuracy: 0.7855\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.4285 - accuracy: 0.8301 - val_loss: 0.4935 - val_accuracy: 0.8003\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.3704 - accuracy: 0.8596 - val_loss: 0.3521 - val_accuracy: 0.8499\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.3522 - accuracy: 0.8686 - val_loss: 0.2961 - val_accuracy: 0.8794\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3227 - accuracy: 0.8760 - val_loss: 0.3190 - val_accuracy: 0.8820\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3242 - accuracy: 0.8844 - val_loss: 0.3437 - val_accuracy: 0.8566\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3128 - accuracy: 0.8854 - val_loss: 0.2802 - val_accuracy: 0.8887\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2990 - accuracy: 0.8887 - val_loss: 0.2611 - val_accuracy: 0.9021\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2341 - accuracy: 0.9204 - val_loss: 0.2243 - val_accuracy: 0.9209\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2531 - accuracy: 0.9112 - val_loss: 0.3240 - val_accuracy: 0.8673\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2227 - accuracy: 0.9186 - val_loss: 0.3019 - val_accuracy: 0.8954\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2276 - accuracy: 0.9165 - val_loss: 0.2070 - val_accuracy: 0.9276\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2475 - accuracy: 0.9104 - val_loss: 0.0425 - val_accuracy: 0.9866\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2256 - accuracy: 0.9221 - val_loss: 0.0326 - val_accuracy: 0.9920\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1941 - accuracy: 0.9341 - val_loss: 0.0278 - val_accuracy: 0.9946\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.1994 - accuracy: 0.9295 - val_loss: 0.0390 - val_accuracy: 0.9893\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.1841 - accuracy: 0.9399 - val_loss: 0.0317 - val_accuracy: 0.9920\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1596 - accuracy: 0.9465 - val_loss: 0.0306 - val_accuracy: 0.9879\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1626 - accuracy: 0.9422 - val_loss: 0.0298 - val_accuracy: 0.9893\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1578 - accuracy: 0.9469 - val_loss: 0.0242 - val_accuracy: 0.9973\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1494 - accuracy: 0.9463 - val_loss: 0.0221 - val_accuracy: 0.9920\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1253 - accuracy: 0.9547 - val_loss: 0.0385 - val_accuracy: 0.9853\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1373 - accuracy: 0.9529 - val_loss: 0.0222 - val_accuracy: 0.9946\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1212 - accuracy: 0.9613 - val_loss: 0.0180 - val_accuracy: 0.9973\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1346 - accuracy: 0.9556 - val_loss: 0.0296 - val_accuracy: 0.9879\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1033 - accuracy: 0.9666 - val_loss: 0.0142 - val_accuracy: 0.9946\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1125 - accuracy: 0.9638 - val_loss: 0.0220 - val_accuracy: 0.9920\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1241 - accuracy: 0.9592 - val_loss: 0.0190 - val_accuracy: 0.9960\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1045 - accuracy: 0.9674 - val_loss: 0.0223 - val_accuracy: 0.9946\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0949 - accuracy: 0.9675 - val_loss: 0.0343 - val_accuracy: 0.9906\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1073 - accuracy: 0.9629 - val_loss: 0.0325 - val_accuracy: 0.9879\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1033 - accuracy: 0.9663 - val_loss: 0.0398 - val_accuracy: 0.9826\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0825 - accuracy: 0.9726 - val_loss: 0.0201 - val_accuracy: 0.9960\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1000 - accuracy: 0.9677 - val_loss: 0.0304 - val_accuracy: 0.9893\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0941 - accuracy: 0.9694 - val_loss: 0.0243 - val_accuracy: 0.9933\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0832 - accuracy: 0.9729 - val_loss: 0.0191 - val_accuracy: 0.9920\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0852 - accuracy: 0.9726 - val_loss: 0.0152 - val_accuracy: 0.9960\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0858 - accuracy: 0.9715 - val_loss: 0.0237 - val_accuracy: 0.9933\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0737 - accuracy: 0.9770 - val_loss: 0.0102 - val_accuracy: 0.9973\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0815 - accuracy: 0.9696 - val_loss: 0.0223 - val_accuracy: 0.9933\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0909 - accuracy: 0.9718 - val_loss: 0.0385 - val_accuracy: 0.9879\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0712 - accuracy: 0.9772 - val_loss: 0.0193 - val_accuracy: 0.9973\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0912 - accuracy: 0.9689 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0815 - accuracy: 0.9756 - val_loss: 4.8177e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0732 - accuracy: 0.9757 - val_loss: 9.1780e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0860 - accuracy: 0.9717 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0663 - accuracy: 0.9791 - val_loss: 6.2519e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0654 - accuracy: 0.9793 - val_loss: 5.9535e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0829 - accuracy: 0.9721 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0724 - accuracy: 0.9762 - val_loss: 6.8050e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0660 - accuracy: 0.9760 - val_loss: 6.4259e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0789 - accuracy: 0.9747 - val_loss: 0.0045 - val_accuracy: 0.9973\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0680 - accuracy: 0.9794 - val_loss: 0.0044 - val_accuracy: 0.9973\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0546 - accuracy: 0.9830 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0677 - accuracy: 0.9776 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0631 - accuracy: 0.9797 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0679 - accuracy: 0.9778 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0455 - accuracy: 0.9864 - val_loss: 2.0917e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0556 - accuracy: 0.9812 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0534 - accuracy: 0.9814 - val_loss: 0.0027 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0528 - accuracy: 0.9832 - val_loss: 0.0017 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0587 - accuracy: 0.9806 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0682 - accuracy: 0.9784 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0560 - accuracy: 0.9829 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0403 - accuracy: 0.9854 - val_loss: 7.0536e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0536 - accuracy: 0.9824 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.0420 - accuracy: 0.9867 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0499 - accuracy: 0.9838 - val_loss: 8.2897e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0507 - accuracy: 0.9838 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0431 - accuracy: 0.9852 - val_loss: 0.0022 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0558 - accuracy: 0.9835 - val_loss: 0.0043 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.0690 - accuracy: 0.9781 - val_loss: 0.0179 - val_accuracy: 0.9933\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0508 - accuracy: 0.9826 - val_loss: 7.3093e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.0604 - accuracy: 0.9820 - val_loss: 4.9419e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0526 - accuracy: 0.9826 - val_loss: 1.2639e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0485 - accuracy: 0.9848 - val_loss: 1.1241e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0598 - accuracy: 0.9808 - val_loss: 7.6798e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0494 - accuracy: 0.9838 - val_loss: 8.1040e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0310 - accuracy: 0.9902 - val_loss: 5.4207e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0528 - accuracy: 0.9841 - val_loss: 8.0121e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0564 - accuracy: 0.9841 - val_loss: 3.2452e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0398 - accuracy: 0.9875 - val_loss: 2.0049e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0398 - accuracy: 0.9870 - val_loss: 1.0672e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0383 - accuracy: 0.9881 - val_loss: 1.1664e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0459 - accuracy: 0.9842 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0455 - accuracy: 0.9848 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0435 - accuracy: 0.9870 - val_loss: 1.7200e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0452 - accuracy: 0.9858 - val_loss: 1.7783e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0396 - accuracy: 0.9876 - val_loss: 3.0833e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0479 - accuracy: 0.9845 - val_loss: 9.5801e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0494 - accuracy: 0.9842 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0398 - accuracy: 0.9884 - val_loss: 7.6788e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0383 - accuracy: 0.9879 - val_loss: 5.7011e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0390 - accuracy: 0.9872 - val_loss: 1.7140e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0459 - accuracy: 0.9864 - val_loss: 4.4392e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0387 - accuracy: 0.9878 - val_loss: 1.3184e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0397 - accuracy: 0.9882 - val_loss: 1.8812e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0410 - accuracy: 0.9869 - val_loss: 5.0908e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0403 - accuracy: 0.9858 - val_loss: 1.5593e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0418 - accuracy: 0.9851 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0367 - accuracy: 0.9860 - val_loss: 2.0814e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0326 - accuracy: 0.9896 - val_loss: 6.3596e-05 - val_accuracy: 1.0000\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0414 - accuracy: 0.9872 - val_loss: 1.0973e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0364 - accuracy: 0.9872 - val_loss: 4.5386e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0472 - accuracy: 0.9847 - val_loss: 8.4287e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0437 - accuracy: 0.9866 - val_loss: 9.8107e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0385 - accuracy: 0.9881 - val_loss: 3.0462e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0411 - accuracy: 0.9882 - val_loss: 4.1512e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0410 - accuracy: 0.9876 - val_loss: 3.9938e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0278 - accuracy: 0.9923 - val_loss: 6.5527e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0432 - accuracy: 0.9872 - val_loss: 5.6146e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0418 - accuracy: 0.9861 - val_loss: 5.2077e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0502 - accuracy: 0.9850 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0369 - accuracy: 0.9885 - val_loss: 3.5137e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0355 - accuracy: 0.9864 - val_loss: 4.1911e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0321 - accuracy: 0.9909 - val_loss: 1.1668e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0302 - accuracy: 0.9908 - val_loss: 1.5712e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0371 - accuracy: 0.9891 - val_loss: 8.3149e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0368 - accuracy: 0.9893 - val_loss: 9.1101e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0300 - accuracy: 0.9917 - val_loss: 7.6210e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0374 - accuracy: 0.9894 - val_loss: 5.4972e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0381 - accuracy: 0.9872 - val_loss: 5.0750e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0386 - accuracy: 0.9888 - val_loss: 3.8480e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.0310 - accuracy: 0.9897 - val_loss: 7.7872e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0384 - accuracy: 0.9878 - val_loss: 1.6080e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0353 - accuracy: 0.9900 - val_loss: 7.2443e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0285 - accuracy: 0.9911 - val_loss: 6.9978e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0287 - accuracy: 0.9912 - val_loss: 2.7805e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0374 - accuracy: 0.9888 - val_loss: 1.8665e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0377 - accuracy: 0.9893 - val_loss: 9.5582e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0344 - accuracy: 0.9902 - val_loss: 2.3399e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0319 - accuracy: 0.9903 - val_loss: 3.0873e-05 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0287 - accuracy: 0.9900 - val_loss: 1.4520e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0267 - accuracy: 0.9906 - val_loss: 9.3912e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0249 - accuracy: 0.9917 - val_loss: 1.9217e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0321 - accuracy: 0.9902 - val_loss: 3.0585e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0342 - accuracy: 0.9915 - val_loss: 3.4114e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0379 - accuracy: 0.9887 - val_loss: 9.0862e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0341 - accuracy: 0.9897 - val_loss: 8.6045e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0266 - accuracy: 0.9924 - val_loss: 1.5765e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0312 - accuracy: 0.9905 - val_loss: 3.1277e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0359 - accuracy: 0.9887 - val_loss: 3.2945e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0290 - accuracy: 0.9911 - val_loss: 2.1030e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0266 - accuracy: 0.9902 - val_loss: 1.5696e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0193 - accuracy: 0.9928 - val_loss: 7.8898e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0261 - accuracy: 0.9930 - val_loss: 1.8165e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0254 - accuracy: 0.9908 - val_loss: 3.1302e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0359 - accuracy: 0.9878 - val_loss: 5.4457e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0322 - accuracy: 0.9893 - val_loss: 7.8752e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0287 - accuracy: 0.9911 - val_loss: 1.5072e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0408 - accuracy: 0.9882 - val_loss: 2.4831e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0382 - accuracy: 0.9876 - val_loss: 2.1240e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0270 - accuracy: 0.9903 - val_loss: 6.4402e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0373 - accuracy: 0.9869 - val_loss: 4.5870e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0261 - accuracy: 0.9909 - val_loss: 3.2915e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0324 - accuracy: 0.9909 - val_loss: 1.0944e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0264 - accuracy: 0.9902 - val_loss: 6.0592e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0218 - accuracy: 0.9923 - val_loss: 1.3186e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0286 - accuracy: 0.9914 - val_loss: 1.6771e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0250 - accuracy: 0.9928 - val_loss: 6.0164e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0275 - accuracy: 0.9914 - val_loss: 3.7115e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0242 - accuracy: 0.9924 - val_loss: 6.5871e-05 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0358 - accuracy: 0.9890 - val_loss: 7.9530e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0253 - accuracy: 0.9917 - val_loss: 1.0550e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0380 - accuracy: 0.9890 - val_loss: 3.2462e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0291 - accuracy: 0.9902 - val_loss: 1.3012e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0323 - accuracy: 0.9906 - val_loss: 3.0901e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0380 - accuracy: 0.9879 - val_loss: 3.7806e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0292 - accuracy: 0.9912 - val_loss: 2.7822e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0297 - accuracy: 0.9897 - val_loss: 4.2960e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0259 - accuracy: 0.9912 - val_loss: 2.4193e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0210 - accuracy: 0.9930 - val_loss: 8.1565e-06 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0217 - accuracy: 0.9931 - val_loss: 8.8344e-06 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0202 - accuracy: 0.9931 - val_loss: 4.6774e-06 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0309 - accuracy: 0.9903 - val_loss: 1.0981e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0279 - accuracy: 0.9908 - val_loss: 2.2525e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0240 - accuracy: 0.9927 - val_loss: 1.1178e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0227 - accuracy: 0.9927 - val_loss: 2.5859e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0214 - accuracy: 0.9937 - val_loss: 1.0324e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0252 - accuracy: 0.9934 - val_loss: 3.6121e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0300 - accuracy: 0.9906 - val_loss: 2.7112e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0292 - accuracy: 0.9920 - val_loss: 2.1525e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0283 - accuracy: 0.9911 - val_loss: 2.5321e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0259 - accuracy: 0.9924 - val_loss: 1.9446e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0234 - accuracy: 0.9925 - val_loss: 3.6326e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0150 - accuracy: 0.9946 - val_loss: 2.0890e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0332 - accuracy: 0.9912 - val_loss: 3.2695e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0219 - accuracy: 0.9928 - val_loss: 1.8480e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0206 - accuracy: 0.9936 - val_loss: 3.1956e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0228 - accuracy: 0.9933 - val_loss: 9.6408e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0219 - accuracy: 0.9934 - val_loss: 1.2808e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0204 - accuracy: 0.9923 - val_loss: 2.5101e-05 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0305 - accuracy: 0.9893 - val_loss: 8.5716e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0259 - accuracy: 0.9924 - val_loss: 9.7816e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0188 - accuracy: 0.9934 - val_loss: 1.1291e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0284 - accuracy: 0.9912 - val_loss: 4.4264e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0283 - accuracy: 0.9924 - val_loss: 2.7427e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0244 - accuracy: 0.9925 - val_loss: 2.0968e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0239 - accuracy: 0.9928 - val_loss: 1.7623e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0301 - accuracy: 0.9912 - val_loss: 1.5145e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0226 - accuracy: 0.9937 - val_loss: 1.3045e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0221 - accuracy: 0.9930 - val_loss: 3.4610e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0247 - accuracy: 0.9923 - val_loss: 4.0854e-06 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0299 - accuracy: 0.9911 - val_loss: 2.6148e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0218 - accuracy: 0.9945 - val_loss: 3.0044e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0176 - accuracy: 0.9948 - val_loss: 5.2197e-06 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0289 - accuracy: 0.9927 - val_loss: 4.4022e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0360 - accuracy: 0.9885 - val_loss: 6.5084e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0154 - accuracy: 0.9943 - val_loss: 2.8910e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0229 - accuracy: 0.9936 - val_loss: 1.0325e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0164 - accuracy: 0.9943 - val_loss: 1.4179e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0251 - accuracy: 0.9917 - val_loss: 1.0825e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 5.2253e-06 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0165 - accuracy: 0.9948 - val_loss: 9.1253e-06 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0294 - accuracy: 0.9906 - val_loss: 1.5350e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0397 - accuracy: 0.9875 - val_loss: 2.7945e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0253 - accuracy: 0.9920 - val_loss: 1.3449e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0219 - accuracy: 0.9930 - val_loss: 6.5522e-06 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0215 - accuracy: 0.9934 - val_loss: 3.4429e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0247 - accuracy: 0.9931 - val_loss: 2.2895e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0196 - accuracy: 0.9934 - val_loss: 3.5553e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0251 - accuracy: 0.9923 - val_loss: 4.3031e-04 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "797b534e-cdef-4d7b-b891-1beda5af0e62"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 7ms/step - loss: 0.0422 - accuracy: 0.9893\n",
            "Accuracy  : 0.9892703890800476\n",
            "F1_Score  : 0.9890888627719647\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "480ddc85-1b50-4995-f843-769a8ed25d39"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'#dominance\\nX_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\\nprint(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "378d2e16-3599-41d1-b0a7-dc9786f61c7d"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'foldNum=0\\nmodel = get_model()\\nfor train_index, val_index in kfold.split(X_train, Y_train):\\n  foldNum = foldNum + 1\\n  print(\"Results for fold\",foldNum)\\n  x_train, x_val = X_train[train_index], X_train[val_index]\\n  y_train, y_val = Y_train[train_index], Y_train[val_index]\\n  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\\n  gc.collect() # Garbage collecter\\n  del x_train, x_val, y_train, y_val\\n  gc.collect()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "5abf7d41-15f9-4337-9d39-9aadd040f9a7"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'acrc = model.evaluate(x_test, y_test)\\npred = model.predict(x_test)\\nf1scr = f1_score(y_test.argmax(1), pred.argmax(1), average=\\'macro\\')\\nc_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\\nprint(\"Accuracy  : {}\".format(acrc[1]))\\nprint(\"F1_Score  : {}\".format(f1scr))\\nc_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\\nimport seaborn as sns\\nfigure = plt.figure(figsize=(9, 9))\\nsns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\\nplt.tight_layout()\\nplt.ylabel(\\'True label\\')\\nplt.xlabel(\\'Predicted label\\')\\nplt.show()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}