{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub20_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "42c3e45c-3dc6-476f-ab1e-14d6a66e5aa4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e3\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  #EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "9a0c1655-e862-4dc4-d2da-1284ecee3282"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(20,21):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.20\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (1631,) (3961,) (3728,)\n",
            "(9320,) (1165,) (4893,) (3262,)\n",
            "(9320,) (3495,) (4427,) (1398,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "2a9387eb-12c9-4756-c5d5-3202b7d8f8d2"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "c29ab539-0215-4018-afc0-5c4b5768fd31"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "622"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "8b9354d0-f375-444b-909f-28fd050e865d"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70a11d65-e500-4321-f1e9-e71721f0f550"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 50s 61ms/step - loss: 1.1154 - accuracy: 0.4127 - val_loss: 1.0278 - val_accuracy: 0.4410\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0515 - accuracy: 0.4140 - val_loss: 1.0320 - val_accuracy: 0.4397\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0477 - accuracy: 0.4381 - val_loss: 1.0321 - val_accuracy: 0.4182\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0372 - accuracy: 0.4418 - val_loss: 1.0243 - val_accuracy: 0.4316\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0336 - accuracy: 0.4548 - val_loss: 1.0212 - val_accuracy: 0.4504\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0345 - accuracy: 0.4426 - val_loss: 1.0187 - val_accuracy: 0.4531\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0371 - accuracy: 0.4467 - val_loss: 1.0198 - val_accuracy: 0.4290\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0277 - accuracy: 0.4496 - val_loss: 1.0269 - val_accuracy: 0.4598\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0296 - accuracy: 0.4494 - val_loss: 1.0155 - val_accuracy: 0.4665\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0270 - accuracy: 0.4556 - val_loss: 1.0103 - val_accuracy: 0.4584\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0265 - accuracy: 0.4516 - val_loss: 1.0069 - val_accuracy: 0.4598\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0207 - accuracy: 0.4655 - val_loss: 1.0086 - val_accuracy: 0.4651\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0150 - accuracy: 0.4704 - val_loss: 1.0175 - val_accuracy: 0.4718\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0202 - accuracy: 0.4680 - val_loss: 1.0100 - val_accuracy: 0.4718\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0268 - accuracy: 0.4582 - val_loss: 1.0209 - val_accuracy: 0.4692\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0138 - accuracy: 0.4766 - val_loss: 1.0099 - val_accuracy: 0.4625\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0092 - accuracy: 0.4746 - val_loss: 1.0127 - val_accuracy: 0.4759\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0144 - accuracy: 0.4742 - val_loss: 1.0012 - val_accuracy: 0.4692\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0062 - accuracy: 0.4905 - val_loss: 1.0039 - val_accuracy: 0.4839\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0126 - accuracy: 0.4800 - val_loss: 1.0002 - val_accuracy: 0.4906\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0127 - accuracy: 0.4851 - val_loss: 0.9941 - val_accuracy: 0.4933\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0045 - accuracy: 0.4874 - val_loss: 0.9955 - val_accuracy: 0.4799\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0142 - accuracy: 0.4772 - val_loss: 0.9959 - val_accuracy: 0.4987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0163 - accuracy: 0.4707 - val_loss: 0.9929 - val_accuracy: 0.4906\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9984 - accuracy: 0.4990 - val_loss: 0.9939 - val_accuracy: 0.4906\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9999 - accuracy: 0.4931 - val_loss: 0.9963 - val_accuracy: 0.4732\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9963 - accuracy: 0.5052 - val_loss: 1.0102 - val_accuracy: 0.4504\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9967 - accuracy: 0.4932 - val_loss: 0.9854 - val_accuracy: 0.4839\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9892 - accuracy: 0.4946 - val_loss: 0.9979 - val_accuracy: 0.4906\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9984 - accuracy: 0.4898 - val_loss: 0.9794 - val_accuracy: 0.5013\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9906 - accuracy: 0.4936 - val_loss: 0.9658 - val_accuracy: 0.5268\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9831 - accuracy: 0.5092 - val_loss: 0.9744 - val_accuracy: 0.5107\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9809 - accuracy: 0.5085 - val_loss: 0.9612 - val_accuracy: 0.5121\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9755 - accuracy: 0.5119 - val_loss: 0.9550 - val_accuracy: 0.5295\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9671 - accuracy: 0.5158 - val_loss: 0.9512 - val_accuracy: 0.5282\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9706 - accuracy: 0.5134 - val_loss: 0.9352 - val_accuracy: 0.5349\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9576 - accuracy: 0.5176 - val_loss: 1.0082 - val_accuracy: 0.4933\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9579 - accuracy: 0.5292 - val_loss: 0.9492 - val_accuracy: 0.5255\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9469 - accuracy: 0.5224 - val_loss: 0.9524 - val_accuracy: 0.5214\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9521 - accuracy: 0.5356 - val_loss: 0.9340 - val_accuracy: 0.5563\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9331 - accuracy: 0.5367 - val_loss: 0.9308 - val_accuracy: 0.5429\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9132 - accuracy: 0.5587 - val_loss: 0.9017 - val_accuracy: 0.5630\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8995 - accuracy: 0.5675 - val_loss: 0.9107 - val_accuracy: 0.5590\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8865 - accuracy: 0.5700 - val_loss: 0.8713 - val_accuracy: 0.5898\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8762 - accuracy: 0.5808 - val_loss: 0.8663 - val_accuracy: 0.5697\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8491 - accuracy: 0.5934 - val_loss: 0.8560 - val_accuracy: 0.5777\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8357 - accuracy: 0.6094 - val_loss: 0.8324 - val_accuracy: 0.6059\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8312 - accuracy: 0.6018 - val_loss: 0.8037 - val_accuracy: 0.6099\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7908 - accuracy: 0.6396 - val_loss: 0.7890 - val_accuracy: 0.6206\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7634 - accuracy: 0.6523 - val_loss: 0.7404 - val_accuracy: 0.6488\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7321 - accuracy: 0.6700 - val_loss: 0.7408 - val_accuracy: 0.6595\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6989 - accuracy: 0.6863 - val_loss: 0.7111 - val_accuracy: 0.6756\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6763 - accuracy: 0.7042 - val_loss: 0.7141 - val_accuracy: 0.6836\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6600 - accuracy: 0.7076 - val_loss: 0.6436 - val_accuracy: 0.7252\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.6229 - accuracy: 0.7259 - val_loss: 0.6183 - val_accuracy: 0.7306\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5798 - accuracy: 0.7519 - val_loss: 0.6369 - val_accuracy: 0.7105\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5587 - accuracy: 0.7632 - val_loss: 0.5832 - val_accuracy: 0.7654\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5327 - accuracy: 0.7785 - val_loss: 0.5782 - val_accuracy: 0.7587\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4841 - accuracy: 0.7997 - val_loss: 0.5319 - val_accuracy: 0.7788\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4582 - accuracy: 0.8139 - val_loss: 0.5031 - val_accuracy: 0.7989\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4734 - accuracy: 0.8051 - val_loss: 0.3183 - val_accuracy: 0.9048\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4633 - accuracy: 0.8180 - val_loss: 0.2582 - val_accuracy: 0.9196\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4238 - accuracy: 0.8303 - val_loss: 0.1929 - val_accuracy: 0.9424\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3679 - accuracy: 0.8583 - val_loss: 0.2035 - val_accuracy: 0.9316\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3497 - accuracy: 0.8668 - val_loss: 0.2056 - val_accuracy: 0.9263\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3224 - accuracy: 0.8778 - val_loss: 0.1921 - val_accuracy: 0.9410\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3103 - accuracy: 0.8815 - val_loss: 0.1548 - val_accuracy: 0.9517\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2995 - accuracy: 0.8876 - val_loss: 0.1534 - val_accuracy: 0.9464\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2669 - accuracy: 0.9030 - val_loss: 0.1288 - val_accuracy: 0.9611\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2531 - accuracy: 0.9089 - val_loss: 0.1238 - val_accuracy: 0.9584\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2406 - accuracy: 0.9092 - val_loss: 0.1175 - val_accuracy: 0.9584\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2582 - accuracy: 0.9064 - val_loss: 0.1341 - val_accuracy: 0.9544\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2403 - accuracy: 0.9098 - val_loss: 0.1140 - val_accuracy: 0.9611\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2223 - accuracy: 0.9191 - val_loss: 0.0900 - val_accuracy: 0.9678\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1997 - accuracy: 0.9288 - val_loss: 0.1061 - val_accuracy: 0.9625\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1795 - accuracy: 0.9402 - val_loss: 0.0802 - val_accuracy: 0.9786\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1729 - accuracy: 0.9365 - val_loss: 0.1201 - val_accuracy: 0.9558\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1808 - accuracy: 0.9367 - val_loss: 0.0657 - val_accuracy: 0.9786\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1594 - accuracy: 0.9438 - val_loss: 0.0903 - val_accuracy: 0.9692\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1526 - accuracy: 0.9474 - val_loss: 0.0523 - val_accuracy: 0.9866\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1406 - accuracy: 0.9514 - val_loss: 0.0834 - val_accuracy: 0.9745\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1529 - accuracy: 0.9477 - val_loss: 0.0570 - val_accuracy: 0.9799\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1344 - accuracy: 0.9539 - val_loss: 0.0635 - val_accuracy: 0.9732\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1332 - accuracy: 0.9544 - val_loss: 0.0379 - val_accuracy: 0.9906\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1167 - accuracy: 0.9595 - val_loss: 0.0447 - val_accuracy: 0.9839\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0931 - accuracy: 0.9660 - val_loss: 0.0616 - val_accuracy: 0.9853\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1391 - accuracy: 0.9539 - val_loss: 0.0646 - val_accuracy: 0.9786\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1139 - accuracy: 0.9635 - val_loss: 0.0435 - val_accuracy: 0.9853\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1183 - accuracy: 0.9614 - val_loss: 0.0615 - val_accuracy: 0.9786\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1226 - accuracy: 0.9602 - val_loss: 0.0523 - val_accuracy: 0.9866\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.1144 - accuracy: 0.9621 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1226 - accuracy: 0.9611 - val_loss: 0.0042 - val_accuracy: 0.9987\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1118 - accuracy: 0.9666 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0917 - accuracy: 0.9681 - val_loss: 0.0084 - val_accuracy: 0.9973\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0982 - accuracy: 0.9683 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0865 - accuracy: 0.9712 - val_loss: 0.0135 - val_accuracy: 0.9946\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1037 - accuracy: 0.9665 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0873 - accuracy: 0.9721 - val_loss: 0.0069 - val_accuracy: 0.9973\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0801 - accuracy: 0.9741 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0808 - accuracy: 0.9742 - val_loss: 0.0033 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0972 - accuracy: 0.9711 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0831 - accuracy: 0.9730 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0731 - accuracy: 0.9770 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0844 - accuracy: 0.9718 - val_loss: 0.0081 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0841 - accuracy: 0.9718 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0999 - accuracy: 0.9683 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0689 - accuracy: 0.9769 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0719 - accuracy: 0.9766 - val_loss: 0.0061 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0664 - accuracy: 0.9785 - val_loss: 0.0042 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0625 - accuracy: 0.9797 - val_loss: 0.0035 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0582 - accuracy: 0.9803 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0672 - accuracy: 0.9793 - val_loss: 0.0092 - val_accuracy: 0.9973\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0709 - accuracy: 0.9782 - val_loss: 0.0084 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0680 - accuracy: 0.9790 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0636 - accuracy: 0.9802 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0651 - accuracy: 0.9803 - val_loss: 0.0081 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0712 - accuracy: 0.9766 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0535 - accuracy: 0.9839 - val_loss: 0.0034 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0651 - accuracy: 0.9785 - val_loss: 0.0029 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0556 - accuracy: 0.9805 - val_loss: 0.0042 - val_accuracy: 0.9987\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0793 - accuracy: 0.9739 - val_loss: 4.6423e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0513 - accuracy: 0.9841 - val_loss: 7.8272e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0645 - accuracy: 0.9805 - val_loss: 6.2764e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0582 - accuracy: 0.9821 - val_loss: 4.6388e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0559 - accuracy: 0.9824 - val_loss: 3.2971e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0705 - accuracy: 0.9766 - val_loss: 0.0025 - val_accuracy: 0.9987\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0516 - accuracy: 0.9829 - val_loss: 3.6399e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0597 - accuracy: 0.9796 - val_loss: 8.0232e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0501 - accuracy: 0.9836 - val_loss: 5.5194e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0479 - accuracy: 0.9846 - val_loss: 3.4583e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0688 - accuracy: 0.9791 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0609 - accuracy: 0.9818 - val_loss: 8.0029e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0579 - accuracy: 0.9787 - val_loss: 8.8627e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0525 - accuracy: 0.9830 - val_loss: 3.7486e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0484 - accuracy: 0.9823 - val_loss: 3.8717e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0543 - accuracy: 0.9836 - val_loss: 8.0100e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0433 - accuracy: 0.9873 - val_loss: 1.9697e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0383 - accuracy: 0.9878 - val_loss: 2.8339e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0503 - accuracy: 0.9846 - val_loss: 9.6611e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0544 - accuracy: 0.9844 - val_loss: 5.5237e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0386 - accuracy: 0.9872 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0550 - accuracy: 0.9830 - val_loss: 4.2166e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0572 - accuracy: 0.9823 - val_loss: 0.0021 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0442 - accuracy: 0.9872 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1126 - accuracy: 0.9654 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0576 - accuracy: 0.9815 - val_loss: 6.1104e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0368 - accuracy: 0.9894 - val_loss: 4.7025e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0323 - accuracy: 0.9888 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0505 - accuracy: 0.9838 - val_loss: 5.6287e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0507 - accuracy: 0.9842 - val_loss: 8.3403e-04 - val_accuracy: 1.0000\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0398 - accuracy: 0.9872 - val_loss: 7.5031e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0457 - accuracy: 0.9858 - val_loss: 4.8366e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0469 - accuracy: 0.9864 - val_loss: 3.4838e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0434 - accuracy: 0.9867 - val_loss: 1.0653e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0436 - accuracy: 0.9849 - val_loss: 4.7845e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0445 - accuracy: 0.9842 - val_loss: 5.8114e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0375 - accuracy: 0.9876 - val_loss: 2.9699e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0343 - accuracy: 0.9891 - val_loss: 5.5214e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0479 - accuracy: 0.9848 - val_loss: 5.5161e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0520 - accuracy: 0.9838 - val_loss: 1.3373e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0323 - accuracy: 0.9903 - val_loss: 3.8854e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0702 - accuracy: 0.9765 - val_loss: 7.1703e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0399 - accuracy: 0.9854 - val_loss: 9.8378e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0371 - accuracy: 0.9887 - val_loss: 1.0329e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0368 - accuracy: 0.9863 - val_loss: 7.0191e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0308 - accuracy: 0.9905 - val_loss: 3.1553e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0409 - accuracy: 0.9876 - val_loss: 2.6265e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0432 - accuracy: 0.9852 - val_loss: 3.5106e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0380 - accuracy: 0.9884 - val_loss: 2.2745e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0287 - accuracy: 0.9909 - val_loss: 8.6254e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0405 - accuracy: 0.9885 - val_loss: 3.0189e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0359 - accuracy: 0.9897 - val_loss: 1.9839e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0282 - accuracy: 0.9908 - val_loss: 0.0072 - val_accuracy: 0.9973\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0315 - accuracy: 0.9888 - val_loss: 1.2154e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0306 - accuracy: 0.9905 - val_loss: 7.1018e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0388 - accuracy: 0.9867 - val_loss: 3.8513e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0387 - accuracy: 0.9902 - val_loss: 2.7868e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0444 - accuracy: 0.9872 - val_loss: 1.3067e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0352 - accuracy: 0.9902 - val_loss: 6.4243e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0334 - accuracy: 0.9893 - val_loss: 6.8506e-05 - val_accuracy: 1.0000\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 49ms/step - loss: 0.0371 - accuracy: 0.9864 - val_loss: 4.2044e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0470 - accuracy: 0.9842 - val_loss: 6.3260e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2207 - accuracy: 0.9331 - val_loss: 0.1935 - val_accuracy: 0.9450\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0876 - accuracy: 0.9738 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0348 - accuracy: 0.9893 - val_loss: 8.3635e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0327 - accuracy: 0.9897 - val_loss: 8.6794e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0302 - accuracy: 0.9903 - val_loss: 5.1953e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0292 - accuracy: 0.9915 - val_loss: 7.2801e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0293 - accuracy: 0.9900 - val_loss: 6.2145e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0233 - accuracy: 0.9928 - val_loss: 1.3484e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0269 - accuracy: 0.9923 - val_loss: 5.8700e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0320 - accuracy: 0.9903 - val_loss: 6.1834e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0246 - accuracy: 0.9928 - val_loss: 2.8073e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0242 - accuracy: 0.9927 - val_loss: 1.8037e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0291 - accuracy: 0.9906 - val_loss: 1.6570e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0334 - accuracy: 0.9897 - val_loss: 4.0154e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0236 - accuracy: 0.9915 - val_loss: 1.9432e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0243 - accuracy: 0.9918 - val_loss: 1.2259e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0308 - accuracy: 0.9890 - val_loss: 3.2626e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0236 - accuracy: 0.9936 - val_loss: 1.2306e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0331 - accuracy: 0.9902 - val_loss: 7.9840e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0438 - accuracy: 0.9857 - val_loss: 0.0017 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0379 - accuracy: 0.9863 - val_loss: 6.3850e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0341 - accuracy: 0.9893 - val_loss: 4.4294e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0282 - accuracy: 0.9912 - val_loss: 4.5822e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0429 - accuracy: 0.9890 - val_loss: 4.9520e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0226 - accuracy: 0.9927 - val_loss: 3.6379e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0202 - accuracy: 0.9939 - val_loss: 1.5989e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0294 - accuracy: 0.9905 - val_loss: 4.8011e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0212 - accuracy: 0.9933 - val_loss: 5.6367e-05 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0359 - accuracy: 0.9884 - val_loss: 3.7169e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0239 - accuracy: 0.9915 - val_loss: 1.2742e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0290 - accuracy: 0.9915 - val_loss: 3.1948e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0252 - accuracy: 0.9924 - val_loss: 7.7271e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0329 - accuracy: 0.9897 - val_loss: 2.1339e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0215 - accuracy: 0.9946 - val_loss: 3.6760e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0302 - accuracy: 0.9912 - val_loss: 1.2967e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0316 - accuracy: 0.9899 - val_loss: 9.5438e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0377 - accuracy: 0.9876 - val_loss: 6.5260e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0300 - accuracy: 0.9900 - val_loss: 4.8658e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0382 - accuracy: 0.9890 - val_loss: 3.0256e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0316 - accuracy: 0.9905 - val_loss: 1.2147e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0275 - accuracy: 0.9921 - val_loss: 1.6990e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0314 - accuracy: 0.9909 - val_loss: 2.0597e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0228 - accuracy: 0.9936 - val_loss: 2.2508e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0318 - accuracy: 0.9908 - val_loss: 0.0048 - val_accuracy: 0.9987\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0315 - accuracy: 0.9911 - val_loss: 7.2180e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0224 - accuracy: 0.9925 - val_loss: 8.7256e-06 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0210 - accuracy: 0.9931 - val_loss: 7.9645e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0283 - accuracy: 0.9923 - val_loss: 1.0791e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0275 - accuracy: 0.9906 - val_loss: 1.3555e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0413 - accuracy: 0.9869 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0325 - accuracy: 0.9888 - val_loss: 1.0910e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0256 - accuracy: 0.9912 - val_loss: 4.8173e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0238 - accuracy: 0.9920 - val_loss: 9.6535e-06 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0232 - accuracy: 0.9925 - val_loss: 1.9618e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0247 - accuracy: 0.9928 - val_loss: 2.9644e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0269 - accuracy: 0.9924 - val_loss: 2.5242e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0211 - accuracy: 0.9936 - val_loss: 3.2005e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0292 - accuracy: 0.9914 - val_loss: 3.6526e-05 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0246 - accuracy: 0.9933 - val_loss: 1.1966e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0471 - accuracy: 0.9870 - val_loss: 1.2364e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0364 - accuracy: 0.9891 - val_loss: 3.2046e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0284 - accuracy: 0.9914 - val_loss: 2.8536e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0427 - accuracy: 0.9873 - val_loss: 4.2770e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0310 - accuracy: 0.9899 - val_loss: 4.9596e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0268 - accuracy: 0.9905 - val_loss: 2.4497e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0250 - accuracy: 0.9924 - val_loss: 4.2981e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0261 - accuracy: 0.9915 - val_loss: 1.7629e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0255 - accuracy: 0.9918 - val_loss: 8.0961e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0311 - accuracy: 0.9893 - val_loss: 2.9844e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0181 - accuracy: 0.9940 - val_loss: 1.5112e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0250 - accuracy: 0.9927 - val_loss: 1.9328e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0251 - accuracy: 0.9925 - val_loss: 9.6093e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0216 - accuracy: 0.9918 - val_loss: 5.7611e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0247 - accuracy: 0.9908 - val_loss: 1.6853e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0321 - accuracy: 0.9900 - val_loss: 1.4727e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0308 - accuracy: 0.9897 - val_loss: 2.0973e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0220 - accuracy: 0.9923 - val_loss: 1.1711e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0231 - accuracy: 0.9934 - val_loss: 1.4477e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0200 - accuracy: 0.9945 - val_loss: 2.2920e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0220 - accuracy: 0.9924 - val_loss: 1.1304e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0308 - accuracy: 0.9918 - val_loss: 2.3152e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0212 - accuracy: 0.9928 - val_loss: 5.6853e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0211 - accuracy: 0.9928 - val_loss: 1.5506e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0244 - accuracy: 0.9921 - val_loss: 1.1144e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0276 - accuracy: 0.9928 - val_loss: 1.2622e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0197 - accuracy: 0.9940 - val_loss: 4.2199e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0208 - accuracy: 0.9930 - val_loss: 9.4370e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0238 - accuracy: 0.9928 - val_loss: 2.4061e-05 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0240 - accuracy: 0.9924 - val_loss: 3.9884e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0227 - accuracy: 0.9937 - val_loss: 4.0425e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0292 - accuracy: 0.9921 - val_loss: 8.2886e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0314 - accuracy: 0.9902 - val_loss: 4.2827e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0365 - accuracy: 0.9888 - val_loss: 2.9240e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0311 - accuracy: 0.9887 - val_loss: 1.1733e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0224 - accuracy: 0.9918 - val_loss: 5.9573e-06 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0235 - accuracy: 0.9931 - val_loss: 1.6238e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0224 - accuracy: 0.9936 - val_loss: 6.7445e-06 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0210 - accuracy: 0.9940 - val_loss: 5.6970e-06 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0257 - accuracy: 0.9918 - val_loss: 9.0230e-06 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 2.0474e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0273 - accuracy: 0.9917 - val_loss: 2.0513e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0191 - accuracy: 0.9939 - val_loss: 1.2366e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0199 - accuracy: 0.9940 - val_loss: 1.6935e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0284 - accuracy: 0.9902 - val_loss: 1.2876e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0164 - accuracy: 0.9942 - val_loss: 2.5341e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0237 - accuracy: 0.9905 - val_loss: 6.9630e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0391 - accuracy: 0.9866 - val_loss: 7.4238e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 1.0066e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0207 - accuracy: 0.9942 - val_loss: 8.7948e-06 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0234 - accuracy: 0.9936 - val_loss: 9.1870e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0250 - accuracy: 0.9928 - val_loss: 3.7487e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0176 - accuracy: 0.9948 - val_loss: 3.5371e-06 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0181 - accuracy: 0.9939 - val_loss: 1.9372e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0245 - accuracy: 0.9931 - val_loss: 1.0669e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0412 - accuracy: 0.9881 - val_loss: 2.9492e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0336 - accuracy: 0.9900 - val_loss: 7.0961e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0194 - accuracy: 0.9943 - val_loss: 3.0379e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0186 - accuracy: 0.9931 - val_loss: 2.2558e-04 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "CAnc2SJa3o9f",
        "outputId": "e4d0386b-ffbb-478d-f682-59f4cb06fca0"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 8ms/step - loss: 0.0284 - accuracy: 0.9914\n",
            "Accuracy  : 0.991416335105896\n",
            "F1_Score  : 0.9904247240528422\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7fcxLuwZpkK",
        "outputId": "240875f4-4ce0-40f3-fa30-3fd44b925a20"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "d7aae89a-1ad0-4751-c48d-b34431afedd0"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 52ms/step - loss: 1.0649 - accuracy: 0.4710 - val_loss: 0.9763 - val_accuracy: 0.5147\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0001 - accuracy: 0.5079 - val_loss: 0.9619 - val_accuracy: 0.5147\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9843 - accuracy: 0.5168 - val_loss: 0.9687 - val_accuracy: 0.5147\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9900 - accuracy: 0.5184 - val_loss: 0.9600 - val_accuracy: 0.5147\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9704 - accuracy: 0.5370 - val_loss: 0.9590 - val_accuracy: 0.5147\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9765 - accuracy: 0.5235 - val_loss: 0.9571 - val_accuracy: 0.5147\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9838 - accuracy: 0.5168 - val_loss: 0.9544 - val_accuracy: 0.5121\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9649 - accuracy: 0.5260 - val_loss: 0.9526 - val_accuracy: 0.5147\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9730 - accuracy: 0.5178 - val_loss: 0.9608 - val_accuracy: 0.5147\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9702 - accuracy: 0.5214 - val_loss: 0.9583 - val_accuracy: 0.5147\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9769 - accuracy: 0.5156 - val_loss: 0.9525 - val_accuracy: 0.5147\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9590 - accuracy: 0.5299 - val_loss: 0.9527 - val_accuracy: 0.5147\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9593 - accuracy: 0.5320 - val_loss: 0.9540 - val_accuracy: 0.5147\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9616 - accuracy: 0.5262 - val_loss: 0.9529 - val_accuracy: 0.5147\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9498 - accuracy: 0.5358 - val_loss: 0.9637 - val_accuracy: 0.5147\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9634 - accuracy: 0.5236 - val_loss: 0.9556 - val_accuracy: 0.5147\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9639 - accuracy: 0.5221 - val_loss: 0.9569 - val_accuracy: 0.5147\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9503 - accuracy: 0.5269 - val_loss: 0.9477 - val_accuracy: 0.5147\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9496 - accuracy: 0.5237 - val_loss: 0.9471 - val_accuracy: 0.5147\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9601 - accuracy: 0.5124 - val_loss: 0.9437 - val_accuracy: 0.5147\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9559 - accuracy: 0.5203 - val_loss: 0.9354 - val_accuracy: 0.5161\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9457 - accuracy: 0.5239 - val_loss: 0.9367 - val_accuracy: 0.5147\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9428 - accuracy: 0.5210 - val_loss: 0.9472 - val_accuracy: 0.5147\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9489 - accuracy: 0.5217 - val_loss: 0.9331 - val_accuracy: 0.5147\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9258 - accuracy: 0.5339 - val_loss: 0.9322 - val_accuracy: 0.5161\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9402 - accuracy: 0.5238 - val_loss: 0.9241 - val_accuracy: 0.5161\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9249 - accuracy: 0.5231 - val_loss: 0.9418 - val_accuracy: 0.5147\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9319 - accuracy: 0.5324 - val_loss: 0.9348 - val_accuracy: 0.5214\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9163 - accuracy: 0.5302 - val_loss: 0.9336 - val_accuracy: 0.5161\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9222 - accuracy: 0.5292 - val_loss: 0.9163 - val_accuracy: 0.5174\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9190 - accuracy: 0.5325 - val_loss: 0.8630 - val_accuracy: 0.5375\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9192 - accuracy: 0.5294 - val_loss: 0.8901 - val_accuracy: 0.5402\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9070 - accuracy: 0.5347 - val_loss: 0.8674 - val_accuracy: 0.5456\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9114 - accuracy: 0.5379 - val_loss: 0.8600 - val_accuracy: 0.5416\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9039 - accuracy: 0.5387 - val_loss: 0.8701 - val_accuracy: 0.5509\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8992 - accuracy: 0.5428 - val_loss: 0.8632 - val_accuracy: 0.5429\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8904 - accuracy: 0.5431 - val_loss: 0.8565 - val_accuracy: 0.5402\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8893 - accuracy: 0.5450 - val_loss: 0.8498 - val_accuracy: 0.5469\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8753 - accuracy: 0.5461 - val_loss: 0.8383 - val_accuracy: 0.5523\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8727 - accuracy: 0.5592 - val_loss: 0.8332 - val_accuracy: 0.5563\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8677 - accuracy: 0.5648 - val_loss: 0.8352 - val_accuracy: 0.5617\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8470 - accuracy: 0.5595 - val_loss: 0.8123 - val_accuracy: 0.5764\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8475 - accuracy: 0.5675 - val_loss: 0.7942 - val_accuracy: 0.5684\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8334 - accuracy: 0.5784 - val_loss: 0.7942 - val_accuracy: 0.5791\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8149 - accuracy: 0.5855 - val_loss: 0.8092 - val_accuracy: 0.5858\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7987 - accuracy: 0.5930 - val_loss: 0.7740 - val_accuracy: 0.5938\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7918 - accuracy: 0.5999 - val_loss: 0.7708 - val_accuracy: 0.5965\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7712 - accuracy: 0.6113 - val_loss: 0.7495 - val_accuracy: 0.6059\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7598 - accuracy: 0.6238 - val_loss: 0.7350 - val_accuracy: 0.6354\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7325 - accuracy: 0.6440 - val_loss: 0.7240 - val_accuracy: 0.6340\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6987 - accuracy: 0.6621 - val_loss: 0.6898 - val_accuracy: 0.6475\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6672 - accuracy: 0.6726 - val_loss: 0.6564 - val_accuracy: 0.6850\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6728 - accuracy: 0.6775 - val_loss: 0.6294 - val_accuracy: 0.7145\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6479 - accuracy: 0.6899 - val_loss: 0.5801 - val_accuracy: 0.7064\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6120 - accuracy: 0.7162 - val_loss: 0.6046 - val_accuracy: 0.7024\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5694 - accuracy: 0.7368 - val_loss: 0.5434 - val_accuracy: 0.7319\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5256 - accuracy: 0.7531 - val_loss: 0.5220 - val_accuracy: 0.7453\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5222 - accuracy: 0.7627 - val_loss: 0.5135 - val_accuracy: 0.7399\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4728 - accuracy: 0.7902 - val_loss: 0.5084 - val_accuracy: 0.7507\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4500 - accuracy: 0.7969 - val_loss: 0.4742 - val_accuracy: 0.7694\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4513 - accuracy: 0.8031 - val_loss: 0.2527 - val_accuracy: 0.8968\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4219 - accuracy: 0.8174 - val_loss: 0.2552 - val_accuracy: 0.9115\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4256 - accuracy: 0.8121 - val_loss: 0.2429 - val_accuracy: 0.9182\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3872 - accuracy: 0.8383 - val_loss: 0.2025 - val_accuracy: 0.9424\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3363 - accuracy: 0.8601 - val_loss: 0.1944 - val_accuracy: 0.9169\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3464 - accuracy: 0.8526 - val_loss: 0.1883 - val_accuracy: 0.9196\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3238 - accuracy: 0.8657 - val_loss: 0.1999 - val_accuracy: 0.9276\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3115 - accuracy: 0.8702 - val_loss: 0.1791 - val_accuracy: 0.9276\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3192 - accuracy: 0.8723 - val_loss: 0.1800 - val_accuracy: 0.9437\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2750 - accuracy: 0.8893 - val_loss: 0.1287 - val_accuracy: 0.9531\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2492 - accuracy: 0.9024 - val_loss: 0.1775 - val_accuracy: 0.9196\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2487 - accuracy: 0.9075 - val_loss: 0.1989 - val_accuracy: 0.9169\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2523 - accuracy: 0.8985 - val_loss: 0.1113 - val_accuracy: 0.9531\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2367 - accuracy: 0.9104 - val_loss: 0.1097 - val_accuracy: 0.9584\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2025 - accuracy: 0.9264 - val_loss: 0.1028 - val_accuracy: 0.9638\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1927 - accuracy: 0.9291 - val_loss: 0.1159 - val_accuracy: 0.9544\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1970 - accuracy: 0.9285 - val_loss: 0.1416 - val_accuracy: 0.9343\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1818 - accuracy: 0.9325 - val_loss: 0.1081 - val_accuracy: 0.9625\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1656 - accuracy: 0.9404 - val_loss: 0.0808 - val_accuracy: 0.9718\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1607 - accuracy: 0.9423 - val_loss: 0.0922 - val_accuracy: 0.9692\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1548 - accuracy: 0.9455 - val_loss: 0.0674 - val_accuracy: 0.9705\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1634 - accuracy: 0.9407 - val_loss: 0.0716 - val_accuracy: 0.9732\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1434 - accuracy: 0.9513 - val_loss: 0.1021 - val_accuracy: 0.9651\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1586 - accuracy: 0.9459 - val_loss: 0.0564 - val_accuracy: 0.9759\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1349 - accuracy: 0.9516 - val_loss: 0.0795 - val_accuracy: 0.9718\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1339 - accuracy: 0.9551 - val_loss: 0.0462 - val_accuracy: 0.9853\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1185 - accuracy: 0.9590 - val_loss: 0.0649 - val_accuracy: 0.9786\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1340 - accuracy: 0.9534 - val_loss: 0.0515 - val_accuracy: 0.9853\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1125 - accuracy: 0.9647 - val_loss: 0.0500 - val_accuracy: 0.9786\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1193 - accuracy: 0.9598 - val_loss: 0.0453 - val_accuracy: 0.9812\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.1514 - accuracy: 0.9493 - val_loss: 0.0165 - val_accuracy: 0.9987\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1398 - accuracy: 0.9487 - val_loss: 0.0108 - val_accuracy: 0.9960\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1055 - accuracy: 0.9629 - val_loss: 0.0227 - val_accuracy: 0.9933\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1349 - accuracy: 0.9559 - val_loss: 0.0139 - val_accuracy: 0.9946\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1291 - accuracy: 0.9548 - val_loss: 0.0131 - val_accuracy: 0.9960\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1077 - accuracy: 0.9650 - val_loss: 0.0074 - val_accuracy: 0.9973\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1072 - accuracy: 0.9624 - val_loss: 0.0248 - val_accuracy: 0.9893\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1079 - accuracy: 0.9615 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1007 - accuracy: 0.9657 - val_loss: 0.0164 - val_accuracy: 0.9946\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1054 - accuracy: 0.9618 - val_loss: 0.0056 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0867 - accuracy: 0.9729 - val_loss: 0.0089 - val_accuracy: 0.9987\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0915 - accuracy: 0.9706 - val_loss: 0.0122 - val_accuracy: 0.9960\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0864 - accuracy: 0.9705 - val_loss: 0.0058 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0942 - accuracy: 0.9700 - val_loss: 0.0089 - val_accuracy: 0.9946\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0903 - accuracy: 0.9712 - val_loss: 0.0200 - val_accuracy: 0.9893\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1016 - accuracy: 0.9656 - val_loss: 0.0072 - val_accuracy: 0.9973\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0745 - accuracy: 0.9776 - val_loss: 0.0080 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0901 - accuracy: 0.9714 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0796 - accuracy: 0.9724 - val_loss: 0.0059 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0808 - accuracy: 0.9730 - val_loss: 0.0100 - val_accuracy: 0.9973\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0630 - accuracy: 0.9790 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0614 - accuracy: 0.9797 - val_loss: 0.0069 - val_accuracy: 0.9973\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0573 - accuracy: 0.9832 - val_loss: 0.0045 - val_accuracy: 0.9973\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0688 - accuracy: 0.9768 - val_loss: 0.0432 - val_accuracy: 0.9839\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0788 - accuracy: 0.9735 - val_loss: 0.0033 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0682 - accuracy: 0.9779 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0773 - accuracy: 0.9735 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0581 - accuracy: 0.9817 - val_loss: 0.0086 - val_accuracy: 0.9960\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0501 - accuracy: 0.9839 - val_loss: 0.0045 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0688 - accuracy: 0.9768 - val_loss: 0.0104 - val_accuracy: 0.9973\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0857 - accuracy: 0.9741 - val_loss: 2.1632e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 48ms/step - loss: 0.0657 - accuracy: 0.9769 - val_loss: 7.9795e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0660 - accuracy: 0.9790 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0485 - accuracy: 0.9841 - val_loss: 6.7191e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0619 - accuracy: 0.9814 - val_loss: 0.0017 - val_accuracy: 0.9987\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0609 - accuracy: 0.9811 - val_loss: 4.0689e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0698 - accuracy: 0.9787 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0731 - accuracy: 0.9765 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0431 - accuracy: 0.9846 - val_loss: 9.9134e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0543 - accuracy: 0.9827 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0634 - accuracy: 0.9769 - val_loss: 0.0022 - val_accuracy: 0.9987\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0506 - accuracy: 0.9835 - val_loss: 1.5575e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0574 - accuracy: 0.9820 - val_loss: 2.9616e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0573 - accuracy: 0.9808 - val_loss: 5.6535e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0571 - accuracy: 0.9826 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0710 - accuracy: 0.9779 - val_loss: 9.2963e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0625 - accuracy: 0.9803 - val_loss: 6.3618e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0407 - accuracy: 0.9872 - val_loss: 0.0025 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0431 - accuracy: 0.9861 - val_loss: 0.0022 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0542 - accuracy: 0.9824 - val_loss: 0.0026 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0517 - accuracy: 0.9826 - val_loss: 3.9996e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0476 - accuracy: 0.9848 - val_loss: 6.6126e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0534 - accuracy: 0.9833 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0488 - accuracy: 0.9851 - val_loss: 0.0031 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0595 - accuracy: 0.9818 - val_loss: 0.0062 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0599 - accuracy: 0.9799 - val_loss: 6.5807e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0457 - accuracy: 0.9875 - val_loss: 8.4906e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0415 - accuracy: 0.9875 - val_loss: 8.5488e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0442 - accuracy: 0.9857 - val_loss: 4.4387e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0462 - accuracy: 0.9835 - val_loss: 7.7505e-04 - val_accuracy: 1.0000\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0459 - accuracy: 0.9842 - val_loss: 3.2162e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0383 - accuracy: 0.9864 - val_loss: 5.4270e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0363 - accuracy: 0.9882 - val_loss: 4.3342e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0618 - accuracy: 0.9803 - val_loss: 5.2323e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0415 - accuracy: 0.9852 - val_loss: 6.0570e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0564 - accuracy: 0.9809 - val_loss: 2.1653e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0455 - accuracy: 0.9855 - val_loss: 9.7910e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0413 - accuracy: 0.9860 - val_loss: 7.4308e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0687 - accuracy: 0.9806 - val_loss: 1.5934e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0718 - accuracy: 0.9776 - val_loss: 7.2375e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0392 - accuracy: 0.9870 - val_loss: 2.9666e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0427 - accuracy: 0.9873 - val_loss: 1.7085e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0368 - accuracy: 0.9882 - val_loss: 5.0608e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0463 - accuracy: 0.9861 - val_loss: 5.3650e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0551 - accuracy: 0.9844 - val_loss: 4.6120e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0430 - accuracy: 0.9884 - val_loss: 2.5629e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0476 - accuracy: 0.9846 - val_loss: 7.3771e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0463 - accuracy: 0.9842 - val_loss: 1.7426e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0256 - accuracy: 0.9921 - val_loss: 1.0019e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0357 - accuracy: 0.9891 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0429 - accuracy: 0.9842 - val_loss: 4.3600e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0505 - accuracy: 0.9827 - val_loss: 4.5353e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0390 - accuracy: 0.9872 - val_loss: 1.5676e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0383 - accuracy: 0.9878 - val_loss: 1.5007e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0347 - accuracy: 0.9887 - val_loss: 2.4165e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0313 - accuracy: 0.9912 - val_loss: 2.9916e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0327 - accuracy: 0.9897 - val_loss: 1.4799e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0324 - accuracy: 0.9881 - val_loss: 6.9822e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0343 - accuracy: 0.9897 - val_loss: 9.6070e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0335 - accuracy: 0.9906 - val_loss: 1.3399e-04 - val_accuracy: 1.0000\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0400 - accuracy: 0.9864 - val_loss: 2.1932e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0403 - accuracy: 0.9867 - val_loss: 2.9597e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0392 - accuracy: 0.9882 - val_loss: 3.9247e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0479 - accuracy: 0.9864 - val_loss: 4.9077e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0589 - accuracy: 0.9824 - val_loss: 1.0814e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0339 - accuracy: 0.9878 - val_loss: 1.2404e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0279 - accuracy: 0.9903 - val_loss: 4.0208e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0376 - accuracy: 0.9891 - val_loss: 2.4350e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0312 - accuracy: 0.9914 - val_loss: 1.7367e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0332 - accuracy: 0.9879 - val_loss: 2.1908e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0359 - accuracy: 0.9888 - val_loss: 1.9432e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0334 - accuracy: 0.9893 - val_loss: 6.6428e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0465 - accuracy: 0.9855 - val_loss: 9.6333e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0307 - accuracy: 0.9906 - val_loss: 2.1811e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0414 - accuracy: 0.9876 - val_loss: 2.3694e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0293 - accuracy: 0.9902 - val_loss: 2.5896e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0279 - accuracy: 0.9921 - val_loss: 4.1521e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0493 - accuracy: 0.9854 - val_loss: 2.2507e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0419 - accuracy: 0.9845 - val_loss: 1.8726e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0345 - accuracy: 0.9894 - val_loss: 6.7257e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0270 - accuracy: 0.9909 - val_loss: 5.2506e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0515 - accuracy: 0.9867 - val_loss: 1.8212e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0436 - accuracy: 0.9875 - val_loss: 6.0171e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0308 - accuracy: 0.9882 - val_loss: 9.3813e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0286 - accuracy: 0.9908 - val_loss: 6.2440e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 1.4626e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0302 - accuracy: 0.9921 - val_loss: 2.0797e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0269 - accuracy: 0.9921 - val_loss: 2.1618e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0315 - accuracy: 0.9899 - val_loss: 4.0242e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 1.9114e-05 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0252 - accuracy: 0.9930 - val_loss: 8.8517e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0435 - accuracy: 0.9869 - val_loss: 2.3583e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2021 - accuracy: 0.9368 - val_loss: 0.0889 - val_accuracy: 0.9557\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0500 - accuracy: 0.9827 - val_loss: 8.6086e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0336 - accuracy: 0.9876 - val_loss: 1.0597e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0281 - accuracy: 0.9921 - val_loss: 5.2941e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0269 - accuracy: 0.9909 - val_loss: 6.1565e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0362 - accuracy: 0.9896 - val_loss: 1.9876e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0256 - accuracy: 0.9934 - val_loss: 5.4615e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0252 - accuracy: 0.9917 - val_loss: 3.0134e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0330 - accuracy: 0.9909 - val_loss: 3.1328e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0226 - accuracy: 0.9936 - val_loss: 2.6026e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0274 - accuracy: 0.9917 - val_loss: 9.6783e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0315 - accuracy: 0.9890 - val_loss: 2.0788e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0220 - accuracy: 0.9923 - val_loss: 1.7748e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0377 - accuracy: 0.9890 - val_loss: 4.2081e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0313 - accuracy: 0.9906 - val_loss: 5.4255e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0212 - accuracy: 0.9931 - val_loss: 4.3040e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0228 - accuracy: 0.9928 - val_loss: 1.6361e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0195 - accuracy: 0.9939 - val_loss: 2.1655e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0287 - accuracy: 0.9897 - val_loss: 2.2534e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0325 - accuracy: 0.9896 - val_loss: 1.5433e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0449 - accuracy: 0.9872 - val_loss: 1.8419e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0282 - accuracy: 0.9920 - val_loss: 7.5045e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0281 - accuracy: 0.9918 - val_loss: 1.0416e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0215 - accuracy: 0.9928 - val_loss: 2.4898e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0256 - accuracy: 0.9918 - val_loss: 1.7302e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 2.1250e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0273 - accuracy: 0.9909 - val_loss: 3.4879e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0349 - accuracy: 0.9872 - val_loss: 0.0020 - val_accuracy: 0.9987\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0578 - accuracy: 0.9835 - val_loss: 4.4876e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0229 - accuracy: 0.9942 - val_loss: 1.1446e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0364 - accuracy: 0.9887 - val_loss: 4.6848e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0268 - accuracy: 0.9911 - val_loss: 1.6413e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0190 - accuracy: 0.9943 - val_loss: 2.6812e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0260 - accuracy: 0.9928 - val_loss: 1.3715e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0326 - accuracy: 0.9902 - val_loss: 1.0981e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0309 - accuracy: 0.9894 - val_loss: 3.9798e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0312 - accuracy: 0.9897 - val_loss: 9.2781e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0308 - accuracy: 0.9905 - val_loss: 8.2682e-06 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0236 - accuracy: 0.9931 - val_loss: 2.3442e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0222 - accuracy: 0.9931 - val_loss: 1.4925e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0284 - accuracy: 0.9902 - val_loss: 3.8943e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0289 - accuracy: 0.9909 - val_loss: 8.7149e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0316 - accuracy: 0.9918 - val_loss: 2.0722e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0227 - accuracy: 0.9928 - val_loss: 6.0507e-06 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0205 - accuracy: 0.9936 - val_loss: 1.6589e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0343 - accuracy: 0.9887 - val_loss: 1.9209e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0269 - accuracy: 0.9918 - val_loss: 1.1197e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0141 - accuracy: 0.9960 - val_loss: 7.8043e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0171 - accuracy: 0.9948 - val_loss: 5.0006e-06 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0264 - accuracy: 0.9909 - val_loss: 2.7564e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0295 - accuracy: 0.9917 - val_loss: 3.4484e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0262 - accuracy: 0.9921 - val_loss: 1.9788e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0241 - accuracy: 0.9920 - val_loss: 5.7239e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0222 - accuracy: 0.9928 - val_loss: 6.5353e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0248 - accuracy: 0.9912 - val_loss: 2.1046e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0202 - accuracy: 0.9939 - val_loss: 2.0114e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0209 - accuracy: 0.9936 - val_loss: 5.4383e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0249 - accuracy: 0.9917 - val_loss: 2.8561e-04 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0321 - accuracy: 0.9900 - val_loss: 4.8656e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0273 - accuracy: 0.9909 - val_loss: 3.2788e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0236 - accuracy: 0.9925 - val_loss: 1.3360e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0311 - accuracy: 0.9906 - val_loss: 5.0118e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0307 - accuracy: 0.9905 - val_loss: 5.5778e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0202 - accuracy: 0.9928 - val_loss: 2.4050e-06 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0263 - accuracy: 0.9925 - val_loss: 2.1332e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0178 - accuracy: 0.9940 - val_loss: 3.7703e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 1.1199e-06 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0381 - accuracy: 0.9879 - val_loss: 2.9328e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0145 - accuracy: 0.9948 - val_loss: 1.7786e-06 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0246 - accuracy: 0.9925 - val_loss: 1.4493e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0180 - accuracy: 0.9934 - val_loss: 1.7746e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0302 - accuracy: 0.9887 - val_loss: 8.9278e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0449 - accuracy: 0.9872 - val_loss: 3.3199e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0316 - accuracy: 0.9897 - val_loss: 8.2178e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 5.0866e-06 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0192 - accuracy: 0.9934 - val_loss: 5.8339e-06 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0234 - accuracy: 0.9937 - val_loss: 2.5626e-06 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0218 - accuracy: 0.9934 - val_loss: 8.6394e-06 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0284 - accuracy: 0.9911 - val_loss: 3.5523e-06 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 6.7105e-06 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0216 - accuracy: 0.9937 - val_loss: 1.0643e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0167 - accuracy: 0.9955 - val_loss: 5.0787e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0168 - accuracy: 0.9934 - val_loss: 4.3036e-06 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0278 - accuracy: 0.9902 - val_loss: 1.5135e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0243 - accuracy: 0.9928 - val_loss: 3.7196e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0250 - accuracy: 0.9924 - val_loss: 1.0804e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0230 - accuracy: 0.9937 - val_loss: 3.7835e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0182 - accuracy: 0.9951 - val_loss: 1.0445e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "04680369-e8f7-417e-843a-488e666ee722"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 6ms/step - loss: 0.0201 - accuracy: 0.9946\n",
            "Accuracy  : 0.9946351647377014\n",
            "F1_Score  : 0.995162270400059\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}