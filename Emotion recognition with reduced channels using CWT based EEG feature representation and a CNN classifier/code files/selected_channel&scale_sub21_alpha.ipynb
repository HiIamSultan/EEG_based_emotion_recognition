{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub21_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "af7f3d24-5efc-47dd-a53b-9ac853a36d6f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e3\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  #EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "d716a7e1-d8d1-4cf9-8307-d056737b193e"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(21,22):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.21\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (2330,) (3029,) (3961,)\n",
            "(9320,) (1165,) (1631,) (6524,)\n",
            "(9320,) (2330,) (2097,) (4893,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "1c124df8-ae52-4241-f0dd-bbe928b1d6bc"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "9796812a-1d57-4e9c-e387-1c27e695e5b3"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "706"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "3e330b49-6def-4062-8dd7-9cd430dbed1d"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23ba2536-4ee3-4a8e-ca91-37de739e8018"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 22s 59ms/step - loss: 1.1431 - accuracy: 0.3882 - val_loss: 1.0765 - val_accuracy: 0.4249\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0838 - accuracy: 0.4303 - val_loss: 1.0638 - val_accuracy: 0.4249\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0765 - accuracy: 0.4186 - val_loss: 1.0689 - val_accuracy: 0.4249\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0783 - accuracy: 0.4170 - val_loss: 1.0690 - val_accuracy: 0.4249\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0735 - accuracy: 0.4293 - val_loss: 1.0684 - val_accuracy: 0.4249\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0768 - accuracy: 0.4193 - val_loss: 1.0674 - val_accuracy: 0.4249\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0692 - accuracy: 0.4289 - val_loss: 1.0660 - val_accuracy: 0.4249\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0726 - accuracy: 0.4257 - val_loss: 1.0672 - val_accuracy: 0.4249\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0681 - accuracy: 0.4336 - val_loss: 1.0663 - val_accuracy: 0.4249\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0686 - accuracy: 0.4249 - val_loss: 1.0661 - val_accuracy: 0.4249\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0720 - accuracy: 0.4234 - val_loss: 1.0634 - val_accuracy: 0.4249\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0657 - accuracy: 0.4379 - val_loss: 1.0672 - val_accuracy: 0.4249\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0719 - accuracy: 0.4181 - val_loss: 1.0653 - val_accuracy: 0.4249\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0670 - accuracy: 0.4316 - val_loss: 1.0649 - val_accuracy: 0.4249\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0671 - accuracy: 0.4273 - val_loss: 1.0665 - val_accuracy: 0.4249\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0693 - accuracy: 0.4285 - val_loss: 1.0643 - val_accuracy: 0.4249\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0687 - accuracy: 0.4288 - val_loss: 1.0645 - val_accuracy: 0.4249\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0643 - accuracy: 0.4322 - val_loss: 1.0649 - val_accuracy: 0.4249\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0698 - accuracy: 0.4228 - val_loss: 1.0657 - val_accuracy: 0.4249\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0678 - accuracy: 0.4330 - val_loss: 1.0661 - val_accuracy: 0.4249\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0672 - accuracy: 0.4208 - val_loss: 1.0638 - val_accuracy: 0.4249\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0659 - accuracy: 0.4248 - val_loss: 1.0611 - val_accuracy: 0.4249\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0665 - accuracy: 0.4341 - val_loss: 1.0668 - val_accuracy: 0.4249\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0699 - accuracy: 0.4206 - val_loss: 1.0675 - val_accuracy: 0.4249\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0706 - accuracy: 0.4222 - val_loss: 1.0681 - val_accuracy: 0.4249\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0667 - accuracy: 0.4288 - val_loss: 1.0624 - val_accuracy: 0.4249\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0741 - accuracy: 0.4216 - val_loss: 1.0614 - val_accuracy: 0.4249\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0618 - accuracy: 0.4393 - val_loss: 1.0661 - val_accuracy: 0.4249\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0660 - accuracy: 0.4300 - val_loss: 1.0634 - val_accuracy: 0.4249\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0655 - accuracy: 0.4276 - val_loss: 1.0795 - val_accuracy: 0.4249\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 1.0708 - accuracy: 0.4271 - val_loss: 1.0739 - val_accuracy: 0.4155\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0676 - accuracy: 0.4282 - val_loss: 1.0725 - val_accuracy: 0.4155\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0658 - accuracy: 0.4282 - val_loss: 1.0719 - val_accuracy: 0.4155\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0675 - accuracy: 0.4282 - val_loss: 1.0703 - val_accuracy: 0.4155\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0658 - accuracy: 0.4282 - val_loss: 1.0692 - val_accuracy: 0.4155\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0670 - accuracy: 0.4282 - val_loss: 1.0709 - val_accuracy: 0.4155\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0652 - accuracy: 0.4282 - val_loss: 1.0696 - val_accuracy: 0.4155\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0656 - accuracy: 0.4282 - val_loss: 1.0704 - val_accuracy: 0.4155\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0670 - accuracy: 0.4274 - val_loss: 1.0695 - val_accuracy: 0.4155\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0661 - accuracy: 0.4285 - val_loss: 1.0726 - val_accuracy: 0.4155\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0654 - accuracy: 0.4283 - val_loss: 1.0694 - val_accuracy: 0.4155\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0653 - accuracy: 0.4285 - val_loss: 1.0694 - val_accuracy: 0.4155\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0672 - accuracy: 0.4286 - val_loss: 1.0701 - val_accuracy: 0.4155\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0656 - accuracy: 0.4282 - val_loss: 1.0707 - val_accuracy: 0.4155\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0645 - accuracy: 0.4282 - val_loss: 1.0689 - val_accuracy: 0.4155\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0643 - accuracy: 0.4279 - val_loss: 1.0684 - val_accuracy: 0.4155\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0641 - accuracy: 0.4282 - val_loss: 1.0679 - val_accuracy: 0.4155\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0635 - accuracy: 0.4282 - val_loss: 1.0700 - val_accuracy: 0.4155\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0634 - accuracy: 0.4280 - val_loss: 1.0679 - val_accuracy: 0.4155\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0627 - accuracy: 0.4282 - val_loss: 1.0705 - val_accuracy: 0.4155\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0643 - accuracy: 0.4282 - val_loss: 1.0712 - val_accuracy: 0.4155\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0645 - accuracy: 0.4282 - val_loss: 1.0663 - val_accuracy: 0.4155\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0612 - accuracy: 0.4280 - val_loss: 1.0695 - val_accuracy: 0.4155\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0645 - accuracy: 0.4282 - val_loss: 1.0674 - val_accuracy: 0.4155\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0643 - accuracy: 0.4280 - val_loss: 1.0676 - val_accuracy: 0.4155\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0628 - accuracy: 0.4280 - val_loss: 1.0704 - val_accuracy: 0.4155\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0640 - accuracy: 0.4277 - val_loss: 1.0693 - val_accuracy: 0.4155\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0625 - accuracy: 0.4277 - val_loss: 1.0644 - val_accuracy: 0.4155\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0626 - accuracy: 0.4250 - val_loss: 1.0694 - val_accuracy: 0.4155\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0635 - accuracy: 0.4253 - val_loss: 1.0694 - val_accuracy: 0.4155\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 1.0646 - accuracy: 0.4270 - val_loss: 1.0539 - val_accuracy: 0.4236\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0618 - accuracy: 0.4273 - val_loss: 1.0611 - val_accuracy: 0.4236\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0659 - accuracy: 0.4270 - val_loss: 1.0582 - val_accuracy: 0.4236\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0624 - accuracy: 0.4271 - val_loss: 1.0602 - val_accuracy: 0.4236\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0576 - accuracy: 0.4256 - val_loss: 1.0541 - val_accuracy: 0.4290\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0609 - accuracy: 0.4264 - val_loss: 1.0550 - val_accuracy: 0.4236\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0591 - accuracy: 0.4243 - val_loss: 1.0598 - val_accuracy: 0.4236\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0576 - accuracy: 0.4261 - val_loss: 1.0570 - val_accuracy: 0.4236\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0575 - accuracy: 0.4288 - val_loss: 1.0556 - val_accuracy: 0.4236\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0570 - accuracy: 0.4311 - val_loss: 1.0568 - val_accuracy: 0.4303\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0592 - accuracy: 0.4244 - val_loss: 1.0550 - val_accuracy: 0.4236\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0530 - accuracy: 0.4286 - val_loss: 1.0514 - val_accuracy: 0.4209\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0516 - accuracy: 0.4326 - val_loss: 1.0511 - val_accuracy: 0.4236\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0529 - accuracy: 0.4298 - val_loss: 1.0429 - val_accuracy: 0.4263\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0503 - accuracy: 0.4322 - val_loss: 1.0601 - val_accuracy: 0.4290\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0467 - accuracy: 0.4304 - val_loss: 1.0409 - val_accuracy: 0.4276\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0408 - accuracy: 0.4382 - val_loss: 1.0456 - val_accuracy: 0.4357\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0380 - accuracy: 0.4376 - val_loss: 1.0369 - val_accuracy: 0.4330\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0350 - accuracy: 0.4438 - val_loss: 1.0385 - val_accuracy: 0.4169\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0298 - accuracy: 0.4522 - val_loss: 1.0359 - val_accuracy: 0.4531\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0322 - accuracy: 0.4507 - val_loss: 1.0251 - val_accuracy: 0.4625\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0307 - accuracy: 0.4463 - val_loss: 1.0265 - val_accuracy: 0.4692\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0242 - accuracy: 0.4526 - val_loss: 1.0133 - val_accuracy: 0.4772\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0227 - accuracy: 0.4514 - val_loss: 1.0262 - val_accuracy: 0.4598\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0085 - accuracy: 0.4627 - val_loss: 1.0054 - val_accuracy: 0.4772\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0093 - accuracy: 0.4623 - val_loss: 0.9934 - val_accuracy: 0.5134\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9910 - accuracy: 0.4718 - val_loss: 0.9943 - val_accuracy: 0.4839\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9790 - accuracy: 0.4790 - val_loss: 0.9695 - val_accuracy: 0.5228\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9788 - accuracy: 0.4800 - val_loss: 0.9429 - val_accuracy: 0.5429\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9598 - accuracy: 0.4937 - val_loss: 0.9606 - val_accuracy: 0.5375\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9509 - accuracy: 0.5136 - val_loss: 0.8963 - val_accuracy: 0.5576\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9419 - accuracy: 0.5170 - val_loss: 0.9566 - val_accuracy: 0.4853\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9255 - accuracy: 0.5232 - val_loss: 0.8587 - val_accuracy: 0.5925\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8796 - accuracy: 0.5517 - val_loss: 0.8348 - val_accuracy: 0.5912\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8759 - accuracy: 0.5477 - val_loss: 0.8186 - val_accuracy: 0.5791\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8549 - accuracy: 0.5638 - val_loss: 0.8157 - val_accuracy: 0.5871\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8469 - accuracy: 0.5773 - val_loss: 0.7876 - val_accuracy: 0.6354\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8014 - accuracy: 0.5975 - val_loss: 0.7496 - val_accuracy: 0.6233\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7844 - accuracy: 0.6133 - val_loss: 0.7561 - val_accuracy: 0.6287\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7574 - accuracy: 0.6274 - val_loss: 0.6996 - val_accuracy: 0.6528\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7551 - accuracy: 0.6308 - val_loss: 0.6922 - val_accuracy: 0.6475\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7177 - accuracy: 0.6586 - val_loss: 0.6926 - val_accuracy: 0.6649\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7123 - accuracy: 0.6657 - val_loss: 0.6780 - val_accuracy: 0.6917\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7179 - accuracy: 0.6672 - val_loss: 0.6644 - val_accuracy: 0.7011\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6843 - accuracy: 0.6791 - val_loss: 0.6051 - val_accuracy: 0.7051\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6513 - accuracy: 0.6966 - val_loss: 0.6148 - val_accuracy: 0.7105\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6205 - accuracy: 0.7179 - val_loss: 0.5750 - val_accuracy: 0.7359\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5985 - accuracy: 0.7255 - val_loss: 0.5702 - val_accuracy: 0.7399\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6076 - accuracy: 0.7346 - val_loss: 0.5517 - val_accuracy: 0.7440\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5806 - accuracy: 0.7459 - val_loss: 0.5125 - val_accuracy: 0.7761\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5575 - accuracy: 0.7596 - val_loss: 0.4982 - val_accuracy: 0.7936\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5456 - accuracy: 0.7598 - val_loss: 0.4692 - val_accuracy: 0.8217\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5376 - accuracy: 0.7627 - val_loss: 0.4555 - val_accuracy: 0.8217\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5357 - accuracy: 0.7632 - val_loss: 0.5237 - val_accuracy: 0.7828\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5019 - accuracy: 0.7852 - val_loss: 0.4608 - val_accuracy: 0.8029\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5117 - accuracy: 0.7773 - val_loss: 0.4261 - val_accuracy: 0.8338\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4885 - accuracy: 0.7957 - val_loss: 0.4074 - val_accuracy: 0.8298\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4325 - accuracy: 0.8191 - val_loss: 0.4621 - val_accuracy: 0.8097\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4388 - accuracy: 0.8198 - val_loss: 0.3888 - val_accuracy: 0.8378\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4261 - accuracy: 0.8252 - val_loss: 0.4085 - val_accuracy: 0.8271\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4544 - accuracy: 0.8130 - val_loss: 0.1892 - val_accuracy: 0.9678\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4514 - accuracy: 0.8104 - val_loss: 0.4027 - val_accuracy: 0.8164\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4263 - accuracy: 0.8227 - val_loss: 0.1438 - val_accuracy: 0.9705\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3975 - accuracy: 0.8453 - val_loss: 0.1657 - val_accuracy: 0.9598\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3739 - accuracy: 0.8531 - val_loss: 0.1478 - val_accuracy: 0.9558\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3591 - accuracy: 0.8571 - val_loss: 0.1414 - val_accuracy: 0.9759\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3935 - accuracy: 0.8461 - val_loss: 0.1501 - val_accuracy: 0.9598\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3426 - accuracy: 0.8647 - val_loss: 0.1286 - val_accuracy: 0.9692\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3787 - accuracy: 0.8523 - val_loss: 0.1751 - val_accuracy: 0.9491\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3518 - accuracy: 0.8615 - val_loss: 0.1452 - val_accuracy: 0.9558\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2940 - accuracy: 0.8899 - val_loss: 0.1002 - val_accuracy: 0.9745\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3063 - accuracy: 0.8839 - val_loss: 0.1317 - val_accuracy: 0.9611\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2790 - accuracy: 0.8934 - val_loss: 0.1277 - val_accuracy: 0.9705\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3088 - accuracy: 0.8836 - val_loss: 0.1974 - val_accuracy: 0.9209\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2829 - accuracy: 0.8945 - val_loss: 0.1074 - val_accuracy: 0.9678\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2740 - accuracy: 0.8951 - val_loss: 0.1067 - val_accuracy: 0.9745\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2500 - accuracy: 0.9043 - val_loss: 0.0846 - val_accuracy: 0.9799\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2389 - accuracy: 0.9061 - val_loss: 0.0943 - val_accuracy: 0.9665\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2405 - accuracy: 0.9091 - val_loss: 0.0879 - val_accuracy: 0.9772\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2395 - accuracy: 0.9101 - val_loss: 0.0893 - val_accuracy: 0.9759\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2381 - accuracy: 0.9115 - val_loss: 0.0782 - val_accuracy: 0.9839\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2120 - accuracy: 0.9212 - val_loss: 0.0608 - val_accuracy: 0.9853\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1948 - accuracy: 0.9307 - val_loss: 0.1015 - val_accuracy: 0.9732\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2180 - accuracy: 0.9195 - val_loss: 0.0634 - val_accuracy: 0.9853\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1967 - accuracy: 0.9279 - val_loss: 0.0670 - val_accuracy: 0.9786\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1788 - accuracy: 0.9329 - val_loss: 0.0553 - val_accuracy: 0.9826\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2032 - accuracy: 0.9256 - val_loss: 0.1003 - val_accuracy: 0.9638\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1949 - accuracy: 0.9316 - val_loss: 0.0680 - val_accuracy: 0.9786\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1818 - accuracy: 0.9380 - val_loss: 0.0678 - val_accuracy: 0.9812\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1705 - accuracy: 0.9422 - val_loss: 0.0705 - val_accuracy: 0.9786\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2003 - accuracy: 0.9304 - val_loss: 0.0171 - val_accuracy: 0.9973\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1784 - accuracy: 0.9361 - val_loss: 0.0267 - val_accuracy: 0.9973\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1673 - accuracy: 0.9399 - val_loss: 0.0224 - val_accuracy: 0.9987\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1877 - accuracy: 0.9371 - val_loss: 0.0239 - val_accuracy: 0.9987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1658 - accuracy: 0.9385 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1513 - accuracy: 0.9475 - val_loss: 0.0204 - val_accuracy: 0.9973\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1719 - accuracy: 0.9398 - val_loss: 0.0225 - val_accuracy: 0.9973\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1711 - accuracy: 0.9413 - val_loss: 0.0156 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1714 - accuracy: 0.9416 - val_loss: 0.0289 - val_accuracy: 0.9906\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1598 - accuracy: 0.9422 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1300 - accuracy: 0.9545 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1426 - accuracy: 0.9504 - val_loss: 0.0142 - val_accuracy: 0.9973\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1462 - accuracy: 0.9490 - val_loss: 0.0235 - val_accuracy: 0.9946\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1353 - accuracy: 0.9535 - val_loss: 0.0139 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1327 - accuracy: 0.9563 - val_loss: 0.0127 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1274 - accuracy: 0.9547 - val_loss: 0.0088 - val_accuracy: 0.9960\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1505 - accuracy: 0.9493 - val_loss: 0.0151 - val_accuracy: 0.9946\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1125 - accuracy: 0.9639 - val_loss: 0.0191 - val_accuracy: 0.9960\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1050 - accuracy: 0.9650 - val_loss: 0.0113 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1120 - accuracy: 0.9611 - val_loss: 0.0212 - val_accuracy: 0.9906\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1181 - accuracy: 0.9595 - val_loss: 0.0160 - val_accuracy: 0.9960\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1129 - accuracy: 0.9627 - val_loss: 0.0221 - val_accuracy: 0.9946\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1111 - accuracy: 0.9614 - val_loss: 0.0184 - val_accuracy: 0.9960\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1316 - accuracy: 0.9577 - val_loss: 0.0222 - val_accuracy: 0.9946\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1047 - accuracy: 0.9648 - val_loss: 0.0125 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1114 - accuracy: 0.9618 - val_loss: 0.0113 - val_accuracy: 0.9973\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0851 - accuracy: 0.9705 - val_loss: 0.0079 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0997 - accuracy: 0.9684 - val_loss: 0.0114 - val_accuracy: 0.9960\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1095 - accuracy: 0.9642 - val_loss: 0.0183 - val_accuracy: 0.9960\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0938 - accuracy: 0.9687 - val_loss: 0.0116 - val_accuracy: 0.9987\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 50ms/step - loss: 0.0979 - accuracy: 0.9683 - val_loss: 9.8876e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1089 - accuracy: 0.9627 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0903 - accuracy: 0.9681 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0921 - accuracy: 0.9672 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0901 - accuracy: 0.9705 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0959 - accuracy: 0.9659 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0956 - accuracy: 0.9692 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0881 - accuracy: 0.9708 - val_loss: 0.0030 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1084 - accuracy: 0.9648 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1140 - accuracy: 0.9626 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0851 - accuracy: 0.9706 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0894 - accuracy: 0.9702 - val_loss: 0.0028 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0760 - accuracy: 0.9735 - val_loss: 7.4162e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0689 - accuracy: 0.9776 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0789 - accuracy: 0.9729 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0683 - accuracy: 0.9771 - val_loss: 7.3989e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0617 - accuracy: 0.9797 - val_loss: 4.7627e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0804 - accuracy: 0.9739 - val_loss: 0.0017 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0804 - accuracy: 0.9745 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0751 - accuracy: 0.9750 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0663 - accuracy: 0.9790 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0844 - accuracy: 0.9730 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0802 - accuracy: 0.9721 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0695 - accuracy: 0.9756 - val_loss: 0.0021 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0626 - accuracy: 0.9796 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0635 - accuracy: 0.9793 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0707 - accuracy: 0.9771 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0834 - accuracy: 0.9739 - val_loss: 0.0076 - val_accuracy: 0.9973\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0760 - accuracy: 0.9747 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0691 - accuracy: 0.9771 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0791 - accuracy: 0.9745 - val_loss: 6.8908e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0782 - accuracy: 0.9735 - val_loss: 2.1252e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0777 - accuracy: 0.9735 - val_loss: 9.4971e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0806 - accuracy: 0.9729 - val_loss: 8.8183e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0673 - accuracy: 0.9791 - val_loss: 1.9768e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0621 - accuracy: 0.9809 - val_loss: 3.8245e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0752 - accuracy: 0.9760 - val_loss: 5.6299e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0716 - accuracy: 0.9781 - val_loss: 7.1452e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0652 - accuracy: 0.9781 - val_loss: 3.5001e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0779 - accuracy: 0.9736 - val_loss: 3.8979e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0676 - accuracy: 0.9750 - val_loss: 4.1659e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0584 - accuracy: 0.9808 - val_loss: 6.8718e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0671 - accuracy: 0.9763 - val_loss: 0.0014 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0609 - accuracy: 0.9836 - val_loss: 5.1217e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0579 - accuracy: 0.9821 - val_loss: 4.1395e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0634 - accuracy: 0.9802 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0518 - accuracy: 0.9821 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0671 - accuracy: 0.9796 - val_loss: 7.1525e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0604 - accuracy: 0.9814 - val_loss: 5.1426e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0624 - accuracy: 0.9776 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0657 - accuracy: 0.9799 - val_loss: 8.5813e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0604 - accuracy: 0.9797 - val_loss: 4.0128e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0512 - accuracy: 0.9829 - val_loss: 0.0021 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0512 - accuracy: 0.9848 - val_loss: 6.6120e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0497 - accuracy: 0.9838 - val_loss: 0.0042 - val_accuracy: 0.9973\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0489 - accuracy: 0.9858 - val_loss: 5.5172e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0532 - accuracy: 0.9833 - val_loss: 0.0040 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0615 - accuracy: 0.9806 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0495 - accuracy: 0.9855 - val_loss: 0.0024 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0470 - accuracy: 0.9838 - val_loss: 0.0027 - val_accuracy: 0.9987\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0632 - accuracy: 0.9800 - val_loss: 1.1311e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0516 - accuracy: 0.9818 - val_loss: 1.8108e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0834 - accuracy: 0.9747 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0552 - accuracy: 0.9817 - val_loss: 1.1362e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0527 - accuracy: 0.9817 - val_loss: 8.9902e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0618 - accuracy: 0.9811 - val_loss: 2.2574e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0478 - accuracy: 0.9854 - val_loss: 1.2309e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0513 - accuracy: 0.9835 - val_loss: 1.3594e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0520 - accuracy: 0.9824 - val_loss: 2.3427e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0474 - accuracy: 0.9839 - val_loss: 4.1202e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0681 - accuracy: 0.9784 - val_loss: 4.7478e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0430 - accuracy: 0.9860 - val_loss: 1.3255e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0451 - accuracy: 0.9854 - val_loss: 7.2597e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0435 - accuracy: 0.9873 - val_loss: 3.1857e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0563 - accuracy: 0.9829 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0511 - accuracy: 0.9820 - val_loss: 1.0046e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0451 - accuracy: 0.9858 - val_loss: 1.4940e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0422 - accuracy: 0.9867 - val_loss: 7.0933e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0675 - accuracy: 0.9762 - val_loss: 3.3984e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0606 - accuracy: 0.9811 - val_loss: 7.7520e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0556 - accuracy: 0.9803 - val_loss: 2.3693e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0596 - accuracy: 0.9802 - val_loss: 3.1836e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0516 - accuracy: 0.9847 - val_loss: 5.5445e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0480 - accuracy: 0.9845 - val_loss: 5.1638e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0416 - accuracy: 0.9875 - val_loss: 7.2991e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0599 - accuracy: 0.9809 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0376 - accuracy: 0.9872 - val_loss: 6.9195e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0436 - accuracy: 0.9878 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0355 - accuracy: 0.9884 - val_loss: 4.1087e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0477 - accuracy: 0.9855 - val_loss: 1.5847e-04 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0528 - accuracy: 0.9812 - val_loss: 0.0012 - val_accuracy: 0.9987\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0527 - accuracy: 0.9823 - val_loss: 2.2594e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0403 - accuracy: 0.9864 - val_loss: 1.1581e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0442 - accuracy: 0.9848 - val_loss: 3.1225e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0462 - accuracy: 0.9867 - val_loss: 6.1679e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0527 - accuracy: 0.9815 - val_loss: 1.8986e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0535 - accuracy: 0.9829 - val_loss: 1.6885e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0452 - accuracy: 0.9867 - val_loss: 4.9374e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0483 - accuracy: 0.9850 - val_loss: 1.8007e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0509 - accuracy: 0.9838 - val_loss: 6.3273e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0485 - accuracy: 0.9869 - val_loss: 2.6396e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0405 - accuracy: 0.9869 - val_loss: 1.4429e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0304 - accuracy: 0.9897 - val_loss: 2.6397e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0608 - accuracy: 0.9805 - val_loss: 2.0032e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0414 - accuracy: 0.9855 - val_loss: 4.6758e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0629 - accuracy: 0.9799 - val_loss: 1.2765e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0499 - accuracy: 0.9832 - val_loss: 6.9851e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0403 - accuracy: 0.9864 - val_loss: 1.1594e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0288 - accuracy: 0.9899 - val_loss: 4.1833e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0407 - accuracy: 0.9861 - val_loss: 8.1154e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0406 - accuracy: 0.9879 - val_loss: 2.8682e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0393 - accuracy: 0.9872 - val_loss: 4.4482e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0565 - accuracy: 0.9823 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0371 - accuracy: 0.9879 - val_loss: 4.5646e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0452 - accuracy: 0.9854 - val_loss: 3.6883e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0353 - accuracy: 0.9888 - val_loss: 1.1149e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0334 - accuracy: 0.9885 - val_loss: 3.6400e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0329 - accuracy: 0.9897 - val_loss: 0.0012 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0312 - accuracy: 0.9879 - val_loss: 6.6293e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0357 - accuracy: 0.9896 - val_loss: 2.3233e-04 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "CAnc2SJa3o9f",
        "outputId": "1b174028-911c-46b1-82aa-26207c638618"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 7ms/step - loss: 0.0331 - accuracy: 0.9893\n",
            "Accuracy  : 0.9892703890800476\n",
            "F1_Score  : 0.9889735762139843\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7fcxLuwZpkK",
        "outputId": "ee6321c4-7e01-41ba-d6f3-1cf50d8abf84"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "5f51894a-a5b7-44aa-cbc3-e7f3776be17f"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 52ms/step - loss: 0.9613 - accuracy: 0.6209 - val_loss: 0.8338 - val_accuracy: 0.7011\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8627 - accuracy: 0.6953 - val_loss: 0.8311 - val_accuracy: 0.7011\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8860 - accuracy: 0.6813 - val_loss: 0.8080 - val_accuracy: 0.7011\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8550 - accuracy: 0.6912 - val_loss: 0.8098 - val_accuracy: 0.7011\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8424 - accuracy: 0.6995 - val_loss: 0.8039 - val_accuracy: 0.7011\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8351 - accuracy: 0.6994 - val_loss: 0.8061 - val_accuracy: 0.7011\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8364 - accuracy: 0.7023 - val_loss: 0.8042 - val_accuracy: 0.7011\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8531 - accuracy: 0.6857 - val_loss: 0.8066 - val_accuracy: 0.7011\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8395 - accuracy: 0.6951 - val_loss: 0.8096 - val_accuracy: 0.7011\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8408 - accuracy: 0.6995 - val_loss: 0.8065 - val_accuracy: 0.7011\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8178 - accuracy: 0.7109 - val_loss: 0.8085 - val_accuracy: 0.7011\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8397 - accuracy: 0.6915 - val_loss: 0.8070 - val_accuracy: 0.7011\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8121 - accuracy: 0.7105 - val_loss: 0.8078 - val_accuracy: 0.7011\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8366 - accuracy: 0.6913 - val_loss: 0.8049 - val_accuracy: 0.7011\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8131 - accuracy: 0.7041 - val_loss: 0.8075 - val_accuracy: 0.7011\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8372 - accuracy: 0.6879 - val_loss: 0.8078 - val_accuracy: 0.7011\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8347 - accuracy: 0.6942 - val_loss: 0.8046 - val_accuracy: 0.7011\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8186 - accuracy: 0.7037 - val_loss: 0.8058 - val_accuracy: 0.7011\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8215 - accuracy: 0.6978 - val_loss: 0.8088 - val_accuracy: 0.7011\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8191 - accuracy: 0.7006 - val_loss: 0.8099 - val_accuracy: 0.7011\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8197 - accuracy: 0.7007 - val_loss: 0.8063 - val_accuracy: 0.7011\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8224 - accuracy: 0.6969 - val_loss: 0.8055 - val_accuracy: 0.7011\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8068 - accuracy: 0.7052 - val_loss: 0.8082 - val_accuracy: 0.7011\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8239 - accuracy: 0.6956 - val_loss: 0.8069 - val_accuracy: 0.7011\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8240 - accuracy: 0.6931 - val_loss: 0.8057 - val_accuracy: 0.7011\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8240 - accuracy: 0.6953 - val_loss: 0.8064 - val_accuracy: 0.7011\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8218 - accuracy: 0.6932 - val_loss: 0.8028 - val_accuracy: 0.7011\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8149 - accuracy: 0.7013 - val_loss: 0.8040 - val_accuracy: 0.7011\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8083 - accuracy: 0.7022 - val_loss: 0.8031 - val_accuracy: 0.7011\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8200 - accuracy: 0.6948 - val_loss: 0.8045 - val_accuracy: 0.7011\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8147 - accuracy: 0.6994 - val_loss: 0.8195 - val_accuracy: 0.6971\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8142 - accuracy: 0.6997 - val_loss: 0.8189 - val_accuracy: 0.6971\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8105 - accuracy: 0.6996 - val_loss: 0.8200 - val_accuracy: 0.6971\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8123 - accuracy: 0.6997 - val_loss: 0.8182 - val_accuracy: 0.6971\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8110 - accuracy: 0.6997 - val_loss: 0.8186 - val_accuracy: 0.6971\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8120 - accuracy: 0.6997 - val_loss: 0.8142 - val_accuracy: 0.6971\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8112 - accuracy: 0.6997 - val_loss: 0.8168 - val_accuracy: 0.6971\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8092 - accuracy: 0.6997 - val_loss: 0.8155 - val_accuracy: 0.6971\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8083 - accuracy: 0.6997 - val_loss: 0.8150 - val_accuracy: 0.6971\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8098 - accuracy: 0.7001 - val_loss: 0.8146 - val_accuracy: 0.6971\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8085 - accuracy: 0.6994 - val_loss: 0.8190 - val_accuracy: 0.6971\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8072 - accuracy: 0.6999 - val_loss: 0.8126 - val_accuracy: 0.6984\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8098 - accuracy: 0.6993 - val_loss: 0.8134 - val_accuracy: 0.6971\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8065 - accuracy: 0.6996 - val_loss: 0.8219 - val_accuracy: 0.6971\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8057 - accuracy: 0.7009 - val_loss: 0.8247 - val_accuracy: 0.6971\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8069 - accuracy: 0.6991 - val_loss: 0.8122 - val_accuracy: 0.6971\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8080 - accuracy: 0.6999 - val_loss: 0.8150 - val_accuracy: 0.6971\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8057 - accuracy: 0.7001 - val_loss: 0.8133 - val_accuracy: 0.6971\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8064 - accuracy: 0.7003 - val_loss: 0.8178 - val_accuracy: 0.6971\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8054 - accuracy: 0.6997 - val_loss: 0.8155 - val_accuracy: 0.6971\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8021 - accuracy: 0.7006 - val_loss: 0.8151 - val_accuracy: 0.6971\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8062 - accuracy: 0.7001 - val_loss: 0.8163 - val_accuracy: 0.6971\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8027 - accuracy: 0.6999 - val_loss: 0.8124 - val_accuracy: 0.6971\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8019 - accuracy: 0.7000 - val_loss: 0.8094 - val_accuracy: 0.6984\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8020 - accuracy: 0.6999 - val_loss: 0.8121 - val_accuracy: 0.6971\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8015 - accuracy: 0.7007 - val_loss: 0.8046 - val_accuracy: 0.6984\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8002 - accuracy: 0.6996 - val_loss: 0.8146 - val_accuracy: 0.6971\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7978 - accuracy: 0.7022 - val_loss: 0.8134 - val_accuracy: 0.6971\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8018 - accuracy: 0.6997 - val_loss: 0.8024 - val_accuracy: 0.6984\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7991 - accuracy: 0.7009 - val_loss: 0.8122 - val_accuracy: 0.6971\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8010 - accuracy: 0.7001 - val_loss: 0.7912 - val_accuracy: 0.7051\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7980 - accuracy: 0.6996 - val_loss: 0.7839 - val_accuracy: 0.7078\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7980 - accuracy: 0.7001 - val_loss: 0.7888 - val_accuracy: 0.7078\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7890 - accuracy: 0.7010 - val_loss: 0.7876 - val_accuracy: 0.7091\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7907 - accuracy: 0.7010 - val_loss: 0.8063 - val_accuracy: 0.7011\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7897 - accuracy: 0.7013 - val_loss: 0.7863 - val_accuracy: 0.7064\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7911 - accuracy: 0.7012 - val_loss: 0.7972 - val_accuracy: 0.7038\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7884 - accuracy: 0.7022 - val_loss: 0.7827 - val_accuracy: 0.7091\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7792 - accuracy: 0.7015 - val_loss: 0.8060 - val_accuracy: 0.7038\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7784 - accuracy: 0.7015 - val_loss: 0.7710 - val_accuracy: 0.7091\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7729 - accuracy: 0.7031 - val_loss: 0.7725 - val_accuracy: 0.7078\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7757 - accuracy: 0.7028 - val_loss: 0.7867 - val_accuracy: 0.7078\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7646 - accuracy: 0.7052 - val_loss: 0.7727 - val_accuracy: 0.7038\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7607 - accuracy: 0.7040 - val_loss: 0.7886 - val_accuracy: 0.7091\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7639 - accuracy: 0.7045 - val_loss: 0.7568 - val_accuracy: 0.7105\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7629 - accuracy: 0.7040 - val_loss: 0.7652 - val_accuracy: 0.7118\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7440 - accuracy: 0.7049 - val_loss: 0.7431 - val_accuracy: 0.7118\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7367 - accuracy: 0.7077 - val_loss: 0.7412 - val_accuracy: 0.7118\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7216 - accuracy: 0.7100 - val_loss: 0.7106 - val_accuracy: 0.7172\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7162 - accuracy: 0.7098 - val_loss: 0.7087 - val_accuracy: 0.7131\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7059 - accuracy: 0.7134 - val_loss: 0.7144 - val_accuracy: 0.7158\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6796 - accuracy: 0.7195 - val_loss: 0.7042 - val_accuracy: 0.7145\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6719 - accuracy: 0.7253 - val_loss: 0.6655 - val_accuracy: 0.7279\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6423 - accuracy: 0.7379 - val_loss: 0.6170 - val_accuracy: 0.7426\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6177 - accuracy: 0.7393 - val_loss: 0.6110 - val_accuracy: 0.7587\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6175 - accuracy: 0.7463 - val_loss: 0.5995 - val_accuracy: 0.7534\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5646 - accuracy: 0.7626 - val_loss: 0.6050 - val_accuracy: 0.7641\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5632 - accuracy: 0.7617 - val_loss: 0.6523 - val_accuracy: 0.7493\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5322 - accuracy: 0.7796 - val_loss: 0.5398 - val_accuracy: 0.7694\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4787 - accuracy: 0.8051 - val_loss: 0.4398 - val_accuracy: 0.8204\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4817 - accuracy: 0.8051 - val_loss: 0.2826 - val_accuracy: 0.8995\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4557 - accuracy: 0.8115 - val_loss: 0.3076 - val_accuracy: 0.8727\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4387 - accuracy: 0.8253 - val_loss: 0.2981 - val_accuracy: 0.8928\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3932 - accuracy: 0.8411 - val_loss: 0.2400 - val_accuracy: 0.9115\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3885 - accuracy: 0.8416 - val_loss: 0.2225 - val_accuracy: 0.9048\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3529 - accuracy: 0.8544 - val_loss: 0.1831 - val_accuracy: 0.9290\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3229 - accuracy: 0.8742 - val_loss: 0.1859 - val_accuracy: 0.9276\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3041 - accuracy: 0.8817 - val_loss: 0.1694 - val_accuracy: 0.9424\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3108 - accuracy: 0.8775 - val_loss: 0.1817 - val_accuracy: 0.9236\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2854 - accuracy: 0.8902 - val_loss: 0.1962 - val_accuracy: 0.9169\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2533 - accuracy: 0.9018 - val_loss: 0.1442 - val_accuracy: 0.9410\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2467 - accuracy: 0.9042 - val_loss: 0.1394 - val_accuracy: 0.9464\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2581 - accuracy: 0.9031 - val_loss: 0.1394 - val_accuracy: 0.9477\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2093 - accuracy: 0.9234 - val_loss: 0.1521 - val_accuracy: 0.9383\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2130 - accuracy: 0.9198 - val_loss: 0.1409 - val_accuracy: 0.9370\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2108 - accuracy: 0.9191 - val_loss: 0.0984 - val_accuracy: 0.9665\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1707 - accuracy: 0.9334 - val_loss: 0.1194 - val_accuracy: 0.9531\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1764 - accuracy: 0.9374 - val_loss: 0.1194 - val_accuracy: 0.9531\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1753 - accuracy: 0.9347 - val_loss: 0.1191 - val_accuracy: 0.9517\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1832 - accuracy: 0.9361 - val_loss: 0.1006 - val_accuracy: 0.9638\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1818 - accuracy: 0.9334 - val_loss: 0.0809 - val_accuracy: 0.9692\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1525 - accuracy: 0.9486 - val_loss: 0.0957 - val_accuracy: 0.9584\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1519 - accuracy: 0.9443 - val_loss: 0.0905 - val_accuracy: 0.9638\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1529 - accuracy: 0.9466 - val_loss: 0.0979 - val_accuracy: 0.9611\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1272 - accuracy: 0.9545 - val_loss: 0.0824 - val_accuracy: 0.9638\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1308 - accuracy: 0.9535 - val_loss: 0.1003 - val_accuracy: 0.9504\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1248 - accuracy: 0.9577 - val_loss: 0.0846 - val_accuracy: 0.9678\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1230 - accuracy: 0.9574 - val_loss: 0.0930 - val_accuracy: 0.9584\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1149 - accuracy: 0.9587 - val_loss: 0.0809 - val_accuracy: 0.9705\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1342 - accuracy: 0.9569 - val_loss: 0.0817 - val_accuracy: 0.9651\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1131 - accuracy: 0.9635 - val_loss: 0.0171 - val_accuracy: 0.9920\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1214 - accuracy: 0.9569 - val_loss: 0.0167 - val_accuracy: 0.9960\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1014 - accuracy: 0.9653 - val_loss: 0.0166 - val_accuracy: 0.9933\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1062 - accuracy: 0.9623 - val_loss: 0.0169 - val_accuracy: 0.9946\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1092 - accuracy: 0.9626 - val_loss: 0.0175 - val_accuracy: 0.9906\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1133 - accuracy: 0.9614 - val_loss: 0.0174 - val_accuracy: 0.9933\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0918 - accuracy: 0.9703 - val_loss: 0.0174 - val_accuracy: 0.9933\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1005 - accuracy: 0.9653 - val_loss: 0.0171 - val_accuracy: 0.9960\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1102 - accuracy: 0.9615 - val_loss: 0.0206 - val_accuracy: 0.9946\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1004 - accuracy: 0.9680 - val_loss: 0.0137 - val_accuracy: 0.9946\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0921 - accuracy: 0.9689 - val_loss: 0.0233 - val_accuracy: 0.9933\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0947 - accuracy: 0.9697 - val_loss: 0.0189 - val_accuracy: 0.9920\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0778 - accuracy: 0.9747 - val_loss: 0.0162 - val_accuracy: 0.9946\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0752 - accuracy: 0.9745 - val_loss: 0.0159 - val_accuracy: 0.9960\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0733 - accuracy: 0.9732 - val_loss: 0.0174 - val_accuracy: 0.9906\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0719 - accuracy: 0.9747 - val_loss: 0.0188 - val_accuracy: 0.9920\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0796 - accuracy: 0.9727 - val_loss: 0.0170 - val_accuracy: 0.9960\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0659 - accuracy: 0.9768 - val_loss: 0.0197 - val_accuracy: 0.9946\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0724 - accuracy: 0.9757 - val_loss: 0.0336 - val_accuracy: 0.9893\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0683 - accuracy: 0.9744 - val_loss: 0.0132 - val_accuracy: 0.9960\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0749 - accuracy: 0.9747 - val_loss: 0.0159 - val_accuracy: 0.9960\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0598 - accuracy: 0.9796 - val_loss: 0.0127 - val_accuracy: 0.9973\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0600 - accuracy: 0.9805 - val_loss: 0.0210 - val_accuracy: 0.9933\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0669 - accuracy: 0.9769 - val_loss: 0.0176 - val_accuracy: 0.9933\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0603 - accuracy: 0.9809 - val_loss: 0.0314 - val_accuracy: 0.9906\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0675 - accuracy: 0.9776 - val_loss: 0.0194 - val_accuracy: 0.9933\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0665 - accuracy: 0.9778 - val_loss: 0.0238 - val_accuracy: 0.9933\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0703 - accuracy: 0.9769 - val_loss: 0.0127 - val_accuracy: 0.9960\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0589 - accuracy: 0.9791 - val_loss: 0.0409 - val_accuracy: 0.9920\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0578 - accuracy: 0.9821 - val_loss: 0.0234 - val_accuracy: 0.9946\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0755 - accuracy: 0.9762 - val_loss: 5.6807e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0687 - accuracy: 0.9779 - val_loss: 0.0021 - val_accuracy: 0.9987\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0549 - accuracy: 0.9832 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0545 - accuracy: 0.9827 - val_loss: 0.0067 - val_accuracy: 0.9960\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0885 - accuracy: 0.9727 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0761 - accuracy: 0.9757 - val_loss: 0.0066 - val_accuracy: 0.9987\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0642 - accuracy: 0.9811 - val_loss: 0.0031 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0585 - accuracy: 0.9820 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0688 - accuracy: 0.9779 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0443 - accuracy: 0.9852 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0652 - accuracy: 0.9796 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0531 - accuracy: 0.9846 - val_loss: 0.0036 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0460 - accuracy: 0.9866 - val_loss: 0.0025 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0571 - accuracy: 0.9811 - val_loss: 6.2152e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0459 - accuracy: 0.9864 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0496 - accuracy: 0.9826 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0626 - accuracy: 0.9794 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0409 - accuracy: 0.9887 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0403 - accuracy: 0.9876 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0557 - accuracy: 0.9848 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0386 - accuracy: 0.9881 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0451 - accuracy: 0.9846 - val_loss: 4.8484e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0420 - accuracy: 0.9872 - val_loss: 5.3906e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0479 - accuracy: 0.9838 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0501 - accuracy: 0.9836 - val_loss: 8.8223e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0455 - accuracy: 0.9852 - val_loss: 5.3081e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0363 - accuracy: 0.9887 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0381 - accuracy: 0.9878 - val_loss: 0.0037 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0420 - accuracy: 0.9861 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0448 - accuracy: 0.9861 - val_loss: 0.0096 - val_accuracy: 0.9960\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0471 - accuracy: 0.9860 - val_loss: 5.9051e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0460 - accuracy: 0.9870 - val_loss: 1.1637e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0433 - accuracy: 0.9869 - val_loss: 1.2083e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0499 - accuracy: 0.9823 - val_loss: 2.6178e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0488 - accuracy: 0.9851 - val_loss: 3.6944e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0426 - accuracy: 0.9872 - val_loss: 2.4332e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0455 - accuracy: 0.9869 - val_loss: 6.2277e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0379 - accuracy: 0.9873 - val_loss: 2.2025e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0303 - accuracy: 0.9911 - val_loss: 2.0633e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0488 - accuracy: 0.9869 - val_loss: 4.1071e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0352 - accuracy: 0.9888 - val_loss: 3.0048e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0387 - accuracy: 0.9873 - val_loss: 6.0751e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0362 - accuracy: 0.9882 - val_loss: 1.5471e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0471 - accuracy: 0.9858 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0488 - accuracy: 0.9852 - val_loss: 5.5203e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0370 - accuracy: 0.9881 - val_loss: 2.1620e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0346 - accuracy: 0.9900 - val_loss: 1.5192e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0324 - accuracy: 0.9906 - val_loss: 2.1289e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0426 - accuracy: 0.9854 - val_loss: 3.4600e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0315 - accuracy: 0.9888 - val_loss: 2.5428e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0661 - accuracy: 0.9824 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0389 - accuracy: 0.9869 - val_loss: 2.0699e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0412 - accuracy: 0.9864 - val_loss: 7.2069e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0445 - accuracy: 0.9872 - val_loss: 0.0026 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0478 - accuracy: 0.9832 - val_loss: 8.8218e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0315 - accuracy: 0.9899 - val_loss: 3.5988e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0329 - accuracy: 0.9902 - val_loss: 0.0027 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0311 - accuracy: 0.9891 - val_loss: 9.6806e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0368 - accuracy: 0.9888 - val_loss: 4.0414e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0330 - accuracy: 0.9899 - val_loss: 5.1661e-05 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0307 - accuracy: 0.9911 - val_loss: 3.4218e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0462 - accuracy: 0.9848 - val_loss: 2.0694e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0372 - accuracy: 0.9867 - val_loss: 3.6423e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0426 - accuracy: 0.9844 - val_loss: 1.2056e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0387 - accuracy: 0.9870 - val_loss: 3.2762e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0451 - accuracy: 0.9860 - val_loss: 2.3556e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0543 - accuracy: 0.9809 - val_loss: 7.0518e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0307 - accuracy: 0.9891 - val_loss: 5.3792e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0469 - accuracy: 0.9847 - val_loss: 6.3103e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0419 - accuracy: 0.9869 - val_loss: 3.2332e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0359 - accuracy: 0.9887 - val_loss: 6.4904e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0385 - accuracy: 0.9887 - val_loss: 1.5098e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0261 - accuracy: 0.9902 - val_loss: 1.4824e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0239 - accuracy: 0.9915 - val_loss: 1.5896e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0343 - accuracy: 0.9896 - val_loss: 9.2996e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0563 - accuracy: 0.9811 - val_loss: 9.0448e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0272 - accuracy: 0.9908 - val_loss: 6.8802e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0207 - accuracy: 0.9939 - val_loss: 1.2530e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0327 - accuracy: 0.9891 - val_loss: 6.2750e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0311 - accuracy: 0.9903 - val_loss: 3.4167e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0370 - accuracy: 0.9893 - val_loss: 2.8759e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0465 - accuracy: 0.9857 - val_loss: 2.8055e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0289 - accuracy: 0.9909 - val_loss: 2.9809e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0337 - accuracy: 0.9899 - val_loss: 1.3470e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0270 - accuracy: 0.9915 - val_loss: 4.0395e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0259 - accuracy: 0.9920 - val_loss: 2.1601e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0304 - accuracy: 0.9914 - val_loss: 8.1660e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0238 - accuracy: 0.9917 - val_loss: 1.0842e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0245 - accuracy: 0.9931 - val_loss: 7.2200e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0225 - accuracy: 0.9920 - val_loss: 3.8103e-04 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0341 - accuracy: 0.9893 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0325 - accuracy: 0.9911 - val_loss: 1.0342e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0283 - accuracy: 0.9906 - val_loss: 2.4968e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0335 - accuracy: 0.9912 - val_loss: 4.8033e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0301 - accuracy: 0.9897 - val_loss: 7.7303e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0334 - accuracy: 0.9897 - val_loss: 3.5197e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0259 - accuracy: 0.9920 - val_loss: 1.8377e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0266 - accuracy: 0.9921 - val_loss: 3.2823e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0283 - accuracy: 0.9909 - val_loss: 1.8015e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0268 - accuracy: 0.9937 - val_loss: 5.3975e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0285 - accuracy: 0.9905 - val_loss: 2.9344e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0358 - accuracy: 0.9896 - val_loss: 2.6531e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0504 - accuracy: 0.9857 - val_loss: 7.4298e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0409 - accuracy: 0.9873 - val_loss: 1.9721e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0258 - accuracy: 0.9917 - val_loss: 2.1021e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0334 - accuracy: 0.9893 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0253 - accuracy: 0.9930 - val_loss: 7.5198e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0259 - accuracy: 0.9918 - val_loss: 7.9988e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0202 - accuracy: 0.9942 - val_loss: 2.4948e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0276 - accuracy: 0.9911 - val_loss: 3.8057e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0233 - accuracy: 0.9936 - val_loss: 7.9518e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0245 - accuracy: 0.9939 - val_loss: 3.8913e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0244 - accuracy: 0.9927 - val_loss: 7.2198e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0266 - accuracy: 0.9924 - val_loss: 5.7519e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0199 - accuracy: 0.9949 - val_loss: 2.3392e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0273 - accuracy: 0.9917 - val_loss: 1.5784e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0295 - accuracy: 0.9902 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0266 - accuracy: 0.9912 - val_loss: 3.2170e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0189 - accuracy: 0.9942 - val_loss: 2.2515e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0255 - accuracy: 0.9923 - val_loss: 4.0014e-04 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0278 - accuracy: 0.9920 - val_loss: 4.4022e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0229 - accuracy: 0.9945 - val_loss: 2.8314e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0221 - accuracy: 0.9924 - val_loss: 1.2390e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0344 - accuracy: 0.9911 - val_loss: 1.8703e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0275 - accuracy: 0.9909 - val_loss: 1.1334e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0256 - accuracy: 0.9908 - val_loss: 2.6633e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0224 - accuracy: 0.9925 - val_loss: 5.5816e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0343 - accuracy: 0.9900 - val_loss: 1.7594e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0275 - accuracy: 0.9909 - val_loss: 5.7720e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0192 - accuracy: 0.9937 - val_loss: 4.2613e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0219 - accuracy: 0.9943 - val_loss: 1.2299e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0312 - accuracy: 0.9897 - val_loss: 1.3416e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0223 - accuracy: 0.9940 - val_loss: 5.1646e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0260 - accuracy: 0.9936 - val_loss: 1.6303e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0264 - accuracy: 0.9914 - val_loss: 2.3187e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0284 - accuracy: 0.9915 - val_loss: 3.0689e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0252 - accuracy: 0.9925 - val_loss: 4.4141e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0237 - accuracy: 0.9925 - val_loss: 4.0896e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0241 - accuracy: 0.9917 - val_loss: 3.8231e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0239 - accuracy: 0.9917 - val_loss: 2.4032e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0287 - accuracy: 0.9911 - val_loss: 2.5047e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0307 - accuracy: 0.9915 - val_loss: 2.4318e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0179 - accuracy: 0.9936 - val_loss: 4.4834e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 7.8692e-06 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0325 - accuracy: 0.9906 - val_loss: 1.7374e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0286 - accuracy: 0.9914 - val_loss: 1.4415e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0205 - accuracy: 0.9942 - val_loss: 2.2996e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0238 - accuracy: 0.9923 - val_loss: 8.6651e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0272 - accuracy: 0.9917 - val_loss: 1.7016e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0329 - accuracy: 0.9914 - val_loss: 4.9381e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "ad610aa5-c493-4cf1-96c1-df2b007888eb"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 8ms/step - loss: 0.0290 - accuracy: 0.9914\n",
            "Accuracy  : 0.991416335105896\n",
            "F1_Score  : 0.9885941255493842\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "8c3b72f1-9b3f-4839-b12d-698a2a667464"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'#dominance\\nX_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\\nprint(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "f2c1e3cb-2b69-4924-a43c-8c9a2082766b"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'foldNum=0\\nmodel = get_model()\\nfor train_index, val_index in kfold.split(X_train, Y_train):\\n  foldNum = foldNum + 1\\n  print(\"Results for fold\",foldNum)\\n  x_train, x_val = X_train[train_index], X_train[val_index]\\n  y_train, y_val = Y_train[train_index], Y_train[val_index]\\n  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\\n  gc.collect() # Garbage collecter\\n  del x_train, x_val, y_train, y_val\\n  gc.collect()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "0bfb44aa-61eb-4607-950a-890a3eb8fbed"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'acrc = model.evaluate(x_test, y_test)\\npred = model.predict(x_test)\\nf1scr = f1_score(y_test.argmax(1), pred.argmax(1), average=\\'macro\\')\\nc_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\\nprint(\"Accuracy  : {}\".format(acrc[1]))\\nprint(\"F1_Score  : {}\".format(f1scr))\\nc_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\\nimport seaborn as sns\\nfigure = plt.figure(figsize=(9, 9))\\nsns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\\nplt.tight_layout()\\nplt.ylabel(\\'True label\\')\\nplt.xlabel(\\'Predicted label\\')\\nplt.show()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}