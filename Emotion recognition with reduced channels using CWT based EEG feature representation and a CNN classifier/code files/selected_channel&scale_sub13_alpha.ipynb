{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub13_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "cad12b61-db3e-49e9-d503-b98a6d11775d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e3\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  #EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "afbec8ae-dd83-4da1-dd89-7f119ab0fb1f"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(13,14):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.13\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (3029,) (3495,) (2796,)\n",
            "(9320,) (699,) (1864,) (6757,)\n",
            "(9320,) (3495,) (1631,) (4194,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "521963f3-66af-4806-e383-bcaa3da3fae8"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "d518824d-53dc-4618-bb66-560af575a6ac"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "741"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "859ed362-b432-4b61-e554-d3e2d4d9900d"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93c4fbd6-8aba-436b-cda7-79fe00609201"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 29s 56ms/step - loss: 1.2471 - accuracy: 0.3495 - val_loss: 1.0949 - val_accuracy: 0.3740\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0972 - accuracy: 0.3918 - val_loss: 1.0959 - val_accuracy: 0.3753\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0943 - accuracy: 0.3808 - val_loss: 1.0920 - val_accuracy: 0.3753\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0932 - accuracy: 0.3821 - val_loss: 1.0931 - val_accuracy: 0.3753\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0920 - accuracy: 0.3837 - val_loss: 1.0929 - val_accuracy: 0.3753\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0926 - accuracy: 0.3818 - val_loss: 1.0931 - val_accuracy: 0.3740\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0936 - accuracy: 0.3739 - val_loss: 1.0929 - val_accuracy: 0.3740\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0931 - accuracy: 0.3707 - val_loss: 1.0928 - val_accuracy: 0.3740\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0942 - accuracy: 0.3830 - val_loss: 1.0926 - val_accuracy: 0.3928\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0929 - accuracy: 0.3844 - val_loss: 1.0923 - val_accuracy: 0.3847\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0939 - accuracy: 0.3825 - val_loss: 1.0917 - val_accuracy: 0.3901\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0930 - accuracy: 0.3828 - val_loss: 1.0924 - val_accuracy: 0.3954\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0912 - accuracy: 0.3826 - val_loss: 1.0909 - val_accuracy: 0.3981\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0930 - accuracy: 0.3801 - val_loss: 1.0884 - val_accuracy: 0.3981\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0927 - accuracy: 0.3844 - val_loss: 1.0882 - val_accuracy: 0.3981\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0876 - accuracy: 0.3937 - val_loss: 1.0933 - val_accuracy: 0.3686\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0885 - accuracy: 0.3906 - val_loss: 1.0815 - val_accuracy: 0.4008\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0870 - accuracy: 0.3867 - val_loss: 1.0869 - val_accuracy: 0.3874\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0895 - accuracy: 0.3964 - val_loss: 1.0850 - val_accuracy: 0.3968\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0841 - accuracy: 0.3895 - val_loss: 1.0871 - val_accuracy: 0.3995\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0845 - accuracy: 0.3898 - val_loss: 1.0847 - val_accuracy: 0.4088\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0858 - accuracy: 0.3839 - val_loss: 1.0855 - val_accuracy: 0.3981\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0848 - accuracy: 0.3915 - val_loss: 1.0788 - val_accuracy: 0.4155\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0828 - accuracy: 0.3929 - val_loss: 1.0883 - val_accuracy: 0.3941\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0832 - accuracy: 0.3910 - val_loss: 1.0794 - val_accuracy: 0.4062\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0869 - accuracy: 0.3839 - val_loss: 1.0847 - val_accuracy: 0.4062\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0875 - accuracy: 0.3856 - val_loss: 1.0891 - val_accuracy: 0.3861\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0849 - accuracy: 0.3824 - val_loss: 1.0824 - val_accuracy: 0.3794\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0855 - accuracy: 0.3907 - val_loss: 1.0793 - val_accuracy: 0.4048\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0902 - accuracy: 0.3809 - val_loss: 1.0851 - val_accuracy: 0.4155\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0815 - accuracy: 0.4021 - val_loss: 1.0921 - val_accuracy: 0.3552\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0822 - accuracy: 0.3934 - val_loss: 1.0911 - val_accuracy: 0.3619\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0814 - accuracy: 0.3966 - val_loss: 1.0765 - val_accuracy: 0.3606\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0802 - accuracy: 0.3920 - val_loss: 1.0898 - val_accuracy: 0.3512\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0814 - accuracy: 0.3952 - val_loss: 1.0981 - val_accuracy: 0.3660\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0781 - accuracy: 0.3990 - val_loss: 1.0981 - val_accuracy: 0.3660\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0815 - accuracy: 0.3978 - val_loss: 1.0744 - val_accuracy: 0.3592\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0771 - accuracy: 0.3966 - val_loss: 1.0731 - val_accuracy: 0.3646\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0786 - accuracy: 0.4060 - val_loss: 1.0818 - val_accuracy: 0.3458\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0797 - accuracy: 0.3964 - val_loss: 1.0969 - val_accuracy: 0.3552\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0765 - accuracy: 0.4033 - val_loss: 1.0738 - val_accuracy: 0.3995\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0753 - accuracy: 0.3993 - val_loss: 1.0739 - val_accuracy: 0.3592\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0759 - accuracy: 0.4030 - val_loss: 1.0911 - val_accuracy: 0.3673\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0756 - accuracy: 0.3997 - val_loss: 1.0783 - val_accuracy: 0.3794\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0712 - accuracy: 0.3984 - val_loss: 1.0722 - val_accuracy: 0.3847\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0703 - accuracy: 0.4131 - val_loss: 1.0775 - val_accuracy: 0.3552\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0727 - accuracy: 0.4115 - val_loss: 1.0685 - val_accuracy: 0.3807\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0725 - accuracy: 0.4052 - val_loss: 1.0673 - val_accuracy: 0.3820\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0698 - accuracy: 0.4097 - val_loss: 1.0929 - val_accuracy: 0.3713\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0723 - accuracy: 0.4106 - val_loss: 1.0723 - val_accuracy: 0.3673\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0698 - accuracy: 0.4159 - val_loss: 1.0778 - val_accuracy: 0.3794\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0731 - accuracy: 0.4095 - val_loss: 1.0693 - val_accuracy: 0.3914\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0669 - accuracy: 0.4067 - val_loss: 1.0692 - val_accuracy: 0.3928\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0654 - accuracy: 0.4168 - val_loss: 1.0620 - val_accuracy: 0.3981\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0668 - accuracy: 0.4036 - val_loss: 1.0569 - val_accuracy: 0.4088\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0616 - accuracy: 0.4185 - val_loss: 1.0802 - val_accuracy: 0.3820\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0617 - accuracy: 0.4244 - val_loss: 1.0591 - val_accuracy: 0.3968\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0609 - accuracy: 0.4204 - val_loss: 1.0549 - val_accuracy: 0.3820\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0660 - accuracy: 0.4182 - val_loss: 1.0592 - val_accuracy: 0.3807\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0568 - accuracy: 0.4192 - val_loss: 1.0567 - val_accuracy: 0.3954\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0622 - accuracy: 0.4164 - val_loss: 1.0672 - val_accuracy: 0.4290\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0584 - accuracy: 0.4238 - val_loss: 1.0512 - val_accuracy: 0.4290\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0570 - accuracy: 0.4194 - val_loss: 1.0518 - val_accuracy: 0.4357\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0505 - accuracy: 0.4301 - val_loss: 1.0496 - val_accuracy: 0.4464\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0515 - accuracy: 0.4395 - val_loss: 1.0655 - val_accuracy: 0.4196\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0505 - accuracy: 0.4365 - val_loss: 1.0676 - val_accuracy: 0.4088\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0470 - accuracy: 0.4386 - val_loss: 1.0536 - val_accuracy: 0.4249\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0475 - accuracy: 0.4379 - val_loss: 1.0550 - val_accuracy: 0.4142\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0456 - accuracy: 0.4395 - val_loss: 1.0457 - val_accuracy: 0.4343\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0332 - accuracy: 0.4523 - val_loss: 1.0377 - val_accuracy: 0.4491\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0299 - accuracy: 0.4621 - val_loss: 1.0443 - val_accuracy: 0.4343\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0238 - accuracy: 0.4602 - val_loss: 1.0356 - val_accuracy: 0.4544\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0175 - accuracy: 0.4694 - val_loss: 1.0218 - val_accuracy: 0.4906\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0131 - accuracy: 0.4770 - val_loss: 1.0355 - val_accuracy: 0.4732\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0042 - accuracy: 0.4723 - val_loss: 1.0376 - val_accuracy: 0.4745\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9947 - accuracy: 0.4818 - val_loss: 1.0284 - val_accuracy: 0.5107\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9886 - accuracy: 0.4951 - val_loss: 1.0345 - val_accuracy: 0.4879\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9808 - accuracy: 0.4872 - val_loss: 1.0159 - val_accuracy: 0.4946\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9575 - accuracy: 0.5098 - val_loss: 0.9947 - val_accuracy: 0.5080\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9541 - accuracy: 0.5140 - val_loss: 0.9602 - val_accuracy: 0.5214\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9393 - accuracy: 0.5255 - val_loss: 0.9901 - val_accuracy: 0.5013\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9202 - accuracy: 0.5396 - val_loss: 0.9769 - val_accuracy: 0.5147\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9119 - accuracy: 0.5529 - val_loss: 0.9844 - val_accuracy: 0.4799\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8945 - accuracy: 0.5697 - val_loss: 0.9465 - val_accuracy: 0.5429\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8730 - accuracy: 0.5773 - val_loss: 1.0068 - val_accuracy: 0.5161\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8676 - accuracy: 0.5836 - val_loss: 0.8960 - val_accuracy: 0.5684\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8590 - accuracy: 0.5934 - val_loss: 0.9042 - val_accuracy: 0.5550\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8096 - accuracy: 0.6261 - val_loss: 0.8318 - val_accuracy: 0.6287\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7823 - accuracy: 0.6443 - val_loss: 0.8108 - val_accuracy: 0.6367\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7618 - accuracy: 0.6592 - val_loss: 0.8026 - val_accuracy: 0.6287\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7552 - accuracy: 0.6653 - val_loss: 0.5919 - val_accuracy: 0.7507\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7340 - accuracy: 0.6785 - val_loss: 0.5609 - val_accuracy: 0.7574\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6932 - accuracy: 0.6958 - val_loss: 0.4856 - val_accuracy: 0.8150\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6719 - accuracy: 0.7077 - val_loss: 0.4353 - val_accuracy: 0.8164\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6422 - accuracy: 0.7301 - val_loss: 0.4211 - val_accuracy: 0.8324\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5652 - accuracy: 0.7747 - val_loss: 0.4550 - val_accuracy: 0.8083\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5778 - accuracy: 0.7589 - val_loss: 0.5052 - val_accuracy: 0.7815\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5290 - accuracy: 0.7900 - val_loss: 0.3674 - val_accuracy: 0.8686\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5042 - accuracy: 0.7946 - val_loss: 0.4058 - val_accuracy: 0.8324\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4863 - accuracy: 0.8076 - val_loss: 0.3299 - val_accuracy: 0.8767\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4601 - accuracy: 0.8198 - val_loss: 0.2948 - val_accuracy: 0.8861\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4067 - accuracy: 0.8446 - val_loss: 0.3568 - val_accuracy: 0.8592\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4389 - accuracy: 0.8370 - val_loss: 0.2490 - val_accuracy: 0.8941\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3583 - accuracy: 0.8703 - val_loss: 0.2437 - val_accuracy: 0.9142\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3493 - accuracy: 0.8687 - val_loss: 0.2363 - val_accuracy: 0.8995\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3109 - accuracy: 0.8875 - val_loss: 0.2341 - val_accuracy: 0.9021\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3347 - accuracy: 0.8826 - val_loss: 0.2701 - val_accuracy: 0.8887\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3072 - accuracy: 0.8900 - val_loss: 0.2183 - val_accuracy: 0.9102\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2689 - accuracy: 0.9019 - val_loss: 0.1911 - val_accuracy: 0.9155\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2793 - accuracy: 0.9025 - val_loss: 0.1784 - val_accuracy: 0.9357\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2578 - accuracy: 0.9057 - val_loss: 0.1766 - val_accuracy: 0.9343\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2199 - accuracy: 0.9215 - val_loss: 0.1774 - val_accuracy: 0.9397\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.2475 - accuracy: 0.9146 - val_loss: 0.1645 - val_accuracy: 0.9370\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2529 - accuracy: 0.9098 - val_loss: 0.2127 - val_accuracy: 0.9182\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2286 - accuracy: 0.9209 - val_loss: 0.1254 - val_accuracy: 0.9531\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2029 - accuracy: 0.9322 - val_loss: 0.1148 - val_accuracy: 0.9544\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2149 - accuracy: 0.9317 - val_loss: 0.1343 - val_accuracy: 0.9437\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1894 - accuracy: 0.9365 - val_loss: 0.1370 - val_accuracy: 0.9477\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1830 - accuracy: 0.9389 - val_loss: 0.1060 - val_accuracy: 0.9611\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1788 - accuracy: 0.9393 - val_loss: 0.1223 - val_accuracy: 0.9584\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2169 - accuracy: 0.9250 - val_loss: 0.0128 - val_accuracy: 0.9987\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1988 - accuracy: 0.9323 - val_loss: 0.0214 - val_accuracy: 0.9933\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1943 - accuracy: 0.9316 - val_loss: 0.0167 - val_accuracy: 0.9960\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1747 - accuracy: 0.9417 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1785 - accuracy: 0.9416 - val_loss: 0.0090 - val_accuracy: 0.9987\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1586 - accuracy: 0.9490 - val_loss: 0.0138 - val_accuracy: 0.9973\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1640 - accuracy: 0.9447 - val_loss: 0.0130 - val_accuracy: 0.9973\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1721 - accuracy: 0.9444 - val_loss: 0.0172 - val_accuracy: 0.9973\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1297 - accuracy: 0.9563 - val_loss: 0.0123 - val_accuracy: 0.9987\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1308 - accuracy: 0.9559 - val_loss: 0.0102 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.1282 - accuracy: 0.9578 - val_loss: 0.0149 - val_accuracy: 0.9933\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1351 - accuracy: 0.9532 - val_loss: 0.0180 - val_accuracy: 0.9946\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1202 - accuracy: 0.9593 - val_loss: 0.0199 - val_accuracy: 0.9933\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1542 - accuracy: 0.9508 - val_loss: 0.0204 - val_accuracy: 0.9946\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1331 - accuracy: 0.9571 - val_loss: 0.0095 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1281 - accuracy: 0.9596 - val_loss: 0.0115 - val_accuracy: 0.9960\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1209 - accuracy: 0.9599 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1283 - accuracy: 0.9592 - val_loss: 0.0122 - val_accuracy: 0.9973\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.1130 - accuracy: 0.9627 - val_loss: 0.0162 - val_accuracy: 0.9946\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1125 - accuracy: 0.9635 - val_loss: 0.0097 - val_accuracy: 0.9973\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0993 - accuracy: 0.9689 - val_loss: 0.0107 - val_accuracy: 0.9973\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1198 - accuracy: 0.9610 - val_loss: 0.0137 - val_accuracy: 0.9960\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1067 - accuracy: 0.9659 - val_loss: 0.0136 - val_accuracy: 0.9946\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0919 - accuracy: 0.9692 - val_loss: 0.0105 - val_accuracy: 0.9973\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1044 - accuracy: 0.9674 - val_loss: 0.0184 - val_accuracy: 0.9946\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1016 - accuracy: 0.9650 - val_loss: 0.0085 - val_accuracy: 0.9973\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1163 - accuracy: 0.9629 - val_loss: 0.0185 - val_accuracy: 0.9933\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0891 - accuracy: 0.9686 - val_loss: 0.0119 - val_accuracy: 0.9973\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0907 - accuracy: 0.9718 - val_loss: 0.0425 - val_accuracy: 0.9826\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0803 - accuracy: 0.9715 - val_loss: 0.0108 - val_accuracy: 0.9960\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0895 - accuracy: 0.9711 - val_loss: 6.7573e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.1004 - accuracy: 0.9687 - val_loss: 2.8977e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0972 - accuracy: 0.9671 - val_loss: 7.8080e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0935 - accuracy: 0.9694 - val_loss: 5.0939e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1021 - accuracy: 0.9675 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0996 - accuracy: 0.9690 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0862 - accuracy: 0.9733 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0892 - accuracy: 0.9733 - val_loss: 3.2854e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0916 - accuracy: 0.9694 - val_loss: 0.0178 - val_accuracy: 0.9933\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0866 - accuracy: 0.9712 - val_loss: 7.6133e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0631 - accuracy: 0.9802 - val_loss: 2.5722e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0716 - accuracy: 0.9763 - val_loss: 0.0029 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1146 - accuracy: 0.9647 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0748 - accuracy: 0.9760 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0925 - accuracy: 0.9696 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0830 - accuracy: 0.9736 - val_loss: 8.4580e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0758 - accuracy: 0.9745 - val_loss: 6.2901e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0822 - accuracy: 0.9723 - val_loss: 6.2357e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0784 - accuracy: 0.9763 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0742 - accuracy: 0.9768 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0526 - accuracy: 0.9802 - val_loss: 9.1623e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0629 - accuracy: 0.9799 - val_loss: 6.3528e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0631 - accuracy: 0.9800 - val_loss: 0.0032 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0704 - accuracy: 0.9772 - val_loss: 6.1139e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0689 - accuracy: 0.9773 - val_loss: 0.0024 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0912 - accuracy: 0.9732 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0787 - accuracy: 0.9751 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0677 - accuracy: 0.9802 - val_loss: 6.1961e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0622 - accuracy: 0.9808 - val_loss: 0.0060 - val_accuracy: 0.9973\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0696 - accuracy: 0.9765 - val_loss: 7.7956e-04 - val_accuracy: 1.0000\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0754 - accuracy: 0.9751 - val_loss: 8.1582e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0663 - accuracy: 0.9790 - val_loss: 1.7525e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0840 - accuracy: 0.9742 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0674 - accuracy: 0.9787 - val_loss: 1.7716e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0735 - accuracy: 0.9772 - val_loss: 4.9109e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0682 - accuracy: 0.9781 - val_loss: 3.7334e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0649 - accuracy: 0.9794 - val_loss: 1.9989e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0521 - accuracy: 0.9839 - val_loss: 1.2911e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0944 - accuracy: 0.9723 - val_loss: 5.1446e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0578 - accuracy: 0.9808 - val_loss: 1.8983e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0559 - accuracy: 0.9826 - val_loss: 3.5697e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0646 - accuracy: 0.9779 - val_loss: 2.1849e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0625 - accuracy: 0.9820 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0649 - accuracy: 0.9794 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0609 - accuracy: 0.9808 - val_loss: 8.2599e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0727 - accuracy: 0.9778 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0590 - accuracy: 0.9809 - val_loss: 0.0032 - val_accuracy: 0.9973\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0425 - accuracy: 0.9860 - val_loss: 6.0230e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0551 - accuracy: 0.9832 - val_loss: 1.9563e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0778 - accuracy: 0.9750 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0652 - accuracy: 0.9799 - val_loss: 0.0022 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0632 - accuracy: 0.9797 - val_loss: 0.0035 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0566 - accuracy: 0.9826 - val_loss: 4.2218e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0499 - accuracy: 0.9841 - val_loss: 0.0014 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0560 - accuracy: 0.9817 - val_loss: 7.2452e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0568 - accuracy: 0.9830 - val_loss: 0.0020 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0483 - accuracy: 0.9833 - val_loss: 2.0789e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0577 - accuracy: 0.9809 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0518 - accuracy: 0.9806 - val_loss: 2.8698e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0497 - accuracy: 0.9847 - val_loss: 4.3250e-04 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0679 - accuracy: 0.9791 - val_loss: 3.4676e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0501 - accuracy: 0.9808 - val_loss: 3.0093e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0535 - accuracy: 0.9820 - val_loss: 1.4748e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0591 - accuracy: 0.9823 - val_loss: 1.2213e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0481 - accuracy: 0.9835 - val_loss: 5.0661e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0569 - accuracy: 0.9830 - val_loss: 3.5849e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0548 - accuracy: 0.9835 - val_loss: 1.6652e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0464 - accuracy: 0.9847 - val_loss: 5.4635e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0547 - accuracy: 0.9835 - val_loss: 1.6070e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0495 - accuracy: 0.9851 - val_loss: 3.4052e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0368 - accuracy: 0.9893 - val_loss: 5.0476e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0460 - accuracy: 0.9852 - val_loss: 2.8409e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0549 - accuracy: 0.9835 - val_loss: 9.5829e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0524 - accuracy: 0.9835 - val_loss: 5.3398e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0459 - accuracy: 0.9866 - val_loss: 7.2721e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0493 - accuracy: 0.9850 - val_loss: 6.3057e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0566 - accuracy: 0.9820 - val_loss: 1.5667e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0451 - accuracy: 0.9861 - val_loss: 8.7896e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0446 - accuracy: 0.9870 - val_loss: 7.8475e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0561 - accuracy: 0.9823 - val_loss: 2.9815e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0435 - accuracy: 0.9861 - val_loss: 2.3845e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0420 - accuracy: 0.9855 - val_loss: 3.8185e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0465 - accuracy: 0.9858 - val_loss: 9.9501e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0449 - accuracy: 0.9854 - val_loss: 1.0146e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0398 - accuracy: 0.9878 - val_loss: 6.9952e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0385 - accuracy: 0.9878 - val_loss: 7.7423e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0449 - accuracy: 0.9864 - val_loss: 0.0065 - val_accuracy: 0.9973\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0523 - accuracy: 0.9842 - val_loss: 6.7576e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0429 - accuracy: 0.9866 - val_loss: 5.7158e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0518 - accuracy: 0.9844 - val_loss: 1.4814e-04 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0444 - accuracy: 0.9878 - val_loss: 3.3762e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0701 - accuracy: 0.9799 - val_loss: 1.8380e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0440 - accuracy: 0.9854 - val_loss: 5.3318e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0373 - accuracy: 0.9873 - val_loss: 1.6734e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0416 - accuracy: 0.9872 - val_loss: 6.8374e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0626 - accuracy: 0.9803 - val_loss: 3.1520e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0444 - accuracy: 0.9885 - val_loss: 7.1234e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0359 - accuracy: 0.9890 - val_loss: 3.7344e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0387 - accuracy: 0.9876 - val_loss: 8.6807e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0562 - accuracy: 0.9832 - val_loss: 7.8268e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0358 - accuracy: 0.9888 - val_loss: 1.0190e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0459 - accuracy: 0.9854 - val_loss: 1.4293e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0452 - accuracy: 0.9873 - val_loss: 5.6989e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0492 - accuracy: 0.9848 - val_loss: 1.4632e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0373 - accuracy: 0.9893 - val_loss: 2.9964e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0457 - accuracy: 0.9869 - val_loss: 7.8044e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0364 - accuracy: 0.9891 - val_loss: 3.0483e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0348 - accuracy: 0.9875 - val_loss: 1.3462e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0443 - accuracy: 0.9860 - val_loss: 2.6611e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0468 - accuracy: 0.9857 - val_loss: 2.4615e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0413 - accuracy: 0.9867 - val_loss: 7.0127e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0358 - accuracy: 0.9891 - val_loss: 1.5462e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0515 - accuracy: 0.9830 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0350 - accuracy: 0.9887 - val_loss: 5.3785e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0372 - accuracy: 0.9879 - val_loss: 6.2766e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0375 - accuracy: 0.9881 - val_loss: 2.4376e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0452 - accuracy: 0.9845 - val_loss: 6.0595e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0328 - accuracy: 0.9906 - val_loss: 1.1875e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0283 - accuracy: 0.9894 - val_loss: 4.8193e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0340 - accuracy: 0.9881 - val_loss: 1.0201e-04 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0543 - accuracy: 0.9829 - val_loss: 1.6117e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0478 - accuracy: 0.9872 - val_loss: 5.8289e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0438 - accuracy: 0.9847 - val_loss: 1.8864e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0302 - accuracy: 0.9912 - val_loss: 1.0298e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0336 - accuracy: 0.9890 - val_loss: 1.6211e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0399 - accuracy: 0.9870 - val_loss: 1.2581e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0375 - accuracy: 0.9881 - val_loss: 3.3712e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0392 - accuracy: 0.9876 - val_loss: 1.9744e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0374 - accuracy: 0.9885 - val_loss: 5.4544e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0355 - accuracy: 0.9888 - val_loss: 4.4696e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0343 - accuracy: 0.9888 - val_loss: 1.4275e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0339 - accuracy: 0.9884 - val_loss: 6.2535e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0474 - accuracy: 0.9832 - val_loss: 5.0175e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0469 - accuracy: 0.9847 - val_loss: 3.3769e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0438 - accuracy: 0.9861 - val_loss: 2.2681e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0301 - accuracy: 0.9914 - val_loss: 4.1298e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0390 - accuracy: 0.9879 - val_loss: 7.1836e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0336 - accuracy: 0.9890 - val_loss: 1.8968e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0377 - accuracy: 0.9888 - val_loss: 7.5922e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0277 - accuracy: 0.9911 - val_loss: 4.0871e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0353 - accuracy: 0.9884 - val_loss: 5.6481e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0427 - accuracy: 0.9875 - val_loss: 1.5214e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0405 - accuracy: 0.9873 - val_loss: 6.9938e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1722 - accuracy: 0.9535 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0513 - accuracy: 0.9851 - val_loss: 1.9781e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0469 - accuracy: 0.9850 - val_loss: 2.0228e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0346 - accuracy: 0.9887 - val_loss: 5.7462e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0338 - accuracy: 0.9885 - val_loss: 4.9313e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0287 - accuracy: 0.9914 - val_loss: 5.6914e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0376 - accuracy: 0.9882 - val_loss: 6.0744e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "CAnc2SJa3o9f",
        "outputId": "966dedd0-60b5-4336-9d37-fc5edc95443c"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 7ms/step - loss: 0.0396 - accuracy: 0.9844\n",
            "Accuracy  : 0.9844420552253723\n",
            "F1_Score  : 0.9844425049080076\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7fcxLuwZpkK",
        "outputId": "b3e4de63-dbb1-4e43-c14f-b10a10a557e6"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "5244955f-5769-475a-ec63-9f8a08527d15"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 50ms/step - loss: 0.9054 - accuracy: 0.6768 - val_loss: 0.8089 - val_accuracy: 0.7064\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.7946 - accuracy: 0.7300 - val_loss: 0.7787 - val_accuracy: 0.7064\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.7955 - accuracy: 0.7204 - val_loss: 0.7626 - val_accuracy: 0.7064\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.7818 - accuracy: 0.7293 - val_loss: 0.7652 - val_accuracy: 0.7064\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7732 - accuracy: 0.7312 - val_loss: 0.7687 - val_accuracy: 0.7064\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7732 - accuracy: 0.7327 - val_loss: 0.7674 - val_accuracy: 0.7064\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7720 - accuracy: 0.7269 - val_loss: 0.7646 - val_accuracy: 0.7064\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7824 - accuracy: 0.7227 - val_loss: 0.7659 - val_accuracy: 0.7064\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7654 - accuracy: 0.7267 - val_loss: 0.7664 - val_accuracy: 0.7064\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7587 - accuracy: 0.7312 - val_loss: 0.7627 - val_accuracy: 0.7064\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7643 - accuracy: 0.7279 - val_loss: 0.7650 - val_accuracy: 0.7064\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7531 - accuracy: 0.7325 - val_loss: 0.7669 - val_accuracy: 0.7064\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7509 - accuracy: 0.7309 - val_loss: 0.7645 - val_accuracy: 0.7064\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7559 - accuracy: 0.7297 - val_loss: 0.7623 - val_accuracy: 0.7064\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.7743 - accuracy: 0.7186 - val_loss: 0.7635 - val_accuracy: 0.7064\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7553 - accuracy: 0.7261 - val_loss: 0.7641 - val_accuracy: 0.7064\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7592 - accuracy: 0.7255 - val_loss: 0.7620 - val_accuracy: 0.7064\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7531 - accuracy: 0.7276 - val_loss: 0.7612 - val_accuracy: 0.7064\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7475 - accuracy: 0.7289 - val_loss: 0.7614 - val_accuracy: 0.7064\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.7489 - accuracy: 0.7271 - val_loss: 0.7600 - val_accuracy: 0.7064\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7366 - accuracy: 0.7323 - val_loss: 0.7595 - val_accuracy: 0.7064\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7448 - accuracy: 0.7229 - val_loss: 0.7580 - val_accuracy: 0.7064\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7469 - accuracy: 0.7299 - val_loss: 0.7616 - val_accuracy: 0.7064\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7250 - accuracy: 0.7414 - val_loss: 0.7585 - val_accuracy: 0.7064\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7398 - accuracy: 0.7325 - val_loss: 0.7564 - val_accuracy: 0.7064\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7450 - accuracy: 0.7273 - val_loss: 0.7533 - val_accuracy: 0.7064\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.7485 - accuracy: 0.7246 - val_loss: 0.7550 - val_accuracy: 0.7064\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7521 - accuracy: 0.7181 - val_loss: 0.7649 - val_accuracy: 0.7064\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7492 - accuracy: 0.7215 - val_loss: 0.7586 - val_accuracy: 0.7064\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.7409 - accuracy: 0.7291 - val_loss: 0.7513 - val_accuracy: 0.7064\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7417 - accuracy: 0.7243 - val_loss: 0.7365 - val_accuracy: 0.7239\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7440 - accuracy: 0.7243 - val_loss: 0.7546 - val_accuracy: 0.7239\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7428 - accuracy: 0.7243 - val_loss: 0.7327 - val_accuracy: 0.7239\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7403 - accuracy: 0.7243 - val_loss: 0.7338 - val_accuracy: 0.7239\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7408 - accuracy: 0.7243 - val_loss: 0.7332 - val_accuracy: 0.7239\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7409 - accuracy: 0.7243 - val_loss: 0.7370 - val_accuracy: 0.7239\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7393 - accuracy: 0.7243 - val_loss: 0.7349 - val_accuracy: 0.7239\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7379 - accuracy: 0.7243 - val_loss: 0.7367 - val_accuracy: 0.7239\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.7392 - accuracy: 0.7243 - val_loss: 0.7318 - val_accuracy: 0.7239\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7347 - accuracy: 0.7243 - val_loss: 0.7329 - val_accuracy: 0.7239\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7340 - accuracy: 0.7243 - val_loss: 0.7299 - val_accuracy: 0.7239\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7343 - accuracy: 0.7243 - val_loss: 0.7326 - val_accuracy: 0.7239\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7306 - accuracy: 0.7243 - val_loss: 0.7351 - val_accuracy: 0.7239\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7308 - accuracy: 0.7243 - val_loss: 0.7237 - val_accuracy: 0.7239\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7286 - accuracy: 0.7243 - val_loss: 0.7403 - val_accuracy: 0.7239\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7293 - accuracy: 0.7243 - val_loss: 0.7199 - val_accuracy: 0.7239\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7275 - accuracy: 0.7243 - val_loss: 0.7268 - val_accuracy: 0.7239\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7235 - accuracy: 0.7243 - val_loss: 0.7336 - val_accuracy: 0.7239\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7189 - accuracy: 0.7243 - val_loss: 0.7354 - val_accuracy: 0.7239\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7212 - accuracy: 0.7243 - val_loss: 0.7168 - val_accuracy: 0.7239\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7213 - accuracy: 0.7243 - val_loss: 0.7170 - val_accuracy: 0.7239\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7050 - accuracy: 0.7243 - val_loss: 0.7114 - val_accuracy: 0.7239\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7074 - accuracy: 0.7243 - val_loss: 0.7102 - val_accuracy: 0.7239\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7042 - accuracy: 0.7243 - val_loss: 0.7282 - val_accuracy: 0.7239\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6949 - accuracy: 0.7243 - val_loss: 0.7099 - val_accuracy: 0.7239\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6931 - accuracy: 0.7243 - val_loss: 0.6821 - val_accuracy: 0.7239\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6902 - accuracy: 0.7243 - val_loss: 0.7301 - val_accuracy: 0.7239\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6851 - accuracy: 0.7243 - val_loss: 0.6944 - val_accuracy: 0.7239\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6764 - accuracy: 0.7243 - val_loss: 0.6731 - val_accuracy: 0.7239\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.6671 - accuracy: 0.7243 - val_loss: 0.6668 - val_accuracy: 0.7239\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6655 - accuracy: 0.7237 - val_loss: 0.6451 - val_accuracy: 0.7292\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6549 - accuracy: 0.7232 - val_loss: 0.6117 - val_accuracy: 0.7292\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.6454 - accuracy: 0.7237 - val_loss: 0.6950 - val_accuracy: 0.7292\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6341 - accuracy: 0.7237 - val_loss: 0.6178 - val_accuracy: 0.7292\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6142 - accuracy: 0.7243 - val_loss: 0.5980 - val_accuracy: 0.7292\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5976 - accuracy: 0.7252 - val_loss: 0.5904 - val_accuracy: 0.7292\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.5942 - accuracy: 0.7301 - val_loss: 0.5680 - val_accuracy: 0.7480\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5818 - accuracy: 0.7294 - val_loss: 0.5852 - val_accuracy: 0.7292\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5947 - accuracy: 0.7240 - val_loss: 0.5391 - val_accuracy: 0.7292\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5428 - accuracy: 0.7240 - val_loss: 0.5665 - val_accuracy: 0.7292\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5335 - accuracy: 0.7258 - val_loss: 0.5947 - val_accuracy: 0.7292\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5280 - accuracy: 0.7551 - val_loss: 0.5215 - val_accuracy: 0.7453\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5127 - accuracy: 0.7547 - val_loss: 0.5094 - val_accuracy: 0.7775\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4923 - accuracy: 0.7982 - val_loss: 0.4804 - val_accuracy: 0.8070\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4630 - accuracy: 0.8109 - val_loss: 0.5127 - val_accuracy: 0.7788\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4634 - accuracy: 0.8161 - val_loss: 0.4724 - val_accuracy: 0.8003\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4386 - accuracy: 0.8270 - val_loss: 0.4989 - val_accuracy: 0.7560\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4299 - accuracy: 0.8294 - val_loss: 0.4034 - val_accuracy: 0.8204\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4134 - accuracy: 0.8411 - val_loss: 0.4113 - val_accuracy: 0.8097\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3982 - accuracy: 0.8423 - val_loss: 0.3800 - val_accuracy: 0.8378\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4006 - accuracy: 0.8474 - val_loss: 0.4246 - val_accuracy: 0.8365\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3875 - accuracy: 0.8516 - val_loss: 0.3984 - val_accuracy: 0.8458\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3725 - accuracy: 0.8569 - val_loss: 0.3798 - val_accuracy: 0.8405\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3589 - accuracy: 0.8626 - val_loss: 0.3340 - val_accuracy: 0.8633\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3700 - accuracy: 0.8566 - val_loss: 0.3205 - val_accuracy: 0.8633\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3427 - accuracy: 0.8700 - val_loss: 0.3243 - val_accuracy: 0.8713\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3408 - accuracy: 0.8709 - val_loss: 0.3214 - val_accuracy: 0.8740\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3132 - accuracy: 0.8776 - val_loss: 0.3997 - val_accuracy: 0.8579\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3096 - accuracy: 0.8796 - val_loss: 0.3599 - val_accuracy: 0.8579\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3082 - accuracy: 0.8821 - val_loss: 0.4277 - val_accuracy: 0.8552\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3390 - accuracy: 0.8708 - val_loss: 0.2272 - val_accuracy: 0.8928\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3069 - accuracy: 0.8805 - val_loss: 0.2034 - val_accuracy: 0.9048\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2946 - accuracy: 0.8836 - val_loss: 0.2155 - val_accuracy: 0.8995\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.2857 - accuracy: 0.8879 - val_loss: 0.2091 - val_accuracy: 0.8954\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3029 - accuracy: 0.8802 - val_loss: 0.2619 - val_accuracy: 0.8847\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3078 - accuracy: 0.8842 - val_loss: 0.2083 - val_accuracy: 0.9021\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2724 - accuracy: 0.8939 - val_loss: 0.2027 - val_accuracy: 0.9008\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.2547 - accuracy: 0.8982 - val_loss: 0.2012 - val_accuracy: 0.9035\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2629 - accuracy: 0.8973 - val_loss: 0.1972 - val_accuracy: 0.9035\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2608 - accuracy: 0.8967 - val_loss: 0.2133 - val_accuracy: 0.8995\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2508 - accuracy: 0.8988 - val_loss: 0.2086 - val_accuracy: 0.9008\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2467 - accuracy: 0.9009 - val_loss: 0.2053 - val_accuracy: 0.9008\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2393 - accuracy: 0.9016 - val_loss: 0.1952 - val_accuracy: 0.9035\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2470 - accuracy: 0.9010 - val_loss: 0.2052 - val_accuracy: 0.9035\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2449 - accuracy: 0.9031 - val_loss: 0.2013 - val_accuracy: 0.9021\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2447 - accuracy: 0.9003 - val_loss: 0.2045 - val_accuracy: 0.9021\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2435 - accuracy: 0.9001 - val_loss: 0.2006 - val_accuracy: 0.9021\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2452 - accuracy: 0.8991 - val_loss: 0.2011 - val_accuracy: 0.8995\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2333 - accuracy: 0.9021 - val_loss: 0.1939 - val_accuracy: 0.9035\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2418 - accuracy: 0.9010 - val_loss: 0.2093 - val_accuracy: 0.8981\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2296 - accuracy: 0.9046 - val_loss: 0.1858 - val_accuracy: 0.9062\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2281 - accuracy: 0.9058 - val_loss: 0.2135 - val_accuracy: 0.9008\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2358 - accuracy: 0.9003 - val_loss: 0.1930 - val_accuracy: 0.9048\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.2175 - accuracy: 0.9073 - val_loss: 0.1913 - val_accuracy: 0.9021\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2346 - accuracy: 0.8985 - val_loss: 0.1863 - val_accuracy: 0.9021\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2199 - accuracy: 0.9052 - val_loss: 0.1863 - val_accuracy: 0.9062\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2033 - accuracy: 0.9100 - val_loss: 0.1890 - val_accuracy: 0.9048\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1991 - accuracy: 0.9121 - val_loss: 0.1781 - val_accuracy: 0.9048\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2327 - accuracy: 0.9027 - val_loss: 0.1854 - val_accuracy: 0.9035\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1961 - accuracy: 0.9121 - val_loss: 0.1792 - val_accuracy: 0.9021\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2064 - accuracy: 0.9061 - val_loss: 0.1426 - val_accuracy: 0.9142\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1925 - accuracy: 0.9104 - val_loss: 0.1369 - val_accuracy: 0.9142\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2004 - accuracy: 0.9069 - val_loss: 0.1259 - val_accuracy: 0.9142\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1960 - accuracy: 0.9082 - val_loss: 0.1261 - val_accuracy: 0.9142\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1959 - accuracy: 0.9072 - val_loss: 0.1331 - val_accuracy: 0.9129\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1947 - accuracy: 0.9137 - val_loss: 0.1298 - val_accuracy: 0.9142\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1726 - accuracy: 0.9194 - val_loss: 0.1191 - val_accuracy: 0.9370\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1771 - accuracy: 0.9197 - val_loss: 0.1156 - val_accuracy: 0.9397\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1715 - accuracy: 0.9234 - val_loss: 0.1077 - val_accuracy: 0.9397\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1662 - accuracy: 0.9335 - val_loss: 0.0932 - val_accuracy: 0.9598\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1497 - accuracy: 0.9364 - val_loss: 0.0845 - val_accuracy: 0.9611\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1550 - accuracy: 0.9382 - val_loss: 0.0852 - val_accuracy: 0.9651\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1566 - accuracy: 0.9361 - val_loss: 0.0762 - val_accuracy: 0.9705\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1338 - accuracy: 0.9474 - val_loss: 0.0668 - val_accuracy: 0.9759\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1254 - accuracy: 0.9496 - val_loss: 0.0973 - val_accuracy: 0.9584\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1216 - accuracy: 0.9532 - val_loss: 0.0622 - val_accuracy: 0.9732\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1273 - accuracy: 0.9489 - val_loss: 0.0641 - val_accuracy: 0.9745\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1146 - accuracy: 0.9574 - val_loss: 0.0475 - val_accuracy: 0.9853\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1017 - accuracy: 0.9595 - val_loss: 0.0394 - val_accuracy: 0.9853\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1162 - accuracy: 0.9581 - val_loss: 0.0487 - val_accuracy: 0.9812\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1079 - accuracy: 0.9618 - val_loss: 0.0650 - val_accuracy: 0.9759\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0975 - accuracy: 0.9635 - val_loss: 0.0441 - val_accuracy: 0.9826\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1077 - accuracy: 0.9662 - val_loss: 0.0325 - val_accuracy: 0.9866\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0962 - accuracy: 0.9660 - val_loss: 0.0379 - val_accuracy: 0.9853\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0822 - accuracy: 0.9735 - val_loss: 0.0249 - val_accuracy: 0.9893\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0814 - accuracy: 0.9697 - val_loss: 0.0272 - val_accuracy: 0.9879\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0724 - accuracy: 0.9763 - val_loss: 0.0265 - val_accuracy: 0.9853\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0811 - accuracy: 0.9723 - val_loss: 0.0131 - val_accuracy: 0.9960\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0603 - accuracy: 0.9788 - val_loss: 0.0102 - val_accuracy: 0.9960\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0714 - accuracy: 0.9768 - val_loss: 0.0353 - val_accuracy: 0.9839\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0779 - accuracy: 0.9732 - val_loss: 7.6243e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0758 - accuracy: 0.9739 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0745 - accuracy: 0.9729 - val_loss: 0.0024 - val_accuracy: 0.9987\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0757 - accuracy: 0.9739 - val_loss: 7.1105e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0676 - accuracy: 0.9762 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0658 - accuracy: 0.9741 - val_loss: 6.1305e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0699 - accuracy: 0.9769 - val_loss: 9.0178e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0634 - accuracy: 0.9794 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0637 - accuracy: 0.9753 - val_loss: 0.0024 - val_accuracy: 0.9987\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0719 - accuracy: 0.9753 - val_loss: 7.1568e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0655 - accuracy: 0.9808 - val_loss: 0.0042 - val_accuracy: 0.9987\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0520 - accuracy: 0.9818 - val_loss: 4.2193e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0478 - accuracy: 0.9842 - val_loss: 6.5245e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0530 - accuracy: 0.9848 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0502 - accuracy: 0.9830 - val_loss: 0.0016 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0460 - accuracy: 0.9849 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0528 - accuracy: 0.9827 - val_loss: 0.0025 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0555 - accuracy: 0.9812 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0504 - accuracy: 0.9854 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0447 - accuracy: 0.9857 - val_loss: 0.0024 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0565 - accuracy: 0.9814 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0480 - accuracy: 0.9839 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0487 - accuracy: 0.9842 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0523 - accuracy: 0.9827 - val_loss: 0.0017 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0572 - accuracy: 0.9805 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0470 - accuracy: 0.9832 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0496 - accuracy: 0.9839 - val_loss: 9.2575e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0388 - accuracy: 0.9894 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.0379 - accuracy: 0.9882 - val_loss: 6.1088e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0330 - accuracy: 0.9894 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0430 - accuracy: 0.9863 - val_loss: 5.3375e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0588 - accuracy: 0.9827 - val_loss: 1.0878e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0426 - accuracy: 0.9876 - val_loss: 1.4633e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0319 - accuracy: 0.9894 - val_loss: 1.0357e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0401 - accuracy: 0.9888 - val_loss: 7.2282e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0516 - accuracy: 0.9847 - val_loss: 1.5122e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0492 - accuracy: 0.9848 - val_loss: 1.5819e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0420 - accuracy: 0.9873 - val_loss: 4.2813e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0313 - accuracy: 0.9906 - val_loss: 1.0357e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0351 - accuracy: 0.9894 - val_loss: 9.8754e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0474 - accuracy: 0.9861 - val_loss: 5.2352e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0411 - accuracy: 0.9891 - val_loss: 2.0302e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0352 - accuracy: 0.9893 - val_loss: 1.1888e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0363 - accuracy: 0.9882 - val_loss: 7.3103e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0435 - accuracy: 0.9878 - val_loss: 1.0492e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0478 - accuracy: 0.9854 - val_loss: 6.8304e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0527 - accuracy: 0.9852 - val_loss: 2.7486e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0400 - accuracy: 0.9875 - val_loss: 3.7512e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0446 - accuracy: 0.9885 - val_loss: 2.3114e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0317 - accuracy: 0.9891 - val_loss: 1.7531e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0440 - accuracy: 0.9879 - val_loss: 1.7825e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0352 - accuracy: 0.9878 - val_loss: 1.4487e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0406 - accuracy: 0.9872 - val_loss: 2.3942e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0411 - accuracy: 0.9869 - val_loss: 1.4777e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0315 - accuracy: 0.9909 - val_loss: 2.1693e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0740 - accuracy: 0.9806 - val_loss: 0.0062 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0571 - accuracy: 0.9818 - val_loss: 4.0247e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0340 - accuracy: 0.9899 - val_loss: 3.8670e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0396 - accuracy: 0.9870 - val_loss: 1.9355e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0371 - accuracy: 0.9902 - val_loss: 1.3462e-04 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0337 - accuracy: 0.9899 - val_loss: 9.5383e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0377 - accuracy: 0.9887 - val_loss: 2.5542e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0335 - accuracy: 0.9891 - val_loss: 1.3475e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0327 - accuracy: 0.9888 - val_loss: 6.1844e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0231 - accuracy: 0.9936 - val_loss: 2.6000e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0328 - accuracy: 0.9900 - val_loss: 1.3050e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0377 - accuracy: 0.9885 - val_loss: 9.3992e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0430 - accuracy: 0.9876 - val_loss: 7.1292e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0236 - accuracy: 0.9934 - val_loss: 7.2138e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0404 - accuracy: 0.9882 - val_loss: 2.7348e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0581 - accuracy: 0.9808 - val_loss: 1.4677e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0275 - accuracy: 0.9925 - val_loss: 1.0542e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0271 - accuracy: 0.9915 - val_loss: 1.6079e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0182 - accuracy: 0.9943 - val_loss: 5.3547e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0224 - accuracy: 0.9939 - val_loss: 3.3708e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0344 - accuracy: 0.9897 - val_loss: 7.3664e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0482 - accuracy: 0.9866 - val_loss: 7.9628e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0630 - accuracy: 0.9811 - val_loss: 2.3405e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0240 - accuracy: 0.9939 - val_loss: 1.0323e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0220 - accuracy: 0.9936 - val_loss: 1.7654e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0231 - accuracy: 0.9931 - val_loss: 4.4935e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0246 - accuracy: 0.9934 - val_loss: 6.3972e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0239 - accuracy: 0.9933 - val_loss: 4.7773e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0290 - accuracy: 0.9923 - val_loss: 2.6184e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0350 - accuracy: 0.9905 - val_loss: 0.0021 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0364 - accuracy: 0.9902 - val_loss: 3.4051e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0365 - accuracy: 0.9894 - val_loss: 2.2600e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0271 - accuracy: 0.9924 - val_loss: 1.0310e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0274 - accuracy: 0.9920 - val_loss: 9.8628e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0290 - accuracy: 0.9912 - val_loss: 4.6536e-05 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0229 - accuracy: 0.9937 - val_loss: 7.6467e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0349 - accuracy: 0.9909 - val_loss: 2.2768e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0334 - accuracy: 0.9915 - val_loss: 2.5281e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0261 - accuracy: 0.9925 - val_loss: 3.2732e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0222 - accuracy: 0.9927 - val_loss: 2.9171e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0268 - accuracy: 0.9921 - val_loss: 7.0951e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0201 - accuracy: 0.9942 - val_loss: 8.1798e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0296 - accuracy: 0.9908 - val_loss: 2.6784e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0465 - accuracy: 0.9876 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0273 - accuracy: 0.9924 - val_loss: 3.6468e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0246 - accuracy: 0.9930 - val_loss: 2.5772e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0259 - accuracy: 0.9942 - val_loss: 3.5230e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0204 - accuracy: 0.9954 - val_loss: 7.5707e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0417 - accuracy: 0.9899 - val_loss: 2.6922e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0238 - accuracy: 0.9930 - val_loss: 4.0329e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0293 - accuracy: 0.9914 - val_loss: 0.0011 - val_accuracy: 0.9987\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0276 - accuracy: 0.9936 - val_loss: 2.8267e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0379 - accuracy: 0.9879 - val_loss: 2.7681e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0191 - accuracy: 0.9948 - val_loss: 2.3653e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0209 - accuracy: 0.9939 - val_loss: 2.5148e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0286 - accuracy: 0.9915 - val_loss: 2.8281e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0359 - accuracy: 0.9914 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0270 - accuracy: 0.9903 - val_loss: 3.8293e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0296 - accuracy: 0.9915 - val_loss: 1.5107e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0285 - accuracy: 0.9911 - val_loss: 6.0140e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0340 - accuracy: 0.9882 - val_loss: 6.2871e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0212 - accuracy: 0.9933 - val_loss: 1.6798e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0365 - accuracy: 0.9896 - val_loss: 3.6356e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0242 - accuracy: 0.9917 - val_loss: 3.9831e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0200 - accuracy: 0.9934 - val_loss: 0.0027 - val_accuracy: 0.9987\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0289 - accuracy: 0.9905 - val_loss: 2.4472e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0252 - accuracy: 0.9936 - val_loss: 5.5859e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0319 - accuracy: 0.9897 - val_loss: 3.0948e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0164 - accuracy: 0.9952 - val_loss: 5.9984e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0213 - accuracy: 0.9939 - val_loss: 1.1963e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0277 - accuracy: 0.9917 - val_loss: 1.2781e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0276 - accuracy: 0.9918 - val_loss: 4.5152e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0216 - accuracy: 0.9937 - val_loss: 2.0618e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0268 - accuracy: 0.9928 - val_loss: 2.6435e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0173 - accuracy: 0.9948 - val_loss: 1.0888e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0161 - accuracy: 0.9957 - val_loss: 1.4946e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0205 - accuracy: 0.9940 - val_loss: 2.0579e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0228 - accuracy: 0.9924 - val_loss: 8.8573e-06 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0194 - accuracy: 0.9945 - val_loss: 3.9313e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0194 - accuracy: 0.9939 - val_loss: 1.1214e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0260 - accuracy: 0.9923 - val_loss: 7.9931e-06 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0236 - accuracy: 0.9928 - val_loss: 2.6628e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0172 - accuracy: 0.9943 - val_loss: 1.8530e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0195 - accuracy: 0.9927 - val_loss: 4.8999e-06 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0485 - accuracy: 0.9887 - val_loss: 1.8192e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0207 - accuracy: 0.9928 - val_loss: 4.8160e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0166 - accuracy: 0.9948 - val_loss: 8.8592e-06 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0208 - accuracy: 0.9949 - val_loss: 1.3315e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0237 - accuracy: 0.9934 - val_loss: 7.7317e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0244 - accuracy: 0.9928 - val_loss: 8.2310e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0177 - accuracy: 0.9942 - val_loss: 1.5459e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0208 - accuracy: 0.9934 - val_loss: 4.1471e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0180 - accuracy: 0.9945 - val_loss: 2.5569e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0204 - accuracy: 0.9936 - val_loss: 8.7365e-06 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0155 - accuracy: 0.9954 - val_loss: 5.3205e-06 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "30720135-ee80-413a-d157-0503a7a34fcb"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 7ms/step - loss: 0.0342 - accuracy: 0.9936\n",
            "Accuracy  : 0.9935622215270996\n",
            "F1_Score  : 0.9905843282805266\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "303790c6-c023-435a-d9a7-2286536f837b"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'#dominance\\nX_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\\nprint(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "ac877085-c665-4adf-ccc4-cf82104dfadf"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'foldNum=0\\nmodel = get_model()\\nfor train_index, val_index in kfold.split(X_train, Y_train):\\n  foldNum = foldNum + 1\\n  print(\"Results for fold\",foldNum)\\n  x_train, x_val = X_train[train_index], X_train[val_index]\\n  y_train, y_val = Y_train[train_index], Y_train[val_index]\\n  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\\n  gc.collect() # Garbage collecter\\n  del x_train, x_val, y_train, y_val\\n  gc.collect()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "25da75cb-38fd-4413-9f48-f76f05159d3c"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'acrc = model.evaluate(x_test, y_test)\\npred = model.predict(x_test)\\nf1scr = f1_score(y_test.argmax(1), pred.argmax(1), average=\\'macro\\')\\nc_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\\nprint(\"Accuracy  : {}\".format(acrc[1]))\\nprint(\"F1_Score  : {}\".format(f1scr))\\nc_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\\nimport seaborn as sns\\nfigure = plt.figure(figsize=(9, 9))\\nsns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\\nplt.tight_layout()\\nplt.ylabel(\\'True label\\')\\nplt.xlabel(\\'Predicted label\\')\\nplt.show()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}