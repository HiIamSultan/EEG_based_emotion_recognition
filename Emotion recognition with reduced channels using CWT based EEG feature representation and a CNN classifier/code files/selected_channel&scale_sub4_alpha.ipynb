{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub4_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "25dcfd36-62a3-4a49-b5c5-5c2216ab85ca"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e3\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  #EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "9742e427-f041-44c3-a607-21e9c602017c"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(4,5):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.4\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (4660,) (1631,) (3029,)\n",
            "(9320,) (4893,) (2097,) (2330,)\n",
            "(9320,) (4893,) (3262,) (1165,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "00d562e0-c168-46ac-f7fc-a65316315171"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "dfb76d2e-ca99-42a1-a4bf-ee85525d81cc"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "632"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "79f4e355-16ac-47f5-c728-3f92f0f838b8"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "680bf1c6-5763-4744-f49d-bb1fe3ad0ebd"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 21s 58ms/step - loss: 1.1192 - accuracy: 0.4377 - val_loss: 1.0300 - val_accuracy: 0.4812\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0544 - accuracy: 0.4760 - val_loss: 1.0204 - val_accuracy: 0.5027\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0389 - accuracy: 0.4834 - val_loss: 1.0245 - val_accuracy: 0.5027\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0323 - accuracy: 0.4888 - val_loss: 1.0212 - val_accuracy: 0.5027\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 39ms/step - loss: 1.0359 - accuracy: 0.4870 - val_loss: 1.0213 - val_accuracy: 0.5027\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 39ms/step - loss: 1.0190 - accuracy: 0.5051 - val_loss: 1.0217 - val_accuracy: 0.5027\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0256 - accuracy: 0.4986 - val_loss: 1.0221 - val_accuracy: 0.5027\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0275 - accuracy: 0.4994 - val_loss: 1.0246 - val_accuracy: 0.5027\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0228 - accuracy: 0.4969 - val_loss: 1.0210 - val_accuracy: 0.5027\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0249 - accuracy: 0.4986 - val_loss: 1.0213 - val_accuracy: 0.5027\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0254 - accuracy: 0.4979 - val_loss: 1.0202 - val_accuracy: 0.5027\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0175 - accuracy: 0.4988 - val_loss: 1.0190 - val_accuracy: 0.5027\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0243 - accuracy: 0.4916 - val_loss: 1.0158 - val_accuracy: 0.5027\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0164 - accuracy: 0.4997 - val_loss: 1.0182 - val_accuracy: 0.5027\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0280 - accuracy: 0.4895 - val_loss: 1.0157 - val_accuracy: 0.5027\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0146 - accuracy: 0.5020 - val_loss: 1.0159 - val_accuracy: 0.5027\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0276 - accuracy: 0.4827 - val_loss: 1.0164 - val_accuracy: 0.5027\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0095 - accuracy: 0.5048 - val_loss: 1.0150 - val_accuracy: 0.5027\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0183 - accuracy: 0.4975 - val_loss: 1.0153 - val_accuracy: 0.5027\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0169 - accuracy: 0.4886 - val_loss: 1.0151 - val_accuracy: 0.5027\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0215 - accuracy: 0.4820 - val_loss: 1.0134 - val_accuracy: 0.5027\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0141 - accuracy: 0.5016 - val_loss: 1.0139 - val_accuracy: 0.5027\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0140 - accuracy: 0.4973 - val_loss: 1.0106 - val_accuracy: 0.5027\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0063 - accuracy: 0.5066 - val_loss: 1.0134 - val_accuracy: 0.5027\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0051 - accuracy: 0.5045 - val_loss: 1.0096 - val_accuracy: 0.5027\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0165 - accuracy: 0.4960 - val_loss: 1.0053 - val_accuracy: 0.5027\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0045 - accuracy: 0.5033 - val_loss: 1.0122 - val_accuracy: 0.5027\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0068 - accuracy: 0.4982 - val_loss: 1.0087 - val_accuracy: 0.5027\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0085 - accuracy: 0.4871 - val_loss: 1.0110 - val_accuracy: 0.5027\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0088 - accuracy: 0.4963 - val_loss: 1.0064 - val_accuracy: 0.5027\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0114 - accuracy: 0.4978 - val_loss: 1.0006 - val_accuracy: 0.4920\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0111 - accuracy: 0.4994 - val_loss: 1.0048 - val_accuracy: 0.4920\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0082 - accuracy: 0.4954 - val_loss: 1.0120 - val_accuracy: 0.4920\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0092 - accuracy: 0.4958 - val_loss: 0.9978 - val_accuracy: 0.4920\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0093 - accuracy: 0.4993 - val_loss: 1.0039 - val_accuracy: 0.4920\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0071 - accuracy: 0.5004 - val_loss: 0.9973 - val_accuracy: 0.4920\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0070 - accuracy: 0.4984 - val_loss: 1.0002 - val_accuracy: 0.4920\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0092 - accuracy: 0.4993 - val_loss: 1.0043 - val_accuracy: 0.4920\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0106 - accuracy: 0.4981 - val_loss: 0.9988 - val_accuracy: 0.4920\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0057 - accuracy: 0.5000 - val_loss: 0.9957 - val_accuracy: 0.4920\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0071 - accuracy: 0.4978 - val_loss: 0.9982 - val_accuracy: 0.4920\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0068 - accuracy: 0.4976 - val_loss: 1.0017 - val_accuracy: 0.4920\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0046 - accuracy: 0.4984 - val_loss: 0.9940 - val_accuracy: 0.4946\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0059 - accuracy: 0.4975 - val_loss: 0.9998 - val_accuracy: 0.4920\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0018 - accuracy: 0.5019 - val_loss: 0.9948 - val_accuracy: 0.4960\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0041 - accuracy: 0.4988 - val_loss: 0.9937 - val_accuracy: 0.4987\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0017 - accuracy: 0.5009 - val_loss: 0.9968 - val_accuracy: 0.4987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0032 - accuracy: 0.5019 - val_loss: 0.9952 - val_accuracy: 0.4946\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0009 - accuracy: 0.5051 - val_loss: 0.9975 - val_accuracy: 0.5040\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0012 - accuracy: 0.4985 - val_loss: 0.9921 - val_accuracy: 0.4853\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9964 - accuracy: 0.5051 - val_loss: 0.9950 - val_accuracy: 0.4879\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9981 - accuracy: 0.5073 - val_loss: 0.9920 - val_accuracy: 0.4987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0017 - accuracy: 0.5037 - val_loss: 0.9933 - val_accuracy: 0.4893\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9940 - accuracy: 0.5127 - val_loss: 0.9831 - val_accuracy: 0.5121\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9923 - accuracy: 0.5128 - val_loss: 0.9843 - val_accuracy: 0.4960\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9933 - accuracy: 0.5063 - val_loss: 0.9890 - val_accuracy: 0.4933\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9864 - accuracy: 0.5207 - val_loss: 0.9694 - val_accuracy: 0.5080\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9875 - accuracy: 0.5270 - val_loss: 0.9707 - val_accuracy: 0.5121\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9790 - accuracy: 0.5294 - val_loss: 0.9967 - val_accuracy: 0.4933\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9744 - accuracy: 0.5316 - val_loss: 0.9639 - val_accuracy: 0.5241\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9713 - accuracy: 0.5306 - val_loss: 0.9764 - val_accuracy: 0.5107\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9704 - accuracy: 0.5364 - val_loss: 0.9517 - val_accuracy: 0.5550\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9645 - accuracy: 0.5413 - val_loss: 0.9610 - val_accuracy: 0.5282\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9692 - accuracy: 0.5416 - val_loss: 0.9519 - val_accuracy: 0.5509\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9522 - accuracy: 0.5471 - val_loss: 0.9933 - val_accuracy: 0.5188\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9561 - accuracy: 0.5477 - val_loss: 0.9680 - val_accuracy: 0.5389\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9447 - accuracy: 0.5532 - val_loss: 0.9332 - val_accuracy: 0.5643\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9361 - accuracy: 0.5566 - val_loss: 0.9148 - val_accuracy: 0.5657\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9291 - accuracy: 0.5709 - val_loss: 0.9360 - val_accuracy: 0.5349\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9188 - accuracy: 0.5760 - val_loss: 0.8867 - val_accuracy: 0.5858\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9235 - accuracy: 0.5730 - val_loss: 0.9089 - val_accuracy: 0.5724\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9001 - accuracy: 0.5784 - val_loss: 0.8955 - val_accuracy: 0.5804\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8962 - accuracy: 0.5899 - val_loss: 0.8855 - val_accuracy: 0.5871\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8780 - accuracy: 0.5958 - val_loss: 0.8933 - val_accuracy: 0.5697\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8630 - accuracy: 0.6106 - val_loss: 0.8673 - val_accuracy: 0.5952\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8467 - accuracy: 0.6189 - val_loss: 0.8432 - val_accuracy: 0.6032\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8262 - accuracy: 0.6298 - val_loss: 0.8732 - val_accuracy: 0.5885\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8465 - accuracy: 0.6189 - val_loss: 0.8239 - val_accuracy: 0.6113\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8258 - accuracy: 0.6304 - val_loss: 0.8500 - val_accuracy: 0.6113\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8169 - accuracy: 0.6365 - val_loss: 0.7990 - val_accuracy: 0.6340\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8027 - accuracy: 0.6461 - val_loss: 0.8485 - val_accuracy: 0.6032\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7824 - accuracy: 0.6539 - val_loss: 0.7626 - val_accuracy: 0.6582\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7724 - accuracy: 0.6620 - val_loss: 0.7473 - val_accuracy: 0.6515\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7558 - accuracy: 0.6644 - val_loss: 0.7597 - val_accuracy: 0.6501\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7503 - accuracy: 0.6689 - val_loss: 0.7886 - val_accuracy: 0.6662\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7232 - accuracy: 0.6832 - val_loss: 0.7362 - val_accuracy: 0.6783\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7170 - accuracy: 0.6906 - val_loss: 0.7021 - val_accuracy: 0.6877\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6953 - accuracy: 0.6987 - val_loss: 0.7331 - val_accuracy: 0.6810\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6899 - accuracy: 0.6949 - val_loss: 0.6856 - val_accuracy: 0.6903\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6834 - accuracy: 0.7024 - val_loss: 0.7243 - val_accuracy: 0.6957\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7093 - accuracy: 0.6911 - val_loss: 0.5466 - val_accuracy: 0.7453\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6714 - accuracy: 0.7077 - val_loss: 0.5155 - val_accuracy: 0.7413\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6726 - accuracy: 0.7040 - val_loss: 0.5556 - val_accuracy: 0.7668\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6719 - accuracy: 0.7073 - val_loss: 0.5104 - val_accuracy: 0.7748\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6451 - accuracy: 0.7156 - val_loss: 0.4971 - val_accuracy: 0.7815\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6200 - accuracy: 0.7234 - val_loss: 0.4750 - val_accuracy: 0.7614\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6251 - accuracy: 0.7222 - val_loss: 0.4801 - val_accuracy: 0.7627\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6051 - accuracy: 0.7295 - val_loss: 0.4679 - val_accuracy: 0.7627\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6178 - accuracy: 0.7286 - val_loss: 0.4719 - val_accuracy: 0.7815\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5800 - accuracy: 0.7408 - val_loss: 0.4527 - val_accuracy: 0.7949\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5787 - accuracy: 0.7386 - val_loss: 0.5017 - val_accuracy: 0.7815\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5783 - accuracy: 0.7393 - val_loss: 0.4710 - val_accuracy: 0.7828\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6475 - accuracy: 0.7136 - val_loss: 0.4896 - val_accuracy: 0.7614\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5893 - accuracy: 0.7374 - val_loss: 0.4709 - val_accuracy: 0.7748\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5622 - accuracy: 0.7431 - val_loss: 0.4321 - val_accuracy: 0.7989\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5098 - accuracy: 0.7672 - val_loss: 0.4295 - val_accuracy: 0.8137\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5314 - accuracy: 0.7630 - val_loss: 0.4285 - val_accuracy: 0.8056\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5356 - accuracy: 0.7610 - val_loss: 0.4371 - val_accuracy: 0.7989\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5250 - accuracy: 0.7674 - val_loss: 0.4239 - val_accuracy: 0.8217\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5193 - accuracy: 0.7684 - val_loss: 0.3761 - val_accuracy: 0.8257\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4836 - accuracy: 0.7857 - val_loss: 0.3785 - val_accuracy: 0.8391\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5224 - accuracy: 0.7766 - val_loss: 0.4267 - val_accuracy: 0.7962\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4892 - accuracy: 0.7866 - val_loss: 0.3766 - val_accuracy: 0.8458\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4557 - accuracy: 0.7966 - val_loss: 0.3559 - val_accuracy: 0.8378\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4493 - accuracy: 0.8042 - val_loss: 0.3629 - val_accuracy: 0.8633\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4713 - accuracy: 0.7957 - val_loss: 0.3941 - val_accuracy: 0.8324\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4534 - accuracy: 0.8042 - val_loss: 0.3496 - val_accuracy: 0.8552\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4417 - accuracy: 0.8133 - val_loss: 0.3639 - val_accuracy: 0.8499\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4145 - accuracy: 0.8197 - val_loss: 0.3310 - val_accuracy: 0.8539\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4091 - accuracy: 0.8234 - val_loss: 0.3581 - val_accuracy: 0.8378\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4151 - accuracy: 0.8258 - val_loss: 0.2072 - val_accuracy: 0.9370\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4205 - accuracy: 0.8171 - val_loss: 0.2001 - val_accuracy: 0.9236\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.3691 - accuracy: 0.8455 - val_loss: 0.1932 - val_accuracy: 0.9249\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3657 - accuracy: 0.8478 - val_loss: 0.1921 - val_accuracy: 0.9303\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3789 - accuracy: 0.8401 - val_loss: 0.1710 - val_accuracy: 0.9330\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4052 - accuracy: 0.8277 - val_loss: 0.2182 - val_accuracy: 0.9182\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3596 - accuracy: 0.8453 - val_loss: 0.1595 - val_accuracy: 0.9491\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3325 - accuracy: 0.8578 - val_loss: 0.1536 - val_accuracy: 0.9437\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3415 - accuracy: 0.8598 - val_loss: 0.1633 - val_accuracy: 0.9491\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3521 - accuracy: 0.8569 - val_loss: 0.1454 - val_accuracy: 0.9558\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3204 - accuracy: 0.8674 - val_loss: 0.1521 - val_accuracy: 0.9517\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3051 - accuracy: 0.8729 - val_loss: 0.1330 - val_accuracy: 0.9598\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3243 - accuracy: 0.8696 - val_loss: 0.1397 - val_accuracy: 0.9531\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3206 - accuracy: 0.8750 - val_loss: 0.1708 - val_accuracy: 0.9410\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3187 - accuracy: 0.8699 - val_loss: 0.1540 - val_accuracy: 0.9504\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2992 - accuracy: 0.8826 - val_loss: 0.1620 - val_accuracy: 0.9330\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2780 - accuracy: 0.8903 - val_loss: 0.1336 - val_accuracy: 0.9544\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2821 - accuracy: 0.8854 - val_loss: 0.1486 - val_accuracy: 0.9370\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2945 - accuracy: 0.8835 - val_loss: 0.1286 - val_accuracy: 0.9464\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2682 - accuracy: 0.8949 - val_loss: 0.1335 - val_accuracy: 0.9491\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2550 - accuracy: 0.9009 - val_loss: 0.1148 - val_accuracy: 0.9611\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2480 - accuracy: 0.9024 - val_loss: 0.1288 - val_accuracy: 0.9571\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2618 - accuracy: 0.8966 - val_loss: 0.1231 - val_accuracy: 0.9598\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2560 - accuracy: 0.9024 - val_loss: 0.1050 - val_accuracy: 0.9665\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2532 - accuracy: 0.9049 - val_loss: 0.1073 - val_accuracy: 0.9745\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3199 - accuracy: 0.8781 - val_loss: 0.1566 - val_accuracy: 0.9263\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2679 - accuracy: 0.8937 - val_loss: 0.1137 - val_accuracy: 0.9759\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2515 - accuracy: 0.9052 - val_loss: 0.1255 - val_accuracy: 0.9665\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2390 - accuracy: 0.9094 - val_loss: 0.1042 - val_accuracy: 0.9638\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2179 - accuracy: 0.9179 - val_loss: 0.0897 - val_accuracy: 0.9611\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2302 - accuracy: 0.9115 - val_loss: 0.0671 - val_accuracy: 0.9853\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2351 - accuracy: 0.9124 - val_loss: 0.0650 - val_accuracy: 0.9826\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2219 - accuracy: 0.9168 - val_loss: 0.0701 - val_accuracy: 0.9839\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2350 - accuracy: 0.9115 - val_loss: 0.0817 - val_accuracy: 0.9678\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2177 - accuracy: 0.9151 - val_loss: 0.0882 - val_accuracy: 0.9598\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2126 - accuracy: 0.9185 - val_loss: 0.0834 - val_accuracy: 0.9558\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2128 - accuracy: 0.9204 - val_loss: 0.0611 - val_accuracy: 0.9839\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2158 - accuracy: 0.9213 - val_loss: 0.0615 - val_accuracy: 0.9812\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2367 - accuracy: 0.9133 - val_loss: 0.0835 - val_accuracy: 0.9651\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2827 - accuracy: 0.8930 - val_loss: 0.0810 - val_accuracy: 0.9799\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2036 - accuracy: 0.9234 - val_loss: 0.0977 - val_accuracy: 0.9558\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2115 - accuracy: 0.9206 - val_loss: 0.1161 - val_accuracy: 0.9464\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2052 - accuracy: 0.9271 - val_loss: 0.0791 - val_accuracy: 0.9692\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1886 - accuracy: 0.9316 - val_loss: 0.0542 - val_accuracy: 0.9799\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1828 - accuracy: 0.9325 - val_loss: 0.0701 - val_accuracy: 0.9705\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1731 - accuracy: 0.9332 - val_loss: 0.0812 - val_accuracy: 0.9665\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1926 - accuracy: 0.9291 - val_loss: 0.0571 - val_accuracy: 0.9826\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1780 - accuracy: 0.9356 - val_loss: 0.0593 - val_accuracy: 0.9812\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1690 - accuracy: 0.9379 - val_loss: 0.0510 - val_accuracy: 0.9799\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1998 - accuracy: 0.9264 - val_loss: 0.0690 - val_accuracy: 0.9745\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1664 - accuracy: 0.9434 - val_loss: 0.0669 - val_accuracy: 0.9678\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1657 - accuracy: 0.9410 - val_loss: 0.0623 - val_accuracy: 0.9732\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1837 - accuracy: 0.9295 - val_loss: 0.0554 - val_accuracy: 0.9879\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1736 - accuracy: 0.9380 - val_loss: 0.0595 - val_accuracy: 0.9866\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1732 - accuracy: 0.9382 - val_loss: 0.0552 - val_accuracy: 0.9866\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1501 - accuracy: 0.9446 - val_loss: 0.0406 - val_accuracy: 0.9933\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2128 - accuracy: 0.9222 - val_loss: 0.0781 - val_accuracy: 0.9786\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1888 - accuracy: 0.9265 - val_loss: 0.0558 - val_accuracy: 0.9812\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1634 - accuracy: 0.9429 - val_loss: 0.0459 - val_accuracy: 0.9906\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1760 - accuracy: 0.9374 - val_loss: 0.0872 - val_accuracy: 0.9866\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 48ms/step - loss: 0.1571 - accuracy: 0.9391 - val_loss: 0.0306 - val_accuracy: 0.9919\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1605 - accuracy: 0.9446 - val_loss: 0.0291 - val_accuracy: 0.9906\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1797 - accuracy: 0.9376 - val_loss: 0.0338 - val_accuracy: 0.9933\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1501 - accuracy: 0.9458 - val_loss: 0.0262 - val_accuracy: 0.9960\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1873 - accuracy: 0.9298 - val_loss: 0.0267 - val_accuracy: 0.9946\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1629 - accuracy: 0.9395 - val_loss: 0.0218 - val_accuracy: 0.9960\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1419 - accuracy: 0.9501 - val_loss: 0.0239 - val_accuracy: 0.9946\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1518 - accuracy: 0.9453 - val_loss: 0.0260 - val_accuracy: 0.9960\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1660 - accuracy: 0.9385 - val_loss: 0.0204 - val_accuracy: 0.9946\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1389 - accuracy: 0.9511 - val_loss: 0.0240 - val_accuracy: 0.9946\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1581 - accuracy: 0.9450 - val_loss: 0.0395 - val_accuracy: 0.9852\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1587 - accuracy: 0.9416 - val_loss: 0.0387 - val_accuracy: 0.9879\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1519 - accuracy: 0.9411 - val_loss: 0.0270 - val_accuracy: 0.9960\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1685 - accuracy: 0.9374 - val_loss: 0.0362 - val_accuracy: 0.9906\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1582 - accuracy: 0.9431 - val_loss: 0.0374 - val_accuracy: 0.9879\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1550 - accuracy: 0.9431 - val_loss: 0.0354 - val_accuracy: 0.9946\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1769 - accuracy: 0.9359 - val_loss: 0.0312 - val_accuracy: 0.9893\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1504 - accuracy: 0.9464 - val_loss: 0.0352 - val_accuracy: 0.9866\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1676 - accuracy: 0.9371 - val_loss: 0.0769 - val_accuracy: 0.9705\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1431 - accuracy: 0.9508 - val_loss: 0.0264 - val_accuracy: 0.9946\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1366 - accuracy: 0.9520 - val_loss: 0.0236 - val_accuracy: 0.9933\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1296 - accuracy: 0.9537 - val_loss: 0.0211 - val_accuracy: 0.9960\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1201 - accuracy: 0.9556 - val_loss: 0.0396 - val_accuracy: 0.9839\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1513 - accuracy: 0.9459 - val_loss: 0.0318 - val_accuracy: 0.9933\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1346 - accuracy: 0.9537 - val_loss: 0.0220 - val_accuracy: 0.9946\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1310 - accuracy: 0.9549 - val_loss: 0.0309 - val_accuracy: 0.9960\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1391 - accuracy: 0.9520 - val_loss: 0.0333 - val_accuracy: 0.9906\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1272 - accuracy: 0.9525 - val_loss: 0.0189 - val_accuracy: 0.9960\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1190 - accuracy: 0.9581 - val_loss: 0.0389 - val_accuracy: 0.9879\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1239 - accuracy: 0.9554 - val_loss: 0.0311 - val_accuracy: 0.9893\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.1362 - accuracy: 0.9520 - val_loss: 0.0282 - val_accuracy: 0.9919\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1847 - accuracy: 0.9340 - val_loss: 0.0337 - val_accuracy: 0.9960\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1261 - accuracy: 0.9519 - val_loss: 0.0189 - val_accuracy: 0.9960\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1276 - accuracy: 0.9550 - val_loss: 0.0272 - val_accuracy: 0.9919\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1182 - accuracy: 0.9563 - val_loss: 0.0194 - val_accuracy: 0.9919\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1304 - accuracy: 0.9508 - val_loss: 0.0212 - val_accuracy: 0.9946\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1253 - accuracy: 0.9523 - val_loss: 0.0198 - val_accuracy: 0.9960\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1093 - accuracy: 0.9574 - val_loss: 0.0196 - val_accuracy: 0.9946\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1189 - accuracy: 0.9556 - val_loss: 0.0204 - val_accuracy: 0.9960\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1353 - accuracy: 0.9549 - val_loss: 0.0353 - val_accuracy: 0.9893\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1390 - accuracy: 0.9537 - val_loss: 0.0387 - val_accuracy: 0.9919\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1235 - accuracy: 0.9537 - val_loss: 0.0246 - val_accuracy: 0.9893\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1088 - accuracy: 0.9601 - val_loss: 0.0138 - val_accuracy: 0.9973\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1046 - accuracy: 0.9619 - val_loss: 0.0236 - val_accuracy: 0.9933\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1110 - accuracy: 0.9616 - val_loss: 0.0312 - val_accuracy: 0.9866\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1138 - accuracy: 0.9572 - val_loss: 0.0169 - val_accuracy: 0.9919\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1146 - accuracy: 0.9599 - val_loss: 0.0146 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1172 - accuracy: 0.9572 - val_loss: 0.0202 - val_accuracy: 0.9933\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1235 - accuracy: 0.9562 - val_loss: 0.0194 - val_accuracy: 0.9933\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1346 - accuracy: 0.9547 - val_loss: 0.0283 - val_accuracy: 0.9906\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1163 - accuracy: 0.9574 - val_loss: 0.0181 - val_accuracy: 0.9933\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1169 - accuracy: 0.9583 - val_loss: 0.0211 - val_accuracy: 0.9946\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1453 - accuracy: 0.9462 - val_loss: 0.0673 - val_accuracy: 0.9866\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1151 - accuracy: 0.9578 - val_loss: 0.0293 - val_accuracy: 0.9919\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1073 - accuracy: 0.9581 - val_loss: 0.0244 - val_accuracy: 0.9919\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1053 - accuracy: 0.9626 - val_loss: 0.0187 - val_accuracy: 0.9960\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1049 - accuracy: 0.9639 - val_loss: 0.0294 - val_accuracy: 0.9893\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1214 - accuracy: 0.9586 - val_loss: 0.0274 - val_accuracy: 0.9893\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0950 - accuracy: 0.9645 - val_loss: 0.0272 - val_accuracy: 0.9879\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1232 - accuracy: 0.9528 - val_loss: 0.0199 - val_accuracy: 0.9933\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1256 - accuracy: 0.9562 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1518 - accuracy: 0.9495 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1155 - accuracy: 0.9578 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1372 - accuracy: 0.9511 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1038 - accuracy: 0.9638 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1078 - accuracy: 0.9632 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1041 - accuracy: 0.9633 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1106 - accuracy: 0.9604 - val_loss: 0.0067 - val_accuracy: 0.9973\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0992 - accuracy: 0.9647 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1191 - accuracy: 0.9554 - val_loss: 0.0094 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1285 - accuracy: 0.9514 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0997 - accuracy: 0.9662 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0954 - accuracy: 0.9656 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1010 - accuracy: 0.9657 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1036 - accuracy: 0.9638 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0909 - accuracy: 0.9659 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1035 - accuracy: 0.9619 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0952 - accuracy: 0.9668 - val_loss: 0.0028 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1174 - accuracy: 0.9577 - val_loss: 0.0155 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0975 - accuracy: 0.9657 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1066 - accuracy: 0.9610 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0930 - accuracy: 0.9687 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0996 - accuracy: 0.9659 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1194 - accuracy: 0.9569 - val_loss: 0.0061 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0952 - accuracy: 0.9651 - val_loss: 0.0131 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1082 - accuracy: 0.9614 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0855 - accuracy: 0.9696 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1019 - accuracy: 0.9632 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0813 - accuracy: 0.9690 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1092 - accuracy: 0.9619 - val_loss: 0.0073 - val_accuracy: 0.9973\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.1080 - accuracy: 0.9647 - val_loss: 0.0104 - val_accuracy: 0.9987\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0934 - accuracy: 0.9690 - val_loss: 0.0138 - val_accuracy: 0.9987\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0889 - accuracy: 0.9680 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0856 - accuracy: 0.9693 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0928 - accuracy: 0.9671 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0942 - accuracy: 0.9666 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0858 - accuracy: 0.9698 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0897 - accuracy: 0.9671 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0829 - accuracy: 0.9692 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0967 - accuracy: 0.9666 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0752 - accuracy: 0.9717 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0925 - accuracy: 0.9680 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0803 - accuracy: 0.9705 - val_loss: 0.0156 - val_accuracy: 0.9946\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0905 - accuracy: 0.9681 - val_loss: 0.0168 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1017 - accuracy: 0.9630 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0827 - accuracy: 0.9695 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0795 - accuracy: 0.9729 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0912 - accuracy: 0.9686 - val_loss: 0.0228 - val_accuracy: 0.9919\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2147 - accuracy: 0.9242 - val_loss: 0.0948 - val_accuracy: 0.9517\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1158 - accuracy: 0.9596 - val_loss: 0.0198 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0815 - accuracy: 0.9690 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0964 - accuracy: 0.9680 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0913 - accuracy: 0.9668 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0717 - accuracy: 0.9745 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0928 - accuracy: 0.9680 - val_loss: 0.0128 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0738 - accuracy: 0.9759 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0821 - accuracy: 0.9733 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0846 - accuracy: 0.9698 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0759 - accuracy: 0.9742 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0971 - accuracy: 0.9689 - val_loss: 0.0411 - val_accuracy: 0.9772\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "id": "CAnc2SJa3o9f",
        "outputId": "78731acb-cb39-47a3-e635-1069746a5655"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 7ms/step - loss: 0.0990 - accuracy: 0.9598\n",
            "Accuracy  : 0.9597639441490173\n",
            "F1_Score  : 0.957522106750719\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7fcxLuwZpkK",
        "outputId": "a4300c02-c04a-4f88-d4b8-24ab8ba2491c"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "bd1fbaf8-ade8-4d0a-f967-2f55248d6517"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 53ms/step - loss: 1.1253 - accuracy: 0.4643 - val_loss: 1.0341 - val_accuracy: 0.5362\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0413 - accuracy: 0.5289 - val_loss: 1.0182 - val_accuracy: 0.5362\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0273 - accuracy: 0.5358 - val_loss: 1.0160 - val_accuracy: 0.5362\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0351 - accuracy: 0.5228 - val_loss: 1.0177 - val_accuracy: 0.5362\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0356 - accuracy: 0.5168 - val_loss: 1.0119 - val_accuracy: 0.5362\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0180 - accuracy: 0.5373 - val_loss: 1.0170 - val_accuracy: 0.5362\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0233 - accuracy: 0.5306 - val_loss: 1.0151 - val_accuracy: 0.5362\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0260 - accuracy: 0.5261 - val_loss: 1.0134 - val_accuracy: 0.5362\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0231 - accuracy: 0.5245 - val_loss: 1.0129 - val_accuracy: 0.5362\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0185 - accuracy: 0.5379 - val_loss: 1.0126 - val_accuracy: 0.5362\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0248 - accuracy: 0.5230 - val_loss: 1.0107 - val_accuracy: 0.5362\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0231 - accuracy: 0.5263 - val_loss: 1.0129 - val_accuracy: 0.5362\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0100 - accuracy: 0.5392 - val_loss: 1.0115 - val_accuracy: 0.5362\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0218 - accuracy: 0.5270 - val_loss: 1.0103 - val_accuracy: 0.5362\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0205 - accuracy: 0.5236 - val_loss: 1.0072 - val_accuracy: 0.5362\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0185 - accuracy: 0.5262 - val_loss: 1.0063 - val_accuracy: 0.5362\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0170 - accuracy: 0.5240 - val_loss: 1.0030 - val_accuracy: 0.5362\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0177 - accuracy: 0.5225 - val_loss: 1.0070 - val_accuracy: 0.5362\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0117 - accuracy: 0.5257 - val_loss: 0.9971 - val_accuracy: 0.5362\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0150 - accuracy: 0.5213 - val_loss: 0.9962 - val_accuracy: 0.5362\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0079 - accuracy: 0.5235 - val_loss: 0.9975 - val_accuracy: 0.5362\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0061 - accuracy: 0.5348 - val_loss: 1.0027 - val_accuracy: 0.5362\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0132 - accuracy: 0.5215 - val_loss: 1.0008 - val_accuracy: 0.5362\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0085 - accuracy: 0.5232 - val_loss: 1.0035 - val_accuracy: 0.5362\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0068 - accuracy: 0.5231 - val_loss: 0.9969 - val_accuracy: 0.5362\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0095 - accuracy: 0.5236 - val_loss: 1.0110 - val_accuracy: 0.5362\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0041 - accuracy: 0.5311 - val_loss: 0.9974 - val_accuracy: 0.5362\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0138 - accuracy: 0.5202 - val_loss: 1.0000 - val_accuracy: 0.5362\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9978 - accuracy: 0.5312 - val_loss: 1.0002 - val_accuracy: 0.5362\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9982 - accuracy: 0.5346 - val_loss: 1.0052 - val_accuracy: 0.5362\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 1.0018 - accuracy: 0.5292 - val_loss: 0.9945 - val_accuracy: 0.5214\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0008 - accuracy: 0.5292 - val_loss: 0.9963 - val_accuracy: 0.5214\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0024 - accuracy: 0.5292 - val_loss: 1.0036 - val_accuracy: 0.5214\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0005 - accuracy: 0.5292 - val_loss: 1.0000 - val_accuracy: 0.5214\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0018 - accuracy: 0.5292 - val_loss: 0.9953 - val_accuracy: 0.5214\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0019 - accuracy: 0.5292 - val_loss: 0.9931 - val_accuracy: 0.5214\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9983 - accuracy: 0.5292 - val_loss: 0.9902 - val_accuracy: 0.5214\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9970 - accuracy: 0.5292 - val_loss: 1.0009 - val_accuracy: 0.5214\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9980 - accuracy: 0.5292 - val_loss: 0.9875 - val_accuracy: 0.5214\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9958 - accuracy: 0.5291 - val_loss: 0.9871 - val_accuracy: 0.5214\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9945 - accuracy: 0.5292 - val_loss: 0.9924 - val_accuracy: 0.5214\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9917 - accuracy: 0.5286 - val_loss: 0.9880 - val_accuracy: 0.5214\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9946 - accuracy: 0.5291 - val_loss: 0.9923 - val_accuracy: 0.5214\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9912 - accuracy: 0.5291 - val_loss: 0.9930 - val_accuracy: 0.5214\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9892 - accuracy: 0.5292 - val_loss: 0.9875 - val_accuracy: 0.5214\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9888 - accuracy: 0.5292 - val_loss: 0.9767 - val_accuracy: 0.5214\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9904 - accuracy: 0.5292 - val_loss: 0.9843 - val_accuracy: 0.5214\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9841 - accuracy: 0.5295 - val_loss: 0.9756 - val_accuracy: 0.5214\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9862 - accuracy: 0.5292 - val_loss: 0.9839 - val_accuracy: 0.5214\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9851 - accuracy: 0.5292 - val_loss: 0.9847 - val_accuracy: 0.5214\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9798 - accuracy: 0.5285 - val_loss: 0.9712 - val_accuracy: 0.5214\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9789 - accuracy: 0.5289 - val_loss: 0.9686 - val_accuracy: 0.5214\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9785 - accuracy: 0.5288 - val_loss: 0.9738 - val_accuracy: 0.5214\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9738 - accuracy: 0.5292 - val_loss: 0.9579 - val_accuracy: 0.5214\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9745 - accuracy: 0.5292 - val_loss: 0.9707 - val_accuracy: 0.5214\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9645 - accuracy: 0.5292 - val_loss: 0.9800 - val_accuracy: 0.5214\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9694 - accuracy: 0.5291 - val_loss: 0.9542 - val_accuracy: 0.5214\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9700 - accuracy: 0.5291 - val_loss: 0.9734 - val_accuracy: 0.5214\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9739 - accuracy: 0.5282 - val_loss: 0.9663 - val_accuracy: 0.5214\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9667 - accuracy: 0.5279 - val_loss: 0.9464 - val_accuracy: 0.5214\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9578 - accuracy: 0.5316 - val_loss: 0.9445 - val_accuracy: 0.5080\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9485 - accuracy: 0.5303 - val_loss: 0.9339 - val_accuracy: 0.5080\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9459 - accuracy: 0.5308 - val_loss: 0.9380 - val_accuracy: 0.5080\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9557 - accuracy: 0.5308 - val_loss: 0.9451 - val_accuracy: 0.5080\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9351 - accuracy: 0.5303 - val_loss: 0.9261 - val_accuracy: 0.5080\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9290 - accuracy: 0.5297 - val_loss: 0.9326 - val_accuracy: 0.5080\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9326 - accuracy: 0.5306 - val_loss: 0.9202 - val_accuracy: 0.5080\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9415 - accuracy: 0.5307 - val_loss: 0.9244 - val_accuracy: 0.5080\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9264 - accuracy: 0.5308 - val_loss: 0.9168 - val_accuracy: 0.5080\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9215 - accuracy: 0.5323 - val_loss: 0.9133 - val_accuracy: 0.5080\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9102 - accuracy: 0.5280 - val_loss: 0.9060 - val_accuracy: 0.5080\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9023 - accuracy: 0.5356 - val_loss: 0.9018 - val_accuracy: 0.5241\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9127 - accuracy: 0.5404 - val_loss: 0.9023 - val_accuracy: 0.5295\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8978 - accuracy: 0.5490 - val_loss: 0.8807 - val_accuracy: 0.5523\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8857 - accuracy: 0.5441 - val_loss: 0.8892 - val_accuracy: 0.5576\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8798 - accuracy: 0.5523 - val_loss: 0.8745 - val_accuracy: 0.5684\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8562 - accuracy: 0.5677 - val_loss: 0.8512 - val_accuracy: 0.5590\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8775 - accuracy: 0.5650 - val_loss: 0.8486 - val_accuracy: 0.5523\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8546 - accuracy: 0.5747 - val_loss: 0.8404 - val_accuracy: 0.5737\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8388 - accuracy: 0.5799 - val_loss: 0.8350 - val_accuracy: 0.5777\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8193 - accuracy: 0.5909 - val_loss: 0.7930 - val_accuracy: 0.5965\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8024 - accuracy: 0.6013 - val_loss: 0.7851 - val_accuracy: 0.6019\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7933 - accuracy: 0.6066 - val_loss: 0.7840 - val_accuracy: 0.6032\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7936 - accuracy: 0.6133 - val_loss: 0.7597 - val_accuracy: 0.6139\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7638 - accuracy: 0.6197 - val_loss: 0.8073 - val_accuracy: 0.5764\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7591 - accuracy: 0.6265 - val_loss: 0.7400 - val_accuracy: 0.6086\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7403 - accuracy: 0.6396 - val_loss: 0.7418 - val_accuracy: 0.6153\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7285 - accuracy: 0.6380 - val_loss: 0.7183 - val_accuracy: 0.6448\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7213 - accuracy: 0.6422 - val_loss: 0.7000 - val_accuracy: 0.6300\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6858 - accuracy: 0.6537 - val_loss: 0.6855 - val_accuracy: 0.6582\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7002 - accuracy: 0.6569 - val_loss: 0.5449 - val_accuracy: 0.7131\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.6992 - accuracy: 0.6544 - val_loss: 0.5556 - val_accuracy: 0.7279\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6756 - accuracy: 0.6604 - val_loss: 0.5440 - val_accuracy: 0.7198\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6536 - accuracy: 0.6744 - val_loss: 0.5364 - val_accuracy: 0.7252\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6514 - accuracy: 0.6745 - val_loss: 0.5241 - val_accuracy: 0.7185\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6463 - accuracy: 0.6735 - val_loss: 0.5292 - val_accuracy: 0.7426\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6263 - accuracy: 0.6826 - val_loss: 0.6139 - val_accuracy: 0.7024\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6420 - accuracy: 0.6806 - val_loss: 0.5540 - val_accuracy: 0.7292\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6044 - accuracy: 0.6964 - val_loss: 0.5241 - val_accuracy: 0.7252\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5977 - accuracy: 0.6981 - val_loss: 0.4921 - val_accuracy: 0.7466\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6004 - accuracy: 0.7043 - val_loss: 0.5316 - val_accuracy: 0.7265\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5891 - accuracy: 0.6985 - val_loss: 0.4914 - val_accuracy: 0.7373\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5835 - accuracy: 0.7010 - val_loss: 0.5151 - val_accuracy: 0.7239\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5629 - accuracy: 0.7192 - val_loss: 0.4795 - val_accuracy: 0.7547\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5496 - accuracy: 0.7221 - val_loss: 0.4796 - val_accuracy: 0.7601\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5621 - accuracy: 0.7148 - val_loss: 0.4920 - val_accuracy: 0.7520\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5677 - accuracy: 0.7155 - val_loss: 0.4833 - val_accuracy: 0.7641\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5419 - accuracy: 0.7341 - val_loss: 0.4980 - val_accuracy: 0.7493\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5342 - accuracy: 0.7367 - val_loss: 0.4544 - val_accuracy: 0.7815\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5183 - accuracy: 0.7419 - val_loss: 0.4577 - val_accuracy: 0.7882\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5397 - accuracy: 0.7385 - val_loss: 0.4762 - val_accuracy: 0.7681\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5076 - accuracy: 0.7489 - val_loss: 0.4635 - val_accuracy: 0.7761\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5370 - accuracy: 0.7438 - val_loss: 0.4685 - val_accuracy: 0.7641\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4984 - accuracy: 0.7551 - val_loss: 0.4290 - val_accuracy: 0.8110\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5292 - accuracy: 0.7450 - val_loss: 0.4596 - val_accuracy: 0.7735\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5084 - accuracy: 0.7581 - val_loss: 0.4360 - val_accuracy: 0.7976\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4791 - accuracy: 0.7689 - val_loss: 0.4380 - val_accuracy: 0.7922\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4533 - accuracy: 0.7793 - val_loss: 0.4075 - val_accuracy: 0.8231\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4603 - accuracy: 0.7911 - val_loss: 0.4246 - val_accuracy: 0.8029\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4681 - accuracy: 0.7830 - val_loss: 0.4049 - val_accuracy: 0.8324\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4788 - accuracy: 0.7832 - val_loss: 0.2909 - val_accuracy: 0.8713\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4628 - accuracy: 0.7931 - val_loss: 0.2640 - val_accuracy: 0.8914\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4518 - accuracy: 0.8030 - val_loss: 0.2644 - val_accuracy: 0.8981\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4480 - accuracy: 0.7999 - val_loss: 0.2648 - val_accuracy: 0.8794\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4290 - accuracy: 0.8140 - val_loss: 0.2466 - val_accuracy: 0.9021\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4370 - accuracy: 0.8089 - val_loss: 0.2992 - val_accuracy: 0.8633\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4824 - accuracy: 0.7946 - val_loss: 0.2578 - val_accuracy: 0.9075\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4114 - accuracy: 0.8267 - val_loss: 0.2401 - val_accuracy: 0.9035\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3954 - accuracy: 0.8291 - val_loss: 0.2338 - val_accuracy: 0.8928\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3756 - accuracy: 0.8510 - val_loss: 0.2412 - val_accuracy: 0.8941\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3787 - accuracy: 0.8423 - val_loss: 0.2217 - val_accuracy: 0.9021\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3613 - accuracy: 0.8449 - val_loss: 0.2109 - val_accuracy: 0.9223\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3645 - accuracy: 0.8507 - val_loss: 0.2251 - val_accuracy: 0.9115\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3620 - accuracy: 0.8550 - val_loss: 0.2248 - val_accuracy: 0.8941\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3155 - accuracy: 0.8751 - val_loss: 0.1675 - val_accuracy: 0.9370\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3185 - accuracy: 0.8723 - val_loss: 0.1941 - val_accuracy: 0.9249\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3203 - accuracy: 0.8759 - val_loss: 0.1725 - val_accuracy: 0.9383\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3226 - accuracy: 0.8708 - val_loss: 0.1595 - val_accuracy: 0.9370\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3087 - accuracy: 0.8808 - val_loss: 0.1372 - val_accuracy: 0.9558\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2878 - accuracy: 0.8882 - val_loss: 0.1461 - val_accuracy: 0.9464\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2882 - accuracy: 0.8900 - val_loss: 0.1408 - val_accuracy: 0.9611\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2878 - accuracy: 0.8893 - val_loss: 0.1339 - val_accuracy: 0.9477\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2724 - accuracy: 0.8984 - val_loss: 0.1207 - val_accuracy: 0.9571\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2671 - accuracy: 0.8994 - val_loss: 0.1454 - val_accuracy: 0.9410\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2616 - accuracy: 0.9030 - val_loss: 0.1240 - val_accuracy: 0.9544\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2564 - accuracy: 0.9042 - val_loss: 0.1196 - val_accuracy: 0.9558\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2493 - accuracy: 0.9061 - val_loss: 0.1151 - val_accuracy: 0.9571\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2464 - accuracy: 0.9095 - val_loss: 0.1526 - val_accuracy: 0.9491\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2651 - accuracy: 0.9051 - val_loss: 0.1328 - val_accuracy: 0.9558\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2223 - accuracy: 0.9170 - val_loss: 0.0960 - val_accuracy: 0.9692\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2508 - accuracy: 0.9069 - val_loss: 0.0635 - val_accuracy: 0.9826\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2777 - accuracy: 0.8931 - val_loss: 0.0641 - val_accuracy: 0.9839\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2500 - accuracy: 0.9080 - val_loss: 0.0619 - val_accuracy: 0.9812\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2677 - accuracy: 0.9037 - val_loss: 0.0911 - val_accuracy: 0.9906\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2414 - accuracy: 0.9092 - val_loss: 0.0525 - val_accuracy: 0.9906\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2447 - accuracy: 0.9110 - val_loss: 0.0615 - val_accuracy: 0.9745\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2145 - accuracy: 0.9186 - val_loss: 0.0435 - val_accuracy: 0.9893\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2273 - accuracy: 0.9198 - val_loss: 0.0526 - val_accuracy: 0.9853\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2170 - accuracy: 0.9186 - val_loss: 0.0421 - val_accuracy: 0.9933\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2317 - accuracy: 0.9137 - val_loss: 0.0683 - val_accuracy: 0.9839\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2018 - accuracy: 0.9273 - val_loss: 0.0561 - val_accuracy: 0.9812\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2163 - accuracy: 0.9201 - val_loss: 0.0448 - val_accuracy: 0.9893\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1858 - accuracy: 0.9289 - val_loss: 0.0418 - val_accuracy: 0.9933\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2119 - accuracy: 0.9261 - val_loss: 0.0452 - val_accuracy: 0.9933\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1953 - accuracy: 0.9289 - val_loss: 0.0452 - val_accuracy: 0.9853\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2179 - accuracy: 0.9225 - val_loss: 0.0498 - val_accuracy: 0.9826\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1928 - accuracy: 0.9268 - val_loss: 0.0539 - val_accuracy: 0.9879\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1906 - accuracy: 0.9304 - val_loss: 0.0374 - val_accuracy: 0.9906\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1834 - accuracy: 0.9326 - val_loss: 0.0427 - val_accuracy: 0.9839\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1777 - accuracy: 0.9361 - val_loss: 0.0383 - val_accuracy: 0.9893\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1646 - accuracy: 0.9386 - val_loss: 0.0362 - val_accuracy: 0.9920\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1973 - accuracy: 0.9307 - val_loss: 0.0442 - val_accuracy: 0.9893\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1569 - accuracy: 0.9453 - val_loss: 0.0347 - val_accuracy: 0.9933\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1726 - accuracy: 0.9389 - val_loss: 0.0407 - val_accuracy: 0.9879\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1689 - accuracy: 0.9398 - val_loss: 0.0397 - val_accuracy: 0.9893\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1700 - accuracy: 0.9416 - val_loss: 0.0291 - val_accuracy: 0.9933\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1675 - accuracy: 0.9398 - val_loss: 0.0432 - val_accuracy: 0.9893\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1675 - accuracy: 0.9399 - val_loss: 0.0374 - val_accuracy: 0.9946\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1748 - accuracy: 0.9370 - val_loss: 0.0354 - val_accuracy: 0.9866\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1720 - accuracy: 0.9358 - val_loss: 0.0431 - val_accuracy: 0.9853\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1760 - accuracy: 0.9325 - val_loss: 0.0171 - val_accuracy: 0.9973\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1840 - accuracy: 0.9300 - val_loss: 0.0232 - val_accuracy: 0.9987\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1642 - accuracy: 0.9388 - val_loss: 0.0195 - val_accuracy: 0.9946\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1551 - accuracy: 0.9426 - val_loss: 0.0182 - val_accuracy: 0.9960\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1399 - accuracy: 0.9508 - val_loss: 0.0146 - val_accuracy: 0.9987\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1693 - accuracy: 0.9371 - val_loss: 0.0157 - val_accuracy: 0.9973\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1679 - accuracy: 0.9408 - val_loss: 0.0204 - val_accuracy: 0.9933\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1691 - accuracy: 0.9398 - val_loss: 0.0149 - val_accuracy: 0.9973\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1638 - accuracy: 0.9391 - val_loss: 0.0164 - val_accuracy: 0.9987\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1759 - accuracy: 0.9359 - val_loss: 0.0397 - val_accuracy: 0.9973\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1385 - accuracy: 0.9499 - val_loss: 0.0252 - val_accuracy: 0.9906\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1442 - accuracy: 0.9441 - val_loss: 0.0351 - val_accuracy: 0.9946\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1480 - accuracy: 0.9471 - val_loss: 0.0254 - val_accuracy: 0.9933\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1399 - accuracy: 0.9484 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1852 - accuracy: 0.9334 - val_loss: 0.0553 - val_accuracy: 0.9839\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1617 - accuracy: 0.9411 - val_loss: 0.0195 - val_accuracy: 0.9973\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1443 - accuracy: 0.9468 - val_loss: 0.0170 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1322 - accuracy: 0.9499 - val_loss: 0.0157 - val_accuracy: 0.9973\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1493 - accuracy: 0.9455 - val_loss: 0.0238 - val_accuracy: 0.9946\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1323 - accuracy: 0.9519 - val_loss: 0.0229 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1374 - accuracy: 0.9547 - val_loss: 0.0304 - val_accuracy: 0.9973\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1774 - accuracy: 0.9365 - val_loss: 0.0188 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1270 - accuracy: 0.9553 - val_loss: 0.0153 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1341 - accuracy: 0.9486 - val_loss: 0.0179 - val_accuracy: 0.9946\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1379 - accuracy: 0.9477 - val_loss: 0.0198 - val_accuracy: 0.9933\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1592 - accuracy: 0.9389 - val_loss: 0.0228 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1453 - accuracy: 0.9481 - val_loss: 0.0181 - val_accuracy: 0.9933\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1382 - accuracy: 0.9478 - val_loss: 0.0206 - val_accuracy: 0.9960\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1354 - accuracy: 0.9523 - val_loss: 0.0137 - val_accuracy: 0.9973\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1358 - accuracy: 0.9513 - val_loss: 0.0143 - val_accuracy: 0.9973\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1360 - accuracy: 0.9508 - val_loss: 0.0139 - val_accuracy: 0.9987\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1451 - accuracy: 0.9468 - val_loss: 0.0099 - val_accuracy: 0.9987\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1468 - accuracy: 0.9459 - val_loss: 0.0097 - val_accuracy: 0.9987\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1385 - accuracy: 0.9499 - val_loss: 0.0101 - val_accuracy: 0.9987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1299 - accuracy: 0.9550 - val_loss: 0.0075 - val_accuracy: 0.9987\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1362 - accuracy: 0.9516 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1363 - accuracy: 0.9531 - val_loss: 0.0157 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1156 - accuracy: 0.9583 - val_loss: 0.0099 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1293 - accuracy: 0.9551 - val_loss: 0.0176 - val_accuracy: 0.9987\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1298 - accuracy: 0.9514 - val_loss: 0.0178 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1251 - accuracy: 0.9550 - val_loss: 0.0072 - val_accuracy: 0.9987\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1130 - accuracy: 0.9595 - val_loss: 0.0100 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1160 - accuracy: 0.9590 - val_loss: 0.0084 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1139 - accuracy: 0.9608 - val_loss: 0.0097 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1224 - accuracy: 0.9547 - val_loss: 0.0096 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1289 - accuracy: 0.9540 - val_loss: 0.0123 - val_accuracy: 0.9987\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1160 - accuracy: 0.9565 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1328 - accuracy: 0.9499 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1232 - accuracy: 0.9560 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1314 - accuracy: 0.9510 - val_loss: 0.0154 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1068 - accuracy: 0.9651 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1234 - accuracy: 0.9565 - val_loss: 0.0079 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1457 - accuracy: 0.9525 - val_loss: 0.0159 - val_accuracy: 0.9973\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1796 - accuracy: 0.9318 - val_loss: 0.0451 - val_accuracy: 0.9933\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1323 - accuracy: 0.9538 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1064 - accuracy: 0.9611 - val_loss: 0.0107 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1223 - accuracy: 0.9572 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1084 - accuracy: 0.9616 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1092 - accuracy: 0.9611 - val_loss: 0.0089 - val_accuracy: 0.9973\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1105 - accuracy: 0.9636 - val_loss: 0.0131 - val_accuracy: 0.9973\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1296 - accuracy: 0.9540 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1155 - accuracy: 0.9581 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1116 - accuracy: 0.9584 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0948 - accuracy: 0.9686 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1146 - accuracy: 0.9619 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1079 - accuracy: 0.9605 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1132 - accuracy: 0.9651 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1113 - accuracy: 0.9610 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1116 - accuracy: 0.9613 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0987 - accuracy: 0.9629 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1119 - accuracy: 0.9593 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0988 - accuracy: 0.9651 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1004 - accuracy: 0.9613 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0951 - accuracy: 0.9692 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1011 - accuracy: 0.9648 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0984 - accuracy: 0.9645 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1121 - accuracy: 0.9632 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0923 - accuracy: 0.9681 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1155 - accuracy: 0.9580 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1068 - accuracy: 0.9613 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1022 - accuracy: 0.9619 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1044 - accuracy: 0.9654 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1031 - accuracy: 0.9651 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0964 - accuracy: 0.9669 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1041 - accuracy: 0.9648 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0915 - accuracy: 0.9656 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0953 - accuracy: 0.9654 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1093 - accuracy: 0.9617 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1116 - accuracy: 0.9610 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0945 - accuracy: 0.9648 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0934 - accuracy: 0.9669 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0979 - accuracy: 0.9644 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1129 - accuracy: 0.9608 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0994 - accuracy: 0.9620 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0920 - accuracy: 0.9698 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0936 - accuracy: 0.9696 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0811 - accuracy: 0.9709 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0921 - accuracy: 0.9695 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1026 - accuracy: 0.9610 - val_loss: 0.0300 - val_accuracy: 0.9987\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0945 - accuracy: 0.9648 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0830 - accuracy: 0.9680 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0896 - accuracy: 0.9686 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1046 - accuracy: 0.9636 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1080 - accuracy: 0.9610 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1067 - accuracy: 0.9639 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0836 - accuracy: 0.9703 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0956 - accuracy: 0.9651 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0901 - accuracy: 0.9671 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0951 - accuracy: 0.9692 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0982 - accuracy: 0.9654 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0806 - accuracy: 0.9674 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0775 - accuracy: 0.9727 - val_loss: 0.0076 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0961 - accuracy: 0.9650 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1024 - accuracy: 0.9623 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1108 - accuracy: 0.9610 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0862 - accuracy: 0.9696 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0868 - accuracy: 0.9702 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0806 - accuracy: 0.9692 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0848 - accuracy: 0.9700 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0784 - accuracy: 0.9727 - val_loss: 0.0039 - val_accuracy: 0.9987\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "21b0a6c8-e191-430d-b0a4-01bd0c493777"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 8ms/step - loss: 0.0343 - accuracy: 0.9898\n",
            "Accuracy  : 0.9898068904876709\n",
            "F1_Score  : 0.9888055784993259\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7e09c85a-53ba-4b4a-9669-a35b0aeafc91"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'#dominance\\nX_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\\nprint(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "a7b1240a-0f6c-4726-8d58-37e7a6cff8f0"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'foldNum=0\\nmodel = get_model()\\nfor train_index, val_index in kfold.split(X_train, Y_train):\\n  foldNum = foldNum + 1\\n  print(\"Results for fold\",foldNum)\\n  x_train, x_val = X_train[train_index], X_train[val_index]\\n  y_train, y_val = Y_train[train_index], Y_train[val_index]\\n  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\\n  gc.collect() # Garbage collecter\\n  del x_train, x_val, y_train, y_val\\n  gc.collect()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "91cc93e8-fe70-4c99-9f8d-16ace1929a9c"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'acrc = model.evaluate(x_test, y_test)\\npred = model.predict(x_test)\\nf1scr = f1_score(y_test.argmax(1), pred.argmax(1), average=\\'macro\\')\\nc_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\\nprint(\"Accuracy  : {}\".format(acrc[1]))\\nprint(\"F1_Score  : {}\".format(f1scr))\\nc_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\\nimport seaborn as sns\\nfigure = plt.figure(figsize=(9, 9))\\nsns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\\nplt.tight_layout()\\nplt.ylabel(\\'True label\\')\\nplt.xlabel(\\'Predicted label\\')\\nplt.show()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}