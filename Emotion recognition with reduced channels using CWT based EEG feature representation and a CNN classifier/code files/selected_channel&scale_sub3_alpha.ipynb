{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub3_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "dac5c2a5-6f73-4566-d4e6-d55e2eeab0c9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e3\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  #EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "54a5d514-880b-452b-91c7-e420a786c19a"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(3,4):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.3\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (1165,) (4427,) (3728,)\n",
            "(9320,) (5592,) (2796,) (932,)\n",
            "(9320,) (2330,) (6990,) (0,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "12405916-252e-498a-9994-e91f4ca98871"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "e54bc48c-0e39-4eb1-8219-b8e51b5eedcb"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "706"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "cecb9328-a122-4813-99b9-e3b28111b72c"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d86c00d4-5a0e-4f1c-beb7-e1cd5d2ef964"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 52s 93ms/step - loss: 1.0949 - accuracy: 0.4470 - val_loss: 0.9969 - val_accuracy: 0.3954\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 1.0034 - accuracy: 0.4795 - val_loss: 0.9866 - val_accuracy: 0.5013\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9974 - accuracy: 0.4880 - val_loss: 0.9856 - val_accuracy: 0.5027\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 0.9860 - accuracy: 0.4900 - val_loss: 0.9790 - val_accuracy: 0.5228\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.9916 - accuracy: 0.4779 - val_loss: 0.9719 - val_accuracy: 0.5161\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 0.9927 - accuracy: 0.4917 - val_loss: 0.9752 - val_accuracy: 0.5188\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9910 - accuracy: 0.4818 - val_loss: 0.9739 - val_accuracy: 0.5308\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9867 - accuracy: 0.4960 - val_loss: 0.9717 - val_accuracy: 0.5282\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9721 - accuracy: 0.4990 - val_loss: 0.9678 - val_accuracy: 0.5268\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9763 - accuracy: 0.4982 - val_loss: 0.9702 - val_accuracy: 0.5201\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9816 - accuracy: 0.4807 - val_loss: 0.9727 - val_accuracy: 0.5308\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9604 - accuracy: 0.4951 - val_loss: 0.9656 - val_accuracy: 0.5282\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9645 - accuracy: 0.4916 - val_loss: 0.9645 - val_accuracy: 0.5268\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.9673 - accuracy: 0.5007 - val_loss: 0.9704 - val_accuracy: 0.5255\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.9658 - accuracy: 0.5020 - val_loss: 0.9609 - val_accuracy: 0.5362\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9533 - accuracy: 0.5177 - val_loss: 0.9653 - val_accuracy: 0.5054\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9663 - accuracy: 0.5000 - val_loss: 0.9597 - val_accuracy: 0.5255\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9625 - accuracy: 0.5083 - val_loss: 0.9595 - val_accuracy: 0.5241\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.9634 - accuracy: 0.5046 - val_loss: 0.9634 - val_accuracy: 0.5107\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.9562 - accuracy: 0.5155 - val_loss: 0.9559 - val_accuracy: 0.5241\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.9557 - accuracy: 0.5112 - val_loss: 0.9637 - val_accuracy: 0.4960\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 0.9531 - accuracy: 0.5040 - val_loss: 0.9601 - val_accuracy: 0.5228\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9541 - accuracy: 0.5068 - val_loss: 0.9591 - val_accuracy: 0.5349\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9684 - accuracy: 0.4939 - val_loss: 0.9520 - val_accuracy: 0.5268\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 0.9538 - accuracy: 0.5102 - val_loss: 0.9532 - val_accuracy: 0.5308\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9438 - accuracy: 0.5238 - val_loss: 0.9543 - val_accuracy: 0.5188\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9475 - accuracy: 0.4973 - val_loss: 0.9536 - val_accuracy: 0.5067\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9516 - accuracy: 0.5152 - val_loss: 0.9538 - val_accuracy: 0.5214\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9417 - accuracy: 0.5227 - val_loss: 0.9569 - val_accuracy: 0.5228\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 0.9422 - accuracy: 0.5197 - val_loss: 0.9608 - val_accuracy: 0.5040\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.9407 - accuracy: 0.5173 - val_loss: 0.9513 - val_accuracy: 0.5308\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.9377 - accuracy: 0.5258 - val_loss: 0.9475 - val_accuracy: 0.5174\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.9336 - accuracy: 0.5277 - val_loss: 0.9508 - val_accuracy: 0.5228\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.9346 - accuracy: 0.5262 - val_loss: 0.9588 - val_accuracy: 0.5080\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.9284 - accuracy: 0.5347 - val_loss: 0.9457 - val_accuracy: 0.5094\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.9296 - accuracy: 0.5294 - val_loss: 0.9646 - val_accuracy: 0.5067\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.9329 - accuracy: 0.5306 - val_loss: 0.9476 - val_accuracy: 0.5188\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9274 - accuracy: 0.5317 - val_loss: 0.9718 - val_accuracy: 0.5013\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9303 - accuracy: 0.5270 - val_loss: 0.9560 - val_accuracy: 0.4933\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 0.9264 - accuracy: 0.5326 - val_loss: 0.9540 - val_accuracy: 0.5147\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.9263 - accuracy: 0.5209 - val_loss: 0.9456 - val_accuracy: 0.5188\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.9265 - accuracy: 0.5232 - val_loss: 0.9673 - val_accuracy: 0.5188\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.9152 - accuracy: 0.5341 - val_loss: 0.9426 - val_accuracy: 0.5000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.9161 - accuracy: 0.5431 - val_loss: 0.9533 - val_accuracy: 0.5255\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.9165 - accuracy: 0.5355 - val_loss: 0.9599 - val_accuracy: 0.5174\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9118 - accuracy: 0.5429 - val_loss: 0.9585 - val_accuracy: 0.5362\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.9078 - accuracy: 0.5432 - val_loss: 0.9366 - val_accuracy: 0.5228\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.9051 - accuracy: 0.5402 - val_loss: 0.9399 - val_accuracy: 0.5335\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9009 - accuracy: 0.5580 - val_loss: 0.9416 - val_accuracy: 0.5161\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.8987 - accuracy: 0.5542 - val_loss: 0.9531 - val_accuracy: 0.5322\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.9053 - accuracy: 0.5483 - val_loss: 0.9381 - val_accuracy: 0.5295\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8966 - accuracy: 0.5526 - val_loss: 0.9243 - val_accuracy: 0.5282\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.8875 - accuracy: 0.5581 - val_loss: 0.9115 - val_accuracy: 0.5416\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8818 - accuracy: 0.5537 - val_loss: 0.9105 - val_accuracy: 0.5402\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.8744 - accuracy: 0.5748 - val_loss: 0.9082 - val_accuracy: 0.5282\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.8758 - accuracy: 0.5651 - val_loss: 0.8876 - val_accuracy: 0.5724\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8666 - accuracy: 0.5681 - val_loss: 0.9056 - val_accuracy: 0.5684\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.8644 - accuracy: 0.5711 - val_loss: 0.9109 - val_accuracy: 0.5536\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.8508 - accuracy: 0.5681 - val_loss: 0.8982 - val_accuracy: 0.5456\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.8456 - accuracy: 0.5867 - val_loss: 0.8773 - val_accuracy: 0.5670\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.8458 - accuracy: 0.5802 - val_loss: 0.7995 - val_accuracy: 0.5871\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8349 - accuracy: 0.5870 - val_loss: 0.8046 - val_accuracy: 0.6099\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.8216 - accuracy: 0.6049 - val_loss: 0.8077 - val_accuracy: 0.5952\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8133 - accuracy: 0.6040 - val_loss: 0.7656 - val_accuracy: 0.6247\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.7794 - accuracy: 0.6311 - val_loss: 0.7789 - val_accuracy: 0.6005\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 0.7751 - accuracy: 0.6258 - val_loss: 0.7192 - val_accuracy: 0.6515\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.7587 - accuracy: 0.6480 - val_loss: 0.7179 - val_accuracy: 0.6381\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.7376 - accuracy: 0.6504 - val_loss: 0.7186 - val_accuracy: 0.6367\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.7169 - accuracy: 0.6668 - val_loss: 0.6838 - val_accuracy: 0.6635\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.6926 - accuracy: 0.6818 - val_loss: 0.6733 - val_accuracy: 0.6635\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.6779 - accuracy: 0.6891 - val_loss: 0.6161 - val_accuracy: 0.6971\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.6292 - accuracy: 0.7218 - val_loss: 0.5767 - val_accuracy: 0.7413\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.6293 - accuracy: 0.7237 - val_loss: 0.5920 - val_accuracy: 0.7145\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 0.5709 - accuracy: 0.7507 - val_loss: 0.5739 - val_accuracy: 0.7399\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.5439 - accuracy: 0.7666 - val_loss: 0.5098 - val_accuracy: 0.7668\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.5210 - accuracy: 0.7748 - val_loss: 0.4801 - val_accuracy: 0.7936\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.4530 - accuracy: 0.8088 - val_loss: 0.4496 - val_accuracy: 0.8164\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.4428 - accuracy: 0.8210 - val_loss: 0.4180 - val_accuracy: 0.8271\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.4057 - accuracy: 0.8382 - val_loss: 0.3918 - val_accuracy: 0.8271\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.3980 - accuracy: 0.8376 - val_loss: 0.4674 - val_accuracy: 0.7788\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.3985 - accuracy: 0.8407 - val_loss: 0.3399 - val_accuracy: 0.8525\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.3240 - accuracy: 0.8768 - val_loss: 0.3332 - val_accuracy: 0.8472\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.3222 - accuracy: 0.8729 - val_loss: 0.2732 - val_accuracy: 0.8861\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.2949 - accuracy: 0.8841 - val_loss: 0.3193 - val_accuracy: 0.8753\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.2768 - accuracy: 0.8943 - val_loss: 0.2615 - val_accuracy: 0.8861\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.2907 - accuracy: 0.8905 - val_loss: 0.3354 - val_accuracy: 0.8660\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.2524 - accuracy: 0.9067 - val_loss: 0.2369 - val_accuracy: 0.8981\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.2396 - accuracy: 0.9139 - val_loss: 0.2182 - val_accuracy: 0.9062\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.2363 - accuracy: 0.9131 - val_loss: 0.2566 - val_accuracy: 0.9021\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.2248 - accuracy: 0.9192 - val_loss: 0.2032 - val_accuracy: 0.9276\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.2255 - accuracy: 0.9164 - val_loss: 0.0588 - val_accuracy: 0.9812\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.2014 - accuracy: 0.9271 - val_loss: 0.0290 - val_accuracy: 0.9906\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.2060 - accuracy: 0.9262 - val_loss: 0.0347 - val_accuracy: 0.9946\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.2109 - accuracy: 0.9213 - val_loss: 0.0603 - val_accuracy: 0.9826\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1874 - accuracy: 0.9317 - val_loss: 0.0331 - val_accuracy: 0.9906\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1575 - accuracy: 0.9458 - val_loss: 0.0278 - val_accuracy: 0.9946\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1633 - accuracy: 0.9426 - val_loss: 0.0685 - val_accuracy: 0.9759\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1680 - accuracy: 0.9414 - val_loss: 0.0316 - val_accuracy: 0.9933\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.1426 - accuracy: 0.9508 - val_loss: 0.0257 - val_accuracy: 0.9933\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1379 - accuracy: 0.9511 - val_loss: 0.0290 - val_accuracy: 0.9906\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1553 - accuracy: 0.9493 - val_loss: 0.0337 - val_accuracy: 0.9906\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1260 - accuracy: 0.9581 - val_loss: 0.0276 - val_accuracy: 0.9893\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.1157 - accuracy: 0.9607 - val_loss: 0.0370 - val_accuracy: 0.9826\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.1332 - accuracy: 0.9528 - val_loss: 0.0272 - val_accuracy: 0.9906\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.1149 - accuracy: 0.9632 - val_loss: 0.0331 - val_accuracy: 0.9879\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0952 - accuracy: 0.9672 - val_loss: 0.0261 - val_accuracy: 0.9893\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.1433 - accuracy: 0.9522 - val_loss: 0.0332 - val_accuracy: 0.9893\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1244 - accuracy: 0.9562 - val_loss: 0.0237 - val_accuracy: 0.9893\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.0965 - accuracy: 0.9669 - val_loss: 0.0387 - val_accuracy: 0.9812\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0879 - accuracy: 0.9699 - val_loss: 0.0382 - val_accuracy: 0.9866\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1003 - accuracy: 0.9680 - val_loss: 0.0331 - val_accuracy: 0.9893\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.1006 - accuracy: 0.9692 - val_loss: 0.0188 - val_accuracy: 0.9946\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0881 - accuracy: 0.9703 - val_loss: 0.0197 - val_accuracy: 0.9933\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0957 - accuracy: 0.9668 - val_loss: 0.0216 - val_accuracy: 0.9933\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.1080 - accuracy: 0.9627 - val_loss: 0.0301 - val_accuracy: 0.9866\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.1070 - accuracy: 0.9639 - val_loss: 0.0239 - val_accuracy: 0.9946\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0772 - accuracy: 0.9705 - val_loss: 0.0391 - val_accuracy: 0.9853\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0853 - accuracy: 0.9697 - val_loss: 0.0302 - val_accuracy: 0.9893\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0777 - accuracy: 0.9733 - val_loss: 0.0446 - val_accuracy: 0.9893\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0793 - accuracy: 0.9730 - val_loss: 0.0213 - val_accuracy: 0.9920\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 77ms/step - loss: 0.0878 - accuracy: 0.9697 - val_loss: 8.8545e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0877 - accuracy: 0.9706 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.1097 - accuracy: 0.9632 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0721 - accuracy: 0.9775 - val_loss: 9.2879e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0845 - accuracy: 0.9712 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0672 - accuracy: 0.9791 - val_loss: 8.3916e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0710 - accuracy: 0.9772 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0657 - accuracy: 0.9790 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0986 - accuracy: 0.9674 - val_loss: 7.9337e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0594 - accuracy: 0.9799 - val_loss: 0.0022 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0626 - accuracy: 0.9778 - val_loss: 9.3223e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0664 - accuracy: 0.9784 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0704 - accuracy: 0.9763 - val_loss: 0.0043 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0676 - accuracy: 0.9793 - val_loss: 0.0025 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0540 - accuracy: 0.9817 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0520 - accuracy: 0.9836 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0678 - accuracy: 0.9763 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0646 - accuracy: 0.9791 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0525 - accuracy: 0.9830 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0441 - accuracy: 0.9851 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0584 - accuracy: 0.9821 - val_loss: 0.0027 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0619 - accuracy: 0.9809 - val_loss: 0.0069 - val_accuracy: 0.9973\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0557 - accuracy: 0.9815 - val_loss: 0.0088 - val_accuracy: 0.9973\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.0562 - accuracy: 0.9818 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0410 - accuracy: 0.9863 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0500 - accuracy: 0.9844 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0466 - accuracy: 0.9841 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0520 - accuracy: 0.9854 - val_loss: 0.0066 - val_accuracy: 0.9973\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0446 - accuracy: 0.9851 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0628 - accuracy: 0.9809 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0645 - accuracy: 0.9817 - val_loss: 4.5595e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0539 - accuracy: 0.9824 - val_loss: 2.1177e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0802 - accuracy: 0.9718 - val_loss: 2.1170e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0518 - accuracy: 0.9839 - val_loss: 1.6716e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0560 - accuracy: 0.9824 - val_loss: 1.4784e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0542 - accuracy: 0.9821 - val_loss: 2.5808e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0584 - accuracy: 0.9803 - val_loss: 4.3509e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0545 - accuracy: 0.9806 - val_loss: 5.5800e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0352 - accuracy: 0.9870 - val_loss: 5.4408e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.0465 - accuracy: 0.9839 - val_loss: 1.2587e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0470 - accuracy: 0.9845 - val_loss: 5.8695e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0389 - accuracy: 0.9872 - val_loss: 5.2629e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0395 - accuracy: 0.9873 - val_loss: 6.7691e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0508 - accuracy: 0.9824 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0509 - accuracy: 0.9832 - val_loss: 5.9270e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0516 - accuracy: 0.9835 - val_loss: 6.8399e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0500 - accuracy: 0.9861 - val_loss: 2.8765e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0355 - accuracy: 0.9881 - val_loss: 0.0016 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0462 - accuracy: 0.9864 - val_loss: 5.7392e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0400 - accuracy: 0.9872 - val_loss: 0.0013 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0538 - accuracy: 0.9829 - val_loss: 0.0038 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0364 - accuracy: 0.9881 - val_loss: 0.0021 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0448 - accuracy: 0.9851 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0461 - accuracy: 0.9842 - val_loss: 4.2651e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0432 - accuracy: 0.9854 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0479 - accuracy: 0.9858 - val_loss: 2.6286e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0412 - accuracy: 0.9867 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0295 - accuracy: 0.9900 - val_loss: 9.0660e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0463 - accuracy: 0.9855 - val_loss: 7.1726e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.2131 - accuracy: 0.9322 - val_loss: 0.0889 - val_accuracy: 0.9678\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 81ms/step - loss: 0.0592 - accuracy: 0.9818 - val_loss: 3.6456e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0357 - accuracy: 0.9893 - val_loss: 1.3752e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0443 - accuracy: 0.9864 - val_loss: 7.5282e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0393 - accuracy: 0.9870 - val_loss: 2.1700e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0339 - accuracy: 0.9885 - val_loss: 1.0347e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0347 - accuracy: 0.9900 - val_loss: 5.4889e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0441 - accuracy: 0.9866 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0469 - accuracy: 0.9850 - val_loss: 2.4304e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0350 - accuracy: 0.9897 - val_loss: 8.2329e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0417 - accuracy: 0.9866 - val_loss: 9.6268e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0314 - accuracy: 0.9896 - val_loss: 1.6484e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0315 - accuracy: 0.9911 - val_loss: 6.6505e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0262 - accuracy: 0.9912 - val_loss: 5.7631e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0463 - accuracy: 0.9848 - val_loss: 3.8840e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0322 - accuracy: 0.9900 - val_loss: 5.9725e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0335 - accuracy: 0.9888 - val_loss: 1.6512e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0322 - accuracy: 0.9894 - val_loss: 4.7136e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0343 - accuracy: 0.9900 - val_loss: 0.0027 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0426 - accuracy: 0.9884 - val_loss: 7.8636e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0389 - accuracy: 0.9863 - val_loss: 7.9785e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0248 - accuracy: 0.9928 - val_loss: 1.1902e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0386 - accuracy: 0.9867 - val_loss: 2.9952e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0337 - accuracy: 0.9890 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0280 - accuracy: 0.9914 - val_loss: 7.7388e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0324 - accuracy: 0.9909 - val_loss: 2.4120e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0426 - accuracy: 0.9867 - val_loss: 1.1515e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0528 - accuracy: 0.9818 - val_loss: 2.9521e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0322 - accuracy: 0.9914 - val_loss: 6.7962e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0272 - accuracy: 0.9914 - val_loss: 9.4456e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0379 - accuracy: 0.9879 - val_loss: 6.6730e-04 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0373 - accuracy: 0.9879 - val_loss: 2.5439e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0351 - accuracy: 0.9890 - val_loss: 2.4887e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0351 - accuracy: 0.9890 - val_loss: 3.5119e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0456 - accuracy: 0.9875 - val_loss: 3.9838e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0262 - accuracy: 0.9905 - val_loss: 5.6162e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 77ms/step - loss: 0.0285 - accuracy: 0.9909 - val_loss: 1.1053e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0317 - accuracy: 0.9903 - val_loss: 2.6217e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0354 - accuracy: 0.9894 - val_loss: 7.6169e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0365 - accuracy: 0.9890 - val_loss: 3.3046e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0301 - accuracy: 0.9899 - val_loss: 4.8327e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 77ms/step - loss: 0.0246 - accuracy: 0.9915 - val_loss: 2.3124e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0325 - accuracy: 0.9878 - val_loss: 1.9098e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0577 - accuracy: 0.9829 - val_loss: 1.0888e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0351 - accuracy: 0.9897 - val_loss: 1.1384e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0280 - accuracy: 0.9911 - val_loss: 4.8040e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0227 - accuracy: 0.9931 - val_loss: 4.5530e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0273 - accuracy: 0.9906 - val_loss: 1.1878e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0366 - accuracy: 0.9873 - val_loss: 1.0260e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0240 - accuracy: 0.9920 - val_loss: 6.1671e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0290 - accuracy: 0.9924 - val_loss: 1.3263e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0290 - accuracy: 0.9911 - val_loss: 1.3699e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0389 - accuracy: 0.9887 - val_loss: 8.3128e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0332 - accuracy: 0.9894 - val_loss: 2.4380e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0372 - accuracy: 0.9897 - val_loss: 3.8147e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0310 - accuracy: 0.9905 - val_loss: 4.7881e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0287 - accuracy: 0.9903 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0262 - accuracy: 0.9912 - val_loss: 3.2193e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0256 - accuracy: 0.9914 - val_loss: 4.9042e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0188 - accuracy: 0.9942 - val_loss: 1.8439e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0249 - accuracy: 0.9912 - val_loss: 3.6754e-05 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0505 - accuracy: 0.9854 - val_loss: 3.2013e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0269 - accuracy: 0.9912 - val_loss: 9.9562e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0303 - accuracy: 0.9900 - val_loss: 1.4486e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0247 - accuracy: 0.9921 - val_loss: 2.6323e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0305 - accuracy: 0.9896 - val_loss: 1.1176e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0573 - accuracy: 0.9835 - val_loss: 2.1987e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0314 - accuracy: 0.9911 - val_loss: 3.8252e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0388 - accuracy: 0.9903 - val_loss: 4.3335e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0329 - accuracy: 0.9890 - val_loss: 3.0611e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0231 - accuracy: 0.9920 - val_loss: 1.9037e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0300 - accuracy: 0.9896 - val_loss: 5.0994e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0307 - accuracy: 0.9914 - val_loss: 2.6507e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0215 - accuracy: 0.9934 - val_loss: 1.5732e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0155 - accuracy: 0.9960 - val_loss: 3.3914e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0273 - accuracy: 0.9927 - val_loss: 1.1367e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0322 - accuracy: 0.9894 - val_loss: 2.9331e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 1.6245e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0254 - accuracy: 0.9917 - val_loss: 4.0285e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0284 - accuracy: 0.9915 - val_loss: 3.2729e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0395 - accuracy: 0.9894 - val_loss: 3.1109e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0285 - accuracy: 0.9911 - val_loss: 3.1577e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0235 - accuracy: 0.9930 - val_loss: 1.1412e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0227 - accuracy: 0.9928 - val_loss: 1.3120e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0336 - accuracy: 0.9918 - val_loss: 3.7789e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 1.7901e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0160 - accuracy: 0.9946 - val_loss: 1.3996e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0300 - accuracy: 0.9912 - val_loss: 2.4161e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0222 - accuracy: 0.9936 - val_loss: 3.1026e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0243 - accuracy: 0.9920 - val_loss: 5.2403e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 77ms/step - loss: 0.0189 - accuracy: 0.9928 - val_loss: 1.3267e-04 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0305 - accuracy: 0.9911 - val_loss: 1.2239e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0270 - accuracy: 0.9914 - val_loss: 7.7863e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0364 - accuracy: 0.9891 - val_loss: 1.4043e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0311 - accuracy: 0.9903 - val_loss: 1.2845e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0293 - accuracy: 0.9903 - val_loss: 9.4485e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0257 - accuracy: 0.9924 - val_loss: 7.8575e-06 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0177 - accuracy: 0.9955 - val_loss: 5.2991e-06 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0248 - accuracy: 0.9928 - val_loss: 6.5386e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0224 - accuracy: 0.9934 - val_loss: 4.6030e-06 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0250 - accuracy: 0.9931 - val_loss: 5.8504e-06 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 6.8710e-06 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0162 - accuracy: 0.9939 - val_loss: 2.7261e-06 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0238 - accuracy: 0.9921 - val_loss: 1.9069e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0272 - accuracy: 0.9911 - val_loss: 5.2894e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0672 - accuracy: 0.9793 - val_loss: 1.8790e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 78ms/step - loss: 0.0250 - accuracy: 0.9921 - val_loss: 5.2511e-06 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0227 - accuracy: 0.9917 - val_loss: 7.2223e-06 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0267 - accuracy: 0.9933 - val_loss: 1.9043e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 77ms/step - loss: 0.0275 - accuracy: 0.9917 - val_loss: 6.7658e-06 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0286 - accuracy: 0.9911 - val_loss: 3.7408e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0275 - accuracy: 0.9912 - val_loss: 1.6861e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0183 - accuracy: 0.9937 - val_loss: 6.8421e-06 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0146 - accuracy: 0.9952 - val_loss: 3.7347e-06 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0260 - accuracy: 0.9924 - val_loss: 6.0911e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0431 - accuracy: 0.9869 - val_loss: 1.6404e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0188 - accuracy: 0.9937 - val_loss: 1.0769e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 77ms/step - loss: 0.0214 - accuracy: 0.9937 - val_loss: 4.4279e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0288 - accuracy: 0.9917 - val_loss: 5.9613e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0240 - accuracy: 0.9925 - val_loss: 2.1375e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0291 - accuracy: 0.9905 - val_loss: 1.6002e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "CAnc2SJa3o9f",
        "outputId": "5f5102ab-f641-4d48-9764-c43d838fc169"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 13ms/step - loss: 0.0228 - accuracy: 0.9903\n",
            "Accuracy  : 0.9903433322906494\n",
            "F1_Score  : 0.9896994568397798\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7fcxLuwZpkK",
        "outputId": "8ff8e36f-19ad-4fb2-cda8-ee0731ecd5ad"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "650f65ee-ee6e-438a-c07c-9d128eb0f681"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 6s 84ms/step - loss: 1.0826 - accuracy: 0.5081 - val_loss: 0.9044 - val_accuracy: 0.6180\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.9369 - accuracy: 0.5709 - val_loss: 0.8806 - val_accuracy: 0.6180\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9215 - accuracy: 0.5840 - val_loss: 0.8698 - val_accuracy: 0.6180\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9210 - accuracy: 0.5986 - val_loss: 0.8772 - val_accuracy: 0.6180\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.9133 - accuracy: 0.5932 - val_loss: 0.8726 - val_accuracy: 0.6180\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.9065 - accuracy: 0.5848 - val_loss: 0.8716 - val_accuracy: 0.6180\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8975 - accuracy: 0.6014 - val_loss: 0.8740 - val_accuracy: 0.6180\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9008 - accuracy: 0.5942 - val_loss: 0.8616 - val_accuracy: 0.6180\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8997 - accuracy: 0.5940 - val_loss: 0.8737 - val_accuracy: 0.6180\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9071 - accuracy: 0.5926 - val_loss: 0.8851 - val_accuracy: 0.6180\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.8903 - accuracy: 0.6000 - val_loss: 0.8653 - val_accuracy: 0.6180\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.8892 - accuracy: 0.5967 - val_loss: 0.8682 - val_accuracy: 0.6180\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 0.8989 - accuracy: 0.5924 - val_loss: 0.8734 - val_accuracy: 0.6180\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.8767 - accuracy: 0.6030 - val_loss: 0.8601 - val_accuracy: 0.6180\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8874 - accuracy: 0.5881 - val_loss: 0.8444 - val_accuracy: 0.6180\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.8931 - accuracy: 0.5929 - val_loss: 0.8573 - val_accuracy: 0.6180\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.8818 - accuracy: 0.5946 - val_loss: 0.8475 - val_accuracy: 0.6180\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.8871 - accuracy: 0.6008 - val_loss: 0.8780 - val_accuracy: 0.6180\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.8760 - accuracy: 0.5947 - val_loss: 0.8435 - val_accuracy: 0.6180\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8746 - accuracy: 0.5910 - val_loss: 0.8427 - val_accuracy: 0.6180\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8863 - accuracy: 0.5803 - val_loss: 0.8286 - val_accuracy: 0.6180\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8709 - accuracy: 0.5965 - val_loss: 0.8433 - val_accuracy: 0.6180\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8710 - accuracy: 0.5978 - val_loss: 0.8360 - val_accuracy: 0.6180\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.8693 - accuracy: 0.5937 - val_loss: 0.8359 - val_accuracy: 0.6180\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.8637 - accuracy: 0.5998 - val_loss: 0.8468 - val_accuracy: 0.6180\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.8703 - accuracy: 0.5909 - val_loss: 0.8296 - val_accuracy: 0.6180\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8826 - accuracy: 0.5868 - val_loss: 0.8283 - val_accuracy: 0.6180\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.8653 - accuracy: 0.5951 - val_loss: 0.8336 - val_accuracy: 0.6180\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8598 - accuracy: 0.5933 - val_loss: 0.8506 - val_accuracy: 0.6180\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8610 - accuracy: 0.5913 - val_loss: 0.8345 - val_accuracy: 0.6180\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.8535 - accuracy: 0.5934 - val_loss: 0.8595 - val_accuracy: 0.5912\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.8506 - accuracy: 0.5949 - val_loss: 0.8423 - val_accuracy: 0.5912\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8517 - accuracy: 0.5951 - val_loss: 0.8467 - val_accuracy: 0.5912\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8492 - accuracy: 0.5952 - val_loss: 0.8439 - val_accuracy: 0.5912\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8431 - accuracy: 0.5933 - val_loss: 0.8497 - val_accuracy: 0.5912\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8397 - accuracy: 0.5924 - val_loss: 0.8374 - val_accuracy: 0.5912\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.8465 - accuracy: 0.5951 - val_loss: 0.8499 - val_accuracy: 0.5912\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.8364 - accuracy: 0.5964 - val_loss: 0.8442 - val_accuracy: 0.5912\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 0.8337 - accuracy: 0.5952 - val_loss: 0.8325 - val_accuracy: 0.5912\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8324 - accuracy: 0.5955 - val_loss: 0.8194 - val_accuracy: 0.5912\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8246 - accuracy: 0.5949 - val_loss: 0.8307 - val_accuracy: 0.5912\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8228 - accuracy: 0.5955 - val_loss: 0.8594 - val_accuracy: 0.5952\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.8185 - accuracy: 0.5939 - val_loss: 0.8262 - val_accuracy: 0.5925\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8217 - accuracy: 0.5954 - val_loss: 0.8417 - val_accuracy: 0.5912\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8146 - accuracy: 0.5955 - val_loss: 0.8214 - val_accuracy: 0.5925\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8102 - accuracy: 0.6000 - val_loss: 0.8367 - val_accuracy: 0.5925\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8041 - accuracy: 0.5976 - val_loss: 0.8259 - val_accuracy: 0.5925\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.8009 - accuracy: 0.5978 - val_loss: 0.8759 - val_accuracy: 0.5925\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.7929 - accuracy: 0.5994 - val_loss: 0.8111 - val_accuracy: 0.5885\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.7741 - accuracy: 0.6009 - val_loss: 0.7972 - val_accuracy: 0.5952\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.7670 - accuracy: 0.6022 - val_loss: 0.7681 - val_accuracy: 0.5925\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.7534 - accuracy: 0.6085 - val_loss: 0.8161 - val_accuracy: 0.6086\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.7472 - accuracy: 0.6083 - val_loss: 0.7902 - val_accuracy: 0.6032\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.7228 - accuracy: 0.6194 - val_loss: 0.7794 - val_accuracy: 0.6206\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.7207 - accuracy: 0.6177 - val_loss: 0.7675 - val_accuracy: 0.6206\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.6793 - accuracy: 0.6326 - val_loss: 0.6826 - val_accuracy: 0.6394\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.6557 - accuracy: 0.6438 - val_loss: 0.6969 - val_accuracy: 0.6488\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.6477 - accuracy: 0.6489 - val_loss: 0.6916 - val_accuracy: 0.6501\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.6213 - accuracy: 0.6621 - val_loss: 0.6803 - val_accuracy: 0.6635\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.6033 - accuracy: 0.6852 - val_loss: 0.6245 - val_accuracy: 0.6984\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 77ms/step - loss: 0.6004 - accuracy: 0.6937 - val_loss: 0.5318 - val_accuracy: 0.7011\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.5717 - accuracy: 0.7125 - val_loss: 0.5319 - val_accuracy: 0.7426\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.5825 - accuracy: 0.7145 - val_loss: 0.4361 - val_accuracy: 0.7936\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.5313 - accuracy: 0.7399 - val_loss: 0.4291 - val_accuracy: 0.8070\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.5016 - accuracy: 0.7675 - val_loss: 0.4595 - val_accuracy: 0.8123\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.4613 - accuracy: 0.7902 - val_loss: 0.4212 - val_accuracy: 0.7922\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.4505 - accuracy: 0.7967 - val_loss: 0.4437 - val_accuracy: 0.7466\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.4113 - accuracy: 0.8167 - val_loss: 0.5150 - val_accuracy: 0.6823\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.4135 - accuracy: 0.8182 - val_loss: 0.3747 - val_accuracy: 0.7989\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.3943 - accuracy: 0.8279 - val_loss: 0.3752 - val_accuracy: 0.7828\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.3369 - accuracy: 0.8583 - val_loss: 0.2434 - val_accuracy: 0.8914\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.3478 - accuracy: 0.8562 - val_loss: 0.2633 - val_accuracy: 0.8753\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.3161 - accuracy: 0.8763 - val_loss: 0.2526 - val_accuracy: 0.8834\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.3110 - accuracy: 0.8784 - val_loss: 0.3095 - val_accuracy: 0.8713\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.2718 - accuracy: 0.8931 - val_loss: 0.2261 - val_accuracy: 0.9035\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.2686 - accuracy: 0.8934 - val_loss: 0.2346 - val_accuracy: 0.8901\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.2488 - accuracy: 0.9057 - val_loss: 0.1760 - val_accuracy: 0.9169\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.2360 - accuracy: 0.9100 - val_loss: 0.2021 - val_accuracy: 0.9129\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.2335 - accuracy: 0.9110 - val_loss: 0.1901 - val_accuracy: 0.9182\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.2007 - accuracy: 0.9230 - val_loss: 0.1258 - val_accuracy: 0.9544\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.1861 - accuracy: 0.9306 - val_loss: 0.1416 - val_accuracy: 0.9531\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1822 - accuracy: 0.9347 - val_loss: 0.1220 - val_accuracy: 0.9544\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.1849 - accuracy: 0.9353 - val_loss: 0.1886 - val_accuracy: 0.9223\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.2231 - accuracy: 0.9250 - val_loss: 0.1496 - val_accuracy: 0.9343\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.1461 - accuracy: 0.9484 - val_loss: 0.1209 - val_accuracy: 0.9598\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1579 - accuracy: 0.9483 - val_loss: 0.1320 - val_accuracy: 0.9504\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.1491 - accuracy: 0.9471 - val_loss: 0.1051 - val_accuracy: 0.9625\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.1334 - accuracy: 0.9510 - val_loss: 0.1194 - val_accuracy: 0.9598\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1344 - accuracy: 0.9542 - val_loss: 0.1075 - val_accuracy: 0.9611\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1249 - accuracy: 0.9581 - val_loss: 0.0696 - val_accuracy: 0.9799\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 77ms/step - loss: 0.1327 - accuracy: 0.9557 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1258 - accuracy: 0.9572 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1356 - accuracy: 0.9528 - val_loss: 0.0139 - val_accuracy: 0.9960\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1232 - accuracy: 0.9547 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1145 - accuracy: 0.9572 - val_loss: 0.0113 - val_accuracy: 0.9987\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0989 - accuracy: 0.9666 - val_loss: 0.0099 - val_accuracy: 0.9973\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1123 - accuracy: 0.9663 - val_loss: 0.0214 - val_accuracy: 0.9906\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1011 - accuracy: 0.9653 - val_loss: 0.0115 - val_accuracy: 0.9973\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.1038 - accuracy: 0.9644 - val_loss: 0.0115 - val_accuracy: 0.9973\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0880 - accuracy: 0.9720 - val_loss: 0.0073 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0986 - accuracy: 0.9660 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0802 - accuracy: 0.9730 - val_loss: 0.0053 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0739 - accuracy: 0.9750 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0900 - accuracy: 0.9709 - val_loss: 0.0111 - val_accuracy: 0.9960\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0776 - accuracy: 0.9739 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0804 - accuracy: 0.9744 - val_loss: 0.0085 - val_accuracy: 0.9973\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0696 - accuracy: 0.9756 - val_loss: 0.0110 - val_accuracy: 0.9960\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.1259 - accuracy: 0.9587 - val_loss: 0.0167 - val_accuracy: 0.9960\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0752 - accuracy: 0.9732 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0838 - accuracy: 0.9683 - val_loss: 0.0071 - val_accuracy: 0.9973\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.0561 - accuracy: 0.9803 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0571 - accuracy: 0.9818 - val_loss: 0.0093 - val_accuracy: 0.9960\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0709 - accuracy: 0.9775 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0542 - accuracy: 0.9833 - val_loss: 0.0058 - val_accuracy: 0.9973\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0658 - accuracy: 0.9802 - val_loss: 0.0092 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0664 - accuracy: 0.9790 - val_loss: 0.0116 - val_accuracy: 0.9973\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.0539 - accuracy: 0.9848 - val_loss: 0.0068 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0579 - accuracy: 0.9829 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0490 - accuracy: 0.9849 - val_loss: 0.0076 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.0510 - accuracy: 0.9844 - val_loss: 0.0068 - val_accuracy: 0.9987\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0723 - accuracy: 0.9747 - val_loss: 3.3006e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0600 - accuracy: 0.9814 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0494 - accuracy: 0.9848 - val_loss: 6.1652e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0557 - accuracy: 0.9803 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0522 - accuracy: 0.9823 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0689 - accuracy: 0.9790 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0502 - accuracy: 0.9844 - val_loss: 5.3641e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0718 - accuracy: 0.9766 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0705 - accuracy: 0.9772 - val_loss: 8.0339e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0388 - accuracy: 0.9875 - val_loss: 4.3983e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0640 - accuracy: 0.9793 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0611 - accuracy: 0.9814 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0558 - accuracy: 0.9812 - val_loss: 4.7643e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0464 - accuracy: 0.9858 - val_loss: 0.0052 - val_accuracy: 0.9960\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0459 - accuracy: 0.9866 - val_loss: 0.0036 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0482 - accuracy: 0.9844 - val_loss: 7.3580e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0397 - accuracy: 0.9873 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0445 - accuracy: 0.9855 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0424 - accuracy: 0.9884 - val_loss: 5.7885e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0402 - accuracy: 0.9870 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0455 - accuracy: 0.9869 - val_loss: 8.7587e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0313 - accuracy: 0.9902 - val_loss: 4.7400e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0369 - accuracy: 0.9887 - val_loss: 7.2709e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0464 - accuracy: 0.9861 - val_loss: 7.3817e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0820 - accuracy: 0.9733 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0388 - accuracy: 0.9870 - val_loss: 4.8594e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0441 - accuracy: 0.9855 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0541 - accuracy: 0.9839 - val_loss: 0.0039 - val_accuracy: 0.9973\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0440 - accuracy: 0.9870 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0351 - accuracy: 0.9884 - val_loss: 9.4406e-04 - val_accuracy: 1.0000\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0392 - accuracy: 0.9876 - val_loss: 3.6862e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0670 - accuracy: 0.9797 - val_loss: 2.6212e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0422 - accuracy: 0.9866 - val_loss: 7.8532e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0415 - accuracy: 0.9863 - val_loss: 1.2530e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0397 - accuracy: 0.9861 - val_loss: 6.6535e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0557 - accuracy: 0.9824 - val_loss: 1.4306e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0383 - accuracy: 0.9894 - val_loss: 2.7664e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0352 - accuracy: 0.9893 - val_loss: 1.4277e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0368 - accuracy: 0.9894 - val_loss: 5.4691e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0535 - accuracy: 0.9845 - val_loss: 6.3271e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0355 - accuracy: 0.9891 - val_loss: 9.6191e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0376 - accuracy: 0.9896 - val_loss: 1.7281e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0436 - accuracy: 0.9863 - val_loss: 1.0249e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0406 - accuracy: 0.9876 - val_loss: 0.0024 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0366 - accuracy: 0.9885 - val_loss: 7.7245e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0347 - accuracy: 0.9896 - val_loss: 3.8145e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0482 - accuracy: 0.9848 - val_loss: 2.4659e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0312 - accuracy: 0.9908 - val_loss: 7.6058e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0329 - accuracy: 0.9893 - val_loss: 9.8178e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0562 - accuracy: 0.9841 - val_loss: 5.0630e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0361 - accuracy: 0.9882 - val_loss: 2.2847e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0337 - accuracy: 0.9888 - val_loss: 1.2765e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0382 - accuracy: 0.9884 - val_loss: 7.1132e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0334 - accuracy: 0.9872 - val_loss: 1.2685e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0310 - accuracy: 0.9906 - val_loss: 9.9360e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0321 - accuracy: 0.9899 - val_loss: 6.5701e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0207 - accuracy: 0.9936 - val_loss: 6.4795e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0399 - accuracy: 0.9894 - val_loss: 4.7078e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0321 - accuracy: 0.9899 - val_loss: 1.2818e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0357 - accuracy: 0.9896 - val_loss: 1.9363e-04 - val_accuracy: 1.0000\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0288 - accuracy: 0.9905 - val_loss: 5.0436e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0599 - accuracy: 0.9799 - val_loss: 3.2801e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0337 - accuracy: 0.9894 - val_loss: 1.7779e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.0282 - accuracy: 0.9911 - val_loss: 1.7524e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0282 - accuracy: 0.9902 - val_loss: 6.8888e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0276 - accuracy: 0.9909 - val_loss: 1.9632e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0268 - accuracy: 0.9924 - val_loss: 6.5751e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0239 - accuracy: 0.9931 - val_loss: 5.3761e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0428 - accuracy: 0.9872 - val_loss: 0.0014 - val_accuracy: 0.9987\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0350 - accuracy: 0.9885 - val_loss: 6.2676e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0308 - accuracy: 0.9897 - val_loss: 1.5735e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0791 - accuracy: 0.9757 - val_loss: 8.1810e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0549 - accuracy: 0.9838 - val_loss: 1.7913e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 77ms/step - loss: 0.0364 - accuracy: 0.9887 - val_loss: 1.6320e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0270 - accuracy: 0.9914 - val_loss: 0.0024 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0345 - accuracy: 0.9891 - val_loss: 9.5255e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0320 - accuracy: 0.9911 - val_loss: 8.2945e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 4.1859e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0358 - accuracy: 0.9879 - val_loss: 2.9630e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0475 - accuracy: 0.9863 - val_loss: 1.4664e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0224 - accuracy: 0.9930 - val_loss: 2.7159e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0344 - accuracy: 0.9903 - val_loss: 1.0219e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0642 - accuracy: 0.9805 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0248 - accuracy: 0.9931 - val_loss: 4.2477e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0293 - accuracy: 0.9903 - val_loss: 6.3510e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0389 - accuracy: 0.9876 - val_loss: 5.3318e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0279 - accuracy: 0.9911 - val_loss: 1.6866e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0193 - accuracy: 0.9945 - val_loss: 1.8898e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0267 - accuracy: 0.9918 - val_loss: 2.6612e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0285 - accuracy: 0.9923 - val_loss: 7.6943e-05 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0329 - accuracy: 0.9899 - val_loss: 3.9233e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0479 - accuracy: 0.9857 - val_loss: 8.3907e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0318 - accuracy: 0.9903 - val_loss: 0.0058 - val_accuracy: 0.9960\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0215 - accuracy: 0.9931 - val_loss: 1.4612e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0246 - accuracy: 0.9917 - val_loss: 1.2052e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0186 - accuracy: 0.9943 - val_loss: 2.0734e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0260 - accuracy: 0.9921 - val_loss: 2.5939e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0429 - accuracy: 0.9879 - val_loss: 4.5744e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0299 - accuracy: 0.9915 - val_loss: 1.4785e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0178 - accuracy: 0.9948 - val_loss: 5.9955e-06 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0252 - accuracy: 0.9933 - val_loss: 2.5932e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0223 - accuracy: 0.9936 - val_loss: 1.5061e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0339 - accuracy: 0.9899 - val_loss: 8.1430e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0234 - accuracy: 0.9931 - val_loss: 0.0018 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0263 - accuracy: 0.9921 - val_loss: 4.9070e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0232 - accuracy: 0.9928 - val_loss: 7.6627e-06 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0284 - accuracy: 0.9906 - val_loss: 3.3609e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0229 - accuracy: 0.9921 - val_loss: 5.7931e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0301 - accuracy: 0.9908 - val_loss: 0.0023 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0174 - accuracy: 0.9948 - val_loss: 0.0015 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0218 - accuracy: 0.9936 - val_loss: 0.0010 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 9.0695e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0206 - accuracy: 0.9936 - val_loss: 1.1995e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0242 - accuracy: 0.9925 - val_loss: 1.7693e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0340 - accuracy: 0.9888 - val_loss: 0.0045 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0188 - accuracy: 0.9948 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0216 - accuracy: 0.9920 - val_loss: 0.0044 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0341 - accuracy: 0.9902 - val_loss: 6.5874e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0270 - accuracy: 0.9915 - val_loss: 5.8886e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0430 - accuracy: 0.9879 - val_loss: 6.1027e-04 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0520 - accuracy: 0.9847 - val_loss: 8.6471e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0601 - accuracy: 0.9823 - val_loss: 1.3322e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0289 - accuracy: 0.9928 - val_loss: 3.8651e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0244 - accuracy: 0.9930 - val_loss: 2.2065e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0154 - accuracy: 0.9940 - val_loss: 1.9464e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 78ms/step - loss: 0.0301 - accuracy: 0.9909 - val_loss: 2.0078e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0178 - accuracy: 0.9951 - val_loss: 2.8775e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0156 - accuracy: 0.9945 - val_loss: 4.5175e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0175 - accuracy: 0.9952 - val_loss: 7.1915e-06 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0202 - accuracy: 0.9940 - val_loss: 1.4470e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0210 - accuracy: 0.9930 - val_loss: 1.0314e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0264 - accuracy: 0.9925 - val_loss: 1.2500e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0221 - accuracy: 0.9924 - val_loss: 4.3094e-06 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0242 - accuracy: 0.9930 - val_loss: 9.7112e-06 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0356 - accuracy: 0.9893 - val_loss: 9.4988e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 78ms/step - loss: 0.0218 - accuracy: 0.9936 - val_loss: 1.0927e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 7.1123e-06 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 6.5344e-06 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0155 - accuracy: 0.9948 - val_loss: 4.5792e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0181 - accuracy: 0.9937 - val_loss: 0.0042 - val_accuracy: 0.9973\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0265 - accuracy: 0.9900 - val_loss: 3.9096e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0218 - accuracy: 0.9954 - val_loss: 4.2799e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0218 - accuracy: 0.9942 - val_loss: 1.1511e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 0.0011 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 0.0016 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0255 - accuracy: 0.9908 - val_loss: 3.9836e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0229 - accuracy: 0.9925 - val_loss: 3.9530e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0168 - accuracy: 0.9955 - val_loss: 1.1720e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0181 - accuracy: 0.9936 - val_loss: 7.2829e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0155 - accuracy: 0.9957 - val_loss: 2.4068e-04 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0241 - accuracy: 0.9931 - val_loss: 5.2445e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0291 - accuracy: 0.9908 - val_loss: 1.3224e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0343 - accuracy: 0.9893 - val_loss: 9.9767e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0298 - accuracy: 0.9915 - val_loss: 3.7014e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0237 - accuracy: 0.9927 - val_loss: 5.0979e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0193 - accuracy: 0.9937 - val_loss: 1.6591e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0205 - accuracy: 0.9931 - val_loss: 3.0021e-06 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0312 - accuracy: 0.9918 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0243 - accuracy: 0.9924 - val_loss: 5.6829e-06 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 2.9931e-06 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0263 - accuracy: 0.9918 - val_loss: 1.4070e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0224 - accuracy: 0.9927 - val_loss: 0.0027 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0199 - accuracy: 0.9933 - val_loss: 3.5252e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0248 - accuracy: 0.9931 - val_loss: 1.8088e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 77ms/step - loss: 0.0219 - accuracy: 0.9936 - val_loss: 1.7090e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0401 - accuracy: 0.9855 - val_loss: 2.0009e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0207 - accuracy: 0.9928 - val_loss: 1.2518e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0200 - accuracy: 0.9934 - val_loss: 9.1856e-06 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0272 - accuracy: 0.9924 - val_loss: 2.7312e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0310 - accuracy: 0.9917 - val_loss: 8.5642e-06 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 1.6052e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0173 - accuracy: 0.9949 - val_loss: 1.5662e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0136 - accuracy: 0.9963 - val_loss: 4.2150e-06 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0231 - accuracy: 0.9942 - val_loss: 6.5972e-06 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0236 - accuracy: 0.9923 - val_loss: 3.4242e-06 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 3.4333e-06 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0228 - accuracy: 0.9940 - val_loss: 5.7513e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0174 - accuracy: 0.9937 - val_loss: 1.7924e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0135 - accuracy: 0.9952 - val_loss: 4.8084e-06 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0145 - accuracy: 0.9961 - val_loss: 5.1819e-06 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "e6ee72a8-f718-4f11-8550-ca63f02b9f86"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 12ms/step - loss: 0.0307 - accuracy: 0.9909\n",
            "Accuracy  : 0.9908798336982727\n",
            "F1_Score  : 0.988316870086448\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "0867a7d9-1fae-4302-84d2-c626f7075ab3"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'#dominance\\nX_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\\nprint(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "32902d82-14f9-4ca9-a26a-8a0648eda73b"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'foldNum=0\\nmodel = get_model()\\nfor train_index, val_index in kfold.split(X_train, Y_train):\\n  foldNum = foldNum + 1\\n  print(\"Results for fold\",foldNum)\\n  x_train, x_val = X_train[train_index], X_train[val_index]\\n  y_train, y_val = Y_train[train_index], Y_train[val_index]\\n  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\\n  gc.collect() # Garbage collecter\\n  del x_train, x_val, y_train, y_val\\n  gc.collect()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "1426051f-113b-4b48-8a62-ddc190e6c0f2"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'acrc = model.evaluate(x_test, y_test)\\npred = model.predict(x_test)\\nf1scr = f1_score(y_test.argmax(1), pred.argmax(1), average=\\'macro\\')\\nc_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\\nprint(\"Accuracy  : {}\".format(acrc[1]))\\nprint(\"F1_Score  : {}\".format(f1scr))\\nc_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\\nimport seaborn as sns\\nfigure = plt.figure(figsize=(9, 9))\\nsns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\\nplt.tight_layout()\\nplt.ylabel(\\'True label\\')\\nplt.xlabel(\\'Predicted label\\')\\nplt.show()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}