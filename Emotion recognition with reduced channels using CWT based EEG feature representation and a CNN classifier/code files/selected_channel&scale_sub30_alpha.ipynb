{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub30_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "9d123e80-7bc5-4ee2-d0d7-9f7aa770ef39"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e3\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  #EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "a992df7b-4c45-4f83-b61a-b5b0f4523019"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(30,31):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.30\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (1398,) (4660,) (3262,)\n",
            "(9320,) (2330,) (4194,) (2796,)\n",
            "(9320,) (1398,) (5359,) (2563,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "0806a38e-c820-4be8-d4ed-4d1f22f8ff83"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "f3905466-ef1d-40d0-b35e-d99baca53e94"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "622"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "0d47093a-1807-4c06-d1eb-693f2f2a4688"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf711ced-728a-4b0a-bcfe-72bf8e619da9"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 50s 60ms/step - loss: 1.1059 - accuracy: 0.4414 - val_loss: 1.0288 - val_accuracy: 0.5121\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0174 - accuracy: 0.4936 - val_loss: 0.9958 - val_accuracy: 0.5121\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0046 - accuracy: 0.5010 - val_loss: 0.9837 - val_accuracy: 0.5362\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0017 - accuracy: 0.5001 - val_loss: 0.9769 - val_accuracy: 0.5362\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9896 - accuracy: 0.5042 - val_loss: 0.9828 - val_accuracy: 0.5228\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9974 - accuracy: 0.5044 - val_loss: 0.9724 - val_accuracy: 0.5416\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9812 - accuracy: 0.5060 - val_loss: 0.9788 - val_accuracy: 0.5349\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9816 - accuracy: 0.5070 - val_loss: 0.9825 - val_accuracy: 0.5362\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9850 - accuracy: 0.5013 - val_loss: 0.9728 - val_accuracy: 0.5429\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9810 - accuracy: 0.5064 - val_loss: 0.9714 - val_accuracy: 0.5442\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9821 - accuracy: 0.5079 - val_loss: 0.9778 - val_accuracy: 0.5483\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9887 - accuracy: 0.5022 - val_loss: 0.9772 - val_accuracy: 0.5322\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9851 - accuracy: 0.5099 - val_loss: 0.9684 - val_accuracy: 0.5416\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9789 - accuracy: 0.5128 - val_loss: 0.9786 - val_accuracy: 0.5322\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9702 - accuracy: 0.5152 - val_loss: 0.9673 - val_accuracy: 0.5576\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9668 - accuracy: 0.5183 - val_loss: 0.9719 - val_accuracy: 0.5416\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.9630 - accuracy: 0.5274 - val_loss: 0.9584 - val_accuracy: 0.5563\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9777 - accuracy: 0.5141 - val_loss: 0.9701 - val_accuracy: 0.5308\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9695 - accuracy: 0.5118 - val_loss: 0.9586 - val_accuracy: 0.5442\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9684 - accuracy: 0.5225 - val_loss: 0.9530 - val_accuracy: 0.5416\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9760 - accuracy: 0.5145 - val_loss: 0.9675 - val_accuracy: 0.5416\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9613 - accuracy: 0.5211 - val_loss: 0.9612 - val_accuracy: 0.5509\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9570 - accuracy: 0.5280 - val_loss: 0.9781 - val_accuracy: 0.5228\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9681 - accuracy: 0.5258 - val_loss: 0.9591 - val_accuracy: 0.5416\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9595 - accuracy: 0.5288 - val_loss: 0.9484 - val_accuracy: 0.5362\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9673 - accuracy: 0.5146 - val_loss: 0.9521 - val_accuracy: 0.5295\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9532 - accuracy: 0.5327 - val_loss: 0.9750 - val_accuracy: 0.5013\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9563 - accuracy: 0.5204 - val_loss: 0.9743 - val_accuracy: 0.5308\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9559 - accuracy: 0.5223 - val_loss: 0.9436 - val_accuracy: 0.5536\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9524 - accuracy: 0.5181 - val_loss: 0.9569 - val_accuracy: 0.5509\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9555 - accuracy: 0.5189 - val_loss: 0.9418 - val_accuracy: 0.5550\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9532 - accuracy: 0.5224 - val_loss: 0.9491 - val_accuracy: 0.5349\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9512 - accuracy: 0.5258 - val_loss: 0.9327 - val_accuracy: 0.5550\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9450 - accuracy: 0.5282 - val_loss: 0.9610 - val_accuracy: 0.5349\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9433 - accuracy: 0.5316 - val_loss: 0.9114 - val_accuracy: 0.5617\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9414 - accuracy: 0.5349 - val_loss: 0.9344 - val_accuracy: 0.5469\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9358 - accuracy: 0.5347 - val_loss: 0.9420 - val_accuracy: 0.5483\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9394 - accuracy: 0.5311 - val_loss: 0.9237 - val_accuracy: 0.5590\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9263 - accuracy: 0.5410 - val_loss: 0.9197 - val_accuracy: 0.5576\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9163 - accuracy: 0.5441 - val_loss: 0.9349 - val_accuracy: 0.5349\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9221 - accuracy: 0.5402 - val_loss: 0.9273 - val_accuracy: 0.5509\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9049 - accuracy: 0.5517 - val_loss: 0.8950 - val_accuracy: 0.5710\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9089 - accuracy: 0.5484 - val_loss: 0.9143 - val_accuracy: 0.5550\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9047 - accuracy: 0.5487 - val_loss: 0.8979 - val_accuracy: 0.5697\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8863 - accuracy: 0.5565 - val_loss: 0.8899 - val_accuracy: 0.5670\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8800 - accuracy: 0.5604 - val_loss: 0.8889 - val_accuracy: 0.5670\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8654 - accuracy: 0.5683 - val_loss: 0.8680 - val_accuracy: 0.5858\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8469 - accuracy: 0.5766 - val_loss: 0.8638 - val_accuracy: 0.5737\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.8544 - accuracy: 0.5678 - val_loss: 0.8384 - val_accuracy: 0.5845\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8290 - accuracy: 0.5900 - val_loss: 0.8316 - val_accuracy: 0.5831\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.8385 - accuracy: 0.5762 - val_loss: 0.8920 - val_accuracy: 0.5818\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8248 - accuracy: 0.5855 - val_loss: 0.8317 - val_accuracy: 0.6046\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7803 - accuracy: 0.6154 - val_loss: 0.8481 - val_accuracy: 0.6072\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7711 - accuracy: 0.6203 - val_loss: 0.7704 - val_accuracy: 0.6381\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7490 - accuracy: 0.6303 - val_loss: 0.7573 - val_accuracy: 0.6448\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7246 - accuracy: 0.6483 - val_loss: 0.7033 - val_accuracy: 0.6542\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7037 - accuracy: 0.6601 - val_loss: 0.8966 - val_accuracy: 0.6488\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6770 - accuracy: 0.6751 - val_loss: 0.6616 - val_accuracy: 0.6810\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6709 - accuracy: 0.6812 - val_loss: 0.6404 - val_accuracy: 0.7011\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6455 - accuracy: 0.6923 - val_loss: 0.6811 - val_accuracy: 0.6810\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.6404 - accuracy: 0.6981 - val_loss: 0.5481 - val_accuracy: 0.7359\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6218 - accuracy: 0.7112 - val_loss: 0.5183 - val_accuracy: 0.7654\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.5951 - accuracy: 0.7231 - val_loss: 0.5091 - val_accuracy: 0.7480\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5980 - accuracy: 0.7311 - val_loss: 0.5941 - val_accuracy: 0.7386\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5726 - accuracy: 0.7323 - val_loss: 0.4486 - val_accuracy: 0.7909\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.5386 - accuracy: 0.7566 - val_loss: 0.4746 - val_accuracy: 0.7681\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5476 - accuracy: 0.7516 - val_loss: 0.4661 - val_accuracy: 0.8070\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5470 - accuracy: 0.7522 - val_loss: 0.4677 - val_accuracy: 0.7788\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4873 - accuracy: 0.7888 - val_loss: 0.4348 - val_accuracy: 0.7828\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4836 - accuracy: 0.7806 - val_loss: 0.3741 - val_accuracy: 0.8231\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.4427 - accuracy: 0.8070 - val_loss: 0.4029 - val_accuracy: 0.8257\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4227 - accuracy: 0.8130 - val_loss: 0.3297 - val_accuracy: 0.8378\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4531 - accuracy: 0.8089 - val_loss: 0.5206 - val_accuracy: 0.8016\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4237 - accuracy: 0.8204 - val_loss: 0.3816 - val_accuracy: 0.8432\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3912 - accuracy: 0.8317 - val_loss: 0.3583 - val_accuracy: 0.8418\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3853 - accuracy: 0.8362 - val_loss: 0.3068 - val_accuracy: 0.8606\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3923 - accuracy: 0.8319 - val_loss: 0.3916 - val_accuracy: 0.8177\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3848 - accuracy: 0.8398 - val_loss: 0.3469 - val_accuracy: 0.8552\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3285 - accuracy: 0.8699 - val_loss: 0.2894 - val_accuracy: 0.8847\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3167 - accuracy: 0.8693 - val_loss: 0.2644 - val_accuracy: 0.8834\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3100 - accuracy: 0.8790 - val_loss: 0.3216 - val_accuracy: 0.8673\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3918 - accuracy: 0.8456 - val_loss: 0.3845 - val_accuracy: 0.8445\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2809 - accuracy: 0.8928 - val_loss: 0.2418 - val_accuracy: 0.9035\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2631 - accuracy: 0.8957 - val_loss: 0.2194 - val_accuracy: 0.9263\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2503 - accuracy: 0.9015 - val_loss: 0.2890 - val_accuracy: 0.8700\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2519 - accuracy: 0.9022 - val_loss: 0.2485 - val_accuracy: 0.9035\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2550 - accuracy: 0.9034 - val_loss: 0.1882 - val_accuracy: 0.9370\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2197 - accuracy: 0.9143 - val_loss: 0.2572 - val_accuracy: 0.9048\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3066 - accuracy: 0.8836 - val_loss: 0.3626 - val_accuracy: 0.8525\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2073 - accuracy: 0.9258 - val_loss: 0.2042 - val_accuracy: 0.9263\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2324 - accuracy: 0.9137 - val_loss: 0.0483 - val_accuracy: 0.9920\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2204 - accuracy: 0.9218 - val_loss: 0.0577 - val_accuracy: 0.9879\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1970 - accuracy: 0.9270 - val_loss: 0.0717 - val_accuracy: 0.9799\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1826 - accuracy: 0.9331 - val_loss: 0.0590 - val_accuracy: 0.9786\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2448 - accuracy: 0.9130 - val_loss: 0.1403 - val_accuracy: 0.9424\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1849 - accuracy: 0.9329 - val_loss: 0.0535 - val_accuracy: 0.9879\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1752 - accuracy: 0.9367 - val_loss: 0.0446 - val_accuracy: 0.9893\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1518 - accuracy: 0.9434 - val_loss: 0.0517 - val_accuracy: 0.9826\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2102 - accuracy: 0.9270 - val_loss: 0.1087 - val_accuracy: 0.9491\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1863 - accuracy: 0.9316 - val_loss: 0.0368 - val_accuracy: 0.9946\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1458 - accuracy: 0.9471 - val_loss: 0.0482 - val_accuracy: 0.9879\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1365 - accuracy: 0.9487 - val_loss: 0.0350 - val_accuracy: 0.9906\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1576 - accuracy: 0.9425 - val_loss: 0.0546 - val_accuracy: 0.9799\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1908 - accuracy: 0.9325 - val_loss: 0.0623 - val_accuracy: 0.9839\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1432 - accuracy: 0.9478 - val_loss: 0.0294 - val_accuracy: 0.9973\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1232 - accuracy: 0.9577 - val_loss: 0.0240 - val_accuracy: 0.9946\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1571 - accuracy: 0.9438 - val_loss: 0.0697 - val_accuracy: 0.9732\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1208 - accuracy: 0.9551 - val_loss: 0.0409 - val_accuracy: 0.9879\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1264 - accuracy: 0.9542 - val_loss: 0.0380 - val_accuracy: 0.9893\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1239 - accuracy: 0.9548 - val_loss: 0.0255 - val_accuracy: 0.9946\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1257 - accuracy: 0.9542 - val_loss: 0.0507 - val_accuracy: 0.9759\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1474 - accuracy: 0.9462 - val_loss: 0.0903 - val_accuracy: 0.9665\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1304 - accuracy: 0.9541 - val_loss: 0.0234 - val_accuracy: 0.9960\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1311 - accuracy: 0.9525 - val_loss: 0.1156 - val_accuracy: 0.9477\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1240 - accuracy: 0.9568 - val_loss: 0.1301 - val_accuracy: 0.9544\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1339 - accuracy: 0.9511 - val_loss: 0.0521 - val_accuracy: 0.9799\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2199 - accuracy: 0.9294 - val_loss: 0.8390 - val_accuracy: 0.7735\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1964 - accuracy: 0.9274 - val_loss: 0.0359 - val_accuracy: 0.9933\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1215 - accuracy: 0.9584 - val_loss: 0.0314 - val_accuracy: 0.9920\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1047 - accuracy: 0.9626 - val_loss: 0.0177 - val_accuracy: 0.9987\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1133 - accuracy: 0.9590 - val_loss: 0.0095 - val_accuracy: 0.9987\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1071 - accuracy: 0.9647 - val_loss: 0.0092 - val_accuracy: 0.9987\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0941 - accuracy: 0.9654 - val_loss: 0.0131 - val_accuracy: 0.9987\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1058 - accuracy: 0.9618 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1166 - accuracy: 0.9569 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1834 - accuracy: 0.9343 - val_loss: 0.0253 - val_accuracy: 0.9960\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1024 - accuracy: 0.9633 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0927 - accuracy: 0.9672 - val_loss: 0.0150 - val_accuracy: 0.9933\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1057 - accuracy: 0.9596 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0897 - accuracy: 0.9671 - val_loss: 0.0055 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1051 - accuracy: 0.9666 - val_loss: 0.0156 - val_accuracy: 0.9973\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0871 - accuracy: 0.9671 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0937 - accuracy: 0.9657 - val_loss: 0.0169 - val_accuracy: 0.9946\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1152 - accuracy: 0.9566 - val_loss: 0.0382 - val_accuracy: 0.9839\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0945 - accuracy: 0.9666 - val_loss: 0.0276 - val_accuracy: 0.9946\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0939 - accuracy: 0.9671 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0900 - accuracy: 0.9635 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0964 - accuracy: 0.9638 - val_loss: 0.0149 - val_accuracy: 0.9960\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0928 - accuracy: 0.9692 - val_loss: 0.0384 - val_accuracy: 0.9853\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1060 - accuracy: 0.9681 - val_loss: 0.0056 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1040 - accuracy: 0.9651 - val_loss: 0.0120 - val_accuracy: 0.9946\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0845 - accuracy: 0.9709 - val_loss: 0.0090 - val_accuracy: 0.9960\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0863 - accuracy: 0.9705 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0730 - accuracy: 0.9721 - val_loss: 0.0179 - val_accuracy: 0.9920\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0949 - accuracy: 0.9668 - val_loss: 0.0075 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0733 - accuracy: 0.9717 - val_loss: 0.0055 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0670 - accuracy: 0.9775 - val_loss: 0.0058 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0757 - accuracy: 0.9739 - val_loss: 0.0067 - val_accuracy: 0.9973\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0781 - accuracy: 0.9742 - val_loss: 0.0035 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1732 - accuracy: 0.9404 - val_loss: 0.2454 - val_accuracy: 0.9088\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1055 - accuracy: 0.9623 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0992 - accuracy: 0.9650 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0912 - accuracy: 0.9672 - val_loss: 0.0398 - val_accuracy: 0.9839\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0789 - accuracy: 0.9721 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0819 - accuracy: 0.9717 - val_loss: 6.8582e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1117 - accuracy: 0.9620 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0769 - accuracy: 0.9750 - val_loss: 0.0106 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0778 - accuracy: 0.9687 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0780 - accuracy: 0.9742 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0785 - accuracy: 0.9712 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0871 - accuracy: 0.9689 - val_loss: 0.1021 - val_accuracy: 0.9491\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0887 - accuracy: 0.9684 - val_loss: 0.0055 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0789 - accuracy: 0.9720 - val_loss: 8.8920e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0685 - accuracy: 0.9757 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1052 - accuracy: 0.9627 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0605 - accuracy: 0.9788 - val_loss: 8.3861e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0637 - accuracy: 0.9775 - val_loss: 7.1506e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0786 - accuracy: 0.9714 - val_loss: 5.6764e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0751 - accuracy: 0.9750 - val_loss: 0.0540 - val_accuracy: 0.9759\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1061 - accuracy: 0.9651 - val_loss: 0.0127 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0823 - accuracy: 0.9714 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0626 - accuracy: 0.9793 - val_loss: 7.7360e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0705 - accuracy: 0.9768 - val_loss: 8.0612e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0638 - accuracy: 0.9802 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0618 - accuracy: 0.9790 - val_loss: 0.0033 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0803 - accuracy: 0.9726 - val_loss: 0.0735 - val_accuracy: 0.9718\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1161 - accuracy: 0.9598 - val_loss: 0.0179 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0827 - accuracy: 0.9729 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0683 - accuracy: 0.9778 - val_loss: 0.0093 - val_accuracy: 0.9973\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0559 - accuracy: 0.9820 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 50ms/step - loss: 0.1107 - accuracy: 0.9666 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0765 - accuracy: 0.9733 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0611 - accuracy: 0.9785 - val_loss: 7.7506e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0591 - accuracy: 0.9796 - val_loss: 4.7208e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0586 - accuracy: 0.9803 - val_loss: 3.8077e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0695 - accuracy: 0.9778 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0653 - accuracy: 0.9782 - val_loss: 0.0073 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1279 - accuracy: 0.9599 - val_loss: 0.0220 - val_accuracy: 0.9973\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0882 - accuracy: 0.9696 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0653 - accuracy: 0.9759 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0533 - accuracy: 0.9797 - val_loss: 3.2447e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0564 - accuracy: 0.9784 - val_loss: 7.2304e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0600 - accuracy: 0.9788 - val_loss: 7.2304e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0570 - accuracy: 0.9799 - val_loss: 0.0028 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0629 - accuracy: 0.9782 - val_loss: 6.1489e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0649 - accuracy: 0.9782 - val_loss: 9.7933e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0511 - accuracy: 0.9811 - val_loss: 3.1555e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0541 - accuracy: 0.9821 - val_loss: 7.6784e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0746 - accuracy: 0.9760 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0679 - accuracy: 0.9771 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0573 - accuracy: 0.9790 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0498 - accuracy: 0.9838 - val_loss: 3.4274e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0657 - accuracy: 0.9766 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0633 - accuracy: 0.9785 - val_loss: 6.9756e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0609 - accuracy: 0.9784 - val_loss: 0.0233 - val_accuracy: 0.9893\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0531 - accuracy: 0.9838 - val_loss: 8.3004e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0627 - accuracy: 0.9788 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0657 - accuracy: 0.9762 - val_loss: 0.0129 - val_accuracy: 0.9933\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0704 - accuracy: 0.9765 - val_loss: 0.0077 - val_accuracy: 0.9960\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0701 - accuracy: 0.9787 - val_loss: 4.4044e-04 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0550 - accuracy: 0.9820 - val_loss: 7.6047e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0513 - accuracy: 0.9827 - val_loss: 1.3633e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0436 - accuracy: 0.9820 - val_loss: 3.6340e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0434 - accuracy: 0.9857 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0604 - accuracy: 0.9806 - val_loss: 1.9950e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0693 - accuracy: 0.9762 - val_loss: 0.0063 - val_accuracy: 0.9960\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0582 - accuracy: 0.9812 - val_loss: 2.0763e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0525 - accuracy: 0.9817 - val_loss: 1.0346e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0435 - accuracy: 0.9858 - val_loss: 2.5186e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0778 - accuracy: 0.9747 - val_loss: 0.0037 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0585 - accuracy: 0.9799 - val_loss: 1.6882e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0560 - accuracy: 0.9823 - val_loss: 4.8416e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0575 - accuracy: 0.9830 - val_loss: 0.0066 - val_accuracy: 0.9973\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0459 - accuracy: 0.9836 - val_loss: 7.4463e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0524 - accuracy: 0.9821 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0567 - accuracy: 0.9809 - val_loss: 2.0896e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0401 - accuracy: 0.9861 - val_loss: 1.7437e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0455 - accuracy: 0.9850 - val_loss: 3.2685e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0376 - accuracy: 0.9870 - val_loss: 1.5280e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0410 - accuracy: 0.9858 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0388 - accuracy: 0.9864 - val_loss: 1.6233e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0370 - accuracy: 0.9869 - val_loss: 1.2475e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0650 - accuracy: 0.9809 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0527 - accuracy: 0.9824 - val_loss: 4.3010e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0671 - accuracy: 0.9782 - val_loss: 0.0177 - val_accuracy: 0.9946\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0448 - accuracy: 0.9824 - val_loss: 1.6784e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0724 - accuracy: 0.9779 - val_loss: 0.1074 - val_accuracy: 0.9611\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1381 - accuracy: 0.9560 - val_loss: 0.1172 - val_accuracy: 0.9503\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0554 - accuracy: 0.9806 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0502 - accuracy: 0.9832 - val_loss: 7.1272e-04 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0515 - accuracy: 0.9824 - val_loss: 9.2718e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0810 - accuracy: 0.9736 - val_loss: 0.0169 - val_accuracy: 0.9919\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0598 - accuracy: 0.9788 - val_loss: 6.2862e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0426 - accuracy: 0.9839 - val_loss: 2.0800e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0333 - accuracy: 0.9894 - val_loss: 3.8496e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0465 - accuracy: 0.9866 - val_loss: 5.0878e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0685 - accuracy: 0.9779 - val_loss: 2.6082e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0519 - accuracy: 0.9812 - val_loss: 8.3357e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0424 - accuracy: 0.9861 - val_loss: 1.8404e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0332 - accuracy: 0.9899 - val_loss: 1.2057e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0417 - accuracy: 0.9855 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0660 - accuracy: 0.9774 - val_loss: 0.0040 - val_accuracy: 0.9973\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0502 - accuracy: 0.9844 - val_loss: 1.7547e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0485 - accuracy: 0.9845 - val_loss: 1.4041e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0484 - accuracy: 0.9842 - val_loss: 5.9155e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0387 - accuracy: 0.9863 - val_loss: 1.2313e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0455 - accuracy: 0.9854 - val_loss: 5.7357e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0350 - accuracy: 0.9893 - val_loss: 6.3647e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0348 - accuracy: 0.9887 - val_loss: 6.2069e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0434 - accuracy: 0.9850 - val_loss: 4.0193e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0545 - accuracy: 0.9829 - val_loss: 2.4251e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0415 - accuracy: 0.9847 - val_loss: 2.7962e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0411 - accuracy: 0.9866 - val_loss: 2.5693e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0407 - accuracy: 0.9858 - val_loss: 0.0160 - val_accuracy: 0.9933\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0421 - accuracy: 0.9864 - val_loss: 1.1025e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0430 - accuracy: 0.9861 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0471 - accuracy: 0.9823 - val_loss: 0.0074 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0465 - accuracy: 0.9848 - val_loss: 0.0093 - val_accuracy: 0.9946\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0805 - accuracy: 0.9741 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0713 - accuracy: 0.9762 - val_loss: 0.0085 - val_accuracy: 0.9973\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 47ms/step - loss: 0.0563 - accuracy: 0.9797 - val_loss: 9.9546e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0388 - accuracy: 0.9872 - val_loss: 5.2460e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0475 - accuracy: 0.9848 - val_loss: 1.0446e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0454 - accuracy: 0.9854 - val_loss: 1.0501e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0422 - accuracy: 0.9875 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0421 - accuracy: 0.9852 - val_loss: 4.7320e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0445 - accuracy: 0.9851 - val_loss: 2.1321e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0353 - accuracy: 0.9866 - val_loss: 4.7936e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0317 - accuracy: 0.9899 - val_loss: 2.3844e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0402 - accuracy: 0.9864 - val_loss: 1.8084e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0564 - accuracy: 0.9814 - val_loss: 0.0075 - val_accuracy: 0.9987\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0480 - accuracy: 0.9832 - val_loss: 8.3594e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0549 - accuracy: 0.9794 - val_loss: 9.9958e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0475 - accuracy: 0.9839 - val_loss: 5.2382e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0358 - accuracy: 0.9879 - val_loss: 4.1294e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0574 - accuracy: 0.9800 - val_loss: 0.0253 - val_accuracy: 0.9919\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0427 - accuracy: 0.9864 - val_loss: 4.4045e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0343 - accuracy: 0.9881 - val_loss: 3.7271e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0355 - accuracy: 0.9893 - val_loss: 1.8389e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0472 - accuracy: 0.9845 - val_loss: 1.8852e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0450 - accuracy: 0.9854 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0303 - accuracy: 0.9896 - val_loss: 6.3259e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0417 - accuracy: 0.9875 - val_loss: 0.0073 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1474 - accuracy: 0.9638 - val_loss: 0.0382 - val_accuracy: 0.9799\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0479 - accuracy: 0.9848 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0483 - accuracy: 0.9832 - val_loss: 6.9577e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0406 - accuracy: 0.9858 - val_loss: 3.2069e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0323 - accuracy: 0.9899 - val_loss: 7.4168e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0483 - accuracy: 0.9855 - val_loss: 2.5916e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0268 - accuracy: 0.9912 - val_loss: 4.8277e-04 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "CAnc2SJa3o9f",
        "outputId": "e62f29f8-7ae7-461d-bf91-b456bb4b4730"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 7ms/step - loss: 0.0563 - accuracy: 0.9844\n",
            "Accuracy  : 0.9844420552253723\n",
            "F1_Score  : 0.9818678332408366\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7fcxLuwZpkK",
        "outputId": "9d0c2c9d-35d7-404a-f8df-11d871e5e4e2"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "ba6ba495-7a2f-43d1-ed6c-84fa6539be76"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 53ms/step - loss: 1.1359 - accuracy: 0.3885 - val_loss: 1.0661 - val_accuracy: 0.4424\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0719 - accuracy: 0.4248 - val_loss: 1.0484 - val_accuracy: 0.4732\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0687 - accuracy: 0.4221 - val_loss: 1.0538 - val_accuracy: 0.4732\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0667 - accuracy: 0.4352 - val_loss: 1.0427 - val_accuracy: 0.4732\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0590 - accuracy: 0.4386 - val_loss: 1.0441 - val_accuracy: 0.4732\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0653 - accuracy: 0.4422 - val_loss: 1.0378 - val_accuracy: 0.4732\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0536 - accuracy: 0.4496 - val_loss: 1.0452 - val_accuracy: 0.4732\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0595 - accuracy: 0.4359 - val_loss: 1.0375 - val_accuracy: 0.4732\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0596 - accuracy: 0.4352 - val_loss: 1.0345 - val_accuracy: 0.4732\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0532 - accuracy: 0.4339 - val_loss: 1.0398 - val_accuracy: 0.4732\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0502 - accuracy: 0.4384 - val_loss: 1.0363 - val_accuracy: 0.4732\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 1.0610 - accuracy: 0.4335 - val_loss: 1.0309 - val_accuracy: 0.4732\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0516 - accuracy: 0.4403 - val_loss: 1.0340 - val_accuracy: 0.4732\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0532 - accuracy: 0.4344 - val_loss: 1.0368 - val_accuracy: 0.4772\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0482 - accuracy: 0.4468 - val_loss: 1.0377 - val_accuracy: 0.4732\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 1.0501 - accuracy: 0.4371 - val_loss: 1.0297 - val_accuracy: 0.4718\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0562 - accuracy: 0.4361 - val_loss: 1.0299 - val_accuracy: 0.4732\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 1.0512 - accuracy: 0.4461 - val_loss: 1.0267 - val_accuracy: 0.4732\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0491 - accuracy: 0.4356 - val_loss: 1.0283 - val_accuracy: 0.4732\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0479 - accuracy: 0.4429 - val_loss: 1.0261 - val_accuracy: 0.4732\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0447 - accuracy: 0.4428 - val_loss: 1.0225 - val_accuracy: 0.4732\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0406 - accuracy: 0.4480 - val_loss: 1.0245 - val_accuracy: 0.4745\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0495 - accuracy: 0.4431 - val_loss: 1.0240 - val_accuracy: 0.4705\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0440 - accuracy: 0.4382 - val_loss: 1.0236 - val_accuracy: 0.4732\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0392 - accuracy: 0.4348 - val_loss: 1.0280 - val_accuracy: 0.4732\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0342 - accuracy: 0.4452 - val_loss: 1.0146 - val_accuracy: 0.4786\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0459 - accuracy: 0.4384 - val_loss: 1.0240 - val_accuracy: 0.4718\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0486 - accuracy: 0.4335 - val_loss: 1.0238 - val_accuracy: 0.4692\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0437 - accuracy: 0.4342 - val_loss: 1.0135 - val_accuracy: 0.4812\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0373 - accuracy: 0.4481 - val_loss: 1.0135 - val_accuracy: 0.4812\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0375 - accuracy: 0.4495 - val_loss: 1.0367 - val_accuracy: 0.4343\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0400 - accuracy: 0.4474 - val_loss: 1.0333 - val_accuracy: 0.4343\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0368 - accuracy: 0.4452 - val_loss: 1.0352 - val_accuracy: 0.4330\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0346 - accuracy: 0.4461 - val_loss: 1.0406 - val_accuracy: 0.4450\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0349 - accuracy: 0.4419 - val_loss: 1.0302 - val_accuracy: 0.4343\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0362 - accuracy: 0.4447 - val_loss: 1.0233 - val_accuracy: 0.4370\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0367 - accuracy: 0.4450 - val_loss: 1.0393 - val_accuracy: 0.4290\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0337 - accuracy: 0.4469 - val_loss: 1.0367 - val_accuracy: 0.4477\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 1.0275 - accuracy: 0.4405 - val_loss: 1.0184 - val_accuracy: 0.4504\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0368 - accuracy: 0.4499 - val_loss: 1.0256 - val_accuracy: 0.4357\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0273 - accuracy: 0.4495 - val_loss: 1.0219 - val_accuracy: 0.4450\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 1.0277 - accuracy: 0.4458 - val_loss: 1.0292 - val_accuracy: 0.4410\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0291 - accuracy: 0.4453 - val_loss: 1.0351 - val_accuracy: 0.4303\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0290 - accuracy: 0.4446 - val_loss: 1.0232 - val_accuracy: 0.4531\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0211 - accuracy: 0.4432 - val_loss: 1.0192 - val_accuracy: 0.4397\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0247 - accuracy: 0.4450 - val_loss: 1.0337 - val_accuracy: 0.4290\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0234 - accuracy: 0.4459 - val_loss: 1.0139 - val_accuracy: 0.4491\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 1.0236 - accuracy: 0.4477 - val_loss: 1.0095 - val_accuracy: 0.4544\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0154 - accuracy: 0.4468 - val_loss: 1.0187 - val_accuracy: 0.4383\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0141 - accuracy: 0.4443 - val_loss: 1.0214 - val_accuracy: 0.4383\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0134 - accuracy: 0.4469 - val_loss: 1.0351 - val_accuracy: 0.4343\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0144 - accuracy: 0.4435 - val_loss: 1.0048 - val_accuracy: 0.4571\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0101 - accuracy: 0.4508 - val_loss: 0.9964 - val_accuracy: 0.4491\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 1.0058 - accuracy: 0.4469 - val_loss: 1.0005 - val_accuracy: 0.4383\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0073 - accuracy: 0.4435 - val_loss: 1.0116 - val_accuracy: 0.4383\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0054 - accuracy: 0.4483 - val_loss: 0.9994 - val_accuracy: 0.4491\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 1.0035 - accuracy: 0.4477 - val_loss: 1.0044 - val_accuracy: 0.4437\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 48ms/step - loss: 0.9994 - accuracy: 0.4449 - val_loss: 0.9973 - val_accuracy: 0.4437\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0043 - accuracy: 0.4525 - val_loss: 1.0058 - val_accuracy: 0.4424\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9954 - accuracy: 0.4514 - val_loss: 0.9921 - val_accuracy: 0.4477\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9936 - accuracy: 0.4511 - val_loss: 0.9708 - val_accuracy: 0.4598\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9933 - accuracy: 0.4487 - val_loss: 0.9939 - val_accuracy: 0.4598\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9873 - accuracy: 0.4523 - val_loss: 0.9696 - val_accuracy: 0.4611\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9790 - accuracy: 0.4537 - val_loss: 0.9740 - val_accuracy: 0.4598\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9915 - accuracy: 0.4529 - val_loss: 0.9992 - val_accuracy: 0.4625\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9772 - accuracy: 0.4604 - val_loss: 0.9745 - val_accuracy: 0.4745\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9700 - accuracy: 0.4692 - val_loss: 0.9902 - val_accuracy: 0.4517\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9746 - accuracy: 0.4675 - val_loss: 0.9638 - val_accuracy: 0.4732\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9606 - accuracy: 0.4613 - val_loss: 0.9781 - val_accuracy: 0.4879\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9639 - accuracy: 0.4654 - val_loss: 0.9703 - val_accuracy: 0.4826\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9525 - accuracy: 0.4678 - val_loss: 0.9504 - val_accuracy: 0.4786\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9558 - accuracy: 0.4741 - val_loss: 0.9730 - val_accuracy: 0.4786\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9458 - accuracy: 0.4826 - val_loss: 0.9908 - val_accuracy: 0.4772\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9420 - accuracy: 0.4747 - val_loss: 0.9867 - val_accuracy: 0.4584\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9333 - accuracy: 0.4893 - val_loss: 0.9389 - val_accuracy: 0.4987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9230 - accuracy: 0.4969 - val_loss: 0.9517 - val_accuracy: 0.4987\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9246 - accuracy: 0.5112 - val_loss: 0.9622 - val_accuracy: 0.5201\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9187 - accuracy: 0.5097 - val_loss: 0.9293 - val_accuracy: 0.5241\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8995 - accuracy: 0.5228 - val_loss: 0.9276 - val_accuracy: 0.5134\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8981 - accuracy: 0.5283 - val_loss: 0.9264 - val_accuracy: 0.5214\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8916 - accuracy: 0.5389 - val_loss: 0.9148 - val_accuracy: 0.5335\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8768 - accuracy: 0.5477 - val_loss: 0.9034 - val_accuracy: 0.5308\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8635 - accuracy: 0.5607 - val_loss: 0.8964 - val_accuracy: 0.5389\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8562 - accuracy: 0.5621 - val_loss: 0.8919 - val_accuracy: 0.5389\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8529 - accuracy: 0.5706 - val_loss: 0.8917 - val_accuracy: 0.5469\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8261 - accuracy: 0.5806 - val_loss: 0.8822 - val_accuracy: 0.5523\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8185 - accuracy: 0.5882 - val_loss: 0.8677 - val_accuracy: 0.5657\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8075 - accuracy: 0.5945 - val_loss: 0.8548 - val_accuracy: 0.5684\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7903 - accuracy: 0.6094 - val_loss: 0.8199 - val_accuracy: 0.5925\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7687 - accuracy: 0.6308 - val_loss: 0.8052 - val_accuracy: 0.5885\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.8252 - accuracy: 0.5838 - val_loss: 0.6614 - val_accuracy: 0.7145\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7776 - accuracy: 0.6349 - val_loss: 0.6556 - val_accuracy: 0.7225\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7423 - accuracy: 0.6456 - val_loss: 0.6249 - val_accuracy: 0.7386\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7433 - accuracy: 0.6486 - val_loss: 0.5830 - val_accuracy: 0.7534\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7216 - accuracy: 0.6656 - val_loss: 0.5962 - val_accuracy: 0.7413\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6989 - accuracy: 0.6736 - val_loss: 0.6168 - val_accuracy: 0.7145\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7001 - accuracy: 0.6759 - val_loss: 0.5967 - val_accuracy: 0.7399\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6669 - accuracy: 0.6954 - val_loss: 0.5838 - val_accuracy: 0.7265\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6771 - accuracy: 0.6960 - val_loss: 0.6286 - val_accuracy: 0.7105\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6231 - accuracy: 0.7204 - val_loss: 0.5448 - val_accuracy: 0.7520\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6182 - accuracy: 0.7249 - val_loss: 0.5444 - val_accuracy: 0.7574\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6166 - accuracy: 0.7271 - val_loss: 0.4761 - val_accuracy: 0.7962\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5829 - accuracy: 0.7452 - val_loss: 0.4559 - val_accuracy: 0.8056\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5736 - accuracy: 0.7538 - val_loss: 0.5167 - val_accuracy: 0.7895\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5471 - accuracy: 0.7629 - val_loss: 0.4769 - val_accuracy: 0.7895\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5584 - accuracy: 0.7592 - val_loss: 0.4707 - val_accuracy: 0.8123\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5564 - accuracy: 0.7675 - val_loss: 0.4876 - val_accuracy: 0.7560\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5163 - accuracy: 0.7829 - val_loss: 0.4897 - val_accuracy: 0.7936\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4859 - accuracy: 0.7993 - val_loss: 0.4152 - val_accuracy: 0.8177\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4827 - accuracy: 0.7990 - val_loss: 0.4049 - val_accuracy: 0.8284\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4670 - accuracy: 0.8142 - val_loss: 0.4102 - val_accuracy: 0.8338\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4489 - accuracy: 0.8154 - val_loss: 0.3745 - val_accuracy: 0.8499\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4369 - accuracy: 0.8173 - val_loss: 0.3916 - val_accuracy: 0.8271\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4428 - accuracy: 0.8232 - val_loss: 0.3692 - val_accuracy: 0.8566\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4433 - accuracy: 0.8224 - val_loss: 0.4422 - val_accuracy: 0.8284\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3903 - accuracy: 0.8449 - val_loss: 0.3272 - val_accuracy: 0.8686\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3873 - accuracy: 0.8428 - val_loss: 0.3238 - val_accuracy: 0.8700\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3654 - accuracy: 0.8611 - val_loss: 0.2983 - val_accuracy: 0.8753\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3560 - accuracy: 0.8626 - val_loss: 0.3792 - val_accuracy: 0.8378\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3953 - accuracy: 0.8478 - val_loss: 0.3133 - val_accuracy: 0.8820\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4000 - accuracy: 0.8429 - val_loss: 0.1512 - val_accuracy: 0.9531\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3878 - accuracy: 0.8520 - val_loss: 0.1250 - val_accuracy: 0.9745\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3493 - accuracy: 0.8626 - val_loss: 0.1186 - val_accuracy: 0.9651\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3335 - accuracy: 0.8724 - val_loss: 0.1138 - val_accuracy: 0.9665\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3414 - accuracy: 0.8717 - val_loss: 0.1319 - val_accuracy: 0.9718\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3252 - accuracy: 0.8733 - val_loss: 0.1267 - val_accuracy: 0.9692\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3085 - accuracy: 0.8799 - val_loss: 0.1109 - val_accuracy: 0.9638\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3010 - accuracy: 0.8872 - val_loss: 0.0921 - val_accuracy: 0.9678\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3020 - accuracy: 0.8866 - val_loss: 0.1289 - val_accuracy: 0.9625\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2871 - accuracy: 0.8921 - val_loss: 0.0998 - val_accuracy: 0.9705\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2581 - accuracy: 0.9058 - val_loss: 0.1079 - val_accuracy: 0.9678\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2658 - accuracy: 0.9004 - val_loss: 0.1018 - val_accuracy: 0.9705\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3158 - accuracy: 0.8964 - val_loss: 0.1819 - val_accuracy: 0.9182\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3481 - accuracy: 0.8629 - val_loss: 0.1855 - val_accuracy: 0.9464\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2667 - accuracy: 0.8991 - val_loss: 0.1189 - val_accuracy: 0.9692\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2426 - accuracy: 0.9055 - val_loss: 0.0801 - val_accuracy: 0.9786\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2339 - accuracy: 0.9079 - val_loss: 0.0841 - val_accuracy: 0.9732\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2131 - accuracy: 0.9219 - val_loss: 0.0709 - val_accuracy: 0.9812\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2178 - accuracy: 0.9218 - val_loss: 0.0728 - val_accuracy: 0.9786\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2279 - accuracy: 0.9156 - val_loss: 0.0885 - val_accuracy: 0.9651\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2164 - accuracy: 0.9235 - val_loss: 0.0732 - val_accuracy: 0.9786\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2136 - accuracy: 0.9206 - val_loss: 0.0667 - val_accuracy: 0.9786\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1875 - accuracy: 0.9320 - val_loss: 0.0873 - val_accuracy: 0.9665\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2364 - accuracy: 0.9154 - val_loss: 0.0911 - val_accuracy: 0.9678\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2290 - accuracy: 0.9165 - val_loss: 0.1089 - val_accuracy: 0.9651\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1880 - accuracy: 0.9316 - val_loss: 0.0878 - val_accuracy: 0.9705\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1920 - accuracy: 0.9316 - val_loss: 0.0797 - val_accuracy: 0.9718\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2150 - accuracy: 0.9177 - val_loss: 0.0720 - val_accuracy: 0.9745\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1658 - accuracy: 0.9380 - val_loss: 0.0881 - val_accuracy: 0.9678\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1870 - accuracy: 0.9301 - val_loss: 0.0753 - val_accuracy: 0.9745\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2215 - accuracy: 0.9188 - val_loss: 0.0269 - val_accuracy: 0.9987\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1853 - accuracy: 0.9316 - val_loss: 0.0147 - val_accuracy: 0.9987\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1736 - accuracy: 0.9382 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1841 - accuracy: 0.9331 - val_loss: 0.0154 - val_accuracy: 0.9973\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2001 - accuracy: 0.9291 - val_loss: 0.0185 - val_accuracy: 0.9987\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1687 - accuracy: 0.9364 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1688 - accuracy: 0.9416 - val_loss: 0.0164 - val_accuracy: 0.9960\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1678 - accuracy: 0.9379 - val_loss: 0.0210 - val_accuracy: 0.9960\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1479 - accuracy: 0.9462 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1558 - accuracy: 0.9463 - val_loss: 0.0149 - val_accuracy: 0.9946\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1665 - accuracy: 0.9393 - val_loss: 0.0282 - val_accuracy: 0.9920\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1529 - accuracy: 0.9425 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1319 - accuracy: 0.9499 - val_loss: 0.0197 - val_accuracy: 0.9973\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1926 - accuracy: 0.9295 - val_loss: 0.0284 - val_accuracy: 0.9920\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1666 - accuracy: 0.9385 - val_loss: 0.0274 - val_accuracy: 0.9933\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1386 - accuracy: 0.9495 - val_loss: 0.0131 - val_accuracy: 0.9987\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1545 - accuracy: 0.9437 - val_loss: 0.0301 - val_accuracy: 0.9920\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1496 - accuracy: 0.9450 - val_loss: 0.0340 - val_accuracy: 0.9920\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1510 - accuracy: 0.9489 - val_loss: 0.0300 - val_accuracy: 0.9946\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1401 - accuracy: 0.9487 - val_loss: 0.0304 - val_accuracy: 0.9960\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1428 - accuracy: 0.9484 - val_loss: 0.0183 - val_accuracy: 0.9960\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1348 - accuracy: 0.9525 - val_loss: 0.0218 - val_accuracy: 0.9946\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1331 - accuracy: 0.9539 - val_loss: 0.0253 - val_accuracy: 0.9946\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1392 - accuracy: 0.9447 - val_loss: 0.0200 - val_accuracy: 0.9973\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1302 - accuracy: 0.9505 - val_loss: 0.0152 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1528 - accuracy: 0.9468 - val_loss: 0.0713 - val_accuracy: 0.9759\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1225 - accuracy: 0.9534 - val_loss: 0.0391 - val_accuracy: 0.9866\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1363 - accuracy: 0.9517 - val_loss: 0.0291 - val_accuracy: 0.9920\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1155 - accuracy: 0.9618 - val_loss: 0.0154 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1225 - accuracy: 0.9574 - val_loss: 0.0186 - val_accuracy: 0.9960\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.1578 - accuracy: 0.9480 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1327 - accuracy: 0.9516 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1151 - accuracy: 0.9595 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1521 - accuracy: 0.9532 - val_loss: 0.0129 - val_accuracy: 0.9987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1179 - accuracy: 0.9578 - val_loss: 0.0074 - val_accuracy: 0.9987\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1169 - accuracy: 0.9562 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1116 - accuracy: 0.9580 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1219 - accuracy: 0.9583 - val_loss: 0.0087 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1181 - accuracy: 0.9566 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1330 - accuracy: 0.9517 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1085 - accuracy: 0.9607 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1303 - accuracy: 0.9556 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1159 - accuracy: 0.9571 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1257 - accuracy: 0.9550 - val_loss: 0.0093 - val_accuracy: 0.9973\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1220 - accuracy: 0.9590 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1237 - accuracy: 0.9566 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1133 - accuracy: 0.9557 - val_loss: 0.0119 - val_accuracy: 0.9973\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1141 - accuracy: 0.9574 - val_loss: 0.0127 - val_accuracy: 0.9960\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0954 - accuracy: 0.9666 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1166 - accuracy: 0.9587 - val_loss: 0.0168 - val_accuracy: 0.9946\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1166 - accuracy: 0.9602 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1256 - accuracy: 0.9577 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1052 - accuracy: 0.9601 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1144 - accuracy: 0.9589 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1129 - accuracy: 0.9614 - val_loss: 0.0196 - val_accuracy: 0.9973\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1095 - accuracy: 0.9626 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0957 - accuracy: 0.9666 - val_loss: 0.0063 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1386 - accuracy: 0.9529 - val_loss: 0.0467 - val_accuracy: 0.9812\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1075 - accuracy: 0.9629 - val_loss: 0.0284 - val_accuracy: 0.9919\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0967 - accuracy: 0.9642 - val_loss: 0.0142 - val_accuracy: 0.9960\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.1007 - accuracy: 0.9659 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0905 - accuracy: 0.9666 - val_loss: 4.9175e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0778 - accuracy: 0.9726 - val_loss: 5.8750e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1266 - accuracy: 0.9583 - val_loss: 0.0295 - val_accuracy: 0.9879\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1180 - accuracy: 0.9578 - val_loss: 0.0085 - val_accuracy: 0.9987\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0965 - accuracy: 0.9644 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0977 - accuracy: 0.9650 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1056 - accuracy: 0.9650 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0767 - accuracy: 0.9748 - val_loss: 8.8604e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0711 - accuracy: 0.9730 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0781 - accuracy: 0.9735 - val_loss: 6.3342e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0871 - accuracy: 0.9675 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1151 - accuracy: 0.9586 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0886 - accuracy: 0.9678 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0744 - accuracy: 0.9715 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0778 - accuracy: 0.9721 - val_loss: 7.1485e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0861 - accuracy: 0.9693 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1130 - accuracy: 0.9636 - val_loss: 0.0072 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1908 - accuracy: 0.9304 - val_loss: 0.0311 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0856 - accuracy: 0.9703 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0958 - accuracy: 0.9663 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0833 - accuracy: 0.9711 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0806 - accuracy: 0.9708 - val_loss: 0.0048 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1072 - accuracy: 0.9647 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0768 - accuracy: 0.9739 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0743 - accuracy: 0.9756 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0734 - accuracy: 0.9739 - val_loss: 5.8226e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0720 - accuracy: 0.9741 - val_loss: 0.0018 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1097 - accuracy: 0.9671 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1075 - accuracy: 0.9648 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0897 - accuracy: 0.9671 - val_loss: 9.0133e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0833 - accuracy: 0.9696 - val_loss: 8.0324e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0882 - accuracy: 0.9684 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0841 - accuracy: 0.9705 - val_loss: 6.3630e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0729 - accuracy: 0.9754 - val_loss: 4.5486e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0899 - accuracy: 0.9696 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0786 - accuracy: 0.9750 - val_loss: 5.8318e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0711 - accuracy: 0.9760 - val_loss: 2.6254e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0761 - accuracy: 0.9779 - val_loss: 3.0286e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0753 - accuracy: 0.9729 - val_loss: 5.2780e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0737 - accuracy: 0.9745 - val_loss: 4.5294e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1196 - accuracy: 0.9624 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0915 - accuracy: 0.9668 - val_loss: 6.3663e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0755 - accuracy: 0.9709 - val_loss: 6.1958e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0853 - accuracy: 0.9699 - val_loss: 9.9788e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0725 - accuracy: 0.9741 - val_loss: 6.8188e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1028 - accuracy: 0.9638 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1152 - accuracy: 0.9581 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0686 - accuracy: 0.9765 - val_loss: 6.7832e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0693 - accuracy: 0.9754 - val_loss: 4.6891e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0967 - accuracy: 0.9639 - val_loss: 6.6679e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0902 - accuracy: 0.9686 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0814 - accuracy: 0.9733 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0706 - accuracy: 0.9748 - val_loss: 7.3528e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0786 - accuracy: 0.9720 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0589 - accuracy: 0.9781 - val_loss: 4.0033e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0731 - accuracy: 0.9768 - val_loss: 0.0028 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0824 - accuracy: 0.9686 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0774 - accuracy: 0.9735 - val_loss: 0.0079 - val_accuracy: 0.9960\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0795 - accuracy: 0.9711 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0726 - accuracy: 0.9768 - val_loss: 5.6123e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0820 - accuracy: 0.9720 - val_loss: 4.4675e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0764 - accuracy: 0.9741 - val_loss: 7.1435e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0660 - accuracy: 0.9787 - val_loss: 3.8775e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0857 - accuracy: 0.9708 - val_loss: 2.8823e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0714 - accuracy: 0.9748 - val_loss: 6.4968e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0875 - accuracy: 0.9705 - val_loss: 4.3158e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0700 - accuracy: 0.9742 - val_loss: 6.1851e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0672 - accuracy: 0.9778 - val_loss: 1.7812e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0704 - accuracy: 0.9741 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0712 - accuracy: 0.9759 - val_loss: 5.3543e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0774 - accuracy: 0.9739 - val_loss: 8.7076e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0815 - accuracy: 0.9718 - val_loss: 7.9430e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0771 - accuracy: 0.9745 - val_loss: 2.2451e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0698 - accuracy: 0.9754 - val_loss: 2.7296e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0734 - accuracy: 0.9729 - val_loss: 2.7639e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0700 - accuracy: 0.9756 - val_loss: 2.4327e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0902 - accuracy: 0.9718 - val_loss: 6.4608e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0722 - accuracy: 0.9741 - val_loss: 3.3936e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0497 - accuracy: 0.9850 - val_loss: 5.7722e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0747 - accuracy: 0.9753 - val_loss: 3.4256e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0748 - accuracy: 0.9733 - val_loss: 5.7382e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0528 - accuracy: 0.9785 - val_loss: 2.0323e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0655 - accuracy: 0.9757 - val_loss: 3.5846e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0651 - accuracy: 0.9787 - val_loss: 2.8666e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0670 - accuracy: 0.9765 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0687 - accuracy: 0.9774 - val_loss: 5.6268e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0783 - accuracy: 0.9747 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0748 - accuracy: 0.9748 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0632 - accuracy: 0.9787 - val_loss: 7.4136e-04 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "980c6194-f82f-46c6-cc51-bacb558ab3ad"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 7ms/step - loss: 0.0924 - accuracy: 0.9769\n",
            "Accuracy  : 0.9769313335418701\n",
            "F1_Score  : 0.9755333347293488\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}