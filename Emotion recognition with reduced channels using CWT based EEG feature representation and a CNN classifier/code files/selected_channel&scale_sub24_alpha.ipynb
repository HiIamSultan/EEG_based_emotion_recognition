{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub24_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "1a69ec7b-ae4b-48c7-cc56-6cef8bb1d44e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e3\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  #EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "7bb9eaef-f4ce-409c-cd6f-1bf8f1903e2d"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(24,25):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.24\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (2796,) (3029,) (3495,)\n",
            "(9320,) (932,) (3029,) (5359,)\n",
            "(9320,) (1631,) (3495,) (4194,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "0370b576-9e93-409d-e63a-b7c8de875b9d"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "23b3c78c-5b14-406d-ebf4-5dd6647ac4c8"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "341"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "7f1e4719-10f8-45c5-f6af-d088700a50c2"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "524245a4-0263-4777-d7fb-dc451ec1dc55"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 21s 57ms/step - loss: 1.1999 - accuracy: 0.3470 - val_loss: 1.0973 - val_accuracy: 0.3807\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 39ms/step - loss: 1.0975 - accuracy: 0.3727 - val_loss: 1.0953 - val_accuracy: 0.3807\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0963 - accuracy: 0.3779 - val_loss: 1.0955 - val_accuracy: 0.3807\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0953 - accuracy: 0.3653 - val_loss: 1.0935 - val_accuracy: 0.3807\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0946 - accuracy: 0.3821 - val_loss: 1.0944 - val_accuracy: 0.3807\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0965 - accuracy: 0.3659 - val_loss: 1.0936 - val_accuracy: 0.3807\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 39ms/step - loss: 1.0958 - accuracy: 0.3751 - val_loss: 1.0938 - val_accuracy: 0.3807\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0940 - accuracy: 0.3727 - val_loss: 1.0942 - val_accuracy: 0.3807\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0928 - accuracy: 0.3767 - val_loss: 1.0943 - val_accuracy: 0.3807\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0911 - accuracy: 0.3899 - val_loss: 1.0935 - val_accuracy: 0.3807\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0934 - accuracy: 0.3720 - val_loss: 1.0935 - val_accuracy: 0.3807\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0884 - accuracy: 0.3817 - val_loss: 1.0932 - val_accuracy: 0.3807\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0910 - accuracy: 0.3822 - val_loss: 1.0926 - val_accuracy: 0.3807\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0933 - accuracy: 0.3683 - val_loss: 1.1052 - val_accuracy: 0.3807\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0969 - accuracy: 0.3744 - val_loss: 1.0950 - val_accuracy: 0.3807\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0939 - accuracy: 0.3768 - val_loss: 1.0942 - val_accuracy: 0.3807\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0908 - accuracy: 0.3825 - val_loss: 1.0896 - val_accuracy: 0.3807\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0895 - accuracy: 0.3758 - val_loss: 1.0909 - val_accuracy: 0.3807\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0931 - accuracy: 0.3684 - val_loss: 1.0872 - val_accuracy: 0.3807\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0866 - accuracy: 0.3914 - val_loss: 1.0878 - val_accuracy: 0.3928\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0855 - accuracy: 0.3949 - val_loss: 1.0785 - val_accuracy: 0.4196\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0831 - accuracy: 0.3898 - val_loss: 1.0879 - val_accuracy: 0.3887\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0814 - accuracy: 0.4034 - val_loss: 1.0858 - val_accuracy: 0.4155\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0840 - accuracy: 0.3968 - val_loss: 1.0719 - val_accuracy: 0.4196\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0772 - accuracy: 0.4039 - val_loss: 1.0738 - val_accuracy: 0.4223\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0790 - accuracy: 0.4038 - val_loss: 1.0740 - val_accuracy: 0.4142\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0780 - accuracy: 0.4069 - val_loss: 1.0736 - val_accuracy: 0.4102\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0768 - accuracy: 0.4007 - val_loss: 1.0694 - val_accuracy: 0.4182\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0727 - accuracy: 0.4142 - val_loss: 1.0855 - val_accuracy: 0.4129\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0789 - accuracy: 0.4139 - val_loss: 1.0744 - val_accuracy: 0.4410\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0738 - accuracy: 0.4113 - val_loss: 1.0723 - val_accuracy: 0.4102\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0705 - accuracy: 0.4194 - val_loss: 1.0660 - val_accuracy: 0.4182\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0738 - accuracy: 0.4128 - val_loss: 1.0763 - val_accuracy: 0.4021\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0704 - accuracy: 0.4146 - val_loss: 1.0757 - val_accuracy: 0.4021\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0738 - accuracy: 0.4110 - val_loss: 1.0719 - val_accuracy: 0.4169\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0725 - accuracy: 0.4159 - val_loss: 1.0638 - val_accuracy: 0.4236\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0704 - accuracy: 0.4165 - val_loss: 1.0707 - val_accuracy: 0.4075\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0680 - accuracy: 0.4201 - val_loss: 1.0684 - val_accuracy: 0.4196\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0726 - accuracy: 0.4137 - val_loss: 1.0692 - val_accuracy: 0.4088\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0686 - accuracy: 0.4156 - val_loss: 1.0580 - val_accuracy: 0.4316\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0660 - accuracy: 0.4161 - val_loss: 1.0709 - val_accuracy: 0.4062\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0648 - accuracy: 0.4195 - val_loss: 1.0613 - val_accuracy: 0.4343\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0617 - accuracy: 0.4198 - val_loss: 1.0584 - val_accuracy: 0.4370\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0637 - accuracy: 0.4200 - val_loss: 1.0616 - val_accuracy: 0.4383\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0672 - accuracy: 0.4182 - val_loss: 1.0628 - val_accuracy: 0.4263\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0562 - accuracy: 0.4249 - val_loss: 1.0615 - val_accuracy: 0.4397\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0599 - accuracy: 0.4265 - val_loss: 1.0749 - val_accuracy: 0.3981\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0636 - accuracy: 0.4234 - val_loss: 1.0617 - val_accuracy: 0.4330\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0630 - accuracy: 0.4258 - val_loss: 1.0773 - val_accuracy: 0.4035\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0581 - accuracy: 0.4270 - val_loss: 1.0637 - val_accuracy: 0.4209\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0566 - accuracy: 0.4282 - val_loss: 1.0581 - val_accuracy: 0.4410\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0567 - accuracy: 0.4320 - val_loss: 1.0598 - val_accuracy: 0.4357\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0549 - accuracy: 0.4297 - val_loss: 1.0664 - val_accuracy: 0.4410\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0577 - accuracy: 0.4352 - val_loss: 1.0537 - val_accuracy: 0.4625\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0527 - accuracy: 0.4332 - val_loss: 1.0563 - val_accuracy: 0.4316\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0518 - accuracy: 0.4329 - val_loss: 1.0526 - val_accuracy: 0.4303\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0544 - accuracy: 0.4356 - val_loss: 1.0518 - val_accuracy: 0.4437\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0523 - accuracy: 0.4341 - val_loss: 1.0517 - val_accuracy: 0.4437\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0472 - accuracy: 0.4390 - val_loss: 1.0621 - val_accuracy: 0.4410\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0461 - accuracy: 0.4411 - val_loss: 1.0602 - val_accuracy: 0.4424\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0485 - accuracy: 0.4428 - val_loss: 1.0293 - val_accuracy: 0.4745\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0482 - accuracy: 0.4386 - val_loss: 1.0274 - val_accuracy: 0.4692\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0449 - accuracy: 0.4401 - val_loss: 1.0363 - val_accuracy: 0.4343\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0453 - accuracy: 0.4416 - val_loss: 1.0229 - val_accuracy: 0.4705\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0346 - accuracy: 0.4504 - val_loss: 1.0326 - val_accuracy: 0.4544\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0365 - accuracy: 0.4490 - val_loss: 1.0451 - val_accuracy: 0.4424\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0323 - accuracy: 0.4520 - val_loss: 1.0493 - val_accuracy: 0.4491\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0329 - accuracy: 0.4526 - val_loss: 1.0366 - val_accuracy: 0.4611\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0280 - accuracy: 0.4541 - val_loss: 1.0304 - val_accuracy: 0.4571\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0320 - accuracy: 0.4520 - val_loss: 1.0311 - val_accuracy: 0.4531\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0280 - accuracy: 0.4545 - val_loss: 1.0220 - val_accuracy: 0.4772\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0280 - accuracy: 0.4559 - val_loss: 1.0404 - val_accuracy: 0.4383\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0270 - accuracy: 0.4547 - val_loss: 1.0227 - val_accuracy: 0.4571\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0191 - accuracy: 0.4604 - val_loss: 1.0172 - val_accuracy: 0.4732\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0146 - accuracy: 0.4633 - val_loss: 1.0089 - val_accuracy: 0.4772\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0152 - accuracy: 0.4687 - val_loss: 1.0012 - val_accuracy: 0.4866\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0130 - accuracy: 0.4657 - val_loss: 1.0036 - val_accuracy: 0.4933\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0160 - accuracy: 0.4668 - val_loss: 1.0156 - val_accuracy: 0.4558\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9998 - accuracy: 0.4800 - val_loss: 1.0015 - val_accuracy: 0.4987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0065 - accuracy: 0.4706 - val_loss: 1.0049 - val_accuracy: 0.4906\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0023 - accuracy: 0.4714 - val_loss: 1.0037 - val_accuracy: 0.4799\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0010 - accuracy: 0.4835 - val_loss: 0.9995 - val_accuracy: 0.4745\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0001 - accuracy: 0.4797 - val_loss: 1.0112 - val_accuracy: 0.4665\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0001 - accuracy: 0.4744 - val_loss: 0.9861 - val_accuracy: 0.4893\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9932 - accuracy: 0.4836 - val_loss: 1.0026 - val_accuracy: 0.4799\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9871 - accuracy: 0.4928 - val_loss: 0.9799 - val_accuracy: 0.4786\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9886 - accuracy: 0.4891 - val_loss: 0.9934 - val_accuracy: 0.4772\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9696 - accuracy: 0.4948 - val_loss: 0.9699 - val_accuracy: 0.5121\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9753 - accuracy: 0.4961 - val_loss: 0.9732 - val_accuracy: 0.5040\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9641 - accuracy: 0.5037 - val_loss: 0.9948 - val_accuracy: 0.5054\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9682 - accuracy: 0.4988 - val_loss: 0.9168 - val_accuracy: 0.5483\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9678 - accuracy: 0.5072 - val_loss: 0.9245 - val_accuracy: 0.5228\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9532 - accuracy: 0.5082 - val_loss: 0.9429 - val_accuracy: 0.5228\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9536 - accuracy: 0.5142 - val_loss: 0.9239 - val_accuracy: 0.5335\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9389 - accuracy: 0.5206 - val_loss: 0.9225 - val_accuracy: 0.5429\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9554 - accuracy: 0.5083 - val_loss: 0.9233 - val_accuracy: 0.5214\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9411 - accuracy: 0.5213 - val_loss: 0.9275 - val_accuracy: 0.5282\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9291 - accuracy: 0.5282 - val_loss: 0.9055 - val_accuracy: 0.5483\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9333 - accuracy: 0.5311 - val_loss: 0.8939 - val_accuracy: 0.5483\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9147 - accuracy: 0.5392 - val_loss: 0.8716 - val_accuracy: 0.5536\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9136 - accuracy: 0.5426 - val_loss: 0.8874 - val_accuracy: 0.5483\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9004 - accuracy: 0.5486 - val_loss: 0.9199 - val_accuracy: 0.5308\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8988 - accuracy: 0.5528 - val_loss: 0.8535 - val_accuracy: 0.5657\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8895 - accuracy: 0.5611 - val_loss: 0.9342 - val_accuracy: 0.5362\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8694 - accuracy: 0.5636 - val_loss: 0.8446 - val_accuracy: 0.5885\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8707 - accuracy: 0.5675 - val_loss: 0.8401 - val_accuracy: 0.5845\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8594 - accuracy: 0.5802 - val_loss: 0.8527 - val_accuracy: 0.5697\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8683 - accuracy: 0.5706 - val_loss: 0.8328 - val_accuracy: 0.5751\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8552 - accuracy: 0.5849 - val_loss: 0.8345 - val_accuracy: 0.5871\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8397 - accuracy: 0.5908 - val_loss: 0.8392 - val_accuracy: 0.5992\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8333 - accuracy: 0.5917 - val_loss: 0.8222 - val_accuracy: 0.5804\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8061 - accuracy: 0.6145 - val_loss: 0.8040 - val_accuracy: 0.6059\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8128 - accuracy: 0.6097 - val_loss: 0.8086 - val_accuracy: 0.5938\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7727 - accuracy: 0.6289 - val_loss: 0.8359 - val_accuracy: 0.5764\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7893 - accuracy: 0.6218 - val_loss: 0.7676 - val_accuracy: 0.6515\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7781 - accuracy: 0.6326 - val_loss: 0.7900 - val_accuracy: 0.6153\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7590 - accuracy: 0.6449 - val_loss: 0.7706 - val_accuracy: 0.6367\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7403 - accuracy: 0.6559 - val_loss: 0.7625 - val_accuracy: 0.6448\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7381 - accuracy: 0.6584 - val_loss: 0.7969 - val_accuracy: 0.6139\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.7276 - accuracy: 0.6605 - val_loss: 0.7637 - val_accuracy: 0.6408\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7309 - accuracy: 0.6633 - val_loss: 0.6113 - val_accuracy: 0.7386\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7177 - accuracy: 0.6694 - val_loss: 0.5911 - val_accuracy: 0.7373\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.7050 - accuracy: 0.6765 - val_loss: 0.5746 - val_accuracy: 0.7507\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6984 - accuracy: 0.6806 - val_loss: 0.6205 - val_accuracy: 0.7480\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6796 - accuracy: 0.6957 - val_loss: 0.5676 - val_accuracy: 0.7534\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6567 - accuracy: 0.7049 - val_loss: 0.5690 - val_accuracy: 0.7560\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.6560 - accuracy: 0.7140 - val_loss: 0.5559 - val_accuracy: 0.7493\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6452 - accuracy: 0.7094 - val_loss: 0.5525 - val_accuracy: 0.7721\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6118 - accuracy: 0.7359 - val_loss: 0.5342 - val_accuracy: 0.7761\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6073 - accuracy: 0.7371 - val_loss: 0.5542 - val_accuracy: 0.7466\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5827 - accuracy: 0.7425 - val_loss: 0.5180 - val_accuracy: 0.7828\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5781 - accuracy: 0.7510 - val_loss: 0.5108 - val_accuracy: 0.7748\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5619 - accuracy: 0.7560 - val_loss: 0.4963 - val_accuracy: 0.7922\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5459 - accuracy: 0.7630 - val_loss: 0.5263 - val_accuracy: 0.7614\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5430 - accuracy: 0.7756 - val_loss: 0.4748 - val_accuracy: 0.8016\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4990 - accuracy: 0.7899 - val_loss: 0.4809 - val_accuracy: 0.7962\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4838 - accuracy: 0.8027 - val_loss: 0.4313 - val_accuracy: 0.8204\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4767 - accuracy: 0.8004 - val_loss: 0.4211 - val_accuracy: 0.8204\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4766 - accuracy: 0.7984 - val_loss: 0.4624 - val_accuracy: 0.8070\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4632 - accuracy: 0.8067 - val_loss: 0.4091 - val_accuracy: 0.8378\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4411 - accuracy: 0.8171 - val_loss: 0.4199 - val_accuracy: 0.8190\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4420 - accuracy: 0.8185 - val_loss: 0.4034 - val_accuracy: 0.8244\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4266 - accuracy: 0.8291 - val_loss: 0.4245 - val_accuracy: 0.8298\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4098 - accuracy: 0.8361 - val_loss: 0.4353 - val_accuracy: 0.8311\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3908 - accuracy: 0.8489 - val_loss: 0.3847 - val_accuracy: 0.8391\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3984 - accuracy: 0.8425 - val_loss: 0.3361 - val_accuracy: 0.8780\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3729 - accuracy: 0.8586 - val_loss: 0.3566 - val_accuracy: 0.8592\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3582 - accuracy: 0.8639 - val_loss: 0.3161 - val_accuracy: 0.8700\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3414 - accuracy: 0.8696 - val_loss: 0.4607 - val_accuracy: 0.8244\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3283 - accuracy: 0.8782 - val_loss: 0.3089 - val_accuracy: 0.8874\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3306 - accuracy: 0.8757 - val_loss: 0.1232 - val_accuracy: 0.9517\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3419 - accuracy: 0.8757 - val_loss: 0.1167 - val_accuracy: 0.9598\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3196 - accuracy: 0.8776 - val_loss: 0.1527 - val_accuracy: 0.9397\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3090 - accuracy: 0.8839 - val_loss: 0.0929 - val_accuracy: 0.9678\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2804 - accuracy: 0.9009 - val_loss: 0.1097 - val_accuracy: 0.9638\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2871 - accuracy: 0.8948 - val_loss: 0.1078 - val_accuracy: 0.9611\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2700 - accuracy: 0.9049 - val_loss: 0.0996 - val_accuracy: 0.9665\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2952 - accuracy: 0.8925 - val_loss: 0.0900 - val_accuracy: 0.9732\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2554 - accuracy: 0.9098 - val_loss: 0.0914 - val_accuracy: 0.9678\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2683 - accuracy: 0.9025 - val_loss: 0.0837 - val_accuracy: 0.9759\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2560 - accuracy: 0.9110 - val_loss: 0.1163 - val_accuracy: 0.9544\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2461 - accuracy: 0.9095 - val_loss: 0.0838 - val_accuracy: 0.9718\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2511 - accuracy: 0.9140 - val_loss: 0.0843 - val_accuracy: 0.9718\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2157 - accuracy: 0.9237 - val_loss: 0.0739 - val_accuracy: 0.9745\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2184 - accuracy: 0.9250 - val_loss: 0.0698 - val_accuracy: 0.9772\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1965 - accuracy: 0.9319 - val_loss: 0.0817 - val_accuracy: 0.9718\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2004 - accuracy: 0.9355 - val_loss: 0.0612 - val_accuracy: 0.9786\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1875 - accuracy: 0.9364 - val_loss: 0.0698 - val_accuracy: 0.9745\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1903 - accuracy: 0.9332 - val_loss: 0.0730 - val_accuracy: 0.9732\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1822 - accuracy: 0.9350 - val_loss: 0.0638 - val_accuracy: 0.9786\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1716 - accuracy: 0.9398 - val_loss: 0.0621 - val_accuracy: 0.9799\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1506 - accuracy: 0.9466 - val_loss: 0.0723 - val_accuracy: 0.9759\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1703 - accuracy: 0.9399 - val_loss: 0.0570 - val_accuracy: 0.9826\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1658 - accuracy: 0.9466 - val_loss: 0.0617 - val_accuracy: 0.9799\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1659 - accuracy: 0.9437 - val_loss: 0.0521 - val_accuracy: 0.9826\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1630 - accuracy: 0.9432 - val_loss: 0.0943 - val_accuracy: 0.9665\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1486 - accuracy: 0.9490 - val_loss: 0.0440 - val_accuracy: 0.9866\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1603 - accuracy: 0.9472 - val_loss: 0.0525 - val_accuracy: 0.9799\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1366 - accuracy: 0.9517 - val_loss: 0.0707 - val_accuracy: 0.9745\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1428 - accuracy: 0.9523 - val_loss: 0.0524 - val_accuracy: 0.9812\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 48ms/step - loss: 0.1482 - accuracy: 0.9511 - val_loss: 0.0138 - val_accuracy: 0.9987\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1735 - accuracy: 0.9437 - val_loss: 0.0178 - val_accuracy: 0.9987\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1414 - accuracy: 0.9501 - val_loss: 0.0078 - val_accuracy: 0.9987\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1408 - accuracy: 0.9538 - val_loss: 0.0116 - val_accuracy: 0.9973\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1309 - accuracy: 0.9559 - val_loss: 0.0133 - val_accuracy: 0.9960\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1412 - accuracy: 0.9543 - val_loss: 0.0129 - val_accuracy: 0.9973\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1382 - accuracy: 0.9562 - val_loss: 0.0085 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1293 - accuracy: 0.9568 - val_loss: 0.0080 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1367 - accuracy: 0.9540 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1232 - accuracy: 0.9578 - val_loss: 0.0081 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1145 - accuracy: 0.9633 - val_loss: 0.0129 - val_accuracy: 0.9960\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1125 - accuracy: 0.9617 - val_loss: 0.0109 - val_accuracy: 0.9973\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1270 - accuracy: 0.9593 - val_loss: 0.0144 - val_accuracy: 0.9973\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1016 - accuracy: 0.9678 - val_loss: 0.0078 - val_accuracy: 0.9973\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1122 - accuracy: 0.9630 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0928 - accuracy: 0.9674 - val_loss: 0.0090 - val_accuracy: 0.9973\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1073 - accuracy: 0.9648 - val_loss: 0.0091 - val_accuracy: 0.9946\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0977 - accuracy: 0.9684 - val_loss: 0.0123 - val_accuracy: 0.9960\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1070 - accuracy: 0.9626 - val_loss: 0.0118 - val_accuracy: 0.9946\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1013 - accuracy: 0.9672 - val_loss: 0.0104 - val_accuracy: 0.9973\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0935 - accuracy: 0.9705 - val_loss: 0.0154 - val_accuracy: 0.9946\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.1082 - accuracy: 0.9650 - val_loss: 0.0116 - val_accuracy: 0.9960\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1020 - accuracy: 0.9665 - val_loss: 0.0067 - val_accuracy: 0.9973\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0921 - accuracy: 0.9720 - val_loss: 0.0059 - val_accuracy: 0.9973\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1008 - accuracy: 0.9675 - val_loss: 0.0135 - val_accuracy: 0.9933\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0859 - accuracy: 0.9726 - val_loss: 0.0156 - val_accuracy: 0.9919\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1112 - accuracy: 0.9622 - val_loss: 0.0170 - val_accuracy: 0.9946\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0932 - accuracy: 0.9689 - val_loss: 0.0077 - val_accuracy: 0.9973\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0799 - accuracy: 0.9738 - val_loss: 0.0099 - val_accuracy: 0.9946\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0846 - accuracy: 0.9720 - val_loss: 0.0091 - val_accuracy: 0.9960\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1045 - accuracy: 0.9674 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1049 - accuracy: 0.9636 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0891 - accuracy: 0.9692 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0860 - accuracy: 0.9715 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0868 - accuracy: 0.9735 - val_loss: 0.0042 - val_accuracy: 0.9987\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0897 - accuracy: 0.9692 - val_loss: 0.0030 - val_accuracy: 0.9987\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1020 - accuracy: 0.9684 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0859 - accuracy: 0.9705 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0833 - accuracy: 0.9742 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0786 - accuracy: 0.9733 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0746 - accuracy: 0.9771 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0745 - accuracy: 0.9753 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0751 - accuracy: 0.9774 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0753 - accuracy: 0.9748 - val_loss: 0.0034 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0867 - accuracy: 0.9732 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0834 - accuracy: 0.9705 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0782 - accuracy: 0.9765 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0599 - accuracy: 0.9832 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0752 - accuracy: 0.9759 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0566 - accuracy: 0.9800 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0779 - accuracy: 0.9742 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0689 - accuracy: 0.9793 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0646 - accuracy: 0.9806 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0636 - accuracy: 0.9779 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0557 - accuracy: 0.9826 - val_loss: 0.0084 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0797 - accuracy: 0.9753 - val_loss: 0.0071 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0610 - accuracy: 0.9799 - val_loss: 0.0061 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0546 - accuracy: 0.9839 - val_loss: 0.0072 - val_accuracy: 0.9973\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0527 - accuracy: 0.9806 - val_loss: 0.0078 - val_accuracy: 0.9960\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0643 - accuracy: 0.9772 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0734 - accuracy: 0.9753 - val_loss: 2.2355e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0815 - accuracy: 0.9721 - val_loss: 2.3742e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0654 - accuracy: 0.9784 - val_loss: 5.9889e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0664 - accuracy: 0.9796 - val_loss: 4.8727e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0675 - accuracy: 0.9776 - val_loss: 9.7593e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0702 - accuracy: 0.9754 - val_loss: 3.0020e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0601 - accuracy: 0.9811 - val_loss: 4.2606e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0609 - accuracy: 0.9791 - val_loss: 2.5669e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0574 - accuracy: 0.9803 - val_loss: 3.6019e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0688 - accuracy: 0.9791 - val_loss: 9.7650e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0622 - accuracy: 0.9818 - val_loss: 3.8967e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0613 - accuracy: 0.9788 - val_loss: 2.8934e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0543 - accuracy: 0.9815 - val_loss: 3.1468e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0620 - accuracy: 0.9785 - val_loss: 0.0051 - val_accuracy: 0.9973\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0674 - accuracy: 0.9785 - val_loss: 2.8945e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0509 - accuracy: 0.9818 - val_loss: 5.2984e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0569 - accuracy: 0.9806 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0741 - accuracy: 0.9766 - val_loss: 7.4410e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0609 - accuracy: 0.9799 - val_loss: 4.7379e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0563 - accuracy: 0.9817 - val_loss: 2.5977e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0551 - accuracy: 0.9830 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0462 - accuracy: 0.9855 - val_loss: 3.0764e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0462 - accuracy: 0.9854 - val_loss: 9.1068e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0505 - accuracy: 0.9839 - val_loss: 0.0037 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0588 - accuracy: 0.9823 - val_loss: 4.9499e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0491 - accuracy: 0.9851 - val_loss: 2.9712e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0464 - accuracy: 0.9869 - val_loss: 3.4711e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0494 - accuracy: 0.9826 - val_loss: 8.3656e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0450 - accuracy: 0.9864 - val_loss: 6.8892e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0592 - accuracy: 0.9817 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0616 - accuracy: 0.9791 - val_loss: 7.2563e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0495 - accuracy: 0.9852 - val_loss: 5.8490e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0688 - accuracy: 0.9793 - val_loss: 3.8025e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0621 - accuracy: 0.9811 - val_loss: 2.0295e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0626 - accuracy: 0.9803 - val_loss: 4.6086e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0539 - accuracy: 0.9841 - val_loss: 1.6881e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0397 - accuracy: 0.9869 - val_loss: 7.9250e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0403 - accuracy: 0.9885 - val_loss: 1.0291e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0535 - accuracy: 0.9830 - val_loss: 5.2582e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0592 - accuracy: 0.9818 - val_loss: 3.0412e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0375 - accuracy: 0.9878 - val_loss: 1.3506e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0510 - accuracy: 0.9835 - val_loss: 3.5321e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0542 - accuracy: 0.9857 - val_loss: 2.2181e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0443 - accuracy: 0.9870 - val_loss: 5.9355e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0628 - accuracy: 0.9794 - val_loss: 4.4822e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0550 - accuracy: 0.9823 - val_loss: 2.5417e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0391 - accuracy: 0.9881 - val_loss: 3.3146e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0394 - accuracy: 0.9897 - val_loss: 4.9548e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0487 - accuracy: 0.9838 - val_loss: 1.4221e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0507 - accuracy: 0.9848 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0566 - accuracy: 0.9811 - val_loss: 2.6242e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0446 - accuracy: 0.9881 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0503 - accuracy: 0.9830 - val_loss: 0.0062 - val_accuracy: 0.9973\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0499 - accuracy: 0.9841 - val_loss: 0.0050 - val_accuracy: 0.9973\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0561 - accuracy: 0.9817 - val_loss: 2.1517e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0357 - accuracy: 0.9891 - val_loss: 4.2895e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0576 - accuracy: 0.9826 - val_loss: 6.7943e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0495 - accuracy: 0.9861 - val_loss: 9.5322e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0472 - accuracy: 0.9850 - val_loss: 2.3698e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0586 - accuracy: 0.9836 - val_loss: 2.9409e-04 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "CAnc2SJa3o9f",
        "outputId": "43a80104-66e9-4e97-813b-3d75cedb023c"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 8ms/step - loss: 0.0709 - accuracy: 0.9759\n",
            "Accuracy  : 0.9758583903312683\n",
            "F1_Score  : 0.9755340791548869\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAAKOCAYAAAAS8uXWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZhcVZk/8O9JQpAtCSDpAAmIBIddQUXUEUKQVQaIgOI6rowLCqgIiKAyimwCOsooqCPjKAqyk7CJ7LIKDqtLQIVE6fhjjwSSdO7vj25COpBFnM49SX0+89TzdFWdunUuXmpevu8995amaQIAQD0GtT0BAAD6U6ABAFRGgQYAUBkFGgBAZRRoAACVGdL2BBZkha0+Y3kprXvk+hPangIkSeZYcU8lVhpaShvfu8IW+7f2L8GM27+5xPdZggYAUBkFGgBAZaptcQIAzFU6K1PqrL0FAFgKKNAAACqjxQkA1K+dxaOtkaABAFRGggYA1M8iAQAA2iRBAwDq5xw0AADapEADAKiMFicAUD+LBAAAaJMEDQCon0UCAAC0SYEGAFAZLU4AoH4WCQAA0CYJGgBQP4sEAABokwQNAKifc9AAAGiTAg0AoDJanABA/SwSAACgTRI0AKB+FgkAANAmCRoAUD/noAEA0CYFGgBAZbQ4AYD6WSQAAECbJGgAQP0kaAAAtEmBBgBQGS1OAKB+g1wHDQCAFknQAID6WSQAAECbJGgAQP3cixMAgDYp0AAAKqPFCQDUzyIBAADaJEEDAOpnkQAAAG1SoAEAVEaLEwCon0UCAAC0SYIGANTPIgEAANokQQMA6uccNAAA2qRAAwCojBYnAFA/iwQAAGiTBA0AqJ9FAgAAtEmCBgDUzzloAAC0SYEGAFAZLU4AoH4WCQAA0CYJGgBQPwkaAABtUqABAFRGixMAqJ/roAEA0CYJGgBQP4sEAABokwQNAKifc9AAAGiTAg0AoDJanABA/SwSAACgTRI0AKB+FgkAANAmCRoAUL0iQQMAoE0KNACAymhxAgDV0+IEAKBVEjQAoH6dFaBJ0AAAaqNAAwCojBYnAFA9iwQAAGiVBA0AqJ4EDQCAVknQAIDqSdAAAGiVAg0AoDJanABA9bQ4AQBolQQNAKhfZwVoEjQAgNpI0JZSO2z9Tznh03tk8KBB+cH5N+WE/76y3/vrjFo13z7ibXnpiJXy6BMz8oEv/DhTpz2ebV69fo47aPe54/5p3ZF57+f/JxdeffeS3gWWUtdfd02OO+YrmdMzJxP22icf+NB+/d6fOXNmPn/YZ3PvPXdn+IgROfaEk7L22qPz2GOP5jMHfTJ333VXdt9zQg47/MgkyYwZM3Lwpw7IlCkPZNCgwdl23HY54KDPtLFrLGWuv+7anHDsV9LTMycT3rp33v8Cx+IRnzsk995zd0aMGJFjjj8xa609Ojf+8vp84+SvZfasWRmy3HI58NOfzVav2zozZszIIZ8+MFMefCCDBg/ONttul08e9OmW9o75OQeN6g0aVHLyZydkjwO+my3efnz22WmLbLheV78xXz1gt/xo0q+y1btOzNHfuzxHfWzXJMk1v7ovW7/7pGz97pOyy8e+naeenpWf3/i7NnaDpVBPT0+++uWj8q3//G7OuWBiLpl0Ue67b3K/Meeec1aGDRuWCy++PO9+z/vy9RNPSJIsP3T5fPwTB+RTn/ns87b7r+//QM678JL89Gfn5te335brrr16iewPS6+enp4c+5Wj8h+nnJazz78ol1w8MffPdyyed87PMmzYsFww6bK86z3/mq+f9LUkyYhVV83Xv/mfOfPcC3PUV47JEZ977ph8z/ven3MuvDhnnHVOfv3r23L9tdcs0f2CZw1YgVZK2bCUckgp5Rt9j0NKKRsN1Pd1ktdusk7um/Jw/vjnRzJrdk/OuuzX2W2bTfqN2XC9rlx9y++TJFffOvl57yfJhPGb57IbfpMZz8xaIvNm6XfXnXdkzDrrZvSYMVluuaHZaZe35KpfXNFvzFW/+EX+ZY8JSZI377hTbr7phjRNkxVWXDFbbPmaDF1++X7jV1hhhbx2q62TJMstNzQbbrRxuru7l8wOsdS66847MnqddeY5FnfNVVfOdyxeeUV2233PJMn2O+yUW/qOxQ032jhrjOz9j9r1x26QZ55+JjNnznzesbjRRhunu/uhJbtj0GdACrRSyiFJfpLeU/pu7nuUJGeUUg4diO/sJGutMTxTuh+b+3zqtMey9hrD+4258/d/zh7bbZYk2WPcphm28kuy2vAV+43ZZ8ctcuZltw/8hFlmTJvWnVGjRs193tXVlWnTul9gzJpJkiFDhmTllVfJY489uljbf+KJJ3LN1Vfmda97/f/dpFkm/XWe4yxJRnaNyrT5Cvu/Tpv2AsfiY/3GXHH5pdlwo40zdOjQfq8/+cQTueaqK7OVY7EapZTWHm0YqHPQPphkk6Zp+kUzpZQTk9yd5JgX+lApZb8k+yXJkHV3yJCRmw/Q9JZ9h339opx08IS8e7fX5vrb78/U7sfS0zNn7vujVl8lm6w/Kpff8NsWZwnPmT17dg777Kfyjne9J6PHjGl7OnSA+yb/Pt846Wv51qnf6/d677H46ezrWKRFA1WgzUmyVpI/zff6mn3vvaCmaU5NcmqSrLDVZ5oBmttS789/fTyju0bMfb72yBGZ+tfH+435y/97IvsecnqSZKUVhmbP7TbL49Ofnvv+Xm9+ZS646q7M7lng/xzwPCNHduWhh55r+XR3d2fkyK4XGPOXdI0aldmzZ2f69CczYsSqi9z2v3/xiKyzzsvy7ve87/962iyD1ug7zp41rfuhjOzqmm/MyBc4Fnt/O7sfeiifPnD/HHX0sRkzZp1+n/vyl47MOuuum3e9518HfkdYbBYJ/N84MMkVpZSLSymn9j0uSXJFkgMG6Ds7xq33PJixY16adddaLcsNGZx9dnxVJl7bfxXm6sNXnHswH/y+8Tn9wlv6vf827U1ehE023SwPPPDHTJ3yYGbNmplLL56Ybbcb32/MttuNz4Xnn5sk+flll+a1r9t6kT+s3/zGSZk+fXoOPvRzAzZ3li2bbLpZHvzTnzJ1ypS+Y3FSth0337E4bnwuuuC8JL2tzNdu1XssPvnEE/nkx/8tnzjw03nVFlv2+8y3vnFypk9/Mp85xLFIu0rTDExQVUoZlGSrJGv3vTQ1yS1N0/QszuclaAu30xs2zPGf2iODB5WcfuEtOe6/rsgR++2U2+59MBOvvScTxm+eoz62S5ok191+fw487pzMnNX7j36dNVfNlaftn7H/8uUM1P/+y4pHrj+h7SlU59prrs7xxx6dOT092WPCXvnwv300p3zz69l4k00zbrvt88wzz+Twww7Ob++9N8OGD8+xx580t020y47j87fp0zNr1qysMmyV/Oep38/KK62cnd68bdZb7+VZru88oH3f8e68de992tzN6szx7+rzXHfN1TnhuKMzp2dOdp+wVz6030fyn9/8RjbeZNNsu934PPPMMznisM/mN7+5N8OHD89Xjzsxo8eMyXe/85/5/vdOzTrrrDt3W6d853uZNWtWdtlhXF623svnnpP29ne8KxP2cizOa6Wh7URZq73nx639S/DID9+5xPd5wAq0f5QCjRoo0KiFAo1atFWgrf7eM1r7l+Dh/37HEt9n10EDAKiMOwkAAPXrrDUCEjQAgNpI0ACA6rnMBgAArVKgAQBURoEGAFSv5ntxllJ2LqX8tpQy+YXuOV5KWaeUcmUp5fZSyh2llF0XtU0FGgDAi1RKGZzkW0l2SbJxkneUUjaeb9jnk5zZNM0WSfZNcsqitmuRAABQvYoXCWyVZHLTNPcnSSnlJ0n2SHLPPGOaJMP6/h6e5M+L2qgEDQBgIUop+5VSbp3nsd88b6+d5MF5nk/Jc7e5fNYXk7y7lDIlyaQkn1jUd0rQAAAWommaU5Oc+g9s4h1JftA0zddKKa9P8sNSyqZN08xZ0AcUaABA/artcGZqkjHzPB/d99q8Pphk5yRpmuaGUspLkrw0ybQFbVSLEwDgxbslyQallPVKKUPTuwjggvnGPJBk+yQppWyU5CVJ/rqwjUrQAIDq1bpIoGma2aWU/ZNcmmRwku83TXN3KeWoJLc2TXNBkk8nOa2UclB6Fwy8r2maZmHbVaABAPwDmqaZlN6T/+d97ch5/r4nyRv/nm0q0ACA6tWaoA0U56ABAFRGgQYAUBktTgCgelqcAAC0SoIGAFRPggYAQKskaABA/TorQJOgAQDURoEGAFAZLU4AoHoWCQAA0CoJGgBQPQkaAACtUqABAFRGixMAqJ4WJwAArZKgAQD166wATYIGAFAbCRoAUD3noAEA0CoFGgBAZbQ4AYDqaXECANAqCRoAUD0JGgAArZKgAQDVk6ABANAqBRoAQGW0OAGA+nVWh1OCBgBQGwkaAFA9iwQAAGiVAg0AoDJanABA9bQ4AQBolQQNAKhehwVoEjQAgNpI0ACA6jkHDQCAVinQAAAqo8UJAFSvwzqcEjQAgNpI0ACA6lkkAABAqxRoAACV0eIEAKrXYR1OCRoAQG0kaABA9QYN6qwITYIGAFAZCRoAUD3noAEA0CoFGgBAZbQ4AYDquZMAAACtkqABANXrsABNggYAUBsJGgBQPeegAQDQKgUaAEBltDgBgOppcQIA0CoJGgBQvQ4L0CRoAAC1UaABAFRGixMAqJ5FAgAAtEqCBgBUr8MCNAkaAEBtJGgAQPWcgwYAQKsUaAAAldHiBACq12EdTgkaAEBtJGgAQPUsEgAAoFUSNACgeh0WoEnQAABqo0ADAKiMFicAUD2LBAAAaFW1CdrD1x3f9hQgq219QNtTgCTJozd9ve0pQKs6LECToAEA1EaBBgBQmWpbnAAAz7JIAACAVknQAIDqdViAJkEDAKiNBA0AqJ5z0AAAaJUCDQCgMlqcAED1OqzDKUEDAKiNBA0AqJ5FAgAAtEqBBgBQGS1OAKB6WpwAALRKggYAVK/DAjQJGgBAbSRoAED1nIMGAECrFGgAAJXR4gQAqtdhHU4JGgBAbSRoAED1LBIAAKBVEjQAoHodFqBJ0AAAaqNAAwCojBYnAFC9QR3W45SgAQBURoIGAFSvwwI0CRoAQG0UaAAAlVGgAQDVK6W09liMue1cSvltKWVyKeXQBYx5WynlnlLK3aWUHy9qm85BAwB4kUopg5N8K8kOSaYkuaWUckHTNPfMM2aDJIcleWPTNI+WUkYuarsKNACgeoPqXSSwVZLJTdPcnySllJ8k2SPJPfOM+XCSbzVN82iSNE0zbVEb1eIEAFiIUsp+pZRb53nsN8/bayd5cJ7nU/pem9crkryilHJ9KeXGUsrOi/pOCRoAUL3FORdsoDRNc2qSU/+BTQxJskGScUlGJ7mmlLJZ0zSPLegDEjQAgBdvapIx8zwf3ffavKYkuaBpmllN0/whye/SW7AtkAINAODFuyXJBqWU9UopQ5Psm+SC+cacl970LKWUl6a35Xn/wjaqxQkAVK/WOwk0TTO7lLJ/kkuTDE7y/aZp7i6lHJXk1qZpLuh7b8dSyj1JepIc3DTNwwvbrgINAOAf0DTNpCST5nvtyHn+bpJ8qu+xWBRoAED1SiqN0AaIc9AAACojQQMAqlfxhWoHhAQNAKAyCjQAgMpocQIA1WvzTgJtkKABAFRGggYAVK/DAjQJGgBAbRRoAACV0eIEAKo3qMN6nBI0AIDKSNAAgOp1WIAmQQMAqI0EDQCongvVAgDQKgUaAEBltDgBgOp1WIdTggYAUBsJGgBQPReqBQCgVQo0AIDKaHECANXrrAanBA0AoDoSNACgeu4kAABAqyRoAED1BnVWgCZBAwCojQINAKAyWpwAQPUsEgAAoFUSNACgeh0WoEnQAABqI0EDAKrnHDQAAFqlQAMAqIwWJwBQvU67k8ACC7RSyn8kaRb0ftM0nxyQGQEAdLiFJWi3LrFZAAAsRKctElhggdY0zenzPi+lrNg0zVMDPyUAgM62yEUCpZTXl1LuSfKbvuevLKWcMuAzAwDoUIuzivPkJDsleThJmqb53yTbDOSkAADmVVp8tGGxLrPRNM2D873UMwBzAQAgi3eZjQdLKW9I0pRSlktyQJJ7B3ZaAADPGdRhiwQWJ0H7SJKPJ1k7yZ+TvKrvOQAAA2CRCVrTNP8vybuWwFwAAF5QhwVoi7WK8+WllAtLKX8tpUwrpZxfSnn5kpgcAEAnWpwW54+TnJlkzSRrJTkryRkDOSkAgE62OAXaik3T/LBpmtl9j/9J8pKBnhgAwLNKKa092rCwe3Gu1vfnxaWUQ5P8JL335nx7kklLYG4AAB1pYYsEfpXeguzZ0vHf5nmvSXLYQE0KAGBenbZIYGH34lxvSU4EAIBei3Oh2pRSNk2yceY596xpmv8eqEkBAMyr0y5Uu8gCrZTyhSTj0lugTUqyS5LrkijQAAAGwOKs4tw7yfZJHmqa5v1JXplk+IDOCgCggy1Oi3NG0zRzSimzSynDkkxLMmaA58ULuP66a3P8sV/JnJ452fOte+cDH9qv3/szZ87MEZ87JPfec3eGjxiRY48/MWutPTqPPfZoDv7UAbn7rruy+x575tDDj5z7mYsnXZTvn/adlFKyxsiR+fJXj8+qq666pHeNpdQOr98wJ3zmrRk8eFB+cN6NOeEHP+/3/jqjVs23v/DOvHTVlfPo43/LB474YaZOezzbvGZsjvvUhLnj/ullXXnv507PhVfduaR3gaXM9ddek2OP6f0dnLDXPvngh5//O3j4YZ/NvXf3/g4e97WTsvbao5Mk3zvtOzn37J9l0OBBOeSwz+eN//ymJMkTTzyRLx35+Uye/LuUUvKlfz86r3zVFjn40wfmT3/4Q5LkySefzCqrrJIzzzl/ye4wc3VYh3OxCrRbSykjkpyW3pWd05PcMKCz4nl6enpyzFeOyn+e+v10jerKu/bdJ9tuNz7rrz927pjzzvlZVhk2LBdMuiyXXDwxXz/pazn2hJOy/NDl87H9D8jkyb/Pfb//3dzxs2fPzvHHHp2zz5uYVVddNSefeHx+esb/5CMf+0Qbu8hSZtCgkpMP3Sdv+dgpmdr9WK774adz0dV35jd/6J475qsH7ZEfTbw5P7rolmz72g1y1P7/kg8e+T+55tbJ2fqdxydJVh22Yu467/P5+Y2/aWtXWEr09PTk6K8cle+c9l/p6urKO9++d8ZtNz7rj33ud/Dcs8/KsGHDctEll+fiSRNz8okn5PivnZz7Jk/OJZMm5pwLJmbatO7824fenwsmXprBgwfnuK9+JW/85zflayd/I7NmzsyMp59Okhz/tZPnbveE447JyiuvvMT3mc61yBZn0zQfa5rmsaZpvp1khyT/2tfqZAm66847MmaddTJ6zJgst9zQ7LTLrrnqyiv6jbnqyivyL7vvmSR58w475eabbkjTNFlhxRWzxZavzvJDh/Yb3zRNmqbJjBlPpWmaTJ8+PWusMXKJ7RNLt9dusm7ue/Cv+ePUhzNrdk/Ouuy27DZus35jNlxvVK6+5fdJkqtv+X1223az521nwvavzGW/vDcznp61RObN0uuuO+/ImDHr9v4ODh2anXd9y/N+B6/8xS+y+x696ewOO+6Um2/s/R286sorsvOub8nQoUMzevSYjBmzbu668448+eST+dWvbsmEvfZOkiw3dGiGDRvWb5tN0+SySy/OLm/ZbcnsKC+o0y5Uu8ACrZSy5fyPJKslGdL394tSSlHcvQjTpnWna9Sac593dY3KX7u75xszLaP6xgwZMiQrr7xKHnvssQVuc7nllsvnPv+FvO2tu2fH8dvk/vvuy55v3XtgdoBlzlojh2dK93PH19Tux7L2Gv1PT73z93/OHuNfmSTZY7vNM2zll2S14Sv2G7PPTlvmzEtvG/gJs9Sb1t2dUWuOmvt8ZFdXup/3O9jd/3dwlVXy2GOPpru7O12jnvts16iuTOvuztQpU7LqqqvlyMMPy9v22jNfPPLwPPXUU/22eduvbs3qq6+eddd92cDtHMxnYQna1xbyOOEf+M4vLeiNUsp+pZRbSym3fv+7p/4DX8HimDVrVn525k9yxlnn5rJfXJNXvOIV8c+d/0uHnXRe3rTl+rnhRwfnTa8em6ndj6Wnp5n7/qiXDssmY9fK5Tfc2+Is6WQ9PbPzm3vvyT77viNnnn1eVlhhhef9Dl486aLsvKv0jCVrYReq3e7FbrSUcseC3krStZDvPDXJqUny1MymWdC4TjRyZFe6H/rL3Ofd3Q9lja6u+caMzEMP/SVdo0Zl9uzZmT79yYwYMWKB2/zdb3vP+RkzZp0kyQ477ZL/+t5pAzB7lkV/nvZ4Rnc9d3yt3TUiU//6eL8xf/l/T2Tfg7+fJFlphaHZc/wr8/j0GXPf32uHLXLBlXdk9uw5S2bSLNVGdnXlob88NPf5tO7udD3vd7Cr/+/gk09mxIhV09XVle6Hnvts90PdGdnVla6uUenqGpXNN+9NenfYced+Bdrs2bNzxc8vz0/OPGeA945FWZzLTixLBmp/u5K8N8m/vMDj4QH6zmXaJptulgf+9KdMnTIls2bNzKUXT8q4ceP7jdl23PhceMF5SZKfX35pXrvV1gvtna8xcmTuv+++PPLII0mSG2/4ZdZ7+csHbidYptx6zwMZO2aNrLvWalluyODss+OWmXj1Xf3GrD5ipbnH4MHv3yGnX3Bjv/ffttOWOfPSXy2xObN022TTzfLAA3/MlCkPZtbMmblk0sRsu13/38Fx243PBeefmyS5/LJLs9Xren8Ht91ufC6ZNDEzZ87MlCkP5oEH/phNN9s8L11jjXSNGpU//uH+JMlNN96Ql6+//tzt3XTDL7Peei/v1x6FJWGx7iTwIlyUZOWmaX49/xullKsG6DuXaUOGDMkhnzsiH/vIBzOnZ072mLBX1h+7QU755jey8SabZtx247PnW/fO5w/7bHbfdccMGz48xxx34tzP77rT+Pxt+t8ya9asXPmLK3LKqd/L+uuPzX4f/Xg+9L53Z8iQIVlzrbXypS9/tcW9ZGnS0zMnBx13di785kczePCgnH7+jbn3/odyxEd2yW33PJiJ19yVbV49Nkft/y9pmibX3X5fDjzmrLmfX2fN1TK6a0Su/dV9Le4FS5MhQ4bksMOPzEf3+1DmzOnJnhP2ytixG+Rb//H1bLLJphk3fvtM2GvvHH7owdlt5x0ybPjwHHfCSUmSsWM3yI4775IJu++awYMH53OfPzKDBw9Okhz6uSNy2CGfyaxZszJ69JgcNc/v4CUXT8rOu76llf2lv7ZO1m9LaSrtJGpxUoPVX39g21OAJMmjN3297SlAkuQlQ9JKpfTJ837TWl3wjT03XOL7vDi3eipJ3pXk5U3THFVKWSfJqKZpbh7w2QEAJBnUWQHaYp2DdkqS1yd5R9/zJ5N8a8BmBADQ4RbnHLTXNU2zZSnl9iRpmubRUsrQRX0IAIAXZ3EKtFmllMFJmiQppayRxJp4AGCJ0eJ8vm8kOTfJyFLKV5Jcl+ToAZ0VAEAHW2SC1jTNj0opv0qyfXovNLtn0zQu+w0ALDGddpmNxVnFuU6Sp5JcOO9rTdM8MJATAwDoVItzDtrE9J5/VpK8JMl6SX6bZJMBnBcAQMdanBbnZvM+L6VsmeRjAzYjAID5WCSwCE3T3JbkdQMwFwAAsnjnoH1qnqeDkmyZ5M8DNiMAgPl02BqBxToHbZV5/p6d3nPSzh6Y6QAAsNACre8Ctas0TfOZJTQfAIDnGdRhEdoCz0ErpQxpmqYnyRuX4HwAADrewhK0m9N7vtmvSykXJDkryd+efbNpmnMGeG4AAB1pcc5Be0mSh5OMz3PXQ2uSKNAAgCXi777sxFJuYQXayL4VnHflucLsWc2AzgoAoIMtrEAbnGTl9C/MnqVAAwCWmA5bI7DQAu0vTdMctcRmAgBAkoUXaB1WqwIAtXKZjedsv8RmAQDAXAss0JqmeWRJTgQAgF6Lc5kNAIBWdViHs+MuKwIAUD0JGgBQvUESNAAA2qRAAwCojBYnAFA910EDAKBVEjQAoHodFqBJ0AAAaiNBAwCq5zIbAAC0SoEGAFAZLU4AoHolndXjlKABAFRGggYAVM8iAQAAWiVBAwCqJ0EDAKBVCjQAgMpocQIA1SsddjNOCRoAQGUkaABA9SwSAACgVQo0AIDKaHECANXrsDUCEjQAgNpI0ACA6g3qsAhNggYAUBkJGgBQPZfZAABgsZVSdi6l/LaUMrmUcuhCxu1VSmlKKa9Z1DYVaAAAL1IpZXCSbyXZJcnGSd5RStn4BcatkuSAJDctznYVaABA9Upp77EIWyWZ3DTN/U3TzEzykyR7vMC4f09ybJKnF2d/FWgAAC/e2kkenOf5lL7X5iqlbJlkTNM0Exd3oxYJAADVG5T2VgmUUvZLst88L53aNM2pi/nZQUlOTPK+v+c7FWgAAAvRV4wtqCCbmmTMPM9H9732rFWSbJrkqtLbLx2V5IJSyu5N09y6oO9UoAEA1av4OrW3JNmglLJeeguzfZO889k3m6Z5PMlLn31eSrkqyWcWVpwlzkEDAHjRmqaZnWT/JJcmuTfJmU3T3F1KOaqUsvuL3a4EDQDgH9A0zaQkk+Z77cgFjB23ONtUoAEA1XMnAQAAWiVBAwCqN6jiVQIDQYIGAFAZBRoAQGW0OAGA6nVYh1OCBgBQGwkaAFA9iwQAAGiVBA0AqF6HBWgSNACA2ijQAAAqo8UJAFSv0xKlTttfAIDqSdAAgOqVDlslIEEDAKiMAg0AoDJanABA9TqrwSlBAwCojgQNAKiee3ECANAqCRoAUL3Oys8kaAAA1VGgAQBURosTAKheh60RkKABANRGggYAVM+9OAEAaJUEDQCoXqclSp22vwAA1VOgAQBURosTAKieRQIAALRKggYAVK+z8jMJGgBAdRRoAACVqbbFOWhQp4WZ1OjRm77e9hQgSbLqa/dvewqQJJlx+zdb+V6LBAAAaFW1CRoAwLM6LVHqtP0FAKieBA0AqJ5z0AAAaJUCDQCgMlqcAED1OqvBKUEDAKiOBA0AqF6HrRGQoMrkD8UAABKOSURBVAEA1EaCBgBUb1CHnYUmQQMAqIwCDQCgMlqcAED1LBIAAKBVEjQAoHrFIgEAANqkQAMAqIwWJwBQPYsEAABolQQNAKieOwkAANAqCRoAUD3noAEA0CoFGgBAZbQ4AYDqaXECANAqCRoAUD334gQAoFUKNACAymhxAgDVG9RZHU4JGgBAbSRoAED1LBIAAKBVEjQAoHouVAsAQKsUaAAAldHiBACqZ5EAAACtkqABANVzoVoAAFolQQMAquccNAAAWqVAAwCojBYnAFA9dxIAAKBVEjQAoHodFqBJ0AAAaqNAAwCojBYnAFC9QR22SkCCBgBQGQkaAFC9zsrPJGgAANWRoAEA9euwCE2CBgBQGQUaAEBltDgBgOqVDutxStAAACojQQMAqtdh16mVoAEA1EaCBgBUr8MCNAkaAEBtFGgAAJXR4gQA6tdhPU4JGgBAZSRoAED1XKgWAIBWKdAAACqjxQkAVM+dBAAAaJUEDQCoXocFaBI0AIDaSNAAgPp1WIQmQQMAqIwCDQCgMlqcAED13EkAAIBWSdAAgOq5UC0AAK1SoAEA/ANKKTuXUn5bSplcSjn0Bd7/VCnlnlLKHaWUK0op6y5qmwo0AKB6pcXHQudVyuAk30qyS5KNk7yjlLLxfMNuT/Kapmk2T/KzJMctan8VaAAAL95WSSY3TXN/0zQzk/wkyR7zDmia5sqmaZ7qe3pjktGL2qgCDQCoX4sRWillv1LKrfM89ptnZmsneXCe51P6XluQDya5eFG7axUnAMBCNE1zapJT/9HtlFLeneQ1SbZd1FgFGgBQvYovVDs1yZh5no/ue62fUsqbkxyeZNumaZ5Z1Ea1OAEAXrxbkmxQSlmvlDI0yb5JLph3QClliyTfSbJ70zTTFmejCjQAgBepaZrZSfZPcmmSe5Oc2TTN3aWUo0opu/cNOz7JyknOKqX8upRywQI2N5cWJwBQvZrvJNA0zaQkk+Z77ch5/n7z37tNCRoAQGUkaABA9SoO0AaEBA0AoDISNACgfh0WoUnQAAAqo0ADAKiMFicAUL2K7yQwICRoAACVkaABANWr+UK1A0GBVrnrr70mxx7zlczpmZMJe+2TD354v37vz5w5M4cf9tnce/fdGT5iRI772klZe+3RSZLvnfadnHv2zzJo8KAcctjn88Z/flOS5Ien/yDnnH1WSinZYINX5KivfDXLL7983veed+apv/0tSfLIIw9n0802z8n/ccqS3WGqNBDH4S47jM+KK62UwYMGZfCQwTnjzHOSJL+59958+agvZOYzz2TwkMH53Oe/mM0233zJ7jBLnR3esFFOOHjvDB40KD8475c54b8u7/f+Omuumm9/4d156aor59EnnsoHDj89U6c9liT58if3yM5v2iRJcsxpl+Rnl922xOcP89PirFhPT0+O/spROeXb3825F0zMJZMuyn2TJ/cbc+7ZZ2XYsGG56JLL8+73vi8nn3hCkuS+yZNzyaSJOeeCiTnlO9/N0V/+Unp6etLd3Z0f/+i/c8aZZ+ec8y/KnDk9uWTSxCTJD37445x5zvk585zzs/krt8j2b95xie8z9RmI4/BZ3/2v03PmOefPLc6S5KQTj89HPvbxnHnO+fnY/gfk5BOPXzI7ylJr0KCSkw99W/bY/5RssdeXs8/Or86GLx/Vb8xXD5qQH028OVu9/as5+tSLc9Qnem+RuPM/b5JXbTQmr9v3mGzznhNy4Hu3zyorvaSN3YB+BqxAK6VsWErZvpSy8nyv7zxQ37msuevOOzJmzLoZPWZMlhs6NDvv+pZcdeUV/cZc+YtfZPc9JiRJdthxp9x84w1pmiZXXXlFdt71LRk6dGhGjx6TMWPWzV133pGk9//hPvP005k9e3ZmPP101hg5st82p0+fnptvvjHbbf933zqMZdBAHYcLUlIyfXpvkjv9ySezxhojFzoeXrvpy3Lfg/8vf5z6cGbN7slZl96W3cb1T103fPmaufrm3yZJrr7ld9lt3GZJko1ePirX3TY5PT1z8tTTM3Pn76dmxzdstMT3gUUrLT7aMCAFWinlk0nOT/KJJHeVUvaY5+2jB+I7l0XTurszas3n/itwZFdXuru7+4+Z1p1Ro9ZMkgwZMiQrr7JKHnvs0XR3d6dr1HOf7RrVlWnd3enq6sq/vu8D2enN2+XN4/45q6y8ct7wxn/ut80rr/h5Xve612fllfvV1nSogTgOkyQl+ciHP5h993lrfnbmT+eO+eyhn8tJJxyXHbffNl874dh88qBPDeDesSxYa+TwTOl+dO7zqd2PZu01hvcbc+fvpmaP8a9Kkuwx/pUZtvIKWW34Srnjd70F2QovWS6rj1gp277mFRk9atUlOn94IQOVoH04yaubptkzybgkR5RSDuh7b4HFaCllv1LKraWUW7932qkDNLXO9sTjj+fKX1yRSZddkcuvvDYzZszIRRee32/MxZMuyi67vqWlGdIpfvDDM/LTn52bb337tPz0jB/lV7fekiQ586dn5OBDDstlV1ydgw85LF884vCWZ8qy4LCTzs2bXj02N5xxSN706rGZ2v1oenrm5Iobf5NLrrsnV/7g0zn9q+/PTXf8IT09c9qeLi+kwyK0gSrQBjVNMz1Jmqb5Y3qLtF1KKSdmIbvaNM2pTdO8pmma18x/EnInGtnVlYf+8tDc588mYP3GjOzKQw/9JUkye/bsTH/yyYwYsWq6urrS/dBzn+1+qDsju7py442/zNqjR2e11VbLcsstl+3fvGP+9/bb54579NFHctedd+ZN244b2J1jqTEQx2GSudtYffXVM/7NO8xtfV54/rnZfofe8x933GmXRbZE4c/THs/orudSr7W7Vs3Uvz7eb8xf/vp49v3Md/P6dxybL3zzwiTJ49NnJEmO+96l2XrfY7LbR7+ZUkp+/8C0JTd5WICBKtC6SymvevZJX7G2W5KXJtlsgL5zmbPJppvlgQf+mClTHsysmTNzyaSJ2Xa78f3GjNtufC44/9wkyeWXXZqtXrd1SinZdrvxuWTSxMycOTNTpjyYBx74YzbdbPOMWnOt3PG//5sZM2akaZrcdOMNWW/99edu7/LLLs02247L8ssvv0T3lXoNxHH41FNP5W9/m54keeqpp3LDL6/P2LEbJEnWGDkyt95yc5Lk5ptuzDrrvmzJ7SxLpVvv/lPGrrNG1l1r9Sw3ZHD22WnLTLyqf2G/+oiVUvqu03DwB3bK6effmKR3gcFqw1dKkmy6wVrZdIO18vMbfrNkd4DFUlr8vzYM1GU23ptk9rwvNE0zO8l7SynfGaDvXOYMGTIkhx1+ZD6634cyZ05P9pywV8aO3SDf+o+vZ5NNNs248dtnwl575/BDD85uO++QYcOH57gTTkqSjB27QXbceZdM2H3XDB48OJ/7/JEZPHhwNt/8ldlhx52y7z4TMnjwkGy40UbZe5+3z/3OSy+elA988MNt7TIVGojj8JGHH85Bn/x4kmR2T092fctueeObtkmSHPnFf89xxxydntmzM3T55XPkF49qbd9ZOvT0zMlBx56ZC0/5eAYPKjn9/Btz7/0P5YiPviW33fNAJl59Z7Z5zQY56hO7p2mS626bnAO/emaSZLkhg/Pz7x+YJHly+tP5wOGna3FShdI0TdtzeEFPz06dEwNowaqv3b/tKUCSZMbt32wlUvrNX55qrS7YcM0Vl/g+u1AtAFC9TruTgAvVAgBURoIGAFSvwwI0CRoAQG0kaABA/TosQpOgAQBURoEGAFAZLU4AoHptXdG/LRI0AIDKSNAAgOq5UC0AAK1SoAEAVEaLEwCoXod1OCVoAAC1kaABAPXrsAhNggYAUBkJGgBQPReqBQCgVQo0AIDKaHECANVzJwEAAFolQQMAqtdhAZoEDQCgNgo0AIDKaHECAPXrsB6nBA0AoDISNACgeu4kAABAqyRoAED1XKgWAIBWKdAAACqjxQkAVK/DOpwSNACA2kjQAIDqWSQAAECrJGgAwFKgsyI0CRoAQGUUaAAAldHiBACqZ5EAAACtkqABANXrsABNggYAUBsFGgBAZbQ4AYDqWSQAAECrJGgAQPVKhy0TkKABAFRGggYA1K+zAjQJGgBAbRRoAACV0eIEAKrXYR1OCRoAQG0kaABA9VyoFgCAVknQAIDquVAtAACtUqABAFRGixMAqF9ndTglaAAAtZGgAQDV67AATYIGAFAbBRoAQGW0OAGA6rmTAAAArZKgAQDVcycBAABaJUEDAKrnHDQAAFqlQAMAqIwCDQCgMgo0AIDKWCQAAFTPIgEAAFolQQMAqudCtQAAtEqBBgBQGS1OAKB6FgkAANAqCRoAUL0OC9AkaAAAtVGgAQBURosTAKhfh/U4JWgAAJWRoAEA1XMnAQAAWiVBAwCq50K1AAC0SoEGAFAZLU4AoHod1uGUoAEA1EaCBgDUr8MiNAkaAEBlFGgAAJXR4gQAqudOAgAAtEqCBgBUz50EAABoVWmapu05MEBKKfs1TXNq2/MAxyI1cByyNJGgLdv2a3sC0MexSA0chyw1FGgAAJVRoAEAVEaBtmxzrgW1cCxSA8chSw2LBAAAKiNBAwCojAINAKAyCrRlVCll51LKb0spk0sph7Y9HzpTKeX7pZRppZS72p4LnauUMqaUcmUp5Z5Syt2llAPanhMsinPQlkGllMFJfpdkhyRTktyS5B1N09zT6sToOKWUbZJMT/LfTdNs2vZ86EyllDWTrNk0zW2llFWS/CrJnn4TqZkEbdm0VZLJTdPc3zTNzCQ/SbJHy3OiAzVNc02SR9qeB52taZq/NE1zW9/fTya5N8na7c4KFk6BtmxaO8mD8zyfEj9GACmlvCzJFkluancmsHAKNAA6Qill5SRnJzmwaZon2p4PLIwCbdk0NcmYeZ6P7nsNoCOVUpZLb3H2o6Zpzml7PrAoCrRl0y1JNiilrFdKGZpk3yQXtDwngFaUUkqS7yW5t2maE9ueDywOBdoyqGma2Un2T3Jpek+GPbNpmrvbnRWdqJRyRpIbkvxTKWVKKeWDbc+JjvTGJO9JMr6U8uu+x65tTwoWxmU2AAAqI0EDAKiMAg0AoDIKNACAyijQAAAqo0ADAKiMAg2WQaWUnr5LCdxVSjmrlLLiP7CtH5RS9u77+7ullI0XMnZcKeUNL+I7/lhKeenivj7fmOl/53d9sZTymb93jgBLkgINlk0zmqZ5VdM0myaZmeQj875ZShnyYjbaNM2Hmqa5ZyFDxiX5uws0APpToMGy79okY/vSrWtLKRckuaeUMriUcnwp5ZZSyh2llH9Leq+6Xkr5Zinlt6WUnycZ+eyGSilXlVJe0/f3zqWU20op/1tKuaLvJtQfSXJQX3r3plLKGqWUs/u+45ZSyhv7Prt6KeWyUsrdpZTvJimL2olSynmllF/1fWa/+d47qe/1K0opa/S9tn4p5ZK+z1xbStnw/+IfJsCS8KL+KxpYOvQlZbskuaTvpS2TbNo0zR/6ipzHm6Z5bSll+STXl1IuS7JFkn9KsnGSriT3JPn+fNtdI8lpSbbp29ZqTdM8Ukr5dpLpTdOc0Dfux0lOaprmulLKOum9u8VGSb6Q5LqmaY4qpbwlyeLcYeADfd+xQpJbSilnN03zcJKVktzaNM1BpZQj+7a9f5JTk3ykaZrfl1Jel+SUJONfxD9GgCVOgQbLphVKKb/u+/va9N6H8A1Jbm6a5g99r++YZPNnzy9LMjzJBkm2SXJG0zQ9Sf5cSvnFC2x/6yTXPLutpmkeWcA83pxk495bISZJhpVSVu77jrf2fXZiKeXRxdinT5ZSJvT9PaZvrg8nmZPkp32v/0+Sc/q+4w1Jzprnu5dfjO8AqIICDZZNM5qmedW8L/QVKn+b96Ukn2ia5tL5xv1f3qNwUJKtm6Z5+gXmsthKKePSW+y9vmmap0opVyV5yQKGN33f+9j8/wwAlhbOQYPOdWmSj5ZSlkuSUsorSikrJbkmydv7zlFbM8l2L/DZG5NsU0pZr++zq/W9/mSSVeYZd1mSTzz7pJTybMF0TZJ39r22S5JVFzHX4Uke7SvONkxvgvesQUmeTQHfmd7W6RNJ/lBK2afvO0op5ZWL+A6AaijQoHN9N73nl91WSrkryXfSm6qfm+T3fe/9d5Ib5v9g0zR/TbJfetuJ/5vnWowXJpnw7CKBJJ9M8pq+RQj35LnVpF9Kb4F3d3pbnQ8sYq6XJBlSSrk3yTHpLRCf9bckW/Xtw/gkR/W9/q4kH+yb391J9liMfyYAVShN07Q9BwAA5iFBAwCojAINAKAyCjQAgMoo0AAAKqNAAwCojAINAKAyCjQAgMr8f5EsxmCuTezLAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7fcxLuwZpkK",
        "outputId": "6894ae74-7afa-4e9f-9439-f7c45ebd103c"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "304849a1-bd9f-4c88-9a62-e8f3860aa16f"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 52ms/step - loss: 1.1207 - accuracy: 0.4872 - val_loss: 0.9188 - val_accuracy: 0.5858\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9626 - accuracy: 0.5678 - val_loss: 0.9269 - val_accuracy: 0.5858\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9561 - accuracy: 0.5729 - val_loss: 0.9163 - val_accuracy: 0.5858\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9611 - accuracy: 0.5647 - val_loss: 0.9081 - val_accuracy: 0.5858\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9589 - accuracy: 0.5578 - val_loss: 0.9172 - val_accuracy: 0.5858\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9421 - accuracy: 0.5659 - val_loss: 0.9124 - val_accuracy: 0.5858\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9464 - accuracy: 0.5681 - val_loss: 0.9145 - val_accuracy: 0.5858\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9281 - accuracy: 0.5697 - val_loss: 0.9095 - val_accuracy: 0.5858\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9442 - accuracy: 0.5642 - val_loss: 0.9128 - val_accuracy: 0.5858\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9335 - accuracy: 0.5701 - val_loss: 0.9030 - val_accuracy: 0.5858\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9256 - accuracy: 0.5739 - val_loss: 0.9075 - val_accuracy: 0.5858\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9300 - accuracy: 0.5686 - val_loss: 0.9061 - val_accuracy: 0.5858\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9142 - accuracy: 0.5822 - val_loss: 0.9079 - val_accuracy: 0.5858\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9284 - accuracy: 0.5700 - val_loss: 0.9093 - val_accuracy: 0.5858\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9175 - accuracy: 0.5674 - val_loss: 0.9124 - val_accuracy: 0.5858\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9290 - accuracy: 0.5714 - val_loss: 0.9012 - val_accuracy: 0.5858\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9148 - accuracy: 0.5741 - val_loss: 0.9012 - val_accuracy: 0.5858\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9149 - accuracy: 0.5710 - val_loss: 0.9031 - val_accuracy: 0.5858\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9078 - accuracy: 0.5711 - val_loss: 0.9034 - val_accuracy: 0.5858\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9165 - accuracy: 0.5704 - val_loss: 0.8998 - val_accuracy: 0.5871\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9147 - accuracy: 0.5675 - val_loss: 0.9017 - val_accuracy: 0.5858\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9186 - accuracy: 0.5701 - val_loss: 0.9044 - val_accuracy: 0.5858\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9169 - accuracy: 0.5725 - val_loss: 0.9011 - val_accuracy: 0.5858\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9122 - accuracy: 0.5659 - val_loss: 0.9011 - val_accuracy: 0.5858\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9144 - accuracy: 0.5670 - val_loss: 0.8998 - val_accuracy: 0.5858\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9198 - accuracy: 0.5662 - val_loss: 0.8965 - val_accuracy: 0.5858\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9218 - accuracy: 0.5574 - val_loss: 0.8979 - val_accuracy: 0.5871\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9116 - accuracy: 0.5688 - val_loss: 0.9014 - val_accuracy: 0.5858\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9023 - accuracy: 0.5773 - val_loss: 0.8953 - val_accuracy: 0.5858\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9028 - accuracy: 0.5725 - val_loss: 0.8953 - val_accuracy: 0.5871\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9113 - accuracy: 0.5690 - val_loss: 0.8953 - val_accuracy: 0.5777\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9105 - accuracy: 0.5690 - val_loss: 0.8855 - val_accuracy: 0.5777\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9097 - accuracy: 0.5681 - val_loss: 0.8984 - val_accuracy: 0.5777\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9080 - accuracy: 0.5693 - val_loss: 0.8950 - val_accuracy: 0.5791\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9071 - accuracy: 0.5705 - val_loss: 0.8924 - val_accuracy: 0.5777\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9084 - accuracy: 0.5684 - val_loss: 0.8959 - val_accuracy: 0.5777\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9055 - accuracy: 0.5672 - val_loss: 0.8907 - val_accuracy: 0.5777\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9059 - accuracy: 0.5683 - val_loss: 0.9087 - val_accuracy: 0.5791\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9097 - accuracy: 0.5675 - val_loss: 0.8864 - val_accuracy: 0.5777\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8996 - accuracy: 0.5718 - val_loss: 0.8911 - val_accuracy: 0.5777\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9028 - accuracy: 0.5700 - val_loss: 0.8953 - val_accuracy: 0.5791\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8999 - accuracy: 0.5715 - val_loss: 0.9031 - val_accuracy: 0.5777\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9000 - accuracy: 0.5715 - val_loss: 0.8823 - val_accuracy: 0.5777\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8971 - accuracy: 0.5724 - val_loss: 0.8785 - val_accuracy: 0.5804\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8976 - accuracy: 0.5680 - val_loss: 0.8797 - val_accuracy: 0.5751\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8974 - accuracy: 0.5751 - val_loss: 0.8799 - val_accuracy: 0.5777\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8916 - accuracy: 0.5712 - val_loss: 0.8790 - val_accuracy: 0.5777\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8967 - accuracy: 0.5693 - val_loss: 0.8698 - val_accuracy: 0.5777\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8982 - accuracy: 0.5705 - val_loss: 0.8672 - val_accuracy: 0.5992\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8921 - accuracy: 0.5751 - val_loss: 0.8954 - val_accuracy: 0.5724\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8938 - accuracy: 0.5730 - val_loss: 0.8733 - val_accuracy: 0.5804\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.8901 - accuracy: 0.5718 - val_loss: 0.8717 - val_accuracy: 0.5845\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8863 - accuracy: 0.5692 - val_loss: 0.8702 - val_accuracy: 0.5777\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8824 - accuracy: 0.5745 - val_loss: 0.8707 - val_accuracy: 0.5858\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.8835 - accuracy: 0.5735 - val_loss: 0.8655 - val_accuracy: 0.5724\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8759 - accuracy: 0.5770 - val_loss: 0.8732 - val_accuracy: 0.6032\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8850 - accuracy: 0.5744 - val_loss: 0.9285 - val_accuracy: 0.5724\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8808 - accuracy: 0.5815 - val_loss: 0.8732 - val_accuracy: 0.5764\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8732 - accuracy: 0.5788 - val_loss: 0.8689 - val_accuracy: 0.5845\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.8698 - accuracy: 0.5814 - val_loss: 0.8696 - val_accuracy: 0.5965\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8623 - accuracy: 0.5808 - val_loss: 0.8488 - val_accuracy: 0.6019\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8615 - accuracy: 0.5768 - val_loss: 0.8391 - val_accuracy: 0.6166\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.8670 - accuracy: 0.5781 - val_loss: 0.8543 - val_accuracy: 0.6059\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8644 - accuracy: 0.5811 - val_loss: 0.8457 - val_accuracy: 0.6005\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8521 - accuracy: 0.5782 - val_loss: 0.8491 - val_accuracy: 0.6220\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8498 - accuracy: 0.5791 - val_loss: 0.8463 - val_accuracy: 0.6126\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8453 - accuracy: 0.5824 - val_loss: 0.8349 - val_accuracy: 0.6180\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.8489 - accuracy: 0.5835 - val_loss: 0.8178 - val_accuracy: 0.6153\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8340 - accuracy: 0.5891 - val_loss: 0.8484 - val_accuracy: 0.5885\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8358 - accuracy: 0.5849 - val_loss: 0.8143 - val_accuracy: 0.6180\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8170 - accuracy: 0.5933 - val_loss: 0.8171 - val_accuracy: 0.6153\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8163 - accuracy: 0.5940 - val_loss: 0.8208 - val_accuracy: 0.6273\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8224 - accuracy: 0.5876 - val_loss: 0.8188 - val_accuracy: 0.6166\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8061 - accuracy: 0.5936 - val_loss: 0.7881 - val_accuracy: 0.6381\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7989 - accuracy: 0.6055 - val_loss: 0.7970 - val_accuracy: 0.6126\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7904 - accuracy: 0.6080 - val_loss: 0.7933 - val_accuracy: 0.6314\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7738 - accuracy: 0.6073 - val_loss: 0.7871 - val_accuracy: 0.6475\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7709 - accuracy: 0.6140 - val_loss: 0.7865 - val_accuracy: 0.6233\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7591 - accuracy: 0.6228 - val_loss: 0.7534 - val_accuracy: 0.6434\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7504 - accuracy: 0.6177 - val_loss: 0.7641 - val_accuracy: 0.6434\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7401 - accuracy: 0.6279 - val_loss: 0.7427 - val_accuracy: 0.6381\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7279 - accuracy: 0.6340 - val_loss: 0.7365 - val_accuracy: 0.6501\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7039 - accuracy: 0.6493 - val_loss: 0.7085 - val_accuracy: 0.6501\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6872 - accuracy: 0.6613 - val_loss: 0.7141 - val_accuracy: 0.6595\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6710 - accuracy: 0.6648 - val_loss: 0.7187 - val_accuracy: 0.6488\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6660 - accuracy: 0.6733 - val_loss: 0.6675 - val_accuracy: 0.6971\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6298 - accuracy: 0.6857 - val_loss: 0.6751 - val_accuracy: 0.6810\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6226 - accuracy: 0.6990 - val_loss: 0.6246 - val_accuracy: 0.6984\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5982 - accuracy: 0.7131 - val_loss: 0.6526 - val_accuracy: 0.7105\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5808 - accuracy: 0.7246 - val_loss: 0.6047 - val_accuracy: 0.7386\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5927 - accuracy: 0.7213 - val_loss: 0.3971 - val_accuracy: 0.8324\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.5633 - accuracy: 0.7417 - val_loss: 0.4488 - val_accuracy: 0.8204\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5443 - accuracy: 0.7526 - val_loss: 0.4421 - val_accuracy: 0.8056\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5270 - accuracy: 0.7638 - val_loss: 0.3973 - val_accuracy: 0.8365\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5134 - accuracy: 0.7699 - val_loss: 0.3652 - val_accuracy: 0.8552\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4769 - accuracy: 0.7869 - val_loss: 0.3659 - val_accuracy: 0.8566\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4624 - accuracy: 0.7969 - val_loss: 0.4109 - val_accuracy: 0.8338\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4377 - accuracy: 0.8070 - val_loss: 0.3604 - val_accuracy: 0.8432\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4247 - accuracy: 0.8185 - val_loss: 0.3328 - val_accuracy: 0.8700\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4056 - accuracy: 0.8247 - val_loss: 0.3485 - val_accuracy: 0.8566\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3856 - accuracy: 0.8432 - val_loss: 0.3106 - val_accuracy: 0.8660\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3740 - accuracy: 0.8487 - val_loss: 0.2796 - val_accuracy: 0.8767\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3593 - accuracy: 0.8511 - val_loss: 0.2995 - val_accuracy: 0.8820\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3388 - accuracy: 0.8614 - val_loss: 0.2652 - val_accuracy: 0.8914\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3204 - accuracy: 0.8689 - val_loss: 0.2684 - val_accuracy: 0.8954\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2973 - accuracy: 0.8748 - val_loss: 0.2699 - val_accuracy: 0.8887\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2946 - accuracy: 0.8818 - val_loss: 0.2541 - val_accuracy: 0.8954\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.2858 - accuracy: 0.8908 - val_loss: 0.2493 - val_accuracy: 0.9008\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2713 - accuracy: 0.8879 - val_loss: 0.2232 - val_accuracy: 0.9196\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2717 - accuracy: 0.8960 - val_loss: 0.2169 - val_accuracy: 0.9088\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2313 - accuracy: 0.9125 - val_loss: 0.2245 - val_accuracy: 0.9088\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2529 - accuracy: 0.9086 - val_loss: 0.1922 - val_accuracy: 0.9236\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2373 - accuracy: 0.9133 - val_loss: 0.1813 - val_accuracy: 0.9343\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2131 - accuracy: 0.9161 - val_loss: 0.1972 - val_accuracy: 0.9223\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2035 - accuracy: 0.9241 - val_loss: 0.1683 - val_accuracy: 0.9410\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2025 - accuracy: 0.9189 - val_loss: 0.1767 - val_accuracy: 0.9290\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1910 - accuracy: 0.9310 - val_loss: 0.1842 - val_accuracy: 0.9209\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1909 - accuracy: 0.9346 - val_loss: 0.1599 - val_accuracy: 0.9370\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.1675 - accuracy: 0.9380 - val_loss: 0.1715 - val_accuracy: 0.9343\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.1716 - accuracy: 0.9356 - val_loss: 0.1872 - val_accuracy: 0.9263\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1901 - accuracy: 0.9314 - val_loss: 0.0590 - val_accuracy: 0.9853\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1979 - accuracy: 0.9301 - val_loss: 0.0442 - val_accuracy: 0.9893\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1586 - accuracy: 0.9463 - val_loss: 0.0375 - val_accuracy: 0.9893\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1705 - accuracy: 0.9389 - val_loss: 0.0480 - val_accuracy: 0.9853\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1491 - accuracy: 0.9471 - val_loss: 0.0399 - val_accuracy: 0.9893\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1613 - accuracy: 0.9408 - val_loss: 0.0409 - val_accuracy: 0.9866\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1556 - accuracy: 0.9455 - val_loss: 0.0477 - val_accuracy: 0.9866\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1388 - accuracy: 0.9532 - val_loss: 0.0330 - val_accuracy: 0.9879\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1455 - accuracy: 0.9477 - val_loss: 0.0353 - val_accuracy: 0.9906\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1219 - accuracy: 0.9568 - val_loss: 0.0263 - val_accuracy: 0.9906\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1207 - accuracy: 0.9610 - val_loss: 0.0417 - val_accuracy: 0.9853\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1142 - accuracy: 0.9639 - val_loss: 0.0370 - val_accuracy: 0.9853\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1243 - accuracy: 0.9608 - val_loss: 0.0610 - val_accuracy: 0.9732\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1206 - accuracy: 0.9587 - val_loss: 0.0381 - val_accuracy: 0.9839\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1160 - accuracy: 0.9611 - val_loss: 0.0343 - val_accuracy: 0.9879\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1000 - accuracy: 0.9672 - val_loss: 0.0341 - val_accuracy: 0.9893\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1070 - accuracy: 0.9635 - val_loss: 0.0424 - val_accuracy: 0.9853\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1114 - accuracy: 0.9611 - val_loss: 0.0323 - val_accuracy: 0.9893\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0902 - accuracy: 0.9693 - val_loss: 0.0348 - val_accuracy: 0.9812\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1000 - accuracy: 0.9657 - val_loss: 0.0307 - val_accuracy: 0.9906\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0923 - accuracy: 0.9718 - val_loss: 0.0345 - val_accuracy: 0.9893\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1289 - accuracy: 0.9583 - val_loss: 0.0641 - val_accuracy: 0.9759\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0966 - accuracy: 0.9660 - val_loss: 0.0325 - val_accuracy: 0.9879\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0925 - accuracy: 0.9700 - val_loss: 0.0369 - val_accuracy: 0.9879\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0869 - accuracy: 0.9715 - val_loss: 0.0381 - val_accuracy: 0.9839\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0846 - accuracy: 0.9715 - val_loss: 0.0252 - val_accuracy: 0.9906\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0917 - accuracy: 0.9711 - val_loss: 0.0395 - val_accuracy: 0.9879\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0832 - accuracy: 0.9720 - val_loss: 0.0377 - val_accuracy: 0.9839\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0716 - accuracy: 0.9776 - val_loss: 0.0236 - val_accuracy: 0.9933\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1022 - accuracy: 0.9644 - val_loss: 0.0288 - val_accuracy: 0.9920\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1003 - accuracy: 0.9671 - val_loss: 0.0060 - val_accuracy: 0.9987\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0900 - accuracy: 0.9687 - val_loss: 0.0063 - val_accuracy: 0.9987\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0839 - accuracy: 0.9730 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0836 - accuracy: 0.9724 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0752 - accuracy: 0.9759 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0776 - accuracy: 0.9759 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0806 - accuracy: 0.9751 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0832 - accuracy: 0.9721 - val_loss: 0.0062 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0835 - accuracy: 0.9742 - val_loss: 0.0028 - val_accuracy: 0.9987\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0779 - accuracy: 0.9748 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.0694 - accuracy: 0.9778 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0752 - accuracy: 0.9772 - val_loss: 0.0040 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0639 - accuracy: 0.9815 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0533 - accuracy: 0.9833 - val_loss: 0.0048 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0753 - accuracy: 0.9769 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0656 - accuracy: 0.9800 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0598 - accuracy: 0.9814 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0620 - accuracy: 0.9782 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0506 - accuracy: 0.9832 - val_loss: 0.0023 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0696 - accuracy: 0.9778 - val_loss: 0.0055 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0550 - accuracy: 0.9835 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0576 - accuracy: 0.9811 - val_loss: 8.8282e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0650 - accuracy: 0.9823 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0498 - accuracy: 0.9849 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0661 - accuracy: 0.9796 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0563 - accuracy: 0.9827 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0526 - accuracy: 0.9844 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0555 - accuracy: 0.9824 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0629 - accuracy: 0.9785 - val_loss: 0.0135 - val_accuracy: 0.9960\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0659 - accuracy: 0.9808 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0585 - accuracy: 0.9824 - val_loss: 5.9066e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0605 - accuracy: 0.9814 - val_loss: 5.8411e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0543 - accuracy: 0.9823 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.0628 - accuracy: 0.9806 - val_loss: 5.8759e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0599 - accuracy: 0.9808 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0458 - accuracy: 0.9850 - val_loss: 4.4974e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0582 - accuracy: 0.9805 - val_loss: 4.6592e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0458 - accuracy: 0.9861 - val_loss: 7.0273e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0504 - accuracy: 0.9817 - val_loss: 6.5366e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0599 - accuracy: 0.9815 - val_loss: 0.0021 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0647 - accuracy: 0.9802 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0444 - accuracy: 0.9844 - val_loss: 7.4277e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0390 - accuracy: 0.9876 - val_loss: 5.7834e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0566 - accuracy: 0.9829 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0498 - accuracy: 0.9826 - val_loss: 8.9246e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0451 - accuracy: 0.9861 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0528 - accuracy: 0.9827 - val_loss: 3.2915e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0539 - accuracy: 0.9841 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0428 - accuracy: 0.9852 - val_loss: 3.7638e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0373 - accuracy: 0.9885 - val_loss: 3.3902e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0485 - accuracy: 0.9863 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0394 - accuracy: 0.9864 - val_loss: 0.0026 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0502 - accuracy: 0.9857 - val_loss: 8.2952e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0335 - accuracy: 0.9902 - val_loss: 4.0156e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0371 - accuracy: 0.9882 - val_loss: 6.9475e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0506 - accuracy: 0.9827 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.0554 - accuracy: 0.9811 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0445 - accuracy: 0.9876 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0404 - accuracy: 0.9869 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0353 - accuracy: 0.9873 - val_loss: 7.1199e-04 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0459 - accuracy: 0.9844 - val_loss: 6.0994e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0551 - accuracy: 0.9823 - val_loss: 1.3986e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0368 - accuracy: 0.9888 - val_loss: 1.3546e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0403 - accuracy: 0.9887 - val_loss: 1.9660e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0436 - accuracy: 0.9881 - val_loss: 3.5196e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0377 - accuracy: 0.9881 - val_loss: 1.8621e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0489 - accuracy: 0.9844 - val_loss: 5.0363e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0397 - accuracy: 0.9864 - val_loss: 2.8010e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0504 - accuracy: 0.9833 - val_loss: 4.7930e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0432 - accuracy: 0.9884 - val_loss: 1.3611e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0440 - accuracy: 0.9861 - val_loss: 8.9409e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0434 - accuracy: 0.9878 - val_loss: 1.9667e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0399 - accuracy: 0.9872 - val_loss: 6.3302e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0370 - accuracy: 0.9893 - val_loss: 1.8477e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0276 - accuracy: 0.9914 - val_loss: 1.0438e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0490 - accuracy: 0.9864 - val_loss: 7.9116e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0364 - accuracy: 0.9893 - val_loss: 5.5065e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0442 - accuracy: 0.9869 - val_loss: 5.0580e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0332 - accuracy: 0.9902 - val_loss: 1.5669e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0256 - accuracy: 0.9902 - val_loss: 9.0750e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0402 - accuracy: 0.9866 - val_loss: 3.3671e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0382 - accuracy: 0.9894 - val_loss: 7.9939e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0263 - accuracy: 0.9917 - val_loss: 2.6453e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0388 - accuracy: 0.9857 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0371 - accuracy: 0.9876 - val_loss: 2.9927e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0423 - accuracy: 0.9881 - val_loss: 7.9994e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0376 - accuracy: 0.9882 - val_loss: 0.0034 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0515 - accuracy: 0.9842 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0390 - accuracy: 0.9875 - val_loss: 0.0112 - val_accuracy: 0.9946\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0368 - accuracy: 0.9891 - val_loss: 9.8302e-05 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0483 - accuracy: 0.9866 - val_loss: 6.2326e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0424 - accuracy: 0.9864 - val_loss: 2.1956e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0263 - accuracy: 0.9908 - val_loss: 1.5824e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0340 - accuracy: 0.9873 - val_loss: 3.4657e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0363 - accuracy: 0.9882 - val_loss: 3.7915e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0340 - accuracy: 0.9896 - val_loss: 2.3062e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0304 - accuracy: 0.9917 - val_loss: 4.2248e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0733 - accuracy: 0.9784 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0307 - accuracy: 0.9902 - val_loss: 4.4400e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0401 - accuracy: 0.9861 - val_loss: 8.6383e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0388 - accuracy: 0.9869 - val_loss: 5.4233e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0340 - accuracy: 0.9908 - val_loss: 5.9084e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0304 - accuracy: 0.9908 - val_loss: 6.6084e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0402 - accuracy: 0.9884 - val_loss: 1.3597e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0358 - accuracy: 0.9897 - val_loss: 2.0409e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0287 - accuracy: 0.9899 - val_loss: 8.0606e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0292 - accuracy: 0.9918 - val_loss: 3.9513e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0278 - accuracy: 0.9909 - val_loss: 4.1542e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0332 - accuracy: 0.9899 - val_loss: 4.2898e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0287 - accuracy: 0.9906 - val_loss: 7.4587e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0335 - accuracy: 0.9902 - val_loss: 1.5089e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0272 - accuracy: 0.9914 - val_loss: 2.2756e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0336 - accuracy: 0.9885 - val_loss: 3.7749e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0299 - accuracy: 0.9900 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 0.0020 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0259 - accuracy: 0.9927 - val_loss: 1.3125e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0335 - accuracy: 0.9903 - val_loss: 3.8385e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0303 - accuracy: 0.9914 - val_loss: 7.6723e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0460 - accuracy: 0.9858 - val_loss: 4.5270e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0345 - accuracy: 0.9891 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0270 - accuracy: 0.9908 - val_loss: 1.0857e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0362 - accuracy: 0.9893 - val_loss: 1.2579e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0273 - accuracy: 0.9917 - val_loss: 2.9894e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0331 - accuracy: 0.9906 - val_loss: 4.0256e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0261 - accuracy: 0.9915 - val_loss: 2.5720e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 3.8605e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0229 - accuracy: 0.9927 - val_loss: 7.7674e-06 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0515 - accuracy: 0.9848 - val_loss: 5.9365e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0271 - accuracy: 0.9909 - val_loss: 2.1811e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0315 - accuracy: 0.9899 - val_loss: 7.6583e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0464 - accuracy: 0.9861 - val_loss: 3.5341e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0307 - accuracy: 0.9911 - val_loss: 3.7615e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0392 - accuracy: 0.9873 - val_loss: 3.4665e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0314 - accuracy: 0.9903 - val_loss: 6.4947e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0268 - accuracy: 0.9917 - val_loss: 3.9402e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0197 - accuracy: 0.9930 - val_loss: 6.3384e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0501 - accuracy: 0.9861 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0326 - accuracy: 0.9893 - val_loss: 6.2968e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0239 - accuracy: 0.9924 - val_loss: 2.0912e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0253 - accuracy: 0.9921 - val_loss: 5.0728e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0263 - accuracy: 0.9920 - val_loss: 1.8121e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0306 - accuracy: 0.9923 - val_loss: 3.6531e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0318 - accuracy: 0.9906 - val_loss: 6.6289e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0297 - accuracy: 0.9908 - val_loss: 2.3927e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0248 - accuracy: 0.9920 - val_loss: 5.3560e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0233 - accuracy: 0.9925 - val_loss: 7.4764e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0230 - accuracy: 0.9927 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0341 - accuracy: 0.9891 - val_loss: 9.2133e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0376 - accuracy: 0.9875 - val_loss: 5.0721e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0245 - accuracy: 0.9927 - val_loss: 5.1037e-04 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "1205d708-436c-4de2-fb26-d99ecf4b7fb4"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 7ms/step - loss: 0.0616 - accuracy: 0.9807\n",
            "Accuracy  : 0.9806867241859436\n",
            "F1_Score  : 0.9773839963240062\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "c859b36d-8ce4-41ba-e4fe-395ebd361ab4"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'#dominance\\nX_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\\nprint(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "8185f8d1-76db-425e-e377-7ff9d13c6e58"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'foldNum=0\\nmodel = get_model()\\nfor train_index, val_index in kfold.split(X_train, Y_train):\\n  foldNum = foldNum + 1\\n  print(\"Results for fold\",foldNum)\\n  x_train, x_val = X_train[train_index], X_train[val_index]\\n  y_train, y_val = Y_train[train_index], Y_train[val_index]\\n  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\\n  gc.collect() # Garbage collecter\\n  del x_train, x_val, y_train, y_val\\n  gc.collect()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "f0a0d85b-e87c-4f07-96be-7338a384e1f7"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'acrc = model.evaluate(x_test, y_test)\\npred = model.predict(x_test)\\nf1scr = f1_score(y_test.argmax(1), pred.argmax(1), average=\\'macro\\')\\nc_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\\nprint(\"Accuracy  : {}\".format(acrc[1]))\\nprint(\"F1_Score  : {}\".format(f1scr))\\nc_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\\nimport seaborn as sns\\nfigure = plt.figure(figsize=(9, 9))\\nsns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\\nplt.tight_layout()\\nplt.ylabel(\\'True label\\')\\nplt.xlabel(\\'Predicted label\\')\\nplt.show()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}