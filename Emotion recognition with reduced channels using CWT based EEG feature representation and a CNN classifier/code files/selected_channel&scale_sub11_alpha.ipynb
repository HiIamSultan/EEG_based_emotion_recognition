{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub11_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "7dae8beb-038a-41f0-de5b-d40c2273eb68"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e3\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  #EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "19e9443f-2bb7-419e-dc70-d9d43f51f041"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(11,12):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.11\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (2563,) (3029,) (3728,)\n",
            "(9320,) (4893,) (1631,) (2796,)\n",
            "(9320,) (2097,) (2563,) (4660,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "23c5a04c-395f-41ff-f156-02eb17754c8f"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "89e26a36-d4b3-43ab-d1fc-9425796858d1"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "622"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "435e59bf-4c04-4b40-b2c4-9faf775d3a40"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b4940b5-612c-40fb-da6a-9eb8c76eebbc"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 53s 95ms/step - loss: 1.2678 - accuracy: 0.3669 - val_loss: 1.0804 - val_accuracy: 0.4142\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0947 - accuracy: 0.3869 - val_loss: 1.0715 - val_accuracy: 0.4088\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 1.0889 - accuracy: 0.3957 - val_loss: 1.0704 - val_accuracy: 0.4330\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 1.0840 - accuracy: 0.4088 - val_loss: 1.0757 - val_accuracy: 0.4088\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0802 - accuracy: 0.4214 - val_loss: 1.0754 - val_accuracy: 0.4209\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 1.0821 - accuracy: 0.3977 - val_loss: 1.0701 - val_accuracy: 0.4209\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0779 - accuracy: 0.4106 - val_loss: 1.0685 - val_accuracy: 0.4263\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0816 - accuracy: 0.3995 - val_loss: 1.0706 - val_accuracy: 0.4316\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0844 - accuracy: 0.4021 - val_loss: 1.0725 - val_accuracy: 0.4088\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 1.0823 - accuracy: 0.4009 - val_loss: 1.0689 - val_accuracy: 0.4223\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0846 - accuracy: 0.3954 - val_loss: 1.0708 - val_accuracy: 0.4263\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0843 - accuracy: 0.3935 - val_loss: 1.0714 - val_accuracy: 0.4249\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 1.0787 - accuracy: 0.4093 - val_loss: 1.0683 - val_accuracy: 0.4290\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 1.0800 - accuracy: 0.4074 - val_loss: 1.0690 - val_accuracy: 0.4276\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0728 - accuracy: 0.4188 - val_loss: 1.0737 - val_accuracy: 0.4169\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0844 - accuracy: 0.4004 - val_loss: 1.0701 - val_accuracy: 0.4316\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 1.0805 - accuracy: 0.4059 - val_loss: 1.0676 - val_accuracy: 0.4303\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 1.0784 - accuracy: 0.4089 - val_loss: 1.0687 - val_accuracy: 0.4316\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 1.0779 - accuracy: 0.4088 - val_loss: 1.0778 - val_accuracy: 0.4276\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0817 - accuracy: 0.4028 - val_loss: 1.0704 - val_accuracy: 0.4303\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 1.0816 - accuracy: 0.4063 - val_loss: 1.0681 - val_accuracy: 0.4303\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 1.0753 - accuracy: 0.4085 - val_loss: 1.0717 - val_accuracy: 0.4303\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 1.0821 - accuracy: 0.3966 - val_loss: 1.0755 - val_accuracy: 0.4316\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 1.0768 - accuracy: 0.4109 - val_loss: 1.0714 - val_accuracy: 0.4343\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0788 - accuracy: 0.4029 - val_loss: 1.0702 - val_accuracy: 0.4290\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0785 - accuracy: 0.4121 - val_loss: 1.0738 - val_accuracy: 0.4290\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0785 - accuracy: 0.4002 - val_loss: 1.0652 - val_accuracy: 0.4343\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0809 - accuracy: 0.4012 - val_loss: 1.0742 - val_accuracy: 0.4357\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0763 - accuracy: 0.4087 - val_loss: 1.0664 - val_accuracy: 0.4263\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0851 - accuracy: 0.4018 - val_loss: 1.0699 - val_accuracy: 0.4249\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 1.0788 - accuracy: 0.4073 - val_loss: 1.0715 - val_accuracy: 0.4102\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0777 - accuracy: 0.4079 - val_loss: 1.0812 - val_accuracy: 0.4155\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0780 - accuracy: 0.4037 - val_loss: 1.0765 - val_accuracy: 0.4155\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0787 - accuracy: 0.4115 - val_loss: 1.0743 - val_accuracy: 0.4115\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 1.0786 - accuracy: 0.4082 - val_loss: 1.0791 - val_accuracy: 0.4155\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 1.0766 - accuracy: 0.4058 - val_loss: 1.0770 - val_accuracy: 0.4155\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0752 - accuracy: 0.4057 - val_loss: 1.0781 - val_accuracy: 0.4169\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0761 - accuracy: 0.4082 - val_loss: 1.0883 - val_accuracy: 0.4223\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 1.0802 - accuracy: 0.4057 - val_loss: 1.0723 - val_accuracy: 0.4223\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0769 - accuracy: 0.4061 - val_loss: 1.0694 - val_accuracy: 0.4169\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 1.0752 - accuracy: 0.4086 - val_loss: 1.0707 - val_accuracy: 0.4142\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 1.0761 - accuracy: 0.4097 - val_loss: 1.0831 - val_accuracy: 0.4196\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 1.0768 - accuracy: 0.4088 - val_loss: 1.0718 - val_accuracy: 0.4182\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0781 - accuracy: 0.4034 - val_loss: 1.0715 - val_accuracy: 0.4115\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 1.0788 - accuracy: 0.4040 - val_loss: 1.0754 - val_accuracy: 0.4196\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0740 - accuracy: 0.4148 - val_loss: 1.0720 - val_accuracy: 0.4182\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 1.0770 - accuracy: 0.4033 - val_loss: 1.0759 - val_accuracy: 0.4088\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 1.0783 - accuracy: 0.4119 - val_loss: 1.0729 - val_accuracy: 0.4182\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0758 - accuracy: 0.4107 - val_loss: 1.0681 - val_accuracy: 0.4129\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0733 - accuracy: 0.4055 - val_loss: 1.0812 - val_accuracy: 0.4169\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 69ms/step - loss: 1.0736 - accuracy: 0.4145 - val_loss: 1.0764 - val_accuracy: 0.4169\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 1.0752 - accuracy: 0.4156 - val_loss: 1.0715 - val_accuracy: 0.4155\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 1.0770 - accuracy: 0.4088 - val_loss: 1.0702 - val_accuracy: 0.4209\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 1.0735 - accuracy: 0.4207 - val_loss: 1.0698 - val_accuracy: 0.4155\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0743 - accuracy: 0.4092 - val_loss: 1.0739 - val_accuracy: 0.4102\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 1.0691 - accuracy: 0.4195 - val_loss: 1.0647 - val_accuracy: 0.4142\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0752 - accuracy: 0.4057 - val_loss: 1.0661 - val_accuracy: 0.4236\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0686 - accuracy: 0.4145 - val_loss: 1.0726 - val_accuracy: 0.4142\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 1.0701 - accuracy: 0.4149 - val_loss: 1.0665 - val_accuracy: 0.4075\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0681 - accuracy: 0.4161 - val_loss: 1.0549 - val_accuracy: 0.4290\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 1.0699 - accuracy: 0.4185 - val_loss: 1.0556 - val_accuracy: 0.4357\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 1.0672 - accuracy: 0.4234 - val_loss: 1.0712 - val_accuracy: 0.4383\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0644 - accuracy: 0.4180 - val_loss: 1.0668 - val_accuracy: 0.4276\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 1.0654 - accuracy: 0.4167 - val_loss: 1.0584 - val_accuracy: 0.4236\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0623 - accuracy: 0.4185 - val_loss: 1.0556 - val_accuracy: 0.4196\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 1.0614 - accuracy: 0.4183 - val_loss: 1.0576 - val_accuracy: 0.4223\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 1.0589 - accuracy: 0.4158 - val_loss: 1.0612 - val_accuracy: 0.4021\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 1.0595 - accuracy: 0.4218 - val_loss: 1.0640 - val_accuracy: 0.4370\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 1.0574 - accuracy: 0.4212 - val_loss: 1.0530 - val_accuracy: 0.4437\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 1.0517 - accuracy: 0.4280 - val_loss: 1.0517 - val_accuracy: 0.4316\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 1.0552 - accuracy: 0.4222 - val_loss: 1.0578 - val_accuracy: 0.4424\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0530 - accuracy: 0.4231 - val_loss: 1.0488 - val_accuracy: 0.4249\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0455 - accuracy: 0.4262 - val_loss: 1.0578 - val_accuracy: 0.4343\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 1.0404 - accuracy: 0.4277 - val_loss: 1.0601 - val_accuracy: 0.4424\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0396 - accuracy: 0.4259 - val_loss: 1.0343 - val_accuracy: 0.4504\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 1.0369 - accuracy: 0.4292 - val_loss: 1.0383 - val_accuracy: 0.4357\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 1.0352 - accuracy: 0.4322 - val_loss: 1.0495 - val_accuracy: 0.4383\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 1.0255 - accuracy: 0.4250 - val_loss: 1.0650 - val_accuracy: 0.4571\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 1.0303 - accuracy: 0.4294 - val_loss: 1.0218 - val_accuracy: 0.4383\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 1.0171 - accuracy: 0.4303 - val_loss: 1.0325 - val_accuracy: 0.4182\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 1.0130 - accuracy: 0.4356 - val_loss: 1.0235 - val_accuracy: 0.4276\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0119 - accuracy: 0.4398 - val_loss: 1.1906 - val_accuracy: 0.4249\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 1.0096 - accuracy: 0.4322 - val_loss: 1.0326 - val_accuracy: 0.4223\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 1.0029 - accuracy: 0.4586 - val_loss: 1.0165 - val_accuracy: 0.4249\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.9927 - accuracy: 0.4705 - val_loss: 1.0117 - val_accuracy: 0.4584\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.9942 - accuracy: 0.4683 - val_loss: 1.0053 - val_accuracy: 0.4410\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.9794 - accuracy: 0.4781 - val_loss: 1.0231 - val_accuracy: 0.4223\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9807 - accuracy: 0.4772 - val_loss: 0.9993 - val_accuracy: 0.4236\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9750 - accuracy: 0.4753 - val_loss: 0.9981 - val_accuracy: 0.4544\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.9588 - accuracy: 0.5006 - val_loss: 1.0021 - val_accuracy: 0.4343\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.9626 - accuracy: 0.4861 - val_loss: 0.9012 - val_accuracy: 0.5643\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.9540 - accuracy: 0.5082 - val_loss: 0.9450 - val_accuracy: 0.5523\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9474 - accuracy: 0.5076 - val_loss: 0.8812 - val_accuracy: 0.5684\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 0.9453 - accuracy: 0.5069 - val_loss: 0.9206 - val_accuracy: 0.5349\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.9405 - accuracy: 0.5177 - val_loss: 0.8747 - val_accuracy: 0.5657\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.9348 - accuracy: 0.5221 - val_loss: 0.8914 - val_accuracy: 0.5496\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 0.9197 - accuracy: 0.5341 - val_loss: 0.8599 - val_accuracy: 0.5710\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.9157 - accuracy: 0.5359 - val_loss: 0.8835 - val_accuracy: 0.5697\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8973 - accuracy: 0.5525 - val_loss: 0.8512 - val_accuracy: 0.6153\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.8825 - accuracy: 0.5541 - val_loss: 0.8844 - val_accuracy: 0.5724\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.8869 - accuracy: 0.5632 - val_loss: 0.8443 - val_accuracy: 0.6139\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 0.8671 - accuracy: 0.5756 - val_loss: 0.8057 - val_accuracy: 0.6220\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.8573 - accuracy: 0.5809 - val_loss: 0.8713 - val_accuracy: 0.5777\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8434 - accuracy: 0.5890 - val_loss: 0.7881 - val_accuracy: 0.6394\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.8269 - accuracy: 0.6013 - val_loss: 0.8015 - val_accuracy: 0.6273\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.8182 - accuracy: 0.6113 - val_loss: 0.7612 - val_accuracy: 0.6635\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.8034 - accuracy: 0.6195 - val_loss: 0.7566 - val_accuracy: 0.6702\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.7935 - accuracy: 0.6306 - val_loss: 0.7797 - val_accuracy: 0.6300\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.7706 - accuracy: 0.6368 - val_loss: 0.7275 - val_accuracy: 0.6769\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.7619 - accuracy: 0.6499 - val_loss: 0.7604 - val_accuracy: 0.6609\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.7536 - accuracy: 0.6539 - val_loss: 0.7432 - val_accuracy: 0.6836\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.7343 - accuracy: 0.6639 - val_loss: 0.6996 - val_accuracy: 0.6944\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.7198 - accuracy: 0.6794 - val_loss: 0.6808 - val_accuracy: 0.7118\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.7037 - accuracy: 0.6906 - val_loss: 0.6241 - val_accuracy: 0.7440\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.6930 - accuracy: 0.6957 - val_loss: 0.6423 - val_accuracy: 0.7319\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.6627 - accuracy: 0.7076 - val_loss: 0.6346 - val_accuracy: 0.7198\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.6700 - accuracy: 0.7027 - val_loss: 0.5813 - val_accuracy: 0.7708\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.6342 - accuracy: 0.7240 - val_loss: 0.5504 - val_accuracy: 0.7855\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.6055 - accuracy: 0.7455 - val_loss: 0.5243 - val_accuracy: 0.7855\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.6039 - accuracy: 0.7393 - val_loss: 0.5162 - val_accuracy: 0.8043\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.6013 - accuracy: 0.7504 - val_loss: 0.3779 - val_accuracy: 0.8552\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.6147 - accuracy: 0.7450 - val_loss: 0.4008 - val_accuracy: 0.8298\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.5616 - accuracy: 0.7697 - val_loss: 0.4058 - val_accuracy: 0.8070\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.5506 - accuracy: 0.7776 - val_loss: 0.3212 - val_accuracy: 0.8834\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.5174 - accuracy: 0.7902 - val_loss: 0.3607 - val_accuracy: 0.8566\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.4922 - accuracy: 0.8060 - val_loss: 0.3037 - val_accuracy: 0.9021\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.4864 - accuracy: 0.8088 - val_loss: 0.3594 - val_accuracy: 0.8552\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.4681 - accuracy: 0.8130 - val_loss: 0.2999 - val_accuracy: 0.8847\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.4638 - accuracy: 0.8116 - val_loss: 0.2773 - val_accuracy: 0.9021\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.4652 - accuracy: 0.8158 - val_loss: 0.2753 - val_accuracy: 0.9075\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.4304 - accuracy: 0.8264 - val_loss: 0.2657 - val_accuracy: 0.8995\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.4263 - accuracy: 0.8325 - val_loss: 0.2535 - val_accuracy: 0.9169\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.4031 - accuracy: 0.8431 - val_loss: 0.2342 - val_accuracy: 0.9142\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.4105 - accuracy: 0.8395 - val_loss: 0.2954 - val_accuracy: 0.8820\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.3747 - accuracy: 0.8557 - val_loss: 0.2958 - val_accuracy: 0.8552\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.3892 - accuracy: 0.8499 - val_loss: 0.3058 - val_accuracy: 0.8700\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.3375 - accuracy: 0.8677 - val_loss: 0.2613 - val_accuracy: 0.8995\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.3449 - accuracy: 0.8674 - val_loss: 0.2232 - val_accuracy: 0.9155\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.3395 - accuracy: 0.8703 - val_loss: 0.2216 - val_accuracy: 0.9223\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.3219 - accuracy: 0.8814 - val_loss: 0.1847 - val_accuracy: 0.9276\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.2907 - accuracy: 0.8908 - val_loss: 0.2130 - val_accuracy: 0.9115\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.2988 - accuracy: 0.8915 - val_loss: 0.2168 - val_accuracy: 0.9129\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.2931 - accuracy: 0.8911 - val_loss: 0.2555 - val_accuracy: 0.8968\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.2895 - accuracy: 0.8942 - val_loss: 0.1568 - val_accuracy: 0.9464\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.2713 - accuracy: 0.9013 - val_loss: 0.1655 - val_accuracy: 0.9316\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.2538 - accuracy: 0.9064 - val_loss: 0.1726 - val_accuracy: 0.9343\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.2720 - accuracy: 0.9046 - val_loss: 0.1746 - val_accuracy: 0.9330\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.2447 - accuracy: 0.9095 - val_loss: 0.1667 - val_accuracy: 0.9383\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.2437 - accuracy: 0.9094 - val_loss: 0.1569 - val_accuracy: 0.9357\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.2268 - accuracy: 0.9140 - val_loss: 0.1454 - val_accuracy: 0.9437\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.2700 - accuracy: 0.9021 - val_loss: 0.1516 - val_accuracy: 0.9263\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.2539 - accuracy: 0.9113 - val_loss: 0.0346 - val_accuracy: 0.9946\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.2406 - accuracy: 0.9161 - val_loss: 0.0397 - val_accuracy: 0.9946\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.2348 - accuracy: 0.9162 - val_loss: 0.0362 - val_accuracy: 0.9893\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.2228 - accuracy: 0.9206 - val_loss: 0.0466 - val_accuracy: 0.9839\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.2059 - accuracy: 0.9267 - val_loss: 0.0329 - val_accuracy: 0.9946\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.2048 - accuracy: 0.9313 - val_loss: 0.0315 - val_accuracy: 0.9946\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.2100 - accuracy: 0.9264 - val_loss: 0.0326 - val_accuracy: 0.9960\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.2133 - accuracy: 0.9265 - val_loss: 0.0376 - val_accuracy: 0.9933\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.1957 - accuracy: 0.9341 - val_loss: 0.0290 - val_accuracy: 0.9960\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1790 - accuracy: 0.9413 - val_loss: 0.0357 - val_accuracy: 0.9906\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.1732 - accuracy: 0.9417 - val_loss: 0.0354 - val_accuracy: 0.9933\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.1816 - accuracy: 0.9355 - val_loss: 0.0266 - val_accuracy: 0.9933\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.1896 - accuracy: 0.9368 - val_loss: 0.0310 - val_accuracy: 0.9920\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.1710 - accuracy: 0.9440 - val_loss: 0.0270 - val_accuracy: 0.9933\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.1694 - accuracy: 0.9425 - val_loss: 0.0343 - val_accuracy: 0.9906\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.1736 - accuracy: 0.9407 - val_loss: 0.0265 - val_accuracy: 0.9933\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.1552 - accuracy: 0.9475 - val_loss: 0.0255 - val_accuracy: 0.9973\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.1568 - accuracy: 0.9480 - val_loss: 0.0214 - val_accuracy: 0.9960\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.1759 - accuracy: 0.9417 - val_loss: 0.0195 - val_accuracy: 0.9973\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.1508 - accuracy: 0.9511 - val_loss: 0.0195 - val_accuracy: 0.9973\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.1419 - accuracy: 0.9529 - val_loss: 0.0278 - val_accuracy: 0.9920\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.1321 - accuracy: 0.9557 - val_loss: 0.0239 - val_accuracy: 0.9920\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1418 - accuracy: 0.9505 - val_loss: 0.0287 - val_accuracy: 0.9946\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.1540 - accuracy: 0.9492 - val_loss: 0.0510 - val_accuracy: 0.9826\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1283 - accuracy: 0.9601 - val_loss: 0.0302 - val_accuracy: 0.9906\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.1325 - accuracy: 0.9556 - val_loss: 0.0276 - val_accuracy: 0.9920\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.1392 - accuracy: 0.9532 - val_loss: 0.0290 - val_accuracy: 0.9893\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1421 - accuracy: 0.9532 - val_loss: 0.0232 - val_accuracy: 0.9933\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1180 - accuracy: 0.9639 - val_loss: 0.0167 - val_accuracy: 0.9973\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 81ms/step - loss: 0.1486 - accuracy: 0.9516 - val_loss: 0.0106 - val_accuracy: 0.9960\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.1334 - accuracy: 0.9571 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.1478 - accuracy: 0.9501 - val_loss: 0.0274 - val_accuracy: 0.9893\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1270 - accuracy: 0.9598 - val_loss: 0.0241 - val_accuracy: 0.9906\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.1271 - accuracy: 0.9575 - val_loss: 0.0126 - val_accuracy: 0.9946\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1203 - accuracy: 0.9613 - val_loss: 0.0180 - val_accuracy: 0.9933\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.1273 - accuracy: 0.9584 - val_loss: 0.0100 - val_accuracy: 0.9973\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1283 - accuracy: 0.9584 - val_loss: 0.0088 - val_accuracy: 0.9973\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.1078 - accuracy: 0.9663 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1188 - accuracy: 0.9638 - val_loss: 0.0097 - val_accuracy: 0.9973\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.1202 - accuracy: 0.9586 - val_loss: 0.0069 - val_accuracy: 0.9987\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.1349 - accuracy: 0.9546 - val_loss: 0.0104 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.1177 - accuracy: 0.9616 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1185 - accuracy: 0.9635 - val_loss: 0.0087 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.1093 - accuracy: 0.9632 - val_loss: 0.0098 - val_accuracy: 0.9973\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0987 - accuracy: 0.9687 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1163 - accuracy: 0.9648 - val_loss: 0.0158 - val_accuracy: 0.9919\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0965 - accuracy: 0.9681 - val_loss: 0.0155 - val_accuracy: 0.9906\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1003 - accuracy: 0.9699 - val_loss: 0.0132 - val_accuracy: 0.9933\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1088 - accuracy: 0.9654 - val_loss: 0.0278 - val_accuracy: 0.9893\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1382 - accuracy: 0.9540 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0989 - accuracy: 0.9657 - val_loss: 0.0099 - val_accuracy: 0.9960\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0960 - accuracy: 0.9705 - val_loss: 0.0102 - val_accuracy: 0.9960\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0870 - accuracy: 0.9712 - val_loss: 0.0075 - val_accuracy: 0.9960\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0990 - accuracy: 0.9669 - val_loss: 0.0075 - val_accuracy: 0.9973\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0990 - accuracy: 0.9668 - val_loss: 0.0107 - val_accuracy: 0.9960\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.0994 - accuracy: 0.9651 - val_loss: 0.0067 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.1011 - accuracy: 0.9684 - val_loss: 0.0109 - val_accuracy: 0.9973\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0925 - accuracy: 0.9718 - val_loss: 0.0059 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0833 - accuracy: 0.9765 - val_loss: 0.0067 - val_accuracy: 0.9987\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 78ms/step - loss: 0.0981 - accuracy: 0.9665 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0991 - accuracy: 0.9692 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0973 - accuracy: 0.9706 - val_loss: 9.2877e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.1109 - accuracy: 0.9627 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0909 - accuracy: 0.9699 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0820 - accuracy: 0.9730 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0978 - accuracy: 0.9665 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0863 - accuracy: 0.9751 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0923 - accuracy: 0.9708 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.1106 - accuracy: 0.9659 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0896 - accuracy: 0.9687 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0743 - accuracy: 0.9750 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0928 - accuracy: 0.9692 - val_loss: 0.0032 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0832 - accuracy: 0.9744 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0783 - accuracy: 0.9751 - val_loss: 0.0057 - val_accuracy: 0.9973\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0906 - accuracy: 0.9733 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0676 - accuracy: 0.9784 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0850 - accuracy: 0.9726 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0731 - accuracy: 0.9769 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0748 - accuracy: 0.9757 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0756 - accuracy: 0.9766 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0873 - accuracy: 0.9733 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0606 - accuracy: 0.9779 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0712 - accuracy: 0.9769 - val_loss: 0.0058 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0644 - accuracy: 0.9797 - val_loss: 0.0048 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0672 - accuracy: 0.9775 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0858 - accuracy: 0.9718 - val_loss: 0.0074 - val_accuracy: 0.9973\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0690 - accuracy: 0.9766 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0748 - accuracy: 0.9762 - val_loss: 0.0033 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0570 - accuracy: 0.9829 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 79ms/step - loss: 0.0862 - accuracy: 0.9723 - val_loss: 4.3198e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0789 - accuracy: 0.9739 - val_loss: 5.3278e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0832 - accuracy: 0.9735 - val_loss: 0.0034 - val_accuracy: 0.9987\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0705 - accuracy: 0.9757 - val_loss: 8.7425e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0691 - accuracy: 0.9779 - val_loss: 6.9720e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0690 - accuracy: 0.9768 - val_loss: 7.8802e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0961 - accuracy: 0.9687 - val_loss: 5.2288e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0865 - accuracy: 0.9714 - val_loss: 4.6921e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0612 - accuracy: 0.9820 - val_loss: 7.4584e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0615 - accuracy: 0.9815 - val_loss: 2.9448e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0652 - accuracy: 0.9800 - val_loss: 3.5298e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0612 - accuracy: 0.9802 - val_loss: 5.4187e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0580 - accuracy: 0.9799 - val_loss: 3.3674e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0663 - accuracy: 0.9768 - val_loss: 3.6713e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0512 - accuracy: 0.9818 - val_loss: 3.9191e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0646 - accuracy: 0.9809 - val_loss: 8.1151e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0678 - accuracy: 0.9778 - val_loss: 4.5777e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0716 - accuracy: 0.9765 - val_loss: 7.0885e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0731 - accuracy: 0.9769 - val_loss: 5.5407e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0554 - accuracy: 0.9820 - val_loss: 4.5900e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.0606 - accuracy: 0.9815 - val_loss: 8.2067e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0638 - accuracy: 0.9800 - val_loss: 5.4924e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0552 - accuracy: 0.9829 - val_loss: 4.9718e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0590 - accuracy: 0.9820 - val_loss: 6.3352e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0588 - accuracy: 0.9820 - val_loss: 7.5393e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0639 - accuracy: 0.9771 - val_loss: 6.8815e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0583 - accuracy: 0.9817 - val_loss: 5.6040e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0877 - accuracy: 0.9735 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0712 - accuracy: 0.9763 - val_loss: 0.0031 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0604 - accuracy: 0.9820 - val_loss: 3.8672e-04 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0711 - accuracy: 0.9772 - val_loss: 3.5266e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0578 - accuracy: 0.9820 - val_loss: 1.5272e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0628 - accuracy: 0.9818 - val_loss: 1.4526e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0640 - accuracy: 0.9797 - val_loss: 3.8556e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0569 - accuracy: 0.9815 - val_loss: 1.9954e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0568 - accuracy: 0.9830 - val_loss: 1.4843e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0561 - accuracy: 0.9824 - val_loss: 1.9755e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0494 - accuracy: 0.9833 - val_loss: 1.4013e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0522 - accuracy: 0.9827 - val_loss: 2.1721e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0794 - accuracy: 0.9759 - val_loss: 2.0093e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0611 - accuracy: 0.9815 - val_loss: 2.9494e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0508 - accuracy: 0.9848 - val_loss: 2.2697e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0562 - accuracy: 0.9824 - val_loss: 1.5376e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0550 - accuracy: 0.9833 - val_loss: 2.2084e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0556 - accuracy: 0.9827 - val_loss: 1.5244e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0540 - accuracy: 0.9814 - val_loss: 8.0189e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0673 - accuracy: 0.9774 - val_loss: 3.0811e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0545 - accuracy: 0.9841 - val_loss: 4.2861e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0640 - accuracy: 0.9794 - val_loss: 3.0879e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0499 - accuracy: 0.9838 - val_loss: 1.9047e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0660 - accuracy: 0.9788 - val_loss: 1.2503e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0640 - accuracy: 0.9788 - val_loss: 4.1756e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0544 - accuracy: 0.9830 - val_loss: 1.7547e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0633 - accuracy: 0.9799 - val_loss: 9.7551e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0555 - accuracy: 0.9829 - val_loss: 0.0078 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0426 - accuracy: 0.9866 - val_loss: 2.6821e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0514 - accuracy: 0.9832 - val_loss: 2.2765e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0484 - accuracy: 0.9844 - val_loss: 2.1331e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0807 - accuracy: 0.9744 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0578 - accuracy: 0.9838 - val_loss: 3.4656e-04 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "CAnc2SJa3o9f",
        "outputId": "7e2a835f-1296-47a0-f8b9-6c1767ebcd4a"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 12ms/step - loss: 0.0497 - accuracy: 0.9850\n",
            "Accuracy  : 0.9849785566329956\n",
            "F1_Score  : 0.9846162298092024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAAKOCAYAAAAS8uXWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debQdVZk34N9OQpgTFEmiEGa6UQZlFpUpGEiYwiAoTt22itIggoKAU7d8iiIKaCM2g7Zja4OARBMICiKDTBGVWQ2IkAiJIoMgGnLZ3x/3EpKQyejN2cl5HtdZ65yqOnV2sWpd3/ze2lWl1hoAANoxoNMDAABgbgo0AIDGKNAAABqjQAMAaIwCDQCgMYM6PYAFWXnbY0wvpeMe/slpnR4CJElKKZ0eAiRJVl4hHTkZV97qyI7VBU/97MylfswSNACAxijQAAAa02yLEwBgttJdmVJ3HS0AwDJAgQYA0BgtTgCgfV02k1mCBgDQGAkaANA+kwQAAOgkCRoA0D7XoAEA0EkKNACAxmhxAgDtM0kAAIBOkqABAO0zSQAAgE5SoAEANEaLEwBon0kCAAB0kgQNAGifSQIAAHSSBA0AaJ9r0AAA6CQFGgBAY7Q4AYD2mSQAAEAnSdAAgPaZJAAAQCdJ0ACA9rkGDQCATlKgAQA0RosTAGifSQIAAHSSBA0AaJ8EDQCATlKgAQA0RosTAGjfAPdBAwCggyRoAED7TBIAAKCTJGgAQPs8ixMAgE5SoAEANEaLEwBon0kCAAB0kgQNAGifSQIAAHSSAg0AoDFanABA+0wSAACgkyRoAED7TBIAAKCTJGgAQPtcgwYAQCcp0AAAGqPFCQC0zyQBAAA6SYIGALTPJAEAADpJggYAtM81aAAAdJICDQCgMVqcAED7TBIAAKCTJGgAQPskaAAAdJICDQCgMVqcAED73AcNAIBOkqABAO0zSQAAgE6SoAEA7XMNGgAAnaRAAwBojBYnANA+kwQAAOgkCRoA0D6TBAAA6CQJGgDQvCJBAwCgkxRoAACN0eIEAJqnxQkAQEdJ0ACA9nVXgCZBAwBojQINAKAxWpwAQPNMEgAAoKMkaABA8yRoAAB0lAQNAGieBA0AgI5SoAEANEaLEwBonhYnAAAdJUEDANrXXQGaBA0AoDUKtGXU6B03zS8uPDG3X/zBHPsvuz9v/bojXpCJZx2em751XCadfUTWHjZ09rpPHLVvfvp/x+dnF5yQzx57wNIcNsuB6669JvvvOyb77bVHvnzeOc9bP3PmzBx/7DHZb6898pY3HpLfTZuaJHn00Ufyzn97a161/db51CdOmu++3/uew/O6A/bt1/GzbLvu2qszbp89s+/Y0Qs8/z7w/qOz79jRefOhB2da3/mXJF869+zsO3Z0xu2zZ35y3TWzl4/dY1Red8C+OeSgcXnjIQfOXn733XflLW88ZPby2267tX8PjoUqpXTs1QkKtGXQgAElZxx/UMYddU62OviUHLznVtl0g+FzbfPJo/fLNydMzvaHnpqTz52Uk47cJ0nyyi3Xz44v3yDbHfrpbPP6U7LNy9bNTtts1InDYBnU09OTT33ipJx51rm58JLv57JLJ+See6bMtc13L/pOVh8yJOMnXp43veVf8rnTP5skWXHwivn3I9+bY479wHz3fcUPL88qK6/S78fAsqunpyef/PhJ+cIXz8tF4yfksonff975d/FFF2TIkCH53qU/yJvf8q/53GmfSZLcc8+UTLp0Qi68ZELO+u/zcvL/+1h6enpmf+/cL3815194Sf73/ItmLzvjs6fmXYcfkfMvvCSHH/nenPHZU5fOgUL6sUArpWxaSjm+lPL5vtfxpZSX9tfvdZPtNls39zzwh9w37eE8PasnF1z+s+yzy+ZzbbPpBiPy48m/TpL8ePKU7LNz7/paa1YcPCiDVxiUFVcYlEGDBmbGw39a6sfAsun2227NyHXXzTojR2aFFQZnz7F75aofXTHXNlf96Irsu9/+SZLXjt4zN914fWqtWXmVVbLV1ttkxcGDn7ffP//5yXzja1/JO951+FI5DpZNveffenOcf3vnqivnOf+uvDL7juvtDLx2j+fOv6uuvCJ7jt07gwcPztrrjMzIddfL7YtIxEopefKJJ5MkTzzxp6w1bFj/HBjMR78UaKWU45N8O72X9N3U9ypJvlVKOaE/frObvGTYGpk6/dHZn6fNeGyuFmaS3PbraRm325ZJknG7bZEhq62UFw5dJTfe9ttcPXlKfnPZx/KbSR/LD2+4O7+8b8ZSHT/Lrhkzpmf4iBfP/jx8+Ij8fvr0ebaZkRF92wwaNCirrbZ6Hn300SzMWf/1+bzlX96WlVda6R8/aJYbM2ZMz4gRI2Z/Hj58eGbMmPf8mz6f8++RhX63lOTww96eQw85MN+54P9mb3Pc8R/M6Z/9dPbcfZec9plTctTR7+vPw2MRtDj/Md6eZLta66dqrd/oe30qyfZ96+arlHJYKWVyKWXyrN/f1k9D6w4nnjE+O229Ua7/5vuz09YbZ9r0R9PT80w2XOdF+ecNhmfjvf4zG439z+y67SZ59Ss27PRw6WK/vPuuPDD1/ozafXSnh0KX+p+vfSvfvuDifOGL5+b8b30zP518c5Lkgv/7Vo49/sRMuuLHOfYDJ+ZjH/1Qh0dKN+mvAu2ZJC+Zz/IX962br1rrObXWbWut2w5aa4t+Gtqy73czHs06w9eY/XntYUMzbcZjc23z4B8ezxs+8D/Z8U2fzX+cNSFJ8tgTf8m43bbITbfdlyefmpknn5qZST+5Kztsuf7SHD7LsGHDhmf6Qw/O/jx9+kNZa/jwebYZlof6tpk1a1aeeOJPWWONNbIgv/jFz3PnHbdnrz1H5W1vfVN+e999ecfb3tI/B8Aybdiw4XnooYdmf54+fXqGDZv3/Bs+n/PvBQv97vC+c/iFa66Z3XYfPbv1+b3xF2f31+6RJNljz7GLbInSvyRo/xhHJ7milHJpKeWcvtdlSa5I8t5++s2uMfnOB7LxyLWy3ktemBUGDczBe2yVCVffMdc2aw5ddfZJddzbXpuvjr8xSfLAQ49kp603zsCBAzJo4IDstPVGufs305/3GzA/m22+Re7/7W8zberUPP30zEy6dGJ23XXUXNvssuuofG/8d5MkP/zBpGy3/SsX+gfukNcfmh9ceU0mTroy//O1b2a99dfPef/z9X49DpZNm22+Re6//75Mm/pA3/k3IbvsNs/5t9uofO+Si5MkP7x8Urbboff822W3UZl06YTMnDkz06Y+kPvvvy+bb7Flnvrzn/Pkk08kSZ76859z/U+uy8abbJIkWWutYZl8801JkptuvCHrrrf+0jtYul6/3Ki21npZKeWf0tvSXLtv8bQkN9daexb8TRZHT88zOebUC/O9/3pXBg4ckK+OvzF33ftQPvKuMbnlrgcy4eo7svO2G+ekI/ZOrTXX/uzeHH3Kd5IkF13xi+yy3SaZ/O0PpNaaH1x/dyZec8cifhF6DRo0KMd/8CP593e/Pc/0PJNxBxyUjTbeJGed+fm8bLPNs+tuo7L/ga/Lh0/8QPbba48MGTo0n/r0abO/v9eeo/LkE0/m6aefzo+uvCJnnfOlbLTRxh08IpYlgwYNygkf/GgOf9c78kxPT8YdcFA23niTnHXm5/rOv91zwIGvy4dOPC77jh2dIUOH5pRTT0+SbLzxJhm959gcuN9eGThoYE780EczcODAPPzww3nfe49Ikszq6cnYvfbJq1+zc5Lkox/7f/n0p05Oz6xZGbziivnIf8z/9jDQH0qttdNjmK+Vtz2mzYHRVR7+yWmL3giWgm57DiHtWnmFztzTf823fqtjdcHDXzt0qR+z+6ABADTGszgBgPZ1WYgsQQMAaIwEDQBoXrddhylBAwBojAINAKAxWpwAQPO0OAEA6CgJGgDQPAkaAAAdpUADAPg7lFLGlFJ+WUqZUko5YT7r1y2l/KiU8rNSyq2llL0WtU8FGgDQvtLB18KGVcrAJF9IMjbJy5IcWkp52TybfTjJ+bXWrZK8IclZizpcBRoAwJLbPsmUWuu9tdaZSb6dZNw829QkQ/reD03yu0Xt1CQBAKB5nZwkUEo5LMlhcyw6p9Z6Tt/7tZM8MMe6qUl2mGcX/5nk8lLKe5KsmuS1i/pNBRoAwEL0FWPnLHLDBTs0yVdqrZ8tpeyY5OullM1rrc8s6AsKNACgeQ3fZmNakpFzfF6nb9mc3p5kTJLUWq8vpayU5EVJZixop65BAwBYcjcn2aSUskEpZXB6JwGMn2eb+5PsniSllJcmWSnJ7xe2UwUaAMASqrXOSnJkkklJ7krvbM07SiknlVL269vs/UneWUr5RZJvJfnXWmtd2H61OAGA5jXc4kytdWKSifMs++gc7+9M8uq/ZZ8SNACAxkjQAIDmtZyg9QcJGgBAYyRoAED7uitAk6ABALRGgQYA0BgtTgCgeSYJAADQURI0AKB5EjQAADpKgQYA0BgtTgCgeVqcAAB0lAQNAGhfdwVoEjQAgNZI0ACA5rkGDQCAjlKgAQA0RosTAGieFicAAB0lQQMAmidBAwCgoyRoAEDzJGgAAHSUAg0AoDFanABA+7qrwylBAwBojQQNAGieSQIAAHSUAg0AoDFanABA87Q4AQDoKAkaANC8LgvQJGgAAK2RoAEAzXMNGgAAHaVAAwBojBYnANC8LutwStAAAFojQQMAmmeSAAAAHaVAAwBojBYnANC8LutwStAAAFojQQMAmjdgQHdFaBI0AIDGSNAAgOa5Bg0AgI5SoAEANEaLEwBonicJAADQURI0AKB5XRagSdAAAFojQQMAmucaNAAAOkqBBgDQGC1OAKB5WpwAAHSUBA0AaF6XBWgSNACA1ijQAAAao8UJADTPJAEAADpKggYANK/LAjQJGgBAayRoAEDzXIMGAEBHKdAAABqjxQkANK/LOpwSNACA1kjQAIDmmSQAAEBHSdAAgOZ1WYAmQQMAaI0CDQCgMVqcAEDzTBIAAKCjmk3QHrnh9E4PAfKC7Y7s9BAgSfLIzWd2egjQUV0WoEnQAABao0ADAGhMsy1OAIBnmSQAAEBHSdAAgOZ1WYAmQQMAaI0EDQBonmvQAADoKAUaAEBjtDgBgOZ1WYdTggYA0BoJGgDQPJMEAADoKAUaAEBjtDgBgOZpcQIA0FESNACgeV0WoEnQAABaI0EDAJrnGjQAADpKgQYA0BgtTgCgeV3W4ZSgAQC0RoIGADTPJAEAADpKggYANK/LAjQJGgBAaxRoAACN0eIEAJo3oMt6nBI0AIDGSNAAgOZ1WYAmQQMAaI0CDQCgMVqcAEDzPEkAAICOUqABAM0bUDr3WpRSyphSyi9LKVNKKScsYJtDSil3llLuKKX876L2qcUJALCESikDk3whyegkU5PcXEoZX2u9c45tNklyYpJX11ofKaUMW9R+FWgAQPMavgZt+yRTaq33Jkkp5dtJxiW5c45t3pnkC7XWR5Kk1jpjUTvV4gQAWHJrJ3lgjs9T+5bN6Z+S/FMp5bpSyg2llDGL2qkEDQBgIUophyU5bI5F59Raz/kbdjEoySZJdk2yTpKrSylb1FofXdgXAACa1skOZ18xtqCCbFqSkXN8Xqdv2ZymJrmx1vp0kt+UUn6V3oLt5gX9phYnAMCSuznJJqWUDUopg5O8Icn4ebb5bnrTs5RSXpTelue9C9upBA0AaF5Jm5MEaq2zSilHJpmUZGCSL9da7yilnJRkcq11fN+6PUopdybpSXJcrfXhhe1XgQYA8HeotU5MMnGeZR+d431N8r6+12JRoAEAzVucG8YuT1yDBgDQGAUaAEBjtDgBgOY1/CSBfiFBAwBojAQNAGhelwVoEjQAgNYo0AAAGqPFCQA0b0CX9TglaAAAjZGgAQDN67IATYIGANAaCRoA0Dw3qgUAoKMUaAAAjdHiBACa12UdTgkaAEBrJGgAQPPcqBYAgI5SoAEANEaLEwBoXnc1OCVoAADNkaABAM3zJAEAADpKggYANG9AdwVoEjQAgNYo0AAAGqPFCQA0zyQBAAA6SoIGADSvywI0CRoAQGskaABA81yDBgBARynQAAAao8UJADSv254ksMACrZTyX0nqgtbXWo/qlxEBAHS5hSVok5faKAAAFqLbJgkssECrtX51zs+llFVqrX/u/yEBAHS3RU4SKKXsWEq5M8ndfZ9fXko5q99HBgDQpRZnFucZSfZM8nCS1Fp/kWTn/hwUAMCcSgdfnbBYt9motT4wz6KefhgLAABZvNtsPFBKeVWSWkpZIcl7k9zVv8MCAHjOgC6bJLA4Cdq7kxyRZO0kv0vyir7PAAD0g0UmaLXWPyR501IYCwDAfHVZgLZYszg3LKV8r5Ty+1LKjFLKJaWUDZfG4AAAutHitDj/N8n5SV6c5CVJLkjyrf4cFABAN1ucAm2VWuvXa62z+l7fSLJSfw8MAOBZpZSOvTphYc/ifGHf20tLKSck+XZ6n835+iQTl8LYAAC60sImCfw0vQXZs6Xju+ZYV5Oc2F+DAgCYU7dNEljYszg3WJoDAQCg1+LcqDallM2TvCxzXHtWa/1afw0KAGBO3Xaj2kUWaKWU/0iya3oLtIlJxia5NokCDQCgHyzOLM7XJdk9yUO11rcleXmSof06KgCALrY4BdpTtdZnkswqpQxJMiPJyP4dFs+67pqrs9/ee2afMaPzpXPPed76mTNn5rj3H519xozOm95wcKZNmzp73ZfOPTv7jBmd/fbeM9dde02S5K9//Wve+PrX5eAD9ssB++2ds878/PP2+amTP55XbrtV/x0Uy43Rr3ppfnHxR3L7Jf+RY982+nnr133xCzLxv9+Tm/7vxEw6971Ze9gas9d9/KhxmXzBBzP5gg/mdXtsvTSHzTLsH/03MUk++uETs+tOO+bAcfvMta/j3n90DjlwXA45cFzGjh6VQw4c138HxiKV0rlXJyxOgTa5lLJGknPTO7PzliTX9+uoSJL09PTk5E+clLP++7xcPH5CLpv4/dwzZcpc21x84QUZMmRIvn/ZD/Lmt/5rzjjtM0mSe6ZMyWUTJ+Si8RNy1tnn5eSPfyw9PT0ZPHhwzvvyV3PBxeNz/oXfzXXXXpNbf/Hz2fu74/bb8vjjjy3V42TZNGBAyRknHJJxR56VrQ76eA4es0023XDEXNt88pgD8s0JN2X7138yJ59zaU56z35JkjGv2SyveOnI7PCGT2Xnt3wmR79196y+qtsrsnD98TcxScbtf2C+ePZ5z/u9Uz97Rs6/6JKcf9El2X30Hhn12uf/IwT6yyILtFrrv9daH621/neS0Un+pa/VST+7/bZbM3Lkelln5MisMHhwxuy1d6760RVzbfOjK6/MfuMOSJKM3mPP3HTD9am15qofXZExe+2dwYMHZ511RmbkyPVy+223ppSSVVZdNUkya9aszJo1a/Y/D3p6enLaZz6dY95/3NI9UJZJ222+fu554A+5b9rDeXpWTy6YdEv22XXLubbZdMMX58c3/TJJ8uObf5V9dt0iSfLSDUfk2lumpKfnmfz5LzNz26+nZY9XvXSpHwPLlv74m5gk22y7XYYMXfCVO7XWXD7p0ozde58FbkP/67Yb1S6wQCulbD3vK8kLkwzqe79ESimKu8U0Y/r0jHjxc4nEsOHDM3369Lm3mTE9I0a8OEkyaNCgrLb66nn00Ucyffr0DB/x3HeHjxieGX3f7enpySEHjstuO70qr9zxVdlyy5cnSb79v9/IrrvtnrXWGtbfh8Zy4CXDhmbq9Edmf542/ZGsvdbc/yd326+mZdyoVyRJxo16eYastnJeOHTV3Pqr3oJs5ZVWyJprrJpdtv2nrDPiBUt1/Cx7+utv4qLc8tPJWXPNNbPeeuv//QcBi2lhszg/u5B1NcmoJfzNjyX5n/mtKKUcluSwJDnzrLPz9ncetoQ/wcIMHDgw5190SR5//PEcc9QR+fWvf5WhQ4fm8kmX5Utf+Xqnh8dy5MTTL87pxx+cN++3Q667ZUqmTX8kPT3P5Iob7s42m62XH33l/fnDI0/kxlt/k56eZzo9XJivSyd+P2P2kp6xdC3sRrW7LelOSym3LmhVkuEL+c1zkpyTJH+Zlbqkv7+8GDZ8eB568KHZn2dMn57hw+f+zzds2PA89NCDGT5iRGbNmpUn/vSnrLHGCzJ8+PBMf+i5705/aHqGzfPdIUOGZLvtd8hPrr0mG2y4UR64//7sO3aPJMlf/vJU9hkzOt+/7Af9eIQsy34347GsM/y51Gvt4S/ItN/Pff3ig79/LG84tvfanlVXHpz9d39FHnviqSTJp780KZ/+0qQkyVdO/tf8+v4ZS2nkLKv6+2/i/MyaNStX/PAH+fb5F/3jDoQlsjgXzS9P+ut4hyd5a5J95/N6uJ9+c7mz2eZb5P7778vUqQ/k6Zkzc9nECdllt7mDy113G5Xxl1ycJPnB5ZOy/Q6vTCklu+w2KpdNnJCZM2dm6tQHcv/992XzLbbMH//4xzz++ONJkr/85S+54fqfZP0NNszOu+yaK6++Lpf+4Mpc+oMrs9JKKyvOWKjJd/w2G6+7VtZ7yZpZYdDAHLzn1plw1dz/NltzjVVnX79x3L/tma9eckOS3gkGLxzaey3k5pu8JJtv8pL88Pq7l+4BsMzpj7+Ji3Lj9T/JBhtsOFd7FJaGxXqSwBL4fpLVaq0/n3dFKeWqfvrN5c6gQYNy4oc+msMPe0eeeaYn+x9wUDbeeJN84b8+l8022zy7jto9Bxz0unzohOOyz5jRGTJ0aD79mdOTJBtvvEn2GDM2B+y3VwYOHJgPfvijGThwYP7w+xn58AdPyDPP9OSZZ2r22HNMdtl1icNSulhPzzM55pTz872zjsjAASVfveSG3HXvQ/nI4Xvnljvvz4Qf35adt90kJ71nv9SaXHvLlBz9yfOTJCsMGpgffvnoJMmfnvhL/u1DX9XiZJH6429ikhx/7Psy+eab8uijj2T0qJ1z+BHvyYEHHZwkuezSiRmz194dO2ae06mL9Tul1NpmJ1GLkxa8YLsjOz0ESJI8cvOZnR4CJElWGpSOVEpHfffujtUFn99/06V+zIvzqKeS5E1JNqy1nlRKWTfJiFrrTf0+OgCAJAO6K0BbrGvQzkqyY5JD+z7/KckX+m1EAABdbnGuQduh1rp1KeVnSVJrfaSUMrifxwUA0LUWp0B7upQyML33PkspZa0kruYFAJYaLc7n+3ySi5MMK6V8Ism1SU7u11EBAHSxRSZotdZvllJ+mmT39N5odv9a6139PjIAgD7ddpuNxZnFuW6SPyf53pzLaq339+fAAAC61eJcgzYhvdeflSQrJdkgyS+TbNaP4wIA6FqL0+LcYs7PpZStk/x7v40IAGAeJgksQq31liQ79MNYAADI4l2D9r45Pg5IsnWS3/XbiAAA5tFlcwQW6xq01ed4Pyu916Rd2D/DAQBgoQVa3w1qV6+1HruUxgMA8DwDuixCW+A1aKWUQbXWniSvXorjAQDoegtL0G5K7/VmPy+ljE9yQZInn11Za72on8cGANCVFucatJWSPJxkVJ67H1pNokADAJaKv/m2E8u4hRVow/pmcN6e5wqzZ9V+HRUAQBdbWIE2MMlqmbswe5YCDQBYarpsjsBCC7QHa60nLbWRAACQZOEFWpfVqgBAq9xm4zm7L7VRAAAw2wILtFrrH5fmQAAA6LU4t9kAAOioLutwdt1tRQAAmidBAwCaN0CCBgBAJynQAAAao8UJADTPfdAAAOgoCRoA0LwuC9AkaAAArZGgAQDNc5sNAAA6SoEGANAYLU4AoHkl3dXjlKABADRGggYANM8kAQAAOkqCBgA0T4IGAEBHKdAAABqjxQkANK902cM4JWgAAI2RoAEAzTNJAACAjlKgAQA0RosTAGhel80RkKABALRGggYANG9Al0VoEjQAgMZI0ACA5rnNBgAAHaVAAwD4O5RSxpRSfllKmVJKOWEh2x1USqmllG0XtU8tTgCgea3OESilDEzyhSSjk0xNcnMpZXyt9c55tls9yXuT3Lg4+5WgAQAsue2TTKm13ltrnZnk20nGzWe7/5fklCR/WZydKtAAgOYNSOnYq5RyWCll8hyvw+YY2tpJHpjj89S+ZbOVUrZOMrLWOmFxj1eLEwBgIWqt5yQ5Z0m+W0oZkOS0JP/6t3xPgQYANK/Va9CSTEsyco7P6/Qte9bqSTZPclXpPYgRScaXUvartU5e0E61OAEAltzNSTYppWxQShmc5A1Jxj+7stb6WK31RbXW9Wut6ye5IclCi7NEgQYAsMRqrbOSHJlkUpK7kpxfa72jlHJSKWW/Jd2vFicA0LyWnyRQa52YZOI8yz66gG13XZx9StAAABojQQMAmjeg4VkC/UGCBgDQGAUaAEBjtDgBgOZ1WYdTggYA0BoJGgDQPJMEAADoKAkaANC8LgvQJGgAAK1RoAEANEaLEwBoXrclSt12vAAAzZOgAQDNK102S0CCBgDQGAUaAEBjtDgBgOZ1V4NTggYA0BwJGgDQPM/iBACgoyRoAEDzuis/k6ABADRHgQYA0BgtTgCgeV02R0CCBgDQGgkaANA8z+IEAKCjJGgAQPO6LVHqtuMFAGieAg0AoDFanABA80wSAACgoyRoAEDzuis/k6ABADRHgQYA0JhmW5y1dnoEkDx80391egiQJHnBK4/p9BAgSfLU5NM78rsmCQAA0FHNJmgAAM/qtkSp244XAKB5EjQAoHmuQQMAoKMUaAAAjdHiBACa110NTgkaAEBzJGgAQPO6bI6ABA0AoDUSNACgeQO67Co0CRoAQGMUaAAAjdHiBACaZ5IAAAAdJUEDAJpXTBIAAKCTFGgAAI3R4gQAmmeSAAAAHSVBAwCa50kCAAB0lAQNAGiea9AAAOgoBRoAQGO0OAGA5mlxAgDQURI0AKB5nsUJAEBHKdAAABqjxQkANG9Ad3U4JWgAAK2RoAEAzTNJAACAjpKgAQDNc6NaAAA6SoEGANAYLU4AoHkmCQAA0FESNACgeW5UCwBAR0nQAIDmuQYNAICOUqABADRGixMAaJ4nCQAA0FESNACged42QHYAABGeSURBVF0WoEnQAABao0ADAGiMFicA0LwBXTZLQIIGANAYCRoA0Lzuys8kaAAAzZGgAQDt67IITYIGANAYBRoAQGO0OAGA5pUu63FK0AAAGiNBAwCa12X3qZWgAQC0RoIGADSvywI0CRoAQGsUaAAAjdHiBADa12U9TgkaAEBjJGgAQPPcqBYAgI5SoAEANEaLEwBonicJAADQURI0AKB5XRagSdAAAFojQQMA2tdlEZoEDQCgMQo0AIDGaHECAM3zJAEAADpKggYANM+NagEAWGyllDGllF+WUqaUUk6Yz/r3lVLuLKXcWkq5opSy3qL2qUADAFhCpZSBSb6QZGySlyU5tJTysnk2+1mSbWutWyb5TpJPL2q/CjQAoHmlg69F2D7JlFrrvbXWmUm+nWTcnBvUWn9Ua/1z38cbkqyzqJ0q0AAAFqKUclgpZfIcr8PmWL12kgfm+Dy1b9mCvD3JpYv6TZMEAID2dXCSQK31nCTn/L37KaW8Ocm2SXZZ1LYKNACAJTctycg5Pq/Tt2wupZTXJvlQkl1qrX9d1E4VaABA8xq+Ue3NSTYppWyQ3sLsDUneOOcGpZStkpydZEytdcbi7NQ1aAAAS6jWOivJkUkmJbkryfm11jtKKSeVUvbr2+zUJKsluaCU8vNSyvhF7VeCBgDwd6i1TkwycZ5lH53j/Wv/1n0q0ACA5nmSAAAAHSVBAwCa12UBmgQNAKA1EjQAoH1dFqFJ0AAAGqNAAwBojBYnANC8hp8k0C8kaAAAjZGgAQDNc6NamnLdtVdn3D57Zt+xo/Pl88553vqZM2fmA+8/OvuOHZ03H3pwpk2bOnvdl849O/uOHZ1x++yZn1x3zezl3/z6V3PQ/vvkwHF75xtf/8rs5ad95pTsv++YHHzAvjnmqCPy+OOP9+uxsWy67tprsv8+Y7Lf2D0WeE4e//5jst/YPfKWQw/J7/rOyUcffSTvfNtb86rtts6nPnHSXN8583OnZ8zuu+ZV2229VI6B5c/oHTfNLy48Mbdf/MEc+y+7P2/9uiNekIlnHZ6bvnVcJp19RNYeNnT2uk8ctW9++n/H52cXnJDPHnvA0hw2LJACrWE9PT355MdPyhe+eF4uGj8hl038fu65Z8pc21x80QUZMmRIvnfpD/Lmt/xrPnfaZ5Ik99wzJZMunZALL5mQs/77vJz8/z6Wnp6eTPn1r3LRhRfkG9+6IOdfeEmu+fFVuf/+3yZJXrnjq/Odi7+fCy7+XtZbf/18+byzl/ox07aenp586uMn5cwvnpsLx38/l02c8Lxz8rsXfSerDxmS8Zdenje95V/yudM+myRZcfCK+ff3vDfHHPuB5+135113y9e/ff5SOQaWPwMGlJxx/EEZd9Q52ergU3Lwnltl0w2Gz7XNJ4/eL9+cMDnbH3pqTj53Uk46cp8kySu3XD87vnyDbHfop7PN60/JNi9bNztts1EnDgPm0m8FWill01LK7qWU1eZZPqa/fnN5c/ttt2bkuutlnZEjs8IKg7Pn2L1z1ZVXzLXNVVdemX3H9f6L77V77Jmbbrw+tdZcdeUV2XPs3hk8eHDWXmdkRq67Xm6/7dbce+892WKLLbPyyitn0KBB2Wbb7XLFDy9Pkrzq1a/JoEG9Xe8tt3xFpk9/aOkeMM3rPSfXneOc3Gs+5+QV2Xfc/knmPidXXmWVbLX1NllxxcHP2++WL39F1lpr2FI5BpY/2222bu554A+5b9rDeXpWTy64/GfZZ5fN59pm0w1G5MeTf50k+fHkKdln5971tdasOHhQBq8wKCuuMCiDBg3MjIf/tNSPgUUrHXx1Qr8UaKWUo5JckuQ9SW4vpYybY/XJ/fGby6MZM6ZnxIgRsz8PHz48M2ZMn882L06SDBo0KKuttnoeffSRBX53443/Kbfc8tM8+ugjeeqpp3LtNVdn+kPPL8S+e/GFec1rdu6nI2NZNWPG9AzvO9+SZPjwEfn9887JGfM5Jx9dquOku7xk2BqZOv25c2zajMfmamEmyW2/npZxu22ZJBm32xYZstpKeeHQVXLjbb/N1ZOn5DeXfSy/mfSx/PCGu/PL+2Ys1fHD/PRXgvbOJNvUWvdPsmuSj5RS3tu3boHFaCnlsFLK5FLK5C/N59oW/n4bbrRR3vZv78jhh709R7z7Hfnnf940AwbMfRqce/YXM3DgwOy1z34dGiXAP9aJZ4zPTltvlOu/+f7stPXGmTb90fT0PJMN13lR/nmD4dl4r//MRmP/M7tuu0le/YoNOz1c5qfLIrT+msU5oNb6RJLUWu8rpeya5DullPWykEOttZ6T5Jwkeerp1H4a2zJj2LDheWiOdGv69OkZNmz4fLZ5MMNHjMisWbPyxBN/yhprvGCh3z3goINzwEEHJ0k+f8ZpGT7iuX1e8t2Lcs3VV+Xs876S0m1TZlikYcOGZ/pDD87+PH36Q1nreefksPmck2ss7aHSRX4349GsM/y5c2ztYUMzbcZjc23z4B8ezxs+8D9JklVXHpz9R22Zx574S/7tgB1z02335cmnZiZJJv3kruyw5fq57uf3Lr0DgPnorwRteinlFc9+6CvW9knyoiRb9NNvLnc223yL3H//fZk29YE8/fTMTLp0QnbZbdRc2+yy26h875KLkyQ/vHxSttvhlSmlZJfdRmXSpRMyc+bMTJv6QO6//75svkVvvP/Hhx9Okjz44O9y5RWXZ+xe+ybpnTH61S+flzP+64tZeeWVl+KRsqzoPSd/m2lTp/adkxOz63zPye8mmfuchP4y+c4HsvHItbLeS16YFQYNzMF7bJUJV98x1zZrDl119nl43Ntem6+OvzFJ8sBDj2SnrTfOwIEDMmjggOy09Ua5+zfTn/cbdF7p4P86cry1/uODqlLKOklm1Vqfd3FTKeXVtdbrFrUPCVqva67+cU495eQ809OTcQcclHe+6/Ccdebn8rLNNs+uu+2ev/71r/nQicfll3fdlSFDh+aUU0/POiNHJultVV5y8YUZOGhgjjv+g3nNTrskSd721jfmsUcfzaBBg/L+D5yYHV65Y5Jk37GjM3PmzAztSzu23PLl+fB/nDT/gXWJ6jR8nmuu/nE+c8rJeabnmYw74KC8413vzllnfr7vnByVv/71r/nwiR+YfU5+6tTTZp+Te+0xKk8+8WSefvrprD5k9Zx1zpey0UYb54zPnppLJ34/v58xI2sNG5YDDnxd3n3Eezp8pG1Zc8f3dXoITdvz1S/Nqe/bPwMHDshXx9+YT3/5h/nIu8bklrseyISr78gBu788Jx2xd2qtufZn9+boU76TmU/3ZMCAks+d8Lq8ZquNUmvND66/O8effkmnD6dpT00+vSMVy90P/rljf5A3ffEqS/2Y+6VA+0dQoNECBRqtUKDRCgXa0uFJAgBA87rtSgk3qgUAaIwEDQBoXpcFaBI0AIDWSNAAgPZ1WYQmQQMAaIwCDQCgMVqcAEDzOnVH/06RoAEANEaCBgA0z41qAQDoKAUaAEBjtDgBgOZ1WYdTggYA0BoJGgDQvi6L0CRoAACNkaABAM1zo1oAADpKgQYA0BgtTgCgeZ4kAABAR0nQAIDmdVmAJkEDAGiNAg0AoDFanABA+7qsxylBAwBojAQNAGieJwkAANBREjQAoHluVAsAQEcp0AAAGqPFCQA0r8s6nBI0AIDWSNAAgOaZJAAAQEdJ0ACAZUB3RWgSNACAxijQAAAao8UJADTPJAEAADpKggYANK/LAjQJGgBAaxRoAACN0eIEAJpnkgAAAB0lQQMAmle6bJqABA0AoDESNACgfd0VoEnQAABao0ADAGiMFicA0Lwu63BK0AAAWiNBAwCa50a1AAB0lAQNAGieG9UCANBRCjQAgMZocQIA7euuDqcEDQCgNRI0AKB5XRagSdAAAFqjQAMAaIwWJwDQPE8SAACgoyRoAEDzPEkAAICOkqABAM1zDRoAAB2lQAMAaIwCDQCgMQo0AIDGmCQAADTPJAEAADpKggYANM+NagEA6CgFGgBAY7Q4AYDmmSQAAEBHSdAAgOZ1WYAmQQMAaI0CDQCgMVqcAED7uqzHKUEDAGiMBA0AaJ4nCQAA0FESNACgeW5UCwBARynQAAAao8UJADSvyzqcEjQAgNZI0ACA9nVZhCZBAwBojAINAKAxWpwAQPM8SQAAgI6SoAEAzfMkAQAAOqrUWjs9BvpJKeWwWus5nR4HOBdpgfOQZYkEbfl2WKcHAH2ci7TAecgyQ4EGANAYBRoAQGMUaMs311rQCuciLXAesswwSQAAoDESNACAxijQAAAao0BbTpVSxpRSfllKmVJKOaHT46E7lVK+XEqZUUq5vdNjoXuVUkaWUn5USrmzlHJHKeW9nR4TLIpr0JZDpZSBSX6VZHSSqUluTnJorfXOjg6MrlNK2TnJE0m+VmvdvNPjoTuVUl6c5MW11ltKKasn+WmS/f1NpGUStOXT9kmm1FrvrbXOTPLtJOM6PCa6UK316iR/7PQ46G611gdrrbf0vf9TkruSrN3ZUcHCKdCWT2sneWCOz1PjjxFASinrJ9kqyY2dHQksnAINgK5QSlktyYVJjq61Pt7p8cDCKNCWT9OSjJzj8zp9ywC6UillhfQWZ9+stV7U6fHAoijQlk83J9mklLJBKWVwkjckGd/hMQF0RCmlJPlSkrtqrad1ejywOBRoy6Fa66wkRyaZlN6LYc+vtd7R2VHRjUop30pyfZJ/LqVMLaW8vdNjoiu9Oslbkowqpfy877VXpwcFC+M2GwAAjZGgAQA0RoEGANAYBRoAQGMUaAAAjVGgAQA0RoEGy6FSSk/frQRuL6VcUEpZ5e/Y11dKKa/re39eKeVlC9l211LKq5bgN+4rpbxocZfPs80Tf+Nv/Wcp5di/dYwAS5MCDZZPT9VaX1Fr3TzJzCTvnnNlKWXQkuy01vqOWuudC9lk1yR/c4EGwNwUaLD8uybJxn3p1jWllPFJ7iylDCylnFpKubmUcmsp5V1J713XSylnllJ+WUr5YZJhz+6olHJVKWXbvvdjSim3lFJ+UUq5ou8h1O9OckxferdTKWWtUsqFfb9xcynl1X3fXbOUcnkp5Y5SynlJyqIOopTy3VLKT/u+c9g8607vW35FKWWtvmUblVIu6/vONaWUTf8R/zEBloYl+lc0sGzoS8rGJrmsb9HWSTavtf6mr8h5rNa6XSllxSTXlVIuT7JVkn9O8rIkw5PcmeTL8+x3rSTnJtm5b18vrLX+sZTy30meqLV+pm+7/01yeq312lLKuul9usVLk/xHkmtrrSeVUvZOsjhPGPi3vt9YOcnNpZQLa60PJ1k1yeRa6zGllI/27fvIJOckeXet9dellB2SnJVk1BL8ZwRY6hRosHxauZTy877316T3OYSvSnJTrfU3fcv3SLLls9eXJRmaZJMkOyf5Vq21J8nvSilXzmf/r0xy9bP7qrX+cQHjeG2Sl/U+CjFJMqSUslrfbxzY990JpZRHFuOYjiqlHND3fmTfWB9O8kyS/+tb/o0kF/X9xquSXDDHb6+4GL8B0AQFGiyfnqq1vmLOBX2FypNzLkrynlrrpHm2+0c+o3BAklfWWv8yn7EstlLKrukt9nastf65lHJVkpUWsHnt+91H5/1vALCscA0adK9JSQ4vpayQJKWUfyqlrJrk6iSv77tG7cVJdpvPd29IsnMpZYO+776wb/mfkqw+x3aXJ3nPsx9KKc8WTFcneWPfsrFJXrCIsQ5N8khfcbZpehO8Zw1I8mwK+Mb0tk4fT/KbUsrBfb9RSikvX8RvADRDgQbd67z0Xl92Synl9iRnpzdVvzjJr/vWfS3J9fN+sdb6+ySHpbed+Is812L8XpIDnp0kkOSoJNv2TUK4M8/NJv1Yegu8O9Lb6rx/EWO9LMmgUspdST6V3gLxWU8m2b7vGEYlOalv+ZuSvL1vfHckGbcY/00AmlBqrZ0eAwAAc5CgAQA0RoEGANAYBRoAQGMUaAAAjVGgAQA0RoEGANAYBRoAQGP+P/tdrSPWn4vgAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7fcxLuwZpkK",
        "outputId": "61d5ccf3-f417-4f3c-a2ad-0f1f2208912b"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "6ed68426-c0d4-4337-e375-8c1d76c3e5d6"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 6s 83ms/step - loss: 1.1583 - accuracy: 0.4401 - val_loss: 1.0389 - val_accuracy: 0.5335\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 1.0381 - accuracy: 0.5177 - val_loss: 1.0088 - val_accuracy: 0.5335\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0190 - accuracy: 0.5196 - val_loss: 1.0138 - val_accuracy: 0.5335\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 1.0224 - accuracy: 0.5196 - val_loss: 1.0077 - val_accuracy: 0.5335\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 1.0258 - accuracy: 0.5120 - val_loss: 1.0052 - val_accuracy: 0.5335\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 1.0147 - accuracy: 0.5159 - val_loss: 1.0047 - val_accuracy: 0.5335\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 1.0207 - accuracy: 0.5028 - val_loss: 1.0043 - val_accuracy: 0.5335\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0077 - accuracy: 0.5239 - val_loss: 1.0067 - val_accuracy: 0.5335\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 1.0080 - accuracy: 0.5256 - val_loss: 1.0032 - val_accuracy: 0.5335\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0096 - accuracy: 0.5224 - val_loss: 1.0049 - val_accuracy: 0.5335\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 1.0015 - accuracy: 0.5300 - val_loss: 1.0042 - val_accuracy: 0.5335\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 1.0031 - accuracy: 0.5279 - val_loss: 1.0056 - val_accuracy: 0.5335\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0047 - accuracy: 0.5163 - val_loss: 1.0020 - val_accuracy: 0.5335\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 1.0092 - accuracy: 0.5211 - val_loss: 1.0103 - val_accuracy: 0.5335\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 1.0142 - accuracy: 0.5125 - val_loss: 1.0021 - val_accuracy: 0.5335\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9992 - accuracy: 0.5223 - val_loss: 1.0027 - val_accuracy: 0.5335\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0025 - accuracy: 0.5264 - val_loss: 1.0032 - val_accuracy: 0.5335\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0053 - accuracy: 0.5198 - val_loss: 1.0060 - val_accuracy: 0.5335\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 1.0014 - accuracy: 0.5236 - val_loss: 1.0026 - val_accuracy: 0.5335\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 1.0002 - accuracy: 0.5227 - val_loss: 1.0026 - val_accuracy: 0.5335\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9985 - accuracy: 0.5232 - val_loss: 1.0076 - val_accuracy: 0.5335\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 1.0043 - accuracy: 0.5204 - val_loss: 0.9989 - val_accuracy: 0.5335\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 0.9957 - accuracy: 0.5325 - val_loss: 1.0006 - val_accuracy: 0.5335\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 1.0068 - accuracy: 0.5126 - val_loss: 1.0059 - val_accuracy: 0.5335\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 1.0038 - accuracy: 0.5123 - val_loss: 1.0033 - val_accuracy: 0.5335\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 0.9953 - accuracy: 0.5300 - val_loss: 1.0013 - val_accuracy: 0.5335\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 1.0011 - accuracy: 0.5209 - val_loss: 1.0005 - val_accuracy: 0.5335\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9965 - accuracy: 0.5265 - val_loss: 1.0009 - val_accuracy: 0.5335\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9997 - accuracy: 0.5231 - val_loss: 1.0120 - val_accuracy: 0.5335\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 1.0017 - accuracy: 0.5146 - val_loss: 1.0013 - val_accuracy: 0.5335\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.9972 - accuracy: 0.5232 - val_loss: 1.0180 - val_accuracy: 0.5121\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9971 - accuracy: 0.5235 - val_loss: 1.0158 - val_accuracy: 0.5121\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9977 - accuracy: 0.5232 - val_loss: 1.0215 - val_accuracy: 0.5121\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9981 - accuracy: 0.5235 - val_loss: 1.0208 - val_accuracy: 0.5121\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.9975 - accuracy: 0.5235 - val_loss: 1.0208 - val_accuracy: 0.5121\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 0.9965 - accuracy: 0.5235 - val_loss: 1.0240 - val_accuracy: 0.5121\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9979 - accuracy: 0.5234 - val_loss: 1.0202 - val_accuracy: 0.5121\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9966 - accuracy: 0.5235 - val_loss: 1.0226 - val_accuracy: 0.5121\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 0.9961 - accuracy: 0.5235 - val_loss: 1.0254 - val_accuracy: 0.5121\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9941 - accuracy: 0.5235 - val_loss: 1.0328 - val_accuracy: 0.5121\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 0.9970 - accuracy: 0.5235 - val_loss: 1.0198 - val_accuracy: 0.5121\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.9961 - accuracy: 0.5235 - val_loss: 1.0289 - val_accuracy: 0.5121\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.9954 - accuracy: 0.5235 - val_loss: 1.0217 - val_accuracy: 0.5121\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9935 - accuracy: 0.5235 - val_loss: 1.0181 - val_accuracy: 0.5121\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.9931 - accuracy: 0.5235 - val_loss: 1.0165 - val_accuracy: 0.5121\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.9925 - accuracy: 0.5235 - val_loss: 1.0188 - val_accuracy: 0.5121\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9942 - accuracy: 0.5235 - val_loss: 1.0136 - val_accuracy: 0.5121\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9936 - accuracy: 0.5235 - val_loss: 1.0156 - val_accuracy: 0.5121\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 0.9918 - accuracy: 0.5235 - val_loss: 1.0129 - val_accuracy: 0.5121\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9910 - accuracy: 0.5234 - val_loss: 1.0220 - val_accuracy: 0.5121\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.9913 - accuracy: 0.5235 - val_loss: 1.0109 - val_accuracy: 0.5121\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9920 - accuracy: 0.5235 - val_loss: 1.0196 - val_accuracy: 0.5121\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 0.9904 - accuracy: 0.5235 - val_loss: 1.0214 - val_accuracy: 0.5121\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 69ms/step - loss: 0.9896 - accuracy: 0.5235 - val_loss: 1.0097 - val_accuracy: 0.5121\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 0.9876 - accuracy: 0.5232 - val_loss: 1.0174 - val_accuracy: 0.5121\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.9873 - accuracy: 0.5235 - val_loss: 1.0183 - val_accuracy: 0.5121\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9831 - accuracy: 0.5234 - val_loss: 1.0282 - val_accuracy: 0.5121\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.9845 - accuracy: 0.5235 - val_loss: 1.0032 - val_accuracy: 0.5121\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 0.9801 - accuracy: 0.5234 - val_loss: 0.9983 - val_accuracy: 0.5121\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9800 - accuracy: 0.5232 - val_loss: 1.0069 - val_accuracy: 0.5121\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.9843 - accuracy: 0.5195 - val_loss: 0.9477 - val_accuracy: 0.5469\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9808 - accuracy: 0.5198 - val_loss: 0.9246 - val_accuracy: 0.5469\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 0.9815 - accuracy: 0.5195 - val_loss: 0.9303 - val_accuracy: 0.5469\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.9765 - accuracy: 0.5189 - val_loss: 0.9288 - val_accuracy: 0.5469\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9731 - accuracy: 0.5197 - val_loss: 0.9244 - val_accuracy: 0.5469\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.9712 - accuracy: 0.5197 - val_loss: 0.9352 - val_accuracy: 0.5469\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9696 - accuracy: 0.5197 - val_loss: 0.9072 - val_accuracy: 0.5469\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.9682 - accuracy: 0.5194 - val_loss: 0.9230 - val_accuracy: 0.5469\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9715 - accuracy: 0.5198 - val_loss: 0.9291 - val_accuracy: 0.5469\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9598 - accuracy: 0.5186 - val_loss: 0.9016 - val_accuracy: 0.5469\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.9513 - accuracy: 0.5194 - val_loss: 0.9209 - val_accuracy: 0.5469\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9467 - accuracy: 0.5197 - val_loss: 0.9306 - val_accuracy: 0.5469\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9373 - accuracy: 0.5197 - val_loss: 0.8806 - val_accuracy: 0.5509\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9319 - accuracy: 0.5197 - val_loss: 0.8910 - val_accuracy: 0.5469\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.9300 - accuracy: 0.5174 - val_loss: 0.8839 - val_accuracy: 0.5469\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.9278 - accuracy: 0.5200 - val_loss: 0.8637 - val_accuracy: 0.5496\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 0.9182 - accuracy: 0.5209 - val_loss: 0.8550 - val_accuracy: 0.5469\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9141 - accuracy: 0.5191 - val_loss: 0.8478 - val_accuracy: 0.5469\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.9044 - accuracy: 0.5224 - val_loss: 0.8725 - val_accuracy: 0.5536\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.8972 - accuracy: 0.5617 - val_loss: 0.8395 - val_accuracy: 0.5590\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8854 - accuracy: 0.5642 - val_loss: 0.8443 - val_accuracy: 0.5751\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8730 - accuracy: 0.5851 - val_loss: 0.8349 - val_accuracy: 0.5724\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8721 - accuracy: 0.5858 - val_loss: 0.8247 - val_accuracy: 0.6126\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.8601 - accuracy: 0.5979 - val_loss: 0.8103 - val_accuracy: 0.5912\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 0.8500 - accuracy: 0.6013 - val_loss: 0.8117 - val_accuracy: 0.6099\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.8336 - accuracy: 0.6112 - val_loss: 0.7827 - val_accuracy: 0.6300\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.8409 - accuracy: 0.6022 - val_loss: 0.7825 - val_accuracy: 0.6220\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8322 - accuracy: 0.6176 - val_loss: 0.7637 - val_accuracy: 0.6408\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 0.7944 - accuracy: 0.6349 - val_loss: 0.7555 - val_accuracy: 0.6555\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.8146 - accuracy: 0.6249 - val_loss: 0.7671 - val_accuracy: 0.6448\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.7969 - accuracy: 0.6376 - val_loss: 0.6842 - val_accuracy: 0.6957\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.7873 - accuracy: 0.6431 - val_loss: 0.7440 - val_accuracy: 0.6796\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 70ms/step - loss: 0.7786 - accuracy: 0.6484 - val_loss: 0.6497 - val_accuracy: 0.7198\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.7513 - accuracy: 0.6689 - val_loss: 0.6572 - val_accuracy: 0.7198\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.7540 - accuracy: 0.6714 - val_loss: 0.6353 - val_accuracy: 0.7292\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.7415 - accuracy: 0.6751 - val_loss: 0.6268 - val_accuracy: 0.7386\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.7162 - accuracy: 0.6945 - val_loss: 0.6262 - val_accuracy: 0.7440\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.7084 - accuracy: 0.6990 - val_loss: 0.6164 - val_accuracy: 0.7587\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.6901 - accuracy: 0.7115 - val_loss: 0.5985 - val_accuracy: 0.7520\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.6699 - accuracy: 0.7216 - val_loss: 0.5820 - val_accuracy: 0.7842\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.6672 - accuracy: 0.7307 - val_loss: 0.5837 - val_accuracy: 0.7735\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.6468 - accuracy: 0.7407 - val_loss: 0.5515 - val_accuracy: 0.7922\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.6287 - accuracy: 0.7505 - val_loss: 0.5287 - val_accuracy: 0.8056\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.6167 - accuracy: 0.7538 - val_loss: 0.5514 - val_accuracy: 0.7788\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.6079 - accuracy: 0.7592 - val_loss: 0.5430 - val_accuracy: 0.7882\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.5888 - accuracy: 0.7656 - val_loss: 0.5277 - val_accuracy: 0.7949\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.5592 - accuracy: 0.7808 - val_loss: 0.4991 - val_accuracy: 0.8150\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.5532 - accuracy: 0.7855 - val_loss: 0.5031 - val_accuracy: 0.8110\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.5458 - accuracy: 0.7867 - val_loss: 0.4899 - val_accuracy: 0.8070\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.5310 - accuracy: 0.7894 - val_loss: 0.4531 - val_accuracy: 0.8097\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.5039 - accuracy: 0.8036 - val_loss: 0.4393 - val_accuracy: 0.8244\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.4779 - accuracy: 0.8131 - val_loss: 0.4275 - val_accuracy: 0.8298\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.4854 - accuracy: 0.8107 - val_loss: 0.4143 - val_accuracy: 0.8391\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.4392 - accuracy: 0.8303 - val_loss: 0.3847 - val_accuracy: 0.8539\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.4371 - accuracy: 0.8298 - val_loss: 0.3789 - val_accuracy: 0.8445\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.4132 - accuracy: 0.8370 - val_loss: 0.4042 - val_accuracy: 0.8405\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.4108 - accuracy: 0.8379 - val_loss: 0.3667 - val_accuracy: 0.8592\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.4014 - accuracy: 0.8441 - val_loss: 0.3401 - val_accuracy: 0.8660\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.3879 - accuracy: 0.8475 - val_loss: 0.3416 - val_accuracy: 0.8767\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.3626 - accuracy: 0.8593 - val_loss: 0.3271 - val_accuracy: 0.8700\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.3727 - accuracy: 0.8572 - val_loss: 0.1937 - val_accuracy: 0.9142\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.3648 - accuracy: 0.8593 - val_loss: 0.1841 - val_accuracy: 0.9303\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.3660 - accuracy: 0.8614 - val_loss: 0.1744 - val_accuracy: 0.9330\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.3226 - accuracy: 0.8770 - val_loss: 0.1633 - val_accuracy: 0.9357\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.3267 - accuracy: 0.8715 - val_loss: 0.1775 - val_accuracy: 0.9303\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.3185 - accuracy: 0.8787 - val_loss: 0.1454 - val_accuracy: 0.9437\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.3096 - accuracy: 0.8808 - val_loss: 0.1433 - val_accuracy: 0.9450\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.2876 - accuracy: 0.8928 - val_loss: 0.1559 - val_accuracy: 0.9316\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.2726 - accuracy: 0.8966 - val_loss: 0.1523 - val_accuracy: 0.9370\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.2564 - accuracy: 0.9031 - val_loss: 0.1474 - val_accuracy: 0.9383\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.2524 - accuracy: 0.9082 - val_loss: 0.1206 - val_accuracy: 0.9464\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.2521 - accuracy: 0.9061 - val_loss: 0.1253 - val_accuracy: 0.9531\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.2457 - accuracy: 0.9051 - val_loss: 0.1186 - val_accuracy: 0.9544\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.2230 - accuracy: 0.9185 - val_loss: 0.1244 - val_accuracy: 0.9450\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.2246 - accuracy: 0.9156 - val_loss: 0.1019 - val_accuracy: 0.9638\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.2242 - accuracy: 0.9182 - val_loss: 0.1053 - val_accuracy: 0.9544\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.2247 - accuracy: 0.9171 - val_loss: 0.1051 - val_accuracy: 0.9625\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1928 - accuracy: 0.9295 - val_loss: 0.1159 - val_accuracy: 0.9491\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.2048 - accuracy: 0.9246 - val_loss: 0.0980 - val_accuracy: 0.9598\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.1982 - accuracy: 0.9276 - val_loss: 0.1250 - val_accuracy: 0.9584\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.2037 - accuracy: 0.9265 - val_loss: 0.1111 - val_accuracy: 0.9651\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1905 - accuracy: 0.9320 - val_loss: 0.0890 - val_accuracy: 0.9651\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1906 - accuracy: 0.9322 - val_loss: 0.1215 - val_accuracy: 0.9437\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.1959 - accuracy: 0.9277 - val_loss: 0.0839 - val_accuracy: 0.9732\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1753 - accuracy: 0.9361 - val_loss: 0.0928 - val_accuracy: 0.9584\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1821 - accuracy: 0.9387 - val_loss: 0.0765 - val_accuracy: 0.9692\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1540 - accuracy: 0.9440 - val_loss: 0.0833 - val_accuracy: 0.9678\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1462 - accuracy: 0.9461 - val_loss: 0.0703 - val_accuracy: 0.9772\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.1546 - accuracy: 0.9426 - val_loss: 0.0897 - val_accuracy: 0.9665\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.1576 - accuracy: 0.9458 - val_loss: 0.0737 - val_accuracy: 0.9732\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1517 - accuracy: 0.9459 - val_loss: 0.0206 - val_accuracy: 0.9987\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1556 - accuracy: 0.9463 - val_loss: 0.0192 - val_accuracy: 0.9987\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1707 - accuracy: 0.9404 - val_loss: 0.0235 - val_accuracy: 0.9973\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.1430 - accuracy: 0.9502 - val_loss: 0.0158 - val_accuracy: 0.9987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1566 - accuracy: 0.9496 - val_loss: 0.0195 - val_accuracy: 0.9987\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.1352 - accuracy: 0.9528 - val_loss: 0.0216 - val_accuracy: 0.9973\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.1464 - accuracy: 0.9496 - val_loss: 0.0194 - val_accuracy: 0.9973\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1478 - accuracy: 0.9455 - val_loss: 0.0208 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1356 - accuracy: 0.9525 - val_loss: 0.0178 - val_accuracy: 0.9987\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1196 - accuracy: 0.9604 - val_loss: 0.0195 - val_accuracy: 0.9933\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1157 - accuracy: 0.9607 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1393 - accuracy: 0.9508 - val_loss: 0.0629 - val_accuracy: 0.9732\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1241 - accuracy: 0.9554 - val_loss: 0.0172 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1385 - accuracy: 0.9517 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.1257 - accuracy: 0.9547 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1260 - accuracy: 0.9566 - val_loss: 0.0141 - val_accuracy: 0.9987\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1248 - accuracy: 0.9550 - val_loss: 0.0152 - val_accuracy: 0.9973\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.1249 - accuracy: 0.9581 - val_loss: 0.0162 - val_accuracy: 0.9960\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.1082 - accuracy: 0.9651 - val_loss: 0.0205 - val_accuracy: 0.9946\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0904 - accuracy: 0.9681 - val_loss: 0.0107 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.1128 - accuracy: 0.9639 - val_loss: 0.0131 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1114 - accuracy: 0.9660 - val_loss: 0.0142 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1070 - accuracy: 0.9674 - val_loss: 0.0305 - val_accuracy: 0.9866\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.1150 - accuracy: 0.9620 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0919 - accuracy: 0.9702 - val_loss: 0.0121 - val_accuracy: 0.9973\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0881 - accuracy: 0.9721 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0915 - accuracy: 0.9732 - val_loss: 0.0096 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0927 - accuracy: 0.9666 - val_loss: 0.0079 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0977 - accuracy: 0.9689 - val_loss: 0.0120 - val_accuracy: 0.9973\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0843 - accuracy: 0.9724 - val_loss: 0.0185 - val_accuracy: 0.9946\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.1035 - accuracy: 0.9653 - val_loss: 0.0099 - val_accuracy: 0.9973\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.0923 - accuracy: 0.9689 - val_loss: 0.0059 - val_accuracy: 0.9987\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0919 - accuracy: 0.9689 - val_loss: 0.0103 - val_accuracy: 0.9960\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0881 - accuracy: 0.9709 - val_loss: 0.0067 - val_accuracy: 0.9987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0905 - accuracy: 0.9705 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0834 - accuracy: 0.9733 - val_loss: 0.0067 - val_accuracy: 0.9973\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0899 - accuracy: 0.9686 - val_loss: 0.0119 - val_accuracy: 0.9960\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0810 - accuracy: 0.9729 - val_loss: 0.0068 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0884 - accuracy: 0.9708 - val_loss: 0.0123 - val_accuracy: 0.9960\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0889 - accuracy: 0.9714 - val_loss: 0.0088 - val_accuracy: 0.9960\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0845 - accuracy: 0.9723 - val_loss: 0.0136 - val_accuracy: 0.9946\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0783 - accuracy: 0.9742 - val_loss: 0.0089 - val_accuracy: 0.9973\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0864 - accuracy: 0.9708 - val_loss: 0.0068 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0775 - accuracy: 0.9754 - val_loss: 0.0085 - val_accuracy: 0.9973\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0704 - accuracy: 0.9754 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0679 - accuracy: 0.9779 - val_loss: 0.0079 - val_accuracy: 0.9973\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0685 - accuracy: 0.9782 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0629 - accuracy: 0.9781 - val_loss: 0.0074 - val_accuracy: 0.9973\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0732 - accuracy: 0.9768 - val_loss: 0.0054 - val_accuracy: 0.9973\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0713 - accuracy: 0.9750 - val_loss: 0.0082 - val_accuracy: 0.9960\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0692 - accuracy: 0.9762 - val_loss: 0.0078 - val_accuracy: 0.9960\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0764 - accuracy: 0.9753 - val_loss: 0.0037 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.0722 - accuracy: 0.9765 - val_loss: 0.0104 - val_accuracy: 0.9960\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0702 - accuracy: 0.9759 - val_loss: 0.0065 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0644 - accuracy: 0.9776 - val_loss: 0.0037 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0715 - accuracy: 0.9769 - val_loss: 0.0079 - val_accuracy: 0.9973\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0743 - accuracy: 0.9738 - val_loss: 0.0470 - val_accuracy: 0.9799\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0702 - accuracy: 0.9765 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0569 - accuracy: 0.9793 - val_loss: 0.0055 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0630 - accuracy: 0.9778 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0736 - accuracy: 0.9759 - val_loss: 0.0017 - val_accuracy: 0.9987\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0740 - accuracy: 0.9782 - val_loss: 9.9562e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0640 - accuracy: 0.9784 - val_loss: 9.7527e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0831 - accuracy: 0.9732 - val_loss: 0.0019 - val_accuracy: 0.9987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0711 - accuracy: 0.9741 - val_loss: 0.0092 - val_accuracy: 0.9987\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0640 - accuracy: 0.9794 - val_loss: 0.0044 - val_accuracy: 0.9987\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0701 - accuracy: 0.9774 - val_loss: 0.0024 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0601 - accuracy: 0.9790 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.0619 - accuracy: 0.9794 - val_loss: 0.0031 - val_accuracy: 0.9987\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0603 - accuracy: 0.9799 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0602 - accuracy: 0.9823 - val_loss: 0.0031 - val_accuracy: 0.9987\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0621 - accuracy: 0.9809 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0581 - accuracy: 0.9803 - val_loss: 7.8903e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0621 - accuracy: 0.9787 - val_loss: 6.7361e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.0670 - accuracy: 0.9785 - val_loss: 6.9858e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0572 - accuracy: 0.9817 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0710 - accuracy: 0.9781 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0648 - accuracy: 0.9794 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0573 - accuracy: 0.9830 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0589 - accuracy: 0.9803 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0483 - accuracy: 0.9823 - val_loss: 8.6458e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0729 - accuracy: 0.9788 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0589 - accuracy: 0.9814 - val_loss: 9.8861e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0640 - accuracy: 0.9797 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0532 - accuracy: 0.9817 - val_loss: 0.0032 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0562 - accuracy: 0.9805 - val_loss: 0.0017 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0684 - accuracy: 0.9766 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0497 - accuracy: 0.9833 - val_loss: 5.7512e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0567 - accuracy: 0.9830 - val_loss: 7.1240e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0453 - accuracy: 0.9845 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0534 - accuracy: 0.9826 - val_loss: 3.3889e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0562 - accuracy: 0.9814 - val_loss: 1.5066e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0426 - accuracy: 0.9858 - val_loss: 2.0441e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0506 - accuracy: 0.9824 - val_loss: 1.2670e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0529 - accuracy: 0.9854 - val_loss: 4.6857e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0423 - accuracy: 0.9872 - val_loss: 9.0081e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0453 - accuracy: 0.9875 - val_loss: 0.1391 - val_accuracy: 0.9651\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0601 - accuracy: 0.9821 - val_loss: 2.7557e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0664 - accuracy: 0.9774 - val_loss: 3.2384e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0536 - accuracy: 0.9842 - val_loss: 2.9241e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0545 - accuracy: 0.9835 - val_loss: 1.8631e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0450 - accuracy: 0.9857 - val_loss: 1.8121e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0493 - accuracy: 0.9845 - val_loss: 5.5023e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0686 - accuracy: 0.9771 - val_loss: 4.1429e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0485 - accuracy: 0.9838 - val_loss: 3.7821e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0453 - accuracy: 0.9873 - val_loss: 3.1895e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0496 - accuracy: 0.9833 - val_loss: 8.1932e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0424 - accuracy: 0.9854 - val_loss: 1.8922e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0574 - accuracy: 0.9818 - val_loss: 4.9582e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0446 - accuracy: 0.9847 - val_loss: 2.3452e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0467 - accuracy: 0.9863 - val_loss: 0.0022 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0544 - accuracy: 0.9835 - val_loss: 5.3154e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0484 - accuracy: 0.9860 - val_loss: 4.3563e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0552 - accuracy: 0.9817 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0534 - accuracy: 0.9832 - val_loss: 2.1149e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0538 - accuracy: 0.9833 - val_loss: 8.5116e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0483 - accuracy: 0.9830 - val_loss: 3.0677e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0369 - accuracy: 0.9879 - val_loss: 3.4019e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0551 - accuracy: 0.9839 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0497 - accuracy: 0.9866 - val_loss: 3.1039e-04 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0485 - accuracy: 0.9841 - val_loss: 1.2349e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0499 - accuracy: 0.9844 - val_loss: 8.9014e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0467 - accuracy: 0.9860 - val_loss: 4.8109e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0473 - accuracy: 0.9847 - val_loss: 1.0070e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0409 - accuracy: 0.9881 - val_loss: 7.5793e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0569 - accuracy: 0.9814 - val_loss: 7.1969e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0481 - accuracy: 0.9858 - val_loss: 9.0816e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0381 - accuracy: 0.9875 - val_loss: 6.9491e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0435 - accuracy: 0.9866 - val_loss: 1.0861e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0533 - accuracy: 0.9812 - val_loss: 4.2269e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0379 - accuracy: 0.9860 - val_loss: 6.7325e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0574 - accuracy: 0.9815 - val_loss: 5.3162e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0350 - accuracy: 0.9887 - val_loss: 3.6092e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0445 - accuracy: 0.9861 - val_loss: 4.1307e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0327 - accuracy: 0.9897 - val_loss: 3.3251e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0622 - accuracy: 0.9824 - val_loss: 5.0452e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0391 - accuracy: 0.9867 - val_loss: 6.0268e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0372 - accuracy: 0.9885 - val_loss: 3.3076e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0337 - accuracy: 0.9887 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0521 - accuracy: 0.9867 - val_loss: 1.9628e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0388 - accuracy: 0.9867 - val_loss: 6.3239e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0377 - accuracy: 0.9876 - val_loss: 5.4650e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 4s 74ms/step - loss: 0.0408 - accuracy: 0.9879 - val_loss: 7.4854e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 4s 72ms/step - loss: 0.0365 - accuracy: 0.9873 - val_loss: 3.9597e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0414 - accuracy: 0.9858 - val_loss: 1.0546e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 4s 75ms/step - loss: 0.0321 - accuracy: 0.9903 - val_loss: 5.7713e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0435 - accuracy: 0.9864 - val_loss: 8.3063e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 4s 73ms/step - loss: 0.0517 - accuracy: 0.9836 - val_loss: 2.8476e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 4s 76ms/step - loss: 0.0403 - accuracy: 0.9858 - val_loss: 5.8157e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.0419 - accuracy: 0.9858 - val_loss: 6.9556e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "bb55881d-10b0-4ec1-d15a-129160002340"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 10ms/step - loss: 0.0615 - accuracy: 0.9839\n",
            "Accuracy  : 0.983905553817749\n",
            "F1_Score  : 0.9816780109105568\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}