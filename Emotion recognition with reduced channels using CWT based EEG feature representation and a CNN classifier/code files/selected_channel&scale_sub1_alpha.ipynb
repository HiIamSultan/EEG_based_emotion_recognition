{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub1_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "14d7e534-0b8d-486f-98f6-d044d907a461"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e3\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "c9022357-bd06-4364-caf5-1b8ef623ca0a"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(1,2):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.1\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (4194,) (932,) (4194,)\n",
            "(9320,) (3495,) (233,) (5592,)\n",
            "(9320,) (2796,) (466,) (6058,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "f9be612a-6584-467b-9237-c05e5f7bf3f4"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "baac30ea-dc1b-447f-bc4d-d6f7609bdbfc"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "622"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "a4e929a4-48c2-43b7-adb3-41a24c8dd52c"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8b69eb2-3fb1-496d-c420-5c0601b4f75d"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 53s 65ms/step - loss: 1.1194 - accuracy: 0.4239 - val_loss: 0.9566 - val_accuracy: 0.4692\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 1.0000 - accuracy: 0.4508 - val_loss: 0.9532 - val_accuracy: 0.4638\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9792 - accuracy: 0.4553 - val_loss: 0.9539 - val_accuracy: 0.4397\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9869 - accuracy: 0.4703 - val_loss: 0.9485 - val_accuracy: 0.4759\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9720 - accuracy: 0.4673 - val_loss: 0.9501 - val_accuracy: 0.4732\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9583 - accuracy: 0.4785 - val_loss: 0.9499 - val_accuracy: 0.4692\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9664 - accuracy: 0.4688 - val_loss: 0.9471 - val_accuracy: 0.4625\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9576 - accuracy: 0.4668 - val_loss: 0.9415 - val_accuracy: 0.4879\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9559 - accuracy: 0.4731 - val_loss: 0.9416 - val_accuracy: 0.4866\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9547 - accuracy: 0.4722 - val_loss: 0.9402 - val_accuracy: 0.4799\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9579 - accuracy: 0.4696 - val_loss: 0.9361 - val_accuracy: 0.4705\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9439 - accuracy: 0.4842 - val_loss: 0.9372 - val_accuracy: 0.4786\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.9479 - accuracy: 0.4842 - val_loss: 0.9303 - val_accuracy: 0.4692\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9450 - accuracy: 0.4869 - val_loss: 0.9303 - val_accuracy: 0.4799\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9399 - accuracy: 0.4810 - val_loss: 0.9388 - val_accuracy: 0.4772\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.9325 - accuracy: 0.5022 - val_loss: 0.9229 - val_accuracy: 0.5067\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9371 - accuracy: 0.5018 - val_loss: 0.9247 - val_accuracy: 0.4786\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.9268 - accuracy: 0.5157 - val_loss: 0.9221 - val_accuracy: 0.4812\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9268 - accuracy: 0.5049 - val_loss: 0.9096 - val_accuracy: 0.4946\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9231 - accuracy: 0.5056 - val_loss: 0.9041 - val_accuracy: 0.5013\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9231 - accuracy: 0.4993 - val_loss: 0.9129 - val_accuracy: 0.4906\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9128 - accuracy: 0.5053 - val_loss: 0.9026 - val_accuracy: 0.4906\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9018 - accuracy: 0.5098 - val_loss: 0.9016 - val_accuracy: 0.5080\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.9079 - accuracy: 0.5164 - val_loss: 0.9056 - val_accuracy: 0.5040\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8979 - accuracy: 0.5236 - val_loss: 0.9009 - val_accuracy: 0.5161\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.9009 - accuracy: 0.5286 - val_loss: 0.8932 - val_accuracy: 0.5054\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8875 - accuracy: 0.5306 - val_loss: 0.8945 - val_accuracy: 0.5322\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.8935 - accuracy: 0.5349 - val_loss: 0.8800 - val_accuracy: 0.5308\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.8716 - accuracy: 0.5513 - val_loss: 0.9082 - val_accuracy: 0.5080\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8751 - accuracy: 0.5532 - val_loss: 0.8843 - val_accuracy: 0.5295\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.8774 - accuracy: 0.5449 - val_loss: 0.8519 - val_accuracy: 0.5751\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.8737 - accuracy: 0.5469 - val_loss: 0.8515 - val_accuracy: 0.5845\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8658 - accuracy: 0.5474 - val_loss: 0.8314 - val_accuracy: 0.5979\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.8633 - accuracy: 0.5475 - val_loss: 0.8422 - val_accuracy: 0.5979\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.8509 - accuracy: 0.5633 - val_loss: 0.8226 - val_accuracy: 0.6005\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8467 - accuracy: 0.5623 - val_loss: 0.8388 - val_accuracy: 0.5952\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8501 - accuracy: 0.5621 - val_loss: 0.8278 - val_accuracy: 0.5912\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.8231 - accuracy: 0.5860 - val_loss: 0.8209 - val_accuracy: 0.5992\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8209 - accuracy: 0.5890 - val_loss: 0.8154 - val_accuracy: 0.5885\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.8133 - accuracy: 0.5861 - val_loss: 0.7995 - val_accuracy: 0.5925\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.8029 - accuracy: 0.5951 - val_loss: 0.7711 - val_accuracy: 0.6367\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.7879 - accuracy: 0.6061 - val_loss: 0.7549 - val_accuracy: 0.6488\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.7776 - accuracy: 0.6164 - val_loss: 0.8197 - val_accuracy: 0.5710\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.7790 - accuracy: 0.6134 - val_loss: 0.7615 - val_accuracy: 0.6059\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.7492 - accuracy: 0.6279 - val_loss: 0.7745 - val_accuracy: 0.6568\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7372 - accuracy: 0.6361 - val_loss: 0.7724 - val_accuracy: 0.6059\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.7162 - accuracy: 0.6513 - val_loss: 0.7161 - val_accuracy: 0.6515\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.7014 - accuracy: 0.6677 - val_loss: 0.6924 - val_accuracy: 0.6716\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6892 - accuracy: 0.6665 - val_loss: 0.6810 - val_accuracy: 0.6850\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.6607 - accuracy: 0.6814 - val_loss: 0.6468 - val_accuracy: 0.7064\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.6558 - accuracy: 0.6869 - val_loss: 0.6563 - val_accuracy: 0.6756\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.6223 - accuracy: 0.7098 - val_loss: 0.6226 - val_accuracy: 0.7239\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5917 - accuracy: 0.7274 - val_loss: 0.6212 - val_accuracy: 0.6997\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5902 - accuracy: 0.7252 - val_loss: 0.5787 - val_accuracy: 0.7306\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.5552 - accuracy: 0.7472 - val_loss: 0.5892 - val_accuracy: 0.7560\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5410 - accuracy: 0.7584 - val_loss: 0.6490 - val_accuracy: 0.7292\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5256 - accuracy: 0.7729 - val_loss: 0.5613 - val_accuracy: 0.7627\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.4890 - accuracy: 0.7861 - val_loss: 0.5220 - val_accuracy: 0.7587\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4577 - accuracy: 0.8046 - val_loss: 0.4534 - val_accuracy: 0.8164\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.4317 - accuracy: 0.8171 - val_loss: 0.4510 - val_accuracy: 0.8150\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.4470 - accuracy: 0.8136 - val_loss: 0.2490 - val_accuracy: 0.9102\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.4103 - accuracy: 0.8276 - val_loss: 0.2007 - val_accuracy: 0.9330\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3860 - accuracy: 0.8486 - val_loss: 0.2364 - val_accuracy: 0.9102\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.3625 - accuracy: 0.8587 - val_loss: 0.1969 - val_accuracy: 0.9316\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3345 - accuracy: 0.8678 - val_loss: 0.2080 - val_accuracy: 0.9102\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3092 - accuracy: 0.8814 - val_loss: 0.1859 - val_accuracy: 0.9209\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2945 - accuracy: 0.8894 - val_loss: 0.1647 - val_accuracy: 0.9383\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2800 - accuracy: 0.8939 - val_loss: 0.1743 - val_accuracy: 0.9276\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2448 - accuracy: 0.9089 - val_loss: 0.1906 - val_accuracy: 0.9276\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2228 - accuracy: 0.9174 - val_loss: 0.1551 - val_accuracy: 0.9397\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2296 - accuracy: 0.9171 - val_loss: 0.1364 - val_accuracy: 0.9464\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2116 - accuracy: 0.9222 - val_loss: 0.1230 - val_accuracy: 0.9504\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1691 - accuracy: 0.9396 - val_loss: 0.1187 - val_accuracy: 0.9584\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1593 - accuracy: 0.9438 - val_loss: 0.1223 - val_accuracy: 0.9491\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1695 - accuracy: 0.9386 - val_loss: 0.1010 - val_accuracy: 0.9558\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1484 - accuracy: 0.9468 - val_loss: 0.0941 - val_accuracy: 0.9611\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1456 - accuracy: 0.9507 - val_loss: 0.1042 - val_accuracy: 0.9571\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1190 - accuracy: 0.9559 - val_loss: 0.0883 - val_accuracy: 0.9692\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1183 - accuracy: 0.9604 - val_loss: 0.1194 - val_accuracy: 0.9598\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.1293 - accuracy: 0.9560 - val_loss: 0.0952 - val_accuracy: 0.9638\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1325 - accuracy: 0.9545 - val_loss: 0.1082 - val_accuracy: 0.9665\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1283 - accuracy: 0.9551 - val_loss: 0.0865 - val_accuracy: 0.9705\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1022 - accuracy: 0.9627 - val_loss: 0.0810 - val_accuracy: 0.9638\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1040 - accuracy: 0.9663 - val_loss: 0.0967 - val_accuracy: 0.9638\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0978 - accuracy: 0.9672 - val_loss: 0.0833 - val_accuracy: 0.9678\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0934 - accuracy: 0.9692 - val_loss: 0.0607 - val_accuracy: 0.9799\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0887 - accuracy: 0.9684 - val_loss: 0.1006 - val_accuracy: 0.9705\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0943 - accuracy: 0.9709 - val_loss: 0.0868 - val_accuracy: 0.9772\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0756 - accuracy: 0.9760 - val_loss: 0.0938 - val_accuracy: 0.9638\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0859 - accuracy: 0.9717 - val_loss: 0.0689 - val_accuracy: 0.9745\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.1091 - accuracy: 0.9633 - val_loss: 0.0073 - val_accuracy: 0.9987\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1008 - accuracy: 0.9680 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0939 - accuracy: 0.9699 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0827 - accuracy: 0.9742 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0671 - accuracy: 0.9790 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0806 - accuracy: 0.9744 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0707 - accuracy: 0.9778 - val_loss: 0.0048 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0589 - accuracy: 0.9821 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0677 - accuracy: 0.9776 - val_loss: 0.0068 - val_accuracy: 0.9987\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0767 - accuracy: 0.9751 - val_loss: 0.0057 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0705 - accuracy: 0.9772 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0652 - accuracy: 0.9778 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0530 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0475 - accuracy: 0.9852 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0511 - accuracy: 0.9827 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0598 - accuracy: 0.9820 - val_loss: 0.0066 - val_accuracy: 0.9973\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0489 - accuracy: 0.9845 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0467 - accuracy: 0.9851 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0429 - accuracy: 0.9860 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0686 - accuracy: 0.9765 - val_loss: 0.0034 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0541 - accuracy: 0.9826 - val_loss: 0.0062 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0498 - accuracy: 0.9818 - val_loss: 0.0126 - val_accuracy: 0.9973\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0542 - accuracy: 0.9836 - val_loss: 0.0105 - val_accuracy: 0.9973\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0475 - accuracy: 0.9848 - val_loss: 0.0064 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0454 - accuracy: 0.9851 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0434 - accuracy: 0.9866 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0448 - accuracy: 0.9861 - val_loss: 0.0053 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0511 - accuracy: 0.9820 - val_loss: 0.0171 - val_accuracy: 0.9933\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0528 - accuracy: 0.9842 - val_loss: 0.0040 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0443 - accuracy: 0.9857 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 47ms/step - loss: 0.0528 - accuracy: 0.9818 - val_loss: 2.3712e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0508 - accuracy: 0.9858 - val_loss: 6.0640e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0482 - accuracy: 0.9852 - val_loss: 3.1149e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0416 - accuracy: 0.9875 - val_loss: 1.4018e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0489 - accuracy: 0.9852 - val_loss: 4.1150e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0369 - accuracy: 0.9872 - val_loss: 1.0975e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0333 - accuracy: 0.9893 - val_loss: 2.8639e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0383 - accuracy: 0.9872 - val_loss: 1.1016e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0534 - accuracy: 0.9855 - val_loss: 2.9436e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0331 - accuracy: 0.9905 - val_loss: 2.9861e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0471 - accuracy: 0.9851 - val_loss: 8.2682e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0374 - accuracy: 0.9899 - val_loss: 5.7989e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0467 - accuracy: 0.9852 - val_loss: 3.4353e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0422 - accuracy: 0.9884 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0346 - accuracy: 0.9902 - val_loss: 5.6704e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0284 - accuracy: 0.9918 - val_loss: 0.0020 - val_accuracy: 0.9987\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 47ms/step - loss: 0.0345 - accuracy: 0.9906 - val_loss: 0.0070 - val_accuracy: 0.9973\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0379 - accuracy: 0.9893 - val_loss: 9.9539e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0297 - accuracy: 0.9900 - val_loss: 5.4475e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0367 - accuracy: 0.9902 - val_loss: 8.4912e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0308 - accuracy: 0.9902 - val_loss: 8.5642e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0361 - accuracy: 0.9876 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0418 - accuracy: 0.9879 - val_loss: 4.7134e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0284 - accuracy: 0.9903 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0387 - accuracy: 0.9861 - val_loss: 0.0020 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0310 - accuracy: 0.9912 - val_loss: 5.3755e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0269 - accuracy: 0.9931 - val_loss: 0.0021 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0342 - accuracy: 0.9893 - val_loss: 8.6986e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0299 - accuracy: 0.9915 - val_loss: 7.9826e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0290 - accuracy: 0.9903 - val_loss: 4.4990e-04 - val_accuracy: 1.0000\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 48ms/step - loss: 0.0409 - accuracy: 0.9873 - val_loss: 2.0160e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0438 - accuracy: 0.9878 - val_loss: 4.2766e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0378 - accuracy: 0.9881 - val_loss: 4.5426e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0303 - accuracy: 0.9905 - val_loss: 1.4823e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0329 - accuracy: 0.9899 - val_loss: 7.9717e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0343 - accuracy: 0.9911 - val_loss: 3.2029e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0345 - accuracy: 0.9887 - val_loss: 1.3395e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0269 - accuracy: 0.9906 - val_loss: 4.6132e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0331 - accuracy: 0.9897 - val_loss: 9.3915e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0269 - accuracy: 0.9933 - val_loss: 8.6091e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0244 - accuracy: 0.9927 - val_loss: 2.1046e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0235 - accuracy: 0.9933 - val_loss: 6.1115e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0287 - accuracy: 0.9914 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0261 - accuracy: 0.9933 - val_loss: 7.0954e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0190 - accuracy: 0.9934 - val_loss: 0.0023 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0342 - accuracy: 0.9890 - val_loss: 1.4960e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0293 - accuracy: 0.9924 - val_loss: 3.5780e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0260 - accuracy: 0.9903 - val_loss: 6.2225e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0269 - accuracy: 0.9906 - val_loss: 1.4204e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0274 - accuracy: 0.9925 - val_loss: 4.9153e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0315 - accuracy: 0.9893 - val_loss: 1.4194e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0367 - accuracy: 0.9881 - val_loss: 9.1712e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0244 - accuracy: 0.9923 - val_loss: 7.4839e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0261 - accuracy: 0.9918 - val_loss: 7.7756e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0346 - accuracy: 0.9888 - val_loss: 2.3449e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0277 - accuracy: 0.9908 - val_loss: 2.2209e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0274 - accuracy: 0.9924 - val_loss: 8.0430e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0206 - accuracy: 0.9936 - val_loss: 4.2295e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0228 - accuracy: 0.9915 - val_loss: 3.3549e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0257 - accuracy: 0.9915 - val_loss: 2.4481e-04 - val_accuracy: 1.0000\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 50ms/step - loss: 0.0223 - accuracy: 0.9930 - val_loss: 7.6517e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0254 - accuracy: 0.9924 - val_loss: 5.0616e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0243 - accuracy: 0.9912 - val_loss: 3.0708e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0225 - accuracy: 0.9933 - val_loss: 4.2403e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0320 - accuracy: 0.9914 - val_loss: 2.7827e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0217 - accuracy: 0.9921 - val_loss: 4.4231e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0245 - accuracy: 0.9927 - val_loss: 3.7479e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0314 - accuracy: 0.9908 - val_loss: 0.0028 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0324 - accuracy: 0.9893 - val_loss: 1.0264e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0318 - accuracy: 0.9912 - val_loss: 4.9199e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 9.5109e-06 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0289 - accuracy: 0.9923 - val_loss: 5.7047e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0177 - accuracy: 0.9930 - val_loss: 1.4558e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 0.0021 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 1.5346e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0197 - accuracy: 0.9934 - val_loss: 3.7216e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0210 - accuracy: 0.9937 - val_loss: 2.5365e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0174 - accuracy: 0.9954 - val_loss: 3.3433e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 8.7142e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0307 - accuracy: 0.9911 - val_loss: 0.0021 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0263 - accuracy: 0.9921 - val_loss: 1.2726e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0239 - accuracy: 0.9924 - val_loss: 6.7900e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0181 - accuracy: 0.9931 - val_loss: 1.0210e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0255 - accuracy: 0.9939 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0258 - accuracy: 0.9912 - val_loss: 1.4752e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 0.0010 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0198 - accuracy: 0.9943 - val_loss: 3.9661e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0269 - accuracy: 0.9902 - val_loss: 0.0016 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0175 - accuracy: 0.9945 - val_loss: 2.2998e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0147 - accuracy: 0.9963 - val_loss: 4.2878e-05 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 48ms/step - loss: 0.0220 - accuracy: 0.9934 - val_loss: 4.8120e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0364 - accuracy: 0.9897 - val_loss: 5.8073e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0278 - accuracy: 0.9915 - val_loss: 6.7942e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0305 - accuracy: 0.9908 - val_loss: 1.9802e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0251 - accuracy: 0.9927 - val_loss: 1.9121e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0250 - accuracy: 0.9920 - val_loss: 2.0470e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0151 - accuracy: 0.9957 - val_loss: 1.7928e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0217 - accuracy: 0.9952 - val_loss: 5.8211e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0195 - accuracy: 0.9937 - val_loss: 1.6004e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0185 - accuracy: 0.9940 - val_loss: 7.7590e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0160 - accuracy: 0.9955 - val_loss: 2.2042e-06 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 47ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 1.3137e-06 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 1.0322e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0141 - accuracy: 0.9949 - val_loss: 1.9690e-06 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0173 - accuracy: 0.9945 - val_loss: 5.7535e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0255 - accuracy: 0.9931 - val_loss: 2.0329e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0235 - accuracy: 0.9920 - val_loss: 7.6057e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0280 - accuracy: 0.9921 - val_loss: 6.0900e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 6.9102e-06 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0216 - accuracy: 0.9946 - val_loss: 1.4213e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0217 - accuracy: 0.9948 - val_loss: 2.0028e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 47ms/step - loss: 0.0314 - accuracy: 0.9914 - val_loss: 0.0018 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0263 - accuracy: 0.9928 - val_loss: 8.6134e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0244 - accuracy: 0.9927 - val_loss: 3.3651e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0214 - accuracy: 0.9942 - val_loss: 1.8132e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0162 - accuracy: 0.9963 - val_loss: 3.4733e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 6.7133e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0184 - accuracy: 0.9946 - val_loss: 1.9758e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0189 - accuracy: 0.9934 - val_loss: 1.9253e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0126 - accuracy: 0.9948 - val_loss: 2.1142e-04 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0232 - accuracy: 0.9931 - val_loss: 3.0701e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0239 - accuracy: 0.9912 - val_loss: 1.3774e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 8.1565e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 1.2644e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0217 - accuracy: 0.9942 - val_loss: 3.7327e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0159 - accuracy: 0.9957 - val_loss: 2.4160e-06 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0209 - accuracy: 0.9928 - val_loss: 6.7520e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 2.2407e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 2.6148e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0226 - accuracy: 0.9934 - val_loss: 3.6828e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0172 - accuracy: 0.9958 - val_loss: 3.5605e-06 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 1.2811e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0217 - accuracy: 0.9939 - val_loss: 1.0347e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0170 - accuracy: 0.9946 - val_loss: 7.2650e-06 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 6.4345e-06 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 47ms/step - loss: 0.0174 - accuracy: 0.9948 - val_loss: 5.0793e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0175 - accuracy: 0.9957 - val_loss: 2.6465e-06 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 7.3483e-06 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0193 - accuracy: 0.9949 - val_loss: 4.5986e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0186 - accuracy: 0.9936 - val_loss: 4.4291e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 47ms/step - loss: 0.0277 - accuracy: 0.9923 - val_loss: 1.2300e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 3.7102e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0110 - accuracy: 0.9958 - val_loss: 1.5757e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 1.6250e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 1.1793e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0208 - accuracy: 0.9937 - val_loss: 5.7094e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 3.3777e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0118 - accuracy: 0.9954 - val_loss: 6.1571e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 5.5649e-06 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 47ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 7.0321e-04 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 48ms/step - loss: 0.0239 - accuracy: 0.9928 - val_loss: 5.7045e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0234 - accuracy: 0.9931 - val_loss: 1.4308e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0211 - accuracy: 0.9943 - val_loss: 5.9154e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0161 - accuracy: 0.9946 - val_loss: 2.9466e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0213 - accuracy: 0.9937 - val_loss: 2.7276e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 47ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 2.0229e-06 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0190 - accuracy: 0.9946 - val_loss: 4.0591e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0107 - accuracy: 0.9957 - val_loss: 7.5845e-07 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 3.2383e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 5.2355e-06 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 47ms/step - loss: 0.0171 - accuracy: 0.9945 - val_loss: 4.0772e-06 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 8.9119e-06 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0128 - accuracy: 0.9949 - val_loss: 4.9880e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0210 - accuracy: 0.9942 - val_loss: 4.8614e-06 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0165 - accuracy: 0.9957 - val_loss: 7.4400e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 6.8957e-06 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 2.6979e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0195 - accuracy: 0.9955 - val_loss: 8.0556e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0158 - accuracy: 0.9960 - val_loss: 1.1313e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 47ms/step - loss: 0.0164 - accuracy: 0.9955 - val_loss: 1.5227e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0207 - accuracy: 0.9939 - val_loss: 9.6028e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0155 - accuracy: 0.9945 - val_loss: 1.7615e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 47ms/step - loss: 0.0151 - accuracy: 0.9960 - val_loss: 1.0344e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0129 - accuracy: 0.9951 - val_loss: 8.1314e-06 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0187 - accuracy: 0.9948 - val_loss: 2.4814e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 1.0090e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0116 - accuracy: 0.9958 - val_loss: 2.9767e-06 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 47ms/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 1.5279e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0134 - accuracy: 0.9949 - val_loss: 1.8562e-06 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0154 - accuracy: 0.9955 - val_loss: 6.7083e-06 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "CAnc2SJa3o9f",
        "outputId": "b932c612-ab47-4be1-d5ca-2c72849fa6b8"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 10ms/step - loss: 0.0352 - accuracy: 0.9914\n",
            "Accuracy  : 0.991416335105896\n",
            "F1_Score  : 0.9886825995884801\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7fcxLuwZpkK",
        "outputId": "2daf3e8d-e286-431b-f31a-9d1e876b9dd0"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "0c7b7099-89b7-4e37-9b2c-7639451a6de8"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 5s 57ms/step - loss: 0.8849 - accuracy: 0.5447 - val_loss: 0.7950 - val_accuracy: 0.5737\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7862 - accuracy: 0.5905 - val_loss: 0.7908 - val_accuracy: 0.5737\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7800 - accuracy: 0.5915 - val_loss: 0.7874 - val_accuracy: 0.5737\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7674 - accuracy: 0.6029 - val_loss: 0.7852 - val_accuracy: 0.5737\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7757 - accuracy: 0.5946 - val_loss: 0.7855 - val_accuracy: 0.5737\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.7597 - accuracy: 0.6033 - val_loss: 0.7785 - val_accuracy: 0.5737\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7518 - accuracy: 0.6056 - val_loss: 0.7725 - val_accuracy: 0.5737\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.7419 - accuracy: 0.6097 - val_loss: 0.7647 - val_accuracy: 0.5737\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.7436 - accuracy: 0.5988 - val_loss: 0.7669 - val_accuracy: 0.5737\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7445 - accuracy: 0.6104 - val_loss: 0.7638 - val_accuracy: 0.5737\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.7398 - accuracy: 0.6159 - val_loss: 0.7605 - val_accuracy: 0.5885\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7344 - accuracy: 0.6214 - val_loss: 0.7578 - val_accuracy: 0.5845\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.7325 - accuracy: 0.6239 - val_loss: 0.7544 - val_accuracy: 0.5965\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.7239 - accuracy: 0.6245 - val_loss: 0.7837 - val_accuracy: 0.5898\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7154 - accuracy: 0.6350 - val_loss: 0.7503 - val_accuracy: 0.5938\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7262 - accuracy: 0.6322 - val_loss: 0.7612 - val_accuracy: 0.6099\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.7164 - accuracy: 0.6424 - val_loss: 0.7550 - val_accuracy: 0.6005\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.7141 - accuracy: 0.6405 - val_loss: 0.7364 - val_accuracy: 0.6247\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.7036 - accuracy: 0.6416 - val_loss: 0.7470 - val_accuracy: 0.6180\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.6897 - accuracy: 0.6562 - val_loss: 0.7426 - val_accuracy: 0.6032\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6923 - accuracy: 0.6404 - val_loss: 0.7250 - val_accuracy: 0.6220\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.6941 - accuracy: 0.6461 - val_loss: 0.7278 - val_accuracy: 0.6193\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.6854 - accuracy: 0.6484 - val_loss: 0.7234 - val_accuracy: 0.6233\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6789 - accuracy: 0.6517 - val_loss: 0.7198 - val_accuracy: 0.6206\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.6683 - accuracy: 0.6623 - val_loss: 0.7212 - val_accuracy: 0.6247\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.6766 - accuracy: 0.6536 - val_loss: 0.7071 - val_accuracy: 0.6287\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6632 - accuracy: 0.6717 - val_loss: 0.7623 - val_accuracy: 0.6247\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.6640 - accuracy: 0.6705 - val_loss: 0.7287 - val_accuracy: 0.6327\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.6471 - accuracy: 0.6677 - val_loss: 0.7178 - val_accuracy: 0.6193\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6588 - accuracy: 0.6618 - val_loss: 0.7168 - val_accuracy: 0.6340\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.6568 - accuracy: 0.6668 - val_loss: 0.5859 - val_accuracy: 0.6957\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.6428 - accuracy: 0.6750 - val_loss: 0.5528 - val_accuracy: 0.7118\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6362 - accuracy: 0.6821 - val_loss: 0.5839 - val_accuracy: 0.7131\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.6276 - accuracy: 0.6768 - val_loss: 0.5715 - val_accuracy: 0.7078\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6179 - accuracy: 0.6846 - val_loss: 0.5472 - val_accuracy: 0.7292\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.6104 - accuracy: 0.6891 - val_loss: 0.5393 - val_accuracy: 0.7373\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.5971 - accuracy: 0.7006 - val_loss: 0.5438 - val_accuracy: 0.7399\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 48ms/step - loss: 0.5891 - accuracy: 0.7037 - val_loss: 0.5123 - val_accuracy: 0.7547\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5768 - accuracy: 0.7115 - val_loss: 0.5032 - val_accuracy: 0.7547\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5624 - accuracy: 0.7204 - val_loss: 0.5094 - val_accuracy: 0.7574\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5539 - accuracy: 0.7301 - val_loss: 0.5061 - val_accuracy: 0.7560\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5302 - accuracy: 0.7398 - val_loss: 0.4812 - val_accuracy: 0.7788\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5311 - accuracy: 0.7431 - val_loss: 0.4977 - val_accuracy: 0.7681\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5073 - accuracy: 0.7598 - val_loss: 0.5414 - val_accuracy: 0.7346\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.5022 - accuracy: 0.7677 - val_loss: 0.4299 - val_accuracy: 0.8016\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4696 - accuracy: 0.7820 - val_loss: 0.4708 - val_accuracy: 0.7735\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4630 - accuracy: 0.7960 - val_loss: 0.4270 - val_accuracy: 0.8150\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4530 - accuracy: 0.7902 - val_loss: 0.4613 - val_accuracy: 0.7721\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4392 - accuracy: 0.8095 - val_loss: 0.4081 - val_accuracy: 0.8164\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3908 - accuracy: 0.8230 - val_loss: 0.4414 - val_accuracy: 0.7855\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3821 - accuracy: 0.8383 - val_loss: 0.3960 - val_accuracy: 0.8284\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3657 - accuracy: 0.8426 - val_loss: 0.3228 - val_accuracy: 0.8686\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3331 - accuracy: 0.8644 - val_loss: 0.4490 - val_accuracy: 0.7855\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3171 - accuracy: 0.8678 - val_loss: 0.2956 - val_accuracy: 0.8700\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2876 - accuracy: 0.8820 - val_loss: 0.3033 - val_accuracy: 0.8713\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2857 - accuracy: 0.8838 - val_loss: 0.2892 - val_accuracy: 0.8713\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2429 - accuracy: 0.9033 - val_loss: 0.2477 - val_accuracy: 0.8954\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2419 - accuracy: 0.9043 - val_loss: 0.3409 - val_accuracy: 0.8485\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2115 - accuracy: 0.9249 - val_loss: 0.2109 - val_accuracy: 0.9102\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1975 - accuracy: 0.9241 - val_loss: 0.2077 - val_accuracy: 0.9209\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.1938 - accuracy: 0.9259 - val_loss: 0.0955 - val_accuracy: 0.9625\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1977 - accuracy: 0.9230 - val_loss: 0.0551 - val_accuracy: 0.9812\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1894 - accuracy: 0.9292 - val_loss: 0.0625 - val_accuracy: 0.9826\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1629 - accuracy: 0.9399 - val_loss: 0.0535 - val_accuracy: 0.9799\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1506 - accuracy: 0.9461 - val_loss: 0.0421 - val_accuracy: 0.9879\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1251 - accuracy: 0.9550 - val_loss: 0.0501 - val_accuracy: 0.9812\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1328 - accuracy: 0.9520 - val_loss: 0.0356 - val_accuracy: 0.9893\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0961 - accuracy: 0.9677 - val_loss: 0.0413 - val_accuracy: 0.9879\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1253 - accuracy: 0.9539 - val_loss: 0.0769 - val_accuracy: 0.9732\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0970 - accuracy: 0.9633 - val_loss: 0.0462 - val_accuracy: 0.9786\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0972 - accuracy: 0.9645 - val_loss: 0.0489 - val_accuracy: 0.9839\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0974 - accuracy: 0.9692 - val_loss: 0.0307 - val_accuracy: 0.9906\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0724 - accuracy: 0.9762 - val_loss: 0.0327 - val_accuracy: 0.9906\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0868 - accuracy: 0.9700 - val_loss: 0.0261 - val_accuracy: 0.9906\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0725 - accuracy: 0.9753 - val_loss: 0.0403 - val_accuracy: 0.9839\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0769 - accuracy: 0.9732 - val_loss: 0.0355 - val_accuracy: 0.9826\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0672 - accuracy: 0.9769 - val_loss: 0.0737 - val_accuracy: 0.9786\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0741 - accuracy: 0.9744 - val_loss: 0.0487 - val_accuracy: 0.9879\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0692 - accuracy: 0.9766 - val_loss: 0.0531 - val_accuracy: 0.9839\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0674 - accuracy: 0.9776 - val_loss: 0.0209 - val_accuracy: 0.9920\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0551 - accuracy: 0.9797 - val_loss: 0.0475 - val_accuracy: 0.9812\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0733 - accuracy: 0.9772 - val_loss: 0.0461 - val_accuracy: 0.9786\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0614 - accuracy: 0.9815 - val_loss: 0.0333 - val_accuracy: 0.9906\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0489 - accuracy: 0.9841 - val_loss: 0.0267 - val_accuracy: 0.9920\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0459 - accuracy: 0.9861 - val_loss: 0.0218 - val_accuracy: 0.9906\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0579 - accuracy: 0.9818 - val_loss: 0.0538 - val_accuracy: 0.9799\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0593 - accuracy: 0.9811 - val_loss: 0.0508 - val_accuracy: 0.9812\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0443 - accuracy: 0.9848 - val_loss: 0.0328 - val_accuracy: 0.9906\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0376 - accuracy: 0.9867 - val_loss: 0.0418 - val_accuracy: 0.9826\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0609 - accuracy: 0.9817 - val_loss: 0.0646 - val_accuracy: 0.9772\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0665 - accuracy: 0.9793 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0507 - accuracy: 0.9851 - val_loss: 6.6586e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0429 - accuracy: 0.9857 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0435 - accuracy: 0.9876 - val_loss: 8.8193e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0428 - accuracy: 0.9858 - val_loss: 8.4856e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0437 - accuracy: 0.9866 - val_loss: 8.7756e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0492 - accuracy: 0.9827 - val_loss: 0.0032 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0384 - accuracy: 0.9866 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0462 - accuracy: 0.9860 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0417 - accuracy: 0.9875 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0391 - accuracy: 0.9891 - val_loss: 0.0029 - val_accuracy: 0.9987\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0485 - accuracy: 0.9835 - val_loss: 0.0024 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0421 - accuracy: 0.9864 - val_loss: 6.1163e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0215 - accuracy: 0.9934 - val_loss: 1.5734e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0292 - accuracy: 0.9909 - val_loss: 2.5524e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0307 - accuracy: 0.9891 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0340 - accuracy: 0.9890 - val_loss: 8.4335e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0402 - accuracy: 0.9885 - val_loss: 4.8686e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0288 - accuracy: 0.9915 - val_loss: 8.4321e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0210 - accuracy: 0.9936 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0326 - accuracy: 0.9912 - val_loss: 0.0022 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0361 - accuracy: 0.9890 - val_loss: 0.0020 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0488 - accuracy: 0.9836 - val_loss: 0.0074 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0283 - accuracy: 0.9905 - val_loss: 8.2221e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0253 - accuracy: 0.9925 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0347 - accuracy: 0.9888 - val_loss: 0.0143 - val_accuracy: 0.9946\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0229 - accuracy: 0.9925 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0234 - accuracy: 0.9936 - val_loss: 0.0058 - val_accuracy: 0.9973\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0307 - accuracy: 0.9908 - val_loss: 9.5854e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0227 - accuracy: 0.9923 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0304 - accuracy: 0.9905 - val_loss: 1.1161e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0239 - accuracy: 0.9921 - val_loss: 7.0092e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0275 - accuracy: 0.9918 - val_loss: 5.6224e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0344 - accuracy: 0.9909 - val_loss: 2.1577e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0227 - accuracy: 0.9931 - val_loss: 4.1451e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0244 - accuracy: 0.9925 - val_loss: 4.6375e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0224 - accuracy: 0.9930 - val_loss: 4.0343e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0359 - accuracy: 0.9881 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0372 - accuracy: 0.9896 - val_loss: 0.0040 - val_accuracy: 0.9987\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0301 - accuracy: 0.9911 - val_loss: 2.4282e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0227 - accuracy: 0.9915 - val_loss: 2.6455e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0293 - accuracy: 0.9911 - val_loss: 0.0026 - val_accuracy: 0.9973\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0293 - accuracy: 0.9915 - val_loss: 5.1910e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0288 - accuracy: 0.9914 - val_loss: 7.7493e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0226 - accuracy: 0.9927 - val_loss: 5.4302e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0242 - accuracy: 0.9934 - val_loss: 0.0016 - val_accuracy: 0.9987\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 0.0033 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0253 - accuracy: 0.9909 - val_loss: 5.2186e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0299 - accuracy: 0.9908 - val_loss: 6.2672e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0231 - accuracy: 0.9912 - val_loss: 3.2072e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0219 - accuracy: 0.9936 - val_loss: 0.0017 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0163 - accuracy: 0.9954 - val_loss: 2.5533e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 6.4526e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0291 - accuracy: 0.9894 - val_loss: 0.0061 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0212 - accuracy: 0.9946 - val_loss: 0.0054 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0296 - accuracy: 0.9906 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0223 - accuracy: 0.9927 - val_loss: 0.0028 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0136 - accuracy: 0.9951 - val_loss: 4.7532e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0288 - accuracy: 0.9903 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0275 - accuracy: 0.9906 - val_loss: 6.6566e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 3.9925e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0193 - accuracy: 0.9930 - val_loss: 3.6973e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 8.8718e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0207 - accuracy: 0.9931 - val_loss: 1.4930e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0172 - accuracy: 0.9940 - val_loss: 4.0436e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0184 - accuracy: 0.9954 - val_loss: 8.2707e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0292 - accuracy: 0.9902 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0292 - accuracy: 0.9911 - val_loss: 4.7471e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0204 - accuracy: 0.9931 - val_loss: 2.7054e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0258 - accuracy: 0.9923 - val_loss: 2.4605e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0173 - accuracy: 0.9958 - val_loss: 6.4768e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0230 - accuracy: 0.9934 - val_loss: 5.7237e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0173 - accuracy: 0.9951 - val_loss: 2.5696e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0211 - accuracy: 0.9921 - val_loss: 1.0633e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0184 - accuracy: 0.9937 - val_loss: 7.7903e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0212 - accuracy: 0.9934 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 8.6145e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0187 - accuracy: 0.9954 - val_loss: 0.0025 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0182 - accuracy: 0.9943 - val_loss: 6.3041e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 3.6986e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0140 - accuracy: 0.9952 - val_loss: 6.9601e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0188 - accuracy: 0.9934 - val_loss: 6.7638e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0244 - accuracy: 0.9931 - val_loss: 6.1038e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0137 - accuracy: 0.9946 - val_loss: 9.9687e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0149 - accuracy: 0.9948 - val_loss: 2.0282e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0196 - accuracy: 0.9928 - val_loss: 7.5029e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0271 - accuracy: 0.9925 - val_loss: 8.7478e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0250 - accuracy: 0.9920 - val_loss: 3.0939e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0136 - accuracy: 0.9960 - val_loss: 7.2114e-05 - val_accuracy: 1.0000\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0211 - accuracy: 0.9939 - val_loss: 1.6889e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 2.5692e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0125 - accuracy: 0.9955 - val_loss: 2.0865e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 3.6794e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0179 - accuracy: 0.9939 - val_loss: 2.6983e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 1.8930e-06 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 9.5247e-06 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0179 - accuracy: 0.9934 - val_loss: 4.8938e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0126 - accuracy: 0.9966 - val_loss: 4.7351e-06 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 3.8992e-06 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 2.5519e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0167 - accuracy: 0.9946 - val_loss: 8.4168e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0292 - accuracy: 0.9911 - val_loss: 5.3976e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0121 - accuracy: 0.9973 - val_loss: 7.3484e-06 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0190 - accuracy: 0.9951 - val_loss: 5.8943e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 6.2344e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0208 - accuracy: 0.9945 - val_loss: 1.2459e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0194 - accuracy: 0.9954 - val_loss: 1.4716e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 3.4686e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 1.7546e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 1.9557e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0253 - accuracy: 0.9921 - val_loss: 1.6909e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 9.5376e-06 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0127 - accuracy: 0.9964 - val_loss: 5.6200e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0172 - accuracy: 0.9951 - val_loss: 7.5089e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0230 - accuracy: 0.9936 - val_loss: 4.9807e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0200 - accuracy: 0.9948 - val_loss: 5.2877e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0215 - accuracy: 0.9940 - val_loss: 7.6032e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 1.9770e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0132 - accuracy: 0.9964 - val_loss: 0.0018 - val_accuracy: 0.9987\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0093 - accuracy: 0.9964 - val_loss: 6.5210e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 8.6247e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0129 - accuracy: 0.9966 - val_loss: 6.3618e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0182 - accuracy: 0.9957 - val_loss: 2.6279e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0194 - accuracy: 0.9927 - val_loss: 8.3834e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 2.7696e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 1.7181e-06 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 3.5198e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0140 - accuracy: 0.9951 - val_loss: 6.5364e-06 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 2.4293e-06 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0088 - accuracy: 0.9967 - val_loss: 2.2222e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0091 - accuracy: 0.9967 - val_loss: 8.0890e-06 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 5.1248e-06 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 5.6082e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0103 - accuracy: 0.9955 - val_loss: 5.5274e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 1.0223e-06 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 1.6850e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0076 - accuracy: 0.9984 - val_loss: 2.7064e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0197 - accuracy: 0.9946 - val_loss: 9.5638e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0198 - accuracy: 0.9928 - val_loss: 1.1775e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 8.6082e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0195 - accuracy: 0.9939 - val_loss: 1.4842e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0191 - accuracy: 0.9954 - val_loss: 1.4035e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 3.6891e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 1.3418e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0176 - accuracy: 0.9954 - val_loss: 3.2416e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0122 - accuracy: 0.9975 - val_loss: 4.4133e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0141 - accuracy: 0.9967 - val_loss: 2.2233e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0200 - accuracy: 0.9943 - val_loss: 2.9516e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0120 - accuracy: 0.9972 - val_loss: 1.1876e-05 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 47ms/step - loss: 0.0091 - accuracy: 0.9975 - val_loss: 4.9274e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 5.6243e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 1.4626e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0177 - accuracy: 0.9954 - val_loss: 0.0027 - val_accuracy: 0.9987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0189 - accuracy: 0.9949 - val_loss: 7.1983e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0108 - accuracy: 0.9972 - val_loss: 2.5218e-06 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0085 - accuracy: 0.9975 - val_loss: 1.2815e-06 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 5.2030e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 1.0452e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0166 - accuracy: 0.9961 - val_loss: 9.3037e-06 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0103 - accuracy: 0.9981 - val_loss: 1.7803e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 2.7154e-06 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0074 - accuracy: 0.9970 - val_loss: 5.0767e-06 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 1.7558e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0144 - accuracy: 0.9964 - val_loss: 1.2210e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 1.1320e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0146 - accuracy: 0.9946 - val_loss: 5.0124e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0121 - accuracy: 0.9957 - val_loss: 5.3587e-06 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0178 - accuracy: 0.9939 - val_loss: 3.2484e-06 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 3.2677e-06 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0076 - accuracy: 0.9972 - val_loss: 1.2160e-06 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 5.1064e-06 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0140 - accuracy: 0.9955 - val_loss: 1.4410e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0210 - accuracy: 0.9949 - val_loss: 5.7380e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0147 - accuracy: 0.9964 - val_loss: 5.6840e-06 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0116 - accuracy: 0.9967 - val_loss: 1.0118e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0126 - accuracy: 0.9967 - val_loss: 2.9641e-06 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 2.2645e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0137 - accuracy: 0.9964 - val_loss: 1.8580e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 7.3760e-06 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 3.0460e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0149 - accuracy: 0.9955 - val_loss: 8.9698e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0128 - accuracy: 0.9964 - val_loss: 2.5931e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 2.4779e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0068 - accuracy: 0.9973 - val_loss: 2.8293e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 5.4915e-07 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 6.7780e-07 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 2.9730e-07 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 1.2397e-06 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 1.3699e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 1.8308e-06 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 1.3612e-06 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0174 - accuracy: 0.9946 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 2.1332e-06 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0165 - accuracy: 0.9958 - val_loss: 1.2958e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 1.5757e-06 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0158 - accuracy: 0.9957 - val_loss: 8.9491e-06 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 1.0203e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0108 - accuracy: 0.9972 - val_loss: 1.1525e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 1.6232e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 2.6084e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0081 - accuracy: 0.9984 - val_loss: 1.1781e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 6.3809e-07 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 3.9860e-06 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0107 - accuracy: 0.9961 - val_loss: 3.4674e-06 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0239 - accuracy: 0.9925 - val_loss: 1.1165e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0149 - accuracy: 0.9961 - val_loss: 2.7806e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0147 - accuracy: 0.9948 - val_loss: 1.8989e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 2.3983e-06 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 1.3199e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "9d2dfdbf-9d71-4ae1-9667-2cdd3a45204a"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 9ms/step - loss: 0.0202 - accuracy: 0.9936\n",
            "Accuracy  : 0.9935622215270996\n",
            "F1_Score  : 0.9953810564848239\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAAKOCAYAAAAS8uXWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debhdZXk3/u+dBByKgFYSEIJSoSKirRNq+6sCyhAFgoKtQ2sH21gr4tiKE75ixYGq1Z8DRqRVW8eiiBLACiLIKwhFiwxag7UQlMQiWHFoIDzvH2cnHmJycgicrCfZn0+vfV17rb32Ws8K23Pd/d7rWataawEAoB+zhh4AAAC3p0ADAOiMAg0AoDMKNACAzijQAAA6o0ADAOiMAg0A4E6oqpOrakVVXb6ez6uq3lVVS6vqsqp6xIb2qUADALhz/jHJwVN8viDJHqPXoiTv29AOFWgAAHdCa+28JD+aYpOFST7cJlyYZPuq2mmqfc65Kwd4V7rHI1/kEQcM7saL3jn0ECBJcpunvtCJe25VNcRx7/Hwowb5H8EvvvGe52Ui9VptcWtt8R3czc5Jrp20vGy07gfr+0K3BRoAwNBGxdgdLcjuNC1OAICZdV2S+ZOWdxmtWy8FGgDQv5o1zOuucVqS54xmcz42yY9ba+ttbyZanAAAd0pVfSzJvknuW1XLkrwuyVZJ0lo7McmSJE9OsjTJz5L86Yb2qUADALgTWmvP3MDnLckL7sg+FWgAQP+GmTw6GNegAQB0RoIGAPTvrrtgf7MwXmcLALAZkKABAP1zDRoAAENSoAEAdEaLEwDon0kCAAAMSYIGAPTPJAEAAIYkQQMA+ucaNAAAhqRAAwDojBYnANA/kwQAABiSBA0A6J9JAgAADEmBBgDQGS1OAKB/JgkAADAkCRoA0D+TBAAAGJIEDQDon2vQAAAYkgINAKAzWpwAQP9MEgAAYEgSNACgfxI0AACGJEEDAPo3y202AAAYkAINAKAzWpwAQP9MEgAAYEgSNACgf57FCQDAkCRoAED/XIMGAMCQFGgAAJ3R4gQA+meSAAAAQ5KgAQD9M0kAAIAhKdAAADqjxQkA9M8kAQAAhiRBAwD6Z5IAAABDkqABAP1zDRoAAENSoAEAdEaLEwDon0kCAAAMSYIGAPTPJAEAAIYkQQMA+ucaNAAAhqRAAwDojBYnANA/LU4AAIYkQQMA+uc2GwAADEmCBgD0zzVoAAAMSYEGANAZLU4AoH8mCQAAMCQJGgDQP5MEAAAYkgINAKAzWpwAQP9MEgAAYEgSNACgeyVBAwBgSBI0AKB7EjQAAAalQAMA6IwWJwDQv/HqcErQAAB6I0EDALpnkgAAAIOSoAEA3ZOgAQAwKAUaAEBntDgBgO5pcQIAMCgJGgDQPQkaAACDkqABAP0brwBNggYA0BsF2mbqgMftmX8/5VW5/NTX5OV/8qRf+XzXHe+dJe97Qb728VfkrPcflZ3nbrfms7994aG55BPH5JJPHJMjD3j4phw2Y+aC88/LYU85KIccfEA++IHFQw+HLcAFXzk/hx9ycA5bcGBOPulXf1MrV67MK172khy24MD80TN/P9+/btmazz74gffnsAUH5vBDDs7/veD8Nes/+pEP58jDD80RCw/JP3/kQ2vWf/tbV+U5z/qD/MERh+dZv39ELv/mZTN7cjCJAm0zNGtW5e+PeXoWHv3+PPzIN+XpBz0ie+4273bbvOklC/PPp38t+zzjLTn+pLNy3FGHJkkO/v/2ym/vOT+PedZb8/g/fnte/Ef7516/drchToMt3KpVq3L8G4/Le088KZ857fScueTzuXrp0qGHxWZs1apVefPfHpd3v+8DOeW0z+fMJafn6qtv/5s69dP/knttu21OO+MLefYf/XHe+fa3JUmuvnppzjpjSf7ls5/Pe048KW96w3FZtWpVln7nP/LpUz6Vj3zsk/nEKafmvC+fm2uu+a8kyd+/7YQsev4L8olTTs3zjzo6f/+2Ezb5OfNLVTXIaygzVqBV1Z5V9Yqqetfo9YqqevBMHW+cPPoh98/V1/4w37vuhtxy66p86guX5pB9H3q7bfbcbcd8+eLvJEm+fPF3csgTJj5/8G475itfX5pVq27Lz36xMt/8zvdz4O/4z8Jd7/JvXpb58++fXebPz1Zbb52Dn/yUnPuls4ceFpuxy795WebvuuvEb2qrrXPQgifn3HNu/5s695yzc+jCw5MkTzrwoHztoq+mtZZzzzk7By14crbeeuvsvMsumb/rrrn8m5flP7/73ez90IflHve4R+bMmZNHPurROeeL/5pkoiD46c03J0luvvkn2WHu3E17woy1GSnQquoVST6eiUv6vjZ6VZKPVdUxM3HMcXK/udtl2fKb1ixft/ym7LzDdrfb5pvf+X4W7v9bSZKF+z0s225z99xnu3vmsu9clwMf9+Dc4+5b5de3/7U84VG7Z5d5996k42c8rFi+PDvutOOa5bnz5mX58uUDjojN3YoVyzNvx53WLM+bt2N+uGL5WtusyI6jbebMmZNttrlXbrrppvxwxfI165Nk7rwds2LF8jxw9z3y9UsvyU033Zif//zn+cr5X8711/8gSfLyV7wqf/+2E3LwE/fNO/7urXnhi1+6Cc6S9Rm3BG2mZnE+N8lDWmu3TF5ZVW9PckWSN6/rS1W1KMmiJJmz6/6Zc9+9Z2h4W75XvuPUvOMVR+YPD9knF3z96ly3/KasWtVy9oXfziP32jVfOvnF+e8bf5qLvvm9rFp129DDBRjEbzzwgfmTP/uL/NWi5+bu97hnHvSgB2f2rNlJkk994mN52SuOyZMOOChfOPOMvP7Y1+T9J/3DwCNmXMxUi/O2JPdbx/qdRp+tU2ttcWvtUa21RynO1u/7K36cXeZtv2Z553nb57of/vh22/zgv/8nz/jrk/O4Z5+Q173n80mSH9/88yTJW0/+1zz2WSfkkBe8N1WV71zzw003eMbG3Hnzcv0Prl+zvGL58sybN2+Kb8DU5s6dl+WjdCtJli+/PjvMnbfWNnPXJGC33nprbr75J9l+++2zw9x5a9YnyYrl12fu6LtPPeLIfPSTn87JH/qnbLvttrn/Ax6QJPn8aafmiU86MElywEEH5wqTBNiEZqpAe3GSs6vqjKpaPHqdmeTsJC+aoWOOjUuuvCa7z98h97/ffbLVnNl5+oGPyOlfvvx22/z69r+2Jpr96z89IB867cIkExMM7rPdPZMke+9+v+y9+/3yxQu/tWlPgLHwkL0fmmuu+V6WLbs2t6xcmTOXnJ4n7Lf/0MNiMzbxm/qvXLdsWW65ZWXOOmNJ9l3rN/WE/fbP5z57apLki184K49+zGNTVdl3v/1z1hlLsnLlyly3bFmuuea/svdDH5Yk+dENNyRJfvCD7+ecs/81C558SJJkhx3m5t8u/lqS5GsXXZhd73//TXWqrIMW512gtXZmVf1mkn2S7DxafV2Si1trq2bimONk1arb8pK3npLPvfv5mT17Vj702Qtz1Xevz2v/ckEuvfLanH7e5Xn8I3fPcUcdmtZavvL1q/PiN38qSbLVnNn54kkTNfJPfvqL/NlrP6LFyYyYM2dOXvnqY/P8RX+e225blcOfekR2332PoYfFZmzOnDl5xatem7963nNz26rbsvCpR+SBu++R9777XdnrIXtn3/32z+FPOzKveeXf5LAFB2bb7bbLm094e5LkgbvvkQMPWpAjDntKZs+ZnWNefWxmz55oZb78JUfnpptuypw5c3LMq4/NvbbdNkny2te/ISe8+Y259dZVudvd7pbXvO64wc6d8VOttaHHsE73eOSL+hwYY+XGi9459BAgSXJbp3+rGT/33GqYWOnXn/OxQf5HcMOHnznI+boPGgBAZzyLEwDon2dxAgAwJAUaAEBntDgBgO4NecuLIUjQAAA6I0EDALonQQMAYFASNACgexI0AAAGpUADAOiMFicA0L/x6nBK0AAA7oyqOriqvl1VS6vqmHV8vmtVfamqvl5Vl1XVkze0TwkaANC9XicJVNXsJO9JckCSZUkurqrTWmtXTtrsNUk+2Vp7X1XtlWRJkgdMtV8JGgDAxtsnydLW2ndbayuTfDzJwrW2aUm2Hb3fLsn3N7RTBRoAwHpU1aKqumTSa9Fam+yc5NpJy8tG6yb7P0n+sKqWZSI9e+GGjqvFCQB0b6gWZ2ttcZLFd3I3z0zyj621t1XV45J8pKr2bq3dtr4vSNAAADbedUnmT1reZbRusucm+WSStNa+muTuSe471U4VaABA96pqkNc0XJxkj6raraq2TvKMJKettc01SZ44Oo8HZ6JA++FUO1WgAQBspNbarUmOSnJWkqsyMVvziqo6rqoOG232siR/UVX/nuRjSf6ktdam2q9r0ACA7vV6m40kaa0tycTF/5PXHTvp/ZVJfveO7FOCBgDQGQUaAEBntDgBgP712+GcERI0AIDOSNAAgO71PElgJkjQAAA6I0EDALonQQMAYFAKNACAzmhxAgDd0+IEAGBQEjQAoH/jFaBJ0AAAeiNBAwC65xo0AAAGpUADAOiMFicA0D0tTgAABiVBAwC6J0EDAGBQCjQAgM5ocQIA3dPiBABgUBI0AKB/4xWgSdAAAHojQQMAuucaNAAABqVAAwDojBYnANA9LU4AAAYlQQMAujdmAZoEDQCgNxI0AKB7rkEDAGBQCjQAgM5ocQIA3RuzDqcEDQCgNxI0AKB7JgkAADAoCRoA0L0xC9AkaAAAvVGgAQB0RosTAOjerFnj1eOUoAEAdEaCBgB0zyQBAAAGpUADAOiMFicA0D1PEgAAYFASNACge2MWoEnQAAB6I0EDALrnGjQAAAalQAMA6IwWJwDQPS1OAAAGJUEDALo3ZgGaBA0AoDcSNACge65BAwBgUAo0AIDOaHECAN0bsw6nBA0AoDcSNACgeyYJAAAwKAkaANC9MQvQJGgAAL1RoAEAdEaLEwDonkkCAAAMSoIGAHRvzAI0CRoAQG8UaAAAndHiBAC6Z5IAAACD6jZBu/Gidw49BMi9H33U0EOAJMmNF7976CHAoMYsQJOgAQD0ptsEDQBgNdegAQAwKAUaAEBntDgBgO6NWYdTggYA0BsJGgDQPZMEAAAYlAQNAOjemAVoEjQAgN4o0AAAOqPFCQB0zyQBAAAGJUEDALonQQMAYFASNACge2MWoEnQAAB6o0ADAOiMFicA0D2TBAAAGJQEDQDo3pgFaBI0AIDeKNAAADqjxQkAdM8kAQAABiVBAwC6N2YBmgQNAKA3EjQAoHuzxixCk6ABAHRGgQYA0BktTgCge2PW4ZSgAQD0RoIGAHTPjWoBABiUBA0A6N6s8QrQJGgAAL1RoAEA3AlVdXBVfbuqllbVMevZ5ver6sqquqKqPrqhfWpxAgDd63WSQFXNTvKeJAckWZbk4qo6rbV25aRt9kjyyiS/21q7sarmbmi/EjQAgI23T5KlrbXvttZWJvl4koVrbfMXSd7TWrsxSVprKza0UwUaANC9qmFe07BzkmsnLS8brZvsN5P8ZlVdUFUXVtXBG9qpFicAwHpU1aIkiyatWtxaW3wHdzMnyR5J9k2yS5LzquqhrbWbpvoCAEDXKsNcgzYqxqYqyK5LMn/S8i6jdZMtS3JRa+2WJP9ZVf+RiYLt4vXtVIsTAGDjXZxkj6raraq2TvKMJKettc2pmUjPUlX3zUTL87tT7VSBBgCwkVprtyY5KslZSa5K8snW2hVVdVxVHTba7KwkN1TVlUm+lOSvW2s3TLVfLU4AoHs9P0mgtbYkyZK11h076X1L8tLRa1okaAAAnZGgAQDd6/VGtTNFggYA0BkFGgBAZ7Q4AYDujVmHU4IGANAbCRoA0L1ZYxahSdAAADojQQMAujdmAZoEDQCgNwo0AIDOaHECAN3zJAEAAAYlQQMAujdmAZoEDQCgNxI0AKB7blQLAMCgFGgAAJ3R4gQAujdeDU4JGgBAdyRoAED33KgWAIBBSdAAgO7NGq8ATYIGANAbBRoAQGe0OAGA7pkkAADAoCRoAED3xixAk6ABAPRGgQYA0BktTgCgeyYJAAAwKAkaANC9cXuSwHoLtKr6/5O09X3eWjt6RkYEADDmpkrQLtlkowAAmMK4XYO23gKttfahyctVdc/W2s9mfkgAAONtg5MEqupxVXVlkm+Nln+rqt474yMDABhT05nF+fdJDkpyQ5K01v49yeNnclAAAJPVQK+hTOs2G621a9datWoGxgIAQKZ3m41rq+p3krSq2irJi5JcNbPDAgD4pVljNklgOgnaXyZ5QZKdk3w/yW+PlgEAmAEbTNBaa/+d5NmbYCwAAOs0ZgHatGZx/kZVfa6qflhVK6rqs1X1G5ticAAA42g6Lc6PJvlkkp2S3C/Jp5J8bCYHBQAwzqZToN2ztfaR1tqto9c/Jbn7TA8MAGC1qhrkNZSpnsV5n9HbM6rqmCQfz8SzOf8gyZJNMDYAgLE01SSBf8tEQba6fHzepM9aklfO1KAAACYbt0kCUz2Lc7dNORAAACZM50a1qaq9k+yVSdeetdY+PFODAgAYZxss0KrqdUn2zUSBtiTJgiRfSaJAAwA2CU8S+FVHJnlikutba3+a5LeSbDejowIAGGPTKdB+3lq7LcmtVbVtkhVJ5s/ssLizLjj/vBz2lINyyMEH5IMfWDz0cBhTJ77u2fmvs9+USz71qqGHwpjzN3HzVzXMayjTKdAuqartk3wgEzM7L03y1RkdFXfKqlWrcvwbj8t7Tzwpnznt9Jy55PO5eunSoYfFGPrI5y7Mwhe8Z+hhMOb8TWRzNJ1ncf7V6O2JVXVmkm1ba5fN7LC4My7/5mWZP//+2WX+RNB58JOfknO/dHYeuPvuA4+McXPBpVdn153us+ENYQb5m7hlGPKmsUNYb4JWVY9Y+5XkPknmjN5vlKr60439LtOzYvny7LjTjmuW586bl+XLlw84IoDh+JvI5miqBO1tU3zWkuy/kcd8fZJ/WNcHVbUoyaIkefd735/n/sWijTwEAMDma6ob1e63sTutqvW1QCvJvCmOuTjJ4iT5xa1pG3v8cTd33rxc/4Pr1yyvWL488+at958dYIvmb+KWYToXzW9JZup85yV5TpJD1/G6YYaOychD9n5orrnme1m27NrcsnJlzlxyep6w38YGngCbN38T2RxN60kCG+HzSbZprX1j7Q+q6twZOiYjc+bMyStffWyev+jPc9ttq3L4U4/I7rvvMfSwGEMfetOf5PceuUfuu/02WXrmG/KGE5fkQ6eaBM6m5W/ilmHcJglUa312ErU46cG9H33U0EOAJMmNF7976CFAkuTuczJIpXT0qd8apC541+F7DnK+03nUUyV5dpLfaK0dV1W7Jtmxtfa1GR8dAECSWeMVoE3rGrT3JnlckmeOln+SxJ0nAQBmyHSuQXtMa+0RVfX1JGmt3VhVW8/wuAAAxtZ0CrRbqmp2Ju59lqraIcltMzoqAIBJtDh/1buSfCbJ3Kp6Y5KvJDl+RkcFADDGpvMszn+uqn9L8sRM3Gj28NbaVTM+MgCAkXG7zcZ0ZnHumuRnST43eV1r7ZqZHBgAwLiazjVop2fi+rNKcvckuyX5dpKHzOC4AADWGLdr0KbT4nzo5OWqekSSv5qxEQEAjLk7/CzO1tqlSR4zA2MBACDTuwbtpZMWZyV5RJLvz9iIAADWMmZzBKZ1Ddq9Jr2/NRPXpJ0yM8MBAGDKAm10g9p7tdZevonGAwDwK2aNWYS23mvQqmpOa21Vkt/dhOMBABh7UyVoX8vE9WbfqKrTknwqyU9Xf9ha+/QMjw0AYCxN5xq0uye5Icn++eX90FoSBRoAsEnc4dtObOamKtDmjmZwXp5fFmartRkdFQDAGJuqQJudZJvcvjBbTYEGAGwyYzZHYMoC7QetteM22UgAAEgydYE2ZrUqANArt9n4pSduslEAALDGegu01tqPNuVAAACYMJ3bbAAADGrMOpxjd1sRAIDuSdAAgO7NkqABADAkCRoA0D232QAAYFAKNACAzmhxAgDdG7MOpwQNAKA3EjQAoHtuswEAwKAkaABA9yrjFaFJ0AAAOqNAAwDojBYnANA9kwQAABiUBA0A6J4EDQCAQSnQAAA6o8UJAHSvxuxhnBI0AIDOSNAAgO6ZJAAAwKAkaABA98bsEjQJGgBAbxRoAACd0eIEALo3a8x6nBI0AIDOSNAAgO65zQYAAINSoAEA3asa5jW9sdXBVfXtqlpaVcdMsd0RVdWq6lEb2qcCDQBgI1XV7CTvSbIgyV5JnllVe61ju3sleVGSi6azXwUaAMDG2yfJ0tbad1trK5N8PMnCdWz3hiRvSfKL6exUgQYAdG9WapDXNOyc5NpJy8tG69aoqkckmd9aO3365wsAwDpV1aKqumTSa9Ed/P6sJG9P8rI78j232QAAujfUfWpba4uTLJ5ik+uSzJ+0vMto3Wr3SrJ3knNr4iR2THJaVR3WWrtkfTuVoAEAbLyLk+xRVbtV1dZJnpHktNUfttZ+3Fq7b2vtAa21ByS5MMmUxVkiQQMANgO93qi2tXZrVR2V5Kwks5Oc3Fq7oqqOS3JJa+20qfewbgo0AIA7obW2JMmStdYdu55t953OPrU4AQA6I0EDALo3a6hZAgORoAEAdEaCBgB0b8wCNAkaAEBvFGgAAJ3R4gQAumeSAAAAg5KgAQDdG7MATYIGANAbCRoA0L1xS5TG7XwBALqnQAMA6IwWJwDQvRqzWQISNACAzkjQAIDujVd+JkEDAOiOBA0A6J5HPQEAMCgFGgBAZ7Q4AYDujVeDU4IGANAdCRoA0L0xmyMgQQMA6I0EDQDonkc9AQAwKAUaAEBntDgBgO6NW6I0bucLANA9CRoA0D2TBAAAGJQCDQCgM1qcAED3xqvBKUEDAOiOBA0A6N64TRLotkBrbegRQHLjxe8eegiQJLn3PkcPPQRIkvz80ncNPYSx0G2BBgCw2rhdkzVu5wsA0D0FGgBAZ7Q4AYDujdskAQkaAEBnJGgAQPfGKz+ToAEAdEeCBgB0b8wuQZOgAQD0RoEGANAZLU4AoHuzxmyagAQNAKAzEjQAoHsmCQAAMCgJGgDQvXINGgAAQ1KgAQB0RosTAOieSQIAAAxKggYAdM+NagEAGJQCDQCgM1qcAED3TBIAAGBQEjQAoHsSNAAABiVBAwC651mcAAAMSoEGANAZLU4AoHuzxqvDKUEDAOiNBA0A6J5JAgAADEqCBgB0z41qAQAYlAINAKAzWpwAQPdMEgAAYFASNACge25UCwDAoCRoAED3XIMGAMCgFGgAAJ3R4gQAuudJAgAADEqCBgB0b8wCNAkaAEBvFGgAAJ3R4gQAujdrzGYJSNAAADojQQMAujde+ZkEDQCgOxI0AKB/YxahSdAAADqjQAMA6IwWJwDQvRqzHqcEDQCgMxI0AKB7Y3afWgkaAEBvJGgAQPfGLECToAEA9EaBBgDQGS1OAKB/Y9bjlKABAHRGggYAdM+NagEAGJQCDQCgM1qcAED3PEkAAIBBSdAAgO6NWYAmQQMA6I0EDQDo35hFaBI0AIDOKNAAADqjxQkAdM+TBAAAGJQEDQDonhvVAgAwbVV1cFV9u6qWVtUx6/j8pVV1ZVVdVlVnV9X9N7RPBRoA0L0a6LXBcVXNTvKeJAuS7JXkmVW111qbfT3Jo1prD0vyL0neuqH9KtAAADbePkmWtta+21pbmeTjSRZO3qC19qXW2s9Gixcm2WVDO1WgAQCsR1UtqqpLJr0WrbXJzkmunbS8bLRufZ6b5IwNHdckAQCgfwNNEmitLU6y+K7YV1X9YZJHJXnChrZVoAEAbLzrksyftLzLaN3tVNWTkrw6yRNaa/+7oZ0q0ACA7nV8o9qLk+xRVbtlojB7RpJnTd6gqh6e5P1JDm6trZjOTl2DBgCwkVprtyY5KslZSa5K8snW2hVVdVxVHTba7IQk2yT5VFV9o6pO29B+JWgAQPd6vlFta21JkiVrrTt20vsn3dF9StAAADqjQAMA6IwWJwDQvY47nDNCggYA0BkJGgDQvzGL0CRoAACdUaABAHRGixMA6F7HTxKYERI0AIDOSNAAgO71/CSBmSBB69wFXzkvCw85KIcuOCAnn7T4Vz5fuXJl/uZlL86hCw7IHz7z6bnuumVrPvvgB96fQxcckIWHHJT/e8H5t/veqlWr8gdHHp4X/tXz1qx77auPyZMP2j+/f8TC/P4RC/Otb101cyfGWLjg/PNy2FMOyiEHH5APfuBXf7+wKZz4umflv774xlzyyWOGHgpMmwKtY6tWrcqb/va4vOd9J+XTp52eM5d8PldfvfR223zm05/Ktttum8+d8a/5wz/6k7zz7X+XJLn66qU564zTc8pnT897Tzwpx7/h9Vm1atWa7330nz6c3X7jgb9yzJe87G/yyVM+m0+e8tnsueeDZ/YE2aKtWrUqx7/xuLz3xJPymdW/36VLN/xFuIt95HMXZeFR7xt6GNxJNdBrKDNWoFXVnlX1xKraZq31B8/UMbc0l3/zsszf9f7ZZf78bLXV1jlowVNy7jln326bc885J4cufGqS5EkHHpSvXfTVtNZy7jln56AFT8nWW2+dnXeZn/m73j+Xf/OyJMny66/P+eedm6cdceQmPyfGx+XfvCzz549+v1tvnYOf/JSc+6WzN/xFuItdcOnV+dGPfzb0MOAOmZECraqOTvLZJC9McnlVLZz08fEzccwt0YoVy7PjjjuuWZ43b15WrFi+jm12SpLMmTMn22xzr9x0041TfveEtxyfF7/0r1P1q//53/2ud+TpTz00J7zl+KxcuXImTosxsWL58uy40y9/g3Pnzcvy5cun+AYAq81UgvYXSR7ZWjs8yb5JXltVLxp9tt7EsKoWVdUlVXXJB9dxvRV33nnnfin3vs99stdD9v6Vz45+8Utz6ufOzD9/4pT8+Mc/zj980H8DADoxZj3OmZrFOau1dnOStNa+V1X7JvmXqrp/pjjd1triJIuT5Oe3pM3Q2DYbc+fOy/XXX79mefny5Zk7d946tvlB5u24Y2699dbcfPNPsv32917vd7/8pbgvi+sAAAoxSURBVHPy5XPPyVfOPy8r//d/89Of3pxXveLlOf4tf5cddpibJNl6662z8PCn5cP/ePKmOVG2SHPnzcv1P/jlb3DF8uWZN2/eFN8AYLWZStCWV9Vvr14YFWuHJLlvkofO0DG3OA/Z+6G55prv5bpl1+aWW1bmrDNOzxP22/922zxhv/3zuc9+JknyxS+clUc/5rGpqjxhv/1z1hmnZ+XKlblu2bW55prvZe+HPixHv+Rl+cLZ5+WML5yTN5/w9jx6n8fm+LdMTCz44Q9XJElaa/nSOV/M7nvssWlPmC3K6t/vsmXX5paVK3Pmkl/9/QJMVw30f0OZqQTtOUlunbyitXZrkudU1ftn6JhbnDlz5uSYVx2b5z/vz3PbqlVZ+NQjsvvue+S9735n9nrI3tl3vyfmqU87Mq9+5V/n0AUHZNvttstbTnhHkmT33ffIAQctyNMOe3Jmz5mdV7762MyePXvK473qFS/PjTfemNZaHvSgPfOa171+U5wmW6g5c+bkla8+Ns9f9Oe57bZVOXz0+4VN7UPH/3F+75G7577bb5OlZxyXN5y4JB/67IVDDwumVK312UnU4qQH43ZjRPp1732OHnoIkCT5+aXvGuQv47ev/9kgdcGDdrznIOfrPmgAAJ1RoAEAdMazOAGA7o3bFScSNACAzkjQAID+jVmEJkEDAOiMBA0A6N6QN40dggQNAKAzCjQAgM5ocQIA3Ru3J7tI0AAAOiNBAwC6N2YBmgQNAKA3CjQAgM5ocQIA/RuzHqcEDQCgMxI0AKB7niQAAMCgJGgAQPfcqBYAgEEp0AAAOqPFCQB0b8w6nBI0AIDeSNAAgP6NWYQmQQMA6IwEDQDonhvVAgAwKAUaAEBntDgBgO55kgAAAIOSoAEA3RuzAE2CBgDQGwkaANA916ABADAoBRoAQGe0OAGAzcB49TglaAAAnZGgAQDdM0kAAIBBKdAAADqjxQkAdG/MOpwSNACA3kjQAIDumSQAAMCgJGgAQPdqzK5Ck6ABAHRGgQYA0BktTgCgf+PV4ZSgAQD0RoIGAHRvzAI0CRoAQG8kaABA99yoFgCAQSnQAAA6o8UJAHTPkwQAABiUBA0A6N94BWgSNACA3kjQAIDujVmAJkEDAOiNAg0AoDNanABA9zxJAACAQUnQAIDuuVEtAACDUqABAHRGixMA6J5JAgAADEqBBgDQGQUaAEBnXIMGAHTPNWgAAAxKgQYA0BktTgCge54kAADAoCRoAED3TBIAAGBQEjQAoHtjFqBJ0AAAeqNAAwDojBYnANC/MetxStAAADojQQMAuudGtQAADEqCBgB0z41qAQAYlAINAKAzWpwAQPfGrMMpQQMA6I0EDQDo35hFaBI0AIDOKNAAADqjxQkAdM+TBAAAmLaqOriqvl1VS6vqmHV8freq+sTo84uq6gEb2qcCDQDoXtUwrw2Pq2YneU+SBUn2SvLMqtprrc2em+TG1truSd6R5C0b2q8CDQBg4+2TZGlr7buttZVJPp5k4VrbLEzyodH7f0nyxKqpy79ur0G7x1Zj1myeAVW1qLW2eOhxgN/inffzS9819BA2e36Hm7e7zxmmLqiqRUkWTVq1eK3f0c5Jrp20vCzJY9bazZptWmu3VtWPk/x6kv9e33ElaFu2RRveBDYJv0V64HfIHdZaW9xae9Sk1yYp8hVoAAAb77ok8yct7zJat85tqmpOku2S3DDVThVoAAAb7+Ike1TVblW1dZJnJDltrW1OS/LHo/dHJjmntdam2mm316Bxl3CtBb3wW6QHfofc5UbXlB2V5Kwks5Oc3Fq7oqqOS3JJa+20JB9M8pGqWprkR5ko4qZUGyjgAADYxLQ4AQA6o0ADAOiMAm0LtaHHTsCmUFUnV9WKqrp86LEwvqpqflV9qaqurKorqupFQ48JNsQ1aFug0WMn/iPJAZm4Yd7FSZ7ZWrty0IExdqrq8UluTvLh1treQ4+H8VRVOyXZqbV2aVXdK8m/JTnc30R6JkHbMk3nsRMw41pr52VixhIMprX2g9bapaP3P0lyVSbu7A7dUqBtmdb12Al/jICxV1UPSPLwJBcNOxKYmgINgLFQVdskOSXJi1tr/zP0eGAqCrQt03QeOwEwNqpqq0wUZ//cWvv00OOBDVGgbZmm89gJgLFQVZWJO7lf1Vp7+9DjgelQoG2BWmu3Jln92ImrknyytXbFsKNiHFXVx5J8NcmDqmpZVT136DExln43yR8l2b+qvjF6PXnoQcFU3GYDAKAzEjQAgM4o0AAAOqNAAwDojAINAKAzCjQAgM4o0GALVFWrRrcSuLyqPlVV97wT+/rHqjpy9P6kqtprim33rarf2YhjfK+q7jvd9Wttc/MdPNb/qaqX39ExAmxKCjTYMv28tfbbrbW9k6xM8peTP6yqORuz09ban7fWrpxik32T3OECDYDbU6DBlu/8JLuP0q3zq+q0JFdW1eyqOqGqLq6qy6rqecnEXder6t1V9e2q+mKSuat3VFXnVtWjRu8PrqpLq+rfq+rs0UOo/zLJS0bp3e9V1Q5VdcroGBdX1e+OvvvrVfWFqrqiqk5KUhs6iao6tar+bfSdRWt99o7R+rOraofRugdW1Zmj75xfVXveFf+YAJvCRv1/0cDmYZSULUhy5mjVI5Ls3Vr7z1GR8+PW2qOr6m5JLqiqLyR5eJIHJdkrybwkVyY5ea397pDkA0keP9rXfVprP6qqE5Pc3Fr7u9F2H03yjtbaV6pq10w83eLBSV6X5CutteOq6ilJpvOEgT8bHeMeSS6uqlNaazck+bUkl7TWXlJVx472fVSSxUn+srX2nap6TJL3Jtl/I/4ZATY5BRpsme5RVd8YvT8/E88h/J0kX2ut/edo/YFJHrb6+rIk2yXZI8njk3ystbYqyfer6px17P+xSc5bva/W2o/WM44nJdlr4lGISZJtq2qb0TGeNvru6VV14zTO6eiqeuro/fzRWG9IcluST4zW/1OST4+O8TtJPjXp2HebxjEAuqBAgy3Tz1trvz15xahQ+enkVUle2Fo7a63t7spnFM5K8tjW2i/WMZZpq6p9M1HsPa619rOqOjfJ3dezeRsd96a1/w0ANheuQYPxdVaS51fVVklSVb9ZVb+W5LwkfzC6Rm2nJPut47sXJnl8Ve02+u59Rut/kuRek7b7QpIXrl6oqtUF03lJnjVatyDJvTcw1u2S3DgqzvbMRIK32qwkq1PAZ2Widfo/Sf6zqp4+OkZV1W9t4BgA3VCgwfg6KRPXl11aVZcneX8mUvXPJPnO6LMPJ/nq2l9srf0wyaJMtBP/Pb9sMX4uyVNXTxJIcnSSR40mIVyZX84mfX0mCrwrMtHqvGYDYz0zyZyquirJmzNRIK720yT7jM5h/yTHjdY/O8lzR+O7IsnCafybAHShWmtDjwEAgEkkaAAAnVGgAQB0RoEGANAZBRoAQGcUaAAAnVGgAQB0RoEGANCZ/wfkjaUKiCvtbgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}