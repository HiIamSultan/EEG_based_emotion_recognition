{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub18_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "6a34a857-5f5d-4c08-d65a-3bc012641f63"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e3\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  #EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "95a6af7b-e951-4766-f1b4-d976012e5373"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(18,19):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)\n",
        "print(valence.shape)\n",
        "print(arousal.shape)\n",
        "print(dominance.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.18\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (932,) (4194,) (4194,)\n",
            "(9320,) (1165,) (3961,) (4194,)\n",
            "(9320,) (466,) (4194,) (4660,)\n",
            "(9320, 3)\n",
            "(9320, 3)\n",
            "(9320, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "3a9200ea-380e-4cc0-c36f-2710849de389"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "c42e40bc-5fd9-48a2-c405-2ffaeb5c6cd0"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "974"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "62caa285-e255-43a0-9bff-0b6908f3d15c"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b73e7c41-3cca-48b9-efe8-7f2ae3d78ae6"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 49s 70ms/step - loss: 1.1347 - accuracy: 0.4213 - val_loss: 0.9660 - val_accuracy: 0.4357\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9522 - accuracy: 0.4492 - val_loss: 0.9379 - val_accuracy: 0.4651\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.9511 - accuracy: 0.4509 - val_loss: 0.9311 - val_accuracy: 0.4584\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9493 - accuracy: 0.4678 - val_loss: 0.9291 - val_accuracy: 0.5134\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9425 - accuracy: 0.4621 - val_loss: 0.9388 - val_accuracy: 0.4330\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9439 - accuracy: 0.4564 - val_loss: 0.9406 - val_accuracy: 0.4987\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9408 - accuracy: 0.4710 - val_loss: 0.9427 - val_accuracy: 0.4799\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9324 - accuracy: 0.4638 - val_loss: 0.9265 - val_accuracy: 0.4973\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.9303 - accuracy: 0.4743 - val_loss: 0.9359 - val_accuracy: 0.4812\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9299 - accuracy: 0.4907 - val_loss: 0.9391 - val_accuracy: 0.4611\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9327 - accuracy: 0.4575 - val_loss: 0.9348 - val_accuracy: 0.4692\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9306 - accuracy: 0.4799 - val_loss: 0.9357 - val_accuracy: 0.4397\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.9148 - accuracy: 0.4865 - val_loss: 0.9327 - val_accuracy: 0.4611\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9108 - accuracy: 0.4853 - val_loss: 0.9216 - val_accuracy: 0.5147\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.9237 - accuracy: 0.4807 - val_loss: 0.9129 - val_accuracy: 0.4893\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9145 - accuracy: 0.4857 - val_loss: 0.9207 - val_accuracy: 0.4973\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.9112 - accuracy: 0.4806 - val_loss: 0.9671 - val_accuracy: 0.4651\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9057 - accuracy: 0.4835 - val_loss: 0.9362 - val_accuracy: 0.4491\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9216 - accuracy: 0.4826 - val_loss: 0.9135 - val_accuracy: 0.5054\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9086 - accuracy: 0.4858 - val_loss: 0.9158 - val_accuracy: 0.5134\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9139 - accuracy: 0.4847 - val_loss: 0.9112 - val_accuracy: 0.4933\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9005 - accuracy: 0.4851 - val_loss: 0.9269 - val_accuracy: 0.4933\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9021 - accuracy: 0.4805 - val_loss: 0.8948 - val_accuracy: 0.5349\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8858 - accuracy: 0.4941 - val_loss: 0.9418 - val_accuracy: 0.4705\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8976 - accuracy: 0.5008 - val_loss: 0.9288 - val_accuracy: 0.4812\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.8956 - accuracy: 0.4980 - val_loss: 0.9164 - val_accuracy: 0.4678\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.8906 - accuracy: 0.4979 - val_loss: 0.8807 - val_accuracy: 0.5255\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8790 - accuracy: 0.5161 - val_loss: 0.9080 - val_accuracy: 0.5107\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8869 - accuracy: 0.4941 - val_loss: 0.8743 - val_accuracy: 0.5402\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8743 - accuracy: 0.5053 - val_loss: 0.8778 - val_accuracy: 0.5201\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8716 - accuracy: 0.5116 - val_loss: 0.8597 - val_accuracy: 0.5550\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8641 - accuracy: 0.5082 - val_loss: 0.8690 - val_accuracy: 0.5617\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8600 - accuracy: 0.5110 - val_loss: 0.8383 - val_accuracy: 0.5603\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.8521 - accuracy: 0.5170 - val_loss: 0.8544 - val_accuracy: 0.5590\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.8336 - accuracy: 0.5280 - val_loss: 0.8271 - val_accuracy: 0.5402\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8374 - accuracy: 0.5316 - val_loss: 0.8644 - val_accuracy: 0.5282\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.8358 - accuracy: 0.5319 - val_loss: 0.8618 - val_accuracy: 0.5563\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8148 - accuracy: 0.5389 - val_loss: 0.7932 - val_accuracy: 0.5737\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.8074 - accuracy: 0.5365 - val_loss: 0.8037 - val_accuracy: 0.5764\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.7960 - accuracy: 0.5613 - val_loss: 0.8181 - val_accuracy: 0.5255\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7964 - accuracy: 0.5516 - val_loss: 0.8281 - val_accuracy: 0.5643\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7872 - accuracy: 0.5566 - val_loss: 0.8077 - val_accuracy: 0.5268\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.7805 - accuracy: 0.5583 - val_loss: 0.8391 - val_accuracy: 0.5402\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7651 - accuracy: 0.5726 - val_loss: 0.7605 - val_accuracy: 0.5764\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.7550 - accuracy: 0.5852 - val_loss: 0.7550 - val_accuracy: 0.5710\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.7347 - accuracy: 0.5979 - val_loss: 0.7347 - val_accuracy: 0.5979\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7324 - accuracy: 0.6006 - val_loss: 0.8221 - val_accuracy: 0.5804\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7137 - accuracy: 0.6198 - val_loss: 0.7591 - val_accuracy: 0.6113\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.6958 - accuracy: 0.6382 - val_loss: 0.6559 - val_accuracy: 0.6635\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7012 - accuracy: 0.6396 - val_loss: 0.7177 - val_accuracy: 0.6287\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.6829 - accuracy: 0.6519 - val_loss: 0.9600 - val_accuracy: 0.5121\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.6620 - accuracy: 0.6581 - val_loss: 0.6103 - val_accuracy: 0.7252\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.6440 - accuracy: 0.6812 - val_loss: 0.6205 - val_accuracy: 0.7038\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.6082 - accuracy: 0.7007 - val_loss: 0.5970 - val_accuracy: 0.7373\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.6140 - accuracy: 0.7066 - val_loss: 0.5506 - val_accuracy: 0.7668\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.5516 - accuracy: 0.7419 - val_loss: 0.5167 - val_accuracy: 0.7895\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.5314 - accuracy: 0.7572 - val_loss: 0.6281 - val_accuracy: 0.7399\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.5378 - accuracy: 0.7642 - val_loss: 0.6451 - val_accuracy: 0.7091\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.4848 - accuracy: 0.7870 - val_loss: 0.4562 - val_accuracy: 0.8043\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.4505 - accuracy: 0.8069 - val_loss: 0.4280 - val_accuracy: 0.8351\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.4441 - accuracy: 0.8173 - val_loss: 0.1835 - val_accuracy: 0.9517\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.4317 - accuracy: 0.8273 - val_loss: 0.2445 - val_accuracy: 0.9209\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.3881 - accuracy: 0.8459 - val_loss: 0.1648 - val_accuracy: 0.9611\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.3520 - accuracy: 0.8630 - val_loss: 0.2346 - val_accuracy: 0.9115\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.3401 - accuracy: 0.8690 - val_loss: 0.2321 - val_accuracy: 0.9048\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3364 - accuracy: 0.8727 - val_loss: 0.2164 - val_accuracy: 0.9075\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3108 - accuracy: 0.8858 - val_loss: 0.1234 - val_accuracy: 0.9665\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.2438 - accuracy: 0.9080 - val_loss: 0.1226 - val_accuracy: 0.9638\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2389 - accuracy: 0.9145 - val_loss: 0.0835 - val_accuracy: 0.9718\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.2294 - accuracy: 0.9156 - val_loss: 0.1014 - val_accuracy: 0.9625\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2107 - accuracy: 0.9240 - val_loss: 0.1163 - val_accuracy: 0.9611\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.2203 - accuracy: 0.9222 - val_loss: 0.0825 - val_accuracy: 0.9718\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.2570 - accuracy: 0.9076 - val_loss: 0.0610 - val_accuracy: 0.9812\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1857 - accuracy: 0.9408 - val_loss: 0.0703 - val_accuracy: 0.9786\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1834 - accuracy: 0.9353 - val_loss: 0.1363 - val_accuracy: 0.9491\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1612 - accuracy: 0.9471 - val_loss: 0.0543 - val_accuracy: 0.9839\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1732 - accuracy: 0.9410 - val_loss: 0.0546 - val_accuracy: 0.9812\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1455 - accuracy: 0.9481 - val_loss: 0.0542 - val_accuracy: 0.9839\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1522 - accuracy: 0.9496 - val_loss: 0.0479 - val_accuracy: 0.9839\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1327 - accuracy: 0.9545 - val_loss: 0.0357 - val_accuracy: 0.9866\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1629 - accuracy: 0.9458 - val_loss: 0.0970 - val_accuracy: 0.9651\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1342 - accuracy: 0.9538 - val_loss: 0.0653 - val_accuracy: 0.9839\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1128 - accuracy: 0.9615 - val_loss: 0.0482 - val_accuracy: 0.9826\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1190 - accuracy: 0.9584 - val_loss: 0.0677 - val_accuracy: 0.9759\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1105 - accuracy: 0.9650 - val_loss: 0.0267 - val_accuracy: 0.9866\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1014 - accuracy: 0.9653 - val_loss: 0.0214 - val_accuracy: 0.9906\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1104 - accuracy: 0.9620 - val_loss: 0.0427 - val_accuracy: 0.9853\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1027 - accuracy: 0.9687 - val_loss: 0.0357 - val_accuracy: 0.9853\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0994 - accuracy: 0.9671 - val_loss: 0.0371 - val_accuracy: 0.9866\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0857 - accuracy: 0.9705 - val_loss: 0.0436 - val_accuracy: 0.9853\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.1190 - accuracy: 0.9592 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1037 - accuracy: 0.9630 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0840 - accuracy: 0.9706 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0946 - accuracy: 0.9675 - val_loss: 0.0024 - val_accuracy: 0.9987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0695 - accuracy: 0.9778 - val_loss: 6.2220e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0939 - accuracy: 0.9687 - val_loss: 0.0072 - val_accuracy: 0.9973\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1034 - accuracy: 0.9674 - val_loss: 0.0032 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0798 - accuracy: 0.9739 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0852 - accuracy: 0.9733 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0723 - accuracy: 0.9756 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0743 - accuracy: 0.9760 - val_loss: 0.0050 - val_accuracy: 0.9973\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0723 - accuracy: 0.9769 - val_loss: 9.2867e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0668 - accuracy: 0.9787 - val_loss: 9.7556e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0734 - accuracy: 0.9760 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0610 - accuracy: 0.9788 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0622 - accuracy: 0.9770 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0650 - accuracy: 0.9793 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0660 - accuracy: 0.9775 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0641 - accuracy: 0.9782 - val_loss: 0.0037 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0780 - accuracy: 0.9759 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0688 - accuracy: 0.9778 - val_loss: 0.0037 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0563 - accuracy: 0.9803 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0691 - accuracy: 0.9790 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0592 - accuracy: 0.9820 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0610 - accuracy: 0.9794 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0508 - accuracy: 0.9830 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0735 - accuracy: 0.9756 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0440 - accuracy: 0.9857 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0569 - accuracy: 0.9824 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0534 - accuracy: 0.9830 - val_loss: 0.0092 - val_accuracy: 0.9960\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0691 - accuracy: 0.9748 - val_loss: 5.2805e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0649 - accuracy: 0.9776 - val_loss: 7.0907e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0550 - accuracy: 0.9806 - val_loss: 4.9985e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0569 - accuracy: 0.9820 - val_loss: 1.2231e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0565 - accuracy: 0.9817 - val_loss: 6.2285e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0456 - accuracy: 0.9870 - val_loss: 6.6366e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0430 - accuracy: 0.9849 - val_loss: 1.9940e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0522 - accuracy: 0.9839 - val_loss: 8.0724e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0458 - accuracy: 0.9851 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0433 - accuracy: 0.9867 - val_loss: 3.7671e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0487 - accuracy: 0.9838 - val_loss: 9.0644e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0519 - accuracy: 0.9841 - val_loss: 3.0096e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0460 - accuracy: 0.9845 - val_loss: 3.7551e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0443 - accuracy: 0.9823 - val_loss: 5.3026e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0418 - accuracy: 0.9867 - val_loss: 7.8749e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0452 - accuracy: 0.9851 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0424 - accuracy: 0.9848 - val_loss: 0.0016 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0515 - accuracy: 0.9841 - val_loss: 6.2188e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0440 - accuracy: 0.9873 - val_loss: 7.6790e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0393 - accuracy: 0.9884 - val_loss: 1.8270e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0473 - accuracy: 0.9836 - val_loss: 3.1079e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0453 - accuracy: 0.9866 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0480 - accuracy: 0.9845 - val_loss: 0.0028 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0457 - accuracy: 0.9845 - val_loss: 4.0697e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0395 - accuracy: 0.9878 - val_loss: 5.5793e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0372 - accuracy: 0.9893 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0328 - accuracy: 0.9885 - val_loss: 2.4104e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0611 - accuracy: 0.9800 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0427 - accuracy: 0.9848 - val_loss: 1.5222e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.0388 - accuracy: 0.9866 - val_loss: 4.1567e-04 - val_accuracy: 1.0000\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0443 - accuracy: 0.9842 - val_loss: 4.0652e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0419 - accuracy: 0.9873 - val_loss: 1.2707e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0459 - accuracy: 0.9866 - val_loss: 4.0221e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0444 - accuracy: 0.9864 - val_loss: 3.4664e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0326 - accuracy: 0.9908 - val_loss: 9.0049e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0430 - accuracy: 0.9861 - val_loss: 1.9537e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0297 - accuracy: 0.9909 - val_loss: 6.8896e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0440 - accuracy: 0.9866 - val_loss: 7.3723e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0479 - accuracy: 0.9836 - val_loss: 7.1230e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0325 - accuracy: 0.9909 - val_loss: 1.6549e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0513 - accuracy: 0.9835 - val_loss: 2.9201e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0478 - accuracy: 0.9823 - val_loss: 2.7453e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0314 - accuracy: 0.9900 - val_loss: 6.1009e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0394 - accuracy: 0.9879 - val_loss: 1.5221e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0520 - accuracy: 0.9824 - val_loss: 5.2410e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0437 - accuracy: 0.9872 - val_loss: 1.3483e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0381 - accuracy: 0.9884 - val_loss: 2.9251e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0266 - accuracy: 0.9905 - val_loss: 3.9374e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0407 - accuracy: 0.9879 - val_loss: 1.3860e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0442 - accuracy: 0.9870 - val_loss: 3.2248e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0390 - accuracy: 0.9861 - val_loss: 6.1333e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0298 - accuracy: 0.9903 - val_loss: 1.6822e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0338 - accuracy: 0.9903 - val_loss: 1.0336e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0379 - accuracy: 0.9875 - val_loss: 4.0276e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0302 - accuracy: 0.9911 - val_loss: 7.4310e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0325 - accuracy: 0.9888 - val_loss: 1.9453e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0341 - accuracy: 0.9884 - val_loss: 7.7014e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0324 - accuracy: 0.9899 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0264 - accuracy: 0.9908 - val_loss: 0.0013 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0249 - accuracy: 0.9911 - val_loss: 1.3210e-04 - val_accuracy: 1.0000\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0271 - accuracy: 0.9912 - val_loss: 7.6997e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0313 - accuracy: 0.9893 - val_loss: 1.8995e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0272 - accuracy: 0.9909 - val_loss: 2.3263e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0317 - accuracy: 0.9902 - val_loss: 4.6845e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0366 - accuracy: 0.9882 - val_loss: 1.0179e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0326 - accuracy: 0.9899 - val_loss: 6.1244e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0277 - accuracy: 0.9920 - val_loss: 1.6208e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0326 - accuracy: 0.9899 - val_loss: 1.1239e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0406 - accuracy: 0.9879 - val_loss: 1.7108e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0244 - accuracy: 0.9920 - val_loss: 1.7699e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0340 - accuracy: 0.9891 - val_loss: 2.1705e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0258 - accuracy: 0.9911 - val_loss: 4.8466e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0204 - accuracy: 0.9930 - val_loss: 3.8006e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0198 - accuracy: 0.9927 - val_loss: 2.6526e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0326 - accuracy: 0.9911 - val_loss: 2.6065e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0304 - accuracy: 0.9903 - val_loss: 2.9299e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0324 - accuracy: 0.9897 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0328 - accuracy: 0.9894 - val_loss: 1.6585e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0345 - accuracy: 0.9888 - val_loss: 0.0034 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0344 - accuracy: 0.9897 - val_loss: 2.6651e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0322 - accuracy: 0.9902 - val_loss: 0.0015 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0434 - accuracy: 0.9844 - val_loss: 6.5941e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0390 - accuracy: 0.9885 - val_loss: 7.4775e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0360 - accuracy: 0.9897 - val_loss: 4.4089e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0302 - accuracy: 0.9896 - val_loss: 9.5646e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0249 - accuracy: 0.9942 - val_loss: 8.3369e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0301 - accuracy: 0.9887 - val_loss: 4.9643e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0283 - accuracy: 0.9893 - val_loss: 1.4402e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0255 - accuracy: 0.9934 - val_loss: 2.7759e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0272 - accuracy: 0.9912 - val_loss: 1.1928e-04 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0369 - accuracy: 0.9887 - val_loss: 4.2603e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0356 - accuracy: 0.9882 - val_loss: 7.7246e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0330 - accuracy: 0.9908 - val_loss: 6.8447e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0291 - accuracy: 0.9915 - val_loss: 4.4701e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0459 - accuracy: 0.9861 - val_loss: 2.7609e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0344 - accuracy: 0.9894 - val_loss: 3.5505e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0216 - accuracy: 0.9939 - val_loss: 8.0881e-06 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0275 - accuracy: 0.9923 - val_loss: 9.3500e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0320 - accuracy: 0.9912 - val_loss: 1.2067e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0188 - accuracy: 0.9937 - val_loss: 6.5514e-06 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 9.9831e-06 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0281 - accuracy: 0.9931 - val_loss: 3.1880e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0255 - accuracy: 0.9918 - val_loss: 2.5228e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0207 - accuracy: 0.9937 - val_loss: 7.5854e-06 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0242 - accuracy: 0.9927 - val_loss: 1.6559e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0238 - accuracy: 0.9920 - val_loss: 1.9119e-06 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0350 - accuracy: 0.9884 - val_loss: 9.0615e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0240 - accuracy: 0.9931 - val_loss: 2.7654e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 6.4250e-06 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0313 - accuracy: 0.9903 - val_loss: 3.7529e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0259 - accuracy: 0.9917 - val_loss: 0.0014 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0368 - accuracy: 0.9894 - val_loss: 5.7201e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0227 - accuracy: 0.9928 - val_loss: 1.4423e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0231 - accuracy: 0.9933 - val_loss: 5.3953e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0188 - accuracy: 0.9930 - val_loss: 3.2968e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0185 - accuracy: 0.9936 - val_loss: 5.1349e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0242 - accuracy: 0.9918 - val_loss: 0.0010 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0255 - accuracy: 0.9927 - val_loss: 1.9548e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0230 - accuracy: 0.9939 - val_loss: 2.9341e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0332 - accuracy: 0.9903 - val_loss: 7.0929e-04 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0208 - accuracy: 0.9939 - val_loss: 9.4050e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0234 - accuracy: 0.9936 - val_loss: 2.7904e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0295 - accuracy: 0.9909 - val_loss: 1.6649e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0245 - accuracy: 0.9923 - val_loss: 5.4389e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0206 - accuracy: 0.9937 - val_loss: 1.2468e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0299 - accuracy: 0.9905 - val_loss: 7.1207e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0278 - accuracy: 0.9911 - val_loss: 7.5875e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0282 - accuracy: 0.9921 - val_loss: 9.2517e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0183 - accuracy: 0.9945 - val_loss: 6.7595e-06 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0254 - accuracy: 0.9925 - val_loss: 8.9352e-06 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0307 - accuracy: 0.9914 - val_loss: 1.1957e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0213 - accuracy: 0.9948 - val_loss: 1.5703e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0140 - accuracy: 0.9952 - val_loss: 3.2529e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 2.1783e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0288 - accuracy: 0.9878 - val_loss: 1.8155e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0684 - accuracy: 0.9821 - val_loss: 0.0104 - val_accuracy: 0.9946\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0279 - accuracy: 0.9928 - val_loss: 8.6905e-06 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0275 - accuracy: 0.9928 - val_loss: 3.7004e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0273 - accuracy: 0.9911 - val_loss: 7.2226e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0172 - accuracy: 0.9943 - val_loss: 8.9144e-06 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 1.5168e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0191 - accuracy: 0.9934 - val_loss: 1.1841e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0216 - accuracy: 0.9937 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0230 - accuracy: 0.9930 - val_loss: 2.3421e-06 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0192 - accuracy: 0.9934 - val_loss: 8.1218e-06 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0233 - accuracy: 0.9928 - val_loss: 2.7462e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0186 - accuracy: 0.9949 - val_loss: 1.5612e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0259 - accuracy: 0.9931 - val_loss: 1.8633e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0333 - accuracy: 0.9914 - val_loss: 1.8655e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0197 - accuracy: 0.9927 - val_loss: 1.1202e-05 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0237 - accuracy: 0.9931 - val_loss: 3.8828e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0288 - accuracy: 0.9914 - val_loss: 5.9460e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0204 - accuracy: 0.9927 - val_loss: 5.0418e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0179 - accuracy: 0.9949 - val_loss: 5.0042e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0299 - accuracy: 0.9915 - val_loss: 1.9190e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0234 - accuracy: 0.9931 - val_loss: 2.3018e-06 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0365 - accuracy: 0.9890 - val_loss: 1.2723e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0264 - accuracy: 0.9918 - val_loss: 2.0328e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0244 - accuracy: 0.9940 - val_loss: 2.4621e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0229 - accuracy: 0.9940 - val_loss: 2.7339e-06 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0212 - accuracy: 0.9939 - val_loss: 3.9308e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0224 - accuracy: 0.9934 - val_loss: 1.1669e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 3.8522e-06 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0183 - accuracy: 0.9948 - val_loss: 2.9270e-06 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 1.6620e-06 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 2.4002e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0217 - accuracy: 0.9940 - val_loss: 1.6098e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0235 - accuracy: 0.9931 - val_loss: 1.6026e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0261 - accuracy: 0.9909 - val_loss: 1.7453e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0205 - accuracy: 0.9936 - val_loss: 2.1871e-06 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 3.5056e-06 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0155 - accuracy: 0.9954 - val_loss: 2.5541e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 6.1599e-06 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0188 - accuracy: 0.9933 - val_loss: 1.5431e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0242 - accuracy: 0.9931 - val_loss: 4.7238e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0165 - accuracy: 0.9942 - val_loss: 2.3322e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0218 - accuracy: 0.9939 - val_loss: 1.1316e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0154 - accuracy: 0.9940 - val_loss: 3.2091e-06 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0232 - accuracy: 0.9934 - val_loss: 2.8209e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0216 - accuracy: 0.9930 - val_loss: 6.6593e-06 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "CAnc2SJa3o9f",
        "outputId": "db4ccd0e-7099-490a-b1bc-1226e6c1631d"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 8ms/step - loss: 0.0151 - accuracy: 0.9946\n",
            "Accuracy  : 0.9946351647377014\n",
            "F1_Score  : 0.9918302287840438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7fcxLuwZpkK",
        "outputId": "372b3f07-f591-4dd6-e9d4-22347c9eb7c3"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "c6388749-a437-4a8e-dc85-c401a925b7e1"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 5s 63ms/step - loss: 1.1343 - accuracy: 0.4171 - val_loss: 1.0660 - val_accuracy: 0.4343\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0164 - accuracy: 0.4563 - val_loss: 1.0071 - val_accuracy: 0.4343\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0159 - accuracy: 0.4472 - val_loss: 0.9992 - val_accuracy: 0.4343\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9924 - accuracy: 0.4641 - val_loss: 1.0004 - val_accuracy: 0.4397\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9857 - accuracy: 0.4443 - val_loss: 0.9971 - val_accuracy: 0.4410\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9909 - accuracy: 0.4581 - val_loss: 0.9994 - val_accuracy: 0.4410\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9829 - accuracy: 0.4522 - val_loss: 0.9964 - val_accuracy: 0.4598\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9806 - accuracy: 0.4535 - val_loss: 1.0015 - val_accuracy: 0.4745\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9776 - accuracy: 0.4670 - val_loss: 0.9914 - val_accuracy: 0.4598\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9652 - accuracy: 0.4697 - val_loss: 1.0014 - val_accuracy: 0.4745\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9813 - accuracy: 0.4593 - val_loss: 0.9974 - val_accuracy: 0.4571\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9741 - accuracy: 0.4465 - val_loss: 1.0007 - val_accuracy: 0.4316\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9710 - accuracy: 0.4593 - val_loss: 0.9986 - val_accuracy: 0.4343\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9744 - accuracy: 0.4487 - val_loss: 0.9932 - val_accuracy: 0.4450\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9700 - accuracy: 0.4543 - val_loss: 0.9943 - val_accuracy: 0.4598\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9791 - accuracy: 0.4351 - val_loss: 0.9967 - val_accuracy: 0.4343\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9674 - accuracy: 0.4566 - val_loss: 0.9922 - val_accuracy: 0.4343\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9702 - accuracy: 0.4506 - val_loss: 0.9872 - val_accuracy: 0.4718\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9684 - accuracy: 0.4501 - val_loss: 0.9807 - val_accuracy: 0.4799\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9692 - accuracy: 0.4577 - val_loss: 0.9901 - val_accuracy: 0.4651\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9693 - accuracy: 0.4556 - val_loss: 0.9854 - val_accuracy: 0.4584\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9647 - accuracy: 0.4576 - val_loss: 0.9836 - val_accuracy: 0.4383\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9700 - accuracy: 0.4646 - val_loss: 0.9816 - val_accuracy: 0.4772\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9626 - accuracy: 0.4577 - val_loss: 0.9808 - val_accuracy: 0.4638\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9682 - accuracy: 0.4636 - val_loss: 0.9783 - val_accuracy: 0.4678\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9576 - accuracy: 0.4709 - val_loss: 0.9879 - val_accuracy: 0.4745\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9598 - accuracy: 0.4591 - val_loss: 0.9786 - val_accuracy: 0.4786\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9685 - accuracy: 0.4570 - val_loss: 0.9798 - val_accuracy: 0.4692\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9652 - accuracy: 0.4595 - val_loss: 0.9846 - val_accuracy: 0.4786\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9607 - accuracy: 0.4641 - val_loss: 0.9768 - val_accuracy: 0.4678\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9595 - accuracy: 0.4633 - val_loss: 0.9519 - val_accuracy: 0.4812\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9568 - accuracy: 0.4639 - val_loss: 0.9535 - val_accuracy: 0.4786\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9558 - accuracy: 0.4638 - val_loss: 0.9412 - val_accuracy: 0.5027\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9581 - accuracy: 0.4669 - val_loss: 0.9585 - val_accuracy: 0.4611\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9537 - accuracy: 0.4633 - val_loss: 0.9542 - val_accuracy: 0.4732\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9542 - accuracy: 0.4727 - val_loss: 0.9471 - val_accuracy: 0.4960\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9568 - accuracy: 0.4694 - val_loss: 0.9591 - val_accuracy: 0.4933\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9488 - accuracy: 0.4748 - val_loss: 0.9612 - val_accuracy: 0.5000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9489 - accuracy: 0.4669 - val_loss: 0.9425 - val_accuracy: 0.5040\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9508 - accuracy: 0.4656 - val_loss: 0.9475 - val_accuracy: 0.5107\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9476 - accuracy: 0.4770 - val_loss: 0.9438 - val_accuracy: 0.5161\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9417 - accuracy: 0.4785 - val_loss: 0.9414 - val_accuracy: 0.5201\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9403 - accuracy: 0.4784 - val_loss: 0.9477 - val_accuracy: 0.4799\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9401 - accuracy: 0.4844 - val_loss: 0.9555 - val_accuracy: 0.4866\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9321 - accuracy: 0.4839 - val_loss: 0.9347 - val_accuracy: 0.5174\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9335 - accuracy: 0.4887 - val_loss: 0.9331 - val_accuracy: 0.5027\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9283 - accuracy: 0.4870 - val_loss: 0.9244 - val_accuracy: 0.5067\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9276 - accuracy: 0.4948 - val_loss: 0.9213 - val_accuracy: 0.5161\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9111 - accuracy: 0.5054 - val_loss: 0.9249 - val_accuracy: 0.5335\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9171 - accuracy: 0.4985 - val_loss: 0.9123 - val_accuracy: 0.4826\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9058 - accuracy: 0.5051 - val_loss: 0.9006 - val_accuracy: 0.5295\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9015 - accuracy: 0.5083 - val_loss: 0.9171 - val_accuracy: 0.5241\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8841 - accuracy: 0.5154 - val_loss: 0.8808 - val_accuracy: 0.5550\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8707 - accuracy: 0.5277 - val_loss: 0.8974 - val_accuracy: 0.5456\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8684 - accuracy: 0.5189 - val_loss: 0.8892 - val_accuracy: 0.5308\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8437 - accuracy: 0.5447 - val_loss: 0.8241 - val_accuracy: 0.5871\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8364 - accuracy: 0.5498 - val_loss: 0.8751 - val_accuracy: 0.5858\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8129 - accuracy: 0.5721 - val_loss: 0.7978 - val_accuracy: 0.6180\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7942 - accuracy: 0.5842 - val_loss: 0.8585 - val_accuracy: 0.6032\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7756 - accuracy: 0.5957 - val_loss: 0.8019 - val_accuracy: 0.6247\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7526 - accuracy: 0.6177 - val_loss: 0.6607 - val_accuracy: 0.6676\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7390 - accuracy: 0.6277 - val_loss: 0.6245 - val_accuracy: 0.6702\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.6936 - accuracy: 0.6563 - val_loss: 0.6421 - val_accuracy: 0.6743\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.6907 - accuracy: 0.6624 - val_loss: 0.5825 - val_accuracy: 0.6944\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.6634 - accuracy: 0.6787 - val_loss: 0.5591 - val_accuracy: 0.7399\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.6102 - accuracy: 0.7069 - val_loss: 0.6463 - val_accuracy: 0.6662\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.6227 - accuracy: 0.7072 - val_loss: 0.5296 - val_accuracy: 0.7440\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.5901 - accuracy: 0.7231 - val_loss: 0.5107 - val_accuracy: 0.7574\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.5668 - accuracy: 0.7416 - val_loss: 0.4824 - val_accuracy: 0.7788\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.5176 - accuracy: 0.7751 - val_loss: 0.4475 - val_accuracy: 0.7815\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.4783 - accuracy: 0.7933 - val_loss: 0.3847 - val_accuracy: 0.8190\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.4739 - accuracy: 0.8037 - val_loss: 0.3998 - val_accuracy: 0.8244\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.4283 - accuracy: 0.8231 - val_loss: 0.3821 - val_accuracy: 0.8324\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.4387 - accuracy: 0.8137 - val_loss: 0.3663 - val_accuracy: 0.8284\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.4141 - accuracy: 0.8240 - val_loss: 0.3222 - val_accuracy: 0.8592\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.3832 - accuracy: 0.8511 - val_loss: 0.3134 - val_accuracy: 0.8592\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3256 - accuracy: 0.8715 - val_loss: 0.2901 - val_accuracy: 0.8874\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3256 - accuracy: 0.8747 - val_loss: 0.2605 - val_accuracy: 0.8941\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.3022 - accuracy: 0.8836 - val_loss: 0.3093 - val_accuracy: 0.8673\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2823 - accuracy: 0.8957 - val_loss: 0.2092 - val_accuracy: 0.9223\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.2328 - accuracy: 0.9186 - val_loss: 0.2006 - val_accuracy: 0.9209\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.2360 - accuracy: 0.9145 - val_loss: 0.3141 - val_accuracy: 0.8807\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.2507 - accuracy: 0.9155 - val_loss: 0.1994 - val_accuracy: 0.9209\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.2195 - accuracy: 0.9216 - val_loss: 0.1660 - val_accuracy: 0.9343\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1905 - accuracy: 0.9323 - val_loss: 0.1758 - val_accuracy: 0.9276\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1892 - accuracy: 0.9328 - val_loss: 0.1614 - val_accuracy: 0.9410\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1943 - accuracy: 0.9317 - val_loss: 0.1966 - val_accuracy: 0.9209\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.1759 - accuracy: 0.9420 - val_loss: 0.1360 - val_accuracy: 0.9517\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.1592 - accuracy: 0.9434 - val_loss: 0.2372 - val_accuracy: 0.9196\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1482 - accuracy: 0.9475 - val_loss: 0.1273 - val_accuracy: 0.9517\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1870 - accuracy: 0.9377 - val_loss: 0.0174 - val_accuracy: 0.9960\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1869 - accuracy: 0.9356 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1394 - accuracy: 0.9535 - val_loss: 0.0060 - val_accuracy: 0.9987\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1592 - accuracy: 0.9465 - val_loss: 0.0120 - val_accuracy: 0.9987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1801 - accuracy: 0.9419 - val_loss: 0.0127 - val_accuracy: 0.9973\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1250 - accuracy: 0.9587 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.1109 - accuracy: 0.9632 - val_loss: 0.0088 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1193 - accuracy: 0.9604 - val_loss: 0.0070 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1041 - accuracy: 0.9668 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1147 - accuracy: 0.9623 - val_loss: 0.0106 - val_accuracy: 0.9946\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1116 - accuracy: 0.9638 - val_loss: 0.0146 - val_accuracy: 0.9946\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1096 - accuracy: 0.9626 - val_loss: 0.0101 - val_accuracy: 0.9973\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0988 - accuracy: 0.9684 - val_loss: 0.0076 - val_accuracy: 0.9973\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1027 - accuracy: 0.9629 - val_loss: 0.0077 - val_accuracy: 0.9973\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1084 - accuracy: 0.9641 - val_loss: 0.0132 - val_accuracy: 0.9960\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0720 - accuracy: 0.9768 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0934 - accuracy: 0.9708 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0943 - accuracy: 0.9706 - val_loss: 0.0070 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0642 - accuracy: 0.9782 - val_loss: 0.0111 - val_accuracy: 0.9946\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.0768 - accuracy: 0.9748 - val_loss: 0.0067 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0807 - accuracy: 0.9745 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0877 - accuracy: 0.9727 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0754 - accuracy: 0.9762 - val_loss: 0.0060 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0821 - accuracy: 0.9726 - val_loss: 0.0116 - val_accuracy: 0.9973\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0704 - accuracy: 0.9796 - val_loss: 0.0077 - val_accuracy: 0.9973\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0811 - accuracy: 0.9751 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0619 - accuracy: 0.9805 - val_loss: 0.0095 - val_accuracy: 0.9960\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0673 - accuracy: 0.9793 - val_loss: 0.0101 - val_accuracy: 0.9960\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0670 - accuracy: 0.9791 - val_loss: 0.0053 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0749 - accuracy: 0.9763 - val_loss: 0.0128 - val_accuracy: 0.9973\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0854 - accuracy: 0.9730 - val_loss: 3.6104e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0761 - accuracy: 0.9750 - val_loss: 0.0018 - val_accuracy: 0.9987\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0538 - accuracy: 0.9826 - val_loss: 3.1453e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0743 - accuracy: 0.9762 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0622 - accuracy: 0.9797 - val_loss: 2.3489e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0626 - accuracy: 0.9788 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0596 - accuracy: 0.9809 - val_loss: 0.0024 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0689 - accuracy: 0.9794 - val_loss: 0.0023 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0678 - accuracy: 0.9788 - val_loss: 2.9312e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1690 - accuracy: 0.9455 - val_loss: 0.0138 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0702 - accuracy: 0.9765 - val_loss: 9.3483e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0705 - accuracy: 0.9776 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0706 - accuracy: 0.9769 - val_loss: 0.0034 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0503 - accuracy: 0.9830 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0554 - accuracy: 0.9794 - val_loss: 4.1461e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0484 - accuracy: 0.9852 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0667 - accuracy: 0.9805 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0627 - accuracy: 0.9808 - val_loss: 0.0024 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0591 - accuracy: 0.9811 - val_loss: 9.7575e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0474 - accuracy: 0.9845 - val_loss: 7.4794e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0469 - accuracy: 0.9870 - val_loss: 0.0085 - val_accuracy: 0.9960\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0494 - accuracy: 0.9842 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0549 - accuracy: 0.9820 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0445 - accuracy: 0.9864 - val_loss: 3.7776e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0520 - accuracy: 0.9851 - val_loss: 0.0015 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0420 - accuracy: 0.9855 - val_loss: 4.6291e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0529 - accuracy: 0.9845 - val_loss: 0.0017 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0486 - accuracy: 0.9848 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0496 - accuracy: 0.9841 - val_loss: 7.8508e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0437 - accuracy: 0.9867 - val_loss: 5.2984e-04 - val_accuracy: 1.0000\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0504 - accuracy: 0.9846 - val_loss: 1.3281e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0438 - accuracy: 0.9875 - val_loss: 3.9706e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0768 - accuracy: 0.9756 - val_loss: 3.9687e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0480 - accuracy: 0.9820 - val_loss: 3.3293e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0420 - accuracy: 0.9875 - val_loss: 1.6083e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0393 - accuracy: 0.9867 - val_loss: 6.8431e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0473 - accuracy: 0.9863 - val_loss: 1.1223e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0392 - accuracy: 0.9875 - val_loss: 1.4643e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0341 - accuracy: 0.9878 - val_loss: 1.9602e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0660 - accuracy: 0.9800 - val_loss: 0.0175 - val_accuracy: 0.9960\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0535 - accuracy: 0.9824 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0642 - accuracy: 0.9802 - val_loss: 2.5148e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0443 - accuracy: 0.9852 - val_loss: 1.4021e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0423 - accuracy: 0.9879 - val_loss: 1.7755e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0416 - accuracy: 0.9870 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0423 - accuracy: 0.9876 - val_loss: 1.4246e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0433 - accuracy: 0.9875 - val_loss: 9.2077e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0497 - accuracy: 0.9855 - val_loss: 2.3402e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0323 - accuracy: 0.9893 - val_loss: 2.2098e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0402 - accuracy: 0.9876 - val_loss: 4.3890e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0378 - accuracy: 0.9884 - val_loss: 9.0200e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0392 - accuracy: 0.9876 - val_loss: 5.5147e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0373 - accuracy: 0.9884 - val_loss: 2.0052e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0297 - accuracy: 0.9908 - val_loss: 2.4403e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0332 - accuracy: 0.9896 - val_loss: 4.4841e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0418 - accuracy: 0.9876 - val_loss: 1.1379e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0304 - accuracy: 0.9914 - val_loss: 2.7574e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0391 - accuracy: 0.9893 - val_loss: 9.0702e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0377 - accuracy: 0.9876 - val_loss: 0.0020 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0454 - accuracy: 0.9873 - val_loss: 1.2070e-04 - val_accuracy: 1.0000\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0486 - accuracy: 0.9869 - val_loss: 6.3606e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0378 - accuracy: 0.9888 - val_loss: 1.4416e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0393 - accuracy: 0.9884 - val_loss: 4.2226e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0389 - accuracy: 0.9888 - val_loss: 2.4510e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0316 - accuracy: 0.9903 - val_loss: 1.0823e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0464 - accuracy: 0.9855 - val_loss: 2.8466e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0429 - accuracy: 0.9861 - val_loss: 1.4699e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0451 - accuracy: 0.9869 - val_loss: 8.3853e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0378 - accuracy: 0.9875 - val_loss: 3.1435e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0467 - accuracy: 0.9847 - val_loss: 6.1150e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0356 - accuracy: 0.9902 - val_loss: 2.3715e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0367 - accuracy: 0.9891 - val_loss: 2.5128e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0346 - accuracy: 0.9893 - val_loss: 2.5422e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0351 - accuracy: 0.9896 - val_loss: 2.8401e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0302 - accuracy: 0.9911 - val_loss: 2.7409e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0326 - accuracy: 0.9905 - val_loss: 0.0025 - val_accuracy: 0.9987\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0367 - accuracy: 0.9881 - val_loss: 8.7001e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0357 - accuracy: 0.9884 - val_loss: 1.4281e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0342 - accuracy: 0.9888 - val_loss: 1.3803e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0268 - accuracy: 0.9921 - val_loss: 8.3868e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0356 - accuracy: 0.9894 - val_loss: 1.3196e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0356 - accuracy: 0.9890 - val_loss: 1.1878e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0299 - accuracy: 0.9917 - val_loss: 8.1634e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0671 - accuracy: 0.9793 - val_loss: 0.0062 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0572 - accuracy: 0.9799 - val_loss: 5.8932e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0350 - accuracy: 0.9902 - val_loss: 1.8820e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0278 - accuracy: 0.9917 - val_loss: 4.7829e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0283 - accuracy: 0.9897 - val_loss: 2.6933e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0296 - accuracy: 0.9912 - val_loss: 4.7611e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0264 - accuracy: 0.9924 - val_loss: 5.8979e-05 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0340 - accuracy: 0.9903 - val_loss: 4.5467e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0381 - accuracy: 0.9885 - val_loss: 1.9815e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0336 - accuracy: 0.9896 - val_loss: 5.5198e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0279 - accuracy: 0.9923 - val_loss: 1.9236e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0276 - accuracy: 0.9924 - val_loss: 1.0606e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0292 - accuracy: 0.9912 - val_loss: 7.6812e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0363 - accuracy: 0.9887 - val_loss: 1.3418e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0426 - accuracy: 0.9866 - val_loss: 2.7454e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0428 - accuracy: 0.9876 - val_loss: 1.9032e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0319 - accuracy: 0.9906 - val_loss: 6.6223e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0319 - accuracy: 0.9918 - val_loss: 1.3086e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0273 - accuracy: 0.9905 - val_loss: 7.9482e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0242 - accuracy: 0.9924 - val_loss: 2.3180e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0486 - accuracy: 0.9864 - val_loss: 3.9676e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0346 - accuracy: 0.9882 - val_loss: 7.6485e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0341 - accuracy: 0.9894 - val_loss: 7.1477e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0239 - accuracy: 0.9927 - val_loss: 1.5075e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0434 - accuracy: 0.9881 - val_loss: 6.3973e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0258 - accuracy: 0.9925 - val_loss: 8.4330e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0341 - accuracy: 0.9893 - val_loss: 1.1648e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0218 - accuracy: 0.9937 - val_loss: 4.7504e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0312 - accuracy: 0.9896 - val_loss: 3.8196e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0274 - accuracy: 0.9921 - val_loss: 6.0842e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0275 - accuracy: 0.9921 - val_loss: 8.5027e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0461 - accuracy: 0.9852 - val_loss: 3.0878e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0675 - accuracy: 0.9796 - val_loss: 6.4178e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0242 - accuracy: 0.9923 - val_loss: 1.3521e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 3.3821e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0255 - accuracy: 0.9928 - val_loss: 0.0017 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0255 - accuracy: 0.9924 - val_loss: 1.1834e-04 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0289 - accuracy: 0.9911 - val_loss: 6.1234e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0256 - accuracy: 0.9912 - val_loss: 3.0197e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0277 - accuracy: 0.9920 - val_loss: 3.6768e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0245 - accuracy: 0.9915 - val_loss: 1.2453e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0276 - accuracy: 0.9917 - val_loss: 1.2785e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0264 - accuracy: 0.9920 - val_loss: 4.2860e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0346 - accuracy: 0.9899 - val_loss: 2.0218e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0212 - accuracy: 0.9946 - val_loss: 6.4069e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0221 - accuracy: 0.9925 - val_loss: 7.1013e-06 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0199 - accuracy: 0.9930 - val_loss: 3.1920e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0334 - accuracy: 0.9918 - val_loss: 2.0705e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0275 - accuracy: 0.9917 - val_loss: 8.6790e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 1.6523e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0282 - accuracy: 0.9912 - val_loss: 6.6391e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0344 - accuracy: 0.9887 - val_loss: 3.5744e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0267 - accuracy: 0.9905 - val_loss: 7.8405e-06 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0363 - accuracy: 0.9897 - val_loss: 1.7923e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0250 - accuracy: 0.9934 - val_loss: 2.2472e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0197 - accuracy: 0.9946 - val_loss: 3.2935e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0243 - accuracy: 0.9931 - val_loss: 6.2272e-06 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 5.4265e-06 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0281 - accuracy: 0.9927 - val_loss: 1.5702e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0245 - accuracy: 0.9925 - val_loss: 3.4940e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0260 - accuracy: 0.9921 - val_loss: 1.9964e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0282 - accuracy: 0.9906 - val_loss: 1.0307e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0228 - accuracy: 0.9931 - val_loss: 1.8170e-06 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0260 - accuracy: 0.9927 - val_loss: 3.3408e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0284 - accuracy: 0.9905 - val_loss: 1.8359e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0235 - accuracy: 0.9927 - val_loss: 5.1134e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0235 - accuracy: 0.9915 - val_loss: 1.1719e-05 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0298 - accuracy: 0.9915 - val_loss: 2.7806e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0303 - accuracy: 0.9912 - val_loss: 2.7855e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0240 - accuracy: 0.9927 - val_loss: 2.2585e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0232 - accuracy: 0.9925 - val_loss: 5.7872e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0284 - accuracy: 0.9920 - val_loss: 4.9241e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0308 - accuracy: 0.9894 - val_loss: 4.7389e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0265 - accuracy: 0.9917 - val_loss: 2.0349e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0259 - accuracy: 0.9928 - val_loss: 1.7141e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0257 - accuracy: 0.9920 - val_loss: 2.3993e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0223 - accuracy: 0.9943 - val_loss: 7.3141e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0223 - accuracy: 0.9943 - val_loss: 5.3615e-06 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0254 - accuracy: 0.9927 - val_loss: 2.6261e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0170 - accuracy: 0.9936 - val_loss: 2.7741e-06 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0205 - accuracy: 0.9940 - val_loss: 5.3084e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0194 - accuracy: 0.9946 - val_loss: 5.5239e-06 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 62ms/step - loss: 0.0313 - accuracy: 0.9923 - val_loss: 4.2976e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0270 - accuracy: 0.9924 - val_loss: 3.0955e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0236 - accuracy: 0.9915 - val_loss: 3.3651e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0224 - accuracy: 0.9924 - val_loss: 3.2419e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0170 - accuracy: 0.9960 - val_loss: 2.3038e-06 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0208 - accuracy: 0.9937 - val_loss: 4.1111e-06 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0294 - accuracy: 0.9894 - val_loss: 3.5643e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0242 - accuracy: 0.9931 - val_loss: 5.2896e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0287 - accuracy: 0.9900 - val_loss: 4.2469e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0299 - accuracy: 0.9921 - val_loss: 3.8797e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0219 - accuracy: 0.9934 - val_loss: 5.4857e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0201 - accuracy: 0.9934 - val_loss: 2.4650e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0246 - accuracy: 0.9930 - val_loss: 2.4138e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0161 - accuracy: 0.9949 - val_loss: 3.1393e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0227 - accuracy: 0.9939 - val_loss: 3.1072e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "d8de4a2a-465f-4333-acfb-afd203083c5e"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 8ms/step - loss: 0.0375 - accuracy: 0.9898\n",
            "Accuracy  : 0.9898068904876709\n",
            "F1_Score  : 0.9871116825306793\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}