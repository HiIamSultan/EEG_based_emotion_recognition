{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub26_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "02c2d699-8b86-47a6-f25e-29882e70c8a8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e3\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  #EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "84704556-6e4a-45a9-dcc4-3f0655b398ca"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(26,27):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.26\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (2796,) (1165,) (5359,)\n",
            "(9320,) (4194,) (2330,) (2796,)\n",
            "(9320,) (2796,) (2563,) (3961,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "cc2c7fe9-d8c8-4751-8008-fc2c5c4eb28e"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "c98ebb95-8199-4e9a-f004-cac1720a0a9f"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "622"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "4b245ff3-6b3e-49f3-cb79-3177489765bf"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d223dda2-1265-47b7-cfe3-13ba10f49605"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 50s 61ms/step - loss: 1.0430 - accuracy: 0.5340 - val_loss: 0.9559 - val_accuracy: 0.5670\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9839 - accuracy: 0.5606 - val_loss: 0.9468 - val_accuracy: 0.5670\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9838 - accuracy: 0.5678 - val_loss: 0.9483 - val_accuracy: 0.5670\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9771 - accuracy: 0.5644 - val_loss: 0.9493 - val_accuracy: 0.5670\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9586 - accuracy: 0.5779 - val_loss: 0.9574 - val_accuracy: 0.5670\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9693 - accuracy: 0.5668 - val_loss: 0.9451 - val_accuracy: 0.5670\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9644 - accuracy: 0.5685 - val_loss: 0.9428 - val_accuracy: 0.5670\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9491 - accuracy: 0.5757 - val_loss: 0.9399 - val_accuracy: 0.5670\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9459 - accuracy: 0.5798 - val_loss: 0.9446 - val_accuracy: 0.5670\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9439 - accuracy: 0.5764 - val_loss: 0.9417 - val_accuracy: 0.5670\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9428 - accuracy: 0.5828 - val_loss: 0.9441 - val_accuracy: 0.5670\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9489 - accuracy: 0.5683 - val_loss: 0.9424 - val_accuracy: 0.5670\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9415 - accuracy: 0.5773 - val_loss: 0.9362 - val_accuracy: 0.5670\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9417 - accuracy: 0.5758 - val_loss: 0.9395 - val_accuracy: 0.5670\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9332 - accuracy: 0.5803 - val_loss: 0.9386 - val_accuracy: 0.5670\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9291 - accuracy: 0.5847 - val_loss: 0.9407 - val_accuracy: 0.5670\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9334 - accuracy: 0.5799 - val_loss: 0.9379 - val_accuracy: 0.5670\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9424 - accuracy: 0.5745 - val_loss: 0.9327 - val_accuracy: 0.5670\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9336 - accuracy: 0.5789 - val_loss: 0.9324 - val_accuracy: 0.5670\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9316 - accuracy: 0.5801 - val_loss: 0.9339 - val_accuracy: 0.5670\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9296 - accuracy: 0.5787 - val_loss: 0.9328 - val_accuracy: 0.5670\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9318 - accuracy: 0.5729 - val_loss: 0.9306 - val_accuracy: 0.5670\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9355 - accuracy: 0.5743 - val_loss: 0.9311 - val_accuracy: 0.5670\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9356 - accuracy: 0.5807 - val_loss: 0.9282 - val_accuracy: 0.5670\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9363 - accuracy: 0.5649 - val_loss: 0.9322 - val_accuracy: 0.5670\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9185 - accuracy: 0.5848 - val_loss: 0.9320 - val_accuracy: 0.5670\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9340 - accuracy: 0.5699 - val_loss: 0.9297 - val_accuracy: 0.5670\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9297 - accuracy: 0.5784 - val_loss: 0.9281 - val_accuracy: 0.5670\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9238 - accuracy: 0.5820 - val_loss: 0.9343 - val_accuracy: 0.5670\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9296 - accuracy: 0.5741 - val_loss: 0.9333 - val_accuracy: 0.5670\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.9303 - accuracy: 0.5711 - val_loss: 0.9189 - val_accuracy: 0.5737\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9296 - accuracy: 0.5708 - val_loss: 0.9163 - val_accuracy: 0.5737\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9238 - accuracy: 0.5697 - val_loss: 0.9126 - val_accuracy: 0.5737\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9264 - accuracy: 0.5708 - val_loss: 0.9138 - val_accuracy: 0.5737\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9273 - accuracy: 0.5699 - val_loss: 0.9088 - val_accuracy: 0.5737\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9203 - accuracy: 0.5736 - val_loss: 0.9059 - val_accuracy: 0.5737\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9248 - accuracy: 0.5720 - val_loss: 0.9056 - val_accuracy: 0.5737\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9187 - accuracy: 0.5733 - val_loss: 0.9161 - val_accuracy: 0.5845\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9181 - accuracy: 0.5750 - val_loss: 0.9065 - val_accuracy: 0.5737\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9177 - accuracy: 0.5742 - val_loss: 0.9177 - val_accuracy: 0.5737\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9164 - accuracy: 0.5720 - val_loss: 0.9100 - val_accuracy: 0.5791\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9138 - accuracy: 0.5747 - val_loss: 0.8985 - val_accuracy: 0.5737\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9151 - accuracy: 0.5765 - val_loss: 0.9081 - val_accuracy: 0.5831\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9152 - accuracy: 0.5775 - val_loss: 0.8997 - val_accuracy: 0.5737\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9129 - accuracy: 0.5736 - val_loss: 0.9029 - val_accuracy: 0.5737\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9151 - accuracy: 0.5717 - val_loss: 0.8993 - val_accuracy: 0.5777\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9138 - accuracy: 0.5735 - val_loss: 0.8930 - val_accuracy: 0.5764\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9136 - accuracy: 0.5754 - val_loss: 0.8973 - val_accuracy: 0.5751\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9107 - accuracy: 0.5799 - val_loss: 0.9189 - val_accuracy: 0.5603\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9072 - accuracy: 0.5772 - val_loss: 0.8923 - val_accuracy: 0.5791\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9062 - accuracy: 0.5778 - val_loss: 0.8919 - val_accuracy: 0.5818\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9080 - accuracy: 0.5791 - val_loss: 0.8845 - val_accuracy: 0.5804\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9059 - accuracy: 0.5776 - val_loss: 0.8857 - val_accuracy: 0.5764\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9024 - accuracy: 0.5793 - val_loss: 0.8855 - val_accuracy: 0.5898\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9019 - accuracy: 0.5776 - val_loss: 0.8843 - val_accuracy: 0.5791\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9073 - accuracy: 0.5823 - val_loss: 0.9033 - val_accuracy: 0.5617\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8966 - accuracy: 0.5829 - val_loss: 0.8924 - val_accuracy: 0.5724\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8926 - accuracy: 0.5844 - val_loss: 0.8826 - val_accuracy: 0.5831\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8950 - accuracy: 0.5814 - val_loss: 0.8879 - val_accuracy: 0.5871\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8946 - accuracy: 0.5838 - val_loss: 0.8935 - val_accuracy: 0.5818\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9005 - accuracy: 0.5772 - val_loss: 0.8532 - val_accuracy: 0.6099\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.8906 - accuracy: 0.5845 - val_loss: 0.8559 - val_accuracy: 0.6072\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8974 - accuracy: 0.5808 - val_loss: 0.8661 - val_accuracy: 0.6113\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8923 - accuracy: 0.5799 - val_loss: 0.8545 - val_accuracy: 0.6126\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8848 - accuracy: 0.5852 - val_loss: 0.8448 - val_accuracy: 0.6126\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8879 - accuracy: 0.5794 - val_loss: 0.8593 - val_accuracy: 0.6193\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8704 - accuracy: 0.5908 - val_loss: 0.8603 - val_accuracy: 0.6072\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8811 - accuracy: 0.5872 - val_loss: 0.8364 - val_accuracy: 0.6113\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8656 - accuracy: 0.5928 - val_loss: 0.8349 - val_accuracy: 0.6166\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8698 - accuracy: 0.5999 - val_loss: 0.8440 - val_accuracy: 0.6180\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8601 - accuracy: 0.5969 - val_loss: 0.8342 - val_accuracy: 0.6206\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8640 - accuracy: 0.5940 - val_loss: 0.8427 - val_accuracy: 0.6166\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8471 - accuracy: 0.6030 - val_loss: 0.8220 - val_accuracy: 0.6273\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8372 - accuracy: 0.6121 - val_loss: 0.8275 - val_accuracy: 0.6220\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8291 - accuracy: 0.6085 - val_loss: 0.8096 - val_accuracy: 0.6126\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8168 - accuracy: 0.6186 - val_loss: 0.8534 - val_accuracy: 0.6072\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8144 - accuracy: 0.6188 - val_loss: 0.7873 - val_accuracy: 0.6340\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8025 - accuracy: 0.6261 - val_loss: 0.8043 - val_accuracy: 0.6260\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7909 - accuracy: 0.6253 - val_loss: 0.8410 - val_accuracy: 0.6005\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7852 - accuracy: 0.6332 - val_loss: 0.7614 - val_accuracy: 0.6568\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7728 - accuracy: 0.6423 - val_loss: 0.8003 - val_accuracy: 0.6314\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7457 - accuracy: 0.6526 - val_loss: 0.7305 - val_accuracy: 0.6716\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7367 - accuracy: 0.6557 - val_loss: 0.7110 - val_accuracy: 0.6810\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7358 - accuracy: 0.6587 - val_loss: 0.7576 - val_accuracy: 0.6515\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7051 - accuracy: 0.6787 - val_loss: 0.7224 - val_accuracy: 0.6877\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6904 - accuracy: 0.6841 - val_loss: 0.6849 - val_accuracy: 0.7051\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6809 - accuracy: 0.6939 - val_loss: 0.7103 - val_accuracy: 0.6796\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6454 - accuracy: 0.7080 - val_loss: 0.6313 - val_accuracy: 0.7158\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6556 - accuracy: 0.7076 - val_loss: 0.6822 - val_accuracy: 0.7091\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6291 - accuracy: 0.7216 - val_loss: 0.6107 - val_accuracy: 0.7373\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6235 - accuracy: 0.7253 - val_loss: 0.4608 - val_accuracy: 0.8311\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.6074 - accuracy: 0.7352 - val_loss: 0.4389 - val_accuracy: 0.8298\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5828 - accuracy: 0.7517 - val_loss: 0.4648 - val_accuracy: 0.8016\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5682 - accuracy: 0.7501 - val_loss: 0.4397 - val_accuracy: 0.8123\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.5507 - accuracy: 0.7598 - val_loss: 0.4108 - val_accuracy: 0.8204\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5216 - accuracy: 0.7791 - val_loss: 0.4244 - val_accuracy: 0.8311\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5037 - accuracy: 0.7897 - val_loss: 0.3731 - val_accuracy: 0.8499\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4950 - accuracy: 0.7943 - val_loss: 0.3997 - val_accuracy: 0.8164\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4745 - accuracy: 0.8016 - val_loss: 0.3540 - val_accuracy: 0.8485\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4696 - accuracy: 0.8024 - val_loss: 0.3481 - val_accuracy: 0.8686\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4318 - accuracy: 0.8265 - val_loss: 0.3400 - val_accuracy: 0.8552\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4260 - accuracy: 0.8289 - val_loss: 0.3527 - val_accuracy: 0.8432\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4198 - accuracy: 0.8286 - val_loss: 0.3212 - val_accuracy: 0.8619\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4078 - accuracy: 0.8368 - val_loss: 0.3122 - val_accuracy: 0.8525\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3764 - accuracy: 0.8474 - val_loss: 0.3060 - val_accuracy: 0.8646\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3571 - accuracy: 0.8638 - val_loss: 0.2898 - val_accuracy: 0.8780\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3594 - accuracy: 0.8535 - val_loss: 0.2733 - val_accuracy: 0.8874\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3513 - accuracy: 0.8575 - val_loss: 0.2845 - val_accuracy: 0.8794\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3352 - accuracy: 0.8613 - val_loss: 0.2951 - val_accuracy: 0.8727\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3246 - accuracy: 0.8723 - val_loss: 0.2615 - val_accuracy: 0.8861\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3171 - accuracy: 0.8735 - val_loss: 0.2770 - val_accuracy: 0.8753\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2972 - accuracy: 0.8863 - val_loss: 0.2966 - val_accuracy: 0.8820\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2968 - accuracy: 0.8823 - val_loss: 0.2645 - val_accuracy: 0.8847\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2881 - accuracy: 0.8936 - val_loss: 0.2490 - val_accuracy: 0.8847\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2876 - accuracy: 0.8925 - val_loss: 0.2712 - val_accuracy: 0.8874\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2607 - accuracy: 0.9018 - val_loss: 0.2325 - val_accuracy: 0.9021\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2625 - accuracy: 0.9033 - val_loss: 0.2281 - val_accuracy: 0.8995\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2505 - accuracy: 0.9069 - val_loss: 0.2243 - val_accuracy: 0.8968\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2457 - accuracy: 0.9057 - val_loss: 0.2074 - val_accuracy: 0.9155\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2448 - accuracy: 0.9103 - val_loss: 0.2125 - val_accuracy: 0.9115\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2550 - accuracy: 0.9063 - val_loss: 0.0538 - val_accuracy: 0.9893\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2510 - accuracy: 0.9043 - val_loss: 0.0540 - val_accuracy: 0.9866\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2388 - accuracy: 0.9094 - val_loss: 0.0500 - val_accuracy: 0.9879\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2246 - accuracy: 0.9127 - val_loss: 0.0526 - val_accuracy: 0.9879\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2410 - accuracy: 0.9133 - val_loss: 0.0506 - val_accuracy: 0.9866\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2203 - accuracy: 0.9189 - val_loss: 0.0907 - val_accuracy: 0.9625\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2381 - accuracy: 0.9124 - val_loss: 0.0565 - val_accuracy: 0.9879\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2038 - accuracy: 0.9262 - val_loss: 0.0531 - val_accuracy: 0.9893\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2096 - accuracy: 0.9238 - val_loss: 0.0419 - val_accuracy: 0.9879\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2052 - accuracy: 0.9241 - val_loss: 0.0480 - val_accuracy: 0.9879\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1766 - accuracy: 0.9385 - val_loss: 0.0358 - val_accuracy: 0.9920\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1905 - accuracy: 0.9303 - val_loss: 0.0398 - val_accuracy: 0.9920\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1719 - accuracy: 0.9340 - val_loss: 0.0343 - val_accuracy: 0.9946\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1708 - accuracy: 0.9373 - val_loss: 0.0516 - val_accuracy: 0.9839\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1716 - accuracy: 0.9411 - val_loss: 0.0489 - val_accuracy: 0.9853\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1772 - accuracy: 0.9367 - val_loss: 0.0560 - val_accuracy: 0.9786\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1713 - accuracy: 0.9429 - val_loss: 0.0382 - val_accuracy: 0.9866\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1641 - accuracy: 0.9428 - val_loss: 0.0522 - val_accuracy: 0.9826\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1707 - accuracy: 0.9411 - val_loss: 0.0408 - val_accuracy: 0.9906\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1593 - accuracy: 0.9434 - val_loss: 0.0347 - val_accuracy: 0.9906\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1447 - accuracy: 0.9523 - val_loss: 0.0343 - val_accuracy: 0.9906\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1495 - accuracy: 0.9469 - val_loss: 0.0344 - val_accuracy: 0.9879\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1301 - accuracy: 0.9562 - val_loss: 0.0398 - val_accuracy: 0.9879\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1463 - accuracy: 0.9516 - val_loss: 0.0462 - val_accuracy: 0.9879\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1391 - accuracy: 0.9489 - val_loss: 0.0319 - val_accuracy: 0.9866\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1216 - accuracy: 0.9586 - val_loss: 0.0367 - val_accuracy: 0.9866\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1312 - accuracy: 0.9562 - val_loss: 0.0421 - val_accuracy: 0.9799\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1567 - accuracy: 0.9446 - val_loss: 0.0655 - val_accuracy: 0.9732\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1434 - accuracy: 0.9514 - val_loss: 0.0480 - val_accuracy: 0.9826\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1162 - accuracy: 0.9618 - val_loss: 0.0347 - val_accuracy: 0.9866\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1412 - accuracy: 0.9513 - val_loss: 0.0111 - val_accuracy: 0.9987\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1378 - accuracy: 0.9531 - val_loss: 0.0184 - val_accuracy: 0.9933\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1242 - accuracy: 0.9557 - val_loss: 0.0087 - val_accuracy: 0.9987\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1206 - accuracy: 0.9580 - val_loss: 0.0111 - val_accuracy: 0.9987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1165 - accuracy: 0.9595 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1212 - accuracy: 0.9590 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1214 - accuracy: 0.9553 - val_loss: 0.0099 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1164 - accuracy: 0.9586 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1176 - accuracy: 0.9627 - val_loss: 0.0299 - val_accuracy: 0.9879\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1313 - accuracy: 0.9551 - val_loss: 0.0119 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1246 - accuracy: 0.9599 - val_loss: 0.0135 - val_accuracy: 0.9960\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1100 - accuracy: 0.9648 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1005 - accuracy: 0.9660 - val_loss: 0.0152 - val_accuracy: 0.9973\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1006 - accuracy: 0.9654 - val_loss: 0.0089 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1118 - accuracy: 0.9635 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1093 - accuracy: 0.9639 - val_loss: 0.0174 - val_accuracy: 0.9987\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1072 - accuracy: 0.9621 - val_loss: 0.0200 - val_accuracy: 0.9960\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0913 - accuracy: 0.9702 - val_loss: 0.0070 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0928 - accuracy: 0.9692 - val_loss: 0.0083 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1022 - accuracy: 0.9654 - val_loss: 0.0154 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0967 - accuracy: 0.9693 - val_loss: 0.0119 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0925 - accuracy: 0.9681 - val_loss: 0.0133 - val_accuracy: 0.9960\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0900 - accuracy: 0.9721 - val_loss: 0.0111 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1005 - accuracy: 0.9651 - val_loss: 0.0123 - val_accuracy: 0.9973\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0894 - accuracy: 0.9720 - val_loss: 0.0107 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0925 - accuracy: 0.9683 - val_loss: 0.0170 - val_accuracy: 0.9933\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1135 - accuracy: 0.9615 - val_loss: 0.0222 - val_accuracy: 0.9879\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1029 - accuracy: 0.9651 - val_loss: 0.0788 - val_accuracy: 0.9692\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0986 - accuracy: 0.9687 - val_loss: 0.0099 - val_accuracy: 0.9973\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0753 - accuracy: 0.9748 - val_loss: 0.0113 - val_accuracy: 0.9973\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 48ms/step - loss: 0.0951 - accuracy: 0.9680 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0914 - accuracy: 0.9690 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0925 - accuracy: 0.9738 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0914 - accuracy: 0.9733 - val_loss: 0.0043 - val_accuracy: 0.9987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0864 - accuracy: 0.9723 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0868 - accuracy: 0.9723 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0915 - accuracy: 0.9689 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0780 - accuracy: 0.9747 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0771 - accuracy: 0.9735 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0899 - accuracy: 0.9738 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0903 - accuracy: 0.9706 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0762 - accuracy: 0.9760 - val_loss: 0.0025 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0882 - accuracy: 0.9724 - val_loss: 0.0028 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0769 - accuracy: 0.9733 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0714 - accuracy: 0.9769 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0695 - accuracy: 0.9775 - val_loss: 0.0031 - val_accuracy: 0.9987\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0765 - accuracy: 0.9726 - val_loss: 0.0058 - val_accuracy: 0.9973\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0790 - accuracy: 0.9753 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0702 - accuracy: 0.9784 - val_loss: 0.0063 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0866 - accuracy: 0.9738 - val_loss: 0.0113 - val_accuracy: 0.9973\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0654 - accuracy: 0.9787 - val_loss: 0.0028 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0841 - accuracy: 0.9732 - val_loss: 0.0032 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0760 - accuracy: 0.9745 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0678 - accuracy: 0.9781 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0679 - accuracy: 0.9785 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0688 - accuracy: 0.9766 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0859 - accuracy: 0.9724 - val_loss: 0.0054 - val_accuracy: 0.9973\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0683 - accuracy: 0.9769 - val_loss: 0.0134 - val_accuracy: 0.9973\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0772 - accuracy: 0.9727 - val_loss: 0.0055 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0895 - accuracy: 0.9739 - val_loss: 0.0055 - val_accuracy: 0.9987\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0717 - accuracy: 0.9759 - val_loss: 4.9644e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0641 - accuracy: 0.9797 - val_loss: 7.4121e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0712 - accuracy: 0.9765 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0782 - accuracy: 0.9747 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0721 - accuracy: 0.9760 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0631 - accuracy: 0.9782 - val_loss: 5.5125e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0497 - accuracy: 0.9857 - val_loss: 5.9378e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0740 - accuracy: 0.9750 - val_loss: 0.0045 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0766 - accuracy: 0.9747 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0519 - accuracy: 0.9841 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0617 - accuracy: 0.9796 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0619 - accuracy: 0.9820 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0616 - accuracy: 0.9790 - val_loss: 5.3527e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0634 - accuracy: 0.9814 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0797 - accuracy: 0.9729 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0687 - accuracy: 0.9809 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0551 - accuracy: 0.9833 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0524 - accuracy: 0.9835 - val_loss: 0.0029 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0586 - accuracy: 0.9830 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0549 - accuracy: 0.9820 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0557 - accuracy: 0.9803 - val_loss: 8.9625e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0652 - accuracy: 0.9791 - val_loss: 0.0080 - val_accuracy: 0.9973\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0607 - accuracy: 0.9802 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0617 - accuracy: 0.9806 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0630 - accuracy: 0.9815 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0597 - accuracy: 0.9824 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0467 - accuracy: 0.9848 - val_loss: 0.0034 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0620 - accuracy: 0.9796 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0564 - accuracy: 0.9841 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0607 - accuracy: 0.9820 - val_loss: 0.0027 - val_accuracy: 0.9987\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0617 - accuracy: 0.9793 - val_loss: 4.4050e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0604 - accuracy: 0.9800 - val_loss: 3.8352e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0584 - accuracy: 0.9818 - val_loss: 6.1348e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0472 - accuracy: 0.9835 - val_loss: 6.0366e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0636 - accuracy: 0.9823 - val_loss: 6.5208e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0598 - accuracy: 0.9808 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0645 - accuracy: 0.9799 - val_loss: 4.3545e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0579 - accuracy: 0.9821 - val_loss: 6.3670e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0644 - accuracy: 0.9805 - val_loss: 8.1557e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0612 - accuracy: 0.9803 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0547 - accuracy: 0.9814 - val_loss: 3.1601e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0617 - accuracy: 0.9817 - val_loss: 2.1220e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0545 - accuracy: 0.9841 - val_loss: 5.9287e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0569 - accuracy: 0.9812 - val_loss: 0.0022 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0500 - accuracy: 0.9839 - val_loss: 5.4229e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0518 - accuracy: 0.9821 - val_loss: 3.8562e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0464 - accuracy: 0.9848 - val_loss: 5.1178e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0657 - accuracy: 0.9776 - val_loss: 9.5955e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0450 - accuracy: 0.9860 - val_loss: 4.7860e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0514 - accuracy: 0.9855 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0458 - accuracy: 0.9847 - val_loss: 5.0469e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0503 - accuracy: 0.9838 - val_loss: 0.0025 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0428 - accuracy: 0.9857 - val_loss: 4.2937e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0503 - accuracy: 0.9854 - val_loss: 0.0030 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0545 - accuracy: 0.9835 - val_loss: 0.0016 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0414 - accuracy: 0.9882 - val_loss: 9.2048e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0444 - accuracy: 0.9854 - val_loss: 9.0433e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0530 - accuracy: 0.9829 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0517 - accuracy: 0.9817 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0538 - accuracy: 0.9818 - val_loss: 4.2139e-04 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0656 - accuracy: 0.9808 - val_loss: 2.0860e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0575 - accuracy: 0.9809 - val_loss: 2.1241e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0444 - accuracy: 0.9839 - val_loss: 1.6038e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0558 - accuracy: 0.9830 - val_loss: 1.8723e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0546 - accuracy: 0.9826 - val_loss: 1.4351e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0455 - accuracy: 0.9854 - val_loss: 2.1119e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0489 - accuracy: 0.9839 - val_loss: 1.9436e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0613 - accuracy: 0.9791 - val_loss: 4.0481e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0502 - accuracy: 0.9824 - val_loss: 9.0794e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0435 - accuracy: 0.9861 - val_loss: 8.3153e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0425 - accuracy: 0.9864 - val_loss: 1.0891e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0535 - accuracy: 0.9845 - val_loss: 1.1068e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0545 - accuracy: 0.9827 - val_loss: 1.3202e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0468 - accuracy: 0.9854 - val_loss: 1.0633e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0463 - accuracy: 0.9847 - val_loss: 1.5862e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0480 - accuracy: 0.9851 - val_loss: 2.2593e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0414 - accuracy: 0.9858 - val_loss: 1.3868e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0439 - accuracy: 0.9857 - val_loss: 1.7567e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0475 - accuracy: 0.9835 - val_loss: 0.0031 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0473 - accuracy: 0.9851 - val_loss: 4.6759e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0596 - accuracy: 0.9823 - val_loss: 0.0034 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0419 - accuracy: 0.9878 - val_loss: 8.6490e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0538 - accuracy: 0.9829 - val_loss: 3.1028e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0416 - accuracy: 0.9864 - val_loss: 2.2450e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0453 - accuracy: 0.9857 - val_loss: 2.1286e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0384 - accuracy: 0.9872 - val_loss: 2.7905e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0521 - accuracy: 0.9832 - val_loss: 5.1391e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0397 - accuracy: 0.9873 - val_loss: 7.5383e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0582 - accuracy: 0.9827 - val_loss: 0.0023 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0566 - accuracy: 0.9811 - val_loss: 1.9882e-04 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "CAnc2SJa3o9f",
        "outputId": "adf908e4-8970-48a7-b4bc-4d35dcacd3e1"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 7ms/step - loss: 0.0643 - accuracy: 0.9759\n",
            "Accuracy  : 0.9758583903312683\n",
            "F1_Score  : 0.9710875252366714\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7fcxLuwZpkK",
        "outputId": "ea8f7abe-d6fa-41df-9cc5-0daaa2c017d8"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "5f874e88-d82b-4b2a-f4c6-320186c1e3ed"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 51ms/step - loss: 1.1619 - accuracy: 0.4008 - val_loss: 1.0912 - val_accuracy: 0.4625\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0664 - accuracy: 0.4442 - val_loss: 1.0668 - val_accuracy: 0.4625\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0644 - accuracy: 0.4554 - val_loss: 1.0561 - val_accuracy: 0.4625\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0572 - accuracy: 0.4525 - val_loss: 1.0531 - val_accuracy: 0.4625\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0570 - accuracy: 0.4508 - val_loss: 1.0448 - val_accuracy: 0.4625\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0572 - accuracy: 0.4494 - val_loss: 1.0439 - val_accuracy: 0.4625\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0533 - accuracy: 0.4490 - val_loss: 1.0477 - val_accuracy: 0.4625\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0592 - accuracy: 0.4482 - val_loss: 1.0425 - val_accuracy: 0.4678\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0571 - accuracy: 0.4540 - val_loss: 1.0427 - val_accuracy: 0.4651\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0561 - accuracy: 0.4534 - val_loss: 1.0434 - val_accuracy: 0.4718\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0479 - accuracy: 0.4592 - val_loss: 1.0515 - val_accuracy: 0.4584\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0545 - accuracy: 0.4433 - val_loss: 1.0413 - val_accuracy: 0.4625\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0508 - accuracy: 0.4491 - val_loss: 1.0396 - val_accuracy: 0.4625\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0467 - accuracy: 0.4539 - val_loss: 1.0610 - val_accuracy: 0.4531\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0462 - accuracy: 0.4595 - val_loss: 1.0509 - val_accuracy: 0.4625\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0524 - accuracy: 0.4587 - val_loss: 1.0399 - val_accuracy: 0.4718\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0463 - accuracy: 0.4385 - val_loss: 1.0394 - val_accuracy: 0.4625\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0396 - accuracy: 0.4646 - val_loss: 1.0523 - val_accuracy: 0.4893\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0444 - accuracy: 0.4573 - val_loss: 1.0369 - val_accuracy: 0.4759\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0364 - accuracy: 0.4583 - val_loss: 1.0424 - val_accuracy: 0.4718\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0333 - accuracy: 0.4654 - val_loss: 1.0273 - val_accuracy: 0.4960\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0280 - accuracy: 0.4669 - val_loss: 1.0348 - val_accuracy: 0.4759\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0355 - accuracy: 0.4595 - val_loss: 1.0298 - val_accuracy: 0.4866\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0238 - accuracy: 0.4768 - val_loss: 1.0327 - val_accuracy: 0.4665\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0377 - accuracy: 0.4589 - val_loss: 1.0243 - val_accuracy: 0.4866\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0369 - accuracy: 0.4586 - val_loss: 1.0249 - val_accuracy: 0.4759\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0341 - accuracy: 0.4635 - val_loss: 1.0305 - val_accuracy: 0.4879\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0351 - accuracy: 0.4575 - val_loss: 1.0275 - val_accuracy: 0.4638\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0314 - accuracy: 0.4643 - val_loss: 1.0276 - val_accuracy: 0.4960\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0200 - accuracy: 0.4802 - val_loss: 1.0339 - val_accuracy: 0.4799\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0272 - accuracy: 0.4700 - val_loss: 1.0152 - val_accuracy: 0.4772\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0247 - accuracy: 0.4660 - val_loss: 1.0139 - val_accuracy: 0.4920\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0243 - accuracy: 0.4745 - val_loss: 1.0189 - val_accuracy: 0.4611\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0215 - accuracy: 0.4709 - val_loss: 1.0157 - val_accuracy: 0.4437\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0224 - accuracy: 0.4663 - val_loss: 1.0178 - val_accuracy: 0.4625\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0243 - accuracy: 0.4735 - val_loss: 1.0105 - val_accuracy: 0.4826\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0237 - accuracy: 0.4650 - val_loss: 1.0145 - val_accuracy: 0.4826\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0193 - accuracy: 0.4700 - val_loss: 1.0119 - val_accuracy: 0.4611\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0209 - accuracy: 0.4626 - val_loss: 1.0091 - val_accuracy: 0.4625\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0177 - accuracy: 0.4692 - val_loss: 1.0081 - val_accuracy: 0.4598\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0215 - accuracy: 0.4651 - val_loss: 1.0263 - val_accuracy: 0.4826\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0163 - accuracy: 0.4779 - val_loss: 1.0104 - val_accuracy: 0.4517\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0171 - accuracy: 0.4754 - val_loss: 1.0141 - val_accuracy: 0.4692\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0110 - accuracy: 0.4803 - val_loss: 1.0185 - val_accuracy: 0.4692\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0132 - accuracy: 0.4769 - val_loss: 1.0052 - val_accuracy: 0.4732\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0165 - accuracy: 0.4799 - val_loss: 1.0035 - val_accuracy: 0.4906\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0137 - accuracy: 0.4768 - val_loss: 1.0104 - val_accuracy: 0.4772\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0136 - accuracy: 0.4750 - val_loss: 1.0042 - val_accuracy: 0.4839\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0116 - accuracy: 0.4866 - val_loss: 1.0028 - val_accuracy: 0.4799\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0104 - accuracy: 0.4778 - val_loss: 0.9990 - val_accuracy: 0.4759\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0129 - accuracy: 0.4770 - val_loss: 0.9989 - val_accuracy: 0.4718\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0082 - accuracy: 0.4803 - val_loss: 0.9964 - val_accuracy: 0.4678\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0139 - accuracy: 0.4770 - val_loss: 0.9952 - val_accuracy: 0.4705\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0058 - accuracy: 0.4844 - val_loss: 0.9968 - val_accuracy: 0.4705\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0008 - accuracy: 0.4817 - val_loss: 1.0280 - val_accuracy: 0.4853\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0064 - accuracy: 0.4791 - val_loss: 0.9906 - val_accuracy: 0.5000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0022 - accuracy: 0.4849 - val_loss: 0.9914 - val_accuracy: 0.4853\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9935 - accuracy: 0.4927 - val_loss: 1.0089 - val_accuracy: 0.4611\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0039 - accuracy: 0.4811 - val_loss: 0.9926 - val_accuracy: 0.4826\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9980 - accuracy: 0.4881 - val_loss: 0.9867 - val_accuracy: 0.4920\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9980 - accuracy: 0.4854 - val_loss: 1.0006 - val_accuracy: 0.4759\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0017 - accuracy: 0.4921 - val_loss: 0.9983 - val_accuracy: 0.4732\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9987 - accuracy: 0.4808 - val_loss: 1.0018 - val_accuracy: 0.4705\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9882 - accuracy: 0.4994 - val_loss: 0.9922 - val_accuracy: 0.4946\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9913 - accuracy: 0.4911 - val_loss: 1.0232 - val_accuracy: 0.4571\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9906 - accuracy: 0.5007 - val_loss: 0.9925 - val_accuracy: 0.4933\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9890 - accuracy: 0.4973 - val_loss: 0.9921 - val_accuracy: 0.4933\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9823 - accuracy: 0.4972 - val_loss: 0.9827 - val_accuracy: 0.4906\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9849 - accuracy: 0.5013 - val_loss: 0.9903 - val_accuracy: 0.4786\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 48ms/step - loss: 0.9817 - accuracy: 0.4996 - val_loss: 0.9886 - val_accuracy: 0.4812\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9735 - accuracy: 0.5088 - val_loss: 0.9874 - val_accuracy: 0.5027\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9684 - accuracy: 0.5127 - val_loss: 0.9871 - val_accuracy: 0.4745\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9737 - accuracy: 0.5162 - val_loss: 0.9903 - val_accuracy: 0.4946\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9813 - accuracy: 0.4961 - val_loss: 0.9740 - val_accuracy: 0.4893\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9693 - accuracy: 0.5104 - val_loss: 0.9709 - val_accuracy: 0.5080\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9683 - accuracy: 0.5072 - val_loss: 0.9795 - val_accuracy: 0.4960\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9613 - accuracy: 0.5218 - val_loss: 0.9760 - val_accuracy: 0.5147\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9554 - accuracy: 0.5189 - val_loss: 0.9871 - val_accuracy: 0.4946\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9566 - accuracy: 0.5289 - val_loss: 0.9683 - val_accuracy: 0.4960\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9590 - accuracy: 0.5195 - val_loss: 0.9867 - val_accuracy: 0.5054\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9462 - accuracy: 0.5216 - val_loss: 0.9720 - val_accuracy: 0.4933\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9472 - accuracy: 0.5271 - val_loss: 0.9717 - val_accuracy: 0.5080\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9343 - accuracy: 0.5361 - val_loss: 0.9495 - val_accuracy: 0.5067\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9370 - accuracy: 0.5373 - val_loss: 0.9563 - val_accuracy: 0.4866\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9314 - accuracy: 0.5344 - val_loss: 0.9503 - val_accuracy: 0.5214\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9228 - accuracy: 0.5471 - val_loss: 1.0107 - val_accuracy: 0.5134\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9250 - accuracy: 0.5471 - val_loss: 0.9485 - val_accuracy: 0.5174\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9251 - accuracy: 0.5423 - val_loss: 0.9911 - val_accuracy: 0.4812\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9136 - accuracy: 0.5477 - val_loss: 0.9334 - val_accuracy: 0.5335\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9041 - accuracy: 0.5559 - val_loss: 0.9808 - val_accuracy: 0.5054\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9195 - accuracy: 0.5416 - val_loss: 0.8477 - val_accuracy: 0.6032\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9022 - accuracy: 0.5559 - val_loss: 0.8507 - val_accuracy: 0.5965\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9007 - accuracy: 0.5684 - val_loss: 0.8273 - val_accuracy: 0.6099\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8942 - accuracy: 0.5620 - val_loss: 0.8207 - val_accuracy: 0.6166\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8762 - accuracy: 0.5712 - val_loss: 0.8129 - val_accuracy: 0.6166\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8853 - accuracy: 0.5709 - val_loss: 0.8095 - val_accuracy: 0.6072\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8754 - accuracy: 0.5733 - val_loss: 0.8341 - val_accuracy: 0.6126\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8594 - accuracy: 0.5902 - val_loss: 0.7790 - val_accuracy: 0.6475\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8584 - accuracy: 0.5870 - val_loss: 0.7886 - val_accuracy: 0.6434\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8419 - accuracy: 0.6003 - val_loss: 0.7875 - val_accuracy: 0.6260\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8418 - accuracy: 0.5999 - val_loss: 0.7787 - val_accuracy: 0.6314\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8225 - accuracy: 0.6149 - val_loss: 0.8017 - val_accuracy: 0.6327\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8096 - accuracy: 0.6255 - val_loss: 0.7788 - val_accuracy: 0.6676\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8066 - accuracy: 0.6280 - val_loss: 0.8204 - val_accuracy: 0.6287\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8083 - accuracy: 0.6311 - val_loss: 0.7415 - val_accuracy: 0.6756\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7852 - accuracy: 0.6413 - val_loss: 0.7317 - val_accuracy: 0.6944\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7755 - accuracy: 0.6426 - val_loss: 0.7511 - val_accuracy: 0.6622\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7724 - accuracy: 0.6569 - val_loss: 0.7369 - val_accuracy: 0.6796\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7585 - accuracy: 0.6645 - val_loss: 0.6965 - val_accuracy: 0.7024\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7284 - accuracy: 0.6823 - val_loss: 0.6875 - val_accuracy: 0.7078\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7267 - accuracy: 0.6776 - val_loss: 0.7195 - val_accuracy: 0.6783\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7138 - accuracy: 0.6841 - val_loss: 0.6862 - val_accuracy: 0.6971\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7019 - accuracy: 0.6942 - val_loss: 0.6866 - val_accuracy: 0.6810\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6907 - accuracy: 0.6933 - val_loss: 0.7078 - val_accuracy: 0.7024\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6852 - accuracy: 0.7012 - val_loss: 0.6677 - val_accuracy: 0.7131\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6725 - accuracy: 0.7149 - val_loss: 0.6915 - val_accuracy: 0.6917\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6641 - accuracy: 0.7213 - val_loss: 0.6609 - val_accuracy: 0.7051\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6511 - accuracy: 0.7225 - val_loss: 0.6196 - val_accuracy: 0.7239\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6199 - accuracy: 0.7404 - val_loss: 0.5991 - val_accuracy: 0.7466\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6305 - accuracy: 0.7386 - val_loss: 0.6191 - val_accuracy: 0.7265\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6212 - accuracy: 0.7393 - val_loss: 0.3718 - val_accuracy: 0.8807\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6320 - accuracy: 0.7365 - val_loss: 0.3804 - val_accuracy: 0.8767\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5961 - accuracy: 0.7574 - val_loss: 0.3802 - val_accuracy: 0.8660\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5681 - accuracy: 0.7659 - val_loss: 0.3622 - val_accuracy: 0.8753\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5881 - accuracy: 0.7571 - val_loss: 0.3996 - val_accuracy: 0.8606\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5472 - accuracy: 0.7785 - val_loss: 0.3818 - val_accuracy: 0.8727\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5342 - accuracy: 0.7891 - val_loss: 0.3676 - val_accuracy: 0.8753\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5369 - accuracy: 0.7830 - val_loss: 0.3272 - val_accuracy: 0.8874\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5096 - accuracy: 0.8009 - val_loss: 0.3394 - val_accuracy: 0.8834\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5298 - accuracy: 0.7920 - val_loss: 0.3935 - val_accuracy: 0.8552\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4870 - accuracy: 0.8122 - val_loss: 0.3055 - val_accuracy: 0.8914\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4810 - accuracy: 0.8118 - val_loss: 0.3346 - val_accuracy: 0.8780\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4538 - accuracy: 0.8285 - val_loss: 0.3128 - val_accuracy: 0.8928\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4573 - accuracy: 0.8207 - val_loss: 0.3186 - val_accuracy: 0.8941\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4304 - accuracy: 0.8374 - val_loss: 0.3299 - val_accuracy: 0.8874\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4315 - accuracy: 0.8389 - val_loss: 0.3201 - val_accuracy: 0.8619\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4239 - accuracy: 0.8413 - val_loss: 0.2735 - val_accuracy: 0.8995\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4070 - accuracy: 0.8419 - val_loss: 0.3033 - val_accuracy: 0.8820\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3918 - accuracy: 0.8541 - val_loss: 0.2728 - val_accuracy: 0.8995\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3858 - accuracy: 0.8538 - val_loss: 0.2784 - val_accuracy: 0.9075\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3739 - accuracy: 0.8593 - val_loss: 0.2741 - val_accuracy: 0.9008\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3615 - accuracy: 0.8633 - val_loss: 0.2966 - val_accuracy: 0.8928\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3667 - accuracy: 0.8669 - val_loss: 0.2325 - val_accuracy: 0.9182\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.3657 - accuracy: 0.8681 - val_loss: 0.2341 - val_accuracy: 0.9035\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3329 - accuracy: 0.8796 - val_loss: 0.2429 - val_accuracy: 0.8941\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3211 - accuracy: 0.8818 - val_loss: 0.2167 - val_accuracy: 0.9182\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3043 - accuracy: 0.8842 - val_loss: 0.2446 - val_accuracy: 0.8968\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3082 - accuracy: 0.8873 - val_loss: 0.2049 - val_accuracy: 0.9236\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3111 - accuracy: 0.8870 - val_loss: 0.1881 - val_accuracy: 0.9263\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3111 - accuracy: 0.8887 - val_loss: 0.2106 - val_accuracy: 0.9276\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.3154 - accuracy: 0.8848 - val_loss: 0.0816 - val_accuracy: 0.9745\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2968 - accuracy: 0.8942 - val_loss: 0.0839 - val_accuracy: 0.9759\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2896 - accuracy: 0.8920 - val_loss: 0.0938 - val_accuracy: 0.9692\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2817 - accuracy: 0.8943 - val_loss: 0.0998 - val_accuracy: 0.9692\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2599 - accuracy: 0.9076 - val_loss: 0.0756 - val_accuracy: 0.9786\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2623 - accuracy: 0.9101 - val_loss: 0.0819 - val_accuracy: 0.9799\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2622 - accuracy: 0.9107 - val_loss: 0.0832 - val_accuracy: 0.9745\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2549 - accuracy: 0.9118 - val_loss: 0.0738 - val_accuracy: 0.9799\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2374 - accuracy: 0.9189 - val_loss: 0.0745 - val_accuracy: 0.9759\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2492 - accuracy: 0.9137 - val_loss: 0.0924 - val_accuracy: 0.9705\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2326 - accuracy: 0.9203 - val_loss: 0.0781 - val_accuracy: 0.9786\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2201 - accuracy: 0.9250 - val_loss: 0.0949 - val_accuracy: 0.9678\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2055 - accuracy: 0.9274 - val_loss: 0.0741 - val_accuracy: 0.9732\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2097 - accuracy: 0.9286 - val_loss: 0.0624 - val_accuracy: 0.9786\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2159 - accuracy: 0.9256 - val_loss: 0.0654 - val_accuracy: 0.9786\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2262 - accuracy: 0.9218 - val_loss: 0.0748 - val_accuracy: 0.9772\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2140 - accuracy: 0.9298 - val_loss: 0.0772 - val_accuracy: 0.9759\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2034 - accuracy: 0.9314 - val_loss: 0.0744 - val_accuracy: 0.9759\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1914 - accuracy: 0.9325 - val_loss: 0.0875 - val_accuracy: 0.9732\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1955 - accuracy: 0.9301 - val_loss: 0.0697 - val_accuracy: 0.9772\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1890 - accuracy: 0.9374 - val_loss: 0.0660 - val_accuracy: 0.9786\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1741 - accuracy: 0.9402 - val_loss: 0.0891 - val_accuracy: 0.9651\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1662 - accuracy: 0.9432 - val_loss: 0.1055 - val_accuracy: 0.9611\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1634 - accuracy: 0.9444 - val_loss: 0.0670 - val_accuracy: 0.9718\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1930 - accuracy: 0.9390 - val_loss: 0.0814 - val_accuracy: 0.9705\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1659 - accuracy: 0.9441 - val_loss: 0.0664 - val_accuracy: 0.9745\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1637 - accuracy: 0.9440 - val_loss: 0.0693 - val_accuracy: 0.9745\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1674 - accuracy: 0.9419 - val_loss: 0.0706 - val_accuracy: 0.9786\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1610 - accuracy: 0.9450 - val_loss: 0.0700 - val_accuracy: 0.9745\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1468 - accuracy: 0.9517 - val_loss: 0.1126 - val_accuracy: 0.9571\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1784 - accuracy: 0.9356 - val_loss: 0.0134 - val_accuracy: 0.9987\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1650 - accuracy: 0.9432 - val_loss: 0.0153 - val_accuracy: 0.9960\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1636 - accuracy: 0.9446 - val_loss: 0.0177 - val_accuracy: 0.9987\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1565 - accuracy: 0.9447 - val_loss: 0.0133 - val_accuracy: 0.9973\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1588 - accuracy: 0.9470 - val_loss: 0.0131 - val_accuracy: 0.9973\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1516 - accuracy: 0.9502 - val_loss: 0.0139 - val_accuracy: 0.9960\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1431 - accuracy: 0.9489 - val_loss: 0.0153 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1496 - accuracy: 0.9511 - val_loss: 0.0116 - val_accuracy: 0.9960\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1496 - accuracy: 0.9486 - val_loss: 0.0187 - val_accuracy: 0.9933\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1763 - accuracy: 0.9404 - val_loss: 0.0206 - val_accuracy: 0.9946\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1471 - accuracy: 0.9492 - val_loss: 0.0211 - val_accuracy: 0.9946\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1436 - accuracy: 0.9540 - val_loss: 0.0185 - val_accuracy: 0.9960\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1461 - accuracy: 0.9502 - val_loss: 0.0227 - val_accuracy: 0.9919\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1280 - accuracy: 0.9549 - val_loss: 0.0180 - val_accuracy: 0.9960\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1298 - accuracy: 0.9589 - val_loss: 0.0201 - val_accuracy: 0.9960\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1260 - accuracy: 0.9589 - val_loss: 0.0195 - val_accuracy: 0.9933\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1269 - accuracy: 0.9587 - val_loss: 0.0151 - val_accuracy: 0.9960\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1251 - accuracy: 0.9569 - val_loss: 0.0207 - val_accuracy: 0.9919\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1208 - accuracy: 0.9602 - val_loss: 0.0210 - val_accuracy: 0.9946\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1290 - accuracy: 0.9578 - val_loss: 0.0248 - val_accuracy: 0.9960\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1211 - accuracy: 0.9599 - val_loss: 0.0154 - val_accuracy: 0.9973\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1175 - accuracy: 0.9638 - val_loss: 0.0164 - val_accuracy: 0.9960\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1272 - accuracy: 0.9578 - val_loss: 0.0210 - val_accuracy: 0.9946\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1189 - accuracy: 0.9596 - val_loss: 0.0141 - val_accuracy: 0.9960\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1101 - accuracy: 0.9633 - val_loss: 0.0132 - val_accuracy: 0.9960\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1245 - accuracy: 0.9569 - val_loss: 0.0243 - val_accuracy: 0.9946\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1180 - accuracy: 0.9613 - val_loss: 0.0203 - val_accuracy: 0.9946\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1011 - accuracy: 0.9671 - val_loss: 0.0209 - val_accuracy: 0.9960\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1100 - accuracy: 0.9668 - val_loss: 0.0140 - val_accuracy: 0.9973\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1012 - accuracy: 0.9666 - val_loss: 0.0185 - val_accuracy: 0.9960\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1297 - accuracy: 0.9540 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1213 - accuracy: 0.9596 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1042 - accuracy: 0.9647 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1012 - accuracy: 0.9665 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0988 - accuracy: 0.9674 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1099 - accuracy: 0.9632 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1041 - accuracy: 0.9687 - val_loss: 0.0035 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1056 - accuracy: 0.9657 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1081 - accuracy: 0.9644 - val_loss: 0.0070 - val_accuracy: 0.9973\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1197 - accuracy: 0.9611 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1058 - accuracy: 0.9678 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0988 - accuracy: 0.9681 - val_loss: 0.0050 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0823 - accuracy: 0.9736 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0883 - accuracy: 0.9720 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0956 - accuracy: 0.9683 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1073 - accuracy: 0.9632 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0901 - accuracy: 0.9738 - val_loss: 0.0055 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0999 - accuracy: 0.9687 - val_loss: 0.0118 - val_accuracy: 0.9960\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0892 - accuracy: 0.9706 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0811 - accuracy: 0.9729 - val_loss: 0.0068 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0998 - accuracy: 0.9674 - val_loss: 0.0107 - val_accuracy: 0.9973\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1017 - accuracy: 0.9639 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1029 - accuracy: 0.9644 - val_loss: 0.0045 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0870 - accuracy: 0.9696 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0835 - accuracy: 0.9727 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0868 - accuracy: 0.9739 - val_loss: 0.0076 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0768 - accuracy: 0.9751 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0802 - accuracy: 0.9724 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0734 - accuracy: 0.9768 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0927 - accuracy: 0.9705 - val_loss: 0.0064 - val_accuracy: 0.9987\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0945 - accuracy: 0.9678 - val_loss: 8.8050e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0666 - accuracy: 0.9785 - val_loss: 9.2010e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0891 - accuracy: 0.9709 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0772 - accuracy: 0.9738 - val_loss: 9.9007e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0864 - accuracy: 0.9708 - val_loss: 5.7878e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0794 - accuracy: 0.9754 - val_loss: 5.4180e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0913 - accuracy: 0.9712 - val_loss: 3.7536e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0840 - accuracy: 0.9723 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0851 - accuracy: 0.9693 - val_loss: 5.3099e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0844 - accuracy: 0.9735 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0738 - accuracy: 0.9744 - val_loss: 5.7258e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0804 - accuracy: 0.9741 - val_loss: 8.6502e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0763 - accuracy: 0.9750 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0794 - accuracy: 0.9732 - val_loss: 5.5825e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0765 - accuracy: 0.9741 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0699 - accuracy: 0.9768 - val_loss: 9.0310e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0692 - accuracy: 0.9785 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0692 - accuracy: 0.9765 - val_loss: 9.4605e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0862 - accuracy: 0.9732 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0734 - accuracy: 0.9769 - val_loss: 7.2247e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0934 - accuracy: 0.9714 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0725 - accuracy: 0.9756 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0759 - accuracy: 0.9759 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0732 - accuracy: 0.9753 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0700 - accuracy: 0.9771 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0685 - accuracy: 0.9790 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0601 - accuracy: 0.9812 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0672 - accuracy: 0.9759 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0799 - accuracy: 0.9742 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0693 - accuracy: 0.9784 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0952 - accuracy: 0.9715 - val_loss: 6.7340e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0987 - accuracy: 0.9654 - val_loss: 6.7771e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0728 - accuracy: 0.9742 - val_loss: 3.7980e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0659 - accuracy: 0.9771 - val_loss: 3.9242e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0736 - accuracy: 0.9739 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0680 - accuracy: 0.9785 - val_loss: 5.1183e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0818 - accuracy: 0.9768 - val_loss: 5.7677e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0777 - accuracy: 0.9736 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0757 - accuracy: 0.9762 - val_loss: 4.5906e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0526 - accuracy: 0.9845 - val_loss: 4.2037e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0916 - accuracy: 0.9703 - val_loss: 5.7533e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0719 - accuracy: 0.9784 - val_loss: 2.9266e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0670 - accuracy: 0.9781 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0625 - accuracy: 0.9808 - val_loss: 9.3024e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0631 - accuracy: 0.9781 - val_loss: 3.1595e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0669 - accuracy: 0.9797 - val_loss: 3.5102e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0711 - accuracy: 0.9791 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0763 - accuracy: 0.9732 - val_loss: 7.9856e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0600 - accuracy: 0.9820 - val_loss: 4.0049e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0571 - accuracy: 0.9829 - val_loss: 3.6014e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0586 - accuracy: 0.9800 - val_loss: 6.8000e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0667 - accuracy: 0.9817 - val_loss: 2.1830e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0534 - accuracy: 0.9821 - val_loss: 2.9131e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0546 - accuracy: 0.9827 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0631 - accuracy: 0.9799 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0628 - accuracy: 0.9800 - val_loss: 0.0029 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0667 - accuracy: 0.9788 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0609 - accuracy: 0.9785 - val_loss: 7.1911e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0640 - accuracy: 0.9787 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0535 - accuracy: 0.9826 - val_loss: 0.0011 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "8d3fd52b-f318-4239-c5a2-ae03d6f4d97d"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 8ms/step - loss: 0.0751 - accuracy: 0.9700\n",
            "Accuracy  : 0.9699570536613464\n",
            "F1_Score  : 0.9684436804474427\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}