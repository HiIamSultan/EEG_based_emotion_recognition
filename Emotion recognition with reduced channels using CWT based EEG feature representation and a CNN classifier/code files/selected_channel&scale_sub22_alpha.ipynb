{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub22_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "f5fe3647-4c02-491f-955a-f1ff6d0c3fa1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e3\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  #EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "89d58f8e-a46e-483d-ece5-da242a91629d"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(22,23):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.22\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (3495,) (2330,) (3495,)\n",
            "(9320,) (1864,) (2796,) (4660,)\n",
            "(9320,) (1631,) (3961,) (3728,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "e228f3aa-173e-4b64-af9c-426d348a1ee1"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "0a659fe3-bffa-4413-e996-e4a5f654049b"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "479"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "346cfa1d-67a8-48ec-c3df-e654adc9009c"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21798773-e2ba-4e6a-bbf3-dfd9c3d44c0d"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 28s 59ms/step - loss: 1.1966 - accuracy: 0.3497 - val_loss: 1.0965 - val_accuracy: 0.3579\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0900 - accuracy: 0.3798 - val_loss: 1.0941 - val_accuracy: 0.3472\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0858 - accuracy: 0.3740 - val_loss: 1.0949 - val_accuracy: 0.3579\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0848 - accuracy: 0.3735 - val_loss: 1.0905 - val_accuracy: 0.3619\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0848 - accuracy: 0.3759 - val_loss: 1.0933 - val_accuracy: 0.3579\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0861 - accuracy: 0.3732 - val_loss: 1.0928 - val_accuracy: 0.3646\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0827 - accuracy: 0.3653 - val_loss: 1.0909 - val_accuracy: 0.3579\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0829 - accuracy: 0.3803 - val_loss: 1.0937 - val_accuracy: 0.3579\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0811 - accuracy: 0.3744 - val_loss: 1.0918 - val_accuracy: 0.3700\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0825 - accuracy: 0.3765 - val_loss: 1.0928 - val_accuracy: 0.3633\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0825 - accuracy: 0.3704 - val_loss: 1.0922 - val_accuracy: 0.3579\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0812 - accuracy: 0.3806 - val_loss: 1.0932 - val_accuracy: 0.3660\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0824 - accuracy: 0.3745 - val_loss: 1.0918 - val_accuracy: 0.3700\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0826 - accuracy: 0.3779 - val_loss: 1.0920 - val_accuracy: 0.3646\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0791 - accuracy: 0.3770 - val_loss: 1.0923 - val_accuracy: 0.3713\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0833 - accuracy: 0.3773 - val_loss: 1.0919 - val_accuracy: 0.3539\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0774 - accuracy: 0.3801 - val_loss: 1.0906 - val_accuracy: 0.3579\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0818 - accuracy: 0.3786 - val_loss: 1.0921 - val_accuracy: 0.3646\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0796 - accuracy: 0.3764 - val_loss: 1.0895 - val_accuracy: 0.3686\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0826 - accuracy: 0.3647 - val_loss: 1.0934 - val_accuracy: 0.3579\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0816 - accuracy: 0.3700 - val_loss: 1.0908 - val_accuracy: 0.3700\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0775 - accuracy: 0.3859 - val_loss: 1.0889 - val_accuracy: 0.3633\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0768 - accuracy: 0.3928 - val_loss: 1.0894 - val_accuracy: 0.3700\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0852 - accuracy: 0.3641 - val_loss: 1.0919 - val_accuracy: 0.3727\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0831 - accuracy: 0.3833 - val_loss: 1.0906 - val_accuracy: 0.3606\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0825 - accuracy: 0.3768 - val_loss: 1.0923 - val_accuracy: 0.3525\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0788 - accuracy: 0.3776 - val_loss: 1.0896 - val_accuracy: 0.3592\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0784 - accuracy: 0.3812 - val_loss: 1.0905 - val_accuracy: 0.3673\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0775 - accuracy: 0.3779 - val_loss: 1.0907 - val_accuracy: 0.3713\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0848 - accuracy: 0.3746 - val_loss: 1.0928 - val_accuracy: 0.3713\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0815 - accuracy: 0.3727 - val_loss: 1.0739 - val_accuracy: 0.3968\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0803 - accuracy: 0.3739 - val_loss: 1.0782 - val_accuracy: 0.3847\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0814 - accuracy: 0.3742 - val_loss: 1.0697 - val_accuracy: 0.3740\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0808 - accuracy: 0.3790 - val_loss: 1.0711 - val_accuracy: 0.3928\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0805 - accuracy: 0.3808 - val_loss: 1.0696 - val_accuracy: 0.3928\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0806 - accuracy: 0.3773 - val_loss: 1.0724 - val_accuracy: 0.3847\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0796 - accuracy: 0.3702 - val_loss: 1.0725 - val_accuracy: 0.3887\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0800 - accuracy: 0.3779 - val_loss: 1.0718 - val_accuracy: 0.3901\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0819 - accuracy: 0.3818 - val_loss: 1.0722 - val_accuracy: 0.3887\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0814 - accuracy: 0.3808 - val_loss: 1.0711 - val_accuracy: 0.3914\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0786 - accuracy: 0.3806 - val_loss: 1.0673 - val_accuracy: 0.3713\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0796 - accuracy: 0.3766 - val_loss: 1.0691 - val_accuracy: 0.4008\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0809 - accuracy: 0.3821 - val_loss: 1.0699 - val_accuracy: 0.3887\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0811 - accuracy: 0.3748 - val_loss: 1.0783 - val_accuracy: 0.3646\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0818 - accuracy: 0.3773 - val_loss: 1.0727 - val_accuracy: 0.3981\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0799 - accuracy: 0.3820 - val_loss: 1.0746 - val_accuracy: 0.3861\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0793 - accuracy: 0.3845 - val_loss: 1.0711 - val_accuracy: 0.3941\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0794 - accuracy: 0.3858 - val_loss: 1.0707 - val_accuracy: 0.3901\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0810 - accuracy: 0.3781 - val_loss: 1.0698 - val_accuracy: 0.3834\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0810 - accuracy: 0.3905 - val_loss: 1.0711 - val_accuracy: 0.3914\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0804 - accuracy: 0.3787 - val_loss: 1.0704 - val_accuracy: 0.3981\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0808 - accuracy: 0.3879 - val_loss: 1.0693 - val_accuracy: 0.3901\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0814 - accuracy: 0.3753 - val_loss: 1.0769 - val_accuracy: 0.3847\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0792 - accuracy: 0.3803 - val_loss: 1.0698 - val_accuracy: 0.3954\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0817 - accuracy: 0.3793 - val_loss: 1.0724 - val_accuracy: 0.3914\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0820 - accuracy: 0.3835 - val_loss: 1.0719 - val_accuracy: 0.3901\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0803 - accuracy: 0.3812 - val_loss: 1.0735 - val_accuracy: 0.3834\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0812 - accuracy: 0.3815 - val_loss: 1.0709 - val_accuracy: 0.3874\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0795 - accuracy: 0.3757 - val_loss: 1.0701 - val_accuracy: 0.4088\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0791 - accuracy: 0.3806 - val_loss: 1.0790 - val_accuracy: 0.3780\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0809 - accuracy: 0.3759 - val_loss: 1.0813 - val_accuracy: 0.3673\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0795 - accuracy: 0.3751 - val_loss: 1.0763 - val_accuracy: 0.3780\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0782 - accuracy: 0.3860 - val_loss: 1.0727 - val_accuracy: 0.3874\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0786 - accuracy: 0.3841 - val_loss: 1.0778 - val_accuracy: 0.3780\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0786 - accuracy: 0.3873 - val_loss: 1.0754 - val_accuracy: 0.3834\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0775 - accuracy: 0.3852 - val_loss: 1.0958 - val_accuracy: 0.3633\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0786 - accuracy: 0.3814 - val_loss: 1.0840 - val_accuracy: 0.3740\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0786 - accuracy: 0.3851 - val_loss: 1.0869 - val_accuracy: 0.3660\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0776 - accuracy: 0.3861 - val_loss: 1.0887 - val_accuracy: 0.3566\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0765 - accuracy: 0.3857 - val_loss: 1.0703 - val_accuracy: 0.3874\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0785 - accuracy: 0.3794 - val_loss: 1.0817 - val_accuracy: 0.3740\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0774 - accuracy: 0.3861 - val_loss: 1.0806 - val_accuracy: 0.3834\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0776 - accuracy: 0.3744 - val_loss: 1.0820 - val_accuracy: 0.3861\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0803 - accuracy: 0.3754 - val_loss: 1.0828 - val_accuracy: 0.3686\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0767 - accuracy: 0.3838 - val_loss: 1.0757 - val_accuracy: 0.3941\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0758 - accuracy: 0.3841 - val_loss: 1.0730 - val_accuracy: 0.3807\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0758 - accuracy: 0.3833 - val_loss: 1.0750 - val_accuracy: 0.3981\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0737 - accuracy: 0.3866 - val_loss: 1.0753 - val_accuracy: 0.3861\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0738 - accuracy: 0.3911 - val_loss: 1.0696 - val_accuracy: 0.3941\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0702 - accuracy: 0.3951 - val_loss: 1.0772 - val_accuracy: 0.3807\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0710 - accuracy: 0.3946 - val_loss: 1.0686 - val_accuracy: 0.4021\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0753 - accuracy: 0.3931 - val_loss: 1.0798 - val_accuracy: 0.3686\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0733 - accuracy: 0.3838 - val_loss: 1.0807 - val_accuracy: 0.3753\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0750 - accuracy: 0.3900 - val_loss: 1.0684 - val_accuracy: 0.4035\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0657 - accuracy: 0.4016 - val_loss: 1.0690 - val_accuracy: 0.3847\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0704 - accuracy: 0.3954 - val_loss: 1.0720 - val_accuracy: 0.3954\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0665 - accuracy: 0.3970 - val_loss: 1.0636 - val_accuracy: 0.3995\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0637 - accuracy: 0.4028 - val_loss: 1.0612 - val_accuracy: 0.3981\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0687 - accuracy: 0.4012 - val_loss: 1.0728 - val_accuracy: 0.3914\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0710 - accuracy: 0.3972 - val_loss: 1.0634 - val_accuracy: 0.3995\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0628 - accuracy: 0.4072 - val_loss: 1.0628 - val_accuracy: 0.4209\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0626 - accuracy: 0.4101 - val_loss: 1.0634 - val_accuracy: 0.4062\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0672 - accuracy: 0.3948 - val_loss: 1.0512 - val_accuracy: 0.4263\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0588 - accuracy: 0.4095 - val_loss: 1.0457 - val_accuracy: 0.4343\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0655 - accuracy: 0.4049 - val_loss: 1.0455 - val_accuracy: 0.4370\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0586 - accuracy: 0.4109 - val_loss: 1.0667 - val_accuracy: 0.3874\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0632 - accuracy: 0.4027 - val_loss: 1.0557 - val_accuracy: 0.4102\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0548 - accuracy: 0.4061 - val_loss: 1.0515 - val_accuracy: 0.4397\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0553 - accuracy: 0.4104 - val_loss: 1.0614 - val_accuracy: 0.4316\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0501 - accuracy: 0.4203 - val_loss: 1.0518 - val_accuracy: 0.4075\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0493 - accuracy: 0.4228 - val_loss: 1.0572 - val_accuracy: 0.4276\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0473 - accuracy: 0.4241 - val_loss: 1.0608 - val_accuracy: 0.4142\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0455 - accuracy: 0.4197 - val_loss: 1.0491 - val_accuracy: 0.4531\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0413 - accuracy: 0.4253 - val_loss: 1.0436 - val_accuracy: 0.4504\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0510 - accuracy: 0.4271 - val_loss: 1.0386 - val_accuracy: 0.4812\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0433 - accuracy: 0.4274 - val_loss: 1.0383 - val_accuracy: 0.4464\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0394 - accuracy: 0.4238 - val_loss: 1.0571 - val_accuracy: 0.4249\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0459 - accuracy: 0.4238 - val_loss: 1.0417 - val_accuracy: 0.4316\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0349 - accuracy: 0.4401 - val_loss: 1.0393 - val_accuracy: 0.4450\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0353 - accuracy: 0.4401 - val_loss: 1.0393 - val_accuracy: 0.4370\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0344 - accuracy: 0.4382 - val_loss: 1.0293 - val_accuracy: 0.4544\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0302 - accuracy: 0.4325 - val_loss: 1.0291 - val_accuracy: 0.4477\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0259 - accuracy: 0.4395 - val_loss: 1.0337 - val_accuracy: 0.4437\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0289 - accuracy: 0.4368 - val_loss: 1.0243 - val_accuracy: 0.4598\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0245 - accuracy: 0.4450 - val_loss: 1.0364 - val_accuracy: 0.4343\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0224 - accuracy: 0.4504 - val_loss: 1.0209 - val_accuracy: 0.4665\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0309 - accuracy: 0.4526 - val_loss: 1.0331 - val_accuracy: 0.4799\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0248 - accuracy: 0.4450 - val_loss: 1.0289 - val_accuracy: 0.4357\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0155 - accuracy: 0.4446 - val_loss: 1.0144 - val_accuracy: 0.4611\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0189 - accuracy: 0.4481 - val_loss: 1.0089 - val_accuracy: 0.4584\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0202 - accuracy: 0.4508 - val_loss: 1.0232 - val_accuracy: 0.4142\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0145 - accuracy: 0.4517 - val_loss: 0.9978 - val_accuracy: 0.4437\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0129 - accuracy: 0.4601 - val_loss: 1.0030 - val_accuracy: 0.4437\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0060 - accuracy: 0.4595 - val_loss: 1.0079 - val_accuracy: 0.4196\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0012 - accuracy: 0.4686 - val_loss: 1.0119 - val_accuracy: 0.4155\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9975 - accuracy: 0.4697 - val_loss: 0.9791 - val_accuracy: 0.4906\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9913 - accuracy: 0.4821 - val_loss: 0.9905 - val_accuracy: 0.4450\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9878 - accuracy: 0.4708 - val_loss: 0.9882 - val_accuracy: 0.4357\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9859 - accuracy: 0.4821 - val_loss: 0.9792 - val_accuracy: 0.4424\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9870 - accuracy: 0.4860 - val_loss: 0.9837 - val_accuracy: 0.4464\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9756 - accuracy: 0.4917 - val_loss: 0.9776 - val_accuracy: 0.4638\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9699 - accuracy: 0.4917 - val_loss: 0.9748 - val_accuracy: 0.4705\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9697 - accuracy: 0.4921 - val_loss: 0.9708 - val_accuracy: 0.4558\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9684 - accuracy: 0.4878 - val_loss: 0.9744 - val_accuracy: 0.4651\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9570 - accuracy: 0.4946 - val_loss: 0.9893 - val_accuracy: 0.4357\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9471 - accuracy: 0.5048 - val_loss: 0.9700 - val_accuracy: 0.4504\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9528 - accuracy: 0.5007 - val_loss: 0.9708 - val_accuracy: 0.4638\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9465 - accuracy: 0.5015 - val_loss: 0.9459 - val_accuracy: 0.4772\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9364 - accuracy: 0.5107 - val_loss: 0.9524 - val_accuracy: 0.4611\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9404 - accuracy: 0.5069 - val_loss: 0.9311 - val_accuracy: 0.4839\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9206 - accuracy: 0.5127 - val_loss: 0.9236 - val_accuracy: 0.4920\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9347 - accuracy: 0.5082 - val_loss: 0.9263 - val_accuracy: 0.4866\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9242 - accuracy: 0.5149 - val_loss: 0.9306 - val_accuracy: 0.4826\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9130 - accuracy: 0.5234 - val_loss: 0.9260 - val_accuracy: 0.4933\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9125 - accuracy: 0.5280 - val_loss: 0.9192 - val_accuracy: 0.4960\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9024 - accuracy: 0.5259 - val_loss: 0.8924 - val_accuracy: 0.4973\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8869 - accuracy: 0.5382 - val_loss: 0.9073 - val_accuracy: 0.5054\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8802 - accuracy: 0.5419 - val_loss: 0.8750 - val_accuracy: 0.5107\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9030 - accuracy: 0.5328 - val_loss: 0.9132 - val_accuracy: 0.5067\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8740 - accuracy: 0.5504 - val_loss: 0.8908 - val_accuracy: 0.4946\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8916 - accuracy: 0.5370 - val_loss: 0.8215 - val_accuracy: 0.5818\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8720 - accuracy: 0.5514 - val_loss: 0.8068 - val_accuracy: 0.5804\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8601 - accuracy: 0.5580 - val_loss: 0.8135 - val_accuracy: 0.5777\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8617 - accuracy: 0.5547 - val_loss: 0.8002 - val_accuracy: 0.5938\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8573 - accuracy: 0.5547 - val_loss: 0.8005 - val_accuracy: 0.5858\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8621 - accuracy: 0.5577 - val_loss: 0.8072 - val_accuracy: 0.5751\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8502 - accuracy: 0.5624 - val_loss: 0.7952 - val_accuracy: 0.5885\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8360 - accuracy: 0.5680 - val_loss: 0.7893 - val_accuracy: 0.6247\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8367 - accuracy: 0.5601 - val_loss: 0.7998 - val_accuracy: 0.6059\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8398 - accuracy: 0.5711 - val_loss: 0.7944 - val_accuracy: 0.6059\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8221 - accuracy: 0.5835 - val_loss: 0.7879 - val_accuracy: 0.5871\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8132 - accuracy: 0.5815 - val_loss: 0.7992 - val_accuracy: 0.5965\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8174 - accuracy: 0.5759 - val_loss: 0.7923 - val_accuracy: 0.6072\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8071 - accuracy: 0.5824 - val_loss: 0.8053 - val_accuracy: 0.5898\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8149 - accuracy: 0.5863 - val_loss: 0.7911 - val_accuracy: 0.5938\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7906 - accuracy: 0.5955 - val_loss: 0.7881 - val_accuracy: 0.6086\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8011 - accuracy: 0.5876 - val_loss: 0.7898 - val_accuracy: 0.6005\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7950 - accuracy: 0.5943 - val_loss: 0.7750 - val_accuracy: 0.6019\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7951 - accuracy: 0.6004 - val_loss: 0.7830 - val_accuracy: 0.6340\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7784 - accuracy: 0.6070 - val_loss: 0.7935 - val_accuracy: 0.6059\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7794 - accuracy: 0.6040 - val_loss: 0.7628 - val_accuracy: 0.5965\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7693 - accuracy: 0.6155 - val_loss: 0.7569 - val_accuracy: 0.6367\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7611 - accuracy: 0.6195 - val_loss: 0.7704 - val_accuracy: 0.6381\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7732 - accuracy: 0.6086 - val_loss: 0.7708 - val_accuracy: 0.6340\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7602 - accuracy: 0.6158 - val_loss: 0.7607 - val_accuracy: 0.6461\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7560 - accuracy: 0.6171 - val_loss: 0.7536 - val_accuracy: 0.6367\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7637 - accuracy: 0.6146 - val_loss: 0.7641 - val_accuracy: 0.6287\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7697 - accuracy: 0.6097 - val_loss: 0.7640 - val_accuracy: 0.6260\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7481 - accuracy: 0.6334 - val_loss: 0.7508 - val_accuracy: 0.6582\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7297 - accuracy: 0.6316 - val_loss: 0.7643 - val_accuracy: 0.6300\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 47ms/step - loss: 0.7471 - accuracy: 0.6230 - val_loss: 0.6575 - val_accuracy: 0.6738\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7370 - accuracy: 0.6451 - val_loss: 0.6570 - val_accuracy: 0.6899\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7308 - accuracy: 0.6442 - val_loss: 0.6473 - val_accuracy: 0.7007\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7339 - accuracy: 0.6409 - val_loss: 0.6623 - val_accuracy: 0.6644\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7421 - accuracy: 0.6413 - val_loss: 0.6440 - val_accuracy: 0.6913\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7117 - accuracy: 0.6591 - val_loss: 0.6658 - val_accuracy: 0.6940\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7219 - accuracy: 0.6544 - val_loss: 0.6688 - val_accuracy: 0.6832\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7031 - accuracy: 0.6582 - val_loss: 0.6333 - val_accuracy: 0.6913\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7023 - accuracy: 0.6564 - val_loss: 0.6526 - val_accuracy: 0.6671\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6964 - accuracy: 0.6634 - val_loss: 0.6357 - val_accuracy: 0.7154\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7164 - accuracy: 0.6540 - val_loss: 0.6587 - val_accuracy: 0.6430\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7010 - accuracy: 0.6689 - val_loss: 0.6497 - val_accuracy: 0.7168\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6871 - accuracy: 0.6679 - val_loss: 0.6153 - val_accuracy: 0.7168\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6970 - accuracy: 0.6656 - val_loss: 0.6197 - val_accuracy: 0.7074\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6786 - accuracy: 0.6810 - val_loss: 0.6205 - val_accuracy: 0.7315\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6677 - accuracy: 0.6899 - val_loss: 0.6430 - val_accuracy: 0.6926\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6703 - accuracy: 0.6829 - val_loss: 0.6158 - val_accuracy: 0.7195\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6563 - accuracy: 0.6905 - val_loss: 0.6221 - val_accuracy: 0.7208\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6544 - accuracy: 0.6938 - val_loss: 0.5866 - val_accuracy: 0.7329\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6521 - accuracy: 0.6962 - val_loss: 0.6142 - val_accuracy: 0.7396\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6435 - accuracy: 0.7042 - val_loss: 0.5722 - val_accuracy: 0.7315\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6418 - accuracy: 0.7014 - val_loss: 0.6178 - val_accuracy: 0.7450\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6271 - accuracy: 0.7141 - val_loss: 0.5811 - val_accuracy: 0.7396\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6276 - accuracy: 0.7100 - val_loss: 0.5657 - val_accuracy: 0.7597\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6236 - accuracy: 0.7129 - val_loss: 0.5821 - val_accuracy: 0.7383\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6089 - accuracy: 0.7228 - val_loss: 0.5503 - val_accuracy: 0.7557\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5987 - accuracy: 0.7245 - val_loss: 0.5427 - val_accuracy: 0.7530\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6122 - accuracy: 0.7212 - val_loss: 0.5788 - val_accuracy: 0.7517\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5867 - accuracy: 0.7297 - val_loss: 0.5811 - val_accuracy: 0.7477\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5945 - accuracy: 0.7333 - val_loss: 0.5463 - val_accuracy: 0.7758\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6113 - accuracy: 0.7211 - val_loss: 0.4451 - val_accuracy: 0.8013\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5943 - accuracy: 0.7370 - val_loss: 0.4470 - val_accuracy: 0.7987\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5799 - accuracy: 0.7394 - val_loss: 0.4088 - val_accuracy: 0.8255\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5694 - accuracy: 0.7482 - val_loss: 0.4071 - val_accuracy: 0.8268\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5702 - accuracy: 0.7494 - val_loss: 0.4276 - val_accuracy: 0.8188\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5643 - accuracy: 0.7520 - val_loss: 0.4491 - val_accuracy: 0.8121\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5493 - accuracy: 0.7549 - val_loss: 0.3820 - val_accuracy: 0.8456\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5463 - accuracy: 0.7658 - val_loss: 0.4164 - val_accuracy: 0.8107\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5614 - accuracy: 0.7565 - val_loss: 0.4250 - val_accuracy: 0.7946\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5470 - accuracy: 0.7671 - val_loss: 0.4112 - val_accuracy: 0.8255\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5182 - accuracy: 0.7790 - val_loss: 0.3763 - val_accuracy: 0.8456\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5003 - accuracy: 0.7890 - val_loss: 0.3685 - val_accuracy: 0.8403\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5042 - accuracy: 0.7854 - val_loss: 0.3756 - val_accuracy: 0.8268\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4837 - accuracy: 0.7950 - val_loss: 0.3468 - val_accuracy: 0.8470\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4882 - accuracy: 0.7912 - val_loss: 0.3301 - val_accuracy: 0.8779\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4943 - accuracy: 0.7920 - val_loss: 0.3377 - val_accuracy: 0.8604\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4828 - accuracy: 0.7973 - val_loss: 0.3389 - val_accuracy: 0.8685\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4699 - accuracy: 0.8072 - val_loss: 0.3302 - val_accuracy: 0.8752\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4739 - accuracy: 0.8048 - val_loss: 0.3267 - val_accuracy: 0.8483\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4590 - accuracy: 0.8112 - val_loss: 0.3182 - val_accuracy: 0.8725\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4553 - accuracy: 0.8128 - val_loss: 0.2997 - val_accuracy: 0.8846\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4379 - accuracy: 0.8198 - val_loss: 0.2989 - val_accuracy: 0.8886\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4306 - accuracy: 0.8255 - val_loss: 0.2869 - val_accuracy: 0.8859\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4222 - accuracy: 0.8306 - val_loss: 0.2927 - val_accuracy: 0.8738\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4103 - accuracy: 0.8415 - val_loss: 0.2625 - val_accuracy: 0.9034\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4016 - accuracy: 0.8449 - val_loss: 0.2915 - val_accuracy: 0.8832\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3966 - accuracy: 0.8395 - val_loss: 0.2961 - val_accuracy: 0.8725\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3894 - accuracy: 0.8453 - val_loss: 0.2600 - val_accuracy: 0.9020\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3824 - accuracy: 0.8511 - val_loss: 0.2332 - val_accuracy: 0.9141\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3879 - accuracy: 0.8482 - val_loss: 0.2647 - val_accuracy: 0.8913\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3979 - accuracy: 0.8434 - val_loss: 0.1773 - val_accuracy: 0.9611\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4042 - accuracy: 0.8409 - val_loss: 0.1623 - val_accuracy: 0.9409\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.3785 - accuracy: 0.8526 - val_loss: 0.1542 - val_accuracy: 0.9530\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3558 - accuracy: 0.8646 - val_loss: 0.1440 - val_accuracy: 0.9570\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3518 - accuracy: 0.8668 - val_loss: 0.1350 - val_accuracy: 0.9611\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3450 - accuracy: 0.8696 - val_loss: 0.1380 - val_accuracy: 0.9678\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3101 - accuracy: 0.8830 - val_loss: 0.1513 - val_accuracy: 0.9517\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3292 - accuracy: 0.8781 - val_loss: 0.1576 - val_accuracy: 0.9396\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3263 - accuracy: 0.8751 - val_loss: 0.1258 - val_accuracy: 0.9664\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3280 - accuracy: 0.8775 - val_loss: 0.1392 - val_accuracy: 0.9584\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3056 - accuracy: 0.8844 - val_loss: 0.1219 - val_accuracy: 0.9611\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3018 - accuracy: 0.8868 - val_loss: 0.1279 - val_accuracy: 0.9664\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3239 - accuracy: 0.8757 - val_loss: 0.1478 - val_accuracy: 0.9423\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2933 - accuracy: 0.8949 - val_loss: 0.1370 - val_accuracy: 0.9517\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2765 - accuracy: 0.8987 - val_loss: 0.1255 - val_accuracy: 0.9503\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2995 - accuracy: 0.8909 - val_loss: 0.1175 - val_accuracy: 0.9638\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2962 - accuracy: 0.8924 - val_loss: 0.1117 - val_accuracy: 0.9718\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2620 - accuracy: 0.9025 - val_loss: 0.1235 - val_accuracy: 0.9503\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2573 - accuracy: 0.9085 - val_loss: 0.1080 - val_accuracy: 0.9678\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2687 - accuracy: 0.9037 - val_loss: 0.1254 - val_accuracy: 0.9570\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3078 - accuracy: 0.8845 - val_loss: 0.1153 - val_accuracy: 0.9678\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2598 - accuracy: 0.9064 - val_loss: 0.0936 - val_accuracy: 0.9691\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2392 - accuracy: 0.9130 - val_loss: 0.0953 - val_accuracy: 0.9651\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2364 - accuracy: 0.9189 - val_loss: 0.0861 - val_accuracy: 0.9718\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2193 - accuracy: 0.9200 - val_loss: 0.0747 - val_accuracy: 0.9772\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2240 - accuracy: 0.9210 - val_loss: 0.0916 - val_accuracy: 0.9758\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2271 - accuracy: 0.9212 - val_loss: 0.0901 - val_accuracy: 0.9745\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2343 - accuracy: 0.9140 - val_loss: 0.0881 - val_accuracy: 0.9745\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2299 - accuracy: 0.9186 - val_loss: 0.0995 - val_accuracy: 0.9718\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2301 - accuracy: 0.9248 - val_loss: 0.0862 - val_accuracy: 0.9772\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2225 - accuracy: 0.9227 - val_loss: 0.0315 - val_accuracy: 0.9946\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1956 - accuracy: 0.9312 - val_loss: 0.0247 - val_accuracy: 0.9973\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2159 - accuracy: 0.9250 - val_loss: 0.0393 - val_accuracy: 0.9933\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1895 - accuracy: 0.9315 - val_loss: 0.0322 - val_accuracy: 0.9960\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1984 - accuracy: 0.9318 - val_loss: 0.0276 - val_accuracy: 0.9960\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2370 - accuracy: 0.9151 - val_loss: 0.0388 - val_accuracy: 0.9946\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2042 - accuracy: 0.9252 - val_loss: 0.0291 - val_accuracy: 0.9960\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2056 - accuracy: 0.9297 - val_loss: 0.0313 - val_accuracy: 0.9946\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1828 - accuracy: 0.9349 - val_loss: 0.0345 - val_accuracy: 0.9919\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1996 - accuracy: 0.9288 - val_loss: 0.0331 - val_accuracy: 0.9919\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1757 - accuracy: 0.9377 - val_loss: 0.0312 - val_accuracy: 0.9933\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1945 - accuracy: 0.9286 - val_loss: 0.0271 - val_accuracy: 0.9960\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1664 - accuracy: 0.9417 - val_loss: 0.0253 - val_accuracy: 0.9973\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2154 - accuracy: 0.9306 - val_loss: 0.0416 - val_accuracy: 0.9893\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1626 - accuracy: 0.9449 - val_loss: 0.0428 - val_accuracy: 0.9839\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1695 - accuracy: 0.9432 - val_loss: 0.0236 - val_accuracy: 0.9960\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1653 - accuracy: 0.9422 - val_loss: 0.0372 - val_accuracy: 0.9866\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1505 - accuracy: 0.9459 - val_loss: 0.0449 - val_accuracy: 0.9826\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2474 - accuracy: 0.9176 - val_loss: 0.0483 - val_accuracy: 0.9879\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1514 - accuracy: 0.9505 - val_loss: 0.0298 - val_accuracy: 0.9933\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1519 - accuracy: 0.9462 - val_loss: 0.0292 - val_accuracy: 0.9933\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1567 - accuracy: 0.9444 - val_loss: 0.0234 - val_accuracy: 0.9973\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1733 - accuracy: 0.9428 - val_loss: 0.0339 - val_accuracy: 0.9906\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1366 - accuracy: 0.9517 - val_loss: 0.0225 - val_accuracy: 0.9919\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1575 - accuracy: 0.9483 - val_loss: 0.0232 - val_accuracy: 0.9919\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1320 - accuracy: 0.9586 - val_loss: 0.0222 - val_accuracy: 0.9960\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1301 - accuracy: 0.9563 - val_loss: 0.0230 - val_accuracy: 0.9933\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1349 - accuracy: 0.9523 - val_loss: 0.0254 - val_accuracy: 0.9919\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1420 - accuracy: 0.9493 - val_loss: 0.0199 - val_accuracy: 0.9919\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1325 - accuracy: 0.9560 - val_loss: 0.0244 - val_accuracy: 0.9919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "CAnc2SJa3o9f",
        "outputId": "a4fc4ac5-719f-4126-a50f-5e89bceb45f9"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 8ms/step - loss: 0.1193 - accuracy: 0.9549\n",
            "Accuracy  : 0.954935610294342\n",
            "F1_Score  : 0.9531457729472063\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7fcxLuwZpkK",
        "outputId": "ac61f19f-e932-4cf0-c696-0d49fca3cc00"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "dbb8297f-b642-4798-cd7f-f4cc3c342977"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 53ms/step - loss: 1.1570 - accuracy: 0.4419 - val_loss: 1.0465 - val_accuracy: 0.4893\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0416 - accuracy: 0.5070 - val_loss: 1.0314 - val_accuracy: 0.4893\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0415 - accuracy: 0.5016 - val_loss: 1.0330 - val_accuracy: 0.4893\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0394 - accuracy: 0.5068 - val_loss: 1.0333 - val_accuracy: 0.4893\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0305 - accuracy: 0.4974 - val_loss: 1.0307 - val_accuracy: 0.4893\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0294 - accuracy: 0.5095 - val_loss: 1.0312 - val_accuracy: 0.4893\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0284 - accuracy: 0.5013 - val_loss: 1.0307 - val_accuracy: 0.4893\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0248 - accuracy: 0.5036 - val_loss: 1.0282 - val_accuracy: 0.4893\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0312 - accuracy: 0.5006 - val_loss: 1.0292 - val_accuracy: 0.4893\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0225 - accuracy: 0.5108 - val_loss: 1.0279 - val_accuracy: 0.4893\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0305 - accuracy: 0.5017 - val_loss: 1.0258 - val_accuracy: 0.4893\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0208 - accuracy: 0.5115 - val_loss: 1.0306 - val_accuracy: 0.4893\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0178 - accuracy: 0.5061 - val_loss: 1.0278 - val_accuracy: 0.4893\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0295 - accuracy: 0.4956 - val_loss: 1.0269 - val_accuracy: 0.4893\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0213 - accuracy: 0.5046 - val_loss: 1.0304 - val_accuracy: 0.4893\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0232 - accuracy: 0.5018 - val_loss: 1.0252 - val_accuracy: 0.4893\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0256 - accuracy: 0.4906 - val_loss: 1.0248 - val_accuracy: 0.4893\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0251 - accuracy: 0.4951 - val_loss: 1.0298 - val_accuracy: 0.4893\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0252 - accuracy: 0.5020 - val_loss: 1.0238 - val_accuracy: 0.4893\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0258 - accuracy: 0.4965 - val_loss: 1.0246 - val_accuracy: 0.4893\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0175 - accuracy: 0.4981 - val_loss: 1.0267 - val_accuracy: 0.4893\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0176 - accuracy: 0.5064 - val_loss: 1.0274 - val_accuracy: 0.4893\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0202 - accuracy: 0.5014 - val_loss: 1.0260 - val_accuracy: 0.4893\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0173 - accuracy: 0.5047 - val_loss: 1.0238 - val_accuracy: 0.4893\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0181 - accuracy: 0.5007 - val_loss: 1.0223 - val_accuracy: 0.4893\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0151 - accuracy: 0.5078 - val_loss: 1.0256 - val_accuracy: 0.4893\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0262 - accuracy: 0.4948 - val_loss: 1.0218 - val_accuracy: 0.4893\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0200 - accuracy: 0.4991 - val_loss: 1.0231 - val_accuracy: 0.4893\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0242 - accuracy: 0.4955 - val_loss: 1.0323 - val_accuracy: 0.4893\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0167 - accuracy: 0.5034 - val_loss: 1.0256 - val_accuracy: 0.4893\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0230 - accuracy: 0.4958 - val_loss: 0.9835 - val_accuracy: 0.5550\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0238 - accuracy: 0.4923 - val_loss: 0.9842 - val_accuracy: 0.5550\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0233 - accuracy: 0.4952 - val_loss: 0.9834 - val_accuracy: 0.5550\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0225 - accuracy: 0.4934 - val_loss: 0.9822 - val_accuracy: 0.5550\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0204 - accuracy: 0.4957 - val_loss: 0.9775 - val_accuracy: 0.5509\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0210 - accuracy: 0.4979 - val_loss: 0.9813 - val_accuracy: 0.5523\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0219 - accuracy: 0.4969 - val_loss: 0.9865 - val_accuracy: 0.5550\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0207 - accuracy: 0.4952 - val_loss: 0.9850 - val_accuracy: 0.5429\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0212 - accuracy: 0.4988 - val_loss: 0.9882 - val_accuracy: 0.5389\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0211 - accuracy: 0.4955 - val_loss: 0.9955 - val_accuracy: 0.5295\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0216 - accuracy: 0.4969 - val_loss: 0.9804 - val_accuracy: 0.5442\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0166 - accuracy: 0.5025 - val_loss: 0.9920 - val_accuracy: 0.5335\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0202 - accuracy: 0.4967 - val_loss: 0.9852 - val_accuracy: 0.5349\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0197 - accuracy: 0.4931 - val_loss: 0.9983 - val_accuracy: 0.5188\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0210 - accuracy: 0.4952 - val_loss: 0.9802 - val_accuracy: 0.5550\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0171 - accuracy: 0.4955 - val_loss: 0.9792 - val_accuracy: 0.5550\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0182 - accuracy: 0.4946 - val_loss: 0.9806 - val_accuracy: 0.5550\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0154 - accuracy: 0.4987 - val_loss: 0.9849 - val_accuracy: 0.5295\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0154 - accuracy: 0.4994 - val_loss: 1.0039 - val_accuracy: 0.5134\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0171 - accuracy: 0.4976 - val_loss: 0.9782 - val_accuracy: 0.5483\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0157 - accuracy: 0.4994 - val_loss: 0.9807 - val_accuracy: 0.5509\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0142 - accuracy: 0.5007 - val_loss: 0.9893 - val_accuracy: 0.5550\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0136 - accuracy: 0.5027 - val_loss: 0.9849 - val_accuracy: 0.5550\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0138 - accuracy: 0.5012 - val_loss: 0.9882 - val_accuracy: 0.5523\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0117 - accuracy: 0.5021 - val_loss: 0.9816 - val_accuracy: 0.5416\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0134 - accuracy: 0.5000 - val_loss: 0.9760 - val_accuracy: 0.5523\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0116 - accuracy: 0.4994 - val_loss: 1.0030 - val_accuracy: 0.5134\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0085 - accuracy: 0.5015 - val_loss: 0.9809 - val_accuracy: 0.5509\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0125 - accuracy: 0.5057 - val_loss: 0.9827 - val_accuracy: 0.5349\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0076 - accuracy: 0.5046 - val_loss: 0.9984 - val_accuracy: 0.5268\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0077 - accuracy: 0.5034 - val_loss: 1.0160 - val_accuracy: 0.4893\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0078 - accuracy: 0.5063 - val_loss: 1.0112 - val_accuracy: 0.4920\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0019 - accuracy: 0.5089 - val_loss: 1.0170 - val_accuracy: 0.5013\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0001 - accuracy: 0.5086 - val_loss: 1.0149 - val_accuracy: 0.5067\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0049 - accuracy: 0.5054 - val_loss: 1.0227 - val_accuracy: 0.5067\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9972 - accuracy: 0.5097 - val_loss: 1.0084 - val_accuracy: 0.4920\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9978 - accuracy: 0.5097 - val_loss: 1.0123 - val_accuracy: 0.4933\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0019 - accuracy: 0.5119 - val_loss: 1.0050 - val_accuracy: 0.5027\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9983 - accuracy: 0.5122 - val_loss: 1.0028 - val_accuracy: 0.5027\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0003 - accuracy: 0.5109 - val_loss: 1.0174 - val_accuracy: 0.5027\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0006 - accuracy: 0.5101 - val_loss: 1.0075 - val_accuracy: 0.5054\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9962 - accuracy: 0.5167 - val_loss: 1.0213 - val_accuracy: 0.4853\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0002 - accuracy: 0.5069 - val_loss: 1.0126 - val_accuracy: 0.4987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9969 - accuracy: 0.5136 - val_loss: 1.0129 - val_accuracy: 0.5094\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9999 - accuracy: 0.5134 - val_loss: 1.0136 - val_accuracy: 0.5094\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9954 - accuracy: 0.5113 - val_loss: 1.0051 - val_accuracy: 0.4960\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9928 - accuracy: 0.5179 - val_loss: 1.0115 - val_accuracy: 0.5013\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9941 - accuracy: 0.5130 - val_loss: 1.0077 - val_accuracy: 0.5027\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9936 - accuracy: 0.5161 - val_loss: 1.0069 - val_accuracy: 0.4987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9964 - accuracy: 0.5127 - val_loss: 1.0234 - val_accuracy: 0.4987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9908 - accuracy: 0.5216 - val_loss: 0.9946 - val_accuracy: 0.4973\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9818 - accuracy: 0.5256 - val_loss: 1.0010 - val_accuracy: 0.5040\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9810 - accuracy: 0.5250 - val_loss: 1.0017 - val_accuracy: 0.5174\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9802 - accuracy: 0.5250 - val_loss: 0.9957 - val_accuracy: 0.5282\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9793 - accuracy: 0.5221 - val_loss: 0.9943 - val_accuracy: 0.5054\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9764 - accuracy: 0.5283 - val_loss: 0.9835 - val_accuracy: 0.5147\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9681 - accuracy: 0.5347 - val_loss: 0.9695 - val_accuracy: 0.5121\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9683 - accuracy: 0.5344 - val_loss: 0.9776 - val_accuracy: 0.5067\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9713 - accuracy: 0.5255 - val_loss: 0.9752 - val_accuracy: 0.5121\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9660 - accuracy: 0.5346 - val_loss: 0.9681 - val_accuracy: 0.5268\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9652 - accuracy: 0.5288 - val_loss: 0.9443 - val_accuracy: 0.5469\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9611 - accuracy: 0.5331 - val_loss: 0.9182 - val_accuracy: 0.5496\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9573 - accuracy: 0.5423 - val_loss: 0.9054 - val_accuracy: 0.5576\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9471 - accuracy: 0.5458 - val_loss: 0.9199 - val_accuracy: 0.5469\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9428 - accuracy: 0.5478 - val_loss: 0.8964 - val_accuracy: 0.5657\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9404 - accuracy: 0.5474 - val_loss: 0.9169 - val_accuracy: 0.5483\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9341 - accuracy: 0.5475 - val_loss: 0.8663 - val_accuracy: 0.5710\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9216 - accuracy: 0.5678 - val_loss: 0.8878 - val_accuracy: 0.5791\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9116 - accuracy: 0.5669 - val_loss: 0.8594 - val_accuracy: 0.5898\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9111 - accuracy: 0.5663 - val_loss: 0.8816 - val_accuracy: 0.5804\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8997 - accuracy: 0.5727 - val_loss: 0.8591 - val_accuracy: 0.5952\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8842 - accuracy: 0.5817 - val_loss: 0.8462 - val_accuracy: 0.6019\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8860 - accuracy: 0.5842 - val_loss: 0.8381 - val_accuracy: 0.6126\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8654 - accuracy: 0.5946 - val_loss: 0.8382 - val_accuracy: 0.6180\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8665 - accuracy: 0.5894 - val_loss: 0.8482 - val_accuracy: 0.6019\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8507 - accuracy: 0.6010 - val_loss: 0.8241 - val_accuracy: 0.6099\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8406 - accuracy: 0.6174 - val_loss: 0.8104 - val_accuracy: 0.6086\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8330 - accuracy: 0.6122 - val_loss: 0.7850 - val_accuracy: 0.6300\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8226 - accuracy: 0.6188 - val_loss: 0.7915 - val_accuracy: 0.6300\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7903 - accuracy: 0.6392 - val_loss: 0.7814 - val_accuracy: 0.6153\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7942 - accuracy: 0.6420 - val_loss: 0.7646 - val_accuracy: 0.6501\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7611 - accuracy: 0.6574 - val_loss: 0.7372 - val_accuracy: 0.6729\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7669 - accuracy: 0.6541 - val_loss: 0.7266 - val_accuracy: 0.6367\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7386 - accuracy: 0.6711 - val_loss: 0.6843 - val_accuracy: 0.6863\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7165 - accuracy: 0.6793 - val_loss: 0.6696 - val_accuracy: 0.6944\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7018 - accuracy: 0.6902 - val_loss: 0.6714 - val_accuracy: 0.6917\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6822 - accuracy: 0.7060 - val_loss: 0.6440 - val_accuracy: 0.7024\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6697 - accuracy: 0.7045 - val_loss: 0.6213 - val_accuracy: 0.7118\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6569 - accuracy: 0.7158 - val_loss: 0.6289 - val_accuracy: 0.6984\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6233 - accuracy: 0.7320 - val_loss: 0.6060 - val_accuracy: 0.7252\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6491 - accuracy: 0.7186 - val_loss: 0.4136 - val_accuracy: 0.8190\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6289 - accuracy: 0.7264 - val_loss: 0.4176 - val_accuracy: 0.8405\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5723 - accuracy: 0.7548 - val_loss: 0.3650 - val_accuracy: 0.8418\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5827 - accuracy: 0.7589 - val_loss: 0.3894 - val_accuracy: 0.8298\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5549 - accuracy: 0.7650 - val_loss: 0.3494 - val_accuracy: 0.8633\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5409 - accuracy: 0.7687 - val_loss: 0.3503 - val_accuracy: 0.8673\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5199 - accuracy: 0.7873 - val_loss: 0.3405 - val_accuracy: 0.8633\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5526 - accuracy: 0.7706 - val_loss: 0.3456 - val_accuracy: 0.8727\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4879 - accuracy: 0.7979 - val_loss: 0.3138 - val_accuracy: 0.8592\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4751 - accuracy: 0.8083 - val_loss: 0.3091 - val_accuracy: 0.8727\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4673 - accuracy: 0.8091 - val_loss: 0.3224 - val_accuracy: 0.8713\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4455 - accuracy: 0.8221 - val_loss: 0.2640 - val_accuracy: 0.8968\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4286 - accuracy: 0.8295 - val_loss: 0.3083 - val_accuracy: 0.8566\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4225 - accuracy: 0.8277 - val_loss: 0.2693 - val_accuracy: 0.8901\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4169 - accuracy: 0.8294 - val_loss: 0.2816 - val_accuracy: 0.8834\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3947 - accuracy: 0.8466 - val_loss: 0.2531 - val_accuracy: 0.9088\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3726 - accuracy: 0.8544 - val_loss: 0.2413 - val_accuracy: 0.8968\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3711 - accuracy: 0.8519 - val_loss: 0.2305 - val_accuracy: 0.9182\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3443 - accuracy: 0.8660 - val_loss: 0.2096 - val_accuracy: 0.9223\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3381 - accuracy: 0.8687 - val_loss: 0.1991 - val_accuracy: 0.9316\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3372 - accuracy: 0.8693 - val_loss: 0.1970 - val_accuracy: 0.9249\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3182 - accuracy: 0.8765 - val_loss: 0.1954 - val_accuracy: 0.9236\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2995 - accuracy: 0.8873 - val_loss: 0.1777 - val_accuracy: 0.9330\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3232 - accuracy: 0.8729 - val_loss: 0.1808 - val_accuracy: 0.9370\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2740 - accuracy: 0.8976 - val_loss: 0.1504 - val_accuracy: 0.9450\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2771 - accuracy: 0.9013 - val_loss: 0.1425 - val_accuracy: 0.9491\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2624 - accuracy: 0.9016 - val_loss: 0.1859 - val_accuracy: 0.9236\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2627 - accuracy: 0.9024 - val_loss: 0.1951 - val_accuracy: 0.9115\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2591 - accuracy: 0.9051 - val_loss: 0.1509 - val_accuracy: 0.9424\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2534 - accuracy: 0.9072 - val_loss: 0.1527 - val_accuracy: 0.9437\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2536 - accuracy: 0.9051 - val_loss: 0.0372 - val_accuracy: 0.9973\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2364 - accuracy: 0.9140 - val_loss: 0.0337 - val_accuracy: 0.9973\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2240 - accuracy: 0.9168 - val_loss: 0.0425 - val_accuracy: 0.9933\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2391 - accuracy: 0.9124 - val_loss: 0.0398 - val_accuracy: 0.9933\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2300 - accuracy: 0.9177 - val_loss: 0.0502 - val_accuracy: 0.9906\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2156 - accuracy: 0.9219 - val_loss: 0.0263 - val_accuracy: 0.9973\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2155 - accuracy: 0.9259 - val_loss: 0.0335 - val_accuracy: 0.9933\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1987 - accuracy: 0.9265 - val_loss: 0.0271 - val_accuracy: 0.9973\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1815 - accuracy: 0.9343 - val_loss: 0.0338 - val_accuracy: 0.9920\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1915 - accuracy: 0.9306 - val_loss: 0.0271 - val_accuracy: 0.9946\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1879 - accuracy: 0.9347 - val_loss: 0.0421 - val_accuracy: 0.9893\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1786 - accuracy: 0.9389 - val_loss: 0.0235 - val_accuracy: 0.9946\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1858 - accuracy: 0.9377 - val_loss: 0.0363 - val_accuracy: 0.9906\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1776 - accuracy: 0.9361 - val_loss: 0.0377 - val_accuracy: 0.9933\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1660 - accuracy: 0.9420 - val_loss: 0.0374 - val_accuracy: 0.9879\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1742 - accuracy: 0.9408 - val_loss: 0.0201 - val_accuracy: 0.9987\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1652 - accuracy: 0.9402 - val_loss: 0.0371 - val_accuracy: 0.9893\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1464 - accuracy: 0.9483 - val_loss: 0.0235 - val_accuracy: 0.9946\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1546 - accuracy: 0.9444 - val_loss: 0.0237 - val_accuracy: 0.9946\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1451 - accuracy: 0.9461 - val_loss: 0.0356 - val_accuracy: 0.9866\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1567 - accuracy: 0.9456 - val_loss: 0.0329 - val_accuracy: 0.9893\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1381 - accuracy: 0.9514 - val_loss: 0.0217 - val_accuracy: 0.9933\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1432 - accuracy: 0.9529 - val_loss: 0.0252 - val_accuracy: 0.9946\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1432 - accuracy: 0.9486 - val_loss: 0.0259 - val_accuracy: 0.9920\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1477 - accuracy: 0.9493 - val_loss: 0.0250 - val_accuracy: 0.9933\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1304 - accuracy: 0.9560 - val_loss: 0.0207 - val_accuracy: 0.9933\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1210 - accuracy: 0.9583 - val_loss: 0.0160 - val_accuracy: 0.9960\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1322 - accuracy: 0.9583 - val_loss: 0.0225 - val_accuracy: 0.9946\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1258 - accuracy: 0.9569 - val_loss: 0.0337 - val_accuracy: 0.9906\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1627 - accuracy: 0.9413 - val_loss: 0.0301 - val_accuracy: 0.9946\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1873 - accuracy: 0.9391 - val_loss: 0.0108 - val_accuracy: 0.9987\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1651 - accuracy: 0.9419 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1492 - accuracy: 0.9507 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1410 - accuracy: 0.9484 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0992 - accuracy: 0.9678 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1034 - accuracy: 0.9668 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1023 - accuracy: 0.9657 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1423 - accuracy: 0.9519 - val_loss: 0.0152 - val_accuracy: 0.9960\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1270 - accuracy: 0.9553 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1144 - accuracy: 0.9638 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0987 - accuracy: 0.9674 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0926 - accuracy: 0.9703 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0939 - accuracy: 0.9686 - val_loss: 0.0066 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0870 - accuracy: 0.9709 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1117 - accuracy: 0.9629 - val_loss: 0.0108 - val_accuracy: 0.9973\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0981 - accuracy: 0.9648 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1217 - accuracy: 0.9589 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1337 - accuracy: 0.9534 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1028 - accuracy: 0.9651 - val_loss: 0.0055 - val_accuracy: 0.9973\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1028 - accuracy: 0.9644 - val_loss: 0.0055 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0883 - accuracy: 0.9677 - val_loss: 0.0059 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1038 - accuracy: 0.9654 - val_loss: 0.0070 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1214 - accuracy: 0.9611 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1156 - accuracy: 0.9607 - val_loss: 0.0097 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0977 - accuracy: 0.9684 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0997 - accuracy: 0.9683 - val_loss: 0.0060 - val_accuracy: 0.9973\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1069 - accuracy: 0.9648 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0804 - accuracy: 0.9717 - val_loss: 0.0068 - val_accuracy: 0.9973\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1062 - accuracy: 0.9650 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0883 - accuracy: 0.9698 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1005 - accuracy: 0.9663 - val_loss: 5.1202e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0894 - accuracy: 0.9695 - val_loss: 5.5343e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0990 - accuracy: 0.9674 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0973 - accuracy: 0.9686 - val_loss: 8.4773e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0994 - accuracy: 0.9659 - val_loss: 7.5036e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1217 - accuracy: 0.9613 - val_loss: 6.3536e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0831 - accuracy: 0.9733 - val_loss: 5.1914e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0736 - accuracy: 0.9765 - val_loss: 8.2753e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0814 - accuracy: 0.9730 - val_loss: 3.9100e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0818 - accuracy: 0.9717 - val_loss: 7.3982e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0940 - accuracy: 0.9702 - val_loss: 9.0786e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0721 - accuracy: 0.9760 - val_loss: 4.1382e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0796 - accuracy: 0.9739 - val_loss: 9.3674e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0702 - accuracy: 0.9774 - val_loss: 3.1817e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0798 - accuracy: 0.9753 - val_loss: 8.8689e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0763 - accuracy: 0.9754 - val_loss: 5.7887e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0735 - accuracy: 0.9763 - val_loss: 9.7807e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1103 - accuracy: 0.9650 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1021 - accuracy: 0.9660 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0827 - accuracy: 0.9738 - val_loss: 8.8861e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0824 - accuracy: 0.9738 - val_loss: 7.4304e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0706 - accuracy: 0.9751 - val_loss: 7.2517e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0735 - accuracy: 0.9736 - val_loss: 4.9273e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0947 - accuracy: 0.9681 - val_loss: 0.0030 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1220 - accuracy: 0.9566 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0748 - accuracy: 0.9736 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0668 - accuracy: 0.9800 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0756 - accuracy: 0.9733 - val_loss: 9.6218e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0919 - accuracy: 0.9695 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0808 - accuracy: 0.9712 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0784 - accuracy: 0.9739 - val_loss: 3.2733e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0704 - accuracy: 0.9771 - val_loss: 4.8933e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0673 - accuracy: 0.9791 - val_loss: 2.2783e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0707 - accuracy: 0.9765 - val_loss: 2.9233e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0737 - accuracy: 0.9747 - val_loss: 7.1706e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0692 - accuracy: 0.9796 - val_loss: 3.3108e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0746 - accuracy: 0.9747 - val_loss: 2.2517e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0810 - accuracy: 0.9741 - val_loss: 2.6802e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0696 - accuracy: 0.9775 - val_loss: 6.2970e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0722 - accuracy: 0.9741 - val_loss: 3.3907e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0767 - accuracy: 0.9748 - val_loss: 5.6810e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0698 - accuracy: 0.9790 - val_loss: 2.7429e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0678 - accuracy: 0.9768 - val_loss: 2.1754e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0849 - accuracy: 0.9736 - val_loss: 2.1306e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0637 - accuracy: 0.9793 - val_loss: 0.0025 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0551 - accuracy: 0.9839 - val_loss: 3.1671e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0621 - accuracy: 0.9799 - val_loss: 2.0303e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0686 - accuracy: 0.9762 - val_loss: 2.7173e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0714 - accuracy: 0.9781 - val_loss: 3.2349e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0624 - accuracy: 0.9791 - val_loss: 3.0174e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0716 - accuracy: 0.9766 - val_loss: 6.3037e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0523 - accuracy: 0.9844 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0701 - accuracy: 0.9779 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0711 - accuracy: 0.9762 - val_loss: 5.8478e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0594 - accuracy: 0.9812 - val_loss: 4.9698e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0503 - accuracy: 0.9851 - val_loss: 3.1493e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0534 - accuracy: 0.9830 - val_loss: 2.4918e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0682 - accuracy: 0.9785 - val_loss: 4.1406e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0565 - accuracy: 0.9815 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0469 - accuracy: 0.9860 - val_loss: 6.0255e-04 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0761 - accuracy: 0.9756 - val_loss: 1.2665e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0644 - accuracy: 0.9775 - val_loss: 1.5286e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0609 - accuracy: 0.9802 - val_loss: 1.4177e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0601 - accuracy: 0.9803 - val_loss: 1.8209e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0750 - accuracy: 0.9754 - val_loss: 1.2767e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0616 - accuracy: 0.9809 - val_loss: 2.0009e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0495 - accuracy: 0.9830 - val_loss: 1.7304e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0591 - accuracy: 0.9830 - val_loss: 2.1031e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0764 - accuracy: 0.9741 - val_loss: 2.3340e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0591 - accuracy: 0.9811 - val_loss: 3.6214e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0635 - accuracy: 0.9800 - val_loss: 3.6185e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0603 - accuracy: 0.9823 - val_loss: 4.6105e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0693 - accuracy: 0.9766 - val_loss: 2.7549e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0621 - accuracy: 0.9796 - val_loss: 2.9003e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0596 - accuracy: 0.9794 - val_loss: 3.0690e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0620 - accuracy: 0.9790 - val_loss: 1.6214e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0495 - accuracy: 0.9823 - val_loss: 4.2874e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0497 - accuracy: 0.9836 - val_loss: 2.1066e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0593 - accuracy: 0.9824 - val_loss: 1.4629e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0458 - accuracy: 0.9844 - val_loss: 2.1757e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0616 - accuracy: 0.9829 - val_loss: 5.7704e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0611 - accuracy: 0.9797 - val_loss: 2.2589e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0752 - accuracy: 0.9776 - val_loss: 4.4273e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0550 - accuracy: 0.9835 - val_loss: 1.9283e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0557 - accuracy: 0.9830 - val_loss: 1.4712e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0544 - accuracy: 0.9827 - val_loss: 1.8962e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0538 - accuracy: 0.9827 - val_loss: 2.6577e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0648 - accuracy: 0.9793 - val_loss: 2.3135e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0645 - accuracy: 0.9790 - val_loss: 2.6023e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0542 - accuracy: 0.9811 - val_loss: 6.3125e-04 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "9b617f49-7c13-4f2d-9367-57c5b5a233e1"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 6ms/step - loss: 0.0414 - accuracy: 0.9855\n",
            "Accuracy  : 0.9855149984359741\n",
            "F1_Score  : 0.9849470842992044\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "65bb3eb0-44ab-4e92-ba71-21a5028b6e80"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'#dominance\\nX_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\\nprint(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "21143cb2-3b5d-4b38-c7c3-5882f9534051"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'foldNum=0\\nmodel = get_model()\\nfor train_index, val_index in kfold.split(X_train, Y_train):\\n  foldNum = foldNum + 1\\n  print(\"Results for fold\",foldNum)\\n  x_train, x_val = X_train[train_index], X_train[val_index]\\n  y_train, y_val = Y_train[train_index], Y_train[val_index]\\n  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\\n  gc.collect() # Garbage collecter\\n  del x_train, x_val, y_train, y_val\\n  gc.collect()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "7b83cec9-d6be-43dd-8711-0e45d1449a52"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'acrc = model.evaluate(x_test, y_test)\\npred = model.predict(x_test)\\nf1scr = f1_score(y_test.argmax(1), pred.argmax(1), average=\\'macro\\')\\nc_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\\nprint(\"Accuracy  : {}\".format(acrc[1]))\\nprint(\"F1_Score  : {}\".format(f1scr))\\nc_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\\nimport seaborn as sns\\nfigure = plt.figure(figsize=(9, 9))\\nsns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\\nplt.tight_layout()\\nplt.ylabel(\\'True label\\')\\nplt.xlabel(\\'Predicted label\\')\\nplt.show()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}