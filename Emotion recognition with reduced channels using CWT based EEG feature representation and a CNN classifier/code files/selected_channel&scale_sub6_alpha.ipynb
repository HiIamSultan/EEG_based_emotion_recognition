{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub6_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "5a6a4e79-eba7-44b6-88c8-97620b119ba3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e3\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  #EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "b1d80d7c-8670-4470-b0c9-41ae70fbbc67"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(6,7):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.6\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (1165,) (2563,) (5592,)\n",
            "(9320,) (3495,) (3961,) (1864,)\n",
            "(9320,) (3029,) (932,) (5359,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "dd760951-3f55-45ca-d9cc-f4ee7630027e"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "3c42a68c-4296-4528-ce2b-bc9b7d208233"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "706"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "773b5baa-cc39-474c-c5bf-dde24c5425cd"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4387f005-cfb9-4674-804b-3ff91ff61add"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 50s 61ms/step - loss: 1.0790 - accuracy: 0.5355 - val_loss: 0.9504 - val_accuracy: 0.6367\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9691 - accuracy: 0.5974 - val_loss: 0.9205 - val_accuracy: 0.6367\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9592 - accuracy: 0.5936 - val_loss: 0.9045 - val_accuracy: 0.6367\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9556 - accuracy: 0.5902 - val_loss: 0.9000 - val_accuracy: 0.6367\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9539 - accuracy: 0.5903 - val_loss: 0.9014 - val_accuracy: 0.6367\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9342 - accuracy: 0.6009 - val_loss: 0.8915 - val_accuracy: 0.6367\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9365 - accuracy: 0.5870 - val_loss: 0.8962 - val_accuracy: 0.6367\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9289 - accuracy: 0.6002 - val_loss: 0.8847 - val_accuracy: 0.6367\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9316 - accuracy: 0.5990 - val_loss: 0.8887 - val_accuracy: 0.6367\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9298 - accuracy: 0.5869 - val_loss: 0.8976 - val_accuracy: 0.6367\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9218 - accuracy: 0.6000 - val_loss: 0.8806 - val_accuracy: 0.6367\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9231 - accuracy: 0.5895 - val_loss: 0.8780 - val_accuracy: 0.6367\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9029 - accuracy: 0.6073 - val_loss: 0.8796 - val_accuracy: 0.6367\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9255 - accuracy: 0.5851 - val_loss: 0.8721 - val_accuracy: 0.6367\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9225 - accuracy: 0.5917 - val_loss: 0.8767 - val_accuracy: 0.6367\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9151 - accuracy: 0.5990 - val_loss: 0.8726 - val_accuracy: 0.6367\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9109 - accuracy: 0.5928 - val_loss: 0.8737 - val_accuracy: 0.6367\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9103 - accuracy: 0.5976 - val_loss: 0.8749 - val_accuracy: 0.6367\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9196 - accuracy: 0.5862 - val_loss: 0.8721 - val_accuracy: 0.6354\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9018 - accuracy: 0.6009 - val_loss: 0.8653 - val_accuracy: 0.6367\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9043 - accuracy: 0.5896 - val_loss: 0.8706 - val_accuracy: 0.6367\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9034 - accuracy: 0.6001 - val_loss: 0.8677 - val_accuracy: 0.6354\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8889 - accuracy: 0.6064 - val_loss: 0.8732 - val_accuracy: 0.6367\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8965 - accuracy: 0.6058 - val_loss: 0.8676 - val_accuracy: 0.6381\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8969 - accuracy: 0.6022 - val_loss: 0.8566 - val_accuracy: 0.6501\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8963 - accuracy: 0.6031 - val_loss: 0.8563 - val_accuracy: 0.6421\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9017 - accuracy: 0.5981 - val_loss: 0.8467 - val_accuracy: 0.6408\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8957 - accuracy: 0.6072 - val_loss: 0.8604 - val_accuracy: 0.6461\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8888 - accuracy: 0.6077 - val_loss: 0.8667 - val_accuracy: 0.6354\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8844 - accuracy: 0.6088 - val_loss: 0.8431 - val_accuracy: 0.6408\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8715 - accuracy: 0.6237 - val_loss: 0.9088 - val_accuracy: 0.5791\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8698 - accuracy: 0.6244 - val_loss: 0.8741 - val_accuracy: 0.6032\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8678 - accuracy: 0.6219 - val_loss: 0.8831 - val_accuracy: 0.5898\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8571 - accuracy: 0.6222 - val_loss: 0.8703 - val_accuracy: 0.6072\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8593 - accuracy: 0.6246 - val_loss: 0.8670 - val_accuracy: 0.5938\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8531 - accuracy: 0.6264 - val_loss: 0.8666 - val_accuracy: 0.5925\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8551 - accuracy: 0.6249 - val_loss: 0.8654 - val_accuracy: 0.6032\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8403 - accuracy: 0.6340 - val_loss: 0.8516 - val_accuracy: 0.6086\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8397 - accuracy: 0.6319 - val_loss: 0.8732 - val_accuracy: 0.6032\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8316 - accuracy: 0.6382 - val_loss: 0.8454 - val_accuracy: 0.6113\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8273 - accuracy: 0.6358 - val_loss: 0.8461 - val_accuracy: 0.6072\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8258 - accuracy: 0.6468 - val_loss: 0.8606 - val_accuracy: 0.5925\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8186 - accuracy: 0.6435 - val_loss: 0.8326 - val_accuracy: 0.6153\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8109 - accuracy: 0.6489 - val_loss: 0.8376 - val_accuracy: 0.6247\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7951 - accuracy: 0.6502 - val_loss: 0.8512 - val_accuracy: 0.5979\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7890 - accuracy: 0.6598 - val_loss: 0.8569 - val_accuracy: 0.5992\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7834 - accuracy: 0.6620 - val_loss: 0.8442 - val_accuracy: 0.6072\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7799 - accuracy: 0.6569 - val_loss: 0.8182 - val_accuracy: 0.6273\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7638 - accuracy: 0.6660 - val_loss: 0.7972 - val_accuracy: 0.6340\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7635 - accuracy: 0.6651 - val_loss: 0.8077 - val_accuracy: 0.6461\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7503 - accuracy: 0.6705 - val_loss: 0.8314 - val_accuracy: 0.6059\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7418 - accuracy: 0.6712 - val_loss: 0.7908 - val_accuracy: 0.6394\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7284 - accuracy: 0.6814 - val_loss: 0.7700 - val_accuracy: 0.6501\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7166 - accuracy: 0.6848 - val_loss: 0.7624 - val_accuracy: 0.6515\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7095 - accuracy: 0.6854 - val_loss: 0.7551 - val_accuracy: 0.6635\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6813 - accuracy: 0.7021 - val_loss: 0.7399 - val_accuracy: 0.6702\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6796 - accuracy: 0.6984 - val_loss: 0.7212 - val_accuracy: 0.6676\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6588 - accuracy: 0.7086 - val_loss: 0.7062 - val_accuracy: 0.6810\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6495 - accuracy: 0.7146 - val_loss: 0.7261 - val_accuracy: 0.6662\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6400 - accuracy: 0.7165 - val_loss: 0.6923 - val_accuracy: 0.6890\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.6443 - accuracy: 0.7198 - val_loss: 0.5257 - val_accuracy: 0.7708\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6070 - accuracy: 0.7308 - val_loss: 0.5243 - val_accuracy: 0.7748\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5935 - accuracy: 0.7386 - val_loss: 0.5344 - val_accuracy: 0.7949\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5777 - accuracy: 0.7474 - val_loss: 0.4786 - val_accuracy: 0.7989\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5584 - accuracy: 0.7596 - val_loss: 0.4924 - val_accuracy: 0.8177\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5481 - accuracy: 0.7632 - val_loss: 0.4594 - val_accuracy: 0.8056\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5134 - accuracy: 0.7794 - val_loss: 0.4724 - val_accuracy: 0.8029\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4987 - accuracy: 0.7818 - val_loss: 0.4357 - val_accuracy: 0.8150\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4677 - accuracy: 0.8033 - val_loss: 0.4505 - val_accuracy: 0.7882\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4682 - accuracy: 0.8037 - val_loss: 0.5103 - val_accuracy: 0.7694\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4414 - accuracy: 0.8182 - val_loss: 0.4337 - val_accuracy: 0.8110\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4255 - accuracy: 0.8224 - val_loss: 0.4297 - val_accuracy: 0.8190\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3957 - accuracy: 0.8359 - val_loss: 0.3637 - val_accuracy: 0.8579\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3671 - accuracy: 0.8450 - val_loss: 0.3354 - val_accuracy: 0.8539\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3411 - accuracy: 0.8562 - val_loss: 0.3451 - val_accuracy: 0.8485\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3665 - accuracy: 0.8554 - val_loss: 0.3359 - val_accuracy: 0.8525\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3230 - accuracy: 0.8699 - val_loss: 0.3594 - val_accuracy: 0.8552\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3080 - accuracy: 0.8773 - val_loss: 0.3173 - val_accuracy: 0.8807\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2964 - accuracy: 0.8787 - val_loss: 0.3047 - val_accuracy: 0.8981\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2720 - accuracy: 0.8888 - val_loss: 0.2944 - val_accuracy: 0.8901\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2597 - accuracy: 0.8999 - val_loss: 0.3076 - val_accuracy: 0.8606\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2533 - accuracy: 0.9060 - val_loss: 0.2261 - val_accuracy: 0.9155\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2373 - accuracy: 0.9110 - val_loss: 0.2496 - val_accuracy: 0.9048\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2242 - accuracy: 0.9149 - val_loss: 0.2408 - val_accuracy: 0.9155\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2217 - accuracy: 0.9189 - val_loss: 0.2012 - val_accuracy: 0.9263\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1970 - accuracy: 0.9292 - val_loss: 0.2253 - val_accuracy: 0.9142\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1930 - accuracy: 0.9274 - val_loss: 0.2234 - val_accuracy: 0.9129\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1811 - accuracy: 0.9349 - val_loss: 0.1740 - val_accuracy: 0.9370\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1761 - accuracy: 0.9380 - val_loss: 0.2022 - val_accuracy: 0.9276\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1623 - accuracy: 0.9429 - val_loss: 0.1765 - val_accuracy: 0.9450\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1877 - accuracy: 0.9337 - val_loss: 0.0215 - val_accuracy: 0.9960\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1973 - accuracy: 0.9295 - val_loss: 0.0227 - val_accuracy: 0.9946\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1551 - accuracy: 0.9477 - val_loss: 0.0305 - val_accuracy: 0.9960\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1387 - accuracy: 0.9534 - val_loss: 0.0244 - val_accuracy: 0.9933\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1565 - accuracy: 0.9447 - val_loss: 0.0328 - val_accuracy: 0.9920\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1274 - accuracy: 0.9551 - val_loss: 0.0325 - val_accuracy: 0.9933\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1260 - accuracy: 0.9581 - val_loss: 0.0259 - val_accuracy: 0.9960\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1088 - accuracy: 0.9621 - val_loss: 0.0206 - val_accuracy: 0.9973\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1166 - accuracy: 0.9589 - val_loss: 0.0205 - val_accuracy: 0.9946\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1242 - accuracy: 0.9611 - val_loss: 0.0230 - val_accuracy: 0.9906\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1048 - accuracy: 0.9660 - val_loss: 0.0181 - val_accuracy: 0.9960\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0981 - accuracy: 0.9671 - val_loss: 0.0332 - val_accuracy: 0.9906\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1114 - accuracy: 0.9626 - val_loss: 0.0246 - val_accuracy: 0.9906\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0917 - accuracy: 0.9703 - val_loss: 0.0236 - val_accuracy: 0.9946\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0963 - accuracy: 0.9674 - val_loss: 0.0223 - val_accuracy: 0.9893\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0889 - accuracy: 0.9693 - val_loss: 0.0228 - val_accuracy: 0.9906\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0777 - accuracy: 0.9750 - val_loss: 0.0297 - val_accuracy: 0.9893\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0849 - accuracy: 0.9718 - val_loss: 0.0173 - val_accuracy: 0.9973\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0845 - accuracy: 0.9712 - val_loss: 0.0317 - val_accuracy: 0.9906\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0787 - accuracy: 0.9721 - val_loss: 0.0188 - val_accuracy: 0.9946\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0787 - accuracy: 0.9742 - val_loss: 0.0206 - val_accuracy: 0.9920\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0795 - accuracy: 0.9738 - val_loss: 0.0121 - val_accuracy: 0.9960\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0741 - accuracy: 0.9757 - val_loss: 0.0180 - val_accuracy: 0.9946\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0667 - accuracy: 0.9779 - val_loss: 0.0189 - val_accuracy: 0.9960\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0781 - accuracy: 0.9706 - val_loss: 0.0164 - val_accuracy: 0.9960\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0711 - accuracy: 0.9763 - val_loss: 0.0231 - val_accuracy: 0.9920\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0554 - accuracy: 0.9808 - val_loss: 0.0300 - val_accuracy: 0.9893\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0769 - accuracy: 0.9729 - val_loss: 0.0276 - val_accuracy: 0.9920\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0743 - accuracy: 0.9751 - val_loss: 0.0472 - val_accuracy: 0.9853\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0607 - accuracy: 0.9817 - val_loss: 0.0248 - val_accuracy: 0.9960\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0727 - accuracy: 0.9784 - val_loss: 4.1081e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0710 - accuracy: 0.9772 - val_loss: 6.0432e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0693 - accuracy: 0.9760 - val_loss: 0.0053 - val_accuracy: 0.9987\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0745 - accuracy: 0.9744 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0567 - accuracy: 0.9826 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0629 - accuracy: 0.9800 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0696 - accuracy: 0.9806 - val_loss: 7.7230e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0550 - accuracy: 0.9805 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0565 - accuracy: 0.9832 - val_loss: 5.6663e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0543 - accuracy: 0.9821 - val_loss: 6.2885e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0479 - accuracy: 0.9844 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0605 - accuracy: 0.9797 - val_loss: 0.0062 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0546 - accuracy: 0.9815 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0436 - accuracy: 0.9858 - val_loss: 7.1940e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0455 - accuracy: 0.9857 - val_loss: 0.0033 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0508 - accuracy: 0.9814 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0542 - accuracy: 0.9817 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0476 - accuracy: 0.9805 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0453 - accuracy: 0.9833 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0376 - accuracy: 0.9876 - val_loss: 5.7002e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0571 - accuracy: 0.9817 - val_loss: 0.0021 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0545 - accuracy: 0.9842 - val_loss: 0.0034 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0414 - accuracy: 0.9884 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0410 - accuracy: 0.9870 - val_loss: 8.5162e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0375 - accuracy: 0.9867 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0446 - accuracy: 0.9870 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0498 - accuracy: 0.9844 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0400 - accuracy: 0.9881 - val_loss: 0.0058 - val_accuracy: 0.9960\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0337 - accuracy: 0.9890 - val_loss: 9.5946e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0395 - accuracy: 0.9888 - val_loss: 0.0059 - val_accuracy: 0.9987\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0440 - accuracy: 0.9863 - val_loss: 3.1062e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0390 - accuracy: 0.9887 - val_loss: 2.2872e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0404 - accuracy: 0.9872 - val_loss: 2.2782e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0464 - accuracy: 0.9842 - val_loss: 4.4061e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0534 - accuracy: 0.9849 - val_loss: 2.2517e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0343 - accuracy: 0.9879 - val_loss: 3.1465e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0412 - accuracy: 0.9878 - val_loss: 0.0020 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0392 - accuracy: 0.9884 - val_loss: 2.8067e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0398 - accuracy: 0.9870 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0493 - accuracy: 0.9851 - val_loss: 0.0020 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0385 - accuracy: 0.9878 - val_loss: 5.2829e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0337 - accuracy: 0.9899 - val_loss: 9.6010e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0360 - accuracy: 0.9878 - val_loss: 6.9483e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0375 - accuracy: 0.9888 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0568 - accuracy: 0.9846 - val_loss: 0.0084 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0366 - accuracy: 0.9882 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0367 - accuracy: 0.9876 - val_loss: 0.0075 - val_accuracy: 0.9973\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0352 - accuracy: 0.9890 - val_loss: 4.0834e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0352 - accuracy: 0.9873 - val_loss: 4.2629e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0235 - accuracy: 0.9927 - val_loss: 0.0031 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0379 - accuracy: 0.9881 - val_loss: 0.0034 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0394 - accuracy: 0.9864 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0276 - accuracy: 0.9917 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0320 - accuracy: 0.9912 - val_loss: 0.0102 - val_accuracy: 0.9973\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0267 - accuracy: 0.9909 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0378 - accuracy: 0.9875 - val_loss: 0.0048 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0429 - accuracy: 0.9849 - val_loss: 3.8368e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0310 - accuracy: 0.9911 - val_loss: 7.9154e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0266 - accuracy: 0.9915 - val_loss: 1.5859e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0420 - accuracy: 0.9869 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 50ms/step - loss: 0.0411 - accuracy: 0.9890 - val_loss: 1.6058e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0267 - accuracy: 0.9906 - val_loss: 1.8673e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0267 - accuracy: 0.9915 - val_loss: 8.2043e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0329 - accuracy: 0.9903 - val_loss: 5.6597e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0300 - accuracy: 0.9899 - val_loss: 7.8773e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0401 - accuracy: 0.9882 - val_loss: 4.9042e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 5.0106e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0195 - accuracy: 0.9936 - val_loss: 1.9117e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0426 - accuracy: 0.9881 - val_loss: 3.5523e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0410 - accuracy: 0.9882 - val_loss: 4.7225e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0319 - accuracy: 0.9908 - val_loss: 4.3448e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0415 - accuracy: 0.9870 - val_loss: 2.6400e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0362 - accuracy: 0.9882 - val_loss: 1.0973e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0294 - accuracy: 0.9909 - val_loss: 4.2721e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0227 - accuracy: 0.9934 - val_loss: 2.5103e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0341 - accuracy: 0.9900 - val_loss: 4.9240e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0344 - accuracy: 0.9891 - val_loss: 0.0013 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0352 - accuracy: 0.9884 - val_loss: 4.1575e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0360 - accuracy: 0.9875 - val_loss: 5.7309e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0289 - accuracy: 0.9903 - val_loss: 7.3886e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0292 - accuracy: 0.9917 - val_loss: 7.1445e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0318 - accuracy: 0.9890 - val_loss: 0.0022 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0251 - accuracy: 0.9933 - val_loss: 5.5582e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0341 - accuracy: 0.9891 - val_loss: 8.1401e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0327 - accuracy: 0.9894 - val_loss: 4.3981e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 5.9051e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0279 - accuracy: 0.9915 - val_loss: 9.2005e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0223 - accuracy: 0.9937 - val_loss: 6.4009e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0238 - accuracy: 0.9927 - val_loss: 2.4553e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0196 - accuracy: 0.9931 - val_loss: 7.0360e-05 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0189 - accuracy: 0.9943 - val_loss: 1.0227e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0245 - accuracy: 0.9914 - val_loss: 1.3196e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0360 - accuracy: 0.9891 - val_loss: 6.3475e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0316 - accuracy: 0.9917 - val_loss: 7.6373e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0233 - accuracy: 0.9934 - val_loss: 2.8528e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0243 - accuracy: 0.9923 - val_loss: 3.5947e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 8.5040e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0249 - accuracy: 0.9934 - val_loss: 2.9112e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0247 - accuracy: 0.9925 - val_loss: 2.2607e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0244 - accuracy: 0.9927 - val_loss: 1.1237e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0231 - accuracy: 0.9934 - val_loss: 1.6241e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0301 - accuracy: 0.9903 - val_loss: 1.0202e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0251 - accuracy: 0.9928 - val_loss: 1.9834e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0223 - accuracy: 0.9936 - val_loss: 2.0754e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0273 - accuracy: 0.9924 - val_loss: 1.6486e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0266 - accuracy: 0.9915 - val_loss: 2.9193e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0207 - accuracy: 0.9940 - val_loss: 6.5904e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0169 - accuracy: 0.9939 - val_loss: 4.9263e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0224 - accuracy: 0.9923 - val_loss: 9.3122e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0210 - accuracy: 0.9931 - val_loss: 2.5870e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0254 - accuracy: 0.9920 - val_loss: 6.2705e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0176 - accuracy: 0.9948 - val_loss: 3.4047e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0288 - accuracy: 0.9921 - val_loss: 2.2309e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0216 - accuracy: 0.9923 - val_loss: 3.3419e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 7.8769e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 3.1209e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0254 - accuracy: 0.9930 - val_loss: 8.2812e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0226 - accuracy: 0.9923 - val_loss: 2.3102e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0208 - accuracy: 0.9937 - val_loss: 1.0631e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 6.4055e-05 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 5.6968e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0238 - accuracy: 0.9920 - val_loss: 2.1960e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0306 - accuracy: 0.9903 - val_loss: 1.4124e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0243 - accuracy: 0.9917 - val_loss: 1.5904e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0199 - accuracy: 0.9946 - val_loss: 2.4619e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0306 - accuracy: 0.9915 - val_loss: 2.5070e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0231 - accuracy: 0.9921 - val_loss: 2.3403e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0276 - accuracy: 0.9909 - val_loss: 2.9770e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0273 - accuracy: 0.9920 - val_loss: 3.7736e-06 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0147 - accuracy: 0.9949 - val_loss: 4.1446e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0261 - accuracy: 0.9928 - val_loss: 2.5161e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0294 - accuracy: 0.9920 - val_loss: 1.7118e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0213 - accuracy: 0.9928 - val_loss: 9.5318e-06 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 5.2844e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0187 - accuracy: 0.9949 - val_loss: 1.2505e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0178 - accuracy: 0.9951 - val_loss: 9.2447e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0165 - accuracy: 0.9933 - val_loss: 7.1645e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0131 - accuracy: 0.9966 - val_loss: 9.3168e-06 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0272 - accuracy: 0.9920 - val_loss: 1.7886e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0240 - accuracy: 0.9918 - val_loss: 1.9204e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0157 - accuracy: 0.9942 - val_loss: 9.3035e-06 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0276 - accuracy: 0.9905 - val_loss: 4.9899e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0210 - accuracy: 0.9934 - val_loss: 3.5115e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0212 - accuracy: 0.9934 - val_loss: 2.2727e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 2.9857e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0154 - accuracy: 0.9937 - val_loss: 3.3183e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0137 - accuracy: 0.9966 - val_loss: 0.0032 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0214 - accuracy: 0.9934 - val_loss: 5.6695e-06 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 1.1189e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0241 - accuracy: 0.9937 - val_loss: 7.8005e-05 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0187 - accuracy: 0.9946 - val_loss: 8.5779e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0283 - accuracy: 0.9912 - val_loss: 1.1842e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0164 - accuracy: 0.9942 - val_loss: 5.4144e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0235 - accuracy: 0.9925 - val_loss: 2.4389e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0212 - accuracy: 0.9945 - val_loss: 5.3472e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0327 - accuracy: 0.9908 - val_loss: 1.1045e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0238 - accuracy: 0.9921 - val_loss: 1.8014e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0204 - accuracy: 0.9937 - val_loss: 2.1955e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0208 - accuracy: 0.9927 - val_loss: 1.2983e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0208 - accuracy: 0.9942 - val_loss: 5.9911e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0217 - accuracy: 0.9951 - val_loss: 1.7786e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0194 - accuracy: 0.9949 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0197 - accuracy: 0.9934 - val_loss: 5.1231e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0292 - accuracy: 0.9918 - val_loss: 1.5448e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0182 - accuracy: 0.9949 - val_loss: 4.2682e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0141 - accuracy: 0.9963 - val_loss: 2.3378e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0196 - accuracy: 0.9930 - val_loss: 6.0246e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0118 - accuracy: 0.9955 - val_loss: 7.1913e-06 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0179 - accuracy: 0.9945 - val_loss: 3.1383e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0228 - accuracy: 0.9930 - val_loss: 2.0447e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 4.0993e-06 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0167 - accuracy: 0.9948 - val_loss: 3.0313e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0169 - accuracy: 0.9946 - val_loss: 1.0459e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0181 - accuracy: 0.9940 - val_loss: 2.5478e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 2.4214e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0169 - accuracy: 0.9948 - val_loss: 2.3859e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 1.5640e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0188 - accuracy: 0.9948 - val_loss: 1.7897e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 8.2262e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 1.3864e-04 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAnc2SJa3o9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "726fad69-af0b-4a25-e616-91b273f72c77"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 9ms/step - loss: 0.1278 - accuracy: 0.9705\n",
            "Accuracy  : 0.9704935550689697\n",
            "F1_Score  : 0.9670800726508905\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7fcxLuwZpkK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22650fbd-8aae-4b6a-9c01-4c64888454f3"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "65a79d89-1b20-4f4a-e5a5-1a94a05d535b"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 54ms/step - loss: 1.1866 - accuracy: 0.4030 - val_loss: 1.0584 - val_accuracy: 0.4290\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0670 - accuracy: 0.4299 - val_loss: 1.0425 - val_accuracy: 0.4718\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0563 - accuracy: 0.4449 - val_loss: 1.0401 - val_accuracy: 0.4705\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0535 - accuracy: 0.4456 - val_loss: 1.0363 - val_accuracy: 0.4638\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0554 - accuracy: 0.4521 - val_loss: 1.0315 - val_accuracy: 0.4638\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0477 - accuracy: 0.4550 - val_loss: 1.0316 - val_accuracy: 0.4772\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0446 - accuracy: 0.4643 - val_loss: 1.0302 - val_accuracy: 0.4692\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0414 - accuracy: 0.4650 - val_loss: 1.0268 - val_accuracy: 0.4718\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0327 - accuracy: 0.4834 - val_loss: 1.0298 - val_accuracy: 0.4678\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0358 - accuracy: 0.4807 - val_loss: 1.0245 - val_accuracy: 0.4678\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0326 - accuracy: 0.4714 - val_loss: 1.0257 - val_accuracy: 0.4718\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0332 - accuracy: 0.4673 - val_loss: 1.0273 - val_accuracy: 0.4692\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0295 - accuracy: 0.4730 - val_loss: 1.0253 - val_accuracy: 0.4665\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0321 - accuracy: 0.4730 - val_loss: 1.0269 - val_accuracy: 0.4692\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0303 - accuracy: 0.4765 - val_loss: 1.0183 - val_accuracy: 0.4705\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0229 - accuracy: 0.4811 - val_loss: 1.0235 - val_accuracy: 0.4759\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0300 - accuracy: 0.4829 - val_loss: 1.0103 - val_accuracy: 0.4772\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0186 - accuracy: 0.4776 - val_loss: 1.0125 - val_accuracy: 0.4933\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0164 - accuracy: 0.4837 - val_loss: 1.0113 - val_accuracy: 0.4786\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0187 - accuracy: 0.4880 - val_loss: 1.0137 - val_accuracy: 0.4799\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0179 - accuracy: 0.4726 - val_loss: 1.0030 - val_accuracy: 0.4893\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0083 - accuracy: 0.5019 - val_loss: 1.0007 - val_accuracy: 0.4879\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0194 - accuracy: 0.4832 - val_loss: 1.0093 - val_accuracy: 0.4893\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0106 - accuracy: 0.4880 - val_loss: 1.0127 - val_accuracy: 0.4772\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0096 - accuracy: 0.4820 - val_loss: 0.9961 - val_accuracy: 0.4853\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0067 - accuracy: 0.4905 - val_loss: 1.0086 - val_accuracy: 0.4812\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9964 - accuracy: 0.4963 - val_loss: 1.0036 - val_accuracy: 0.4839\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0064 - accuracy: 0.4872 - val_loss: 1.0107 - val_accuracy: 0.4759\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9946 - accuracy: 0.4887 - val_loss: 1.0059 - val_accuracy: 0.4786\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9893 - accuracy: 0.5024 - val_loss: 0.9856 - val_accuracy: 0.4946\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9878 - accuracy: 0.5037 - val_loss: 0.9658 - val_accuracy: 0.5067\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9961 - accuracy: 0.4943 - val_loss: 0.9754 - val_accuracy: 0.5080\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9851 - accuracy: 0.5018 - val_loss: 0.9717 - val_accuracy: 0.5094\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9752 - accuracy: 0.5097 - val_loss: 0.9580 - val_accuracy: 0.5295\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9767 - accuracy: 0.5122 - val_loss: 0.9624 - val_accuracy: 0.5335\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9738 - accuracy: 0.5155 - val_loss: 0.9529 - val_accuracy: 0.5241\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9604 - accuracy: 0.5222 - val_loss: 0.9712 - val_accuracy: 0.5214\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9644 - accuracy: 0.5103 - val_loss: 0.9675 - val_accuracy: 0.5161\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9590 - accuracy: 0.5244 - val_loss: 0.9501 - val_accuracy: 0.5201\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9501 - accuracy: 0.5329 - val_loss: 0.9419 - val_accuracy: 0.5228\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9548 - accuracy: 0.5247 - val_loss: 0.9434 - val_accuracy: 0.5322\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9431 - accuracy: 0.5353 - val_loss: 0.9304 - val_accuracy: 0.5509\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9344 - accuracy: 0.5449 - val_loss: 0.9364 - val_accuracy: 0.5349\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9302 - accuracy: 0.5420 - val_loss: 0.9295 - val_accuracy: 0.5429\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9243 - accuracy: 0.5452 - val_loss: 0.9340 - val_accuracy: 0.5268\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9166 - accuracy: 0.5569 - val_loss: 0.9137 - val_accuracy: 0.5429\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9031 - accuracy: 0.5638 - val_loss: 0.9120 - val_accuracy: 0.5509\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8988 - accuracy: 0.5678 - val_loss: 0.9033 - val_accuracy: 0.5643\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8902 - accuracy: 0.5791 - val_loss: 0.9054 - val_accuracy: 0.5603\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8854 - accuracy: 0.5776 - val_loss: 0.8768 - val_accuracy: 0.5791\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8699 - accuracy: 0.5867 - val_loss: 0.8848 - val_accuracy: 0.5630\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8598 - accuracy: 0.5943 - val_loss: 0.8800 - val_accuracy: 0.5509\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8499 - accuracy: 0.5996 - val_loss: 0.8664 - val_accuracy: 0.5764\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8246 - accuracy: 0.6145 - val_loss: 0.8594 - val_accuracy: 0.6113\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8196 - accuracy: 0.6227 - val_loss: 0.8519 - val_accuracy: 0.5845\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7955 - accuracy: 0.6292 - val_loss: 0.8148 - val_accuracy: 0.6300\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7835 - accuracy: 0.6399 - val_loss: 0.8131 - val_accuracy: 0.6408\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7635 - accuracy: 0.6519 - val_loss: 0.7994 - val_accuracy: 0.6113\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7363 - accuracy: 0.6663 - val_loss: 0.7511 - val_accuracy: 0.6649\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7243 - accuracy: 0.6768 - val_loss: 0.7150 - val_accuracy: 0.6944\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7207 - accuracy: 0.6729 - val_loss: 0.5950 - val_accuracy: 0.7386\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6853 - accuracy: 0.6982 - val_loss: 0.5530 - val_accuracy: 0.7601\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6573 - accuracy: 0.7125 - val_loss: 0.5160 - val_accuracy: 0.7909\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6420 - accuracy: 0.7203 - val_loss: 0.5247 - val_accuracy: 0.7627\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6180 - accuracy: 0.7441 - val_loss: 0.5014 - val_accuracy: 0.7788\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5622 - accuracy: 0.7647 - val_loss: 0.4768 - val_accuracy: 0.8016\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5501 - accuracy: 0.7815 - val_loss: 0.4451 - val_accuracy: 0.8445\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5062 - accuracy: 0.7928 - val_loss: 0.3829 - val_accuracy: 0.8579\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4800 - accuracy: 0.8046 - val_loss: 0.3604 - val_accuracy: 0.8592\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4457 - accuracy: 0.8288 - val_loss: 0.3630 - val_accuracy: 0.8606\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4225 - accuracy: 0.8341 - val_loss: 0.3287 - val_accuracy: 0.8834\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3624 - accuracy: 0.8650 - val_loss: 0.3009 - val_accuracy: 0.8847\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3533 - accuracy: 0.8648 - val_loss: 0.2989 - val_accuracy: 0.8834\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3320 - accuracy: 0.8729 - val_loss: 0.2297 - val_accuracy: 0.9276\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2886 - accuracy: 0.8942 - val_loss: 0.2177 - val_accuracy: 0.9155\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2794 - accuracy: 0.8978 - val_loss: 0.1932 - val_accuracy: 0.9316\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2562 - accuracy: 0.9067 - val_loss: 0.1695 - val_accuracy: 0.9437\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2420 - accuracy: 0.9115 - val_loss: 0.1819 - val_accuracy: 0.9383\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2277 - accuracy: 0.9222 - val_loss: 0.1955 - val_accuracy: 0.9290\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2077 - accuracy: 0.9285 - val_loss: 0.2054 - val_accuracy: 0.9223\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2125 - accuracy: 0.9238 - val_loss: 0.1513 - val_accuracy: 0.9424\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1751 - accuracy: 0.9414 - val_loss: 0.1473 - val_accuracy: 0.9504\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1665 - accuracy: 0.9429 - val_loss: 0.1368 - val_accuracy: 0.9531\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1766 - accuracy: 0.9387 - val_loss: 0.1114 - val_accuracy: 0.9517\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1591 - accuracy: 0.9450 - val_loss: 0.1195 - val_accuracy: 0.9584\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1453 - accuracy: 0.9511 - val_loss: 0.1052 - val_accuracy: 0.9571\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1419 - accuracy: 0.9538 - val_loss: 0.1380 - val_accuracy: 0.9370\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1344 - accuracy: 0.9547 - val_loss: 0.0900 - val_accuracy: 0.9678\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1082 - accuracy: 0.9636 - val_loss: 0.1546 - val_accuracy: 0.9424\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1144 - accuracy: 0.9599 - val_loss: 0.1059 - val_accuracy: 0.9651\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1466 - accuracy: 0.9517 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1137 - accuracy: 0.9618 - val_loss: 0.0045 - val_accuracy: 0.9987\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1206 - accuracy: 0.9614 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1124 - accuracy: 0.9626 - val_loss: 0.0093 - val_accuracy: 0.9987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1092 - accuracy: 0.9648 - val_loss: 0.0127 - val_accuracy: 0.9946\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0955 - accuracy: 0.9697 - val_loss: 0.0071 - val_accuracy: 0.9973\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1004 - accuracy: 0.9696 - val_loss: 0.0064 - val_accuracy: 0.9973\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0913 - accuracy: 0.9694 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0929 - accuracy: 0.9696 - val_loss: 0.0110 - val_accuracy: 0.9960\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0893 - accuracy: 0.9705 - val_loss: 0.0116 - val_accuracy: 0.9973\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0804 - accuracy: 0.9753 - val_loss: 0.0143 - val_accuracy: 0.9960\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0802 - accuracy: 0.9727 - val_loss: 0.0112 - val_accuracy: 0.9973\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0725 - accuracy: 0.9773 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0780 - accuracy: 0.9753 - val_loss: 0.0056 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0781 - accuracy: 0.9741 - val_loss: 0.0124 - val_accuracy: 0.9933\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0737 - accuracy: 0.9773 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0643 - accuracy: 0.9803 - val_loss: 0.0054 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0646 - accuracy: 0.9803 - val_loss: 0.0078 - val_accuracy: 0.9960\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0604 - accuracy: 0.9803 - val_loss: 0.0157 - val_accuracy: 0.9973\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0535 - accuracy: 0.9832 - val_loss: 0.0100 - val_accuracy: 0.9973\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0720 - accuracy: 0.9762 - val_loss: 0.0162 - val_accuracy: 0.9933\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0497 - accuracy: 0.9829 - val_loss: 0.0074 - val_accuracy: 0.9973\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0520 - accuracy: 0.9824 - val_loss: 0.0113 - val_accuracy: 0.9973\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0477 - accuracy: 0.9839 - val_loss: 0.0057 - val_accuracy: 0.9973\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0631 - accuracy: 0.9788 - val_loss: 0.0096 - val_accuracy: 0.9960\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0455 - accuracy: 0.9873 - val_loss: 0.0135 - val_accuracy: 0.9946\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0528 - accuracy: 0.9832 - val_loss: 0.0196 - val_accuracy: 0.9933\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0568 - accuracy: 0.9821 - val_loss: 0.0131 - val_accuracy: 0.9960\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0495 - accuracy: 0.9855 - val_loss: 0.0079 - val_accuracy: 0.9973\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0535 - accuracy: 0.9826 - val_loss: 0.0138 - val_accuracy: 0.9946\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0639 - accuracy: 0.9793 - val_loss: 2.5095e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0593 - accuracy: 0.9815 - val_loss: 5.4546e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0513 - accuracy: 0.9836 - val_loss: 1.0303e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0631 - accuracy: 0.9815 - val_loss: 3.7878e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0546 - accuracy: 0.9835 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0527 - accuracy: 0.9821 - val_loss: 1.3395e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0425 - accuracy: 0.9870 - val_loss: 3.1312e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0438 - accuracy: 0.9867 - val_loss: 1.7583e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0514 - accuracy: 0.9826 - val_loss: 0.0065 - val_accuracy: 0.9987\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0560 - accuracy: 0.9817 - val_loss: 8.0182e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0410 - accuracy: 0.9870 - val_loss: 3.8664e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0417 - accuracy: 0.9863 - val_loss: 6.1838e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0567 - accuracy: 0.9818 - val_loss: 2.5182e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0489 - accuracy: 0.9835 - val_loss: 9.7754e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0400 - accuracy: 0.9872 - val_loss: 2.2269e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0332 - accuracy: 0.9899 - val_loss: 1.6814e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0392 - accuracy: 0.9884 - val_loss: 2.6970e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0368 - accuracy: 0.9884 - val_loss: 4.9352e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0427 - accuracy: 0.9866 - val_loss: 1.9559e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0516 - accuracy: 0.9855 - val_loss: 3.5674e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0557 - accuracy: 0.9846 - val_loss: 3.8398e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0436 - accuracy: 0.9870 - val_loss: 4.7563e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0308 - accuracy: 0.9902 - val_loss: 0.0015 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0405 - accuracy: 0.9867 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0479 - accuracy: 0.9835 - val_loss: 3.7327e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0500 - accuracy: 0.9846 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0325 - accuracy: 0.9905 - val_loss: 2.3605e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0329 - accuracy: 0.9890 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0286 - accuracy: 0.9909 - val_loss: 0.0028 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0355 - accuracy: 0.9885 - val_loss: 0.0038 - val_accuracy: 0.9987\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0531 - accuracy: 0.9844 - val_loss: 2.8252e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0325 - accuracy: 0.9914 - val_loss: 1.1424e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0328 - accuracy: 0.9894 - val_loss: 9.6047e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0367 - accuracy: 0.9890 - val_loss: 7.8390e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0418 - accuracy: 0.9879 - val_loss: 8.1358e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0350 - accuracy: 0.9878 - val_loss: 1.7746e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0352 - accuracy: 0.9893 - val_loss: 9.8250e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0380 - accuracy: 0.9894 - val_loss: 1.1802e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0302 - accuracy: 0.9914 - val_loss: 6.9677e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0315 - accuracy: 0.9915 - val_loss: 8.3109e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0209 - accuracy: 0.9924 - val_loss: 5.9146e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0275 - accuracy: 0.9923 - val_loss: 4.6699e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0235 - accuracy: 0.9928 - val_loss: 1.1847e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0401 - accuracy: 0.9888 - val_loss: 3.2323e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0416 - accuracy: 0.9890 - val_loss: 9.8455e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0439 - accuracy: 0.9875 - val_loss: 8.6047e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0361 - accuracy: 0.9882 - val_loss: 4.0299e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0334 - accuracy: 0.9905 - val_loss: 7.2550e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0303 - accuracy: 0.9888 - val_loss: 0.0012 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0314 - accuracy: 0.9905 - val_loss: 1.6630e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0364 - accuracy: 0.9887 - val_loss: 0.0021 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0465 - accuracy: 0.9858 - val_loss: 3.2829e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0315 - accuracy: 0.9905 - val_loss: 2.6397e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0257 - accuracy: 0.9933 - val_loss: 7.7056e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0334 - accuracy: 0.9903 - val_loss: 1.4231e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0365 - accuracy: 0.9885 - val_loss: 0.0045 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0250 - accuracy: 0.9918 - val_loss: 2.7064e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0223 - accuracy: 0.9937 - val_loss: 2.0690e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0354 - accuracy: 0.9905 - val_loss: 5.1856e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0301 - accuracy: 0.9903 - val_loss: 1.3777e-04 - val_accuracy: 1.0000\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0297 - accuracy: 0.9914 - val_loss: 7.9396e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0219 - accuracy: 0.9934 - val_loss: 7.3632e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0220 - accuracy: 0.9939 - val_loss: 1.0906e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0461 - accuracy: 0.9867 - val_loss: 1.5694e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0320 - accuracy: 0.9899 - val_loss: 4.0800e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0262 - accuracy: 0.9917 - val_loss: 7.3644e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0264 - accuracy: 0.9927 - val_loss: 6.0602e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0269 - accuracy: 0.9914 - val_loss: 4.8371e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0420 - accuracy: 0.9869 - val_loss: 7.8287e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0241 - accuracy: 0.9925 - val_loss: 2.4311e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0309 - accuracy: 0.9905 - val_loss: 5.3894e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0191 - accuracy: 0.9939 - val_loss: 1.4015e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0302 - accuracy: 0.9906 - val_loss: 1.6815e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0253 - accuracy: 0.9918 - val_loss: 4.6119e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0261 - accuracy: 0.9918 - val_loss: 6.5675e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0375 - accuracy: 0.9885 - val_loss: 1.6103e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0267 - accuracy: 0.9928 - val_loss: 1.0537e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0276 - accuracy: 0.9912 - val_loss: 2.2535e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0271 - accuracy: 0.9915 - val_loss: 3.0085e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0256 - accuracy: 0.9923 - val_loss: 5.0635e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0219 - accuracy: 0.9931 - val_loss: 1.4765e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0259 - accuracy: 0.9917 - val_loss: 1.2109e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0306 - accuracy: 0.9911 - val_loss: 6.4603e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0271 - accuracy: 0.9906 - val_loss: 2.0142e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0290 - accuracy: 0.9900 - val_loss: 0.0022 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0406 - accuracy: 0.9884 - val_loss: 4.4030e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0256 - accuracy: 0.9927 - val_loss: 4.1326e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0132 - accuracy: 0.9948 - val_loss: 2.5116e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0211 - accuracy: 0.9936 - val_loss: 1.7691e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0217 - accuracy: 0.9946 - val_loss: 4.6945e-05 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0296 - accuracy: 0.9921 - val_loss: 2.0495e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0190 - accuracy: 0.9933 - val_loss: 3.5022e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0268 - accuracy: 0.9921 - val_loss: 1.8778e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0257 - accuracy: 0.9915 - val_loss: 5.0433e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0213 - accuracy: 0.9939 - val_loss: 5.1808e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0249 - accuracy: 0.9921 - val_loss: 7.0734e-06 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0280 - accuracy: 0.9897 - val_loss: 7.2346e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0241 - accuracy: 0.9937 - val_loss: 1.0989e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0295 - accuracy: 0.9905 - val_loss: 2.0275e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 2.0272e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0242 - accuracy: 0.9931 - val_loss: 4.1504e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0226 - accuracy: 0.9940 - val_loss: 1.0365e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0153 - accuracy: 0.9960 - val_loss: 1.1972e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 3.1886e-06 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0307 - accuracy: 0.9909 - val_loss: 6.9656e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0298 - accuracy: 0.9912 - val_loss: 1.1164e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0242 - accuracy: 0.9937 - val_loss: 2.9667e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0233 - accuracy: 0.9925 - val_loss: 3.6717e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0252 - accuracy: 0.9927 - val_loss: 2.0411e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0303 - accuracy: 0.9912 - val_loss: 7.3074e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0263 - accuracy: 0.9923 - val_loss: 2.8023e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 1.1388e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 3.4249e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0197 - accuracy: 0.9949 - val_loss: 1.8948e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0263 - accuracy: 0.9914 - val_loss: 2.6891e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0293 - accuracy: 0.9903 - val_loss: 7.9551e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0221 - accuracy: 0.9936 - val_loss: 1.5481e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0174 - accuracy: 0.9954 - val_loss: 2.9863e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0178 - accuracy: 0.9931 - val_loss: 5.1821e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0312 - accuracy: 0.9896 - val_loss: 5.8329e-04 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0208 - accuracy: 0.9928 - val_loss: 6.7982e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0299 - accuracy: 0.9918 - val_loss: 1.8226e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 5.3812e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0262 - accuracy: 0.9928 - val_loss: 1.0572e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0197 - accuracy: 0.9951 - val_loss: 3.4334e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0199 - accuracy: 0.9949 - val_loss: 1.2713e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0242 - accuracy: 0.9943 - val_loss: 1.9657e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0179 - accuracy: 0.9939 - val_loss: 2.9783e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0224 - accuracy: 0.9918 - val_loss: 5.7488e-06 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0215 - accuracy: 0.9934 - val_loss: 2.8352e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0226 - accuracy: 0.9920 - val_loss: 1.1937e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0215 - accuracy: 0.9934 - val_loss: 7.0599e-06 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0224 - accuracy: 0.9936 - val_loss: 1.9089e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0228 - accuracy: 0.9928 - val_loss: 6.2842e-06 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0209 - accuracy: 0.9936 - val_loss: 8.6086e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0285 - accuracy: 0.9915 - val_loss: 1.2126e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0207 - accuracy: 0.9943 - val_loss: 7.5635e-06 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 3.2414e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0189 - accuracy: 0.9952 - val_loss: 1.4270e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 1.0515e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0233 - accuracy: 0.9939 - val_loss: 2.5198e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0193 - accuracy: 0.9951 - val_loss: 1.6716e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0206 - accuracy: 0.9934 - val_loss: 2.9735e-06 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0157 - accuracy: 0.9957 - val_loss: 7.1025e-06 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 6.2091e-06 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 2.7824e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0194 - accuracy: 0.9936 - val_loss: 7.7989e-06 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0197 - accuracy: 0.9943 - val_loss: 1.8662e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0278 - accuracy: 0.9912 - val_loss: 9.1586e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0205 - accuracy: 0.9952 - val_loss: 3.2068e-05 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0210 - accuracy: 0.9930 - val_loss: 3.2166e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0209 - accuracy: 0.9930 - val_loss: 8.3719e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0206 - accuracy: 0.9943 - val_loss: 6.1273e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0286 - accuracy: 0.9923 - val_loss: 4.2423e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0240 - accuracy: 0.9937 - val_loss: 5.3942e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 6.4213e-06 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0260 - accuracy: 0.9934 - val_loss: 4.3964e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 4.0566e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0172 - accuracy: 0.9946 - val_loss: 4.1852e-06 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 1.9799e-06 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 2.3738e-06 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0120 - accuracy: 0.9972 - val_loss: 7.7493e-07 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0199 - accuracy: 0.9931 - val_loss: 4.8049e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0256 - accuracy: 0.9927 - val_loss: 7.0244e-06 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0202 - accuracy: 0.9952 - val_loss: 1.0975e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0165 - accuracy: 0.9954 - val_loss: 2.4445e-06 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0135 - accuracy: 0.9964 - val_loss: 1.4973e-06 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 1.1277e-06 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0169 - accuracy: 0.9942 - val_loss: 5.3308e-06 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0226 - accuracy: 0.9943 - val_loss: 1.6131e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0246 - accuracy: 0.9939 - val_loss: 1.7035e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0245 - accuracy: 0.9924 - val_loss: 1.0769e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0179 - accuracy: 0.9948 - val_loss: 6.1120e-06 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0197 - accuracy: 0.9937 - val_loss: 1.8841e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0195 - accuracy: 0.9948 - val_loss: 2.7446e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0120 - accuracy: 0.9967 - val_loss: 6.2920e-06 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0155 - accuracy: 0.9967 - val_loss: 2.5004e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 1.7222e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0113 - accuracy: 0.9976 - val_loss: 1.5578e-06 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 8.0772e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "776e251d-7e2b-4789-a33a-fc466bf99af3"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 8ms/step - loss: 0.0197 - accuracy: 0.9941\n",
            "Accuracy  : 0.9940987229347229\n",
            "F1_Score  : 0.9934590834204232\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "4f0a9f5c-2f9e-4612-8926-32d93ad74244"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'#dominance\\nX_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\\nprint(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "36e54f4f-ffde-428b-ed3f-73a5599dd2fb"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'foldNum=0\\nmodel = get_model()\\nfor train_index, val_index in kfold.split(X_train, Y_train):\\n  foldNum = foldNum + 1\\n  print(\"Results for fold\",foldNum)\\n  x_train, x_val = X_train[train_index], X_train[val_index]\\n  y_train, y_val = Y_train[train_index], Y_train[val_index]\\n  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\\n  gc.collect() # Garbage collecter\\n  del x_train, x_val, y_train, y_val\\n  gc.collect()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "7ccade3a-950b-4840-dee2-0b073b074c78"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'acrc = model.evaluate(x_test, y_test)\\npred = model.predict(x_test)\\nf1scr = f1_score(y_test.argmax(1), pred.argmax(1), average=\\'macro\\')\\nc_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\\nprint(\"Accuracy  : {}\".format(acrc[1]))\\nprint(\"F1_Score  : {}\".format(f1scr))\\nc_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\\nimport seaborn as sns\\nfigure = plt.figure(figsize=(9, 9))\\nsns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\\nplt.tight_layout()\\nplt.ylabel(\\'True label\\')\\nplt.xlabel(\\'Predicted label\\')\\nplt.show()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}