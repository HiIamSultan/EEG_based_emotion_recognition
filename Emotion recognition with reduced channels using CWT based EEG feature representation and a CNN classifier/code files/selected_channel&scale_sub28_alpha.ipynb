{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub28_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "89630689-4f17-40b3-f770-7856948a06c3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e3\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "90a4958a-5e00-4415-e369-b13e0b839651"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(28,29):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.28\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (3029,) (1398,) (4893,)\n",
            "(9320,) (4427,) (699,) (4194,)\n",
            "(9320,) (2796,) (1398,) (5126,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "6ca862f8-2271-448f-a6d2-e980a733a056"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "dc5528e0-36ca-4c6d-f5d6-16f99df10af0"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "622"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "c26bf070-d715-44a7-fd2e-1ee60b2afca8"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f452ac1a-6af2-4886-cffe-a308deaea229"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 33s 62ms/step - loss: 1.1782 - accuracy: 0.4695 - val_loss: 0.9809 - val_accuracy: 0.5308\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0176 - accuracy: 0.5319 - val_loss: 0.9728 - val_accuracy: 0.5308\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0283 - accuracy: 0.5156 - val_loss: 0.9835 - val_accuracy: 0.5308\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0127 - accuracy: 0.5282 - val_loss: 0.9758 - val_accuracy: 0.5308\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0027 - accuracy: 0.5293 - val_loss: 0.9743 - val_accuracy: 0.5295\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9985 - accuracy: 0.5243 - val_loss: 0.9586 - val_accuracy: 0.5335\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9902 - accuracy: 0.5234 - val_loss: 0.9731 - val_accuracy: 0.5322\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9865 - accuracy: 0.5320 - val_loss: 0.9647 - val_accuracy: 0.5308\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9883 - accuracy: 0.5162 - val_loss: 0.9552 - val_accuracy: 0.5335\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9875 - accuracy: 0.5239 - val_loss: 0.9656 - val_accuracy: 0.5308\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9891 - accuracy: 0.5233 - val_loss: 0.9622 - val_accuracy: 0.5322\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9754 - accuracy: 0.5278 - val_loss: 0.9626 - val_accuracy: 0.5322\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9703 - accuracy: 0.5298 - val_loss: 0.9583 - val_accuracy: 0.5308\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9667 - accuracy: 0.5365 - val_loss: 0.9489 - val_accuracy: 0.5362\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9732 - accuracy: 0.5324 - val_loss: 0.9551 - val_accuracy: 0.5349\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9695 - accuracy: 0.5308 - val_loss: 0.9504 - val_accuracy: 0.5322\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9584 - accuracy: 0.5330 - val_loss: 0.9548 - val_accuracy: 0.5362\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9657 - accuracy: 0.5255 - val_loss: 0.9466 - val_accuracy: 0.5335\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9576 - accuracy: 0.5420 - val_loss: 0.9527 - val_accuracy: 0.5349\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9665 - accuracy: 0.5220 - val_loss: 0.9458 - val_accuracy: 0.5349\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9671 - accuracy: 0.5226 - val_loss: 0.9457 - val_accuracy: 0.5335\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9649 - accuracy: 0.5305 - val_loss: 0.9438 - val_accuracy: 0.5349\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9639 - accuracy: 0.5295 - val_loss: 0.9522 - val_accuracy: 0.5322\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9623 - accuracy: 0.5284 - val_loss: 0.9434 - val_accuracy: 0.5416\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9525 - accuracy: 0.5487 - val_loss: 0.9525 - val_accuracy: 0.5335\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9687 - accuracy: 0.5263 - val_loss: 0.9384 - val_accuracy: 0.5349\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9419 - accuracy: 0.5395 - val_loss: 0.9491 - val_accuracy: 0.5335\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9630 - accuracy: 0.5196 - val_loss: 0.9433 - val_accuracy: 0.5362\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9560 - accuracy: 0.5349 - val_loss: 0.9401 - val_accuracy: 0.5349\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9670 - accuracy: 0.5279 - val_loss: 0.9494 - val_accuracy: 0.5429\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.9528 - accuracy: 0.5347 - val_loss: 0.9471 - val_accuracy: 0.5456\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9545 - accuracy: 0.5328 - val_loss: 0.9408 - val_accuracy: 0.5536\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9521 - accuracy: 0.5347 - val_loss: 0.9416 - val_accuracy: 0.5496\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9538 - accuracy: 0.5332 - val_loss: 0.9393 - val_accuracy: 0.5483\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9547 - accuracy: 0.5346 - val_loss: 0.9346 - val_accuracy: 0.5416\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9515 - accuracy: 0.5346 - val_loss: 0.9375 - val_accuracy: 0.5442\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9518 - accuracy: 0.5380 - val_loss: 0.9500 - val_accuracy: 0.5456\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9483 - accuracy: 0.5398 - val_loss: 0.9495 - val_accuracy: 0.5456\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9511 - accuracy: 0.5383 - val_loss: 0.9346 - val_accuracy: 0.5442\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9475 - accuracy: 0.5425 - val_loss: 0.9554 - val_accuracy: 0.5416\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9456 - accuracy: 0.5428 - val_loss: 0.9380 - val_accuracy: 0.5456\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9421 - accuracy: 0.5492 - val_loss: 0.9370 - val_accuracy: 0.5456\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9402 - accuracy: 0.5469 - val_loss: 0.9297 - val_accuracy: 0.5523\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.9434 - accuracy: 0.5449 - val_loss: 0.9314 - val_accuracy: 0.5442\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9449 - accuracy: 0.5422 - val_loss: 0.9481 - val_accuracy: 0.5416\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9428 - accuracy: 0.5498 - val_loss: 0.9397 - val_accuracy: 0.5429\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9339 - accuracy: 0.5539 - val_loss: 0.9265 - val_accuracy: 0.5509\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9344 - accuracy: 0.5539 - val_loss: 0.9351 - val_accuracy: 0.5550\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9340 - accuracy: 0.5525 - val_loss: 0.9191 - val_accuracy: 0.5603\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9299 - accuracy: 0.5516 - val_loss: 0.9301 - val_accuracy: 0.5576\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9277 - accuracy: 0.5608 - val_loss: 0.9301 - val_accuracy: 0.5442\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9302 - accuracy: 0.5535 - val_loss: 0.9217 - val_accuracy: 0.5617\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9197 - accuracy: 0.5613 - val_loss: 0.9171 - val_accuracy: 0.5576\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9250 - accuracy: 0.5575 - val_loss: 0.9116 - val_accuracy: 0.5643\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9247 - accuracy: 0.5586 - val_loss: 0.9097 - val_accuracy: 0.5617\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9189 - accuracy: 0.5635 - val_loss: 0.9285 - val_accuracy: 0.5603\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.9201 - accuracy: 0.5630 - val_loss: 0.9048 - val_accuracy: 0.5684\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9150 - accuracy: 0.5641 - val_loss: 0.9131 - val_accuracy: 0.5603\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9126 - accuracy: 0.5642 - val_loss: 0.9127 - val_accuracy: 0.5630\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9154 - accuracy: 0.5593 - val_loss: 0.9093 - val_accuracy: 0.5724\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.9055 - accuracy: 0.5689 - val_loss: 0.9318 - val_accuracy: 0.5469\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9133 - accuracy: 0.5703 - val_loss: 0.9229 - val_accuracy: 0.5563\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9009 - accuracy: 0.5674 - val_loss: 0.9243 - val_accuracy: 0.5509\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9037 - accuracy: 0.5708 - val_loss: 0.9131 - val_accuracy: 0.5603\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8978 - accuracy: 0.5726 - val_loss: 0.9264 - val_accuracy: 0.5456\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8944 - accuracy: 0.5742 - val_loss: 0.9206 - val_accuracy: 0.5483\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8838 - accuracy: 0.5811 - val_loss: 0.9255 - val_accuracy: 0.5483\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8816 - accuracy: 0.5818 - val_loss: 0.9213 - val_accuracy: 0.5523\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8913 - accuracy: 0.5748 - val_loss: 0.9519 - val_accuracy: 0.5563\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8850 - accuracy: 0.5769 - val_loss: 0.9067 - val_accuracy: 0.5684\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8860 - accuracy: 0.5760 - val_loss: 0.9209 - val_accuracy: 0.5402\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8842 - accuracy: 0.5773 - val_loss: 0.9024 - val_accuracy: 0.5630\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8725 - accuracy: 0.5818 - val_loss: 0.9093 - val_accuracy: 0.5576\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8751 - accuracy: 0.5818 - val_loss: 0.9019 - val_accuracy: 0.5697\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.8665 - accuracy: 0.5960 - val_loss: 0.8965 - val_accuracy: 0.5737\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8655 - accuracy: 0.5872 - val_loss: 0.8971 - val_accuracy: 0.5684\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8568 - accuracy: 0.5957 - val_loss: 0.9190 - val_accuracy: 0.5536\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8530 - accuracy: 0.5946 - val_loss: 0.9188 - val_accuracy: 0.5710\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8556 - accuracy: 0.5969 - val_loss: 0.8935 - val_accuracy: 0.5684\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8449 - accuracy: 0.6033 - val_loss: 0.9022 - val_accuracy: 0.5603\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8496 - accuracy: 0.6000 - val_loss: 0.8929 - val_accuracy: 0.5724\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8415 - accuracy: 0.6039 - val_loss: 0.8796 - val_accuracy: 0.5751\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8329 - accuracy: 0.6092 - val_loss: 0.8787 - val_accuracy: 0.5751\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8398 - accuracy: 0.6055 - val_loss: 0.8799 - val_accuracy: 0.5871\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8327 - accuracy: 0.6100 - val_loss: 0.8650 - val_accuracy: 0.5764\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8146 - accuracy: 0.6192 - val_loss: 0.8577 - val_accuracy: 0.5912\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8063 - accuracy: 0.6212 - val_loss: 0.8504 - val_accuracy: 0.5777\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8067 - accuracy: 0.6258 - val_loss: 0.8606 - val_accuracy: 0.5898\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7969 - accuracy: 0.6280 - val_loss: 0.8275 - val_accuracy: 0.5965\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7931 - accuracy: 0.6252 - val_loss: 0.8476 - val_accuracy: 0.5925\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.7860 - accuracy: 0.6338 - val_loss: 0.7820 - val_accuracy: 0.6314\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7875 - accuracy: 0.6361 - val_loss: 0.7547 - val_accuracy: 0.6354\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7739 - accuracy: 0.6399 - val_loss: 0.7530 - val_accuracy: 0.6354\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7771 - accuracy: 0.6386 - val_loss: 0.7552 - val_accuracy: 0.6139\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7549 - accuracy: 0.6501 - val_loss: 0.7523 - val_accuracy: 0.6501\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7493 - accuracy: 0.6514 - val_loss: 0.7408 - val_accuracy: 0.6528\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7395 - accuracy: 0.6554 - val_loss: 0.7566 - val_accuracy: 0.6260\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7364 - accuracy: 0.6589 - val_loss: 0.7346 - val_accuracy: 0.6300\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7170 - accuracy: 0.6702 - val_loss: 0.6899 - val_accuracy: 0.6729\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7250 - accuracy: 0.6639 - val_loss: 0.7046 - val_accuracy: 0.6622\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7099 - accuracy: 0.6799 - val_loss: 0.7133 - val_accuracy: 0.6542\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.6874 - accuracy: 0.6878 - val_loss: 0.6924 - val_accuracy: 0.6662\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6826 - accuracy: 0.6911 - val_loss: 0.6583 - val_accuracy: 0.6917\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.6703 - accuracy: 0.6969 - val_loss: 0.6664 - val_accuracy: 0.6930\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.6630 - accuracy: 0.6921 - val_loss: 0.6747 - val_accuracy: 0.6930\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.6519 - accuracy: 0.7046 - val_loss: 0.6410 - val_accuracy: 0.7038\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.6311 - accuracy: 0.7146 - val_loss: 0.6792 - val_accuracy: 0.6823\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6489 - accuracy: 0.7058 - val_loss: 0.6432 - val_accuracy: 0.7051\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.6306 - accuracy: 0.7152 - val_loss: 0.6064 - val_accuracy: 0.7373\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.6082 - accuracy: 0.7200 - val_loss: 0.6147 - val_accuracy: 0.7239\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.5907 - accuracy: 0.7358 - val_loss: 0.5996 - val_accuracy: 0.7185\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5766 - accuracy: 0.7390 - val_loss: 0.6248 - val_accuracy: 0.7198\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5591 - accuracy: 0.7504 - val_loss: 0.5840 - val_accuracy: 0.7426\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.5539 - accuracy: 0.7554 - val_loss: 0.6222 - val_accuracy: 0.7145\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5442 - accuracy: 0.7611 - val_loss: 0.5856 - val_accuracy: 0.7480\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5135 - accuracy: 0.7821 - val_loss: 0.5374 - val_accuracy: 0.7507\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.4999 - accuracy: 0.7830 - val_loss: 0.5293 - val_accuracy: 0.7775\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.5017 - accuracy: 0.7863 - val_loss: 0.5071 - val_accuracy: 0.7882\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4885 - accuracy: 0.7946 - val_loss: 0.5547 - val_accuracy: 0.7601\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4682 - accuracy: 0.7984 - val_loss: 0.5648 - val_accuracy: 0.7721\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.4772 - accuracy: 0.8040 - val_loss: 0.3557 - val_accuracy: 0.8592\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4553 - accuracy: 0.8131 - val_loss: 0.3115 - val_accuracy: 0.8713\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4589 - accuracy: 0.8131 - val_loss: 0.2830 - val_accuracy: 0.8820\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4104 - accuracy: 0.8335 - val_loss: 0.2766 - val_accuracy: 0.8861\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.4070 - accuracy: 0.8361 - val_loss: 0.2590 - val_accuracy: 0.9008\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.3729 - accuracy: 0.8531 - val_loss: 0.2855 - val_accuracy: 0.8861\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3812 - accuracy: 0.8472 - val_loss: 0.2567 - val_accuracy: 0.8874\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3303 - accuracy: 0.8689 - val_loss: 0.2444 - val_accuracy: 0.9102\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.3522 - accuracy: 0.8617 - val_loss: 0.2693 - val_accuracy: 0.9008\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3293 - accuracy: 0.8775 - val_loss: 0.2372 - val_accuracy: 0.9035\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3346 - accuracy: 0.8741 - val_loss: 0.2518 - val_accuracy: 0.9062\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2907 - accuracy: 0.8896 - val_loss: 0.1992 - val_accuracy: 0.9236\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2832 - accuracy: 0.8930 - val_loss: 0.2414 - val_accuracy: 0.8954\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2763 - accuracy: 0.8988 - val_loss: 0.1485 - val_accuracy: 0.9410\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2475 - accuracy: 0.9048 - val_loss: 0.1576 - val_accuracy: 0.9450\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2424 - accuracy: 0.9094 - val_loss: 0.1836 - val_accuracy: 0.9290\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2465 - accuracy: 0.9130 - val_loss: 0.1843 - val_accuracy: 0.9397\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2306 - accuracy: 0.9177 - val_loss: 0.1442 - val_accuracy: 0.9450\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2102 - accuracy: 0.9259 - val_loss: 0.1399 - val_accuracy: 0.9504\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2212 - accuracy: 0.9215 - val_loss: 0.1290 - val_accuracy: 0.9517\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1902 - accuracy: 0.9294 - val_loss: 0.1078 - val_accuracy: 0.9638\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1902 - accuracy: 0.9359 - val_loss: 0.1734 - val_accuracy: 0.9437\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1967 - accuracy: 0.9314 - val_loss: 0.1018 - val_accuracy: 0.9625\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1662 - accuracy: 0.9402 - val_loss: 0.1049 - val_accuracy: 0.9638\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1668 - accuracy: 0.9410 - val_loss: 0.1237 - val_accuracy: 0.9531\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1702 - accuracy: 0.9405 - val_loss: 0.1045 - val_accuracy: 0.9665\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1568 - accuracy: 0.9440 - val_loss: 0.1129 - val_accuracy: 0.9651\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1529 - accuracy: 0.9469 - val_loss: 0.0980 - val_accuracy: 0.9678\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1436 - accuracy: 0.9513 - val_loss: 0.1318 - val_accuracy: 0.9584\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1455 - accuracy: 0.9475 - val_loss: 0.1039 - val_accuracy: 0.9598\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.1826 - accuracy: 0.9373 - val_loss: 0.0132 - val_accuracy: 0.9987\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1525 - accuracy: 0.9461 - val_loss: 0.0118 - val_accuracy: 0.9987\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1458 - accuracy: 0.9487 - val_loss: 0.0117 - val_accuracy: 0.9973\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1421 - accuracy: 0.9511 - val_loss: 0.0238 - val_accuracy: 0.9960\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1569 - accuracy: 0.9466 - val_loss: 0.0180 - val_accuracy: 0.9946\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1305 - accuracy: 0.9572 - val_loss: 0.0142 - val_accuracy: 0.9973\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1351 - accuracy: 0.9548 - val_loss: 0.0244 - val_accuracy: 0.9920\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1102 - accuracy: 0.9601 - val_loss: 0.0162 - val_accuracy: 0.9960\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1330 - accuracy: 0.9551 - val_loss: 0.0106 - val_accuracy: 0.9960\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1060 - accuracy: 0.9635 - val_loss: 0.0101 - val_accuracy: 0.9973\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1049 - accuracy: 0.9633 - val_loss: 0.0114 - val_accuracy: 0.9973\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1037 - accuracy: 0.9644 - val_loss: 0.0135 - val_accuracy: 0.9960\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0997 - accuracy: 0.9693 - val_loss: 0.0100 - val_accuracy: 0.9973\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0966 - accuracy: 0.9686 - val_loss: 0.0085 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0945 - accuracy: 0.9689 - val_loss: 0.0097 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0905 - accuracy: 0.9726 - val_loss: 0.0090 - val_accuracy: 0.9973\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0990 - accuracy: 0.9675 - val_loss: 0.0129 - val_accuracy: 0.9960\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0993 - accuracy: 0.9645 - val_loss: 0.0149 - val_accuracy: 0.9960\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0848 - accuracy: 0.9748 - val_loss: 0.0163 - val_accuracy: 0.9946\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0942 - accuracy: 0.9678 - val_loss: 0.0110 - val_accuracy: 0.9960\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0864 - accuracy: 0.9708 - val_loss: 0.0079 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0784 - accuracy: 0.9759 - val_loss: 0.0199 - val_accuracy: 0.9933\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0969 - accuracy: 0.9703 - val_loss: 0.0085 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0793 - accuracy: 0.9723 - val_loss: 0.0122 - val_accuracy: 0.9960\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0958 - accuracy: 0.9708 - val_loss: 0.0109 - val_accuracy: 0.9973\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0941 - accuracy: 0.9659 - val_loss: 0.0158 - val_accuracy: 0.9960\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0716 - accuracy: 0.9763 - val_loss: 0.0095 - val_accuracy: 0.9960\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0615 - accuracy: 0.9809 - val_loss: 0.0075 - val_accuracy: 0.9973\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0716 - accuracy: 0.9754 - val_loss: 0.0101 - val_accuracy: 0.9960\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0744 - accuracy: 0.9770 - val_loss: 0.0149 - val_accuracy: 0.9933\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 49ms/step - loss: 0.0865 - accuracy: 0.9712 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0750 - accuracy: 0.9747 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0733 - accuracy: 0.9772 - val_loss: 0.0021 - val_accuracy: 0.9987\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0745 - accuracy: 0.9774 - val_loss: 0.0018 - val_accuracy: 0.9987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0764 - accuracy: 0.9748 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0764 - accuracy: 0.9757 - val_loss: 0.0037 - val_accuracy: 0.9987\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0663 - accuracy: 0.9771 - val_loss: 0.0023 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0581 - accuracy: 0.9815 - val_loss: 0.0026 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0763 - accuracy: 0.9751 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0705 - accuracy: 0.9781 - val_loss: 0.0056 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0688 - accuracy: 0.9781 - val_loss: 0.0030 - val_accuracy: 0.9987\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0663 - accuracy: 0.9803 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0726 - accuracy: 0.9797 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0489 - accuracy: 0.9817 - val_loss: 0.0026 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0718 - accuracy: 0.9785 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0601 - accuracy: 0.9815 - val_loss: 6.8012e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0544 - accuracy: 0.9818 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0603 - accuracy: 0.9809 - val_loss: 0.0024 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0553 - accuracy: 0.9827 - val_loss: 9.7662e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0585 - accuracy: 0.9808 - val_loss: 0.0063 - val_accuracy: 0.9973\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0505 - accuracy: 0.9829 - val_loss: 0.0030 - val_accuracy: 0.9973\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0553 - accuracy: 0.9821 - val_loss: 0.0019 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0558 - accuracy: 0.9814 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0503 - accuracy: 0.9836 - val_loss: 0.0028 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0426 - accuracy: 0.9881 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0600 - accuracy: 0.9824 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0452 - accuracy: 0.9854 - val_loss: 9.1992e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0661 - accuracy: 0.9799 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0493 - accuracy: 0.9842 - val_loss: 0.0027 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0456 - accuracy: 0.9850 - val_loss: 0.0016 - val_accuracy: 0.9987\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0462 - accuracy: 0.9857 - val_loss: 1.1905e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0760 - accuracy: 0.9774 - val_loss: 4.8609e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0510 - accuracy: 0.9847 - val_loss: 2.2460e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0414 - accuracy: 0.9869 - val_loss: 2.7409e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0488 - accuracy: 0.9835 - val_loss: 3.7804e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0485 - accuracy: 0.9855 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0511 - accuracy: 0.9833 - val_loss: 3.6092e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0440 - accuracy: 0.9850 - val_loss: 1.7034e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0541 - accuracy: 0.9838 - val_loss: 3.0922e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0446 - accuracy: 0.9848 - val_loss: 2.2965e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0502 - accuracy: 0.9852 - val_loss: 7.5927e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0461 - accuracy: 0.9854 - val_loss: 4.0080e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0578 - accuracy: 0.9821 - val_loss: 6.1487e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0489 - accuracy: 0.9869 - val_loss: 2.7825e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0465 - accuracy: 0.9844 - val_loss: 8.3172e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0506 - accuracy: 0.9829 - val_loss: 2.1197e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0507 - accuracy: 0.9841 - val_loss: 2.7890e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0437 - accuracy: 0.9861 - val_loss: 2.5752e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0472 - accuracy: 0.9863 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0443 - accuracy: 0.9867 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0395 - accuracy: 0.9864 - val_loss: 2.9290e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0373 - accuracy: 0.9887 - val_loss: 4.7120e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0503 - accuracy: 0.9836 - val_loss: 5.2305e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0414 - accuracy: 0.9872 - val_loss: 4.9154e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0515 - accuracy: 0.9826 - val_loss: 3.6312e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0558 - accuracy: 0.9824 - val_loss: 4.2878e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0356 - accuracy: 0.9896 - val_loss: 0.0013 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0412 - accuracy: 0.9875 - val_loss: 5.6703e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0461 - accuracy: 0.9860 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0446 - accuracy: 0.9863 - val_loss: 5.1680e-04 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0507 - accuracy: 0.9844 - val_loss: 2.5207e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0345 - accuracy: 0.9893 - val_loss: 4.1691e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0379 - accuracy: 0.9881 - val_loss: 5.0063e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0473 - accuracy: 0.9850 - val_loss: 6.4961e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0366 - accuracy: 0.9879 - val_loss: 3.1805e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0410 - accuracy: 0.9885 - val_loss: 1.0402e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0364 - accuracy: 0.9887 - val_loss: 5.3506e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0359 - accuracy: 0.9885 - val_loss: 1.3843e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0535 - accuracy: 0.9821 - val_loss: 4.9994e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0360 - accuracy: 0.9878 - val_loss: 4.6775e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0420 - accuracy: 0.9869 - val_loss: 2.0386e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0364 - accuracy: 0.9888 - val_loss: 6.6044e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0403 - accuracy: 0.9881 - val_loss: 6.2319e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0358 - accuracy: 0.9897 - val_loss: 1.5012e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0314 - accuracy: 0.9927 - val_loss: 2.7206e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0351 - accuracy: 0.9893 - val_loss: 4.5857e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0436 - accuracy: 0.9850 - val_loss: 1.4150e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0362 - accuracy: 0.9891 - val_loss: 5.5919e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0329 - accuracy: 0.9891 - val_loss: 1.8229e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0290 - accuracy: 0.9900 - val_loss: 2.3164e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0378 - accuracy: 0.9876 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0387 - accuracy: 0.9863 - val_loss: 1.0820e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0313 - accuracy: 0.9912 - val_loss: 5.1973e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0304 - accuracy: 0.9917 - val_loss: 4.5595e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0358 - accuracy: 0.9893 - val_loss: 2.6650e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0286 - accuracy: 0.9924 - val_loss: 8.2314e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0331 - accuracy: 0.9887 - val_loss: 0.0015 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0427 - accuracy: 0.9873 - val_loss: 0.0021 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0396 - accuracy: 0.9887 - val_loss: 9.7524e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0344 - accuracy: 0.9887 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0300 - accuracy: 0.9908 - val_loss: 3.2397e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0331 - accuracy: 0.9890 - val_loss: 2.2066e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0362 - accuracy: 0.9887 - val_loss: 3.2554e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0346 - accuracy: 0.9897 - val_loss: 9.6808e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0256 - accuracy: 0.9930 - val_loss: 2.3979e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0347 - accuracy: 0.9888 - val_loss: 1.8417e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0396 - accuracy: 0.9873 - val_loss: 7.2903e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0279 - accuracy: 0.9914 - val_loss: 3.5451e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0403 - accuracy: 0.9875 - val_loss: 2.5490e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0397 - accuracy: 0.9884 - val_loss: 1.1821e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0320 - accuracy: 0.9897 - val_loss: 7.4626e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0304 - accuracy: 0.9908 - val_loss: 2.1751e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0398 - accuracy: 0.9878 - val_loss: 5.7313e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0239 - accuracy: 0.9921 - val_loss: 1.9478e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0456 - accuracy: 0.9872 - val_loss: 0.0033 - val_accuracy: 0.9973\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0405 - accuracy: 0.9863 - val_loss: 2.1150e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0290 - accuracy: 0.9915 - val_loss: 6.5102e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0417 - accuracy: 0.9869 - val_loss: 1.7599e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0310 - accuracy: 0.9912 - val_loss: 7.7431e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0329 - accuracy: 0.9909 - val_loss: 1.1087e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0286 - accuracy: 0.9908 - val_loss: 4.7983e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0323 - accuracy: 0.9894 - val_loss: 8.8591e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0377 - accuracy: 0.9888 - val_loss: 8.7778e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0294 - accuracy: 0.9891 - val_loss: 4.7871e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0285 - accuracy: 0.9927 - val_loss: 8.4685e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0313 - accuracy: 0.9909 - val_loss: 3.5429e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0278 - accuracy: 0.9905 - val_loss: 1.7952e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0265 - accuracy: 0.9897 - val_loss: 3.3652e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0327 - accuracy: 0.9891 - val_loss: 6.1041e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0344 - accuracy: 0.9893 - val_loss: 6.9096e-04 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "id": "CAnc2SJa3o9f",
        "outputId": "9e99065f-3f16-4e69-99df-dc45b35186a8"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 8ms/step - loss: 0.0432 - accuracy: 0.9855\n",
            "Accuracy  : 0.9855149984359741\n",
            "F1_Score  : 0.984534833353655\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7fcxLuwZpkK",
        "outputId": "664bb875-002a-40cb-bcf8-539347814591"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "229d2085-97f3-4763-8067-80090ca72670"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 5s 55ms/step - loss: 1.0436 - accuracy: 0.4518 - val_loss: 0.8711 - val_accuracy: 0.5094\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9419 - accuracy: 0.4860 - val_loss: 0.8744 - val_accuracy: 0.4464\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9330 - accuracy: 0.4657 - val_loss: 0.8683 - val_accuracy: 0.4464\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9270 - accuracy: 0.4711 - val_loss: 0.8656 - val_accuracy: 0.5214\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9272 - accuracy: 0.4733 - val_loss: 0.8632 - val_accuracy: 0.4665\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9356 - accuracy: 0.4838 - val_loss: 0.8626 - val_accuracy: 0.5174\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9182 - accuracy: 0.4902 - val_loss: 0.8596 - val_accuracy: 0.5174\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9292 - accuracy: 0.4797 - val_loss: 0.8581 - val_accuracy: 0.5214\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9228 - accuracy: 0.4760 - val_loss: 0.8585 - val_accuracy: 0.5188\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9109 - accuracy: 0.4857 - val_loss: 0.8678 - val_accuracy: 0.5067\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9144 - accuracy: 0.4817 - val_loss: 0.8652 - val_accuracy: 0.5201\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9078 - accuracy: 0.4891 - val_loss: 0.8603 - val_accuracy: 0.5161\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9029 - accuracy: 0.4952 - val_loss: 0.8703 - val_accuracy: 0.4424\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9093 - accuracy: 0.4666 - val_loss: 0.8656 - val_accuracy: 0.5147\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8961 - accuracy: 0.4988 - val_loss: 0.8758 - val_accuracy: 0.5161\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8955 - accuracy: 0.4924 - val_loss: 0.8546 - val_accuracy: 0.5188\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8904 - accuracy: 0.4814 - val_loss: 0.8520 - val_accuracy: 0.5174\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8982 - accuracy: 0.4881 - val_loss: 0.8640 - val_accuracy: 0.5080\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9035 - accuracy: 0.4698 - val_loss: 0.8613 - val_accuracy: 0.5121\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9013 - accuracy: 0.4843 - val_loss: 0.8540 - val_accuracy: 0.5201\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9087 - accuracy: 0.4819 - val_loss: 0.8612 - val_accuracy: 0.5201\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9019 - accuracy: 0.4781 - val_loss: 0.8467 - val_accuracy: 0.5214\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8851 - accuracy: 0.4924 - val_loss: 0.8436 - val_accuracy: 0.5214\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8926 - accuracy: 0.4900 - val_loss: 0.8564 - val_accuracy: 0.5228\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9008 - accuracy: 0.4821 - val_loss: 0.8432 - val_accuracy: 0.5147\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8858 - accuracy: 0.5035 - val_loss: 0.8515 - val_accuracy: 0.5295\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8953 - accuracy: 0.4887 - val_loss: 0.8466 - val_accuracy: 0.5241\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8749 - accuracy: 0.5021 - val_loss: 0.8495 - val_accuracy: 0.5107\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8829 - accuracy: 0.4969 - val_loss: 0.8528 - val_accuracy: 0.5013\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8828 - accuracy: 0.4856 - val_loss: 0.8375 - val_accuracy: 0.5335\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.8734 - accuracy: 0.5073 - val_loss: 0.8803 - val_accuracy: 0.4853\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8694 - accuracy: 0.5118 - val_loss: 0.8632 - val_accuracy: 0.4920\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8662 - accuracy: 0.5142 - val_loss: 0.8638 - val_accuracy: 0.4946\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8684 - accuracy: 0.5134 - val_loss: 0.8531 - val_accuracy: 0.5054\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8590 - accuracy: 0.5171 - val_loss: 0.8447 - val_accuracy: 0.5080\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8605 - accuracy: 0.5268 - val_loss: 0.8499 - val_accuracy: 0.5121\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8520 - accuracy: 0.5314 - val_loss: 0.8467 - val_accuracy: 0.5147\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8513 - accuracy: 0.5206 - val_loss: 0.8397 - val_accuracy: 0.5134\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8527 - accuracy: 0.5271 - val_loss: 0.8336 - val_accuracy: 0.5201\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8492 - accuracy: 0.5292 - val_loss: 0.8312 - val_accuracy: 0.5201\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8390 - accuracy: 0.5459 - val_loss: 0.8303 - val_accuracy: 0.5282\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8318 - accuracy: 0.5446 - val_loss: 0.8448 - val_accuracy: 0.5268\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8409 - accuracy: 0.5411 - val_loss: 0.8213 - val_accuracy: 0.5308\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8322 - accuracy: 0.5508 - val_loss: 0.8127 - val_accuracy: 0.5469\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8359 - accuracy: 0.5507 - val_loss: 0.8291 - val_accuracy: 0.5737\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8291 - accuracy: 0.5550 - val_loss: 0.8208 - val_accuracy: 0.5416\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8245 - accuracy: 0.5480 - val_loss: 0.8082 - val_accuracy: 0.5536\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8223 - accuracy: 0.5569 - val_loss: 0.8155 - val_accuracy: 0.5389\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8248 - accuracy: 0.5645 - val_loss: 0.8084 - val_accuracy: 0.5509\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8179 - accuracy: 0.5537 - val_loss: 0.8089 - val_accuracy: 0.5657\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8081 - accuracy: 0.5741 - val_loss: 0.8009 - val_accuracy: 0.5268\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8071 - accuracy: 0.5620 - val_loss: 0.8399 - val_accuracy: 0.5134\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8086 - accuracy: 0.5662 - val_loss: 0.7997 - val_accuracy: 0.5643\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7925 - accuracy: 0.5772 - val_loss: 0.8255 - val_accuracy: 0.5483\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7856 - accuracy: 0.5766 - val_loss: 0.7766 - val_accuracy: 0.5912\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.7898 - accuracy: 0.5765 - val_loss: 0.7843 - val_accuracy: 0.5657\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7916 - accuracy: 0.5747 - val_loss: 0.7728 - val_accuracy: 0.5871\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7810 - accuracy: 0.5887 - val_loss: 0.7892 - val_accuracy: 0.5845\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7662 - accuracy: 0.5870 - val_loss: 0.7695 - val_accuracy: 0.5845\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7602 - accuracy: 0.5973 - val_loss: 0.7604 - val_accuracy: 0.5791\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.7620 - accuracy: 0.5902 - val_loss: 0.7437 - val_accuracy: 0.5818\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7623 - accuracy: 0.5979 - val_loss: 0.7227 - val_accuracy: 0.5845\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7547 - accuracy: 0.5978 - val_loss: 0.7331 - val_accuracy: 0.6126\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7472 - accuracy: 0.6064 - val_loss: 0.7005 - val_accuracy: 0.6180\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7398 - accuracy: 0.6106 - val_loss: 0.6937 - val_accuracy: 0.6206\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7346 - accuracy: 0.6103 - val_loss: 0.6952 - val_accuracy: 0.6153\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7239 - accuracy: 0.6146 - val_loss: 0.6893 - val_accuracy: 0.6273\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7174 - accuracy: 0.6228 - val_loss: 0.6889 - val_accuracy: 0.6233\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6929 - accuracy: 0.6337 - val_loss: 0.6785 - val_accuracy: 0.6273\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.6825 - accuracy: 0.6380 - val_loss: 0.6647 - val_accuracy: 0.6381\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6753 - accuracy: 0.6432 - val_loss: 0.6843 - val_accuracy: 0.6220\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6830 - accuracy: 0.6422 - val_loss: 0.6464 - val_accuracy: 0.6689\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6493 - accuracy: 0.6610 - val_loss: 0.6539 - val_accuracy: 0.6582\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6453 - accuracy: 0.6583 - val_loss: 0.6201 - val_accuracy: 0.6622\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6191 - accuracy: 0.6888 - val_loss: 0.6424 - val_accuracy: 0.6702\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6227 - accuracy: 0.6893 - val_loss: 0.6686 - val_accuracy: 0.6609\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.6226 - accuracy: 0.6894 - val_loss: 0.6305 - val_accuracy: 0.6702\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5801 - accuracy: 0.7085 - val_loss: 0.6200 - val_accuracy: 0.6930\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5884 - accuracy: 0.7028 - val_loss: 0.6149 - val_accuracy: 0.6823\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5608 - accuracy: 0.7249 - val_loss: 0.5690 - val_accuracy: 0.7225\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5584 - accuracy: 0.7311 - val_loss: 0.5670 - val_accuracy: 0.7292\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5404 - accuracy: 0.7392 - val_loss: 0.5439 - val_accuracy: 0.7265\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5070 - accuracy: 0.7563 - val_loss: 0.5326 - val_accuracy: 0.7480\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5043 - accuracy: 0.7630 - val_loss: 0.5256 - val_accuracy: 0.7426\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4919 - accuracy: 0.7703 - val_loss: 0.4943 - val_accuracy: 0.7587\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4683 - accuracy: 0.7817 - val_loss: 0.5167 - val_accuracy: 0.7587\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.4556 - accuracy: 0.7985 - val_loss: 0.4728 - val_accuracy: 0.7802\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4269 - accuracy: 0.8076 - val_loss: 0.4849 - val_accuracy: 0.7534\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4208 - accuracy: 0.8212 - val_loss: 0.5366 - val_accuracy: 0.7534\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3902 - accuracy: 0.8270 - val_loss: 0.4442 - val_accuracy: 0.7909\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.4192 - accuracy: 0.8207 - val_loss: 0.2162 - val_accuracy: 0.9182\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3884 - accuracy: 0.8331 - val_loss: 0.2236 - val_accuracy: 0.9062\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3602 - accuracy: 0.8508 - val_loss: 0.2310 - val_accuracy: 0.9102\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.3499 - accuracy: 0.8554 - val_loss: 0.1996 - val_accuracy: 0.9155\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3229 - accuracy: 0.8596 - val_loss: 0.2048 - val_accuracy: 0.9330\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3003 - accuracy: 0.8736 - val_loss: 0.2390 - val_accuracy: 0.8794\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3198 - accuracy: 0.8681 - val_loss: 0.1685 - val_accuracy: 0.9330\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2812 - accuracy: 0.8870 - val_loss: 0.1646 - val_accuracy: 0.9397\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3185 - accuracy: 0.8744 - val_loss: 0.2033 - val_accuracy: 0.9155\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2622 - accuracy: 0.8946 - val_loss: 0.1805 - val_accuracy: 0.9196\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2654 - accuracy: 0.8949 - val_loss: 0.1514 - val_accuracy: 0.9397\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2492 - accuracy: 0.9010 - val_loss: 0.1561 - val_accuracy: 0.9424\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2059 - accuracy: 0.9262 - val_loss: 0.1924 - val_accuracy: 0.9196\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2322 - accuracy: 0.9107 - val_loss: 0.1324 - val_accuracy: 0.9437\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2135 - accuracy: 0.9203 - val_loss: 0.1300 - val_accuracy: 0.9464\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1870 - accuracy: 0.9301 - val_loss: 0.1061 - val_accuracy: 0.9544\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1707 - accuracy: 0.9396 - val_loss: 0.1451 - val_accuracy: 0.9397\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1916 - accuracy: 0.9335 - val_loss: 0.1324 - val_accuracy: 0.9450\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1779 - accuracy: 0.9373 - val_loss: 0.1135 - val_accuracy: 0.9464\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1686 - accuracy: 0.9417 - val_loss: 0.1067 - val_accuracy: 0.9571\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1585 - accuracy: 0.9441 - val_loss: 0.0882 - val_accuracy: 0.9692\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1526 - accuracy: 0.9475 - val_loss: 0.1350 - val_accuracy: 0.9464\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1502 - accuracy: 0.9475 - val_loss: 0.1153 - val_accuracy: 0.9558\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1286 - accuracy: 0.9577 - val_loss: 0.1001 - val_accuracy: 0.9638\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1259 - accuracy: 0.9560 - val_loss: 0.0864 - val_accuracy: 0.9625\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1411 - accuracy: 0.9510 - val_loss: 0.0810 - val_accuracy: 0.9718\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1140 - accuracy: 0.9598 - val_loss: 0.0968 - val_accuracy: 0.9651\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1223 - accuracy: 0.9548 - val_loss: 0.0701 - val_accuracy: 0.9772\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1257 - accuracy: 0.9550 - val_loss: 0.1175 - val_accuracy: 0.9598\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1068 - accuracy: 0.9632 - val_loss: 0.0840 - val_accuracy: 0.9705\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.1435 - accuracy: 0.9544 - val_loss: 0.0111 - val_accuracy: 0.9973\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1277 - accuracy: 0.9556 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1134 - accuracy: 0.9629 - val_loss: 0.0109 - val_accuracy: 0.9973\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1142 - accuracy: 0.9653 - val_loss: 0.0155 - val_accuracy: 0.9946\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1020 - accuracy: 0.9656 - val_loss: 0.0122 - val_accuracy: 0.9973\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0949 - accuracy: 0.9697 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0849 - accuracy: 0.9739 - val_loss: 0.0089 - val_accuracy: 0.9960\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0924 - accuracy: 0.9700 - val_loss: 0.0103 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0913 - accuracy: 0.9690 - val_loss: 0.0105 - val_accuracy: 0.9973\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0885 - accuracy: 0.9699 - val_loss: 0.0193 - val_accuracy: 0.9946\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0909 - accuracy: 0.9692 - val_loss: 0.0098 - val_accuracy: 0.9973\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0828 - accuracy: 0.9724 - val_loss: 0.0063 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0938 - accuracy: 0.9689 - val_loss: 0.0147 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0841 - accuracy: 0.9690 - val_loss: 0.0292 - val_accuracy: 0.9893\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0885 - accuracy: 0.9696 - val_loss: 0.0122 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0747 - accuracy: 0.9727 - val_loss: 0.0098 - val_accuracy: 0.9973\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0802 - accuracy: 0.9727 - val_loss: 0.0088 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0755 - accuracy: 0.9751 - val_loss: 0.0092 - val_accuracy: 0.9960\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0882 - accuracy: 0.9732 - val_loss: 0.0104 - val_accuracy: 0.9960\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0819 - accuracy: 0.9727 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0729 - accuracy: 0.9760 - val_loss: 0.0151 - val_accuracy: 0.9960\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0723 - accuracy: 0.9748 - val_loss: 0.0096 - val_accuracy: 0.9973\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0784 - accuracy: 0.9730 - val_loss: 0.0199 - val_accuracy: 0.9933\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0674 - accuracy: 0.9788 - val_loss: 0.0133 - val_accuracy: 0.9973\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0727 - accuracy: 0.9781 - val_loss: 0.0108 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0913 - accuracy: 0.9681 - val_loss: 0.0274 - val_accuracy: 0.9920\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0710 - accuracy: 0.9772 - val_loss: 0.0119 - val_accuracy: 0.9960\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0629 - accuracy: 0.9794 - val_loss: 0.0071 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0500 - accuracy: 0.9841 - val_loss: 0.0067 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0564 - accuracy: 0.9806 - val_loss: 0.0091 - val_accuracy: 0.9987\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0787 - accuracy: 0.9753 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0710 - accuracy: 0.9768 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0667 - accuracy: 0.9787 - val_loss: 5.0829e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0666 - accuracy: 0.9759 - val_loss: 6.6107e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0610 - accuracy: 0.9796 - val_loss: 5.9435e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0527 - accuracy: 0.9826 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0644 - accuracy: 0.9800 - val_loss: 9.5560e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0786 - accuracy: 0.9733 - val_loss: 8.0363e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0709 - accuracy: 0.9760 - val_loss: 3.9916e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0473 - accuracy: 0.9844 - val_loss: 3.5730e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0473 - accuracy: 0.9846 - val_loss: 0.0027 - val_accuracy: 0.9987\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0618 - accuracy: 0.9809 - val_loss: 0.0067 - val_accuracy: 0.9973\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0579 - accuracy: 0.9827 - val_loss: 4.8834e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0447 - accuracy: 0.9855 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0484 - accuracy: 0.9829 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0491 - accuracy: 0.9836 - val_loss: 5.4515e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0476 - accuracy: 0.9824 - val_loss: 6.8407e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0430 - accuracy: 0.9854 - val_loss: 4.3505e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0630 - accuracy: 0.9794 - val_loss: 0.0045 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0584 - accuracy: 0.9809 - val_loss: 0.0019 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0447 - accuracy: 0.9851 - val_loss: 6.8964e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0425 - accuracy: 0.9849 - val_loss: 5.9662e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0505 - accuracy: 0.9838 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0476 - accuracy: 0.9854 - val_loss: 0.0017 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0506 - accuracy: 0.9835 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0457 - accuracy: 0.9857 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0534 - accuracy: 0.9821 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0517 - accuracy: 0.9841 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0569 - accuracy: 0.9815 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0417 - accuracy: 0.9861 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0479 - accuracy: 0.9838 - val_loss: 1.4408e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0529 - accuracy: 0.9836 - val_loss: 1.4351e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0431 - accuracy: 0.9854 - val_loss: 9.5094e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0424 - accuracy: 0.9861 - val_loss: 5.2071e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0663 - accuracy: 0.9785 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0472 - accuracy: 0.9863 - val_loss: 3.1732e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0402 - accuracy: 0.9866 - val_loss: 1.4011e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0403 - accuracy: 0.9861 - val_loss: 3.2263e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0560 - accuracy: 0.9811 - val_loss: 1.9899e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0492 - accuracy: 0.9844 - val_loss: 3.3992e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0557 - accuracy: 0.9814 - val_loss: 2.7034e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0398 - accuracy: 0.9863 - val_loss: 3.6867e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0435 - accuracy: 0.9858 - val_loss: 3.8406e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0394 - accuracy: 0.9870 - val_loss: 5.8562e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0417 - accuracy: 0.9863 - val_loss: 5.4568e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0426 - accuracy: 0.9870 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0315 - accuracy: 0.9905 - val_loss: 1.9734e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0278 - accuracy: 0.9906 - val_loss: 0.0019 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0342 - accuracy: 0.9881 - val_loss: 3.2315e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0396 - accuracy: 0.9875 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0399 - accuracy: 0.9858 - val_loss: 3.1226e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0316 - accuracy: 0.9891 - val_loss: 5.4614e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0343 - accuracy: 0.9884 - val_loss: 1.2433e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0339 - accuracy: 0.9887 - val_loss: 3.6051e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0334 - accuracy: 0.9891 - val_loss: 5.0937e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0540 - accuracy: 0.9812 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0416 - accuracy: 0.9879 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0324 - accuracy: 0.9891 - val_loss: 4.0632e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0321 - accuracy: 0.9905 - val_loss: 1.5392e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0452 - accuracy: 0.9850 - val_loss: 6.0706e-04 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0475 - accuracy: 0.9860 - val_loss: 2.6576e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0376 - accuracy: 0.9884 - val_loss: 1.4123e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0389 - accuracy: 0.9885 - val_loss: 3.3457e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0371 - accuracy: 0.9891 - val_loss: 3.9000e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0261 - accuracy: 0.9923 - val_loss: 2.8156e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0345 - accuracy: 0.9885 - val_loss: 0.0017 - val_accuracy: 0.9987\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0359 - accuracy: 0.9894 - val_loss: 5.1964e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0422 - accuracy: 0.9864 - val_loss: 2.9171e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0343 - accuracy: 0.9890 - val_loss: 1.0881e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0236 - accuracy: 0.9923 - val_loss: 6.5280e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0440 - accuracy: 0.9850 - val_loss: 3.7818e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0407 - accuracy: 0.9878 - val_loss: 8.6776e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0312 - accuracy: 0.9890 - val_loss: 1.9083e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0290 - accuracy: 0.9896 - val_loss: 7.0171e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0539 - accuracy: 0.9829 - val_loss: 2.4997e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0430 - accuracy: 0.9869 - val_loss: 3.9662e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0354 - accuracy: 0.9891 - val_loss: 1.8372e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0361 - accuracy: 0.9890 - val_loss: 1.8372e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0344 - accuracy: 0.9897 - val_loss: 0.0027 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0326 - accuracy: 0.9893 - val_loss: 1.6636e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0261 - accuracy: 0.9915 - val_loss: 9.1200e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0273 - accuracy: 0.9931 - val_loss: 6.7682e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0365 - accuracy: 0.9884 - val_loss: 5.0152e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0342 - accuracy: 0.9899 - val_loss: 0.0017 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0271 - accuracy: 0.9917 - val_loss: 4.8473e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0288 - accuracy: 0.9905 - val_loss: 1.8252e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0256 - accuracy: 0.9920 - val_loss: 1.9113e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0198 - accuracy: 0.9930 - val_loss: 1.1846e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0276 - accuracy: 0.9903 - val_loss: 1.9002e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0336 - accuracy: 0.9902 - val_loss: 8.9537e-05 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0286 - accuracy: 0.9903 - val_loss: 2.7969e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0313 - accuracy: 0.9888 - val_loss: 2.7250e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0260 - accuracy: 0.9914 - val_loss: 2.3390e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0304 - accuracy: 0.9902 - val_loss: 4.2058e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0360 - accuracy: 0.9879 - val_loss: 1.5888e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0287 - accuracy: 0.9906 - val_loss: 3.6849e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0234 - accuracy: 0.9924 - val_loss: 1.4587e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0319 - accuracy: 0.9888 - val_loss: 8.1357e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0486 - accuracy: 0.9861 - val_loss: 2.4821e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0407 - accuracy: 0.9870 - val_loss: 7.8265e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0349 - accuracy: 0.9887 - val_loss: 1.6588e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0222 - accuracy: 0.9936 - val_loss: 2.0294e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0262 - accuracy: 0.9917 - val_loss: 9.0519e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 2.0728e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 0.0031 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0251 - accuracy: 0.9918 - val_loss: 7.5662e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0237 - accuracy: 0.9934 - val_loss: 2.4065e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0352 - accuracy: 0.9905 - val_loss: 2.9701e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0253 - accuracy: 0.9908 - val_loss: 8.5218e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0219 - accuracy: 0.9928 - val_loss: 1.8047e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0289 - accuracy: 0.9896 - val_loss: 2.6380e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0298 - accuracy: 0.9891 - val_loss: 1.7483e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0317 - accuracy: 0.9896 - val_loss: 1.5898e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0231 - accuracy: 0.9933 - val_loss: 3.8327e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0264 - accuracy: 0.9908 - val_loss: 1.4051e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0421 - accuracy: 0.9888 - val_loss: 1.2099e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0256 - accuracy: 0.9920 - val_loss: 3.2581e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0290 - accuracy: 0.9915 - val_loss: 7.0250e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0180 - accuracy: 0.9945 - val_loss: 4.3267e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0272 - accuracy: 0.9912 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0346 - accuracy: 0.9908 - val_loss: 4.1582e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0200 - accuracy: 0.9934 - val_loss: 5.8584e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0210 - accuracy: 0.9946 - val_loss: 1.8825e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0272 - accuracy: 0.9896 - val_loss: 1.4761e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0230 - accuracy: 0.9915 - val_loss: 2.7037e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0395 - accuracy: 0.9887 - val_loss: 3.3179e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 1.1803e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 2.4252e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0197 - accuracy: 0.9952 - val_loss: 6.2138e-06 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0291 - accuracy: 0.9905 - val_loss: 1.4183e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0297 - accuracy: 0.9909 - val_loss: 3.9431e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0227 - accuracy: 0.9923 - val_loss: 1.9515e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0291 - accuracy: 0.9897 - val_loss: 2.6311e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0275 - accuracy: 0.9917 - val_loss: 1.1627e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0267 - accuracy: 0.9915 - val_loss: 1.1179e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0226 - accuracy: 0.9927 - val_loss: 4.6348e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0240 - accuracy: 0.9928 - val_loss: 1.9786e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0240 - accuracy: 0.9936 - val_loss: 2.7824e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0247 - accuracy: 0.9931 - val_loss: 1.6917e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0301 - accuracy: 0.9908 - val_loss: 5.9952e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0301 - accuracy: 0.9911 - val_loss: 4.5166e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0349 - accuracy: 0.9893 - val_loss: 1.2051e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0207 - accuracy: 0.9945 - val_loss: 7.6981e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0233 - accuracy: 0.9933 - val_loss: 1.0925e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0201 - accuracy: 0.9946 - val_loss: 1.2298e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0235 - accuracy: 0.9928 - val_loss: 7.1648e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 2.5860e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0256 - accuracy: 0.9906 - val_loss: 2.2017e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0195 - accuracy: 0.9945 - val_loss: 2.5493e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0217 - accuracy: 0.9925 - val_loss: 4.5862e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "a156202e-2506-421d-812f-9c6326f5f83a"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 7ms/step - loss: 0.0424 - accuracy: 0.9882\n",
            "Accuracy  : 0.9881974458694458\n",
            "F1_Score  : 0.98656684929901\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "9dcb89e5-333e-4879-97a4-a21cda10745d"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'#dominance\\nX_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\\nprint(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "a8b014ae-675d-4d44-b9f3-c86530481ca7"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'foldNum=0\\nmodel = get_model()\\nfor train_index, val_index in kfold.split(X_train, Y_train):\\n  foldNum = foldNum + 1\\n  print(\"Results for fold\",foldNum)\\n  x_train, x_val = X_train[train_index], X_train[val_index]\\n  y_train, y_val = Y_train[train_index], Y_train[val_index]\\n  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\\n  gc.collect() # Garbage collecter\\n  del x_train, x_val, y_train, y_val\\n  gc.collect()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "68b2db64-dd77-47d0-a442-e7e8e472ae21"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'acrc = model.evaluate(x_test, y_test)\\npred = model.predict(x_test)\\nf1scr = f1_score(y_test.argmax(1), pred.argmax(1), average=\\'macro\\')\\nc_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\\nprint(\"Accuracy  : {}\".format(acrc[1]))\\nprint(\"F1_Score  : {}\".format(f1scr))\\nc_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\\nimport seaborn as sns\\nfigure = plt.figure(figsize=(9, 9))\\nsns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\\nplt.tight_layout()\\nplt.ylabel(\\'True label\\')\\nplt.xlabel(\\'Predicted label\\')\\nplt.show()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}