{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub12_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "ccb2cf2d-2cb5-42cf-d194-3893adb504cf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e3\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  #EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "ff1bdde9-442b-4872-e0ca-6297b216dcf8"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(12,13):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.12\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (3495,) (1864,) (3961,)\n",
            "(9320,) (1165,) (2330,) (5825,)\n",
            "(9320,) (4660,) (932,) (3728,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "6db61903-0bcf-4fbe-f82d-1d133bf7d55b"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "20f88ad8-2c12-4550-90b5-1ee38be48262"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "706"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "bceb0418-8de3-4381-8c37-0d7478729ac4"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad9dc630-c3d7-4bef-9346-9c7a18c41397"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 22s 59ms/step - loss: 1.2634 - accuracy: 0.3679 - val_loss: 1.0680 - val_accuracy: 0.4209\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0755 - accuracy: 0.4197 - val_loss: 1.0614 - val_accuracy: 0.4290\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0646 - accuracy: 0.4327 - val_loss: 1.0646 - val_accuracy: 0.4249\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0632 - accuracy: 0.4312 - val_loss: 1.0597 - val_accuracy: 0.4236\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0620 - accuracy: 0.4326 - val_loss: 1.0534 - val_accuracy: 0.4236\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0610 - accuracy: 0.4202 - val_loss: 1.0469 - val_accuracy: 0.4236\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0551 - accuracy: 0.4291 - val_loss: 1.0445 - val_accuracy: 0.4236\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0522 - accuracy: 0.4270 - val_loss: 1.0490 - val_accuracy: 0.4236\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0471 - accuracy: 0.4203 - val_loss: 1.0382 - val_accuracy: 0.4236\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0414 - accuracy: 0.4347 - val_loss: 1.0327 - val_accuracy: 0.4424\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0467 - accuracy: 0.4301 - val_loss: 1.0341 - val_accuracy: 0.4276\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0408 - accuracy: 0.4366 - val_loss: 1.0324 - val_accuracy: 0.4290\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0430 - accuracy: 0.4305 - val_loss: 1.0297 - val_accuracy: 0.4383\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0348 - accuracy: 0.4421 - val_loss: 1.0320 - val_accuracy: 0.4477\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0374 - accuracy: 0.4416 - val_loss: 1.0155 - val_accuracy: 0.4544\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0355 - accuracy: 0.4407 - val_loss: 1.0117 - val_accuracy: 0.4531\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0271 - accuracy: 0.4400 - val_loss: 1.0122 - val_accuracy: 0.4437\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0212 - accuracy: 0.4519 - val_loss: 1.0190 - val_accuracy: 0.4705\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0266 - accuracy: 0.4377 - val_loss: 1.0025 - val_accuracy: 0.4678\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0227 - accuracy: 0.4363 - val_loss: 1.0267 - val_accuracy: 0.4531\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0043 - accuracy: 0.4578 - val_loss: 0.9951 - val_accuracy: 0.4692\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0126 - accuracy: 0.4521 - val_loss: 1.0114 - val_accuracy: 0.4584\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0001 - accuracy: 0.4634 - val_loss: 1.0044 - val_accuracy: 0.4678\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0065 - accuracy: 0.4617 - val_loss: 0.9848 - val_accuracy: 0.4558\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0061 - accuracy: 0.4686 - val_loss: 1.0020 - val_accuracy: 0.4651\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0019 - accuracy: 0.4683 - val_loss: 0.9719 - val_accuracy: 0.4799\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9971 - accuracy: 0.4608 - val_loss: 0.9649 - val_accuracy: 0.4893\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9866 - accuracy: 0.4733 - val_loss: 0.9690 - val_accuracy: 0.4651\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9895 - accuracy: 0.4702 - val_loss: 0.9568 - val_accuracy: 0.4853\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9914 - accuracy: 0.4610 - val_loss: 0.9701 - val_accuracy: 0.4893\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9777 - accuracy: 0.4733 - val_loss: 0.9375 - val_accuracy: 0.4732\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9764 - accuracy: 0.4754 - val_loss: 0.9288 - val_accuracy: 0.4920\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9657 - accuracy: 0.4812 - val_loss: 0.9124 - val_accuracy: 0.5040\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9624 - accuracy: 0.4923 - val_loss: 0.9219 - val_accuracy: 0.5027\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9498 - accuracy: 0.4918 - val_loss: 0.9212 - val_accuracy: 0.5295\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9534 - accuracy: 0.4927 - val_loss: 0.9144 - val_accuracy: 0.5282\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9459 - accuracy: 0.4927 - val_loss: 0.8998 - val_accuracy: 0.5228\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9264 - accuracy: 0.5010 - val_loss: 0.9088 - val_accuracy: 0.5241\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9264 - accuracy: 0.5115 - val_loss: 0.8829 - val_accuracy: 0.5255\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9230 - accuracy: 0.5140 - val_loss: 0.9061 - val_accuracy: 0.5295\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9107 - accuracy: 0.5235 - val_loss: 0.8900 - val_accuracy: 0.5603\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9131 - accuracy: 0.5176 - val_loss: 0.8795 - val_accuracy: 0.5268\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8952 - accuracy: 0.5300 - val_loss: 0.8896 - val_accuracy: 0.5469\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8938 - accuracy: 0.5398 - val_loss: 0.8713 - val_accuracy: 0.5456\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8835 - accuracy: 0.5453 - val_loss: 0.8873 - val_accuracy: 0.5523\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8757 - accuracy: 0.5562 - val_loss: 0.8575 - val_accuracy: 0.5643\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8599 - accuracy: 0.5581 - val_loss: 0.8385 - val_accuracy: 0.5818\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8602 - accuracy: 0.5528 - val_loss: 0.8698 - val_accuracy: 0.5469\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8430 - accuracy: 0.5742 - val_loss: 0.8416 - val_accuracy: 0.5871\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8347 - accuracy: 0.5733 - val_loss: 0.8463 - val_accuracy: 0.5590\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8288 - accuracy: 0.5811 - val_loss: 0.8287 - val_accuracy: 0.5952\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8148 - accuracy: 0.6001 - val_loss: 0.8220 - val_accuracy: 0.5912\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7881 - accuracy: 0.6052 - val_loss: 0.8082 - val_accuracy: 0.6046\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7813 - accuracy: 0.6231 - val_loss: 0.8132 - val_accuracy: 0.5979\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7703 - accuracy: 0.6230 - val_loss: 0.7916 - val_accuracy: 0.5858\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7585 - accuracy: 0.6328 - val_loss: 0.7631 - val_accuracy: 0.6434\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7370 - accuracy: 0.6407 - val_loss: 0.7679 - val_accuracy: 0.6220\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7155 - accuracy: 0.6595 - val_loss: 0.8000 - val_accuracy: 0.6166\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6946 - accuracy: 0.6647 - val_loss: 0.7568 - val_accuracy: 0.6287\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6951 - accuracy: 0.6753 - val_loss: 0.7779 - val_accuracy: 0.6113\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6939 - accuracy: 0.6715 - val_loss: 0.5850 - val_accuracy: 0.7440\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6703 - accuracy: 0.6890 - val_loss: 0.5767 - val_accuracy: 0.7332\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6479 - accuracy: 0.7013 - val_loss: 0.5631 - val_accuracy: 0.7480\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6413 - accuracy: 0.7022 - val_loss: 0.5690 - val_accuracy: 0.7681\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6129 - accuracy: 0.7177 - val_loss: 0.5745 - val_accuracy: 0.7252\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5913 - accuracy: 0.7355 - val_loss: 0.5101 - val_accuracy: 0.7721\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5746 - accuracy: 0.7417 - val_loss: 0.5695 - val_accuracy: 0.7413\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5540 - accuracy: 0.7581 - val_loss: 0.4824 - val_accuracy: 0.7895\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5141 - accuracy: 0.7697 - val_loss: 0.5051 - val_accuracy: 0.7909\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5018 - accuracy: 0.7864 - val_loss: 0.4837 - val_accuracy: 0.8016\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4607 - accuracy: 0.8012 - val_loss: 0.4704 - val_accuracy: 0.7962\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4880 - accuracy: 0.7969 - val_loss: 0.4525 - val_accuracy: 0.7976\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4522 - accuracy: 0.8112 - val_loss: 0.4167 - val_accuracy: 0.8244\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4024 - accuracy: 0.8367 - val_loss: 0.3976 - val_accuracy: 0.8378\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3947 - accuracy: 0.8396 - val_loss: 0.3910 - val_accuracy: 0.8418\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3861 - accuracy: 0.8466 - val_loss: 0.3816 - val_accuracy: 0.8432\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3624 - accuracy: 0.8520 - val_loss: 0.3773 - val_accuracy: 0.8432\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3336 - accuracy: 0.8686 - val_loss: 0.3254 - val_accuracy: 0.8619\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3287 - accuracy: 0.8727 - val_loss: 0.3419 - val_accuracy: 0.8646\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2982 - accuracy: 0.8839 - val_loss: 0.2920 - val_accuracy: 0.9021\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2924 - accuracy: 0.8893 - val_loss: 0.2816 - val_accuracy: 0.8807\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2712 - accuracy: 0.8988 - val_loss: 0.2565 - val_accuracy: 0.9088\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2657 - accuracy: 0.8985 - val_loss: 0.2715 - val_accuracy: 0.9008\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2428 - accuracy: 0.9101 - val_loss: 0.2550 - val_accuracy: 0.9115\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2230 - accuracy: 0.9227 - val_loss: 0.2680 - val_accuracy: 0.8995\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2150 - accuracy: 0.9206 - val_loss: 0.2591 - val_accuracy: 0.9155\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2244 - accuracy: 0.9195 - val_loss: 0.2348 - val_accuracy: 0.9196\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1979 - accuracy: 0.9264 - val_loss: 0.2205 - val_accuracy: 0.9316\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1816 - accuracy: 0.9367 - val_loss: 0.2045 - val_accuracy: 0.9290\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1744 - accuracy: 0.9396 - val_loss: 0.2161 - val_accuracy: 0.9276\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2068 - accuracy: 0.9280 - val_loss: 0.0293 - val_accuracy: 0.9946\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1756 - accuracy: 0.9449 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1679 - accuracy: 0.9420 - val_loss: 0.0208 - val_accuracy: 0.9987\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1727 - accuracy: 0.9416 - val_loss: 0.0349 - val_accuracy: 0.9933\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1685 - accuracy: 0.9420 - val_loss: 0.0271 - val_accuracy: 0.9960\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1442 - accuracy: 0.9525 - val_loss: 0.0260 - val_accuracy: 0.9960\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1493 - accuracy: 0.9480 - val_loss: 0.0232 - val_accuracy: 0.9946\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1232 - accuracy: 0.9571 - val_loss: 0.0228 - val_accuracy: 0.9946\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1213 - accuracy: 0.9605 - val_loss: 0.0378 - val_accuracy: 0.9879\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1411 - accuracy: 0.9529 - val_loss: 0.0473 - val_accuracy: 0.9853\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1156 - accuracy: 0.9617 - val_loss: 0.0271 - val_accuracy: 0.9920\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1184 - accuracy: 0.9617 - val_loss: 0.0196 - val_accuracy: 0.9946\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1105 - accuracy: 0.9641 - val_loss: 0.0218 - val_accuracy: 0.9933\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1026 - accuracy: 0.9671 - val_loss: 0.0214 - val_accuracy: 0.9920\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1140 - accuracy: 0.9654 - val_loss: 0.0315 - val_accuracy: 0.9933\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0968 - accuracy: 0.9686 - val_loss: 0.0241 - val_accuracy: 0.9946\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1064 - accuracy: 0.9665 - val_loss: 0.0415 - val_accuracy: 0.9853\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0884 - accuracy: 0.9712 - val_loss: 0.0194 - val_accuracy: 0.9906\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0943 - accuracy: 0.9687 - val_loss: 0.0219 - val_accuracy: 0.9960\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1021 - accuracy: 0.9662 - val_loss: 0.0600 - val_accuracy: 0.9772\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1103 - accuracy: 0.9647 - val_loss: 0.0275 - val_accuracy: 0.9906\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0829 - accuracy: 0.9748 - val_loss: 0.0173 - val_accuracy: 0.9920\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0695 - accuracy: 0.9784 - val_loss: 0.0133 - val_accuracy: 0.9960\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0709 - accuracy: 0.9768 - val_loss: 0.0239 - val_accuracy: 0.9893\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0755 - accuracy: 0.9760 - val_loss: 0.0209 - val_accuracy: 0.9946\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0770 - accuracy: 0.9756 - val_loss: 0.0257 - val_accuracy: 0.9879\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0634 - accuracy: 0.9815 - val_loss: 0.0274 - val_accuracy: 0.9920\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0692 - accuracy: 0.9785 - val_loss: 0.0202 - val_accuracy: 0.9920\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0642 - accuracy: 0.9809 - val_loss: 0.0612 - val_accuracy: 0.9812\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0781 - accuracy: 0.9756 - val_loss: 0.0233 - val_accuracy: 0.9933\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0887 - accuracy: 0.9720 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0657 - accuracy: 0.9791 - val_loss: 6.3890e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0626 - accuracy: 0.9806 - val_loss: 5.2409e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0686 - accuracy: 0.9803 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0658 - accuracy: 0.9772 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0678 - accuracy: 0.9776 - val_loss: 9.8127e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0669 - accuracy: 0.9793 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0606 - accuracy: 0.9793 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0600 - accuracy: 0.9809 - val_loss: 6.7363e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0595 - accuracy: 0.9812 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0528 - accuracy: 0.9815 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0619 - accuracy: 0.9814 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0650 - accuracy: 0.9797 - val_loss: 5.7973e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0536 - accuracy: 0.9839 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0606 - accuracy: 0.9806 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0570 - accuracy: 0.9820 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0694 - accuracy: 0.9800 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0446 - accuracy: 0.9849 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0467 - accuracy: 0.9835 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0577 - accuracy: 0.9839 - val_loss: 7.3139e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0487 - accuracy: 0.9842 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0585 - accuracy: 0.9806 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0548 - accuracy: 0.9841 - val_loss: 0.0025 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0519 - accuracy: 0.9836 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0414 - accuracy: 0.9876 - val_loss: 0.0050 - val_accuracy: 0.9973\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0446 - accuracy: 0.9866 - val_loss: 0.0036 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0420 - accuracy: 0.9866 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0422 - accuracy: 0.9885 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0451 - accuracy: 0.9866 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0593 - accuracy: 0.9820 - val_loss: 0.0066 - val_accuracy: 0.9987\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0494 - accuracy: 0.9844 - val_loss: 3.3847e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0547 - accuracy: 0.9818 - val_loss: 1.9396e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0524 - accuracy: 0.9852 - val_loss: 2.5218e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0526 - accuracy: 0.9846 - val_loss: 2.8123e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0359 - accuracy: 0.9875 - val_loss: 1.7885e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0420 - accuracy: 0.9884 - val_loss: 1.2144e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0446 - accuracy: 0.9876 - val_loss: 7.8159e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0444 - accuracy: 0.9866 - val_loss: 9.8511e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0297 - accuracy: 0.9897 - val_loss: 1.3650e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0439 - accuracy: 0.9858 - val_loss: 5.6945e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0456 - accuracy: 0.9860 - val_loss: 2.9117e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0416 - accuracy: 0.9863 - val_loss: 0.0027 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0500 - accuracy: 0.9842 - val_loss: 4.8413e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0413 - accuracy: 0.9858 - val_loss: 5.1696e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0456 - accuracy: 0.9858 - val_loss: 0.0035 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0421 - accuracy: 0.9872 - val_loss: 1.5622e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0397 - accuracy: 0.9870 - val_loss: 5.5339e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0322 - accuracy: 0.9900 - val_loss: 6.1337e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0332 - accuracy: 0.9911 - val_loss: 2.7487e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0435 - accuracy: 0.9858 - val_loss: 7.6363e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0422 - accuracy: 0.9863 - val_loss: 3.8219e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0327 - accuracy: 0.9906 - val_loss: 2.8976e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0402 - accuracy: 0.9872 - val_loss: 3.5928e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0362 - accuracy: 0.9893 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0304 - accuracy: 0.9906 - val_loss: 8.7720e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0403 - accuracy: 0.9876 - val_loss: 3.9243e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0428 - accuracy: 0.9860 - val_loss: 7.4589e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0366 - accuracy: 0.9873 - val_loss: 0.0031 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0428 - accuracy: 0.9870 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0482 - accuracy: 0.9842 - val_loss: 0.0074 - val_accuracy: 0.9973\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 47ms/step - loss: 0.0351 - accuracy: 0.9890 - val_loss: 8.3939e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0340 - accuracy: 0.9890 - val_loss: 2.8566e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0361 - accuracy: 0.9882 - val_loss: 1.5295e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0299 - accuracy: 0.9906 - val_loss: 3.6262e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0264 - accuracy: 0.9914 - val_loss: 9.4436e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0203 - accuracy: 0.9943 - val_loss: 9.9543e-06 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0281 - accuracy: 0.9915 - val_loss: 2.1366e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0410 - accuracy: 0.9896 - val_loss: 1.0080e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0293 - accuracy: 0.9902 - val_loss: 6.3989e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0326 - accuracy: 0.9914 - val_loss: 1.6982e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0430 - accuracy: 0.9863 - val_loss: 6.5619e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0364 - accuracy: 0.9902 - val_loss: 1.2608e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0335 - accuracy: 0.9888 - val_loss: 1.8404e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0307 - accuracy: 0.9909 - val_loss: 6.7801e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0300 - accuracy: 0.9914 - val_loss: 1.3566e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0307 - accuracy: 0.9899 - val_loss: 5.2941e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0267 - accuracy: 0.9923 - val_loss: 7.4406e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0375 - accuracy: 0.9890 - val_loss: 1.1919e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0272 - accuracy: 0.9911 - val_loss: 2.6736e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0293 - accuracy: 0.9923 - val_loss: 5.0525e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0209 - accuracy: 0.9924 - val_loss: 1.0210e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 3.3466e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0318 - accuracy: 0.9890 - val_loss: 0.0017 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0429 - accuracy: 0.9872 - val_loss: 8.4623e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0342 - accuracy: 0.9893 - val_loss: 3.5348e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0295 - accuracy: 0.9903 - val_loss: 3.8828e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0237 - accuracy: 0.9933 - val_loss: 9.9520e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0302 - accuracy: 0.9917 - val_loss: 0.0021 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0344 - accuracy: 0.9885 - val_loss: 3.9002e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0319 - accuracy: 0.9903 - val_loss: 8.1443e-05 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0342 - accuracy: 0.9890 - val_loss: 7.7625e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0292 - accuracy: 0.9911 - val_loss: 1.4880e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0272 - accuracy: 0.9920 - val_loss: 1.2876e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0262 - accuracy: 0.9918 - val_loss: 8.8645e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0250 - accuracy: 0.9931 - val_loss: 1.7872e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0238 - accuracy: 0.9923 - val_loss: 1.2910e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0283 - accuracy: 0.9894 - val_loss: 8.4635e-06 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0227 - accuracy: 0.9923 - val_loss: 8.6152e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0223 - accuracy: 0.9931 - val_loss: 5.3936e-06 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0247 - accuracy: 0.9921 - val_loss: 6.0952e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0325 - accuracy: 0.9897 - val_loss: 4.6503e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0255 - accuracy: 0.9923 - val_loss: 3.6201e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0205 - accuracy: 0.9945 - val_loss: 2.7747e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0178 - accuracy: 0.9945 - val_loss: 3.0890e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0175 - accuracy: 0.9940 - val_loss: 9.3512e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0258 - accuracy: 0.9909 - val_loss: 4.6095e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0316 - accuracy: 0.9909 - val_loss: 0.0065 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0290 - accuracy: 0.9914 - val_loss: 1.4318e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0202 - accuracy: 0.9936 - val_loss: 1.3232e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0282 - accuracy: 0.9914 - val_loss: 1.8346e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0233 - accuracy: 0.9936 - val_loss: 7.9658e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0279 - accuracy: 0.9899 - val_loss: 7.1605e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0267 - accuracy: 0.9920 - val_loss: 0.0014 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0268 - accuracy: 0.9923 - val_loss: 8.2179e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0251 - accuracy: 0.9921 - val_loss: 4.9243e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0245 - accuracy: 0.9921 - val_loss: 1.0995e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0214 - accuracy: 0.9948 - val_loss: 3.6060e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0162 - accuracy: 0.9958 - val_loss: 1.1859e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0213 - accuracy: 0.9939 - val_loss: 9.0999e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0367 - accuracy: 0.9888 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0213 - accuracy: 0.9924 - val_loss: 4.9245e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0278 - accuracy: 0.9921 - val_loss: 4.9351e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0273 - accuracy: 0.9900 - val_loss: 2.1670e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 7.1769e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0239 - accuracy: 0.9921 - val_loss: 1.5866e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0206 - accuracy: 0.9939 - val_loss: 4.0349e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0164 - accuracy: 0.9955 - val_loss: 1.1110e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0354 - accuracy: 0.9902 - val_loss: 2.3794e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0291 - accuracy: 0.9908 - val_loss: 1.4167e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0230 - accuracy: 0.9927 - val_loss: 1.1345e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 2.6442e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0197 - accuracy: 0.9936 - val_loss: 2.5189e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0283 - accuracy: 0.9914 - val_loss: 4.9158e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0205 - accuracy: 0.9921 - val_loss: 3.1788e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0244 - accuracy: 0.9945 - val_loss: 1.0274e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0209 - accuracy: 0.9952 - val_loss: 4.6980e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0240 - accuracy: 0.9933 - val_loss: 6.1685e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0161 - accuracy: 0.9955 - val_loss: 3.6598e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 3.1512e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0273 - accuracy: 0.9923 - val_loss: 1.6196e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0272 - accuracy: 0.9911 - val_loss: 5.0351e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0166 - accuracy: 0.9955 - val_loss: 2.0648e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0190 - accuracy: 0.9945 - val_loss: 3.3829e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0261 - accuracy: 0.9927 - val_loss: 2.0427e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0189 - accuracy: 0.9954 - val_loss: 1.2038e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0208 - accuracy: 0.9931 - val_loss: 6.9382e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0188 - accuracy: 0.9945 - val_loss: 1.0898e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0160 - accuracy: 0.9946 - val_loss: 7.8600e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0250 - accuracy: 0.9928 - val_loss: 2.3368e-04 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0243 - accuracy: 0.9920 - val_loss: 1.5626e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0325 - accuracy: 0.9914 - val_loss: 1.6993e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0199 - accuracy: 0.9945 - val_loss: 8.4220e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0290 - accuracy: 0.9918 - val_loss: 2.9798e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0198 - accuracy: 0.9943 - val_loss: 3.2625e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0158 - accuracy: 0.9946 - val_loss: 1.6887e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0214 - accuracy: 0.9931 - val_loss: 0.0019 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0331 - accuracy: 0.9908 - val_loss: 9.9516e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0262 - accuracy: 0.9921 - val_loss: 7.5667e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0237 - accuracy: 0.9931 - val_loss: 9.4226e-06 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0200 - accuracy: 0.9948 - val_loss: 2.6145e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 1.0349e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 7.9429e-06 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0152 - accuracy: 0.9955 - val_loss: 8.3121e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 9.7483e-06 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 4.6781e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0173 - accuracy: 0.9951 - val_loss: 6.4045e-06 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0240 - accuracy: 0.9942 - val_loss: 1.9031e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 5.7555e-06 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0172 - accuracy: 0.9954 - val_loss: 2.4507e-06 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0155 - accuracy: 0.9960 - val_loss: 1.5854e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 9.0171e-06 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0226 - accuracy: 0.9954 - val_loss: 4.1562e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 5.4640e-06 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 5.8381e-06 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0120 - accuracy: 0.9957 - val_loss: 3.8114e-06 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 1.0911e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0204 - accuracy: 0.9940 - val_loss: 5.9395e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 1.2608e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0161 - accuracy: 0.9952 - val_loss: 3.5010e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "id": "CAnc2SJa3o9f",
        "outputId": "958e795f-d282-4d9d-fa91-15543b0240ec"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 8ms/step - loss: 0.0583 - accuracy: 0.9844\n",
            "Accuracy  : 0.9844420552253723\n",
            "F1_Score  : 0.9841505536260118\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAAKOCAYAAAAS8uXWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debhdVXk/8O9KQgQZAihJGAIytcrgwORAmYIhYQyoOGudihOItihSi+2PVpy1WkWNYLXWakVAkASCMmNBiKjMaFCEBEkQAUVpk1zW7497E25Chmv0Zi9yPh+f8zz3nL3PPmvzbLYv33evvUutNQAAtGNE1wMAAGBpCjQAgMYo0AAAGqNAAwBojAINAKAxo7oewIqst9s7TC+lcw9c++muhwBJkr5HnRJpw/qjS+nid9d7zrGd/UvwyI8+s8b3WYIGANAYBRoAQGOabXECACxReitT6q29BQB4AlCgAQA0RosTAGhfN5NHOyNBAwBojAQNAGifSQIAAHRJggYAtM81aAAAdEmBBgDQGC1OAKB9JgkAANAlCRoA0D6TBAAA6JICDQCgMVqcAED7TBIAAKBLEjQAoH0mCQAA0CUJGgDQPtegAQDQJQUaAEBjtDgBgPaZJAAAQJckaABA+0wSAACgSxI0AKB9rkEDAKBLCjQAgMZocQIA7TNJAACALknQAID2SdAAAOiSAg0AoDFanABA+0a4DxoAAB2SoAEA7TNJAACALknQAID2eRYnAABdUqABADRGixMAaJ9JAgAAdEmCBgC0zyQBAAC6pEADAGiMFicA0D6TBAAA6JIEDQBon0kCAAB0SYIGALTPNWgAAHRJgQYA0BgtTgCgfSYJAADQJQkaANA+kwQAAOiSBA0AaJ9r0AAA6JICDQCgMVqcAED7TBIAAKBLEjQAoH0SNAAAuqRAAwBojBYnANA+90EDAKBLEjQAoH0mCQAA0CUJGgDQPtegAQDQJQUaAEBjtDgBgPaZJAAAQJckaABA+0wSAACgSxI0AKB5RYIGAECXFGgAAI3R4gQAmqfFCQBApyRoAED7eitAk6ABALRGgQYA0BgtTgCgeSYJAADQKQkaANA8CRoAAJ2SoAEAzZOgAQDQKQUaAEBjtDgBgOZpcQIA0CkJGgDQvt4K0CRoAACtUaA9QU16wTPyk7Pfl5vOPTknvO6Fj1u+9eabZMbn355r//vEzJx2XLYcu/GSZR84/oj88MyT8qOz/j4ff/eL1+Sw6THfv/KKHHHo5Bw2ZVLO+OK0rofDWub7V12Zow6fkiMOOSj/fvrjj68FCxbkxBPelSMOOSivfeVLc8/cOUmSBx98IMe84bXZe6/d8qEPnLLUdxYuXJB//qeTc+Rhk/Oiww/Oxd+duUb2hVUrpXT26oIC7QloxIiSfz3x6Ew97vN5zotPzdFTds/Ttx2/1DoffOeR+dr512Wvl304p37xwpxy3OFJkuc9c9s8/1nbZc+XfSi7H/3B7L7z1tln9x262A3Wcn19fTn1A6fktM+fnnPOm54LZ5yfO2bP7npYrCX6+vry4Q+ckn877Ys569zzc+EF0/PzO5Y+vr599rey0UYb5bwZF+VVr/nrfOqTH0+SPGn0k/LWY4/Pu054z+O2e/q0z2fTTZ+Sb58/M986d3p222OvNbI/sKxhK9BKKU8vpZxYSvn0wOvEUsozhuv3esmeu2yTO+bclzvn3p+Fi/py5szrc9j+uy61ztO3G5/Lr/tpkuTy636Ww/brX15T86QnrZPR64zKk0aPyqhRIzP/N79b4/vA2u+mG2/IhAnbZKsJE7LO6NGZcsihuezSi7seFmuJm268IVttvXX/8bXO6Ew++JDHHV+XXXpxDjviyCTJgZMm57ofXJ1aa9Z78pPznN12z+jRox+33fPOOTtveNMxSZIRI0Zkk002Gf6dgeUYlgKtlHJikm+k/5K+awdeJcnXSynvHY7f7CVbbLZx5tz74JL3c+c/mC3HjllqnRt/OjdTJz4rSTJ14jOz0QbrZtMxT84PbrgzV1z30/zion/OL2b+S7539a25/Rfz1uj46Q3z583L+M0fS3bHjhuXefMca/x53Dd/XsaP33zJ+7Hjxmf+MsfXffPnL1ln1KhR2WCDDfPggw9mRX73298mSU77zKfyype+KO/52+Nz/69/PQyjZ3Vocf55vDHJnrXWD9Va/3Pg9aEkew0sW65SyjGllFmllFmLfn3TMA2tN5z0yW9nn913yNX/9Z7ss9sOmTvvwfT11Ww34an5y23HZ4cp78/2U07O/nv+RfZ+znZdDxegc4v6+jJv3r151rOfk//65tl55rOenU9+/CNdD4seNVwF2qNJtljO55sPLFuuWuu0WusetdY9Rj11l2Ea2hPfPfc9mK3GP3bR/5ZjN87c+Q8ttc6vfv3bvPyEM/L8V34k//jZ85MkDz38SKYe8Mxce+Od+f0jC/L7RxZk5vdvzXOfue0aHT+9Yey4cbn3V/cueT9/3ryMGzeuwxGxNtls7Ljce++vlryfP+/ejF3m+Nps7Ngl6yxatCgPP/y7bLzxxlmRjTfeOOuut14mvvCgJMkLJ0/JbbfeMgyjZ3VI0P483pnk4lLKBaWUaQOvC5NcnOT4YfrNnjHr5ruyw4TNss0Wm2adUSNz9OTdMv3yG5da5ykbr7/koHr3GyblK+dekyS5+94Hss/uO2TkyBEZNWpE9tl9+9ymxckw2HmXXXPXXXdmzpy7s3DBglw4Y3r2O2Bi18NiLbHzLrvm7l/+MnPnzMnChQsy84IZ2W//pY+v/fafmPPP+3aS5OLvzsyeez1vpf9nW0rJvvsdkFnXXZskufaaq7PddtsP307ASpRa6/BsuJQR6W9pbjnw0dwk19Va+4by/fV2e8fwDGwtMXnvnfLRE16UkSNG5CvnXZOPnHFRTn7LIbn+lrsy/YqbctSBz84pxx2WWpOrrr8j7/zQmVmwcFFGjCj51EkvzV/ttn1qTb77P7fmxE+c0/XuNOuBaz/d9RCe0K684vJ85EOn5tFH+3LkUS/O37z5rV0P6Qmr71GnxGVddcXl+dhHTs2jfY/miKNenDcd85Z87jOfzk4775L9DpiY//u//8vJJ70nt912a8aMGZMPfuQT2WrChCTJoZMn5vcP/z4LFy7MhhtumNOmnZHttt8h99wzNyefdGJ+97vfZpNNN80//fOp2Xzz5TWEetf6o7uJlDZ9zX919i/Bb776yjW+z8NWoP2pFGi0QIFGKxRotKKrAu0pr/16Z/8S3P8fr1jj++w+aAAAjfEsTgCgfZ7FCQBAlyRoAEDzurrdRVckaAAAjVGgAQA0RosTAGieFicAAJ1SoAEAzWv5WZyllCmllNtLKbNLKe9dzvKtSymXllJ+VEq5oZRyyKq2qUADAFhNpZSRST6b5OAkOyV5RSllp2VW+4ck36y1PifJy5OctqrtKtAAAFbfXklm11p/XmtdkOQbSaYus05NstHA32OS3LOqjZokAAC0r8M5AqWUY5IcM+ijabXWaQN/b5nk7kHL5iR57jKb+KckF5VSjkuyfpIXruo3FWgAACsxUIxNW+WKK/aKJF+utX68lPL8JF8tpexSa310RV9QoAEAzWv4Nhtzk0wY9H6rgc8Ge2OSKUlSa726lLJukqcmmb+ijboGDQBg9V2XZMdSyrallNHpnwRw3jLr3JXkwCQppTwjybpJ7lvZRiVoAEDzWk3Qaq2LSinHJpmZZGSSL9Vaby6lnJJkVq31vCR/l+SLpZR3pX/CwOtqrXVl21WgAQD8CWqtM5LMWOaz9w/6+5Yke/8x29TiBABojAQNAGheqy3O4SJBAwBojAQNAGieBA0AgE5J0ACA9vVWgCZBAwBojQINAKAxWpwAQPNMEgAAoFMSNACgeRI0AAA6pUADAGiMFicA0DwtTgAAOiVBAwDa11sBmgQNAKA1EjQAoHmuQQMAoFMKNACAxmhxAgDN0+IEAKBTEjQAoHkSNAAAOiVBAwCaJ0EDAKBTCjQAgMZocQIA7eutDqcEDQCgNRI0AKB5JgkAANApBRoAQGO0OAGA5mlxAgDQKQkaANC8HgvQJGgAAK2RoAEAzXMNGgAAnVKgAQA0RosTAGhej3U4JWgAAK2RoAEAzTNJAACATinQAAAao8UJADSvxzqcEjQAgNZI0ACA5o0Y0VsRmgQNAKAxEjQAoHmuQQMAoFMKNACAxmhxAgDN8yQBAAA6JUEDAJrXYwGaBA0AoDUSNACgea5BAwCgUwo0AIDGaHECAM3T4gQAoFMSNACgeT0WoEnQAABao0ADAGiMFicA0DyTBAAA6JQEDQBoXo8FaBI0AIDWSNAAgOa5Bg0AgE4p0AAAGqPFCQA0r8c6nBI0AIDWSNAAgOaZJAAAQKckaABA83osQJOgAQC0RoEGANAYLU4AoHkmCQAA0KlmE7T7r/lU10OAbPKCE7oeAiRJfn3VR7seAnSqxwI0CRoAQGsUaAAAjWm2xQkAsJhJAgAAdEqCBgA0r8cCNAkaAEBrJGgAQPNcgwYAQKcUaAAAjdHiBACa12MdTgkaAEBrJGgAQPNMEgAAoFMKNACAxmhxAgDN0+IEAKBTEjQAoHk9FqBJ0AAAWiNBAwCa5xo0AAA6pUADAGiMFicA0Lwe63BK0AAAWiNBAwCaZ5IAAACdkqABAM3rsQBNggYA0BoFGgBAY7Q4AYDmjeixHqcEDQCgMRI0AKB5PRagSdAAAFqjQAMAaIwWJwDQPE8SAABgyEopU0opt5dSZpdS3ruCdV5aSrmllHJzKeW/VrVNCRoA0LwRjQZopZSRST6bZFKSOUmuK6WcV2u9ZdA6OyY5KcnetdYHSiljV7VdCRoAwOrbK8nsWuvPa60LknwjydRl1vmbJJ+ttT6QJLXW+avaqAINAGheKaXL1zGllFmDXscMGtqWSe4e9H7OwGeD/UWSvyilfL+Uck0pZcqq9leLEwBgJWqt05JM+xM2MSrJjkn2T7JVkitKKbvWWh9c0RckaAAAq29ukgmD3m818Nlgc5KcV2tdWGv9RZKfpr9gWyEFGgDQvFK6e63CdUl2LKVsW0oZneTlSc5bZp1vpz89Synlqelvef58ZRtVoAEArKZa66IkxyaZmeTWJN+std5cSjmllHLEwGozk9xfSrklyaVJ3l1rvX9l23UNGgDQvJJG77ORpNY6I8mMZT57/6C/a5K/HXgNiQQNAKAxEjQAoHmt3qh2uEjQAAAao0ADAGiMFicA0LwyhPtdrE0kaAAAjZGgAQDN67EATYIGANAaBRoAQGO0OAGA5o3osR6nBA0AoDESNACgeT0WoEnQAABaI0EDAJrnRrUAAHRKgQYA0BgtTgCgeT3W4ZSgAQC0RoIGADTPjWoBAOiUAg0AoDFanABA83qrwSlBAwBojgQNAGieJwkAANApCRoA0LwRvRWgSdAAAFqjQAMAaIwWJwDQPJMEAADolAQNAGhejwVoEjQAgNZI0ACA5rkGDQCATinQAAAao8UJADSv154ksMICrZTyb0nqipbXWt8xLCMCAOhxK0vQZq2xUQAArESvTRJYYYFWa/3K4PellCfXWv8w/EMCAOhtq5wkUEp5finlliS3Dbx/VinltGEfGQBAjxrKLM5/TTI5yf1JUmv9SZJ9h3NQAACDlQ5fXRjSbTZqrXcv81HfMIwFAIAM7TYbd5dSXpCkllLWSXJ8kluHd1gAAI8Z0WOTBIaSoL0lyduTbJnkniTPHngPAMAwWGWCVmv9dZJXrYGxAAAsV48FaEOaxbldKeU7pZT7SinzSynnllK2WxODAwDoRUNpcf5Xkm8m2TzJFknOTPL14RwUAEAvG0qB9uRa61drrYsGXv+ZZN3hHhgAwGKllM5eXVjZszg3HfjzglLKe5N8I/3P5nxZkhlrYGwAAD1pZZMEfpj+gmxx6fjmQctqkpOGa1AAAIP12iSBlT2Lc9s1ORAAAPoN5Ua1KaXskmSnDLr2rNb6H8M1KACAwXrtRrWrLNBKKf+YZP/0F2gzkhyc5KokCjQAgGEwlFmcL0lyYJJ7a62vT/KsJGOGdVQAAD1sKAXaI7XWR5MsKqVslGR+kgnDOyyW5/tXXZkjD5+SIw45KF86fdrjli9YsCAnnvCuHHHIQXnNK1+ae+bOSZI8+OAD+Zs3vDYv2Gu3fOgDpyx328cf99a85KjDh3X8rH0mPe8v85Mz35ObznpvTnjtAY9bvvX4TTLjs2/OtV/728z83Fuz5dj+/7bbd/ftc81/vmvJ64ErP5jD99t5TQ+fJ7jvX3Vljho4J/77Ks6Jr13mnHjMG16bvZc5J/7+9w/n5S85cslr4j7Py0c/fOoa2x9WrpTuXl0YyjVos0opGyf5Yvpndj6c5OphHRWP09fXlw994JR8btqXMm78uLzq5UdnvwMmZvvtd1iyzrfP/lY23GijnDfjolx4wfR86pMfz4c/9sk8afST8rZjj8/s2T/LHT/76eO2ffH3LsqT13vymtwd1gIjRpT863uOyqHHTsvc+Q/lqq8cn/OvvCW3/WLeknU+ePxh+dqMH+Zr02dlvz12yClvOyRv/Kev54of3pHnvfqTSZJNNlovN511Ur53zeOPTViRvr6+fPgDp+S0gXPiqwfOidstc07caOCcOHOZc+Jbjz0+d8z+WWYPOieuv/4G+ca3vr3k/Stf+qJMPHDSGt0vWGyVCVqt9W211gdrrZ9PMinJXw+0OlmDbrrxhkzYeutsNWFC1llndCYffEguu/Tipda57NKLc/gRRyZJXjhpcq79wdWptWa9Jz85z9lt9zxp9OjHbfcPf/h9/vM/vpw3vfmta2Q/WHvsufPWuWPO/bnznt9k4aK+nHnRj3PYvkunYE/fdlwuv+5nSZLLZ81+3PIkOWriM3PR1bflkf9buEbGzdrhphtvyFZDOCceNnBOPHDS5Fy3zDlx9HLOiYv98s5f5IHf/Ca77b7HsO4HQ9drN6pdYYFWStlt2VeSTZOMGvh7tZRSFHerYf78eRk3fvMl78eNG5/75s1bZp35GT+wzqhRo7LBBhvmwQcfXOl2T/u3T+c1f/36rLeuh0Pwx9liszGZM++x42vu/Aez5WZLX55648/uydQDdk2STN1/l2y0wbrZdMzSae3RBz0n37zoR8M/YNYq982ft+R8lyRjx43P/GXOifetxjlxsZkXzMhBUw7u7P+cYWUJ2sdX8vrYn/Cb/29FC0opx5RSZpVSZi3vGiv+vG6/7dbcPecuET7D5qRPnZ99dts+V3/1Xdlnt+0zd96D6et7dMny8U/ZMDtvPz7fvfr2DkcJjzfzwhmZfPChXQ+DHrayG9U+/orfISql3LCiRUnGreQ3pyWZliR/WFDr6v7+2mjs2HGZd++vlryfN+/ebDZu3DLrjM299/4q48aPz6JFi/Lww7/LxhtvvMJt/uQnP84tN9+UQyZPTN+ivvzmN7/Jm17/mpz+718dtv1g7XHPfQ9lq3GPHV9bjt04c+97aKl1fvXr3+blJ34lSbL+eqNz5AG75qGH/3fJ8he/8Fk577KbsmhQ0QZDsdnYcbl30Dlx/rx7M3aZc+Jmf+Q5cbGf3n5b+voWZaedd/mzj5vVN5RZjWuT4drfcUlem+Tw5bzuH6bfXKvtvMuuueuXv8zcOXOycOGCzLxgRvbff+JS6+y3/8R857z+C1y/992Z2XOv5600nn/py16R715yZWbMvCT//h9fyzZPe5rijCGbdcvd2WHCU7PNFptmnVEjc/RBz870K29eap2njHnykmPw3a+bmK9857qllr9Ue5PVtPMuu+buZc6J+y3nnHj+wDnx4iGcExe7cMZ06RmdG9KTBFbD+Uk2qLX+eNkFpZTLhuk312qjRo3KiX9/ct72ljfm0b5HM/WoF2f7HXbMaZ/5dHbaeZfsf8DEHPmil+QfTnpPjjjkoGw0Zkw+9JFPLPn+IZMn5vcP/z4LFy7MpZdcnNOmnbHUDFD4Y/X1PZp3ffScfOfTf5ORI0q+8p3rcuvP5+XkYybn+lvvzvQrb8m+u++QU952cGqSq37087zzI2cv+f7Wm2+SrcZtnCuv/3l3O8ET1uJz4tsHzolHDJwTPzdwTtxv4Jx48sA5ccyYMfngoHPioYPOiZcNnBMXzwD97swL8unTXGbTml67HrDURjuJWpy04Cl/9e6uhwBJkl9f9dGuhwBJkvVHd1MpvePbt3VWF3z6yKev8X0eyqOeSpJXJdmu1npKKWXrJONrrdcO++gAAJKM6K0AbUjXoJ2W5PlJXjHw/ndJPjtsIwIA6HFDuQbtubXW3UopP0qSWusDpZQV390PAIA/yVAKtIWllJFJapKUUjZLYk48ALDGaHE+3qeTnJNkbCnlA0muSuLpsQAAw2SVCVqt9WullB8mOTD9N5o9stZ667CPDABgQK/dZmMoszi3TvKHJN8Z/Fmt9a7hHBgAQK8ayjVo09N//VlJsm6SbZPcnmTnYRwXAEDPGkqLc9fB70spuyV527CNCABgGSYJrEKt9fokzx2GsQAAkKFdg/a3g96OSLJbknuGbUQAAMvosTkCQ7oGbcNBfy9K/zVpZw3PcAAAWGmBNnCD2g1rrSesofEAADzOiB6L0FZ4DVopZVSttS/J3mtwPAAAPW9lCdq16b/e7MellPOSnJnk94sX1lrPHuaxAQD0pKFcg7ZukvuTTMxj90OrSRRoAMAa8UffduIJbmUF2tiBGZw35bHCbLE6rKMCAOhhKyvQRibZIEsXZosp0ACANabH5gistED7Va31lDU2EgAAkqy8QOuxWhUAaJXbbDzmwDU2CgAAllhhgVZr/c2aHAgAAP2GcpsNAIBO9ViHs+duKwIA0DwJGgDQvBESNAAAuqRAAwBojBYnANA890EDAKBTEjQAoHk9FqBJ0AAAWiNBAwCa5zYbAAB0SoEGANAYLU4AoHklvdXjlKABADRGggYANM8kAQAAOiVBAwCaJ0EDAKBTCjQAgMZocQIAzSs99jBOCRoAQGMkaABA80wSAACgUwo0AIDGaHECAM3rsTkCEjQAgNZI0ACA5o3osQhNggYA0BgJGgDQPLfZAABgyEopU0opt5dSZpdS3ruS9V5cSqmllD1WtU0FGgDAaiqljEzy2SQHJ9kpyStKKTstZ70Nkxyf5AdD2a4CDQBoXindvVZhrySza60/r7UuSPKNJFOXs94/J/lwkv8dyv4q0AAAVqKUckwpZdag1zGDFm+Z5O5B7+cMfDb4+7slmVBrnT7U3zRJAABo3oh0N0ug1jotybTV+W4pZUSSTyR53R/zPQkaAMDqm5tkwqD3Ww18ttiGSXZJclkp5c4kz0ty3qomCkjQAIDmNXyf2uuS7FhK2Tb9hdnLk7xy8cJa60NJnrr4fSnlsiQn1FpnrWyjEjQAgNVUa12U5NgkM5PcmuSbtdabSymnlFKOWN3tStAAAP4EtdYZSWYs89n7V7Du/kPZpgINAGieJwkAANApCRoA0LwRDc8SGA4SNACAxijQAAAao8UJADSvxzqcEjQAgNZI0ACA5pkkAABApyRoAEDzeixAk6ABALRGgQYA0BgtTgCgeb2WKPXa/gIANE+CBgA0r/TYLAEJGgBAYxRoAACN0eIEAJrXWw1OCRoAQHMkaABA8zyLEwCATknQAIDm9VZ+JkEDAGiOAg0AoDFanABA83psjoAEDQCgNRI0AKB5nsUJAECnJGgAQPN6LVHqtf0FAGieAg0AoDFanABA80wSAACgUxI0AKB5vZWfSdAAAJqjQAMAaEyzLc5euxiQNj3wPx/regiQJNlkz2O7HgIkSR750Wc6+d1eqwskaAAAjWk2QQMAWKzXEqVe218AgOZJ0ACA5rkGDQCATinQAAAao8UJADSvtxqcEjQAgOZI0ACA5vXYHAEJGgBAayRoAEDzRvTYVWgSNACAxijQAAAao8UJADTPJAEAADolQQMAmldMEgAAoEsKNACAxmhxAgDNM0kAAIBOSdAAgOZ5kgAAAJ2SoAEAzXMNGgAAnVKgAQA0RosTAGieFicAAJ2SoAEAzfMsTgAAOqVAAwBojBYnANC8Eb3V4ZSgAQC0RoIGADTPJAEAADolQQMAmudGtQAAdEqBBgDQGC1OAKB5JgkAANApCRoA0Dw3qgUAoFMSNACgea5BAwCgUwo0AIDGaHECAM3zJAEAADolQQMAmtdjAZoEDQCgNQo0AIDGaHECAM0b0WOzBCRoAACNkaABAM3rrfxMggYA0BwJGgDQvh6L0CRoAACNUaABADRGixMAaF7psR6nBA0AoDESNACgeT12n1oJGgBAayRoAEDzeixAk6ABALRGgQYA0BgtTgCgfT3W45SgAQA0RoIGADTPjWoBAOiUAg0AoDFanABA8zxJAACATknQAIDm9ViAJkEDAGiNBA0AaF+PRWgSNACAxijQAAAao8UJADTPkwQAAOiUAg0AaF4p3b1WPbYypZRyeylldinlvctZ/rellFtKKTeUUi4upWyzqm0q0AAAVlMpZWSSzyY5OMlOSV5RStlpmdV+lGSPWuszk3wryUdWtV0FGgDA6tsryexa689rrQuSfCPJ1MEr1FovrbX+YeDtNUm2WtVGFWgAQPNKl69SjimlzBr0OmbQ0LZMcveg93MGPluRNya5YFX7axYnAMBK1FqnJZn2p26nlPLqJHsk2W9V6yrQAID2tXuXjblJJgx6v9XAZ0sppbwwyfuS7Fdr/b9VbVSLEwBg9V2XZMdSyrallNFJXp7kvMErlFKek+QLSY6otc4fykYlaABA81q9UW2tdVEp5dgkM5OMTPKlWuvNpZRTksyqtZ6X5KNJNkhyZum/b8ddtdYjVrZdBRoAwJ+g1jojyYxlPnv/oL9f+MduU4sTAKAxEjQAoHlDuaP/2kSCBgDQGAkaANC8HgvQJGgAAK2RoAEA7euxCE2CBgDQGAUaAEBjtDgBgOa1+iSB4SJBAwBojAQNAGieG9XSlO9fdUWmHjY5hx88KV86fdrjli9YsCDv+bt35vCDJ+XVrzg6c+fOWbLsjC9+IYcfPClTD5uc//n+lUmSO3/x87z0xVOXvPZ+7m75z69+OUnyuQtKJ04AABBDSURBVM/+WyZN3GfJsiuvuHyN7CPt+/6VV+SIQyfnsCmTcsYXl38cvvvv3pnDpkzKq17++OPwsCmTcsShk/P9q65c8vn7/+Gk7L/P8/OiqYctta1PfOzDmXrYlLzkqMPzzne8Pb/97W+Hb8dYa0x6wTPyk3NOzk3n/mNOeP2kxy3fevNNMuPzx+Xa/z4pM794fLYcu/GSZf/yjqmZdebfZ9aZf5+XHLTbmhw2rJACrWF9fX354L+cks9+7vScfd70XDjj/Nxxx+yl1jnn7DOz0UYb5TsXfDevfs3r8qlPfCxJcscdszPzguk569zpOe3zp+fUf/5/6evry9O23S7fPOvcfPOsc/P1b56dddddLxMPfOxk9urXvG7J8n323W+N7i9t6uvry6kfOCWnff70nLP4OJy9zHF4Vv9xeP6F382rX/u6/Ovi43D27Fw4Y3rOPm96TvvC6Tn1X/qPwySZeuSL8rkvnP6433ve8/fOWd8+P9865zvZZpun5YwvfmH4d5IntBEjSv71vS/N1GNPy3Ne/C85esruefp245da54PvOipfm35t9nrZB3PqtAtyynFHJEmm/NXOefYzJuS5L/9Q9n3Nx/LO1x6YDddft4vdgKUMW4FWSnl6KeXAUsoGy3w+Zbh+c21z0403ZMLW22SrCROyzjqjM/ngQ3PZJRcvtc5ll1ySw6celSR54UGTc+0Prk6tNZddcnEmH3xoRo8enS23mpAJW2+Tm268Yanv/uCaq7PVhAnZYost19g+8cRz0403ZMKEgeNw9OhMOeTQXHbp0sfhpZdckiMGjsNJB03OtdcMHIeXXpwph/Qfh1ttNSETJjx2HO6+x57ZaMyYx/3eC/b+q4wa1X/1xTOf9ezMn3fvMO8hT3R77vK03HH3r3Pn3PuzcFFfzpx5fQ7b/5lLrfP07TbP5dfeniS5/Lqf5rD9d02SPGO78bnq+tnp63s0f/jfBbnxZ3Nz0Auescb3gVUrHb66MCwFWinlHUnOTXJckptKKVMHLT51OH5zbTR//ryMH//YfwWOGzcu8+fPW846mydJRo0alQ022DAPPvjAkL4784LpOfiQpdtL3/j613L0UYfnH//hpPz2oYf+3LvEE9D8efMyfvPHjqWx48Zl3rxVHIcb9h+H8+bNy7jBx+H4cZm/zHdX5ttnn5W999n3T9wD1nZbjB2TOfMeWPJ+7rwHsuVmSxf/N/50bqZOfHaSZOrEZ2WjDdbLpmPWzw0/7S/I1lt3nTxl4/Wz3x5/ka3Gb7JGxw/LM1wJ2t8k2b3WemSS/ZOcXEo5fmDZCovRUsoxpZRZpZRZZyzneiv+fBYuXJDLL7skkw56LNB86ctekfMv+G7++6xz89TNxubjH/1QhyOk133xC5/LyFEjc+hhR3Q9FNYCJ33ynOyz+w65+usnZp/dd8jceQ+kr+/RXHzNbbnwqlty6Zf/Ll/54Ovzgxt+kb6+R7seLsvTYxHacM3iHFFrfThJaq13llL2T/KtUso2Wcmu1lqnJZmWJI8sTB2msT1hjB07Lvfe+1h7Z968eRk7dtxy1vlVxo0fn0WLFuXhh3+XjTfeZJXfverKK/L0Z+ycpzz1qUs+G/z3i15ydN7x9rcMx27xBDN23Ljc+6vHjqX58+Zl3LhVHIe/6z8Ox40bl3mDj8N752XsMt9dnnPPOTtXXH5Zpp3x5ZRem7rFH+2e+Q9lq3GPpV5bjtskc+9bugPwq/seystP6L/mcf31RufIA5+dhx5+JEnykTNm5iNnzEySfPnU1+Vnd81fQyOHFRuuBG1eKeXZi98MFGuHJXlqkl2H6TfXOjvvsmvuuuvOzJ1zdxYuXJCZF0zPfgdMXGqd/Q6YmO+ce06S5HsXzcyez31eSinZ74CJmXnB9CxYsCBz59ydu+66M7vs+tg1GRfOmJ4phxy61Lbuu++xk9IlF38vO+yw4zDuHU8Ui4/DOXPuzsIFC3LhjMcfh/sfMDHnDRyH371oZvYadBxeOKP/OJyznONweb5/5RX58pdOz6c+87mst956w7ZfrD1m3fzL7LD1Ztlmi6dknVEjc/Tk3TL9sqWvuX3KxusvKfbf/YbJ+cq51yTpn2Cw6Zj1kyS77LhFdtlxi3zv6tvW7A4wJKXD/3VhuBK01yZZNPiDWuuiJK8tpZiSNUSjRo3Ke//+/Xnrm9+UR/v6MvWoF2eHHXbMaZ/5VHbaeZfsf8CBOepFL8n7Tnp3Dj94UjYaMyYf/ugnkyQ77LBjJk0+OC864pCMHDUyJ73v/Rk5cmSS5JE//CHXXP0/+Yd/PGWp3/vXj380t99+W0qSLbbc8nHL6U2jRo3KSe97f956zJvy6KN9OXLgOPzsv30qO++8S/afeGCOevFL8r73vjuHTek/Dj/ysceOw4OmHJyjjjgkI0eOzN//w2PH4Ykn/G1mXXdtHnzwgUyauG/e+vbj8qIXH50PfuCfs2DhgrzlTa9Pkuz6rGflZMciK9HX92je9eFv5junvT0jR5R85dxrcuvP783Jbz00199yV6ZffmP23WPHnHLcEak1uer62XnnB7+ZJFln1Mh870vvTJL87uH/zRve9xUtTppQam2zk6jFSQt012jFJnse2/UQIEnyyI8+08mZ8bZf/aGzuuDpmz95je+zJwkAAM3rtf9gdqNaAIDGSNAAgOb1WIAmQQMAaI0EDQBoX49FaBI0AIDGKNAAABqjxQkANK+rO/p3RYIGANAYCRoA0Dw3qgUAoFMKNACAxmhxAgDN67EOpwQNAKA1EjQAoH09FqFJ0AAAGiNBAwCa50a1AAB0SoEGANAYLU4AoHmeJAAAQKckaABA83osQJOgAQC0RoEGANAYLU4AoH091uOUoAEANEaCBgA0z5MEAADolAQNAGieG9UCANApBRoAQGO0OAGA5vVYh1OCBgDQGgkaANA8kwQAAOiUBA0AeALorQhNggYA0BgFGgBAY7Q4AYDmmSQAAECnJGgAQPN6LECToAEAtEaBBgDQGC1OAKB5JgkAANApCRoA0LzSY9MEJGgAAI2RoAEA7eutAE2CBgDQGgUaAEBjtDgBgOb1WIdTggYA0BoJGgDQPDeqBQCgUxI0AKB5blQLAECnFGgAAI3R4gQA2tdbHU4JGgBAayRoAEDzeixAk6ABALRGgQYA0BgtTgCgeZ4kAABApyRoAEDzPEkAAIBOSdAAgOa5Bg0AgE4p0AAAGqNAAwBojAINAKAxJgkAAM0zSQAAgE5J0ACA5rlRLQAAnVKgAQA0RosTAGieSQIAAHRKggYANK/HAjQJGgBAaxRoAACN0eIEANrXYz1OCRoAQGMkaABA8zxJAACATknQAIDmuVEtAACdUqABADRGixMAaF6PdTglaAAArZGgAQDt67EITYIGANAYBRoAQGO0OAGA5nmSAAAAQ1ZKmVJKub2UMruU8t7lLH9SKeW/B5b/oJTytFVtU4EGADSvlO5eKx9XGZnks0kOTrJTkleUUnZaZrU3Jnmg1rpDkk8m+fCq9leBBgCw+vZKMrvW+vNa64Ik30gydZl1pib5ysDf30pyYCkrL/2avQZtvXV6rNk8DEopx9Rap3U9DnAs/uke+dFnuh7CE57j8Ilt3VHd1QWllGOSHDPoo2mDjqUtk9w9aNmcJM9dZhNL1qm1LiqlPJTkKUl+vaLflKCt3Y5Z9SqwRjgWaYHjkNVSa51Wa91j0GvYC30FGgDA6pubZMKg91sNfLbcdUopo5KMSXL/yjaqQAMAWH3XJdmxlLJtKWV0kpcnOW+Zdc5L8tcDf78kySW11rqyjTZ7DRp/Fq61oBWORVrgOOTPbuCasmOTzEwyMsmXaq03l1JOSTKr1npekjOSfLWUMjvJb9JfxK1UWUUBBwDAGqbFCQDQGAUaAEBjFGhrqVU9dgLWhFLKl0op80spN3U9FnpXKWVCKeXSUsotpZSbSynHdz0mWBXXoK2FBh478dMkk9J/w7zrkryi1npLpwOj55RS9k3ycJL/qLXu0vV46E2llM2TbF5rvb6UsmGSHyY50jmRlknQ1k5DeewEDLta6xXpn7EEnam1/qrWev3A379Lcmv67+wOzVKgrZ2W99gJJyOg55VSnpbkOUl+0O1IYOUUaAD0hFLKBknOSvLOWutvux4PrIwCbe00lMdOAPSMUso66S/OvlZrPbvr8cCqKNDWTkN57ARATyillPTfyf3WWusnuh4PDIUCbS1Ua12UZPFjJ25N8s1a683djopeVEr5epKrk/xlKWVOKeWNXY+JnrR3ktckmVhK+fHA65CuBwUr4zYbAACNkaABADRGgQYA0BgFGgBAYxRoAACNUaABADRGgQZroVJK38CtBG4qpZxZSnnyn7CtL5dSXjLw9+mllJ1Wsu7+pZQXrMZv3FlKeepQP19mnYf/yN/6p1LKCX/sGAHWJAUarJ0eqbU+u9a6S5IFSd4yeGEpZdTqbLTW+qZa6y0rWWX/JH90gQbA0hRosPa7MskOA+nWlaWU85LcUkoZWUr5aCnlulLKDaWUNyf9d10vpXymlHJ7KeV7ScYu3lAp5bJSyh4Df08ppVxfSvlJKeXigYdQvyXJuwbSu31KKZuVUs4a+I3rSil7D3z3KaWUi0opN5dSTk9SVrUTpZRvl1J+OPCdY5ZZ9smBzy8upWw28Nn2pZQLB75zZSnl6X+Of5gAa8Jq/Vc08MQwkJQdnOTCgY92S7JLrfUXA0XOQ7XWPUspT0ry/VLKRUmek+Qvk+yUZFySW5J8aZntbpbki0n2HdjWprXW35RSPp/k4VrrxwbW+68kn6y1XlVK2Tr9T7d4RpJ/THJVrfWUUsqhSYbyhIE3DPzGekmuK6WcVWu9P8n6SWbVWt9VSnn/wLaPTTItyVtqrT8rpTw3yWlJJq7GP0aANU6BBmun9UopPx74+8r0P4fwBUmurbX+YuDzg5I8c/H1ZUnGJNkxyb5Jvl5r7UtyTynlkuVs/3lJrli8rVrrb1Ywjhcm2an/UYhJko1KKRsM/MaLBr47vZTywBD26R2llKMG/p4wMNb7kzya5L8HPv/PJGcP/MYLkpw56LefNITfAGiCAg3WTo/UWp89+IOBQuX3gz9KclytdeYy6/05n1E4Isnzaq3/u5yxDFkpZf/0F3vPr7X+oZRyWZJ1V7B6HfjdB5f9ZwDwROEaNOhdM5O8tZSyTpKUUv6ilLJ+kiuSvGzgGrXNkxywnO9ek2TfUsq2A9/ddODz3yXZcNB6FyU5bvGbUsrigumKJK8c+OzgJJusYqxjkjwwUJw9Pf0J3mIjkixOAV+Z/tbpb5P8opRy9MBvlFLKs1bxGwDNUKBB7zo9/deXXV9KuSnJF9Kfqp+T5GcDy/4jydXLfrHWel+SY9LfTvxJHmsxfifJUYsnCSR5R5I9BiYh3JLHZpP+v/QXeDenv9V51yrGemGSUaWUW5N8KP0F4mK/T7LXwD5MTHLKwOevSvLGgfHdnGTqEP6ZADSh1Fq7HgMAAINI0AAAGqNAAwBojAINAKAxCjQAgMYo0AAAGqNAAwBojAINAKAx/x/0/slnTQHnmQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7fcxLuwZpkK",
        "outputId": "e65ca065-6e20-4e1d-b896-07145ec32f38"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "82b577e7-b6e9-4e5c-f57e-7c91688edba1"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 52ms/step - loss: 1.1146 - accuracy: 0.5705 - val_loss: 0.9603 - val_accuracy: 0.6153\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9125 - accuracy: 0.6255 - val_loss: 0.8869 - val_accuracy: 0.6153\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9142 - accuracy: 0.6278 - val_loss: 0.8754 - val_accuracy: 0.6153\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9047 - accuracy: 0.6282 - val_loss: 0.8665 - val_accuracy: 0.6153\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8944 - accuracy: 0.6285 - val_loss: 0.8621 - val_accuracy: 0.6153\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8825 - accuracy: 0.6320 - val_loss: 0.8670 - val_accuracy: 0.6153\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8887 - accuracy: 0.6223 - val_loss: 0.8582 - val_accuracy: 0.6153\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8653 - accuracy: 0.6366 - val_loss: 0.8561 - val_accuracy: 0.6153\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8558 - accuracy: 0.6359 - val_loss: 0.8456 - val_accuracy: 0.6153\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8682 - accuracy: 0.6348 - val_loss: 0.8393 - val_accuracy: 0.6153\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8530 - accuracy: 0.6341 - val_loss: 0.8364 - val_accuracy: 0.6166\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8433 - accuracy: 0.6308 - val_loss: 0.8330 - val_accuracy: 0.6193\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8435 - accuracy: 0.6370 - val_loss: 0.8310 - val_accuracy: 0.6166\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8440 - accuracy: 0.6318 - val_loss: 0.8456 - val_accuracy: 0.6166\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8442 - accuracy: 0.6310 - val_loss: 0.8022 - val_accuracy: 0.6300\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8303 - accuracy: 0.6340 - val_loss: 0.8112 - val_accuracy: 0.6233\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8341 - accuracy: 0.6304 - val_loss: 0.8044 - val_accuracy: 0.6247\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8167 - accuracy: 0.6333 - val_loss: 0.7881 - val_accuracy: 0.6260\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8096 - accuracy: 0.6424 - val_loss: 0.8213 - val_accuracy: 0.6206\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8138 - accuracy: 0.6446 - val_loss: 0.7808 - val_accuracy: 0.6367\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7843 - accuracy: 0.6438 - val_loss: 0.7837 - val_accuracy: 0.6394\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7807 - accuracy: 0.6580 - val_loss: 0.7739 - val_accuracy: 0.6394\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7637 - accuracy: 0.6519 - val_loss: 0.7688 - val_accuracy: 0.6421\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7691 - accuracy: 0.6562 - val_loss: 0.7587 - val_accuracy: 0.6421\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7777 - accuracy: 0.6435 - val_loss: 0.7433 - val_accuracy: 0.6434\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7588 - accuracy: 0.6597 - val_loss: 0.7381 - val_accuracy: 0.6568\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7337 - accuracy: 0.6643 - val_loss: 0.7376 - val_accuracy: 0.6515\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7362 - accuracy: 0.6686 - val_loss: 0.7400 - val_accuracy: 0.6408\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7357 - accuracy: 0.6586 - val_loss: 0.7138 - val_accuracy: 0.6810\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7308 - accuracy: 0.6704 - val_loss: 0.7325 - val_accuracy: 0.6515\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.7281 - accuracy: 0.6678 - val_loss: 0.6631 - val_accuracy: 0.6810\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7069 - accuracy: 0.6736 - val_loss: 0.6728 - val_accuracy: 0.6850\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7051 - accuracy: 0.6735 - val_loss: 0.6760 - val_accuracy: 0.6863\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6968 - accuracy: 0.6800 - val_loss: 0.6527 - val_accuracy: 0.6823\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6807 - accuracy: 0.6881 - val_loss: 0.6759 - val_accuracy: 0.6890\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6980 - accuracy: 0.6809 - val_loss: 0.6636 - val_accuracy: 0.6997\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6693 - accuracy: 0.6912 - val_loss: 0.6332 - val_accuracy: 0.7105\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6566 - accuracy: 0.6979 - val_loss: 0.6213 - val_accuracy: 0.7172\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6319 - accuracy: 0.7106 - val_loss: 0.6419 - val_accuracy: 0.6997\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6217 - accuracy: 0.7137 - val_loss: 0.6308 - val_accuracy: 0.7024\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6094 - accuracy: 0.7234 - val_loss: 0.5854 - val_accuracy: 0.7225\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5984 - accuracy: 0.7283 - val_loss: 0.5777 - val_accuracy: 0.7547\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5778 - accuracy: 0.7364 - val_loss: 0.5726 - val_accuracy: 0.7507\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5768 - accuracy: 0.7365 - val_loss: 0.5947 - val_accuracy: 0.7466\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5537 - accuracy: 0.7517 - val_loss: 0.5342 - val_accuracy: 0.7547\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5429 - accuracy: 0.7571 - val_loss: 0.5455 - val_accuracy: 0.7534\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5373 - accuracy: 0.7639 - val_loss: 0.5370 - val_accuracy: 0.7694\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5261 - accuracy: 0.7680 - val_loss: 0.5503 - val_accuracy: 0.7788\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5075 - accuracy: 0.7709 - val_loss: 0.5207 - val_accuracy: 0.7721\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4826 - accuracy: 0.7885 - val_loss: 0.5222 - val_accuracy: 0.7761\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4539 - accuracy: 0.7975 - val_loss: 0.5431 - val_accuracy: 0.7842\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4547 - accuracy: 0.7975 - val_loss: 0.5128 - val_accuracy: 0.7869\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4334 - accuracy: 0.8100 - val_loss: 0.4430 - val_accuracy: 0.8097\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4023 - accuracy: 0.8311 - val_loss: 0.4469 - val_accuracy: 0.8164\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.3839 - accuracy: 0.8402 - val_loss: 0.4225 - val_accuracy: 0.8378\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3779 - accuracy: 0.8374 - val_loss: 0.3972 - val_accuracy: 0.8351\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3547 - accuracy: 0.8522 - val_loss: 0.4374 - val_accuracy: 0.8217\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3409 - accuracy: 0.8635 - val_loss: 0.4028 - val_accuracy: 0.8257\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3140 - accuracy: 0.8717 - val_loss: 0.3672 - val_accuracy: 0.8660\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3007 - accuracy: 0.8770 - val_loss: 0.3279 - val_accuracy: 0.8566\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2999 - accuracy: 0.8797 - val_loss: 0.1509 - val_accuracy: 0.9397\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2822 - accuracy: 0.8943 - val_loss: 0.1493 - val_accuracy: 0.9464\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2679 - accuracy: 0.8985 - val_loss: 0.1367 - val_accuracy: 0.9531\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2531 - accuracy: 0.9079 - val_loss: 0.1071 - val_accuracy: 0.9651\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2187 - accuracy: 0.9188 - val_loss: 0.1820 - val_accuracy: 0.9263\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2194 - accuracy: 0.9192 - val_loss: 0.1039 - val_accuracy: 0.9611\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2014 - accuracy: 0.9273 - val_loss: 0.0894 - val_accuracy: 0.9678\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1927 - accuracy: 0.9270 - val_loss: 0.1015 - val_accuracy: 0.9651\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1728 - accuracy: 0.9359 - val_loss: 0.1078 - val_accuracy: 0.9625\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1595 - accuracy: 0.9446 - val_loss: 0.0791 - val_accuracy: 0.9732\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1518 - accuracy: 0.9465 - val_loss: 0.0972 - val_accuracy: 0.9665\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1622 - accuracy: 0.9420 - val_loss: 0.0997 - val_accuracy: 0.9584\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1220 - accuracy: 0.9589 - val_loss: 0.0711 - val_accuracy: 0.9759\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1535 - accuracy: 0.9458 - val_loss: 0.0945 - val_accuracy: 0.9651\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1196 - accuracy: 0.9623 - val_loss: 0.0798 - val_accuracy: 0.9705\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1182 - accuracy: 0.9586 - val_loss: 0.0639 - val_accuracy: 0.9759\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1167 - accuracy: 0.9589 - val_loss: 0.0612 - val_accuracy: 0.9826\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1071 - accuracy: 0.9627 - val_loss: 0.1069 - val_accuracy: 0.9651\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1072 - accuracy: 0.9638 - val_loss: 0.0580 - val_accuracy: 0.9812\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1007 - accuracy: 0.9635 - val_loss: 0.0385 - val_accuracy: 0.9893\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0905 - accuracy: 0.9694 - val_loss: 0.0584 - val_accuracy: 0.9786\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0881 - accuracy: 0.9706 - val_loss: 0.0402 - val_accuracy: 0.9839\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0885 - accuracy: 0.9712 - val_loss: 0.0705 - val_accuracy: 0.9759\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0855 - accuracy: 0.9694 - val_loss: 0.0564 - val_accuracy: 0.9812\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0821 - accuracy: 0.9724 - val_loss: 0.0514 - val_accuracy: 0.9826\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0790 - accuracy: 0.9736 - val_loss: 0.0590 - val_accuracy: 0.9799\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0945 - accuracy: 0.9662 - val_loss: 0.0427 - val_accuracy: 0.9893\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0608 - accuracy: 0.9803 - val_loss: 0.0791 - val_accuracy: 0.9745\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0651 - accuracy: 0.9784 - val_loss: 0.0705 - val_accuracy: 0.9772\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0754 - accuracy: 0.9753 - val_loss: 0.0603 - val_accuracy: 0.9799\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0679 - accuracy: 0.9802 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0890 - accuracy: 0.9732 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0884 - accuracy: 0.9706 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0666 - accuracy: 0.9796 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0544 - accuracy: 0.9817 - val_loss: 0.0029 - val_accuracy: 0.9987\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0644 - accuracy: 0.9794 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0659 - accuracy: 0.9782 - val_loss: 0.0060 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0625 - accuracy: 0.9781 - val_loss: 0.0037 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0748 - accuracy: 0.9745 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0574 - accuracy: 0.9817 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0549 - accuracy: 0.9818 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0429 - accuracy: 0.9841 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0542 - accuracy: 0.9844 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0711 - accuracy: 0.9762 - val_loss: 0.0072 - val_accuracy: 0.9960\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0475 - accuracy: 0.9857 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0527 - accuracy: 0.9833 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0471 - accuracy: 0.9869 - val_loss: 0.0080 - val_accuracy: 0.9960\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0478 - accuracy: 0.9870 - val_loss: 0.0068 - val_accuracy: 0.9973\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0506 - accuracy: 0.9860 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0433 - accuracy: 0.9860 - val_loss: 0.0063 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0511 - accuracy: 0.9839 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0466 - accuracy: 0.9838 - val_loss: 0.0060 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0403 - accuracy: 0.9875 - val_loss: 0.0056 - val_accuracy: 0.9973\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0317 - accuracy: 0.9902 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0409 - accuracy: 0.9876 - val_loss: 0.0036 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0454 - accuracy: 0.9851 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0497 - accuracy: 0.9849 - val_loss: 0.0050 - val_accuracy: 0.9973\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0464 - accuracy: 0.9866 - val_loss: 0.0038 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0487 - accuracy: 0.9867 - val_loss: 0.0098 - val_accuracy: 0.9960\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0486 - accuracy: 0.9836 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0415 - accuracy: 0.9867 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0456 - accuracy: 0.9848 - val_loss: 1.6439e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0387 - accuracy: 0.9878 - val_loss: 4.9198e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0369 - accuracy: 0.9887 - val_loss: 1.3260e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0337 - accuracy: 0.9891 - val_loss: 2.4201e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0436 - accuracy: 0.9870 - val_loss: 3.9871e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0450 - accuracy: 0.9851 - val_loss: 0.0028 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0472 - accuracy: 0.9849 - val_loss: 1.7971e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0436 - accuracy: 0.9876 - val_loss: 6.2704e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0336 - accuracy: 0.9890 - val_loss: 4.7472e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0389 - accuracy: 0.9863 - val_loss: 0.0025 - val_accuracy: 0.9987\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0391 - accuracy: 0.9858 - val_loss: 1.3141e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0278 - accuracy: 0.9909 - val_loss: 4.3107e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0377 - accuracy: 0.9884 - val_loss: 0.0026 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0425 - accuracy: 0.9870 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0395 - accuracy: 0.9885 - val_loss: 0.0015 - val_accuracy: 0.9987\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0324 - accuracy: 0.9908 - val_loss: 1.8077e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0259 - accuracy: 0.9921 - val_loss: 8.0091e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0294 - accuracy: 0.9906 - val_loss: 4.4796e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0313 - accuracy: 0.9891 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0327 - accuracy: 0.9884 - val_loss: 5.4499e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0340 - accuracy: 0.9899 - val_loss: 2.5897e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0374 - accuracy: 0.9866 - val_loss: 1.7446e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0284 - accuracy: 0.9920 - val_loss: 5.5977e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0296 - accuracy: 0.9908 - val_loss: 1.8066e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0243 - accuracy: 0.9903 - val_loss: 9.8197e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0298 - accuracy: 0.9917 - val_loss: 3.8655e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0351 - accuracy: 0.9873 - val_loss: 6.8297e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0282 - accuracy: 0.9900 - val_loss: 9.1511e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0315 - accuracy: 0.9915 - val_loss: 3.1493e-04 - val_accuracy: 1.0000\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0354 - accuracy: 0.9894 - val_loss: 9.4480e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0336 - accuracy: 0.9893 - val_loss: 3.8262e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0269 - accuracy: 0.9912 - val_loss: 6.8358e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0386 - accuracy: 0.9887 - val_loss: 0.0017 - val_accuracy: 0.9987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 3.8835e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0310 - accuracy: 0.9893 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0319 - accuracy: 0.9903 - val_loss: 4.5155e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0351 - accuracy: 0.9897 - val_loss: 4.8527e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0312 - accuracy: 0.9896 - val_loss: 5.6871e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0270 - accuracy: 0.9909 - val_loss: 2.1183e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0308 - accuracy: 0.9888 - val_loss: 0.0098 - val_accuracy: 0.9973\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0303 - accuracy: 0.9911 - val_loss: 2.8084e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 3.5544e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0191 - accuracy: 0.9946 - val_loss: 7.3055e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0309 - accuracy: 0.9897 - val_loss: 0.0035 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0349 - accuracy: 0.9905 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0297 - accuracy: 0.9914 - val_loss: 8.6300e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0320 - accuracy: 0.9896 - val_loss: 5.7641e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0297 - accuracy: 0.9914 - val_loss: 1.0030e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 1.0807e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0242 - accuracy: 0.9933 - val_loss: 3.2312e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0202 - accuracy: 0.9928 - val_loss: 1.5062e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0218 - accuracy: 0.9933 - val_loss: 9.1560e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0279 - accuracy: 0.9915 - val_loss: 5.0854e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0211 - accuracy: 0.9934 - val_loss: 6.7346e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0263 - accuracy: 0.9920 - val_loss: 6.5298e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0327 - accuracy: 0.9917 - val_loss: 0.0065 - val_accuracy: 0.9960\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0270 - accuracy: 0.9899 - val_loss: 1.0390e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 3.2612e-04 - val_accuracy: 1.0000\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0235 - accuracy: 0.9917 - val_loss: 9.3267e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0282 - accuracy: 0.9906 - val_loss: 1.0767e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0267 - accuracy: 0.9915 - val_loss: 6.6504e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0296 - accuracy: 0.9915 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0368 - accuracy: 0.9885 - val_loss: 1.1019e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0181 - accuracy: 0.9943 - val_loss: 1.4602e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0252 - accuracy: 0.9928 - val_loss: 7.2243e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0277 - accuracy: 0.9902 - val_loss: 0.0019 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0257 - accuracy: 0.9921 - val_loss: 4.8448e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0389 - accuracy: 0.9882 - val_loss: 0.0029 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0173 - accuracy: 0.9946 - val_loss: 8.8662e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 2.0689e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0214 - accuracy: 0.9942 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0244 - accuracy: 0.9927 - val_loss: 9.2922e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0146 - accuracy: 0.9949 - val_loss: 1.1147e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0206 - accuracy: 0.9945 - val_loss: 9.0165e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0349 - accuracy: 0.9909 - val_loss: 1.1126e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0162 - accuracy: 0.9948 - val_loss: 2.0286e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0281 - accuracy: 0.9915 - val_loss: 1.7978e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0189 - accuracy: 0.9931 - val_loss: 3.7961e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0274 - accuracy: 0.9905 - val_loss: 2.9423e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0174 - accuracy: 0.9933 - val_loss: 0.0080 - val_accuracy: 0.9973\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0229 - accuracy: 0.9924 - val_loss: 3.9605e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0196 - accuracy: 0.9914 - val_loss: 6.1047e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 5.1575e-06 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0204 - accuracy: 0.9945 - val_loss: 2.5292e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0247 - accuracy: 0.9924 - val_loss: 1.4628e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 2.3509e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0274 - accuracy: 0.9915 - val_loss: 5.2602e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0153 - accuracy: 0.9934 - val_loss: 1.6916e-05 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0288 - accuracy: 0.9914 - val_loss: 1.4302e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0257 - accuracy: 0.9921 - val_loss: 1.1636e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0210 - accuracy: 0.9939 - val_loss: 1.0997e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 2.6721e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0238 - accuracy: 0.9933 - val_loss: 7.3882e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0205 - accuracy: 0.9943 - val_loss: 4.4923e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 2.5125e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0230 - accuracy: 0.9928 - val_loss: 6.6312e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 4.7939e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0296 - accuracy: 0.9918 - val_loss: 1.9365e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0192 - accuracy: 0.9946 - val_loss: 4.0202e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0251 - accuracy: 0.9928 - val_loss: 1.1681e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0141 - accuracy: 0.9963 - val_loss: 3.0659e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0185 - accuracy: 0.9949 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 3.7440e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0133 - accuracy: 0.9966 - val_loss: 1.0960e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0137 - accuracy: 0.9955 - val_loss: 1.3672e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 1.2323e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.0026 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0182 - accuracy: 0.9936 - val_loss: 8.0025e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0213 - accuracy: 0.9930 - val_loss: 7.6895e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 0.0022 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 1.3386e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0189 - accuracy: 0.9940 - val_loss: 7.0530e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0231 - accuracy: 0.9946 - val_loss: 0.0060 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0123 - accuracy: 0.9955 - val_loss: 6.5858e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0122 - accuracy: 0.9972 - val_loss: 5.4956e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 4.9199e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.0014 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 3.3768e-05 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0208 - accuracy: 0.9942 - val_loss: 4.4300e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0259 - accuracy: 0.9923 - val_loss: 1.3758e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0220 - accuracy: 0.9924 - val_loss: 3.8939e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0189 - accuracy: 0.9934 - val_loss: 2.5429e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0199 - accuracy: 0.9942 - val_loss: 7.4696e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0155 - accuracy: 0.9958 - val_loss: 1.9352e-06 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 6.6085e-06 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0199 - accuracy: 0.9937 - val_loss: 1.8699e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0125 - accuracy: 0.9951 - val_loss: 2.8868e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 5.8067e-06 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 2.2888e-06 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0191 - accuracy: 0.9942 - val_loss: 2.6526e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0159 - accuracy: 0.9946 - val_loss: 1.8614e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0161 - accuracy: 0.9955 - val_loss: 5.1271e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 7.4601e-06 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0086 - accuracy: 0.9978 - val_loss: 5.6430e-06 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 2.1485e-06 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 1.5421e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0187 - accuracy: 0.9942 - val_loss: 2.8425e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 1.7688e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0126 - accuracy: 0.9952 - val_loss: 6.7482e-06 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0162 - accuracy: 0.9954 - val_loss: 2.4867e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 1.4416e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0102 - accuracy: 0.9979 - val_loss: 1.0131e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0227 - accuracy: 0.9937 - val_loss: 1.0356e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0175 - accuracy: 0.9952 - val_loss: 1.0302e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0199 - accuracy: 0.9954 - val_loss: 1.4175e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0242 - accuracy: 0.9923 - val_loss: 5.2901e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0149 - accuracy: 0.9952 - val_loss: 2.4034e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 7.2178e-05 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0224 - accuracy: 0.9933 - val_loss: 9.1817e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 1.4930e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0161 - accuracy: 0.9942 - val_loss: 6.0242e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 1.0207e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0183 - accuracy: 0.9937 - val_loss: 3.3858e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0169 - accuracy: 0.9948 - val_loss: 1.3259e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 7.5307e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0216 - accuracy: 0.9943 - val_loss: 4.7816e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 9.5838e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 8.5610e-06 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0147 - accuracy: 0.9960 - val_loss: 3.2617e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0132 - accuracy: 0.9964 - val_loss: 1.1527e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 0.0014 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 2.9551e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 1.6237e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0118 - accuracy: 0.9957 - val_loss: 1.2808e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0097 - accuracy: 0.9967 - val_loss: 2.1507e-06 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 8.3759e-06 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0097 - accuracy: 0.9964 - val_loss: 6.3152e-06 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0204 - accuracy: 0.9940 - val_loss: 1.4506e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0193 - accuracy: 0.9936 - val_loss: 2.4983e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0184 - accuracy: 0.9948 - val_loss: 4.3876e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 5.5793e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0142 - accuracy: 0.9948 - val_loss: 5.6703e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 7.1436e-06 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 4.4816e-06 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0199 - accuracy: 0.9943 - val_loss: 7.5423e-06 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0110 - accuracy: 0.9972 - val_loss: 1.8458e-06 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0096 - accuracy: 0.9955 - val_loss: 1.6238e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 4.3484e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "183de249-a28d-4866-a14d-aedbe35ffa33"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 6ms/step - loss: 0.0285 - accuracy: 0.9930\n",
            "Accuracy  : 0.9930257797241211\n",
            "F1_Score  : 0.9910870127832493\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4c611c6d-ae97-4a4d-d3b8-86ac15fdce3a"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'#dominance\\nX_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\\nprint(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "437ec9f0-db8a-4b78-a7bd-9c4e1fae535e"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'foldNum=0\\nmodel = get_model()\\nfor train_index, val_index in kfold.split(X_train, Y_train):\\n  foldNum = foldNum + 1\\n  print(\"Results for fold\",foldNum)\\n  x_train, x_val = X_train[train_index], X_train[val_index]\\n  y_train, y_val = Y_train[train_index], Y_train[val_index]\\n  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\\n  gc.collect() # Garbage collecter\\n  del x_train, x_val, y_train, y_val\\n  gc.collect()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "85670922-c8bd-4eef-82e6-29e01cf540ab"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'acrc = model.evaluate(x_test, y_test)\\npred = model.predict(x_test)\\nf1scr = f1_score(y_test.argmax(1), pred.argmax(1), average=\\'macro\\')\\nc_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\\nprint(\"Accuracy  : {}\".format(acrc[1]))\\nprint(\"F1_Score  : {}\".format(f1scr))\\nc_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\\nimport seaborn as sns\\nfigure = plt.figure(figsize=(9, 9))\\nsns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\\nplt.tight_layout()\\nplt.ylabel(\\'True label\\')\\nplt.xlabel(\\'Predicted label\\')\\nplt.show()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}