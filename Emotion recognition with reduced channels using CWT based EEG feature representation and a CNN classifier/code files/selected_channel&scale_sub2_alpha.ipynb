{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub2_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "bc6c599f-31dd-4271-88fd-294efc95f2c0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e3\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  #EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "faa5d7e8-50fd-4e8b-bf9e-06c5741db6f7"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(2,3):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.2\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (2097,) (2563,) (4660,)\n",
            "(9320,) (3029,) (1398,) (4893,)\n",
            "(9320,) (2563,) (1165,) (5592,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "f425ebcb-e44f-4577-b183-d4af3046c4af"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "1d30273f-a485-4c8a-a80e-125af011070e"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "622"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "96c75181-b227-401b-b9af-3220add874aa"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a8e2a17-ea2d-4ab5-bcfa-ce32d4256b8e"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 50s 62ms/step - loss: 1.1422 - accuracy: 0.4489 - val_loss: 1.0609 - val_accuracy: 0.4866\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0576 - accuracy: 0.4908 - val_loss: 1.0495 - val_accuracy: 0.4866\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0470 - accuracy: 0.4976 - val_loss: 1.0464 - val_accuracy: 0.4866\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0503 - accuracy: 0.4979 - val_loss: 1.0445 - val_accuracy: 0.4866\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0466 - accuracy: 0.4965 - val_loss: 1.0421 - val_accuracy: 0.4866\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0403 - accuracy: 0.5059 - val_loss: 1.0418 - val_accuracy: 0.4866\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0349 - accuracy: 0.5046 - val_loss: 1.0425 - val_accuracy: 0.4866\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0407 - accuracy: 0.4914 - val_loss: 1.0372 - val_accuracy: 0.4866\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0261 - accuracy: 0.5036 - val_loss: 1.0465 - val_accuracy: 0.4866\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0352 - accuracy: 0.4941 - val_loss: 1.0362 - val_accuracy: 0.4866\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0182 - accuracy: 0.5125 - val_loss: 1.0377 - val_accuracy: 0.4866\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0181 - accuracy: 0.5126 - val_loss: 1.0405 - val_accuracy: 0.4866\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0322 - accuracy: 0.4987 - val_loss: 1.0419 - val_accuracy: 0.4866\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0260 - accuracy: 0.5098 - val_loss: 1.0362 - val_accuracy: 0.4866\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0240 - accuracy: 0.5025 - val_loss: 1.0384 - val_accuracy: 0.4866\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0270 - accuracy: 0.5013 - val_loss: 1.0332 - val_accuracy: 0.4866\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0199 - accuracy: 0.5033 - val_loss: 1.0362 - val_accuracy: 0.4866\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0235 - accuracy: 0.4999 - val_loss: 1.0445 - val_accuracy: 0.4866\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0251 - accuracy: 0.5045 - val_loss: 1.0307 - val_accuracy: 0.4866\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0224 - accuracy: 0.4984 - val_loss: 1.0332 - val_accuracy: 0.4866\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0202 - accuracy: 0.5020 - val_loss: 1.0315 - val_accuracy: 0.4866\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0116 - accuracy: 0.5116 - val_loss: 1.0325 - val_accuracy: 0.4866\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0267 - accuracy: 0.4916 - val_loss: 1.0321 - val_accuracy: 0.4866\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0237 - accuracy: 0.4946 - val_loss: 1.0337 - val_accuracy: 0.4866\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0183 - accuracy: 0.5026 - val_loss: 1.0317 - val_accuracy: 0.4866\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0146 - accuracy: 0.5032 - val_loss: 1.0343 - val_accuracy: 0.4866\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0195 - accuracy: 0.4973 - val_loss: 1.0296 - val_accuracy: 0.4866\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0172 - accuracy: 0.4972 - val_loss: 1.0324 - val_accuracy: 0.4866\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0209 - accuracy: 0.4946 - val_loss: 1.0311 - val_accuracy: 0.4866\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0166 - accuracy: 0.5003 - val_loss: 1.0291 - val_accuracy: 0.4866\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 1.0189 - accuracy: 0.4951 - val_loss: 0.9984 - val_accuracy: 0.5282\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0203 - accuracy: 0.4951 - val_loss: 0.9884 - val_accuracy: 0.5282\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0161 - accuracy: 0.4949 - val_loss: 0.9949 - val_accuracy: 0.5214\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0171 - accuracy: 0.4928 - val_loss: 0.9880 - val_accuracy: 0.5282\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0193 - accuracy: 0.4960 - val_loss: 0.9898 - val_accuracy: 0.5282\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0185 - accuracy: 0.4961 - val_loss: 0.9906 - val_accuracy: 0.5282\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0178 - accuracy: 0.4960 - val_loss: 0.9979 - val_accuracy: 0.5282\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0156 - accuracy: 0.4958 - val_loss: 0.9910 - val_accuracy: 0.5282\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0158 - accuracy: 0.4966 - val_loss: 0.9965 - val_accuracy: 0.5282\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0134 - accuracy: 0.4975 - val_loss: 0.9946 - val_accuracy: 0.5295\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0096 - accuracy: 0.4978 - val_loss: 0.9882 - val_accuracy: 0.5349\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0113 - accuracy: 0.4912 - val_loss: 0.9858 - val_accuracy: 0.5295\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0077 - accuracy: 0.4967 - val_loss: 0.9819 - val_accuracy: 0.5322\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0085 - accuracy: 0.4976 - val_loss: 0.9860 - val_accuracy: 0.5295\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0082 - accuracy: 0.4979 - val_loss: 0.9823 - val_accuracy: 0.5295\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0039 - accuracy: 0.4984 - val_loss: 0.9790 - val_accuracy: 0.5295\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0032 - accuracy: 0.4994 - val_loss: 0.9818 - val_accuracy: 0.5282\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0039 - accuracy: 0.5018 - val_loss: 0.9769 - val_accuracy: 0.5322\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0048 - accuracy: 0.4997 - val_loss: 0.9803 - val_accuracy: 0.5308\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0029 - accuracy: 0.4991 - val_loss: 0.9810 - val_accuracy: 0.5308\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9929 - accuracy: 0.5027 - val_loss: 0.9780 - val_accuracy: 0.5295\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9990 - accuracy: 0.5019 - val_loss: 0.9818 - val_accuracy: 0.5282\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9909 - accuracy: 0.5019 - val_loss: 0.9812 - val_accuracy: 0.5268\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9903 - accuracy: 0.5040 - val_loss: 0.9918 - val_accuracy: 0.5201\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9919 - accuracy: 0.5025 - val_loss: 0.9712 - val_accuracy: 0.5322\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9837 - accuracy: 0.5067 - val_loss: 0.9620 - val_accuracy: 0.5362\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9835 - accuracy: 0.5058 - val_loss: 0.9584 - val_accuracy: 0.5442\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9761 - accuracy: 0.5097 - val_loss: 0.9593 - val_accuracy: 0.5362\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9754 - accuracy: 0.5109 - val_loss: 0.9659 - val_accuracy: 0.5456\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9690 - accuracy: 0.5177 - val_loss: 0.9608 - val_accuracy: 0.5389\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9673 - accuracy: 0.5182 - val_loss: 0.9213 - val_accuracy: 0.5496\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9632 - accuracy: 0.5176 - val_loss: 0.9927 - val_accuracy: 0.4973\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9674 - accuracy: 0.5180 - val_loss: 0.9314 - val_accuracy: 0.5536\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9641 - accuracy: 0.5189 - val_loss: 0.9204 - val_accuracy: 0.5523\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9434 - accuracy: 0.5243 - val_loss: 0.9072 - val_accuracy: 0.5670\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9477 - accuracy: 0.5273 - val_loss: 0.9089 - val_accuracy: 0.5617\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9246 - accuracy: 0.5426 - val_loss: 0.9014 - val_accuracy: 0.5804\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9267 - accuracy: 0.5362 - val_loss: 0.9026 - val_accuracy: 0.5643\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9207 - accuracy: 0.5410 - val_loss: 0.9162 - val_accuracy: 0.5483\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8981 - accuracy: 0.5566 - val_loss: 0.9077 - val_accuracy: 0.5469\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8928 - accuracy: 0.5526 - val_loss: 0.8500 - val_accuracy: 0.5791\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8761 - accuracy: 0.5717 - val_loss: 0.8666 - val_accuracy: 0.5617\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8801 - accuracy: 0.5566 - val_loss: 0.8316 - val_accuracy: 0.5885\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8661 - accuracy: 0.5739 - val_loss: 0.8861 - val_accuracy: 0.5697\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8397 - accuracy: 0.5879 - val_loss: 0.8007 - val_accuracy: 0.6180\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8202 - accuracy: 0.5976 - val_loss: 0.8102 - val_accuracy: 0.6233\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8157 - accuracy: 0.6010 - val_loss: 0.7701 - val_accuracy: 0.6340\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7955 - accuracy: 0.6174 - val_loss: 0.7809 - val_accuracy: 0.6247\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7774 - accuracy: 0.6188 - val_loss: 0.8206 - val_accuracy: 0.6086\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7481 - accuracy: 0.6390 - val_loss: 0.7563 - val_accuracy: 0.6421\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7480 - accuracy: 0.6487 - val_loss: 0.6997 - val_accuracy: 0.6810\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7251 - accuracy: 0.6531 - val_loss: 0.6639 - val_accuracy: 0.6850\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7102 - accuracy: 0.6636 - val_loss: 0.6786 - val_accuracy: 0.6689\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6926 - accuracy: 0.6745 - val_loss: 0.7033 - val_accuracy: 0.6783\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6869 - accuracy: 0.6861 - val_loss: 0.6610 - val_accuracy: 0.6783\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6831 - accuracy: 0.6897 - val_loss: 0.6194 - val_accuracy: 0.7198\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6563 - accuracy: 0.7030 - val_loss: 0.6167 - val_accuracy: 0.7172\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6180 - accuracy: 0.7176 - val_loss: 0.6033 - val_accuracy: 0.7279\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6365 - accuracy: 0.7173 - val_loss: 0.6506 - val_accuracy: 0.6769\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6188 - accuracy: 0.7310 - val_loss: 0.5810 - val_accuracy: 0.7614\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.5974 - accuracy: 0.7365 - val_loss: 0.3687 - val_accuracy: 0.8834\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5914 - accuracy: 0.7356 - val_loss: 0.3939 - val_accuracy: 0.8633\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5743 - accuracy: 0.7523 - val_loss: 0.3778 - val_accuracy: 0.8713\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5761 - accuracy: 0.7496 - val_loss: 0.3904 - val_accuracy: 0.8660\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5510 - accuracy: 0.7560 - val_loss: 0.3478 - val_accuracy: 0.8700\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5146 - accuracy: 0.7726 - val_loss: 0.3500 - val_accuracy: 0.8914\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5260 - accuracy: 0.7753 - val_loss: 0.3276 - val_accuracy: 0.8727\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4831 - accuracy: 0.7945 - val_loss: 0.2964 - val_accuracy: 0.8753\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4947 - accuracy: 0.7940 - val_loss: 0.3276 - val_accuracy: 0.8673\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4435 - accuracy: 0.8170 - val_loss: 0.3297 - val_accuracy: 0.8619\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4635 - accuracy: 0.8085 - val_loss: 0.3493 - val_accuracy: 0.8633\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4505 - accuracy: 0.8197 - val_loss: 0.3074 - val_accuracy: 0.8834\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4253 - accuracy: 0.8310 - val_loss: 0.2740 - val_accuracy: 0.9035\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4063 - accuracy: 0.8395 - val_loss: 0.2912 - val_accuracy: 0.8901\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3916 - accuracy: 0.8465 - val_loss: 0.2693 - val_accuracy: 0.9021\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3632 - accuracy: 0.8528 - val_loss: 0.2200 - val_accuracy: 0.9142\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3842 - accuracy: 0.8487 - val_loss: 0.2643 - val_accuracy: 0.8995\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3656 - accuracy: 0.8539 - val_loss: 0.2264 - val_accuracy: 0.8968\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3663 - accuracy: 0.8545 - val_loss: 0.2157 - val_accuracy: 0.9223\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3343 - accuracy: 0.8700 - val_loss: 0.2112 - val_accuracy: 0.9276\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3129 - accuracy: 0.8830 - val_loss: 0.1911 - val_accuracy: 0.9236\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3118 - accuracy: 0.8766 - val_loss: 0.2059 - val_accuracy: 0.9142\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2945 - accuracy: 0.8897 - val_loss: 0.2135 - val_accuracy: 0.9129\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2720 - accuracy: 0.8988 - val_loss: 0.1881 - val_accuracy: 0.9263\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2703 - accuracy: 0.9009 - val_loss: 0.1598 - val_accuracy: 0.9437\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2548 - accuracy: 0.9043 - val_loss: 0.1986 - val_accuracy: 0.9316\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2700 - accuracy: 0.8981 - val_loss: 0.1656 - val_accuracy: 0.9437\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2495 - accuracy: 0.9058 - val_loss: 0.1968 - val_accuracy: 0.9129\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2297 - accuracy: 0.9095 - val_loss: 0.1611 - val_accuracy: 0.9343\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2294 - accuracy: 0.9206 - val_loss: 0.1658 - val_accuracy: 0.9450\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2726 - accuracy: 0.9010 - val_loss: 0.0483 - val_accuracy: 0.9893\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2286 - accuracy: 0.9167 - val_loss: 0.0383 - val_accuracy: 0.9933\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2416 - accuracy: 0.9149 - val_loss: 0.0663 - val_accuracy: 0.9866\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2385 - accuracy: 0.9133 - val_loss: 0.0498 - val_accuracy: 0.9906\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2313 - accuracy: 0.9145 - val_loss: 0.0472 - val_accuracy: 0.9893\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2220 - accuracy: 0.9177 - val_loss: 0.0386 - val_accuracy: 0.9933\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2019 - accuracy: 0.9255 - val_loss: 0.0406 - val_accuracy: 0.9866\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2127 - accuracy: 0.9255 - val_loss: 0.0466 - val_accuracy: 0.9866\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1809 - accuracy: 0.9337 - val_loss: 0.0488 - val_accuracy: 0.9839\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1914 - accuracy: 0.9356 - val_loss: 0.0359 - val_accuracy: 0.9920\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1946 - accuracy: 0.9317 - val_loss: 0.0388 - val_accuracy: 0.9946\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1611 - accuracy: 0.9468 - val_loss: 0.0274 - val_accuracy: 0.9933\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1714 - accuracy: 0.9386 - val_loss: 0.0330 - val_accuracy: 0.9933\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1686 - accuracy: 0.9426 - val_loss: 0.0286 - val_accuracy: 0.9973\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1569 - accuracy: 0.9423 - val_loss: 0.0283 - val_accuracy: 0.9946\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1808 - accuracy: 0.9395 - val_loss: 0.0329 - val_accuracy: 0.9946\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1527 - accuracy: 0.9490 - val_loss: 0.0267 - val_accuracy: 0.9933\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1570 - accuracy: 0.9444 - val_loss: 0.0275 - val_accuracy: 0.9933\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1413 - accuracy: 0.9472 - val_loss: 0.0353 - val_accuracy: 0.9933\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1363 - accuracy: 0.9541 - val_loss: 0.0277 - val_accuracy: 0.9933\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1497 - accuracy: 0.9463 - val_loss: 0.0327 - val_accuracy: 0.9946\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1479 - accuracy: 0.9490 - val_loss: 0.0272 - val_accuracy: 0.9960\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1568 - accuracy: 0.9456 - val_loss: 0.0314 - val_accuracy: 0.9933\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1311 - accuracy: 0.9569 - val_loss: 0.0227 - val_accuracy: 0.9960\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1374 - accuracy: 0.9501 - val_loss: 0.0320 - val_accuracy: 0.9920\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1423 - accuracy: 0.9525 - val_loss: 0.0386 - val_accuracy: 0.9933\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1350 - accuracy: 0.9532 - val_loss: 0.0255 - val_accuracy: 0.9960\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1454 - accuracy: 0.9522 - val_loss: 0.0293 - val_accuracy: 0.9933\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1417 - accuracy: 0.9523 - val_loss: 0.0182 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1272 - accuracy: 0.9554 - val_loss: 0.0221 - val_accuracy: 0.9946\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1347 - accuracy: 0.9568 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1303 - accuracy: 0.9556 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1211 - accuracy: 0.9593 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1199 - accuracy: 0.9598 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1348 - accuracy: 0.9568 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1028 - accuracy: 0.9660 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1069 - accuracy: 0.9613 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1077 - accuracy: 0.9647 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0957 - accuracy: 0.9675 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0990 - accuracy: 0.9686 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1176 - accuracy: 0.9598 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1048 - accuracy: 0.9653 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1235 - accuracy: 0.9613 - val_loss: 0.0055 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1015 - accuracy: 0.9629 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1054 - accuracy: 0.9671 - val_loss: 0.0060 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1163 - accuracy: 0.9659 - val_loss: 0.0132 - val_accuracy: 0.9946\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0906 - accuracy: 0.9700 - val_loss: 0.0084 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0912 - accuracy: 0.9702 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1050 - accuracy: 0.9666 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1065 - accuracy: 0.9645 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0992 - accuracy: 0.9669 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1069 - accuracy: 0.9621 - val_loss: 0.0075 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0997 - accuracy: 0.9686 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1074 - accuracy: 0.9657 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0835 - accuracy: 0.9714 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1133 - accuracy: 0.9620 - val_loss: 0.0082 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0985 - accuracy: 0.9662 - val_loss: 0.0059 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0944 - accuracy: 0.9702 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0780 - accuracy: 0.9768 - val_loss: 0.0071 - val_accuracy: 0.9973\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0836 - accuracy: 0.9724 - val_loss: 0.0065 - val_accuracy: 0.9987\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 47ms/step - loss: 0.0949 - accuracy: 0.9666 - val_loss: 9.9616e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0861 - accuracy: 0.9721 - val_loss: 9.7468e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0871 - accuracy: 0.9720 - val_loss: 7.3875e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0964 - accuracy: 0.9695 - val_loss: 8.6815e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1019 - accuracy: 0.9656 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0862 - accuracy: 0.9724 - val_loss: 7.7286e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1012 - accuracy: 0.9686 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0836 - accuracy: 0.9750 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0914 - accuracy: 0.9730 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0887 - accuracy: 0.9689 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0734 - accuracy: 0.9763 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0672 - accuracy: 0.9766 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0822 - accuracy: 0.9720 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0921 - accuracy: 0.9689 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0596 - accuracy: 0.9791 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0873 - accuracy: 0.9726 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0878 - accuracy: 0.9717 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0833 - accuracy: 0.9735 - val_loss: 0.0037 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0774 - accuracy: 0.9750 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0985 - accuracy: 0.9683 - val_loss: 0.0036 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0815 - accuracy: 0.9727 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0766 - accuracy: 0.9788 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0651 - accuracy: 0.9805 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0568 - accuracy: 0.9809 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0751 - accuracy: 0.9766 - val_loss: 0.0044 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0624 - accuracy: 0.9800 - val_loss: 0.0023 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0557 - accuracy: 0.9826 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0554 - accuracy: 0.9830 - val_loss: 0.0022 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0679 - accuracy: 0.9769 - val_loss: 0.0028 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0774 - accuracy: 0.9754 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0835 - accuracy: 0.9733 - val_loss: 3.4889e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0721 - accuracy: 0.9769 - val_loss: 6.2809e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0664 - accuracy: 0.9765 - val_loss: 2.9346e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0701 - accuracy: 0.9800 - val_loss: 4.5304e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0695 - accuracy: 0.9766 - val_loss: 4.3362e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0645 - accuracy: 0.9781 - val_loss: 0.0080 - val_accuracy: 0.9960\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0672 - accuracy: 0.9776 - val_loss: 3.7727e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0695 - accuracy: 0.9779 - val_loss: 6.2386e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0565 - accuracy: 0.9805 - val_loss: 4.1544e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0615 - accuracy: 0.9784 - val_loss: 2.4047e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0791 - accuracy: 0.9744 - val_loss: 3.1628e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0688 - accuracy: 0.9778 - val_loss: 5.4487e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0727 - accuracy: 0.9730 - val_loss: 9.7389e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0683 - accuracy: 0.9796 - val_loss: 0.0016 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0769 - accuracy: 0.9741 - val_loss: 9.8601e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0587 - accuracy: 0.9811 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0628 - accuracy: 0.9803 - val_loss: 0.0039 - val_accuracy: 0.9973\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0645 - accuracy: 0.9791 - val_loss: 4.4939e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0663 - accuracy: 0.9763 - val_loss: 8.8001e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0878 - accuracy: 0.9757 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1106 - accuracy: 0.9660 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0681 - accuracy: 0.9785 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0689 - accuracy: 0.9784 - val_loss: 0.0096 - val_accuracy: 0.9973\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0576 - accuracy: 0.9814 - val_loss: 0.0031 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0869 - accuracy: 0.9696 - val_loss: 0.0030 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0557 - accuracy: 0.9808 - val_loss: 9.1428e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0677 - accuracy: 0.9778 - val_loss: 9.8160e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0456 - accuracy: 0.9854 - val_loss: 4.2609e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0464 - accuracy: 0.9860 - val_loss: 4.6046e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0681 - accuracy: 0.9793 - val_loss: 0.0026 - val_accuracy: 0.9987\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0485 - accuracy: 0.9867 - val_loss: 4.1312e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0590 - accuracy: 0.9796 - val_loss: 3.0553e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0498 - accuracy: 0.9830 - val_loss: 2.1742e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0703 - accuracy: 0.9794 - val_loss: 6.9349e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0586 - accuracy: 0.9799 - val_loss: 4.0725e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0510 - accuracy: 0.9838 - val_loss: 2.4487e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0671 - accuracy: 0.9775 - val_loss: 6.0233e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0570 - accuracy: 0.9817 - val_loss: 3.7818e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0602 - accuracy: 0.9820 - val_loss: 4.5079e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0638 - accuracy: 0.9842 - val_loss: 4.4227e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0535 - accuracy: 0.9841 - val_loss: 3.6573e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0438 - accuracy: 0.9884 - val_loss: 4.9294e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0553 - accuracy: 0.9820 - val_loss: 3.9969e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0602 - accuracy: 0.9815 - val_loss: 4.5134e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0587 - accuracy: 0.9796 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0527 - accuracy: 0.9823 - val_loss: 5.6872e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0655 - accuracy: 0.9776 - val_loss: 9.2664e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0600 - accuracy: 0.9788 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0563 - accuracy: 0.9826 - val_loss: 7.6108e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0588 - accuracy: 0.9794 - val_loss: 3.4772e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0642 - accuracy: 0.9785 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0580 - accuracy: 0.9823 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0568 - accuracy: 0.9832 - val_loss: 0.0021 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0496 - accuracy: 0.9829 - val_loss: 4.3692e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0598 - accuracy: 0.9818 - val_loss: 7.5952e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0603 - accuracy: 0.9812 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0694 - accuracy: 0.9772 - val_loss: 8.8048e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0449 - accuracy: 0.9864 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0555 - accuracy: 0.9842 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0549 - accuracy: 0.9821 - val_loss: 7.8737e-04 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0514 - accuracy: 0.9854 - val_loss: 7.5780e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0354 - accuracy: 0.9891 - val_loss: 4.5514e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0678 - accuracy: 0.9781 - val_loss: 8.8961e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0576 - accuracy: 0.9824 - val_loss: 7.9201e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0466 - accuracy: 0.9858 - val_loss: 8.4609e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0402 - accuracy: 0.9857 - val_loss: 7.5168e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0593 - accuracy: 0.9821 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0620 - accuracy: 0.9808 - val_loss: 1.3396e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0579 - accuracy: 0.9826 - val_loss: 1.6628e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0453 - accuracy: 0.9869 - val_loss: 6.5397e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0429 - accuracy: 0.9875 - val_loss: 1.6881e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0468 - accuracy: 0.9867 - val_loss: 1.5360e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0407 - accuracy: 0.9867 - val_loss: 3.6806e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0506 - accuracy: 0.9830 - val_loss: 8.3653e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0674 - accuracy: 0.9779 - val_loss: 8.2361e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0784 - accuracy: 0.9766 - val_loss: 3.3927e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0504 - accuracy: 0.9838 - val_loss: 1.6870e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0447 - accuracy: 0.9850 - val_loss: 1.6125e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0395 - accuracy: 0.9875 - val_loss: 1.0784e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0499 - accuracy: 0.9863 - val_loss: 1.9691e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0526 - accuracy: 0.9833 - val_loss: 2.1791e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0493 - accuracy: 0.9832 - val_loss: 1.8236e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0490 - accuracy: 0.9832 - val_loss: 1.8176e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0476 - accuracy: 0.9844 - val_loss: 1.2456e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0488 - accuracy: 0.9842 - val_loss: 1.4221e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0438 - accuracy: 0.9852 - val_loss: 6.3098e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0555 - accuracy: 0.9827 - val_loss: 1.9424e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0498 - accuracy: 0.9833 - val_loss: 3.5315e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0391 - accuracy: 0.9888 - val_loss: 7.9795e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0697 - accuracy: 0.9790 - val_loss: 3.2989e-04 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAnc2SJa3o9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "2d93b57a-ab8f-4836-bffb-fd007093eb2b"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 8ms/step - loss: 0.0360 - accuracy: 0.9855\n",
            "Accuracy  : 0.9855149984359741\n",
            "F1_Score  : 0.9836165152774626\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7fcxLuwZpkK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18f82766-7e33-40d4-bd5d-1f2e66e74920"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "e97bdda4-ae57-471a-e9fd-3a0886430324"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 53ms/step - loss: 1.1341 - accuracy: 0.4502 - val_loss: 1.0077 - val_accuracy: 0.4920\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0091 - accuracy: 0.5070 - val_loss: 0.9983 - val_accuracy: 0.4920\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0091 - accuracy: 0.5084 - val_loss: 0.9920 - val_accuracy: 0.4920\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0012 - accuracy: 0.5237 - val_loss: 0.9963 - val_accuracy: 0.4920\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9938 - accuracy: 0.5276 - val_loss: 0.9973 - val_accuracy: 0.4920\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9876 - accuracy: 0.5303 - val_loss: 0.9940 - val_accuracy: 0.4920\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9912 - accuracy: 0.5231 - val_loss: 0.9906 - val_accuracy: 0.4920\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9818 - accuracy: 0.5315 - val_loss: 0.9955 - val_accuracy: 0.4920\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9878 - accuracy: 0.5212 - val_loss: 0.9927 - val_accuracy: 0.4920\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9897 - accuracy: 0.5214 - val_loss: 0.9916 - val_accuracy: 0.4920\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9872 - accuracy: 0.5281 - val_loss: 0.9928 - val_accuracy: 0.4973\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9766 - accuracy: 0.5288 - val_loss: 0.9907 - val_accuracy: 0.4920\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9796 - accuracy: 0.5214 - val_loss: 0.9904 - val_accuracy: 0.4920\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9692 - accuracy: 0.5408 - val_loss: 0.9913 - val_accuracy: 0.4920\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9775 - accuracy: 0.5243 - val_loss: 0.9941 - val_accuracy: 0.4920\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9799 - accuracy: 0.5246 - val_loss: 0.9952 - val_accuracy: 0.4920\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9824 - accuracy: 0.5224 - val_loss: 0.9940 - val_accuracy: 0.5147\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9763 - accuracy: 0.5291 - val_loss: 0.9908 - val_accuracy: 0.4920\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9663 - accuracy: 0.5333 - val_loss: 0.9964 - val_accuracy: 0.4920\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9676 - accuracy: 0.5301 - val_loss: 0.9964 - val_accuracy: 0.4920\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9702 - accuracy: 0.5431 - val_loss: 0.9926 - val_accuracy: 0.5121\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9800 - accuracy: 0.5282 - val_loss: 0.9953 - val_accuracy: 0.4973\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9713 - accuracy: 0.5258 - val_loss: 0.9943 - val_accuracy: 0.4920\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9798 - accuracy: 0.5304 - val_loss: 0.9939 - val_accuracy: 0.4960\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9659 - accuracy: 0.5421 - val_loss: 0.9938 - val_accuracy: 0.4920\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9688 - accuracy: 0.5344 - val_loss: 0.9929 - val_accuracy: 0.5201\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9864 - accuracy: 0.5174 - val_loss: 0.9937 - val_accuracy: 0.5013\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9667 - accuracy: 0.5420 - val_loss: 0.9918 - val_accuracy: 0.5134\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9698 - accuracy: 0.5396 - val_loss: 0.9941 - val_accuracy: 0.4946\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9771 - accuracy: 0.5266 - val_loss: 0.9976 - val_accuracy: 0.4920\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9748 - accuracy: 0.5295 - val_loss: 0.9478 - val_accuracy: 0.5657\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9786 - accuracy: 0.5247 - val_loss: 0.9299 - val_accuracy: 0.5563\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9781 - accuracy: 0.5276 - val_loss: 0.9257 - val_accuracy: 0.5670\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9765 - accuracy: 0.5297 - val_loss: 0.9350 - val_accuracy: 0.5724\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9761 - accuracy: 0.5273 - val_loss: 0.9365 - val_accuracy: 0.5576\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9691 - accuracy: 0.5311 - val_loss: 0.9412 - val_accuracy: 0.5563\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9754 - accuracy: 0.5313 - val_loss: 0.9217 - val_accuracy: 0.5630\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9725 - accuracy: 0.5310 - val_loss: 0.9259 - val_accuracy: 0.5804\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9711 - accuracy: 0.5329 - val_loss: 0.9366 - val_accuracy: 0.5670\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9688 - accuracy: 0.5352 - val_loss: 0.9317 - val_accuracy: 0.5777\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9674 - accuracy: 0.5361 - val_loss: 0.9268 - val_accuracy: 0.5657\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9680 - accuracy: 0.5346 - val_loss: 0.9415 - val_accuracy: 0.5697\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9715 - accuracy: 0.5393 - val_loss: 0.9229 - val_accuracy: 0.5737\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9666 - accuracy: 0.5358 - val_loss: 0.9205 - val_accuracy: 0.5764\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9669 - accuracy: 0.5393 - val_loss: 0.9222 - val_accuracy: 0.5710\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9635 - accuracy: 0.5396 - val_loss: 0.9308 - val_accuracy: 0.5684\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9646 - accuracy: 0.5434 - val_loss: 0.9168 - val_accuracy: 0.5697\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9612 - accuracy: 0.5434 - val_loss: 0.9246 - val_accuracy: 0.5831\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9627 - accuracy: 0.5434 - val_loss: 0.9146 - val_accuracy: 0.5871\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9669 - accuracy: 0.5380 - val_loss: 0.9149 - val_accuracy: 0.5858\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9582 - accuracy: 0.5447 - val_loss: 0.9353 - val_accuracy: 0.5737\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9585 - accuracy: 0.5435 - val_loss: 0.9146 - val_accuracy: 0.5764\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9575 - accuracy: 0.5435 - val_loss: 0.9143 - val_accuracy: 0.5818\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9550 - accuracy: 0.5463 - val_loss: 0.9154 - val_accuracy: 0.5831\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9521 - accuracy: 0.5478 - val_loss: 0.9155 - val_accuracy: 0.5777\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9519 - accuracy: 0.5504 - val_loss: 0.9110 - val_accuracy: 0.5845\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9502 - accuracy: 0.5480 - val_loss: 0.9305 - val_accuracy: 0.5710\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9490 - accuracy: 0.5461 - val_loss: 0.9269 - val_accuracy: 0.5804\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9453 - accuracy: 0.5514 - val_loss: 0.8952 - val_accuracy: 0.5871\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9505 - accuracy: 0.5472 - val_loss: 0.9019 - val_accuracy: 0.5952\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.9379 - accuracy: 0.5537 - val_loss: 0.9101 - val_accuracy: 0.5952\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9457 - accuracy: 0.5477 - val_loss: 0.8982 - val_accuracy: 0.5965\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9409 - accuracy: 0.5519 - val_loss: 0.9038 - val_accuracy: 0.5938\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9344 - accuracy: 0.5526 - val_loss: 0.8934 - val_accuracy: 0.5885\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9353 - accuracy: 0.5510 - val_loss: 0.9108 - val_accuracy: 0.5979\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9343 - accuracy: 0.5562 - val_loss: 0.9125 - val_accuracy: 0.5871\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9234 - accuracy: 0.5542 - val_loss: 0.8833 - val_accuracy: 0.6005\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9239 - accuracy: 0.5569 - val_loss: 0.8867 - val_accuracy: 0.5912\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9216 - accuracy: 0.5569 - val_loss: 0.8929 - val_accuracy: 0.5871\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9142 - accuracy: 0.5587 - val_loss: 0.9089 - val_accuracy: 0.6005\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9149 - accuracy: 0.5648 - val_loss: 0.8953 - val_accuracy: 0.5925\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9142 - accuracy: 0.5624 - val_loss: 0.8817 - val_accuracy: 0.5791\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9068 - accuracy: 0.5663 - val_loss: 0.8894 - val_accuracy: 0.5992\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9004 - accuracy: 0.5686 - val_loss: 0.8871 - val_accuracy: 0.5992\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8880 - accuracy: 0.5785 - val_loss: 0.9010 - val_accuracy: 0.6032\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8851 - accuracy: 0.5805 - val_loss: 0.8658 - val_accuracy: 0.5898\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8766 - accuracy: 0.5766 - val_loss: 0.8594 - val_accuracy: 0.5952\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8702 - accuracy: 0.5829 - val_loss: 0.8582 - val_accuracy: 0.6019\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8625 - accuracy: 0.5897 - val_loss: 0.8512 - val_accuracy: 0.6099\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8513 - accuracy: 0.5952 - val_loss: 0.8298 - val_accuracy: 0.6206\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8484 - accuracy: 0.5981 - val_loss: 0.8734 - val_accuracy: 0.6072\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8421 - accuracy: 0.5990 - val_loss: 0.7992 - val_accuracy: 0.6367\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8283 - accuracy: 0.6076 - val_loss: 0.8192 - val_accuracy: 0.6434\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8102 - accuracy: 0.6171 - val_loss: 0.8184 - val_accuracy: 0.6327\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7944 - accuracy: 0.6274 - val_loss: 0.7999 - val_accuracy: 0.6206\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7756 - accuracy: 0.6361 - val_loss: 0.7516 - val_accuracy: 0.6542\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7692 - accuracy: 0.6441 - val_loss: 0.7863 - val_accuracy: 0.6582\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7727 - accuracy: 0.6490 - val_loss: 0.7227 - val_accuracy: 0.6796\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7371 - accuracy: 0.6618 - val_loss: 0.7379 - val_accuracy: 0.6662\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7225 - accuracy: 0.6694 - val_loss: 0.7374 - val_accuracy: 0.6756\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7166 - accuracy: 0.6727 - val_loss: 0.5659 - val_accuracy: 0.7399\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6900 - accuracy: 0.6957 - val_loss: 0.5309 - val_accuracy: 0.7882\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6901 - accuracy: 0.6996 - val_loss: 0.5348 - val_accuracy: 0.7748\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6539 - accuracy: 0.7127 - val_loss: 0.5210 - val_accuracy: 0.7721\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6415 - accuracy: 0.7212 - val_loss: 0.4999 - val_accuracy: 0.8016\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6222 - accuracy: 0.7285 - val_loss: 0.4928 - val_accuracy: 0.8029\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6093 - accuracy: 0.7434 - val_loss: 0.4913 - val_accuracy: 0.7721\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5880 - accuracy: 0.7495 - val_loss: 0.4577 - val_accuracy: 0.8070\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5700 - accuracy: 0.7596 - val_loss: 0.4385 - val_accuracy: 0.8164\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5531 - accuracy: 0.7718 - val_loss: 0.4088 - val_accuracy: 0.8311\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5272 - accuracy: 0.7778 - val_loss: 0.3886 - val_accuracy: 0.8338\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4819 - accuracy: 0.8067 - val_loss: 0.3837 - val_accuracy: 0.8351\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5070 - accuracy: 0.8040 - val_loss: 0.3866 - val_accuracy: 0.8566\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4865 - accuracy: 0.8070 - val_loss: 0.3473 - val_accuracy: 0.8592\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4386 - accuracy: 0.8267 - val_loss: 0.3796 - val_accuracy: 0.8458\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4039 - accuracy: 0.8450 - val_loss: 0.3231 - val_accuracy: 0.8633\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4295 - accuracy: 0.8347 - val_loss: 0.3502 - val_accuracy: 0.8713\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4162 - accuracy: 0.8437 - val_loss: 0.3088 - val_accuracy: 0.8713\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3749 - accuracy: 0.8541 - val_loss: 0.2986 - val_accuracy: 0.8928\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3619 - accuracy: 0.8620 - val_loss: 0.3022 - val_accuracy: 0.8928\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3921 - accuracy: 0.8545 - val_loss: 0.2666 - val_accuracy: 0.8995\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3412 - accuracy: 0.8738 - val_loss: 0.2834 - val_accuracy: 0.8901\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3277 - accuracy: 0.8818 - val_loss: 0.2647 - val_accuracy: 0.8928\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3056 - accuracy: 0.8911 - val_loss: 0.2347 - val_accuracy: 0.9142\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3054 - accuracy: 0.8896 - val_loss: 0.2456 - val_accuracy: 0.9062\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2783 - accuracy: 0.9006 - val_loss: 0.2489 - val_accuracy: 0.8981\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2997 - accuracy: 0.8897 - val_loss: 0.1909 - val_accuracy: 0.9316\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2913 - accuracy: 0.8973 - val_loss: 0.2039 - val_accuracy: 0.9236\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2796 - accuracy: 0.9018 - val_loss: 0.1927 - val_accuracy: 0.9303\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2690 - accuracy: 0.8997 - val_loss: 0.2054 - val_accuracy: 0.9290\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.2710 - accuracy: 0.9012 - val_loss: 0.0337 - val_accuracy: 0.9946\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2725 - accuracy: 0.8999 - val_loss: 0.0411 - val_accuracy: 0.9879\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2333 - accuracy: 0.9170 - val_loss: 0.0331 - val_accuracy: 0.9933\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2605 - accuracy: 0.9112 - val_loss: 0.0484 - val_accuracy: 0.9839\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2184 - accuracy: 0.9252 - val_loss: 0.0339 - val_accuracy: 0.9906\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2287 - accuracy: 0.9185 - val_loss: 0.0510 - val_accuracy: 0.9839\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2183 - accuracy: 0.9200 - val_loss: 0.0447 - val_accuracy: 0.9893\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2007 - accuracy: 0.9335 - val_loss: 0.0402 - val_accuracy: 0.9893\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2103 - accuracy: 0.9237 - val_loss: 0.0353 - val_accuracy: 0.9893\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2247 - accuracy: 0.9198 - val_loss: 0.0321 - val_accuracy: 0.9920\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1975 - accuracy: 0.9326 - val_loss: 0.0241 - val_accuracy: 0.9946\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1973 - accuracy: 0.9270 - val_loss: 0.0366 - val_accuracy: 0.9893\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1989 - accuracy: 0.9288 - val_loss: 0.0269 - val_accuracy: 0.9906\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1968 - accuracy: 0.9328 - val_loss: 0.0332 - val_accuracy: 0.9906\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1659 - accuracy: 0.9426 - val_loss: 0.0304 - val_accuracy: 0.9946\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1719 - accuracy: 0.9446 - val_loss: 0.0405 - val_accuracy: 0.9879\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1588 - accuracy: 0.9452 - val_loss: 0.0265 - val_accuracy: 0.9933\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1655 - accuracy: 0.9407 - val_loss: 0.0419 - val_accuracy: 0.9893\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1748 - accuracy: 0.9396 - val_loss: 0.0264 - val_accuracy: 0.9920\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1611 - accuracy: 0.9487 - val_loss: 0.0246 - val_accuracy: 0.9960\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1405 - accuracy: 0.9537 - val_loss: 0.0326 - val_accuracy: 0.9893\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1441 - accuracy: 0.9523 - val_loss: 0.0272 - val_accuracy: 0.9906\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1653 - accuracy: 0.9413 - val_loss: 0.0246 - val_accuracy: 0.9933\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1548 - accuracy: 0.9461 - val_loss: 0.0407 - val_accuracy: 0.9866\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1485 - accuracy: 0.9510 - val_loss: 0.0247 - val_accuracy: 0.9920\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1321 - accuracy: 0.9554 - val_loss: 0.0275 - val_accuracy: 0.9920\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1552 - accuracy: 0.9463 - val_loss: 0.0313 - val_accuracy: 0.9946\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1564 - accuracy: 0.9492 - val_loss: 0.0508 - val_accuracy: 0.9853\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1411 - accuracy: 0.9508 - val_loss: 0.0254 - val_accuracy: 0.9933\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1275 - accuracy: 0.9545 - val_loss: 0.0260 - val_accuracy: 0.9920\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1481 - accuracy: 0.9510 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1361 - accuracy: 0.9551 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1222 - accuracy: 0.9580 - val_loss: 0.0060 - val_accuracy: 0.9987\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1408 - accuracy: 0.9538 - val_loss: 0.0086 - val_accuracy: 0.9973\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1370 - accuracy: 0.9560 - val_loss: 0.0060 - val_accuracy: 0.9987\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1383 - accuracy: 0.9544 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1347 - accuracy: 0.9526 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1190 - accuracy: 0.9608 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1284 - accuracy: 0.9554 - val_loss: 0.0097 - val_accuracy: 0.9973\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1030 - accuracy: 0.9653 - val_loss: 0.0117 - val_accuracy: 0.9973\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1244 - accuracy: 0.9563 - val_loss: 0.0061 - val_accuracy: 0.9987\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1272 - accuracy: 0.9621 - val_loss: 0.0082 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1098 - accuracy: 0.9627 - val_loss: 0.0076 - val_accuracy: 0.9973\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1073 - accuracy: 0.9651 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1204 - accuracy: 0.9602 - val_loss: 0.0069 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1043 - accuracy: 0.9650 - val_loss: 0.0109 - val_accuracy: 0.9973\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0953 - accuracy: 0.9674 - val_loss: 0.0044 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1165 - accuracy: 0.9618 - val_loss: 0.0050 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1083 - accuracy: 0.9623 - val_loss: 0.0045 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1066 - accuracy: 0.9654 - val_loss: 0.0063 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0947 - accuracy: 0.9674 - val_loss: 0.0074 - val_accuracy: 0.9973\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1189 - accuracy: 0.9578 - val_loss: 0.0072 - val_accuracy: 0.9973\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0852 - accuracy: 0.9723 - val_loss: 0.0072 - val_accuracy: 0.9973\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1029 - accuracy: 0.9644 - val_loss: 0.0069 - val_accuracy: 0.9973\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0909 - accuracy: 0.9697 - val_loss: 0.0082 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0892 - accuracy: 0.9705 - val_loss: 0.0061 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0941 - accuracy: 0.9672 - val_loss: 0.0095 - val_accuracy: 0.9973\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0930 - accuracy: 0.9687 - val_loss: 0.0099 - val_accuracy: 0.9960\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1072 - accuracy: 0.9659 - val_loss: 0.0098 - val_accuracy: 0.9973\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0931 - accuracy: 0.9711 - val_loss: 0.0130 - val_accuracy: 0.9973\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0977 - accuracy: 0.9677 - val_loss: 0.0017 - val_accuracy: 0.9987\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0849 - accuracy: 0.9745 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0895 - accuracy: 0.9689 - val_loss: 8.0461e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0981 - accuracy: 0.9678 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0699 - accuracy: 0.9785 - val_loss: 5.8630e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0913 - accuracy: 0.9698 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0942 - accuracy: 0.9692 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0883 - accuracy: 0.9684 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0955 - accuracy: 0.9687 - val_loss: 0.0050 - val_accuracy: 0.9987\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0798 - accuracy: 0.9747 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0952 - accuracy: 0.9711 - val_loss: 0.0062 - val_accuracy: 0.9987\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1057 - accuracy: 0.9642 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0793 - accuracy: 0.9745 - val_loss: 0.0033 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0738 - accuracy: 0.9745 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0849 - accuracy: 0.9720 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0695 - accuracy: 0.9769 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0687 - accuracy: 0.9788 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0840 - accuracy: 0.9745 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0655 - accuracy: 0.9769 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0838 - accuracy: 0.9744 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0830 - accuracy: 0.9723 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0725 - accuracy: 0.9781 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0683 - accuracy: 0.9782 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0788 - accuracy: 0.9742 - val_loss: 7.1323e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0701 - accuracy: 0.9768 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0985 - accuracy: 0.9659 - val_loss: 0.0028 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0770 - accuracy: 0.9739 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0662 - accuracy: 0.9769 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0741 - accuracy: 0.9759 - val_loss: 0.0024 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0740 - accuracy: 0.9756 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0981 - accuracy: 0.9687 - val_loss: 7.6810e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0817 - accuracy: 0.9738 - val_loss: 3.8538e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0808 - accuracy: 0.9756 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0708 - accuracy: 0.9785 - val_loss: 4.7254e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0759 - accuracy: 0.9782 - val_loss: 3.1221e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0847 - accuracy: 0.9718 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0685 - accuracy: 0.9799 - val_loss: 5.8644e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0750 - accuracy: 0.9768 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0683 - accuracy: 0.9772 - val_loss: 5.0673e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0600 - accuracy: 0.9790 - val_loss: 3.3978e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0645 - accuracy: 0.9763 - val_loss: 5.1397e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0724 - accuracy: 0.9750 - val_loss: 6.4881e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0722 - accuracy: 0.9757 - val_loss: 6.5660e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0752 - accuracy: 0.9775 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0703 - accuracy: 0.9775 - val_loss: 8.8729e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0702 - accuracy: 0.9775 - val_loss: 8.6277e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0605 - accuracy: 0.9812 - val_loss: 6.7232e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0657 - accuracy: 0.9793 - val_loss: 6.1133e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0507 - accuracy: 0.9838 - val_loss: 4.3381e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0556 - accuracy: 0.9842 - val_loss: 3.6700e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0572 - accuracy: 0.9820 - val_loss: 0.0017 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0643 - accuracy: 0.9800 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0674 - accuracy: 0.9788 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0494 - accuracy: 0.9832 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0648 - accuracy: 0.9790 - val_loss: 8.0511e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0643 - accuracy: 0.9793 - val_loss: 0.0038 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0726 - accuracy: 0.9763 - val_loss: 8.9361e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0655 - accuracy: 0.9800 - val_loss: 4.8720e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0643 - accuracy: 0.9799 - val_loss: 7.0930e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0711 - accuracy: 0.9782 - val_loss: 0.0055 - val_accuracy: 0.9973\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0806 - accuracy: 0.9759 - val_loss: 4.9485e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0621 - accuracy: 0.9793 - val_loss: 6.4854e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0642 - accuracy: 0.9799 - val_loss: 2.4626e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0568 - accuracy: 0.9817 - val_loss: 3.6658e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0668 - accuracy: 0.9794 - val_loss: 4.2563e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0595 - accuracy: 0.9817 - val_loss: 2.2638e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0600 - accuracy: 0.9809 - val_loss: 3.7624e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0638 - accuracy: 0.9797 - val_loss: 3.3993e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0546 - accuracy: 0.9823 - val_loss: 0.0017 - val_accuracy: 0.9987\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0668 - accuracy: 0.9806 - val_loss: 0.0019 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0557 - accuracy: 0.9820 - val_loss: 2.5383e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0512 - accuracy: 0.9832 - val_loss: 1.9039e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0569 - accuracy: 0.9821 - val_loss: 4.1663e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0617 - accuracy: 0.9809 - val_loss: 6.7857e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0555 - accuracy: 0.9820 - val_loss: 2.9104e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0764 - accuracy: 0.9769 - val_loss: 2.8206e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0506 - accuracy: 0.9845 - val_loss: 2.3281e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0655 - accuracy: 0.9790 - val_loss: 3.2637e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0505 - accuracy: 0.9829 - val_loss: 5.3532e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0621 - accuracy: 0.9790 - val_loss: 5.0984e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0661 - accuracy: 0.9790 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0616 - accuracy: 0.9806 - val_loss: 4.2359e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0504 - accuracy: 0.9848 - val_loss: 3.7481e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0434 - accuracy: 0.9864 - val_loss: 3.2893e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0452 - accuracy: 0.9839 - val_loss: 3.3656e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0850 - accuracy: 0.9727 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0754 - accuracy: 0.9745 - val_loss: 9.3169e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0553 - accuracy: 0.9821 - val_loss: 4.0561e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0462 - accuracy: 0.9855 - val_loss: 4.8560e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0434 - accuracy: 0.9869 - val_loss: 3.5683e-04 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0508 - accuracy: 0.9854 - val_loss: 1.0927e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0772 - accuracy: 0.9750 - val_loss: 1.9953e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0499 - accuracy: 0.9820 - val_loss: 2.4079e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0391 - accuracy: 0.9873 - val_loss: 4.8340e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0604 - accuracy: 0.9805 - val_loss: 2.4465e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0549 - accuracy: 0.9832 - val_loss: 2.5354e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0449 - accuracy: 0.9835 - val_loss: 7.3276e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0416 - accuracy: 0.9869 - val_loss: 7.9507e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0638 - accuracy: 0.9815 - val_loss: 1.6798e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0564 - accuracy: 0.9832 - val_loss: 4.4422e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1046 - accuracy: 0.9642 - val_loss: 0.0087 - val_accuracy: 0.9973\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0727 - accuracy: 0.9762 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0450 - accuracy: 0.9854 - val_loss: 1.1584e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0490 - accuracy: 0.9858 - val_loss: 2.3688e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0444 - accuracy: 0.9857 - val_loss: 1.2308e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0427 - accuracy: 0.9866 - val_loss: 1.4022e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0499 - accuracy: 0.9821 - val_loss: 2.4078e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0524 - accuracy: 0.9820 - val_loss: 1.7108e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0447 - accuracy: 0.9869 - val_loss: 1.2341e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0482 - accuracy: 0.9841 - val_loss: 2.3907e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0456 - accuracy: 0.9851 - val_loss: 5.3465e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0424 - accuracy: 0.9854 - val_loss: 3.6622e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0428 - accuracy: 0.9869 - val_loss: 1.9709e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0532 - accuracy: 0.9838 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0599 - accuracy: 0.9794 - val_loss: 2.2753e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0495 - accuracy: 0.9839 - val_loss: 1.7524e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0415 - accuracy: 0.9870 - val_loss: 3.9585e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0470 - accuracy: 0.9858 - val_loss: 1.5899e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0629 - accuracy: 0.9806 - val_loss: 8.1293e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0421 - accuracy: 0.9872 - val_loss: 1.4158e-04 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "6efc87dc-a891-4a58-9f8c-8aeca74a41b7"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 8ms/step - loss: 0.0504 - accuracy: 0.9839\n",
            "Accuracy  : 0.983905553817749\n",
            "F1_Score  : 0.9819254133218371\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAAKOCAYAAAAS8uXWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debhdZXk3/u+ThCBTEkRywhAQAYsMKiBo8RVCkBCGJiBg8XVo1RZbBIGiIir2LT8HVMShSJXBSztpoYIECQRlUKAgILZMTmAVEskJKiA4JTl5fn+cQ0gCGQBP1pPsz8drX9fZe6291rNwub353utZq9RaAwBAO0Z0PQAAAJamQAMAaIwCDQCgMQo0AIDGKNAAABozqusBLM96ux5reimde+iWs7oeAiRJFplxTyPWX6eULvbbZV3wu++dtdqPWYIGANAYBRoAQGOabXECACxWeitT6q2jBQBYAyjQAAAao8UJALSvm8mjnZGgAQA0RoIGALTPJAEAALokQQMA2ucaNAAAuqRAAwBojBYnANA+kwQAAOiSBA0AaJ9JAgAAdEmBBgDQGC1OAKB9JgkAANAlCRoA0D6TBAAA6JIEDQBon2vQAADokgINAKAxWpwAQPtMEgAAoEsSNACgfSYJAADQJQkaANA+16ABANAlBRoAQGO0OAGA9pkkAABAlyRoAED7JGgAAHRJgQYA0BgtTgCgfSPcBw0AgA5J0ACA9pkkAABAlyRoAED7PIsTAIAuKdAAABqjxQkAtM8kAQAAuiRBAwDaZ5IAAABdUqABADRGixMAaJ9JAgAAdEmCBgC0zyQBAAC6JEEDANrnGjQAALqkQAMAaIwWJwDQPpMEAADokgQNAGifSQIAAHRJggYAtM81aAAAdEmBBgDQGC1OAKB9JgkAANAlCRoA0D4JGgAAXVKgAQA0RosTAGif+6ABANAlCRoA0D6TBAAA6JIEDQBon2vQAADokgINAKAxWpwAQPtMEgAAoEsSNACgfSYJAADQJQkaANC8IkEDAKBLCjQAgMZocQIAzdPiBACgUxI0AKB9vRWgSdAAAFqjQAMAaIwWJwDQPJMEAADolAQNAGieBA0AgE5J0ACA5knQAADolAINAKAxWpwAQPO0OAEA6JQEDQBoX28FaBI0AIDWKNDWUPvv9aL8z8Wn5s5L/j7vfPP+T1q+1WYbZ+bnjsvN/3FKZp17fLYYP27xsg++Y3puvfC9ufXC9+aIKbutzmGzhrrhum9n2sEH5JCp++f8c8950vL58+fnXSedkEOm7p/XH3Vk5syZvXjZ+ed+PodM3T/TDj4gN1x/3eLPP/D+UzLpVX+a10w/ZKltveukE/La10zPa18zPQfuPzmvfc304Tsw1ho3XH9dDj1kaqYdOCVfOO+pz9GTTzox0w6ckje+7rX5+dA5+vDDD+Wv3/ym7LXHbjn9Q6et7mHzNJRSOnt1QYG2BhoxouRT73ltph97dnY9/IM5curu2eEFE5Za5yMnHpZ/u+zm7PnnH8mHz7k8px03LUky9f/slJe+aGJeftTp2fuNZ+SEN+2XjTZ4TheHwRpiYGAgH/7QaTn7c+fl4hmX5YqZX8+999yz1DoXf/XCjBkzJl+/4ht5w5v+Mp8684wkyb333JMrZl6Wi2ZclrM/f14+/MF/yMDAQJJk+qGvyT99/rwn7e/jn/hULrjoklxw0SXZb/8pmfzqJ/8LCCxpYGAgp3/wtJz1T+fmqzO+nitmXpZ77136HP3aRf+ZjcaMyYzLr8zr3/gX+fSZn0iSrDt63Rxz3PE58Z3v7mLosFzDVqCVUnYopZxcSvnM0OvkUsqLhmt/vWSPnZ+fe+//RX4655dZsHAgF866LYdMevFS6+zwgs3yrZt/mCT51i0/yiGTdkmSvOgFE3L9bfdkYGBRfvv7+bnjx3MyZS//tbB8d95xeyZO3DpbTpyYdUaPztSDDs6111y11DrXXH11pk0/LEmy/5QDcvNNN6bWmmuvuSpTDzo4o0ePzpZbTszEiVvnzjtuT5Ls/rI9Mmbs2OXut9aaK2ddngMPPmS560AydI5utdXgObrO6Bxw4EG59uqlz9Frr74qfzb90CTJq6cckJu/M3iOrrf++tl1t92z7rqjuxg6LNewFGillJOTfCWDl/TdPPQqSb5cSnnPcOyzl2w+fmxm9z+0+P2c/oeyxaZL/x/dHT+ak+mTX5okmT75JRmz4Xp57tgNcvuPBguy9Z6zTjYZt0H2edkLs+WEjVfr+FmzzOvvz4TNnkhox/f1pb+/f+l15vVnwoTNkiSjRo3KhhttlIcffij9/f3pm/DEd/sm9GXeMt9dntu+e2s22WSTbL3185/9QbBWmzevP31D51+S9PVNyIPzlj1H5y19jm64UR5++OHVOk6enV5rcQ7XLM63Jtmp1rpgyQ9LKWcmuSvJ6U/1pVLK0UmOTpJRW07KqOftNEzDW/ud8smL88mTj8wbpr08N9x2T+b0P5SBgUW56qYfZPedts41Xzwpv3josXzn9v/NwMCirocLT3L5zK9n6kHSM6A3DVeBtijJ5kl+tsznmw0te0q11nOSnJMk6+16bB2msa3xfj7vkWzZ90TqtUXfxpnz4CNLrfPAg4/kqHcOXt+zwXqjc+h+L80jj/0uSfKx82flY+fPSpJ88cN/mR/fN281jZw10fi+vsx9YO7i9/P6+9PX17f0OuP7MnfuA+mbMCELFy7MY48+mnHjNk5fX1/65z7x3f65/Rm/zHefysKFC3PVN7+Rr1xw0R/vQFhrjR/fl/65Dyx+398/N5uOX/YcHb/0OfrYoxk3btyym6JhblT7x3FCkqtKKZeXUs4Zel2R5Kokxw/TPnvGrXf9LNtttWm23nyTrDNqZI48YLdcdu3tS62zybgNFp/M73rLAfnSJTclGZxg8NyxGyRJdt5+8+y8/eb55o0/WL0HwBplp513yX33/TSzZ9+fBfPn54qZl2WffScvtc6kfSdnxiUXJ0m+ceWs7PnyV6SUkn32nZwrZl6W+fPnZ/bs+3PffT/Nzru8+Kl2s5Tv3Phf2WabFyzVHoXlGTxHf5Y5s2dnwYL5mXX5zExa5hzdZ9/JufSSryVJvnnlrOwxdI5Cq4YlQau1XlFKeWGSPZNsMfTxnCS31FoHhmOfvWRgYFFO/OgFufTst2fkiJIvXXJTvv+TuTn1bw/ObXffl8u+dUf2ftn2Oe24aak1uf62e3LCRy5IkqwzamS++YUTkiSPPvb7vOV9X9LiZIVGjRqVU973gfzt0X+VRYsGcuhhh2e77bbPZ//x09lpp50zafJ+OezwI/K+97wrh0zdP2PGjs3HzvhkkmS77bbPlKkH5rBpB2XkyJF57/s/kJEjRyZJTn7n3+XWW27Oww8/lP0n752/fftxec3hRyZJrrh8ZqYedHBnx8yaZdSoUTn5vafmmLe9NYsGFmX6YYdn2+22z9lnfSY77rRzJu07OYe+5oi8/5R3Z9qBUzJm7Nic/vEzF3//oCmT85vHfpMFCxbkmquvytnnnJ9tt92uwyOCpNTaZidRi5MWPHTLWV0PAZIkixr9rab3rL9ON9HjJm/6cmf/I/jlP79utR+z+6ABADTGszgBgPb12CWDEjQAgMZI0ACA5vXarFsJGgBAYxRoAACNUaABAM1r+VmcpZSppZQfllLueapnjpdStiqlXFNK+V4p5fZSykEr26YCDQDgGSqljEzy2SQHJtkxyetKKTsus9r7k1xQa901yVFJzl7Zdk0SAACa1/AkgT2T3FNr/UmSlFK+kmR6kruXWKcmGTP099gkP1/ZRiVoAAArUEo5upRy6xKvo5dYvEWS+5d4PztPPObycf8vyRtKKbOTzExy3Mr2KUEDAFiBWus5Sc55Fpt4XZIv1lo/UUr50yT/UkrZuda63IdhK9AAgPY12+HMnCQTl3i/5dBnS3prkqlJUmu9sZTynCTPSzJveRvV4gQAeOZuSbJ9KWWbUsroDE4CmLHMOvcl2S9JSikvSvKcJA+uaKMSNACgea1OEqi1LiylHJtkVpKRSb5Qa72rlHJakltrrTOSnJTk3FLKiRmcMPCXtda6ou0q0AAAnoVa68wMXvy/5GcfWOLvu5O88ulsU4EGADSv1QRtuLgGDQCgMQo0AIDGaHECAM3T4gQAoFMSNACgeRI0AAA6JUEDANrXWwGaBA0AoDUKNACAxmhxAgDNM0kAAIBOSdAAgOZJ0AAA6JQCDQCgMVqcAEDztDgBAOiUBA0AaF9vBWgSNACA1kjQAIDmuQYNAIBOKdAAABqjxQkANE+LEwCATknQAIDmSdAAAOiUBA0AaJ4EDQCATinQAAAao8UJALSvtzqcEjQAgNZI0ACA5pkkAABApxRoAACN0eIEAJqnxQkAQKckaABA83osQJOgAQC0RoIGADTPNWgAAHRKgQYA0BgtTgCgeT3W4ZSgAQC0RoIGADTPJAEAADqlQAMAaIwWJwDQvB7rcErQAABaI0EDAJo3YkRvRWgSNACAxkjQAIDmuQYNAIBOKdAAABqjxQkANM+TBAAA6JQEDQBoXo8FaBI0AIDWSNAAgOa5Bg0AgE4p0AAAGqPFCQA0T4sTAIBOSdAAgOb1WIAmQQMAaI0CDQCgMVqcAEDzTBIAAKBTEjQAoHk9FqBJ0AAAWiNBAwCa5xo0AAA6pUADAGiMFicA0Lwe63BK0AAAWiNBAwCaZ5IAAACdkqABAM3rsQBNggYA0BoFGgBAY7Q4AYDmmSQAAECnmk3QfnnzP3Y9BMjGe72z6yFAkuQX13+86yFAp3osQJOgAQC0RoEGANCYZlucAACPM0kAAIBOSdAAgOb1WIAmQQMAaI0EDQBonmvQAADolAINAKAxWpwAQPN6rMMpQQMAaI0EDQBonkkCAAB0SoEGANAYLU4AoHlanAAAdEqCBgA0r8cCNAkaAEBrJGgAQPNcgwYAQKcUaAAAjdHiBACa12MdTgkaAEBrJGgAQPNMEgAAoFMSNACgeT0WoEnQAABao0ADAGiMFicA0LwRPdbjlKABADRGggYANK/HAjQJGgBAaxRoAACNUaABAM0rpXT2WoWxTS2l/LCUck8p5T3LWee1pZS7Syl3lVL+fWXbdA0aAMAzVEoZmeSzSfZPMjvJLaWUGbXWu5dYZ/skpyR5Za31oVLK+JVtV4EGADRvRLuTBPZMck+t9SdJUkr5SpLpSe5eYp2/TvLZWutDSVJrnbeyjWpxAgCsQCnl6FLKrUu8jl5i8RZJ7l/i/eyhz5b0wiQvLKXcUEq5qZQydWX7lKABAM1blWvBhkut9Zwk5zyLTYxKsn2SSUm2TPLtUsoutdaHl/cFCRoAwDM3J8nEJd5vOfTZkmYnmVFrXVBr/d8kP8pgwbZcCjQAgGfuliTbl1K2KaWMTnJUkhnLrPO1DKZnKaU8L4Mtz5+saKNanABA81p9kkCtdWEp5dgks5KMTPKFWutdpZTTktxaa50xtGxKKeXuJANJ3lVr/eWKtqtAAwB4FmqtM5PMXOazDyzxd03yd0OvVaJAAwCaV9JohDZMXIMGANAYCRoA0LyGb1Q7LCRoAACNUaABADRGixMAaF6XTxLoggQNAKAxEjQAoHk9FqBJ0AAAWqNAAwBojBYnANC8ET3W45SgAQA0RoIGADSvxwI0CRoAQGskaABA89yoFgCATinQAAAao8UJADSvxzqcEjQAgNZI0ACA5rlRLQAAnVKgAQA0RosTAGhebzU4JWgAAM2RoAEAzfMkAQAAOiVBAwCaN6K3AjQJGgBAaxRoAACN0eIEAJpnkgAAAJ2SoAEAzeuxAE2CBgDQGgkaANA816ABANApBRoAQGO0OAGA5vXakwSWW6CVUv4xSV3e8lrrO4ZlRAAAPW5FCdqtq20UAAAr0GuTBJZboNVav7Tk+1LK+rXW3w7/kAAAettKJwmUUv60lHJ3kh8MvX9JKeXsYR8ZAECPWpVZnJ9KckCSXyZJrfV/kuw9nIMCAFhS6fDVhVW6zUat9f5lPhoYhrEAAJBVu83G/aWUvZLUUso6SY5P8v3hHRYAwBNG9NgkgVVJ0P4myduTbJHk50leOvQeAIBhsNIErdb6iySvXw1jAQB4Sj0WoK3SLM4XlFIuLaU8WEqZV0q5pJTygtUxOACAXrQqLc5/T3JBks2SbJ7kwiRfHs5BAQD0slUp0Navtf5LrXXh0OtfkzxnuAcGAPC4Ukpnry6s6Fmczx368/JSynuSfCWDz+b88yQzV8PYAAB60oomCXw3gwXZ46Xj25ZYVpOcMlyDAgBYUq9NEljRszi3WZ0DAQBg0KrcqDallJ2T7Jglrj2rtf7zcA0KAGBJvXaj2pUWaKWUv08yKYMF2swkBya5PokCDQBgGKzKLM4jkuyXZG6t9c1JXpJk7LCOCgCgh61Ki/N3tdZFpZSFpZQxSeYlmTjM4+Ip3HD9dfn46R/KooFFOfTwI/KWvzp6qeXz58/PqaecnO/ffVfGjhuXj55xZjbfYss8/PBDedeJx+euO+/MtEMPzXve94HF33n72/4qDz74YAYGBrLrbrvnlPd/ICNHjlzdh8Yaav9X/EnOOGl6Ro4YkS9e8p2c8c/XLLV8qwkb53OnvjbPG7dBHvr17/KWv//3zJn3SPbefdt87MRpi9f7k63H503v/9dc+q27VvchsJa44frrcsZHP5SBgUU57DVH5M1P9fv43sHfx3HjxuX0jw/+Pt70XzfkM5/6RBYuWJBR66yTE056d/Z8+Ss6OgpWpMc6nKuUoN1aShmX5NwMzuy8LcmNwzoqnmRgYCCnf/C0nPVP5+arM76eK2ZelnvvvWepdb520X9mozFjMuPyK/P6N/5FPn3mJ5Ik645eN8ccd3xOfOe7n7Tdj37iU7ngokvyn1+7NA899Kt8Y9YVq+V4WPONGFHyqXcflunHn5dd//zjOfKAXbPDNn1LrfOR4w/Jv838bvZ8/Zn58PnfyGnHHJQk+fZ3780r3vDJvOINn8yBx3wuv/39gnzzph91cRisBQYGBvLRD52Wfzz73Hz1kq/nissvy0+e4vdxzJgxmTFz6Pfxk4O/j+M23jifPuufcsHFl+a0D52eU9/75N9J6MJKC7Ra6zG11odrrZ9Lsn+SvxhqdbIa3XnH7Zm41VbZcuLErLPO6Bxw4EG59uqrllrn2quvyp9NPzRJ8uopB+Tm79yYWmvWW3/97Lrb7ll33dFP2u6GG26YJFm4cGEWLljQ2Q35WPPssdNWuXf2L/PTn/8qCxYO5MIr/zuH7L3TUuvssE1fvnXLj5Mk37r1nictT5LDJr84V974g/zuDwtWy7hZ+9x5x+3Zctnfx2uW+X285qocMm3w93G//Q/ILUO/jzu8aMdsOn7wXyy23W77/OH3f8j8+fNX+zGwcr12o9rlFmillN2WfSV5bpJRQ38/I6UUxd0zMG9ef/ombLb4fV/fhDw4r3+ZdeZlwtA6o0aNyoYbbpSHH354pds+5ui3Zr99Xpn1N9ggr55ywB934Ky1Nt90bGb3P3F+zZn3cLbYdOnLU+/48c8zfd9dkiTTJ+2cMRs+J88du/5S6xw5ZddccOX3hn/ArLUenNe/+LcvScb3Tci8/v5l1ln57+NV35iVHV60Y0aPfvK/zMLqtqIE7RMreJ3xLPb5D8tbUEo5upRyaynl1i+cd86z2AVPx9nnnJ9vXHNd5s+fn1u+c1PXw2Etcsqnv55X7bZtbvyXE/Oq3bbNnP6HMzCwaPHyCZtslJ22nZBv3PjDDkcJyb33/Dif+eQn8r6/X+7/RcFqtaIb1e77TDdaSrl9eYuS9C1nWWqt5yQ5J0l+u6DWZ7r/tdH48X3pn/vA4vf9/XMXx/JPrDM+c+c+kL4JE7Jw4cI89tijGTdu3Cptf911182kfffLtddclVfs9co/6thZO/38wUeyZd8T59cW48dlzoOPLLXOA7/4dY46+UtJkg3WG51D990ljzz2+8XLD3/1SzLj2juzcImiDZ6uTcf3Ze4Sv4/z+udmfF/fMuss//exf+7cnHTCsTntwx/NxIlbrdaxs+pW5aL5tclwHW9fkjcl+bOneP1ymPa5Vttp511y330/y5zZs7NgwfzMunxmJu07eal19tl3ci695GtJkm9eOSt7vPwVK+yd//a3v8mDD85LMngN2vXf/laev80Lhu8gWKvcevf92W7i87L15s/NOqNG5sgpL81l1y09C3OTsesvPgff9ZeT86VLb1lq+Wu1N/kj2GnnXXL/z5b+fdxn0jK/j5Mm5+szBn8fr/rGrOyx5+Dv46O//nXe8fa35bgTTspLd33GV+/AH90qPUngGfh6kg1rrf+97IJSyrXDtM+12qhRo3Lye0/NMW97axYNLMr0ww7Pttttn7PP+kx23GnnTNp3cg59zRF5/ynvzrQDp2TM2LE5/eNnLv7+QVMm5zeP/SYLFizINVdflbPPOT/jxo7LCccekwXz52dRrXnZnnvmiNce1eFRsiYZGFiUEz9+cS79zF9n5IiSL116S77/k/6cevQBue379+ey6+7O3rtvl9OOOTA1yfXf+0lO+NhFi7+/1WYbZ8u+cbnutp90dxCsFR7/fXz73wz+Pk4b+n38p6Hfx32Gfh9PPeXdmXbQlIwdOzYf+djg7+N/fPnfcv/99+Xcz52dcz93dpLk7M+fn+duskmXh8RT6LVJbKU22knU4qQFm7zyXV0PAZIkv7j+410PAZIkG4zuplJ6x9d+0Fld8JlDd1jtx7wqj3oqSV6f5AW11tNKKVslmVBrvXnYRwcAkGREbwVoq3QN2tlJ/jTJ64beP5rks8M2IgCAHrcq16C9vNa6Wynle0lSa32olOImMQAAw2RVCrQFpZSRSWqSlFI2TWJOPACw2mhxPtlnklycZHwp5UNJrk/y4WEdFQBAD1tpglZr/bdSyneT7JfBG80eWmv9/rCPDABgSK/dZmNVZnFuleS3SS5d8rNa633DOTAAgF61KtegXZbB689Kkuck2SbJD5PsNIzjAgDoWavS4txlyfellN2SHDNsIwIAWIZJAitRa70tycuHYSwAAGTVrkH7uyXejkiyW5KfD9uIAACW0WNzBFbpGrSNlvh7YQavSfvq8AwHAIAVFmhDN6jdqNb6ztU0HgCAJxnRYxHacq9BK6WMqrUOJHnlahwPAEDPW1GCdnMGrzf771LKjCQXJvnN4wtrrRcN89gAAHrSqlyD9pwkv0wyOU/cD60mUaABAKvF077txBpuRQXa+KEZnHfmicLscXVYRwUA0MNWVKCNTLJhli7MHqdAAwBWmx6bI7DCAu2BWutpq20kAAAkWXGB1mO1KgDQKrfZeMJ+q20UAAAsttwCrdb6q9U5EAAABq3KbTYAADrVYx3OnrutCABA8yRoAEDzRkjQAADokgINAKAxWpwAQPPcBw0AgE5J0ACA5vVYgCZBAwBojQQNAGie22wAANApBRoAQGO0OAGA5pX0Vo9TggYA0BgJGgDQPJMEAADolAQNAGieBA0AgE4p0AAAGqPFCQA0r/TYwzglaAAAjZGgAQDNM0kAAIBOKdAAABqjxQkANK/H5ghI0AAAWiNBAwCaN6LHIjQJGgBAYxRoAEDzRpTuXitTSplaSvlhKeWeUsp7VrDe4aWUWkp52UqP9+n94wEA4HGllJFJPpvkwCQ7JnldKWXHp1hvoyTHJ/nOqmxXgQYA8MztmeSeWutPaq3zk3wlyfSnWO//S/LRJL9flY0q0ACA5pXS3Wsltkhy/xLvZw99tsTYy25JJtZaL1vV41WgAQCsQCnl6FLKrUu8jn4a3x2R5MwkJz2dfbrNBgDQvBHp7jYbtdZzkpyznMVzkkxc4v2WQ589bqMkOye5tgzGcROSzCilTKu13rq8fUrQAACeuVuSbF9K2aaUMjrJUUlmPL6w1vpIrfV5tdbn11qfn+SmJCsszhIJGgCwBmj1PrW11oWllGOTzEoyMskXaq13lVJOS3JrrXXGirfw1BRoAADPQq11ZpKZy3z2geWsO2lVtqnFCQDQGAkaANC8Vbmj/9pEggYA0BgJGgDQvBGtzhIYJhI0AIDGKNAAABqjxQkANK/HOpwSNACA1kjQAIDmmSQAAECnJGgAQPN6LECToAEAtEaBBgDQGC1OAKB5vZYo9drxAgA0T4IGADSv9NgsAQkaAEBjFGgAAI3R4gQAmtdbDU4JGgBAcyRoAEDzPIsTAIBOSdAAgOb1Vn4mQQMAaI4CDQCgMVqcAEDzemyOgAQNAKA1EjQAoHmexQkAQKckaABA83otUeq14wUAaJ4CDQCgMVqcAEDzTBIAAKBTEjQAoHm9lZ9J0AAAmqNAAwBojBYnrMBD/3VG10OAJMnGexzb9RAgSfK7753VyX5NEgAAoFMSNACgeb2WKPXa8QIANE+CBgA0zzVoAAB0SoEGANAYLU4AoHm91eCUoAEANEeCBgA0r8fmCEjQAABaI0EDAJo3oseuQpOgAQA0RoEGANAYLU4AoHkmCQAA0CkJGgDQvGKSAAAAXVKgAQA0RosTAGieSQIAAHRKggYANM+TBAAA6JQEDQBonmvQAADolAINAKAxWpwAQPO0OAEA6JQEDQBonmdxAgDQKQUaAEBjtDgBgOaN6K0OpwQNAKA1EjQAoHkmCQAA0CkJGgDQPDeqBQCgUwo0AIDGaHECAM0zSQAAgE5J0ACA5rlRLQAAnZKgAQDNcw0aAACdUqABADRGixMAaJ4nCQAA0CkJGgDQvB4L0CRoAACtUaABADRGixMAaN6IHpslIEEDAGiMBA0AaF5v5WcSNACA5kjQAID29ViEJkEDAGiMAg0AoDFanABA80qP9TglaAAAjZGgAQDN67H71ErQAABaI0EDAJrXYwGaBA0AoDUKNACAxmhxAgDt67EepwQNAKAxEjQAoHluVAsAQKcUaAAAjdHiBACa50kCAAB0SoIGADSvxwI0CRoAQGskaABA+3osQpOgAQA0RoEGANAYLU4AoHmeJAAAQKcUaABA80rp7rXysZWppZQfllLuKaW85ymW/10p5e5Syu2llKtKKVuvbJsKNACAZ6iUMjLJZ5McmGTHJK8rpVlyeiEAABAjSURBVOy4zGrfS/KyWuuLk/xnko+tbLsKNACAZ27PJPfUWn9Sa52f5CtJpi+5Qq31mlrrb4fe3pRky5VtVIEGADSvdPkq5ehSyq1LvI5eYmhbJLl/ifezhz5bnrcmuXxlx2sWJwDACtRaz0lyzrPdTinlDUlelmSfla2rQAMA2tfuXTbmJJm4xPsthz5bSinl1Unel2SfWusfVrZRLU4AgGfuliTbl1K2KaWMTnJUkhlLrlBK2TXJ55NMq7XOW5WNStAAgOa1eqPaWuvCUsqxSWYlGZnkC7XWu0oppyW5tdY6I8nHk2yY5MIyeN+O+2qt01a0XQUaAMCzUGudmWTmMp99YIm/X/10t6nFCQDQGAkaANC8Vbmj/9pEggYA0BgJGgDQvB4L0CRoAACtkaABAO3rsQhNggYA0BgFGgBAY7Q4AYDmtfokgeEiQQMAaIwEDQBonhvVska44frrcughUzPtwCn5wnnnPGn5/Pnzc/JJJ2bagVPyxte9Nj+fMztJ8vDDD+Wv3/ym7LXHbjn9Q6et7mGzFrjhum9n2sEH5JCp++f8c5/63HvXSSfkkKn75/VHHZk5Q+dekpx/7udzyNT9M+3gA3LD9dclSf7whz/k//75ETnysGk5bNrBOfusz6y2Y2Htsf9eL8r/XHxq7rzk7/PON+//pOVbbbZxZn7uuNz8H6dk1rnHZ4vx4xYv++A7pufWC9+bWy98b46YstvqHDYslwJtDTQwMJDTP3hazvqnc/PVGV/PFTMvy7333rPUOl+76D+z0ZgxmXH5lXn9G/8inz7zE0mSdUevm2OOOz4nvvPdXQydNdzAwEA+/KHTcvbnzsvFMy7LFTO/nnvvWfrcu/irF2bMmDH5+hXfyBve9Jf51JlnJEnuveeeXDHzslw047Kc/fnz8uEP/kMGBgYyevTonPeFL+XCi2fkgq9+LTdcf11u/5//7uLwWEONGFHyqfe8NtOPPTu7Hv7BHDl19+zwgglLrfOREw/Lv112c/b884/kw+dcntOOm5Ykmfp/dspLXzQxLz/q9Oz9xjNywpv2y0YbPKeLw4ClDFuBVkrZoZSyXyllw2U+nzpc++wVd95xeyZutVW2nDgx66wzOgcceFCuvfqqpda59uqr8mfTD02SvHrKAbn5Ozem1pr11l8/u+62e9Zdd3QXQ2cNd+cdt2fixK0Hz73RozP1oINz7TVLn3vXXH11pk0/LEmy/5QDcvNNg+fetddclakHHZzRo0dnyy0nZuLErXPnHbenlJL1N9ggSbJw4cIsXLiw93oZPCt77Pz83Hv/L/LTOb/MgoUDuXDWbTlk0ouXWmeHF2yWb938wyTJt275UQ6ZtEuS5EUvmJDrb7snAwOL8tvfz88dP56TKXu9aLUfAytXOnx1YVgKtFLKO5JckuS4JHeWUqYvsfjDw7HPXjJvXn/6Jmy2+H1f34Q8OK9/mXXmZcLQOqNGjcqGG26Uhx9+eLWOk7XPvP7+TNjsiWRifF9f+vuXPff6lz73NtooDz/8UPr7+9M34Ynv9k3oy7yh7w4MDOS1r5mefV+1V17xp3vlxS9+yWo4GtYWm48fm9n9Dy1+P6f/oWyx6dil1rnjR3MyffJLkyTTJ78kYzZcL88du0Fu/9FgQbbec9bJJuM2yD4ve2G2nLDxah0/PJXhStD+OsnutdZDk0xKcmop5fihZcstRkspR5dSbi2l3PpU11UBa6eRI0fmgosuyZVXfyt33nF7fvzjH3U9JNYyp3zy4rxq9+1y45dPzqt23y5z+h/KwMCiXHXTD3LF9Xfnmi+elC995M35zu3/m4GBRV0Pl6fSYxHacM3iHFFrfSxJaq0/LaVMSvKfpZSts4JDrbWek+ScJPntglqHaWxrvPHj+9I/94HF7/v752bT8X3LrDM+c+c+kL4JE7Jw4cI89tijGTdu3LKbgqdlfF9f5j4wd/H7ef396etb9tzrW/rce/TRjBu3cfr6+tI/94nv9s/tz/hlvjtmzJjssefL81/XX5ftt3/h8B4Ma42fz3skW/Y9kXpt0bdx5jz4yFLrPPDgIznqneclSTZYb3QO3e+leeSx3yVJPnb+rHzs/FlJki9++C/z4/vmraaRw/INV4LWX0p56eNvhoq1Q5I8L8kuw7TPnrHTzrvkvvt+ljmzZ2fBgvmZdfnMTNp38lLr7LPv5Fx6ydeSJN+8clb2ePkrUlzXw7M0eO79NLNn358F8+fnipmXZZ9lzr1J+07OjEsuTpJ848pZ2XPo3Ntn38m5YuZlmT9/fmbPvj/33ffT7LzLi/OrX/0qv/71r5Mkv//973PTjf+V52/zgtV+bKy5br3rZ9luq02z9eabZJ1RI3PkAbvlsmtvX2qdTcZtsPg38F1vOSBfuuSmJIMTDJ47dvAayJ233zw7b795vnnjD1bvAbBKSof/6cJwJWhvSrJwyQ9qrQuTvKmU8vlh2mfPGDVqVE5+76k55m1vzaKBRZl+2OHZdrvtc/ZZn8mOO+2cSftOzqGvOSLvP+XdmXbglIwZOzanf/zMxd8/aMrk/Oax32TBggW55uqrcvY552fbbbfr8IhYU4waNSqnvO8D+duj/yqLFg3k0MMOz3bbbZ/P/uOns9NOO2fS5P1y2OFH5H3veVcOmbp/xowdm4+d8ckkyXbbbZ8pUw/MYdMOysiRI/Pe938gI0eOzC8enJf3v/c9WbRoIIsW1Uw5YGr2mbRvx0fKmmRgYFFO/OgFufTst2fkiJIvXXJTvv+TuTn1bw/ObXffl8u+dUf2ftn2Oe24aak1uf62e3LCRy5IkqwzamS++YUTkiSPPvb7vOV9X9LipAmlNtpJ1OKkBSOkjjRi4z2O7XoIkCT53ffO6uSH8QcP/LazumCHzdZf7cfsSQIAQPN67d+X3agWAKAxEjQAoHk9FqBJ0AAAWiNBAwDa12MRmgQNAKAxCjQAgMZocQIAzevqjv5dkaABADRGggYANM+NagEA6JQCDQCgMVqcAEDzeqzDKUEDAGiNBA0AaF+PRWgSNACAxkjQAIDmuVEtAACdUqABADRGixMAaJ4nCQAA0CkJGgDQvB4L0CRoAACtUaABADRGixMAaF+P9TglaAAAjZGgAQDN8yQBAAA6JUEDAJrnRrUAAHRKgQYA0BgtTgCgeT3W4ZSgAQC0RoIGADTPJAEAADolQQMA1gC9FaFJ0AAAGqNAAwBojBYnANA8kwQAAOiUBA0AaF6PBWgSNACA1ijQAAAao8UJADTPJAEAADolQQMAmld6bJqABA0AoDESNACgfb0VoEnQAABao0ADAGiMFicA0Lwe63BK0AAAWiNBAwCa50a1AAB0SoIGADTPjWoBAOiUAg0AoDFanABA+3qrwylBAwBojQQNAGhejwVoEjQAgNYo0AAAGqPFCQA0z5MEAADolAQNAGieJwkAANApCRoA0DzXoAEA0CkFGgBAYxRoAACNUaABADTGJAEAoHkmCQAA0CkJGgDQPDeqBQCgUwo0AIDGaHECAM0zSQAAgE5J0ACA5vVYgCZBAwBojQINAKAxWpwAQPt6rMcpQQMAaIwEDQBonicJAADQKQkaANA8N6oFAKBTCjQAgMZocQIAzeuxDqcEDQCgNRI0AKB9PRahSdAAABqjQAMAaIwWJwDQPE8SAACgUxI0AKB5niQAAECnSq216zEwTEopR9daz+l6HOBcpAXOQ9YkErS129FdDwCGOBdpgfOQNYYCDQCgMQo0AIDGKNDWbq61oBXORVrgPGSNYZIAAEBjJGgAAI1RoAEANEaBtpYqpUwtpfywlHJPKeU9XY+H3lRK+UIpZV4p5c6ux0LvKqVMLKVcU0q5u5RyVynl+K7HBCvjGrS1UCllZJIfJdk/yewktyR5Xa317k4HRs8ppeyd5LEk/1xr3bnr8dCbSimbJdms1npbKWWjJN9NcqjfRFomQVs77ZnknlrrT2qt85N8Jcn0jsdED6q1fjvJr7oeB72t1vpArfW2ob8fTfL9JFt0OypYMQXa2mmLJPcv8X52/BgBpJTy/CS7JvlOtyOBFVOgAdATSikbJvlqkhNqrb/uejywIgq0tdOcJBOXeL/l0GcAPamUsk4Gi7N/q7Ve1PV4YGUUaGunW5JsX0rZppQyOslRSWZ0PCaATpRSSpLzk3y/1npm1+OBVaFAWwvVWhcmOTbJrAxeDHtBrfWubkdFLyqlfDnJjUn+pJQyu5Ty1q7HRE96ZZI3JplcSvnvoddBXQ8KVsRtNgAAGiNBAwBojAINAKAxCjQAgMYo0AAAGqNAAwBojAIN1kKllIGhWwncWUq5sJSy/rPY1hdLKUcM/X1eKWXHFaw7qZSy1zPYx09LKc9b1c+XWeexp7mv/1dKeefTHSPA6qRAg7XT72qtL6217pxkfpK/WXJhKWXUM9lorfWvaq13r2CVSUmedoEGwNIUaLD2uy7JdkPp1nWllBlJ7i6ljCylfLyUcksp5fZSytuSwbuul1LOKqX8sJTyzSTjH99QKeXaUsrLhv6eWkq5rZTyP6WUq4YeQv03SU4cSu9eVUrZtJTy1aF93FJKeeXQdzcppVxZSrmrlHJekrKygyilfK2U8t2h7xy9zLJPDn1+VSll06HPti2lXDH0netKKTv8Mf5hAqwOz+jfooE1w1BSdmCSK4Y+2i3JzrXW/x0qch6pte5RSlk3yQ2llCuT7JrkT5LsmKQvyd1JvrDMdjdNcm6SvYe29dxa669KKZ9L8lit9Yyh9f49ySdrrdeXUrbK4NMtXpTk75NcX2s9rZRycJJVecLAW4b2sV6SW0opX621/jLJBklurbWeWEr5wNC2j01yTpK/qbX+uJTy8iRnJ5n8DP4xAqx2CjRYO61XSvnvob+vy+BzCPdKcnOt9X+HPp+S5MWPX1+WZGyS7ZPsneTLtdaBJD8vpVz9FNt/RZJvP76tWuuvljOOVyfZcfBRiEmSMaWUDYf28Zqh715WSnloFY7pHaWUw4b+njg01l8mWZTkP4Y+/9ckFw3tY68kFy6x73VXYR8ATVCgwdrpd7XWly75wVCh8pslP0pyXK111jLr/TGfUTgiyStqrb9/irGsslLKpAwWe39aa/1tKeXaJM9Zzup1aL8PL/vPAGBN4Ro06F2zkvxtKWWdJCmlvLCUskGSbyf586Fr1DZLsu9TfPemJHuXUrYZ+u5zhz5/NMlGS6x3ZZLjHn9TSnm8YPp2kv879NmBSTZeyVjHJnloqDjbIYMJ3uNGJHk8Bfy/GWyd/jrJ/5ZSjhzaRymlvGQl+wBohgINetd5Gby+7LZSyp1JPp/BVP3iJD8eWvbPSW5c9ou11geTHJ3BduL/5IkW46VJDnt8kkCSdyR52dAkhLvzxGzSf8hggXdXBlud961krFckGVVK+X6S0zNYID7uN0n2HDqGyUlOG/r89UneOjS+u5JMX4V/JgBNKLXWrscAAMASJGgAAI1RoAEANEaBBgDQGAUaAEBjFGgAAI1RoAEANEaBBgDQmP8fonNsfwVKl7kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "7dfcdb9a-8326-433f-ddf3-e4ce98013214"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'#dominance\\nX_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\\nprint(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "e207bb62-db12-40dc-ac60-8b379787a256"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'foldNum=0\\nmodel = get_model()\\nfor train_index, val_index in kfold.split(X_train, Y_train):\\n  foldNum = foldNum + 1\\n  print(\"Results for fold\",foldNum)\\n  x_train, x_val = X_train[train_index], X_train[val_index]\\n  y_train, y_val = Y_train[train_index], Y_train[val_index]\\n  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\\n  gc.collect() # Garbage collecter\\n  del x_train, x_val, y_train, y_val\\n  gc.collect()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "08a1c2d1-a94a-41ee-bad3-4ba4400d157b"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'acrc = model.evaluate(x_test, y_test)\\npred = model.predict(x_test)\\nf1scr = f1_score(y_test.argmax(1), pred.argmax(1), average=\\'macro\\')\\nc_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\\nprint(\"Accuracy  : {}\".format(acrc[1]))\\nprint(\"F1_Score  : {}\".format(f1scr))\\nc_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\\nimport seaborn as sns\\nfigure = plt.figure(figsize=(9, 9))\\nsns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\\nplt.tight_layout()\\nplt.ylabel(\\'True label\\')\\nplt.xlabel(\\'Predicted label\\')\\nplt.show()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}