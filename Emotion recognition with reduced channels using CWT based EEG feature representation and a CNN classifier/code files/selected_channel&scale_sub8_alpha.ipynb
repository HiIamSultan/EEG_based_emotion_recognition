{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub8_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "5b7834bf-8617-4930-f08a-87a41d659134"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e3\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  #EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "098859b7-39de-40b2-f99f-8089551b2c3b"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(8,9):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.8\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (1864,) (3961,) (3495,)\n",
            "(9320,) (1631,) (3728,) (3961,)\n",
            "(9320,) (2563,) (4427,) (2330,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "0b8b5f0b-4241-425c-8262-bf2021870768"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "86e74494-d663-4d39-d306-f860c68e1c71"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "706"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "502d9198-d321-4c33-f8e6-caf11504b8bb"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a88a827-6a02-42e5-c7e1-7669b234c13a"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 48s 71ms/step - loss: 1.1457 - accuracy: 0.3948 - val_loss: 1.0523 - val_accuracy: 0.4263\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0642 - accuracy: 0.4277 - val_loss: 1.0488 - val_accuracy: 0.4263\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0509 - accuracy: 0.4355 - val_loss: 1.0481 - val_accuracy: 0.4249\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0586 - accuracy: 0.4116 - val_loss: 1.0487 - val_accuracy: 0.4263\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 1.0510 - accuracy: 0.4310 - val_loss: 1.0493 - val_accuracy: 0.4303\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 1.0519 - accuracy: 0.4238 - val_loss: 1.0461 - val_accuracy: 0.4263\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 1.0557 - accuracy: 0.4198 - val_loss: 1.0502 - val_accuracy: 0.4263\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0460 - accuracy: 0.4293 - val_loss: 1.0484 - val_accuracy: 0.4263\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0424 - accuracy: 0.4422 - val_loss: 1.0448 - val_accuracy: 0.4330\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0487 - accuracy: 0.4287 - val_loss: 1.0463 - val_accuracy: 0.4343\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0453 - accuracy: 0.4412 - val_loss: 1.0465 - val_accuracy: 0.4263\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0501 - accuracy: 0.4238 - val_loss: 1.0455 - val_accuracy: 0.4263\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0352 - accuracy: 0.4450 - val_loss: 1.0418 - val_accuracy: 0.4223\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 1.0451 - accuracy: 0.4284 - val_loss: 1.0407 - val_accuracy: 0.4249\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0435 - accuracy: 0.4366 - val_loss: 1.0428 - val_accuracy: 0.4316\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0424 - accuracy: 0.4270 - val_loss: 1.0377 - val_accuracy: 0.4370\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0417 - accuracy: 0.4360 - val_loss: 1.0385 - val_accuracy: 0.4316\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0317 - accuracy: 0.4352 - val_loss: 1.0364 - val_accuracy: 0.4383\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0378 - accuracy: 0.4312 - val_loss: 1.0362 - val_accuracy: 0.4477\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0286 - accuracy: 0.4585 - val_loss: 1.0374 - val_accuracy: 0.4343\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0318 - accuracy: 0.4506 - val_loss: 1.0355 - val_accuracy: 0.4598\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0265 - accuracy: 0.4526 - val_loss: 1.0307 - val_accuracy: 0.4424\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0306 - accuracy: 0.4424 - val_loss: 1.0275 - val_accuracy: 0.4397\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0195 - accuracy: 0.4629 - val_loss: 1.0256 - val_accuracy: 0.4678\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0318 - accuracy: 0.4622 - val_loss: 1.0302 - val_accuracy: 0.4437\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 1.0200 - accuracy: 0.4750 - val_loss: 1.0161 - val_accuracy: 0.4651\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 1.0145 - accuracy: 0.4792 - val_loss: 1.0073 - val_accuracy: 0.4893\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 1.0206 - accuracy: 0.4715 - val_loss: 1.0091 - val_accuracy: 0.4732\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 1.0125 - accuracy: 0.4769 - val_loss: 1.0116 - val_accuracy: 0.4772\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0085 - accuracy: 0.4737 - val_loss: 0.9998 - val_accuracy: 0.4933\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 1.0081 - accuracy: 0.4717 - val_loss: 1.0014 - val_accuracy: 0.5027\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.9950 - accuracy: 0.4815 - val_loss: 0.9793 - val_accuracy: 0.5027\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.9928 - accuracy: 0.4893 - val_loss: 0.9848 - val_accuracy: 0.4705\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9911 - accuracy: 0.4872 - val_loss: 0.9720 - val_accuracy: 0.5013\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.9884 - accuracy: 0.4912 - val_loss: 0.9754 - val_accuracy: 0.4946\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.9870 - accuracy: 0.4924 - val_loss: 0.9649 - val_accuracy: 0.5241\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9809 - accuracy: 0.4979 - val_loss: 0.9604 - val_accuracy: 0.5054\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9812 - accuracy: 0.4958 - val_loss: 0.9525 - val_accuracy: 0.5389\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9721 - accuracy: 0.4982 - val_loss: 0.9417 - val_accuracy: 0.5362\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9637 - accuracy: 0.5112 - val_loss: 0.9555 - val_accuracy: 0.5161\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9610 - accuracy: 0.5155 - val_loss: 0.9508 - val_accuracy: 0.5241\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9524 - accuracy: 0.5255 - val_loss: 0.9348 - val_accuracy: 0.5362\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9457 - accuracy: 0.5194 - val_loss: 0.9363 - val_accuracy: 0.5174\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9469 - accuracy: 0.5200 - val_loss: 0.9345 - val_accuracy: 0.5188\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9373 - accuracy: 0.5300 - val_loss: 0.9347 - val_accuracy: 0.5241\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9400 - accuracy: 0.5256 - val_loss: 0.9667 - val_accuracy: 0.5456\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9352 - accuracy: 0.5320 - val_loss: 0.8989 - val_accuracy: 0.5737\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9272 - accuracy: 0.5347 - val_loss: 0.9029 - val_accuracy: 0.5469\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9230 - accuracy: 0.5413 - val_loss: 0.8981 - val_accuracy: 0.5469\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9078 - accuracy: 0.5493 - val_loss: 0.9092 - val_accuracy: 0.5550\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9019 - accuracy: 0.5462 - val_loss: 0.8933 - val_accuracy: 0.5483\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.8964 - accuracy: 0.5481 - val_loss: 0.8885 - val_accuracy: 0.5724\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.8868 - accuracy: 0.5559 - val_loss: 0.8936 - val_accuracy: 0.5710\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8863 - accuracy: 0.5686 - val_loss: 0.9057 - val_accuracy: 0.5349\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.8746 - accuracy: 0.5657 - val_loss: 0.8876 - val_accuracy: 0.5536\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8754 - accuracy: 0.5639 - val_loss: 0.8848 - val_accuracy: 0.5362\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8544 - accuracy: 0.5753 - val_loss: 0.9030 - val_accuracy: 0.5349\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8526 - accuracy: 0.5775 - val_loss: 0.8489 - val_accuracy: 0.5684\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8550 - accuracy: 0.5818 - val_loss: 0.8787 - val_accuracy: 0.5804\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8385 - accuracy: 0.5794 - val_loss: 0.8721 - val_accuracy: 0.5617\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8556 - accuracy: 0.5751 - val_loss: 0.7558 - val_accuracy: 0.6314\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8320 - accuracy: 0.5915 - val_loss: 0.7348 - val_accuracy: 0.6434\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8258 - accuracy: 0.5931 - val_loss: 0.7737 - val_accuracy: 0.6153\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8061 - accuracy: 0.6103 - val_loss: 0.7682 - val_accuracy: 0.6461\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8010 - accuracy: 0.6119 - val_loss: 0.7478 - val_accuracy: 0.6515\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7885 - accuracy: 0.6173 - val_loss: 0.7681 - val_accuracy: 0.6381\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.7886 - accuracy: 0.6213 - val_loss: 0.7477 - val_accuracy: 0.6314\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.7689 - accuracy: 0.6308 - val_loss: 0.7314 - val_accuracy: 0.6327\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7478 - accuracy: 0.6398 - val_loss: 0.7373 - val_accuracy: 0.6153\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.7636 - accuracy: 0.6382 - val_loss: 0.7430 - val_accuracy: 0.6515\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7442 - accuracy: 0.6486 - val_loss: 0.6977 - val_accuracy: 0.6408\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.7333 - accuracy: 0.6499 - val_loss: 0.7058 - val_accuracy: 0.6381\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.7271 - accuracy: 0.6610 - val_loss: 0.7018 - val_accuracy: 0.6555\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.7003 - accuracy: 0.6697 - val_loss: 0.6680 - val_accuracy: 0.6836\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.6963 - accuracy: 0.6735 - val_loss: 0.6791 - val_accuracy: 0.6917\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.6781 - accuracy: 0.6879 - val_loss: 0.6512 - val_accuracy: 0.6796\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.6716 - accuracy: 0.6973 - val_loss: 0.6354 - val_accuracy: 0.6836\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.6512 - accuracy: 0.7028 - val_loss: 0.6382 - val_accuracy: 0.6850\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.6405 - accuracy: 0.7137 - val_loss: 0.6213 - val_accuracy: 0.6944\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.6426 - accuracy: 0.7094 - val_loss: 0.6540 - val_accuracy: 0.6783\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.6298 - accuracy: 0.7146 - val_loss: 0.6501 - val_accuracy: 0.6823\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.5938 - accuracy: 0.7370 - val_loss: 0.6079 - val_accuracy: 0.7038\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.5815 - accuracy: 0.7395 - val_loss: 0.6025 - val_accuracy: 0.6997\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.5750 - accuracy: 0.7557 - val_loss: 0.7468 - val_accuracy: 0.6756\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.5765 - accuracy: 0.7414 - val_loss: 0.5818 - val_accuracy: 0.7105\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.5663 - accuracy: 0.7539 - val_loss: 0.5804 - val_accuracy: 0.7145\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.5384 - accuracy: 0.7694 - val_loss: 0.5230 - val_accuracy: 0.7681\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.5330 - accuracy: 0.7711 - val_loss: 0.5350 - val_accuracy: 0.7493\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.5061 - accuracy: 0.7876 - val_loss: 0.5520 - val_accuracy: 0.7493\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.5293 - accuracy: 0.7776 - val_loss: 0.5191 - val_accuracy: 0.7721\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.5250 - accuracy: 0.7768 - val_loss: 0.3159 - val_accuracy: 0.8727\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.5067 - accuracy: 0.7814 - val_loss: 0.2757 - val_accuracy: 0.8954\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.4936 - accuracy: 0.7914 - val_loss: 0.3478 - val_accuracy: 0.8445\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.4822 - accuracy: 0.7993 - val_loss: 0.2954 - val_accuracy: 0.8874\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.4504 - accuracy: 0.8130 - val_loss: 0.2883 - val_accuracy: 0.8767\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.4529 - accuracy: 0.8095 - val_loss: 0.2852 - val_accuracy: 0.8780\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.4251 - accuracy: 0.8215 - val_loss: 0.2893 - val_accuracy: 0.8820\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.4718 - accuracy: 0.8057 - val_loss: 0.3523 - val_accuracy: 0.8566\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.4379 - accuracy: 0.8225 - val_loss: 0.2639 - val_accuracy: 0.8981\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3761 - accuracy: 0.8466 - val_loss: 0.2537 - val_accuracy: 0.9008\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.4077 - accuracy: 0.8347 - val_loss: 0.2700 - val_accuracy: 0.8901\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.3958 - accuracy: 0.8466 - val_loss: 0.3021 - val_accuracy: 0.8767\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3673 - accuracy: 0.8507 - val_loss: 0.2362 - val_accuracy: 0.9008\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.3565 - accuracy: 0.8590 - val_loss: 0.2492 - val_accuracy: 0.8968\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3581 - accuracy: 0.8587 - val_loss: 0.2499 - val_accuracy: 0.9008\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.3530 - accuracy: 0.8598 - val_loss: 0.2611 - val_accuracy: 0.9102\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.3424 - accuracy: 0.8580 - val_loss: 0.2318 - val_accuracy: 0.9155\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3381 - accuracy: 0.8694 - val_loss: 0.2339 - val_accuracy: 0.9062\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2951 - accuracy: 0.8852 - val_loss: 0.2297 - val_accuracy: 0.9088\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.3100 - accuracy: 0.8823 - val_loss: 0.2780 - val_accuracy: 0.8780\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2984 - accuracy: 0.8894 - val_loss: 0.2049 - val_accuracy: 0.9249\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2883 - accuracy: 0.8928 - val_loss: 0.2078 - val_accuracy: 0.9182\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2802 - accuracy: 0.8927 - val_loss: 0.2239 - val_accuracy: 0.9035\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2882 - accuracy: 0.8923 - val_loss: 0.2403 - val_accuracy: 0.9142\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2795 - accuracy: 0.8931 - val_loss: 0.2348 - val_accuracy: 0.9075\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2583 - accuracy: 0.9022 - val_loss: 0.2079 - val_accuracy: 0.9155\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2522 - accuracy: 0.9043 - val_loss: 0.2256 - val_accuracy: 0.9155\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2587 - accuracy: 0.9067 - val_loss: 0.1906 - val_accuracy: 0.9330\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2543 - accuracy: 0.9034 - val_loss: 0.2105 - val_accuracy: 0.9142\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2264 - accuracy: 0.9165 - val_loss: 0.2380 - val_accuracy: 0.9035\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2673 - accuracy: 0.9019 - val_loss: 0.0656 - val_accuracy: 0.9826\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2574 - accuracy: 0.9075 - val_loss: 0.0470 - val_accuracy: 0.9906\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2348 - accuracy: 0.9109 - val_loss: 0.0517 - val_accuracy: 0.9866\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.2282 - accuracy: 0.9182 - val_loss: 0.0489 - val_accuracy: 0.9853\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2432 - accuracy: 0.9203 - val_loss: 0.0571 - val_accuracy: 0.9839\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2340 - accuracy: 0.9127 - val_loss: 0.0556 - val_accuracy: 0.9893\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.2252 - accuracy: 0.9234 - val_loss: 0.0520 - val_accuracy: 0.9839\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2025 - accuracy: 0.9303 - val_loss: 0.0760 - val_accuracy: 0.9732\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2066 - accuracy: 0.9270 - val_loss: 0.0641 - val_accuracy: 0.9879\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2056 - accuracy: 0.9238 - val_loss: 0.0555 - val_accuracy: 0.9839\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1793 - accuracy: 0.9371 - val_loss: 0.0429 - val_accuracy: 0.9879\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1882 - accuracy: 0.9358 - val_loss: 0.0439 - val_accuracy: 0.9893\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2039 - accuracy: 0.9268 - val_loss: 0.0553 - val_accuracy: 0.9826\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1900 - accuracy: 0.9326 - val_loss: 0.0413 - val_accuracy: 0.9866\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1837 - accuracy: 0.9374 - val_loss: 0.0435 - val_accuracy: 0.9893\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1700 - accuracy: 0.9377 - val_loss: 0.0458 - val_accuracy: 0.9839\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1839 - accuracy: 0.9362 - val_loss: 0.0691 - val_accuracy: 0.9745\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1692 - accuracy: 0.9410 - val_loss: 0.0399 - val_accuracy: 0.9893\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1705 - accuracy: 0.9416 - val_loss: 0.0404 - val_accuracy: 0.9893\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1557 - accuracy: 0.9480 - val_loss: 0.0462 - val_accuracy: 0.9893\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1583 - accuracy: 0.9492 - val_loss: 0.0444 - val_accuracy: 0.9866\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1577 - accuracy: 0.9474 - val_loss: 0.0537 - val_accuracy: 0.9786\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1811 - accuracy: 0.9414 - val_loss: 0.0353 - val_accuracy: 0.9893\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1575 - accuracy: 0.9441 - val_loss: 0.0535 - val_accuracy: 0.9812\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.1507 - accuracy: 0.9481 - val_loss: 0.0480 - val_accuracy: 0.9812\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1433 - accuracy: 0.9505 - val_loss: 0.0414 - val_accuracy: 0.9879\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1454 - accuracy: 0.9493 - val_loss: 0.0329 - val_accuracy: 0.9933\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1441 - accuracy: 0.9526 - val_loss: 0.0480 - val_accuracy: 0.9826\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1382 - accuracy: 0.9544 - val_loss: 0.0398 - val_accuracy: 0.9866\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1381 - accuracy: 0.9574 - val_loss: 0.0579 - val_accuracy: 0.9799\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.1696 - accuracy: 0.9440 - val_loss: 0.0170 - val_accuracy: 0.9960\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1487 - accuracy: 0.9477 - val_loss: 0.0113 - val_accuracy: 0.9987\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1283 - accuracy: 0.9538 - val_loss: 0.0103 - val_accuracy: 0.9987\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1399 - accuracy: 0.9542 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1369 - accuracy: 0.9544 - val_loss: 0.0120 - val_accuracy: 0.9973\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1291 - accuracy: 0.9542 - val_loss: 0.0097 - val_accuracy: 0.9987\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1125 - accuracy: 0.9638 - val_loss: 0.0110 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1181 - accuracy: 0.9586 - val_loss: 0.0126 - val_accuracy: 0.9973\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.1333 - accuracy: 0.9550 - val_loss: 0.0122 - val_accuracy: 0.9973\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1376 - accuracy: 0.9545 - val_loss: 0.0129 - val_accuracy: 0.9973\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1271 - accuracy: 0.9578 - val_loss: 0.0158 - val_accuracy: 0.9960\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1122 - accuracy: 0.9611 - val_loss: 0.0108 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1294 - accuracy: 0.9592 - val_loss: 0.0127 - val_accuracy: 0.9973\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1053 - accuracy: 0.9647 - val_loss: 0.0215 - val_accuracy: 0.9920\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1067 - accuracy: 0.9639 - val_loss: 0.0091 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0959 - accuracy: 0.9677 - val_loss: 0.0085 - val_accuracy: 0.9987\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0919 - accuracy: 0.9718 - val_loss: 0.0093 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1075 - accuracy: 0.9645 - val_loss: 0.0124 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.1087 - accuracy: 0.9647 - val_loss: 0.0110 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1027 - accuracy: 0.9656 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0985 - accuracy: 0.9697 - val_loss: 0.0102 - val_accuracy: 0.9973\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0997 - accuracy: 0.9680 - val_loss: 0.0076 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1099 - accuracy: 0.9642 - val_loss: 0.0245 - val_accuracy: 0.9893\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1534 - accuracy: 0.9481 - val_loss: 0.0273 - val_accuracy: 0.9906\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0971 - accuracy: 0.9686 - val_loss: 0.0134 - val_accuracy: 0.9960\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0932 - accuracy: 0.9697 - val_loss: 0.0194 - val_accuracy: 0.9933\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0960 - accuracy: 0.9675 - val_loss: 0.0130 - val_accuracy: 0.9973\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0928 - accuracy: 0.9692 - val_loss: 0.0133 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1035 - accuracy: 0.9656 - val_loss: 0.0147 - val_accuracy: 0.9960\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0908 - accuracy: 0.9690 - val_loss: 0.0158 - val_accuracy: 0.9933\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.1148 - accuracy: 0.9623 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0941 - accuracy: 0.9723 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1064 - accuracy: 0.9633 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0939 - accuracy: 0.9703 - val_loss: 8.4688e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1130 - accuracy: 0.9650 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0907 - accuracy: 0.9692 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0886 - accuracy: 0.9726 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1002 - accuracy: 0.9668 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0971 - accuracy: 0.9678 - val_loss: 0.0054 - val_accuracy: 0.9987\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0910 - accuracy: 0.9706 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0911 - accuracy: 0.9724 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0761 - accuracy: 0.9769 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0797 - accuracy: 0.9765 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0844 - accuracy: 0.9717 - val_loss: 0.0045 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0953 - accuracy: 0.9692 - val_loss: 0.0053 - val_accuracy: 0.9973\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0927 - accuracy: 0.9692 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0922 - accuracy: 0.9698 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0713 - accuracy: 0.9775 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0775 - accuracy: 0.9751 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0886 - accuracy: 0.9715 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0823 - accuracy: 0.9741 - val_loss: 0.0067 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0821 - accuracy: 0.9739 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0845 - accuracy: 0.9738 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0599 - accuracy: 0.9809 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0781 - accuracy: 0.9765 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0773 - accuracy: 0.9765 - val_loss: 0.0053 - val_accuracy: 0.9973\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0672 - accuracy: 0.9774 - val_loss: 0.0051 - val_accuracy: 0.9973\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0693 - accuracy: 0.9751 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0657 - accuracy: 0.9803 - val_loss: 0.0081 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0848 - accuracy: 0.9741 - val_loss: 0.0078 - val_accuracy: 0.9973\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0832 - accuracy: 0.9709 - val_loss: 5.9373e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0820 - accuracy: 0.9744 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0756 - accuracy: 0.9756 - val_loss: 5.9989e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0678 - accuracy: 0.9790 - val_loss: 7.1360e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0812 - accuracy: 0.9765 - val_loss: 9.2592e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0722 - accuracy: 0.9771 - val_loss: 5.0663e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0683 - accuracy: 0.9779 - val_loss: 9.9718e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0850 - accuracy: 0.9735 - val_loss: 9.1496e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0840 - accuracy: 0.9724 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0786 - accuracy: 0.9756 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0773 - accuracy: 0.9782 - val_loss: 9.7356e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0593 - accuracy: 0.9832 - val_loss: 9.9259e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0630 - accuracy: 0.9821 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0685 - accuracy: 0.9791 - val_loss: 8.7868e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0774 - accuracy: 0.9776 - val_loss: 4.6406e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0536 - accuracy: 0.9844 - val_loss: 4.8028e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0661 - accuracy: 0.9794 - val_loss: 0.0021 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0908 - accuracy: 0.9723 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0713 - accuracy: 0.9793 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0630 - accuracy: 0.9808 - val_loss: 5.1330e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0639 - accuracy: 0.9800 - val_loss: 8.3106e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0597 - accuracy: 0.9805 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0779 - accuracy: 0.9765 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0603 - accuracy: 0.9824 - val_loss: 9.0416e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0545 - accuracy: 0.9812 - val_loss: 5.8178e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0663 - accuracy: 0.9803 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0546 - accuracy: 0.9812 - val_loss: 3.6793e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0512 - accuracy: 0.9827 - val_loss: 5.9793e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0665 - accuracy: 0.9793 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0732 - accuracy: 0.9787 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0724 - accuracy: 0.9791 - val_loss: 1.5684e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0579 - accuracy: 0.9841 - val_loss: 2.0406e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0533 - accuracy: 0.9833 - val_loss: 1.3354e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0685 - accuracy: 0.9797 - val_loss: 3.4242e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0575 - accuracy: 0.9821 - val_loss: 2.1082e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0642 - accuracy: 0.9817 - val_loss: 1.6214e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0642 - accuracy: 0.9806 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0509 - accuracy: 0.9854 - val_loss: 3.6986e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0571 - accuracy: 0.9826 - val_loss: 2.2157e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0642 - accuracy: 0.9787 - val_loss: 1.6114e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0641 - accuracy: 0.9785 - val_loss: 1.4365e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0652 - accuracy: 0.9803 - val_loss: 7.0115e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0556 - accuracy: 0.9832 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0648 - accuracy: 0.9790 - val_loss: 4.2496e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0553 - accuracy: 0.9832 - val_loss: 3.8076e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0530 - accuracy: 0.9842 - val_loss: 3.9778e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0426 - accuracy: 0.9885 - val_loss: 1.5251e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0495 - accuracy: 0.9851 - val_loss: 9.4275e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0531 - accuracy: 0.9833 - val_loss: 2.7727e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0552 - accuracy: 0.9832 - val_loss: 0.0014 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0617 - accuracy: 0.9821 - val_loss: 0.0034 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0623 - accuracy: 0.9818 - val_loss: 6.0005e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0595 - accuracy: 0.9841 - val_loss: 4.5070e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0495 - accuracy: 0.9863 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0484 - accuracy: 0.9835 - val_loss: 2.8187e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0451 - accuracy: 0.9858 - val_loss: 1.5438e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0411 - accuracy: 0.9869 - val_loss: 6.6668e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0582 - accuracy: 0.9832 - val_loss: 0.0085 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0500 - accuracy: 0.9852 - val_loss: 2.9936e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0492 - accuracy: 0.9847 - val_loss: 3.3695e-04 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0456 - accuracy: 0.9851 - val_loss: 8.8959e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0578 - accuracy: 0.9811 - val_loss: 2.5921e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0949 - accuracy: 0.9733 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0483 - accuracy: 0.9875 - val_loss: 1.2032e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0538 - accuracy: 0.9845 - val_loss: 1.4835e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0587 - accuracy: 0.9845 - val_loss: 1.4562e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0336 - accuracy: 0.9882 - val_loss: 7.3799e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0487 - accuracy: 0.9848 - val_loss: 1.6249e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0426 - accuracy: 0.9863 - val_loss: 5.0835e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0566 - accuracy: 0.9835 - val_loss: 8.9532e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0512 - accuracy: 0.9850 - val_loss: 3.2768e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0475 - accuracy: 0.9855 - val_loss: 7.7478e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0499 - accuracy: 0.9850 - val_loss: 2.2452e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0826 - accuracy: 0.9751 - val_loss: 2.9428e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0555 - accuracy: 0.9827 - val_loss: 2.3625e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0666 - accuracy: 0.9791 - val_loss: 5.4819e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0506 - accuracy: 0.9844 - val_loss: 5.4595e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0367 - accuracy: 0.9896 - val_loss: 2.0618e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0464 - accuracy: 0.9855 - val_loss: 4.1434e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0389 - accuracy: 0.9860 - val_loss: 1.0929e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0503 - accuracy: 0.9847 - val_loss: 2.2657e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0517 - accuracy: 0.9848 - val_loss: 2.2156e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0447 - accuracy: 0.9872 - val_loss: 7.7791e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0402 - accuracy: 0.9882 - val_loss: 1.0442e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0435 - accuracy: 0.9873 - val_loss: 2.1735e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0417 - accuracy: 0.9867 - val_loss: 3.3828e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0407 - accuracy: 0.9879 - val_loss: 1.7483e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0478 - accuracy: 0.9842 - val_loss: 3.1409e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0378 - accuracy: 0.9860 - val_loss: 1.4087e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0446 - accuracy: 0.9864 - val_loss: 3.8504e-04 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAnc2SJa3o9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "def347be-c11b-468d-bc6a-fd50c9e092d8"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 8ms/step - loss: 0.1189 - accuracy: 0.9705\n",
            "Accuracy  : 0.9704935550689697\n",
            "F1_Score  : 0.9696233228795306\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7fcxLuwZpkK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "116b848f-1b4e-4584-9826-7364e679827d"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "7c68a6a0-0c83-41fb-882a-e7dc397352dd"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 5s 65ms/step - loss: 1.1381 - accuracy: 0.4205 - val_loss: 1.0533 - val_accuracy: 0.4129\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0426 - accuracy: 0.4181 - val_loss: 1.0383 - val_accuracy: 0.4236\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0411 - accuracy: 0.4270 - val_loss: 1.0366 - val_accuracy: 0.4169\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0295 - accuracy: 0.4375 - val_loss: 1.0279 - val_accuracy: 0.4249\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0262 - accuracy: 0.4388 - val_loss: 1.0287 - val_accuracy: 0.4182\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 1.0269 - accuracy: 0.4255 - val_loss: 1.0304 - val_accuracy: 0.4155\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0318 - accuracy: 0.4314 - val_loss: 1.0277 - val_accuracy: 0.4182\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0157 - accuracy: 0.4513 - val_loss: 1.0155 - val_accuracy: 0.4410\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0162 - accuracy: 0.4496 - val_loss: 1.0161 - val_accuracy: 0.4383\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0165 - accuracy: 0.4352 - val_loss: 1.0209 - val_accuracy: 0.4102\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0147 - accuracy: 0.4490 - val_loss: 1.0196 - val_accuracy: 0.4410\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0122 - accuracy: 0.4478 - val_loss: 1.0097 - val_accuracy: 0.4584\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0156 - accuracy: 0.4353 - val_loss: 1.0164 - val_accuracy: 0.4424\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0062 - accuracy: 0.4415 - val_loss: 1.0047 - val_accuracy: 0.4169\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0040 - accuracy: 0.4549 - val_loss: 1.0113 - val_accuracy: 0.4316\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9999 - accuracy: 0.4515 - val_loss: 1.0057 - val_accuracy: 0.4370\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 1.0035 - accuracy: 0.4515 - val_loss: 1.0041 - val_accuracy: 0.4665\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.9958 - accuracy: 0.4551 - val_loss: 1.0035 - val_accuracy: 0.4263\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9945 - accuracy: 0.4589 - val_loss: 0.9954 - val_accuracy: 0.4705\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9975 - accuracy: 0.4535 - val_loss: 0.9897 - val_accuracy: 0.4732\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9941 - accuracy: 0.4791 - val_loss: 0.9920 - val_accuracy: 0.4678\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9965 - accuracy: 0.4581 - val_loss: 1.0003 - val_accuracy: 0.4370\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.9938 - accuracy: 0.4689 - val_loss: 0.9848 - val_accuracy: 0.4678\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9929 - accuracy: 0.4642 - val_loss: 0.9865 - val_accuracy: 0.4692\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9795 - accuracy: 0.4809 - val_loss: 0.9861 - val_accuracy: 0.4866\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9687 - accuracy: 0.4763 - val_loss: 0.9884 - val_accuracy: 0.4397\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9847 - accuracy: 0.4736 - val_loss: 0.9787 - val_accuracy: 0.4772\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9794 - accuracy: 0.4645 - val_loss: 0.9681 - val_accuracy: 0.5054\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9604 - accuracy: 0.4785 - val_loss: 0.9703 - val_accuracy: 0.5201\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.9652 - accuracy: 0.4904 - val_loss: 0.9710 - val_accuracy: 0.5094\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9641 - accuracy: 0.4908 - val_loss: 0.9586 - val_accuracy: 0.4987\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9561 - accuracy: 0.4967 - val_loss: 0.9458 - val_accuracy: 0.4973\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9538 - accuracy: 0.4784 - val_loss: 0.9410 - val_accuracy: 0.5040\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9405 - accuracy: 0.5092 - val_loss: 0.9318 - val_accuracy: 0.5134\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9460 - accuracy: 0.5019 - val_loss: 0.9458 - val_accuracy: 0.4745\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.9341 - accuracy: 0.5036 - val_loss: 0.9358 - val_accuracy: 0.5107\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9397 - accuracy: 0.5095 - val_loss: 0.9457 - val_accuracy: 0.5107\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.9219 - accuracy: 0.5232 - val_loss: 0.9380 - val_accuracy: 0.4893\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9183 - accuracy: 0.5098 - val_loss: 0.9268 - val_accuracy: 0.5295\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9032 - accuracy: 0.5325 - val_loss: 0.9234 - val_accuracy: 0.5375\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9031 - accuracy: 0.5271 - val_loss: 0.9276 - val_accuracy: 0.5174\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.8885 - accuracy: 0.5353 - val_loss: 0.9181 - val_accuracy: 0.5335\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8853 - accuracy: 0.5495 - val_loss: 0.9171 - val_accuracy: 0.5107\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.8741 - accuracy: 0.5623 - val_loss: 0.9357 - val_accuracy: 0.5389\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.8725 - accuracy: 0.5544 - val_loss: 0.9120 - val_accuracy: 0.5241\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.8538 - accuracy: 0.5711 - val_loss: 0.8969 - val_accuracy: 0.5630\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.8630 - accuracy: 0.5662 - val_loss: 0.9168 - val_accuracy: 0.5416\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8294 - accuracy: 0.5863 - val_loss: 0.8934 - val_accuracy: 0.5724\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8289 - accuracy: 0.5829 - val_loss: 0.8859 - val_accuracy: 0.5684\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.7994 - accuracy: 0.6080 - val_loss: 0.8754 - val_accuracy: 0.5496\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.7844 - accuracy: 0.6154 - val_loss: 0.8843 - val_accuracy: 0.5349\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.7768 - accuracy: 0.6179 - val_loss: 0.8516 - val_accuracy: 0.6086\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.7698 - accuracy: 0.6334 - val_loss: 0.8554 - val_accuracy: 0.6086\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.7470 - accuracy: 0.6453 - val_loss: 0.8261 - val_accuracy: 0.5965\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.7378 - accuracy: 0.6548 - val_loss: 0.8200 - val_accuracy: 0.6113\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.7051 - accuracy: 0.6715 - val_loss: 0.8348 - val_accuracy: 0.6166\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.6986 - accuracy: 0.6689 - val_loss: 0.7626 - val_accuracy: 0.6635\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.6729 - accuracy: 0.6906 - val_loss: 0.7569 - val_accuracy: 0.6716\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.6554 - accuracy: 0.7009 - val_loss: 0.7423 - val_accuracy: 0.6649\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.6385 - accuracy: 0.7155 - val_loss: 0.6875 - val_accuracy: 0.6903\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.6362 - accuracy: 0.7201 - val_loss: 0.5165 - val_accuracy: 0.7949\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.6197 - accuracy: 0.7301 - val_loss: 0.4526 - val_accuracy: 0.8029\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.5857 - accuracy: 0.7496 - val_loss: 0.4599 - val_accuracy: 0.8204\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.5398 - accuracy: 0.7683 - val_loss: 0.4542 - val_accuracy: 0.7962\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.5499 - accuracy: 0.7706 - val_loss: 0.4764 - val_accuracy: 0.7842\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.5176 - accuracy: 0.7951 - val_loss: 0.4101 - val_accuracy: 0.8378\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.4820 - accuracy: 0.8022 - val_loss: 0.3767 - val_accuracy: 0.8418\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.4478 - accuracy: 0.8204 - val_loss: 0.3543 - val_accuracy: 0.8485\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.4288 - accuracy: 0.8322 - val_loss: 0.3939 - val_accuracy: 0.8525\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.4002 - accuracy: 0.8387 - val_loss: 0.3341 - val_accuracy: 0.8552\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3815 - accuracy: 0.8474 - val_loss: 0.3328 - val_accuracy: 0.8713\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.3780 - accuracy: 0.8517 - val_loss: 0.2612 - val_accuracy: 0.9142\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.3584 - accuracy: 0.8617 - val_loss: 0.2794 - val_accuracy: 0.8901\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.3623 - accuracy: 0.8659 - val_loss: 0.3337 - val_accuracy: 0.8552\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.3197 - accuracy: 0.8814 - val_loss: 0.2483 - val_accuracy: 0.9088\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3671 - accuracy: 0.8592 - val_loss: 0.2409 - val_accuracy: 0.9075\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2919 - accuracy: 0.8918 - val_loss: 0.2034 - val_accuracy: 0.9276\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2446 - accuracy: 0.9089 - val_loss: 0.1987 - val_accuracy: 0.9303\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2640 - accuracy: 0.9016 - val_loss: 0.2089 - val_accuracy: 0.9276\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.2600 - accuracy: 0.9075 - val_loss: 0.1949 - val_accuracy: 0.9276\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2299 - accuracy: 0.9192 - val_loss: 0.1782 - val_accuracy: 0.9370\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.1985 - accuracy: 0.9292 - val_loss: 0.1551 - val_accuracy: 0.9437\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2287 - accuracy: 0.9174 - val_loss: 0.1836 - val_accuracy: 0.9410\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2025 - accuracy: 0.9222 - val_loss: 0.1938 - val_accuracy: 0.9263\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.2083 - accuracy: 0.9255 - val_loss: 0.1742 - val_accuracy: 0.9330\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1823 - accuracy: 0.9355 - val_loss: 0.2061 - val_accuracy: 0.9249\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1861 - accuracy: 0.9346 - val_loss: 0.1464 - val_accuracy: 0.9517\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1677 - accuracy: 0.9392 - val_loss: 0.1567 - val_accuracy: 0.9464\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1779 - accuracy: 0.9370 - val_loss: 0.1362 - val_accuracy: 0.9477\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1371 - accuracy: 0.9522 - val_loss: 0.1480 - val_accuracy: 0.9477\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.2017 - accuracy: 0.9316 - val_loss: 0.0236 - val_accuracy: 0.9960\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.2113 - accuracy: 0.9237 - val_loss: 0.0314 - val_accuracy: 0.9960\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.1560 - accuracy: 0.9475 - val_loss: 0.0183 - val_accuracy: 0.9987\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.1327 - accuracy: 0.9571 - val_loss: 0.0296 - val_accuracy: 0.9920\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.1344 - accuracy: 0.9560 - val_loss: 0.0190 - val_accuracy: 0.9973\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1598 - accuracy: 0.9444 - val_loss: 0.0340 - val_accuracy: 0.9879\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1513 - accuracy: 0.9477 - val_loss: 0.0187 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1118 - accuracy: 0.9621 - val_loss: 0.0255 - val_accuracy: 0.9920\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1141 - accuracy: 0.9620 - val_loss: 0.0141 - val_accuracy: 0.9973\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1157 - accuracy: 0.9627 - val_loss: 0.0133 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1127 - accuracy: 0.9626 - val_loss: 0.0151 - val_accuracy: 0.9960\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1041 - accuracy: 0.9656 - val_loss: 0.0196 - val_accuracy: 0.9946\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1153 - accuracy: 0.9602 - val_loss: 0.0141 - val_accuracy: 0.9960\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1133 - accuracy: 0.9627 - val_loss: 0.0154 - val_accuracy: 0.9946\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0982 - accuracy: 0.9659 - val_loss: 0.0152 - val_accuracy: 0.9946\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0948 - accuracy: 0.9680 - val_loss: 0.0119 - val_accuracy: 0.9987\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0893 - accuracy: 0.9709 - val_loss: 0.0171 - val_accuracy: 0.9960\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1173 - accuracy: 0.9638 - val_loss: 0.0227 - val_accuracy: 0.9920\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1461 - accuracy: 0.9496 - val_loss: 0.0322 - val_accuracy: 0.9933\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0896 - accuracy: 0.9721 - val_loss: 0.0147 - val_accuracy: 0.9973\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0913 - accuracy: 0.9708 - val_loss: 0.0143 - val_accuracy: 0.9960\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0981 - accuracy: 0.9687 - val_loss: 0.0134 - val_accuracy: 0.9933\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0945 - accuracy: 0.9699 - val_loss: 0.0124 - val_accuracy: 0.9960\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0812 - accuracy: 0.9724 - val_loss: 0.0213 - val_accuracy: 0.9920\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0719 - accuracy: 0.9745 - val_loss: 0.0144 - val_accuracy: 0.9933\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0848 - accuracy: 0.9723 - val_loss: 0.0174 - val_accuracy: 0.9973\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0730 - accuracy: 0.9775 - val_loss: 0.0204 - val_accuracy: 0.9906\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0716 - accuracy: 0.9770 - val_loss: 0.0117 - val_accuracy: 0.9973\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0777 - accuracy: 0.9739 - val_loss: 0.0167 - val_accuracy: 0.9946\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0784 - accuracy: 0.9769 - val_loss: 0.0175 - val_accuracy: 0.9946\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0809 - accuracy: 0.9721 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0933 - accuracy: 0.9680 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0786 - accuracy: 0.9730 - val_loss: 0.0080 - val_accuracy: 0.9987\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0918 - accuracy: 0.9712 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0733 - accuracy: 0.9772 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0688 - accuracy: 0.9788 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1234 - accuracy: 0.9578 - val_loss: 0.0334 - val_accuracy: 0.9906\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0674 - accuracy: 0.9785 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0622 - accuracy: 0.9806 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0753 - accuracy: 0.9736 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0607 - accuracy: 0.9809 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0567 - accuracy: 0.9814 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0606 - accuracy: 0.9803 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0775 - accuracy: 0.9724 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0705 - accuracy: 0.9770 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0553 - accuracy: 0.9817 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1691 - accuracy: 0.9504 - val_loss: 0.0251 - val_accuracy: 0.9933\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0673 - accuracy: 0.9818 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0707 - accuracy: 0.9784 - val_loss: 0.0037 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0517 - accuracy: 0.9836 - val_loss: 9.3212e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0589 - accuracy: 0.9827 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0483 - accuracy: 0.9855 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0600 - accuracy: 0.9808 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0552 - accuracy: 0.9815 - val_loss: 9.1199e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0551 - accuracy: 0.9821 - val_loss: 0.0024 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0569 - accuracy: 0.9830 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0513 - accuracy: 0.9851 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0509 - accuracy: 0.9823 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0538 - accuracy: 0.9814 - val_loss: 0.0038 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0553 - accuracy: 0.9821 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0704 - accuracy: 0.9772 - val_loss: 2.5294e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0583 - accuracy: 0.9806 - val_loss: 3.3420e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0447 - accuracy: 0.9858 - val_loss: 2.7011e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0614 - accuracy: 0.9797 - val_loss: 5.9221e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0466 - accuracy: 0.9852 - val_loss: 6.3243e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0549 - accuracy: 0.9845 - val_loss: 4.0535e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0478 - accuracy: 0.9849 - val_loss: 3.6270e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0514 - accuracy: 0.9832 - val_loss: 5.4223e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0868 - accuracy: 0.9753 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0468 - accuracy: 0.9849 - val_loss: 4.3059e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0527 - accuracy: 0.9844 - val_loss: 5.3503e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0468 - accuracy: 0.9849 - val_loss: 5.6909e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0563 - accuracy: 0.9836 - val_loss: 4.4550e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0444 - accuracy: 0.9858 - val_loss: 4.4707e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0425 - accuracy: 0.9881 - val_loss: 5.5704e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0514 - accuracy: 0.9836 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1080 - accuracy: 0.9689 - val_loss: 0.0220 - val_accuracy: 0.9920\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0726 - accuracy: 0.9753 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0449 - accuracy: 0.9851 - val_loss: 4.0598e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0452 - accuracy: 0.9858 - val_loss: 0.0039 - val_accuracy: 0.9973\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0531 - accuracy: 0.9855 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0484 - accuracy: 0.9844 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0420 - accuracy: 0.9858 - val_loss: 0.0029 - val_accuracy: 0.9973\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0354 - accuracy: 0.9900 - val_loss: 3.1253e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0306 - accuracy: 0.9891 - val_loss: 3.4727e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0512 - accuracy: 0.9845 - val_loss: 9.7698e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0584 - accuracy: 0.9817 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0358 - accuracy: 0.9891 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0508 - accuracy: 0.9838 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0395 - accuracy: 0.9866 - val_loss: 2.9116e-04 - val_accuracy: 1.0000\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 60ms/step - loss: 0.0435 - accuracy: 0.9869 - val_loss: 4.9387e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0518 - accuracy: 0.9836 - val_loss: 6.3384e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0401 - accuracy: 0.9876 - val_loss: 9.8230e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0521 - accuracy: 0.9824 - val_loss: 1.1090e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0559 - accuracy: 0.9827 - val_loss: 1.4631e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0447 - accuracy: 0.9855 - val_loss: 1.1495e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0461 - accuracy: 0.9866 - val_loss: 7.4247e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0372 - accuracy: 0.9894 - val_loss: 6.2986e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0499 - accuracy: 0.9857 - val_loss: 5.0833e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0528 - accuracy: 0.9826 - val_loss: 1.3383e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0448 - accuracy: 0.9863 - val_loss: 2.6170e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0478 - accuracy: 0.9852 - val_loss: 3.0903e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0405 - accuracy: 0.9882 - val_loss: 7.2600e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0439 - accuracy: 0.9869 - val_loss: 2.7997e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0367 - accuracy: 0.9884 - val_loss: 2.4648e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0461 - accuracy: 0.9860 - val_loss: 3.6352e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0736 - accuracy: 0.9757 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0572 - accuracy: 0.9818 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0328 - accuracy: 0.9899 - val_loss: 1.0440e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0371 - accuracy: 0.9872 - val_loss: 8.8554e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0412 - accuracy: 0.9861 - val_loss: 1.1501e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0381 - accuracy: 0.9885 - val_loss: 2.2608e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0312 - accuracy: 0.9903 - val_loss: 1.2510e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0371 - accuracy: 0.9881 - val_loss: 1.1679e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0383 - accuracy: 0.9870 - val_loss: 1.9727e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0381 - accuracy: 0.9884 - val_loss: 2.9192e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0269 - accuracy: 0.9917 - val_loss: 0.0016 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0348 - accuracy: 0.9882 - val_loss: 7.2163e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0454 - accuracy: 0.9857 - val_loss: 9.6970e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0296 - accuracy: 0.9909 - val_loss: 7.3185e-05 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0509 - accuracy: 0.9847 - val_loss: 1.1093e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0495 - accuracy: 0.9830 - val_loss: 4.1242e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0425 - accuracy: 0.9876 - val_loss: 1.4456e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0397 - accuracy: 0.9872 - val_loss: 1.6599e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0316 - accuracy: 0.9900 - val_loss: 8.6332e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0264 - accuracy: 0.9908 - val_loss: 4.7098e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0416 - accuracy: 0.9878 - val_loss: 5.8871e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0372 - accuracy: 0.9882 - val_loss: 4.2899e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0378 - accuracy: 0.9893 - val_loss: 8.4848e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0330 - accuracy: 0.9882 - val_loss: 8.3767e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0385 - accuracy: 0.9879 - val_loss: 5.2478e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0384 - accuracy: 0.9882 - val_loss: 0.0072 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0453 - accuracy: 0.9891 - val_loss: 8.7782e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0445 - accuracy: 0.9848 - val_loss: 2.6200e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0374 - accuracy: 0.9872 - val_loss: 6.3595e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0255 - accuracy: 0.9911 - val_loss: 1.1725e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0263 - accuracy: 0.9918 - val_loss: 1.5825e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0299 - accuracy: 0.9906 - val_loss: 1.9812e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0332 - accuracy: 0.9902 - val_loss: 1.9153e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0446 - accuracy: 0.9870 - val_loss: 5.7871e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0305 - accuracy: 0.9905 - val_loss: 1.6210e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0432 - accuracy: 0.9882 - val_loss: 1.9313e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.1342 - accuracy: 0.9578 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0472 - accuracy: 0.9844 - val_loss: 6.8812e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0360 - accuracy: 0.9905 - val_loss: 3.9366e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0417 - accuracy: 0.9861 - val_loss: 3.6558e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0292 - accuracy: 0.9908 - val_loss: 4.4585e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0294 - accuracy: 0.9909 - val_loss: 2.1624e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0368 - accuracy: 0.9899 - val_loss: 3.3307e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0313 - accuracy: 0.9906 - val_loss: 1.3041e-04 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0244 - accuracy: 0.9917 - val_loss: 1.5554e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0286 - accuracy: 0.9905 - val_loss: 8.1240e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0308 - accuracy: 0.9911 - val_loss: 2.2443e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0240 - accuracy: 0.9930 - val_loss: 8.0935e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0269 - accuracy: 0.9917 - val_loss: 1.2507e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0245 - accuracy: 0.9934 - val_loss: 1.5585e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0307 - accuracy: 0.9896 - val_loss: 1.4556e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0244 - accuracy: 0.9921 - val_loss: 9.0946e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0404 - accuracy: 0.9884 - val_loss: 2.7132e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0339 - accuracy: 0.9891 - val_loss: 1.3171e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0204 - accuracy: 0.9940 - val_loss: 2.7705e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0418 - accuracy: 0.9878 - val_loss: 4.5754e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0347 - accuracy: 0.9884 - val_loss: 5.5201e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0271 - accuracy: 0.9927 - val_loss: 4.8689e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0281 - accuracy: 0.9905 - val_loss: 4.0700e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0376 - accuracy: 0.9894 - val_loss: 1.6342e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0399 - accuracy: 0.9875 - val_loss: 4.9639e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0240 - accuracy: 0.9925 - val_loss: 5.3492e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0328 - accuracy: 0.9906 - val_loss: 3.8176e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0267 - accuracy: 0.9911 - val_loss: 2.7783e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0272 - accuracy: 0.9924 - val_loss: 7.3432e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0244 - accuracy: 0.9924 - val_loss: 1.0922e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0373 - accuracy: 0.9881 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0312 - accuracy: 0.9890 - val_loss: 9.3422e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0378 - accuracy: 0.9891 - val_loss: 1.3996e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0335 - accuracy: 0.9882 - val_loss: 4.8026e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0231 - accuracy: 0.9924 - val_loss: 3.3127e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0284 - accuracy: 0.9918 - val_loss: 7.3618e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0324 - accuracy: 0.9890 - val_loss: 0.0050 - val_accuracy: 0.9973\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0236 - accuracy: 0.9928 - val_loss: 8.1598e-05 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0262 - accuracy: 0.9915 - val_loss: 1.8475e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0306 - accuracy: 0.9900 - val_loss: 1.7918e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 60ms/step - loss: 0.0275 - accuracy: 0.9918 - val_loss: 3.6306e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0244 - accuracy: 0.9928 - val_loss: 6.6084e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0229 - accuracy: 0.9930 - val_loss: 2.0338e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0323 - accuracy: 0.9903 - val_loss: 3.3400e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0427 - accuracy: 0.9872 - val_loss: 6.2725e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0244 - accuracy: 0.9917 - val_loss: 6.4609e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0249 - accuracy: 0.9914 - val_loss: 3.3483e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0321 - accuracy: 0.9905 - val_loss: 1.7219e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0272 - accuracy: 0.9906 - val_loss: 4.1532e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0279 - accuracy: 0.9891 - val_loss: 1.3443e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0358 - accuracy: 0.9903 - val_loss: 4.0739e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0302 - accuracy: 0.9899 - val_loss: 4.4026e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0205 - accuracy: 0.9937 - val_loss: 2.2919e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0220 - accuracy: 0.9923 - val_loss: 2.2504e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0243 - accuracy: 0.9925 - val_loss: 2.2036e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0231 - accuracy: 0.9925 - val_loss: 1.3474e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0307 - accuracy: 0.9899 - val_loss: 4.7413e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0263 - accuracy: 0.9928 - val_loss: 1.6147e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0306 - accuracy: 0.9893 - val_loss: 4.4055e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0177 - accuracy: 0.9937 - val_loss: 4.6321e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0298 - accuracy: 0.9930 - val_loss: 3.1287e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0239 - accuracy: 0.9933 - val_loss: 4.5720e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0204 - accuracy: 0.9930 - val_loss: 9.8292e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0279 - accuracy: 0.9914 - val_loss: 9.6990e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0311 - accuracy: 0.9906 - val_loss: 0.0076 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0217 - accuracy: 0.9928 - val_loss: 1.1457e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0296 - accuracy: 0.9908 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0293 - accuracy: 0.9906 - val_loss: 2.0574e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "id": "RqvjMIc2HEJy",
        "outputId": "dbd61fe0-a017-42f2-a60c-9ce5a299cdc1"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 8ms/step - loss: 0.0320 - accuracy: 0.9909\n",
            "Accuracy  : 0.9908798336982727\n",
            "F1_Score  : 0.9899423913154809\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "0d74cf80-0bea-4887-900c-516be462197e"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'acrc = model.evaluate(x_test, y_test)\\npred = model.predict(x_test)\\nf1scr = f1_score(y_test.argmax(1), pred.argmax(1), average=\\'macro\\')\\nc_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\\nprint(\"Accuracy  : {}\".format(acrc[1]))\\nprint(\"F1_Score  : {}\".format(f1scr))\\nc_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\\nimport seaborn as sns\\nfigure = plt.figure(figsize=(9, 9))\\nsns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\\nplt.tight_layout()\\nplt.ylabel(\\'True label\\')\\nplt.xlabel(\\'Predicted label\\')\\nplt.show()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}