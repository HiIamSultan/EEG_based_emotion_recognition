{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub25_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "335fde68-9ffd-4d77-be48-9ed3abfc3272"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e3\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  #EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "50327934-28e0-405b-8e93-dfbd2ec44489"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(25,26):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.25\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (3495,) (2330,) (3495,)\n",
            "(9320,) (1864,) (1631,) (5825,)\n",
            "(9320,) (233,) (1398,) (7689,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "eef12adf-614c-4934-a804-7a590df6d3d2"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "81c587d4-4b2e-4d94-cd20-840381988643"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "445"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "84ca82ef-4ea6-43f4-a1c3-71f4a125cecd"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5830536d-9609-4997-895e-a0bf8d672fe3"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 27s 60ms/step - loss: 1.2096 - accuracy: 0.3478 - val_loss: 1.0948 - val_accuracy: 0.3807\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0949 - accuracy: 0.3788 - val_loss: 1.0830 - val_accuracy: 0.3807\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0841 - accuracy: 0.3774 - val_loss: 1.0774 - val_accuracy: 0.3606\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0804 - accuracy: 0.3730 - val_loss: 1.0796 - val_accuracy: 0.3820\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0802 - accuracy: 0.3905 - val_loss: 1.0766 - val_accuracy: 0.3995\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0769 - accuracy: 0.3859 - val_loss: 1.0781 - val_accuracy: 0.3928\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0823 - accuracy: 0.3839 - val_loss: 1.0814 - val_accuracy: 0.3807\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0819 - accuracy: 0.3750 - val_loss: 1.0807 - val_accuracy: 0.3807\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0813 - accuracy: 0.3795 - val_loss: 1.0809 - val_accuracy: 0.3887\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0810 - accuracy: 0.3760 - val_loss: 1.0798 - val_accuracy: 0.3968\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0822 - accuracy: 0.3723 - val_loss: 1.0817 - val_accuracy: 0.3941\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0811 - accuracy: 0.3590 - val_loss: 1.0805 - val_accuracy: 0.3579\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0811 - accuracy: 0.3806 - val_loss: 1.0814 - val_accuracy: 0.3968\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0795 - accuracy: 0.3926 - val_loss: 1.0804 - val_accuracy: 0.3928\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0790 - accuracy: 0.3814 - val_loss: 1.0811 - val_accuracy: 0.3861\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0780 - accuracy: 0.3770 - val_loss: 1.0799 - val_accuracy: 0.3914\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0801 - accuracy: 0.3651 - val_loss: 1.0811 - val_accuracy: 0.3579\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0813 - accuracy: 0.3800 - val_loss: 1.0763 - val_accuracy: 0.3928\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0822 - accuracy: 0.3882 - val_loss: 1.0824 - val_accuracy: 0.3968\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0754 - accuracy: 0.3924 - val_loss: 1.0823 - val_accuracy: 0.3981\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0793 - accuracy: 0.3860 - val_loss: 1.0790 - val_accuracy: 0.3954\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0742 - accuracy: 0.3872 - val_loss: 1.0777 - val_accuracy: 0.3928\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0794 - accuracy: 0.3747 - val_loss: 1.0789 - val_accuracy: 0.4008\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0761 - accuracy: 0.3895 - val_loss: 1.0810 - val_accuracy: 0.3928\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0827 - accuracy: 0.3768 - val_loss: 1.0887 - val_accuracy: 0.3847\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0800 - accuracy: 0.3838 - val_loss: 1.0790 - val_accuracy: 0.3928\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0732 - accuracy: 0.3898 - val_loss: 1.0841 - val_accuracy: 0.3847\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0723 - accuracy: 0.3978 - val_loss: 1.0726 - val_accuracy: 0.4021\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0738 - accuracy: 0.3869 - val_loss: 1.0752 - val_accuracy: 0.3928\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0756 - accuracy: 0.3911 - val_loss: 1.0849 - val_accuracy: 0.3780\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0760 - accuracy: 0.3909 - val_loss: 1.0665 - val_accuracy: 0.4035\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0772 - accuracy: 0.3925 - val_loss: 1.0718 - val_accuracy: 0.3941\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0761 - accuracy: 0.3899 - val_loss: 1.0744 - val_accuracy: 0.3727\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0767 - accuracy: 0.3949 - val_loss: 1.0657 - val_accuracy: 0.3968\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0753 - accuracy: 0.3864 - val_loss: 1.0671 - val_accuracy: 0.3941\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0718 - accuracy: 0.3893 - val_loss: 1.0781 - val_accuracy: 0.3753\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0735 - accuracy: 0.3979 - val_loss: 1.0665 - val_accuracy: 0.3807\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0735 - accuracy: 0.3988 - val_loss: 1.0646 - val_accuracy: 0.4102\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0721 - accuracy: 0.3921 - val_loss: 1.0768 - val_accuracy: 0.3767\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0724 - accuracy: 0.3963 - val_loss: 1.0638 - val_accuracy: 0.4021\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0684 - accuracy: 0.3948 - val_loss: 1.0610 - val_accuracy: 0.4129\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0678 - accuracy: 0.3957 - val_loss: 1.0565 - val_accuracy: 0.4169\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0701 - accuracy: 0.3988 - val_loss: 1.0613 - val_accuracy: 0.4142\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0646 - accuracy: 0.4082 - val_loss: 1.0576 - val_accuracy: 0.4169\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0691 - accuracy: 0.4003 - val_loss: 1.0630 - val_accuracy: 0.3847\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0686 - accuracy: 0.3940 - val_loss: 1.0607 - val_accuracy: 0.4102\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0650 - accuracy: 0.4088 - val_loss: 1.0555 - val_accuracy: 0.4196\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0692 - accuracy: 0.3972 - val_loss: 1.0630 - val_accuracy: 0.4276\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0651 - accuracy: 0.4092 - val_loss: 1.0567 - val_accuracy: 0.4276\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0636 - accuracy: 0.4103 - val_loss: 1.0610 - val_accuracy: 0.4142\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0652 - accuracy: 0.3988 - val_loss: 1.0705 - val_accuracy: 0.3807\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0629 - accuracy: 0.4106 - val_loss: 1.0590 - val_accuracy: 0.4115\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0629 - accuracy: 0.4049 - val_loss: 1.0590 - val_accuracy: 0.4102\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0664 - accuracy: 0.4063 - val_loss: 1.0542 - val_accuracy: 0.4169\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0611 - accuracy: 0.4106 - val_loss: 1.0552 - val_accuracy: 0.4303\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0610 - accuracy: 0.4134 - val_loss: 1.0538 - val_accuracy: 0.4276\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0588 - accuracy: 0.4079 - val_loss: 1.0525 - val_accuracy: 0.4357\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0594 - accuracy: 0.4130 - val_loss: 1.0529 - val_accuracy: 0.4236\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0664 - accuracy: 0.3951 - val_loss: 1.0502 - val_accuracy: 0.4477\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0641 - accuracy: 0.4094 - val_loss: 1.0498 - val_accuracy: 0.4357\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0597 - accuracy: 0.4091 - val_loss: 1.0682 - val_accuracy: 0.3861\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0635 - accuracy: 0.4089 - val_loss: 1.0511 - val_accuracy: 0.4223\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0617 - accuracy: 0.4009 - val_loss: 1.0506 - val_accuracy: 0.4303\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0621 - accuracy: 0.4052 - val_loss: 1.0566 - val_accuracy: 0.4088\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0628 - accuracy: 0.4091 - val_loss: 1.0576 - val_accuracy: 0.4129\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0579 - accuracy: 0.4067 - val_loss: 1.0525 - val_accuracy: 0.4209\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0610 - accuracy: 0.4064 - val_loss: 1.0487 - val_accuracy: 0.4383\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0608 - accuracy: 0.4048 - val_loss: 1.0523 - val_accuracy: 0.4330\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0582 - accuracy: 0.4152 - val_loss: 1.0521 - val_accuracy: 0.4196\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0581 - accuracy: 0.4195 - val_loss: 1.0533 - val_accuracy: 0.4263\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0577 - accuracy: 0.4225 - val_loss: 1.0445 - val_accuracy: 0.4196\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0572 - accuracy: 0.4076 - val_loss: 1.0535 - val_accuracy: 0.4048\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0535 - accuracy: 0.4131 - val_loss: 1.0597 - val_accuracy: 0.4075\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0604 - accuracy: 0.4125 - val_loss: 1.0513 - val_accuracy: 0.4223\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0548 - accuracy: 0.4137 - val_loss: 1.0506 - val_accuracy: 0.4223\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0545 - accuracy: 0.4170 - val_loss: 1.0480 - val_accuracy: 0.4169\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0561 - accuracy: 0.4151 - val_loss: 1.0423 - val_accuracy: 0.4209\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0561 - accuracy: 0.4180 - val_loss: 1.0508 - val_accuracy: 0.4249\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0531 - accuracy: 0.4176 - val_loss: 1.0483 - val_accuracy: 0.4142\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0500 - accuracy: 0.4143 - val_loss: 1.0436 - val_accuracy: 0.4303\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0542 - accuracy: 0.4136 - val_loss: 1.0513 - val_accuracy: 0.4290\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0517 - accuracy: 0.4230 - val_loss: 1.0451 - val_accuracy: 0.4303\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0517 - accuracy: 0.4209 - val_loss: 1.0584 - val_accuracy: 0.4169\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0496 - accuracy: 0.4271 - val_loss: 1.0396 - val_accuracy: 0.4209\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0495 - accuracy: 0.4332 - val_loss: 1.0488 - val_accuracy: 0.4182\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0507 - accuracy: 0.4210 - val_loss: 1.0418 - val_accuracy: 0.4303\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0518 - accuracy: 0.4234 - val_loss: 1.0459 - val_accuracy: 0.4048\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0484 - accuracy: 0.4331 - val_loss: 1.0561 - val_accuracy: 0.4048\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0469 - accuracy: 0.4294 - val_loss: 1.0494 - val_accuracy: 0.4035\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0479 - accuracy: 0.4350 - val_loss: 1.0419 - val_accuracy: 0.4155\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0498 - accuracy: 0.4338 - val_loss: 1.0431 - val_accuracy: 0.4544\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0472 - accuracy: 0.4322 - val_loss: 1.0557 - val_accuracy: 0.4209\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0474 - accuracy: 0.4295 - val_loss: 1.0396 - val_accuracy: 0.4357\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0483 - accuracy: 0.4307 - val_loss: 1.0352 - val_accuracy: 0.4343\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0469 - accuracy: 0.4250 - val_loss: 1.0449 - val_accuracy: 0.4223\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0444 - accuracy: 0.4331 - val_loss: 1.0463 - val_accuracy: 0.4276\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0443 - accuracy: 0.4297 - val_loss: 1.0515 - val_accuracy: 0.4169\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0456 - accuracy: 0.4362 - val_loss: 1.0439 - val_accuracy: 0.4316\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0388 - accuracy: 0.4373 - val_loss: 1.0350 - val_accuracy: 0.4424\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0384 - accuracy: 0.4393 - val_loss: 1.0469 - val_accuracy: 0.4223\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0381 - accuracy: 0.4361 - val_loss: 1.0344 - val_accuracy: 0.4504\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0394 - accuracy: 0.4414 - val_loss: 1.0515 - val_accuracy: 0.4531\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0364 - accuracy: 0.4382 - val_loss: 1.0353 - val_accuracy: 0.4303\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0420 - accuracy: 0.4386 - val_loss: 1.0393 - val_accuracy: 0.4343\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0350 - accuracy: 0.4423 - val_loss: 1.0298 - val_accuracy: 0.4517\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0360 - accuracy: 0.4410 - val_loss: 1.0532 - val_accuracy: 0.4249\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0293 - accuracy: 0.4513 - val_loss: 1.0295 - val_accuracy: 0.4477\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0292 - accuracy: 0.4501 - val_loss: 1.0253 - val_accuracy: 0.4450\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0250 - accuracy: 0.4590 - val_loss: 1.0300 - val_accuracy: 0.4450\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0306 - accuracy: 0.4495 - val_loss: 1.0335 - val_accuracy: 0.4397\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0266 - accuracy: 0.4508 - val_loss: 1.0254 - val_accuracy: 0.4450\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0245 - accuracy: 0.4514 - val_loss: 1.0408 - val_accuracy: 0.4370\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0354 - accuracy: 0.4425 - val_loss: 1.0248 - val_accuracy: 0.4584\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0339 - accuracy: 0.4499 - val_loss: 1.0323 - val_accuracy: 0.4531\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0200 - accuracy: 0.4623 - val_loss: 1.0195 - val_accuracy: 0.4665\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0255 - accuracy: 0.4516 - val_loss: 1.0160 - val_accuracy: 0.4732\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0165 - accuracy: 0.4601 - val_loss: 1.0231 - val_accuracy: 0.4651\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0204 - accuracy: 0.4544 - val_loss: 1.0339 - val_accuracy: 0.4424\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0127 - accuracy: 0.4721 - val_loss: 1.0148 - val_accuracy: 0.4651\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0127 - accuracy: 0.4692 - val_loss: 1.0333 - val_accuracy: 0.4598\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0102 - accuracy: 0.4733 - val_loss: 0.9768 - val_accuracy: 0.4933\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0031 - accuracy: 0.4754 - val_loss: 0.9695 - val_accuracy: 0.4893\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0008 - accuracy: 0.4811 - val_loss: 0.9707 - val_accuracy: 0.4920\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0003 - accuracy: 0.4845 - val_loss: 0.9792 - val_accuracy: 0.4839\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9931 - accuracy: 0.4894 - val_loss: 1.0312 - val_accuracy: 0.4410\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9946 - accuracy: 0.4879 - val_loss: 0.9607 - val_accuracy: 0.4973\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9875 - accuracy: 0.4943 - val_loss: 0.9773 - val_accuracy: 0.5013\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9874 - accuracy: 0.4982 - val_loss: 0.9719 - val_accuracy: 0.5121\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9839 - accuracy: 0.4973 - val_loss: 0.9572 - val_accuracy: 0.5188\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9828 - accuracy: 0.5013 - val_loss: 0.9639 - val_accuracy: 0.5080\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9781 - accuracy: 0.4984 - val_loss: 0.9980 - val_accuracy: 0.4893\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9756 - accuracy: 0.5054 - val_loss: 0.9879 - val_accuracy: 0.4853\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9686 - accuracy: 0.5149 - val_loss: 0.9524 - val_accuracy: 0.5268\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9645 - accuracy: 0.5100 - val_loss: 0.9484 - val_accuracy: 0.5402\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9628 - accuracy: 0.5240 - val_loss: 0.9356 - val_accuracy: 0.5134\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9559 - accuracy: 0.5244 - val_loss: 0.9608 - val_accuracy: 0.5214\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9487 - accuracy: 0.5265 - val_loss: 0.9429 - val_accuracy: 0.5268\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9366 - accuracy: 0.5374 - val_loss: 0.9404 - val_accuracy: 0.5174\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9410 - accuracy: 0.5371 - val_loss: 0.9403 - val_accuracy: 0.5295\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9399 - accuracy: 0.5304 - val_loss: 0.9297 - val_accuracy: 0.5509\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9260 - accuracy: 0.5416 - val_loss: 0.9197 - val_accuracy: 0.5429\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9124 - accuracy: 0.5559 - val_loss: 0.9209 - val_accuracy: 0.5295\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9224 - accuracy: 0.5498 - val_loss: 0.8965 - val_accuracy: 0.5563\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9127 - accuracy: 0.5528 - val_loss: 0.9245 - val_accuracy: 0.5442\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9147 - accuracy: 0.5538 - val_loss: 0.8994 - val_accuracy: 0.5469\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9042 - accuracy: 0.5627 - val_loss: 1.0261 - val_accuracy: 0.4853\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8935 - accuracy: 0.5689 - val_loss: 0.8964 - val_accuracy: 0.5643\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8796 - accuracy: 0.5841 - val_loss: 0.8948 - val_accuracy: 0.5684\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8757 - accuracy: 0.5836 - val_loss: 0.9259 - val_accuracy: 0.5563\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8811 - accuracy: 0.5805 - val_loss: 0.9076 - val_accuracy: 0.5563\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8867 - accuracy: 0.5726 - val_loss: 0.7998 - val_accuracy: 0.6542\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8816 - accuracy: 0.5844 - val_loss: 0.7907 - val_accuracy: 0.6434\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8645 - accuracy: 0.5879 - val_loss: 0.7761 - val_accuracy: 0.6528\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8554 - accuracy: 0.5934 - val_loss: 0.7560 - val_accuracy: 0.6649\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8504 - accuracy: 0.6006 - val_loss: 0.7742 - val_accuracy: 0.6381\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8366 - accuracy: 0.6067 - val_loss: 0.7744 - val_accuracy: 0.6354\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8303 - accuracy: 0.6142 - val_loss: 0.7688 - val_accuracy: 0.6421\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8303 - accuracy: 0.6106 - val_loss: 0.7614 - val_accuracy: 0.6662\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8292 - accuracy: 0.6230 - val_loss: 0.8572 - val_accuracy: 0.6099\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8223 - accuracy: 0.6165 - val_loss: 0.7551 - val_accuracy: 0.6729\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8092 - accuracy: 0.6286 - val_loss: 0.7425 - val_accuracy: 0.6743\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7927 - accuracy: 0.6392 - val_loss: 0.7421 - val_accuracy: 0.6676\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7891 - accuracy: 0.6383 - val_loss: 0.7502 - val_accuracy: 0.6542\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7799 - accuracy: 0.6487 - val_loss: 0.7423 - val_accuracy: 0.6676\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7774 - accuracy: 0.6455 - val_loss: 0.7509 - val_accuracy: 0.6475\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7576 - accuracy: 0.6565 - val_loss: 0.7338 - val_accuracy: 0.6542\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7399 - accuracy: 0.6706 - val_loss: 0.7185 - val_accuracy: 0.6555\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7355 - accuracy: 0.6644 - val_loss: 0.7332 - val_accuracy: 0.6702\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7197 - accuracy: 0.6702 - val_loss: 0.6624 - val_accuracy: 0.6971\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7057 - accuracy: 0.6815 - val_loss: 0.6521 - val_accuracy: 0.7185\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7015 - accuracy: 0.6894 - val_loss: 0.6726 - val_accuracy: 0.7078\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7181 - accuracy: 0.6817 - val_loss: 0.7288 - val_accuracy: 0.6716\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6932 - accuracy: 0.6955 - val_loss: 0.7009 - val_accuracy: 0.6850\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6794 - accuracy: 0.6943 - val_loss: 0.6903 - val_accuracy: 0.6930\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6663 - accuracy: 0.7027 - val_loss: 0.6561 - val_accuracy: 0.7131\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6462 - accuracy: 0.7122 - val_loss: 0.6717 - val_accuracy: 0.6890\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6645 - accuracy: 0.7112 - val_loss: 0.6359 - val_accuracy: 0.7185\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6305 - accuracy: 0.7197 - val_loss: 0.6115 - val_accuracy: 0.7373\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6167 - accuracy: 0.7320 - val_loss: 0.6290 - val_accuracy: 0.7225\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6200 - accuracy: 0.7291 - val_loss: 0.6898 - val_accuracy: 0.6930\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 47ms/step - loss: 0.6350 - accuracy: 0.7212 - val_loss: 0.4496 - val_accuracy: 0.8201\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6159 - accuracy: 0.7346 - val_loss: 0.4703 - val_accuracy: 0.8134\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6124 - accuracy: 0.7313 - val_loss: 0.4849 - val_accuracy: 0.7946\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6091 - accuracy: 0.7437 - val_loss: 0.5309 - val_accuracy: 0.7664\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6263 - accuracy: 0.7278 - val_loss: 0.4851 - val_accuracy: 0.7933\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5598 - accuracy: 0.7608 - val_loss: 0.4447 - val_accuracy: 0.8201\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5790 - accuracy: 0.7515 - val_loss: 0.4677 - val_accuracy: 0.8067\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5737 - accuracy: 0.7564 - val_loss: 0.4267 - val_accuracy: 0.8215\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5521 - accuracy: 0.7601 - val_loss: 0.4373 - val_accuracy: 0.8201\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5533 - accuracy: 0.7672 - val_loss: 0.4444 - val_accuracy: 0.8215\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5417 - accuracy: 0.7655 - val_loss: 0.4358 - val_accuracy: 0.8148\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5331 - accuracy: 0.7784 - val_loss: 0.4379 - val_accuracy: 0.8242\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5192 - accuracy: 0.7824 - val_loss: 0.4270 - val_accuracy: 0.8040\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5160 - accuracy: 0.7856 - val_loss: 0.4247 - val_accuracy: 0.8282\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5275 - accuracy: 0.7813 - val_loss: 0.3912 - val_accuracy: 0.8349\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5037 - accuracy: 0.7908 - val_loss: 0.4194 - val_accuracy: 0.8228\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4830 - accuracy: 0.7982 - val_loss: 0.4926 - val_accuracy: 0.7772\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4935 - accuracy: 0.7970 - val_loss: 0.3764 - val_accuracy: 0.8470\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4753 - accuracy: 0.8049 - val_loss: 0.4224 - val_accuracy: 0.8174\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4866 - accuracy: 0.7979 - val_loss: 0.4066 - val_accuracy: 0.8242\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4636 - accuracy: 0.8088 - val_loss: 0.3760 - val_accuracy: 0.8564\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4798 - accuracy: 0.7991 - val_loss: 0.3953 - val_accuracy: 0.8322\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4699 - accuracy: 0.8035 - val_loss: 0.4842 - val_accuracy: 0.7973\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4466 - accuracy: 0.8178 - val_loss: 0.4845 - val_accuracy: 0.8040\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4417 - accuracy: 0.8207 - val_loss: 0.4037 - val_accuracy: 0.8362\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4360 - accuracy: 0.8155 - val_loss: 0.3612 - val_accuracy: 0.8631\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4464 - accuracy: 0.8169 - val_loss: 0.4119 - val_accuracy: 0.8443\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4253 - accuracy: 0.8236 - val_loss: 0.3882 - val_accuracy: 0.8416\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4544 - accuracy: 0.8118 - val_loss: 0.3717 - val_accuracy: 0.8416\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4200 - accuracy: 0.8248 - val_loss: 0.3548 - val_accuracy: 0.8537\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4235 - accuracy: 0.8261 - val_loss: 0.2445 - val_accuracy: 0.9087\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4189 - accuracy: 0.8301 - val_loss: 0.2730 - val_accuracy: 0.8792\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4119 - accuracy: 0.8346 - val_loss: 0.2680 - val_accuracy: 0.9087\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4195 - accuracy: 0.8349 - val_loss: 0.2483 - val_accuracy: 0.8993\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3972 - accuracy: 0.8426 - val_loss: 0.2959 - val_accuracy: 0.8658\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3881 - accuracy: 0.8397 - val_loss: 0.2646 - val_accuracy: 0.8819\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3856 - accuracy: 0.8435 - val_loss: 0.2533 - val_accuracy: 0.8953\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3758 - accuracy: 0.8467 - val_loss: 0.2508 - val_accuracy: 0.8966\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3865 - accuracy: 0.8426 - val_loss: 0.2243 - val_accuracy: 0.9074\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3871 - accuracy: 0.8440 - val_loss: 0.2955 - val_accuracy: 0.8591\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3619 - accuracy: 0.8531 - val_loss: 0.2370 - val_accuracy: 0.8913\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3595 - accuracy: 0.8562 - val_loss: 0.2338 - val_accuracy: 0.8980\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3725 - accuracy: 0.8528 - val_loss: 0.2228 - val_accuracy: 0.9087\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3801 - accuracy: 0.8482 - val_loss: 0.2307 - val_accuracy: 0.8926\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3491 - accuracy: 0.8604 - val_loss: 0.2452 - val_accuracy: 0.9275\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3570 - accuracy: 0.8537 - val_loss: 0.2439 - val_accuracy: 0.8913\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3666 - accuracy: 0.8523 - val_loss: 0.2577 - val_accuracy: 0.9060\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3259 - accuracy: 0.8729 - val_loss: 0.2745 - val_accuracy: 0.8591\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3399 - accuracy: 0.8662 - val_loss: 0.2635 - val_accuracy: 0.8832\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3285 - accuracy: 0.8692 - val_loss: 0.2209 - val_accuracy: 0.9087\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3152 - accuracy: 0.8711 - val_loss: 0.2079 - val_accuracy: 0.9060\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3032 - accuracy: 0.8806 - val_loss: 0.1866 - val_accuracy: 0.9235\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3352 - accuracy: 0.8644 - val_loss: 0.2169 - val_accuracy: 0.9154\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3491 - accuracy: 0.8632 - val_loss: 0.2202 - val_accuracy: 0.9181\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3318 - accuracy: 0.8708 - val_loss: 0.2246 - val_accuracy: 0.9114\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3207 - accuracy: 0.8710 - val_loss: 0.1971 - val_accuracy: 0.9195\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3042 - accuracy: 0.8748 - val_loss: 0.1969 - val_accuracy: 0.9181\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3025 - accuracy: 0.8814 - val_loss: 0.1887 - val_accuracy: 0.9302\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3251 - accuracy: 0.8760 - val_loss: 0.2120 - val_accuracy: 0.9208\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2924 - accuracy: 0.8894 - val_loss: 0.1912 - val_accuracy: 0.9221\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3099 - accuracy: 0.8814 - val_loss: 0.1400 - val_accuracy: 0.9530\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2929 - accuracy: 0.8836 - val_loss: 0.1205 - val_accuracy: 0.9544\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3160 - accuracy: 0.8781 - val_loss: 0.1239 - val_accuracy: 0.9544\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2982 - accuracy: 0.8793 - val_loss: 0.1188 - val_accuracy: 0.9597\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2827 - accuracy: 0.8873 - val_loss: 0.1297 - val_accuracy: 0.9450\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3114 - accuracy: 0.8765 - val_loss: 0.1277 - val_accuracy: 0.9624\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2907 - accuracy: 0.8873 - val_loss: 0.1403 - val_accuracy: 0.9503\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2843 - accuracy: 0.8911 - val_loss: 0.1368 - val_accuracy: 0.9423\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2593 - accuracy: 0.8982 - val_loss: 0.1310 - val_accuracy: 0.9530\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2605 - accuracy: 0.9015 - val_loss: 0.1148 - val_accuracy: 0.9651\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2502 - accuracy: 0.9043 - val_loss: 0.1356 - val_accuracy: 0.9423\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2712 - accuracy: 0.8963 - val_loss: 0.1070 - val_accuracy: 0.9705\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2548 - accuracy: 0.9006 - val_loss: 0.1121 - val_accuracy: 0.9624\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2840 - accuracy: 0.8935 - val_loss: 0.1179 - val_accuracy: 0.9745\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2565 - accuracy: 0.9075 - val_loss: 0.0977 - val_accuracy: 0.9772\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2555 - accuracy: 0.9009 - val_loss: 0.1055 - val_accuracy: 0.9718\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2362 - accuracy: 0.9116 - val_loss: 0.0917 - val_accuracy: 0.9772\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2420 - accuracy: 0.9104 - val_loss: 0.1004 - val_accuracy: 0.9745\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2620 - accuracy: 0.8975 - val_loss: 0.1064 - val_accuracy: 0.9584\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2635 - accuracy: 0.9054 - val_loss: 0.1519 - val_accuracy: 0.9356\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2353 - accuracy: 0.9137 - val_loss: 0.1172 - val_accuracy: 0.9544\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2498 - accuracy: 0.9072 - val_loss: 0.1266 - val_accuracy: 0.9463\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2287 - accuracy: 0.9125 - val_loss: 0.0924 - val_accuracy: 0.9732\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2193 - accuracy: 0.9194 - val_loss: 0.0788 - val_accuracy: 0.9758\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2196 - accuracy: 0.9161 - val_loss: 0.0878 - val_accuracy: 0.9732\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2249 - accuracy: 0.9119 - val_loss: 0.0873 - val_accuracy: 0.9758\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2582 - accuracy: 0.9066 - val_loss: 0.1125 - val_accuracy: 0.9597\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2065 - accuracy: 0.9218 - val_loss: 0.0928 - val_accuracy: 0.9758\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1946 - accuracy: 0.9271 - val_loss: 0.0764 - val_accuracy: 0.9758\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2041 - accuracy: 0.9236 - val_loss: 0.0815 - val_accuracy: 0.9799\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2191 - accuracy: 0.9209 - val_loss: 0.0546 - val_accuracy: 0.9866\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2097 - accuracy: 0.9230 - val_loss: 0.0567 - val_accuracy: 0.9866\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2142 - accuracy: 0.9222 - val_loss: 0.0634 - val_accuracy: 0.9812\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2149 - accuracy: 0.9245 - val_loss: 0.0701 - val_accuracy: 0.9906\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2303 - accuracy: 0.9167 - val_loss: 0.0700 - val_accuracy: 0.9772\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2150 - accuracy: 0.9152 - val_loss: 0.0788 - val_accuracy: 0.9705\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1887 - accuracy: 0.9295 - val_loss: 0.1475 - val_accuracy: 0.9356\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1925 - accuracy: 0.9329 - val_loss: 0.0688 - val_accuracy: 0.9866\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1917 - accuracy: 0.9316 - val_loss: 0.0667 - val_accuracy: 0.9785\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2089 - accuracy: 0.9227 - val_loss: 0.0549 - val_accuracy: 0.9893\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1940 - accuracy: 0.9283 - val_loss: 0.0657 - val_accuracy: 0.9772\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1800 - accuracy: 0.9343 - val_loss: 0.0664 - val_accuracy: 0.9705\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1693 - accuracy: 0.9416 - val_loss: 0.0889 - val_accuracy: 0.9664\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2144 - accuracy: 0.9283 - val_loss: 0.0553 - val_accuracy: 0.9852\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1684 - accuracy: 0.9383 - val_loss: 0.0531 - val_accuracy: 0.9812\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1824 - accuracy: 0.9358 - val_loss: 0.0466 - val_accuracy: 0.9852\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1823 - accuracy: 0.9361 - val_loss: 0.0889 - val_accuracy: 0.9570\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1847 - accuracy: 0.9323 - val_loss: 0.0477 - val_accuracy: 0.9893\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1801 - accuracy: 0.9355 - val_loss: 0.0516 - val_accuracy: 0.9866\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1558 - accuracy: 0.9470 - val_loss: 0.0402 - val_accuracy: 0.9919\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1630 - accuracy: 0.9408 - val_loss: 0.0391 - val_accuracy: 0.9919\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1601 - accuracy: 0.9423 - val_loss: 0.0390 - val_accuracy: 0.9906\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1831 - accuracy: 0.9352 - val_loss: 0.0545 - val_accuracy: 0.9826\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1578 - accuracy: 0.9417 - val_loss: 0.0531 - val_accuracy: 0.9826\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1472 - accuracy: 0.9484 - val_loss: 0.0364 - val_accuracy: 0.9906\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1676 - accuracy: 0.9401 - val_loss: 0.0484 - val_accuracy: 0.9839\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1960 - accuracy: 0.9313 - val_loss: 0.1368 - val_accuracy: 0.9409\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1581 - accuracy: 0.9443 - val_loss: 0.0522 - val_accuracy: 0.9866\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1737 - accuracy: 0.9353 - val_loss: 0.0493 - val_accuracy: 0.9839\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1629 - accuracy: 0.9420 - val_loss: 0.0417 - val_accuracy: 0.9879\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "CAnc2SJa3o9f",
        "outputId": "27368d16-4773-4431-ce7e-f1ad0411b2db"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 8ms/step - loss: 0.1312 - accuracy: 0.9614\n",
            "Accuracy  : 0.9613733887672424\n",
            "F1_Score  : 0.9601936906843397\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7fcxLuwZpkK",
        "outputId": "ba93af86-d778-4d11-ae62-65f339da48a5"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "23489061-c655-4ac0-a4ce-689c74b98547"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 51ms/step - loss: 1.0837 - accuracy: 0.5451 - val_loss: 0.9152 - val_accuracy: 0.6367\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9590 - accuracy: 0.6207 - val_loss: 0.9025 - val_accuracy: 0.6367\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9419 - accuracy: 0.6271 - val_loss: 0.9229 - val_accuracy: 0.6367\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9534 - accuracy: 0.6234 - val_loss: 0.9079 - val_accuracy: 0.6367\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9378 - accuracy: 0.6278 - val_loss: 0.9187 - val_accuracy: 0.6367\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9344 - accuracy: 0.6318 - val_loss: 0.9075 - val_accuracy: 0.6367\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9286 - accuracy: 0.6376 - val_loss: 0.9319 - val_accuracy: 0.6367\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9422 - accuracy: 0.6234 - val_loss: 0.9073 - val_accuracy: 0.6367\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9307 - accuracy: 0.6270 - val_loss: 0.9051 - val_accuracy: 0.6367\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9211 - accuracy: 0.6289 - val_loss: 0.9081 - val_accuracy: 0.6367\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9229 - accuracy: 0.6347 - val_loss: 0.9072 - val_accuracy: 0.6367\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9265 - accuracy: 0.6212 - val_loss: 0.9053 - val_accuracy: 0.6367\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9203 - accuracy: 0.6306 - val_loss: 0.9091 - val_accuracy: 0.6367\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9228 - accuracy: 0.6261 - val_loss: 0.9106 - val_accuracy: 0.6367\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9189 - accuracy: 0.6301 - val_loss: 0.9048 - val_accuracy: 0.6367\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9233 - accuracy: 0.6237 - val_loss: 0.9119 - val_accuracy: 0.6367\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9153 - accuracy: 0.6269 - val_loss: 0.9026 - val_accuracy: 0.6367\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9387 - accuracy: 0.6133 - val_loss: 0.9085 - val_accuracy: 0.6367\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9225 - accuracy: 0.6216 - val_loss: 0.9048 - val_accuracy: 0.6367\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9185 - accuracy: 0.6276 - val_loss: 0.9104 - val_accuracy: 0.6367\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9087 - accuracy: 0.6336 - val_loss: 0.9095 - val_accuracy: 0.6367\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9250 - accuracy: 0.6186 - val_loss: 0.9040 - val_accuracy: 0.6367\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9182 - accuracy: 0.6255 - val_loss: 0.9245 - val_accuracy: 0.6367\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9148 - accuracy: 0.6297 - val_loss: 0.9036 - val_accuracy: 0.6367\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9239 - accuracy: 0.6216 - val_loss: 0.9072 - val_accuracy: 0.6367\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9258 - accuracy: 0.6178 - val_loss: 0.9081 - val_accuracy: 0.6367\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9137 - accuracy: 0.6258 - val_loss: 0.9139 - val_accuracy: 0.6367\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9141 - accuracy: 0.6293 - val_loss: 0.9126 - val_accuracy: 0.6367\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9255 - accuracy: 0.6150 - val_loss: 0.9029 - val_accuracy: 0.6367\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9181 - accuracy: 0.6235 - val_loss: 0.9148 - val_accuracy: 0.6367\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9158 - accuracy: 0.6261 - val_loss: 0.9173 - val_accuracy: 0.6260\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9123 - accuracy: 0.6261 - val_loss: 0.9099 - val_accuracy: 0.6260\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9138 - accuracy: 0.6261 - val_loss: 0.9098 - val_accuracy: 0.6260\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9112 - accuracy: 0.6261 - val_loss: 0.9081 - val_accuracy: 0.6260\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9098 - accuracy: 0.6261 - val_loss: 0.9119 - val_accuracy: 0.6260\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9097 - accuracy: 0.6261 - val_loss: 0.9229 - val_accuracy: 0.6260\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9211 - accuracy: 0.6261 - val_loss: 0.9183 - val_accuracy: 0.6260\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9175 - accuracy: 0.6261 - val_loss: 0.9173 - val_accuracy: 0.6260\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9150 - accuracy: 0.6261 - val_loss: 0.9171 - val_accuracy: 0.6260\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9155 - accuracy: 0.6261 - val_loss: 0.9158 - val_accuracy: 0.6260\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9164 - accuracy: 0.6261 - val_loss: 0.9150 - val_accuracy: 0.6260\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9141 - accuracy: 0.6253 - val_loss: 0.9117 - val_accuracy: 0.6260\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9105 - accuracy: 0.6261 - val_loss: 0.9190 - val_accuracy: 0.6260\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9112 - accuracy: 0.6261 - val_loss: 0.9085 - val_accuracy: 0.6260\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9111 - accuracy: 0.6261 - val_loss: 0.9178 - val_accuracy: 0.6260\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9151 - accuracy: 0.6261 - val_loss: 0.9138 - val_accuracy: 0.6260\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9137 - accuracy: 0.6264 - val_loss: 0.9125 - val_accuracy: 0.6260\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9149 - accuracy: 0.6261 - val_loss: 0.9115 - val_accuracy: 0.6260\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9083 - accuracy: 0.6265 - val_loss: 0.9092 - val_accuracy: 0.6260\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9101 - accuracy: 0.6259 - val_loss: 0.9082 - val_accuracy: 0.6260\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9096 - accuracy: 0.6253 - val_loss: 0.9079 - val_accuracy: 0.6260\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9069 - accuracy: 0.6259 - val_loss: 0.9101 - val_accuracy: 0.6260\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9121 - accuracy: 0.6258 - val_loss: 0.9043 - val_accuracy: 0.6260\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9078 - accuracy: 0.6261 - val_loss: 0.9109 - val_accuracy: 0.6260\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9084 - accuracy: 0.6259 - val_loss: 0.9078 - val_accuracy: 0.6260\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9039 - accuracy: 0.6261 - val_loss: 0.9056 - val_accuracy: 0.6260\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9025 - accuracy: 0.6273 - val_loss: 0.9055 - val_accuracy: 0.6260\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9039 - accuracy: 0.6270 - val_loss: 0.9013 - val_accuracy: 0.6260\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8999 - accuracy: 0.6261 - val_loss: 0.9064 - val_accuracy: 0.6260\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9017 - accuracy: 0.6258 - val_loss: 0.9083 - val_accuracy: 0.6260\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9027 - accuracy: 0.6268 - val_loss: 0.9021 - val_accuracy: 0.6220\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8981 - accuracy: 0.6282 - val_loss: 0.9004 - val_accuracy: 0.6220\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8957 - accuracy: 0.6280 - val_loss: 0.8975 - val_accuracy: 0.6220\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8940 - accuracy: 0.6264 - val_loss: 0.9114 - val_accuracy: 0.6220\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8953 - accuracy: 0.6268 - val_loss: 0.8962 - val_accuracy: 0.6220\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8927 - accuracy: 0.6274 - val_loss: 0.8917 - val_accuracy: 0.6220\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8910 - accuracy: 0.6255 - val_loss: 0.8933 - val_accuracy: 0.6220\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8873 - accuracy: 0.6264 - val_loss: 0.8901 - val_accuracy: 0.6220\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8862 - accuracy: 0.6261 - val_loss: 0.8790 - val_accuracy: 0.6220\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8800 - accuracy: 0.6279 - val_loss: 0.8773 - val_accuracy: 0.6220\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8726 - accuracy: 0.6291 - val_loss: 0.8785 - val_accuracy: 0.6220\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8775 - accuracy: 0.6280 - val_loss: 0.8799 - val_accuracy: 0.6220\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.8686 - accuracy: 0.6291 - val_loss: 0.8587 - val_accuracy: 0.6220\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8624 - accuracy: 0.6292 - val_loss: 0.8616 - val_accuracy: 0.6233\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8580 - accuracy: 0.6292 - val_loss: 0.8424 - val_accuracy: 0.6233\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8540 - accuracy: 0.6311 - val_loss: 0.8799 - val_accuracy: 0.6233\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8439 - accuracy: 0.6316 - val_loss: 0.8440 - val_accuracy: 0.6220\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8319 - accuracy: 0.6373 - val_loss: 0.8425 - val_accuracy: 0.6273\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8281 - accuracy: 0.6376 - val_loss: 0.8558 - val_accuracy: 0.6233\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8281 - accuracy: 0.6359 - val_loss: 0.8454 - val_accuracy: 0.6287\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8096 - accuracy: 0.6431 - val_loss: 0.8149 - val_accuracy: 0.6233\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8139 - accuracy: 0.6408 - val_loss: 0.8006 - val_accuracy: 0.6327\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7947 - accuracy: 0.6480 - val_loss: 0.7957 - val_accuracy: 0.6367\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7749 - accuracy: 0.6553 - val_loss: 0.7875 - val_accuracy: 0.6434\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7655 - accuracy: 0.6608 - val_loss: 0.7905 - val_accuracy: 0.6394\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7390 - accuracy: 0.6689 - val_loss: 0.7776 - val_accuracy: 0.6528\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7341 - accuracy: 0.6747 - val_loss: 0.7472 - val_accuracy: 0.6622\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7194 - accuracy: 0.6790 - val_loss: 0.7413 - val_accuracy: 0.6649\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6892 - accuracy: 0.6909 - val_loss: 0.7271 - val_accuracy: 0.6702\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6802 - accuracy: 0.7019 - val_loss: 0.6814 - val_accuracy: 0.6917\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6732 - accuracy: 0.7027 - val_loss: 0.5533 - val_accuracy: 0.7815\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6765 - accuracy: 0.7030 - val_loss: 0.5638 - val_accuracy: 0.7694\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6579 - accuracy: 0.7079 - val_loss: 0.5324 - val_accuracy: 0.7426\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6224 - accuracy: 0.7200 - val_loss: 0.5360 - val_accuracy: 0.7520\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6293 - accuracy: 0.7270 - val_loss: 0.5293 - val_accuracy: 0.7735\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6009 - accuracy: 0.7343 - val_loss: 0.5238 - val_accuracy: 0.7721\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6065 - accuracy: 0.7335 - val_loss: 0.5115 - val_accuracy: 0.7828\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5656 - accuracy: 0.7514 - val_loss: 0.4719 - val_accuracy: 0.8043\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5575 - accuracy: 0.7537 - val_loss: 0.4527 - val_accuracy: 0.8070\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5497 - accuracy: 0.7575 - val_loss: 0.4503 - val_accuracy: 0.7882\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5231 - accuracy: 0.7699 - val_loss: 0.4514 - val_accuracy: 0.8070\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5129 - accuracy: 0.7778 - val_loss: 0.4553 - val_accuracy: 0.7815\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4825 - accuracy: 0.7915 - val_loss: 0.4211 - val_accuracy: 0.7869\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4744 - accuracy: 0.8015 - val_loss: 0.4266 - val_accuracy: 0.8029\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4679 - accuracy: 0.7963 - val_loss: 0.4206 - val_accuracy: 0.8190\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4471 - accuracy: 0.8137 - val_loss: 0.4280 - val_accuracy: 0.8271\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4221 - accuracy: 0.8213 - val_loss: 0.3751 - val_accuracy: 0.8485\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4200 - accuracy: 0.8294 - val_loss: 0.3719 - val_accuracy: 0.8351\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3909 - accuracy: 0.8335 - val_loss: 0.3556 - val_accuracy: 0.8525\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4176 - accuracy: 0.8285 - val_loss: 0.3509 - val_accuracy: 0.8579\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3850 - accuracy: 0.8484 - val_loss: 0.3177 - val_accuracy: 0.8807\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3734 - accuracy: 0.8514 - val_loss: 0.3489 - val_accuracy: 0.8633\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3645 - accuracy: 0.8565 - val_loss: 0.3214 - val_accuracy: 0.8592\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3530 - accuracy: 0.8577 - val_loss: 0.3002 - val_accuracy: 0.8914\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3368 - accuracy: 0.8653 - val_loss: 0.3385 - val_accuracy: 0.8525\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3196 - accuracy: 0.8735 - val_loss: 0.3028 - val_accuracy: 0.8794\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2962 - accuracy: 0.8820 - val_loss: 0.2801 - val_accuracy: 0.8981\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2839 - accuracy: 0.8873 - val_loss: 0.2987 - val_accuracy: 0.8820\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2982 - accuracy: 0.8830 - val_loss: 0.2619 - val_accuracy: 0.9021\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3025 - accuracy: 0.8849 - val_loss: 0.3114 - val_accuracy: 0.8767\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2995 - accuracy: 0.8845 - val_loss: 0.1145 - val_accuracy: 0.9705\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3110 - accuracy: 0.8794 - val_loss: 0.1081 - val_accuracy: 0.9718\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2764 - accuracy: 0.8939 - val_loss: 0.0965 - val_accuracy: 0.9678\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2748 - accuracy: 0.8967 - val_loss: 0.0820 - val_accuracy: 0.9786\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2669 - accuracy: 0.8994 - val_loss: 0.0829 - val_accuracy: 0.9759\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2570 - accuracy: 0.9006 - val_loss: 0.0837 - val_accuracy: 0.9759\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2358 - accuracy: 0.9067 - val_loss: 0.1039 - val_accuracy: 0.9678\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2337 - accuracy: 0.9072 - val_loss: 0.1067 - val_accuracy: 0.9625\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2359 - accuracy: 0.9106 - val_loss: 0.0848 - val_accuracy: 0.9786\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2174 - accuracy: 0.9200 - val_loss: 0.0802 - val_accuracy: 0.9718\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2062 - accuracy: 0.9188 - val_loss: 0.0770 - val_accuracy: 0.9812\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2140 - accuracy: 0.9237 - val_loss: 0.0709 - val_accuracy: 0.9745\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1994 - accuracy: 0.9252 - val_loss: 0.0611 - val_accuracy: 0.9826\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2124 - accuracy: 0.9224 - val_loss: 0.0677 - val_accuracy: 0.9799\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1972 - accuracy: 0.9288 - val_loss: 0.0615 - val_accuracy: 0.9826\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1688 - accuracy: 0.9340 - val_loss: 0.0593 - val_accuracy: 0.9799\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1656 - accuracy: 0.9411 - val_loss: 0.0487 - val_accuracy: 0.9839\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1744 - accuracy: 0.9328 - val_loss: 0.0707 - val_accuracy: 0.9718\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1750 - accuracy: 0.9353 - val_loss: 0.0521 - val_accuracy: 0.9879\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1734 - accuracy: 0.9380 - val_loss: 0.0515 - val_accuracy: 0.9799\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1597 - accuracy: 0.9413 - val_loss: 0.0512 - val_accuracy: 0.9853\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1628 - accuracy: 0.9440 - val_loss: 0.0576 - val_accuracy: 0.9826\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1660 - accuracy: 0.9429 - val_loss: 0.0442 - val_accuracy: 0.9879\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1587 - accuracy: 0.9456 - val_loss: 0.0530 - val_accuracy: 0.9853\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1627 - accuracy: 0.9396 - val_loss: 0.0669 - val_accuracy: 0.9772\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1553 - accuracy: 0.9401 - val_loss: 0.0380 - val_accuracy: 0.9920\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1376 - accuracy: 0.9499 - val_loss: 0.0773 - val_accuracy: 0.9732\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1430 - accuracy: 0.9463 - val_loss: 0.0353 - val_accuracy: 0.9946\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1281 - accuracy: 0.9542 - val_loss: 0.0345 - val_accuracy: 0.9906\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1213 - accuracy: 0.9574 - val_loss: 0.0409 - val_accuracy: 0.9853\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1565 - accuracy: 0.9465 - val_loss: 0.0239 - val_accuracy: 0.9920\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1340 - accuracy: 0.9537 - val_loss: 0.0208 - val_accuracy: 0.9933\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1391 - accuracy: 0.9522 - val_loss: 0.0368 - val_accuracy: 0.9866\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1444 - accuracy: 0.9492 - val_loss: 0.0288 - val_accuracy: 0.9893\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1354 - accuracy: 0.9535 - val_loss: 0.0267 - val_accuracy: 0.9879\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1397 - accuracy: 0.9534 - val_loss: 0.0309 - val_accuracy: 0.9879\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1161 - accuracy: 0.9593 - val_loss: 0.0169 - val_accuracy: 0.9933\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1276 - accuracy: 0.9554 - val_loss: 0.0481 - val_accuracy: 0.9799\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1208 - accuracy: 0.9587 - val_loss: 0.0220 - val_accuracy: 0.9920\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1166 - accuracy: 0.9589 - val_loss: 0.0184 - val_accuracy: 0.9973\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1229 - accuracy: 0.9596 - val_loss: 0.0201 - val_accuracy: 0.9933\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1084 - accuracy: 0.9604 - val_loss: 0.0252 - val_accuracy: 0.9906\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0984 - accuracy: 0.9663 - val_loss: 0.0248 - val_accuracy: 0.9866\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1181 - accuracy: 0.9592 - val_loss: 0.0233 - val_accuracy: 0.9906\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1120 - accuracy: 0.9624 - val_loss: 0.0244 - val_accuracy: 0.9893\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1162 - accuracy: 0.9592 - val_loss: 0.0252 - val_accuracy: 0.9893\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0824 - accuracy: 0.9714 - val_loss: 0.0210 - val_accuracy: 0.9893\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1170 - accuracy: 0.9615 - val_loss: 0.0363 - val_accuracy: 0.9866\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1135 - accuracy: 0.9620 - val_loss: 0.0210 - val_accuracy: 0.9933\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0934 - accuracy: 0.9690 - val_loss: 0.0630 - val_accuracy: 0.9732\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0948 - accuracy: 0.9678 - val_loss: 0.0284 - val_accuracy: 0.9920\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0825 - accuracy: 0.9727 - val_loss: 0.0254 - val_accuracy: 0.9879\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0831 - accuracy: 0.9706 - val_loss: 0.0213 - val_accuracy: 0.9920\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0960 - accuracy: 0.9660 - val_loss: 0.0180 - val_accuracy: 0.9933\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0896 - accuracy: 0.9697 - val_loss: 0.0188 - val_accuracy: 0.9933\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0769 - accuracy: 0.9754 - val_loss: 0.0148 - val_accuracy: 0.9946\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0777 - accuracy: 0.9732 - val_loss: 0.0173 - val_accuracy: 0.9933\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0846 - accuracy: 0.9711 - val_loss: 0.0289 - val_accuracy: 0.9906\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0908 - accuracy: 0.9683 - val_loss: 0.0306 - val_accuracy: 0.9853\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1059 - accuracy: 0.9620 - val_loss: 0.0166 - val_accuracy: 0.9933\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0896 - accuracy: 0.9683 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1157 - accuracy: 0.9599 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1029 - accuracy: 0.9653 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0849 - accuracy: 0.9733 - val_loss: 0.0042 - val_accuracy: 0.9987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0812 - accuracy: 0.9741 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1046 - accuracy: 0.9648 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1100 - accuracy: 0.9629 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0644 - accuracy: 0.9778 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0815 - accuracy: 0.9736 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0741 - accuracy: 0.9750 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0870 - accuracy: 0.9720 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0763 - accuracy: 0.9739 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0760 - accuracy: 0.9760 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0905 - accuracy: 0.9714 - val_loss: 0.0057 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0766 - accuracy: 0.9741 - val_loss: 0.0037 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0743 - accuracy: 0.9745 - val_loss: 0.0036 - val_accuracy: 0.9987\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0733 - accuracy: 0.9750 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0874 - accuracy: 0.9718 - val_loss: 0.0061 - val_accuracy: 0.9973\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0884 - accuracy: 0.9717 - val_loss: 0.0066 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0904 - accuracy: 0.9684 - val_loss: 0.0066 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0820 - accuracy: 0.9721 - val_loss: 0.0087 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0688 - accuracy: 0.9790 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0848 - accuracy: 0.9711 - val_loss: 0.0068 - val_accuracy: 0.9973\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0686 - accuracy: 0.9771 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0648 - accuracy: 0.9782 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0619 - accuracy: 0.9818 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0630 - accuracy: 0.9779 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0668 - accuracy: 0.9793 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0729 - accuracy: 0.9748 - val_loss: 0.0034 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0749 - accuracy: 0.9760 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0860 - accuracy: 0.9709 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0614 - accuracy: 0.9812 - val_loss: 7.6866e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0574 - accuracy: 0.9823 - val_loss: 5.3502e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0649 - accuracy: 0.9779 - val_loss: 7.5828e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0526 - accuracy: 0.9820 - val_loss: 6.0065e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0585 - accuracy: 0.9793 - val_loss: 8.2579e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0561 - accuracy: 0.9827 - val_loss: 6.5024e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0696 - accuracy: 0.9788 - val_loss: 9.5471e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0568 - accuracy: 0.9806 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0640 - accuracy: 0.9788 - val_loss: 0.0025 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0596 - accuracy: 0.9796 - val_loss: 9.8850e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0709 - accuracy: 0.9772 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0773 - accuracy: 0.9741 - val_loss: 8.9224e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0570 - accuracy: 0.9815 - val_loss: 6.7221e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0605 - accuracy: 0.9788 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0656 - accuracy: 0.9772 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0567 - accuracy: 0.9797 - val_loss: 5.4660e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0594 - accuracy: 0.9805 - val_loss: 5.7256e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0578 - accuracy: 0.9809 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0529 - accuracy: 0.9826 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0665 - accuracy: 0.9805 - val_loss: 9.8096e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0603 - accuracy: 0.9808 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0547 - accuracy: 0.9823 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0772 - accuracy: 0.9742 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0529 - accuracy: 0.9830 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0597 - accuracy: 0.9814 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0474 - accuracy: 0.9830 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0712 - accuracy: 0.9762 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0520 - accuracy: 0.9838 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0495 - accuracy: 0.9827 - val_loss: 0.0025 - val_accuracy: 0.9987\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0505 - accuracy: 0.9833 - val_loss: 0.0023 - val_accuracy: 0.9987\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0660 - accuracy: 0.9782 - val_loss: 5.9920e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0687 - accuracy: 0.9765 - val_loss: 9.7685e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0685 - accuracy: 0.9774 - val_loss: 9.0144e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0574 - accuracy: 0.9824 - val_loss: 3.5180e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0550 - accuracy: 0.9820 - val_loss: 0.0014 - val_accuracy: 0.9987\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0465 - accuracy: 0.9857 - val_loss: 2.4614e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0479 - accuracy: 0.9838 - val_loss: 0.0019 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0669 - accuracy: 0.9805 - val_loss: 4.0969e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0572 - accuracy: 0.9823 - val_loss: 6.1066e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0381 - accuracy: 0.9881 - val_loss: 8.3154e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0449 - accuracy: 0.9857 - val_loss: 5.3311e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0693 - accuracy: 0.9784 - val_loss: 6.2616e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0617 - accuracy: 0.9803 - val_loss: 5.6997e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0420 - accuracy: 0.9866 - val_loss: 5.5080e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0573 - accuracy: 0.9812 - val_loss: 0.0047 - val_accuracy: 0.9973\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0534 - accuracy: 0.9812 - val_loss: 9.2025e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0666 - accuracy: 0.9765 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0764 - accuracy: 0.9735 - val_loss: 4.4153e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0456 - accuracy: 0.9848 - val_loss: 3.3235e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0499 - accuracy: 0.9845 - val_loss: 6.0988e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0467 - accuracy: 0.9839 - val_loss: 0.0015 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0744 - accuracy: 0.9757 - val_loss: 5.8137e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0485 - accuracy: 0.9842 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0544 - accuracy: 0.9809 - val_loss: 1.9492e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0642 - accuracy: 0.9794 - val_loss: 3.7564e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0489 - accuracy: 0.9869 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0370 - accuracy: 0.9893 - val_loss: 2.7536e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0425 - accuracy: 0.9864 - val_loss: 1.1213e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0470 - accuracy: 0.9842 - val_loss: 2.1302e-04 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0470 - accuracy: 0.9850 - val_loss: 1.0357e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0456 - accuracy: 0.9832 - val_loss: 9.9434e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0655 - accuracy: 0.9774 - val_loss: 1.8467e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0451 - accuracy: 0.9854 - val_loss: 2.4807e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0354 - accuracy: 0.9885 - val_loss: 1.6998e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0522 - accuracy: 0.9845 - val_loss: 1.7448e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0477 - accuracy: 0.9848 - val_loss: 2.0265e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0445 - accuracy: 0.9866 - val_loss: 3.3665e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0574 - accuracy: 0.9811 - val_loss: 3.3713e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0818 - accuracy: 0.9753 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0531 - accuracy: 0.9815 - val_loss: 2.7348e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0464 - accuracy: 0.9861 - val_loss: 4.4697e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0448 - accuracy: 0.9857 - val_loss: 4.7731e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0365 - accuracy: 0.9882 - val_loss: 1.5156e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0427 - accuracy: 0.9867 - val_loss: 1.6382e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0483 - accuracy: 0.9847 - val_loss: 1.6847e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0327 - accuracy: 0.9908 - val_loss: 1.7138e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0415 - accuracy: 0.9867 - val_loss: 1.5870e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0378 - accuracy: 0.9872 - val_loss: 1.3753e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0341 - accuracy: 0.9900 - val_loss: 7.7117e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0395 - accuracy: 0.9858 - val_loss: 1.0291e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0387 - accuracy: 0.9867 - val_loss: 3.0018e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0563 - accuracy: 0.9812 - val_loss: 2.0924e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0452 - accuracy: 0.9847 - val_loss: 2.3126e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0410 - accuracy: 0.9872 - val_loss: 2.2225e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0453 - accuracy: 0.9864 - val_loss: 2.3564e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0343 - accuracy: 0.9900 - val_loss: 1.3359e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0551 - accuracy: 0.9835 - val_loss: 2.2708e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0520 - accuracy: 0.9852 - val_loss: 8.9583e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0415 - accuracy: 0.9850 - val_loss: 1.6211e-04 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "47238377-b26a-4df2-927f-b6667ef3aa00"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 6ms/step - loss: 0.0313 - accuracy: 0.9914\n",
            "Accuracy  : 0.991416335105896\n",
            "F1_Score  : 0.9884697047065547\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAAKOCAYAAAAS8uXWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debQdVZk34N9OQkRkRnKDEBAEWxkcEBC1ZQgEwhgQscGpHVFREBQEJ9rG1rZBRW2hNUi3irY2KEqAQFAGGRqEiMroAEpDEBKbqRn0C7ns749cwk3IcA3e1E7O87jOWvdU1anaFc866+X31q4qtdYAANCOEV0PAACA+SnQAAAao0ADAGiMAg0AoDEKNACAxozqegCL8sytDze9lM7df82Xuh4CQFNWHpXSxXGf+dL3dVYX/OnnX17m5yxBAwBojAINAKAxzbY4AQDmKb2VKfXW2QIALAcUaAAAjdHiBADaVzqZPNoZCRoAQGMkaABA+0wSAACgSxI0AKB9rkEDAKBLCjQAgMZocQIA7TNJAACALknQAID2mSQAAECXFGgAAI3R4gQA2meSAAAAXZKgAQDtM0kAAIAuSdAAgPa5Bg0AgC4p0AAAGqPFCQC0zyQBAAC6JEEDANpnkgAAAF2SoAEA7XMNGgAAXVKgAQA0RosTAGifSQIAAHRJggYAtE+CBgBAlxRoAACN0eIEANo3wn3QAADokAQNAGifSQIAAHRJggYAtM+zOAEA6JICDQCgMVqcAED7TBIAAKBLEjQAoH0mCQAA0CUFGgBAY7Q4AYD2mSQAAECXJGgAQPtMEgAAoEsSNACgfa5BAwCgSwo0AIDGaHECAO0zSQAAgC5J0ACA9pkkAABAlyRoAED7XIMGAECXFGgAAI3R4gQA2meSAAAAXZKgAQDtk6ABANAlBRoAQGO0OAGA9rkPGgAAXZKgAQDtM0kAAIAuSdAAgPa5Bg0AgC4p0AAAGqPFCQC0zyQBAAC6JEEDANpnkgAAAF2SoAEAzSsSNAAAuqRAAwBojBYnANA8LU4AADolQQMA2tdbAZoEDQCgNQo0AIDGaHECAM0zSQAAgE5J0ACA5knQAADolAQNAGieBA0AgE4p0AAAGqPFCQA0T4sTAIBOSdAAgPb1VoAmQQMAaI0CbTk14ZUvzC/P+mhuPPvjOeotuz5l/YbrrZWpX3lvrvmvYzJt8mFZf8ya89b90+H7ZvoZx2b6Gcfmtbu9dFkOm+XUlZdfln332j17T5yQ006d/JT1s2fPztEfPCJ7T5yQNxx0YO66a8a8daed+tXsPXFC9t1r91x5xeVJknvuvjtvf8ubsv8+e2b/fffKt0//xrztf3XLLXnjwa/L614zKQe/7jW54frrh/8EWW78tb+LSbLHhPE5YL995n3nBvvPb5+eSXtPzP777pWTPnvC8J0YS1RK6ezVBS3O5dCIESVfOObA7HXoyblr5gO54ltH5dyf3Jhf/f6eedv88xH75dvnXptvn3tNdtx2sxx/2D55+8dPz8S/3TwvecEGefnBJ+QZK43KhacelmlX3pKHHvlzh2dEy/r7+/PpTx2fr576H+nr68vr/+612Wnn8XneppvO2+YH3z8zq6++es694Ec5f+p5+cLnP5sTP/eF3Hbrrblg6nk5a8p5mTVrZt71jrdmynnTMnLUyBz1oWPzws23yCOPPJyDDjwg27/iVXneppvmpM+fmHcf+t787at3zOWX/SRf+PyJOe3rp3f4L0ArhuW7OHJkkuRr//GNrLXW2vMd75qfXp1LL74oZ541JaNHj8699967TM+X3jZsCVop5QWllGNKKV8aeB1TSnnhcB2vl2y75Ua5bcYfc/td9+axOf05c9p12Xunrebb5gWbjM1Prv1NkuQn1/42e+84d/0LNxmbK667Lf39j+fRP8/ODb/9Q3Z7pf9bWLQbb7g+48ZtlA3GjctKo0dn4p575dJLLppvm0suvjj7Tto/STJht91zzdVXpdaaSy+5KBP33CujR4/OBhuMy7hxG+XGG67PuuuOyQs33yJJ8qxnrZpNNtkks2bNTJKUlDz88CNJkocfeijrrjtmGZ4tLRuO7+LinPlf38nb3nFIRo8enSRZZ511hufEYCGGpUArpRyT5LuZe0nfNQOvkuQ7pZRjh+OYveQ5666ZGfc8MO/9XbMeyPpj1phvmxt+c1cmjX9xkmTS+Bdl9VVXztprrJLrfzO3IHvmyitlnTWflR232Swb9K0ZWJRZM2dm7Hpj570f09eXmTNnzr/NrJkZO3a9JMmoUaOy6mqr5YEH7s/MmTPTN/bJz/aN7cusBT57110z8qtbbslWL5r7ff3QsR/JSZ89IbvtsmM+99l/yeFHfmC4To3lzLB9F0vy7ne+PQcd+Jp874z/mrfN/9x+e6772fS84aAD87a/f+MSCzqGlxbnX8fbk2xRa31s8MJSyueT3JTkMwv7UCnlkCSHJMmocTtn1LO3HKbhrfg+fNIPc9KxB+aN+7w8V153a+6a+UD6+2suuvpXedkWG+aS/zgy/3v/w/np9ben//Ha9XDpUY8+8kg+eMThOfrYj2TVVVdNkpzxX9/J0cd8OLvutnumXTA1n/j4RzP5tK93O1BWaF8//Tvp6+vLvffem3e/463ZeJNN8rJtts2c/v48+OCD+dZ3zsiNN9yQoz94RKZOu6jn7sdFN4arxfl4kucsZPl6A+sWqtY6uda6Ta11G8XZov3hjw9kg7FPpl7rj1kzd816cL5t7v7f/8tBR52WV7z+hPzDyecmSR58+E9JkhNOuzDbH3xC9j70lJSS/PZ/Zi27wbPcGdPXl3vufvL6xlkzZ6avr2/+bcb05Z577k6SzJkzJw8/9FDWXHOt9PX1ZeY9T3525j0zM2bgs4899lg+cMTh2XOvfbLrhN3mbXPO2T/ILgPvd9t9D6kF8wzXd/GJfayzzjoZv+uEed+5vr6+7LLrhJRSstWLXpQRI0bk/vvvH9ZzZNF6LUEbrgLtiCQXlVLOL6VMHnhdkOSiJO8fpmP2jOk33ZFNx62bjZ6zdlYaNTIH7r51zvvJDfNts86az5r3pTr6bRPyjbOvTjJ3gsHaa6ySJNlys+dky82ekx9f/atlewIsV7bYcqvcccftmTHjzjw2e3YumHpedtx5/Hzb7LTz+Ew5+wdJkh9dOC3bvXz7lFKy487jc8HU8zJ79uzMmHFn7rjj9my51YtSa80njvtoNtlkk7z5LW+db1/rjhmT6ddek2TuRdobbvTcZXKetG84vouPPvpoHnnk4STJo48+mqv++8psuulmSZKdd9k1117z0yTJ7bf/Po899ljWWmutZXjG9LJhaXHWWi8opTw/yXZJ1h9YfFeSa2ut/cNxzF7S3/94jvyX7+Wckw/NyBEj8o0pV+eW392Tj797z1x38x0577Ibs8PLNsvxh+2dWpMrrrstR3zmzCTJSqNG5senHZEkeeiRP+dtHzs9/f2LDDUho0aNyoc/elzec8g78vjj/dlv/wOy6aab5eR//WK22GLL7DR+l+x/wGvz0WOPzt4TJ2T1NdbICZ89KUmy6aabZbeJe2T/fffMyJEj85GPHZeRI0fmup9Nz7lTzs5mz39+XveaSUmSw474QF69w4457hOfzAmf+XT658zJ6Gc8I8d94vguT5+GDMd38b57782Rh783STKnvz977rV3XvXqHZIk++9/QI77+Efymkl7Z6WVVsonP/UZ7U2WmVJrm9cfPXPrw9scGD3l/mu+1PUQAJqy8qhu7um/zpu/01ldcO83D17m5+xGtQAAjXGjWgCgfT3WXZagAQA0RoIGADSv1yZoSNAAABqjQAMAaIwWJwDQPC1OAAA6JUEDAJonQQMAoFMKNACAxijQAID2lQ5fSxpaKRNLKb8updxaSjl2Ies3LKVcUkr5eSnl+lLKnkvapwINAGAplVJGJjk5yR5JNk9ycCll8wU2+1iSM2qtL01yUJJTlrRfkwQAgOY1PElguyS31lp/lySllO8mmZTk5kHb1CSrD/y9RpI/LGmnEjQAgMUopRxSSpk+6HXIoNXrJ7lz0PsZA8sG+0SSN5ZSZiSZmuSwJR1TggYANK/LBK3WOjnJ5Kexi4OTfL3W+rlSyiuSnF5K2bLW+viiPiBBAwBYenclGTfo/QYDywZ7e5IzkqTWelWSlZM8e3E7VaABACy9a5NsVkrZuJQyOnMnAUxZYJs7kuySJKWUF2ZugfbHxe1UixMAaF6rkwRqrXNKKe9LMi3JyCT/Xmu9qZRyfJLptdYpST6Y5NRSypGZO2HgLbXWurj9KtAAAJ6GWuvUzL34f/Cy4wb9fXOSV/0l+1SgAQDNazVBGy6uQQMAaIwEDQBoX28FaBI0AIDWKNAAABqjxQkANM8kAQAAOiVBAwCaJ0EDAKBTCjQAgMZocQIAzdPiBACgUxI0AKB9vRWgSdAAAFojQQMAmucaNAAAOqVAAwBojBYnANA8LU4AADolQQMAmidBAwCgUxI0AKB5EjQAADqlQAMAaIwWJwDQvt7qcErQAABaI0EDAJpnkgAAAJ1SoAEANEaLEwBonhYnAACdkqABAM3rsQBNggYA0BoJGgDQPNegAQDQKQUaAEBjtDgBgOb1WIdTggYA0BoJGgDQPJMEAADolAINAKAxWpwAQPN6rMMpQQMAaI0EDQBo3ogRvRWhSdAAABojQQMAmucaNAAAOqVAAwBojBYnANA8TxIAAKBTEjQAoHk9FqBJ0AAAWiNBAwCa5xo0AAA6pUADAGiMFicA0DwtTgAAOiVBAwCa12MBmgQNAKA1CjQAgMZocQIAzTNJAACATknQAIDm9ViAJkEDAGiNBA0AaJ5r0AAA6JQCDQCgMVqcAEDzeqzDKUEDAGiNBA0AaJ5JAgAAdEqCBgA0r8cCNAkaAEBrFGgAAI3R4gQAmmeSAAAAnWo2Qbv3p1/segiQtV55VNdDgCTJvVec2PUQYEA3SVaPBWgSNACA1ijQAAAa02yLEwDgCSYJAADQKQkaANC8HgvQJGgAAK2RoAEAzXMNGgAAnVKgAQA0RosTAGhej3U4JWgAAK2RoAEAzTNJAACATinQAAAao8UJADRPixMAgE5J0ACA5vVYgCZBAwBojQQNAGiea9AAAOiUAg0AoDFanABA83qswylBAwBojQQNAGieSQIAAHRKggYANK/HAjQJGgBAaxRoAACN0eIEAJo3osd6nBI0AIDGSNAAgOb1WIAmQQMAaI0CDQCgMVqcAEDzPEkAAIBOSdAAgOaN6K0ATYIGAPB0lFImllJ+XUq5tZRy7CK2eV0p5eZSyk2llP9c0j4laABA81q9Bq2UMjLJyUkmJJmR5NpSypRa682DttksyYeTvKrWen8pZcyS9itBAwBYetslubXW+rta6+wk300yaYFt3pnk5Frr/UlSa521pJ0q0AAAFqOUckgpZfqg1yGDVq+f5M5B72cMLBvs+UmeX0q5spRydSll4pKOqcUJADSvyw5nrXVykslPYxejkmyWZKckGyS5rJSyVa31gUV9QIIGALD07koybtD7DQaWDTYjyZRa62O11t8n+U3mFmyLpEADAJpXOvzfElybZLNSysallNFJDkoyZYFtfpi56VlKKc/O3Jbn7xa3UwUaAMBSqrXOSfK+JNOS3JLkjFrrTaWU40sp+w5sNi3JvaWUm5NckuToWuu9i9uva9AAgOa1fKPaWuvUJFMXWHbcoL9rkg8MvIZEggYA0BgFGgBAY7Q4AYDmtfokgeEiQQMAaIwEDQBoXo8FaBI0AIDWKNAAABqjxQkANG9Ej/U4JWgAAI2RoAEAzeuxAE2CBgDQGgkaANA8N6oFAKBTCjQAgMZocQIAzeuxDqcEDQCgNRI0AKB5blQLAECnFGgAAI3R4gQAmtdbDU4JGgBAcyRoAEDzPEkAAIBOSdAAgOaN6K0ATYIGANAaBRoAQGO0OAGA5pkkAABApyRoAEDzeixAk6ABALRGggYANM81aAAAdEqBBgDQGC1OAKB5vfYkgUUWaKWUf01SF7W+1nr4sIwIAKDHLS5Bm77MRgEAsBi9NklgkQVarfUbg9+XUlaptT46/EMCAOhtS5wkUEp5RSnl5iS/Gnj/4lLKKcM+MgCAHjWUWZxfSLJ7knuTpNb6yyQ7DOegAAAGKx2+ujCk22zUWu9cYFH/MIwFAIAM7TYbd5ZSXpmkllJWSvL+JLcM77AAAJ40oscmCQwlQXt3kvcmWT/JH5K8ZOA9AADDYIkJWq31f5O8YRmMBQBgoXosQBvSLM5NSinnlFL+WEqZVUo5u5SyybIYHABALxpKi/M/k5yRZL0kz0lyZpLvDOegAAB62VAKtFVqrafXWucMvL6VZOXhHhgAwBNKKZ29urC4Z3GuPfDn+aWUY5N8N3Ofzfl3SaYug7EBAPSkxU0S+FnmFmRPlI7vGrSuJvnwcA0KAGCwXpsksLhncW68LAcCAMBcQ7lRbUopWybZPIOuPau1fnO4BgUAMFiv3ah2iQVaKeUfkuyUuQXa1CR7JLkiiQINAGAYDGUW52uT7JLknlrrW5O8OMkawzoqAIAeNpQC7U+11seTzCmlrJ5kVpJxwzssFubKKy7PfntPzL577JZ//9rkp6yfPXt2jvngkdl3j93ypoNflz/cNSNJ8sAD9+edb31zXrnt1vnMp46f7zNf/uJJmbjLTnnltlsvk3NgxTJh+7/JL8/8UG78/rE56s07P2X9hmPXytST35Vrvv2BTPu392T9MXP/226Hlz0vV3/ryHmv+y//5+yz4xbLevgs56684vLst8/E7LvnYn4Tjzoy++65W970+gV+E9/25rxyu6f+Jj7h/Ye9J6/df59hHT9/mVK6e3VhKAXa9FLKmklOzdyZndcluWpYR8VT9Pf35zP/dHy+/G+n5vtTzs0FU8/LbbfdOt82Pzzre1lt9dUz5fwL84Y3/X2++PnPJUmeMfoZOfSw9+fIoz70lP3usNPOOf27ZyyTc2DFMmJEyRc+tH8mvf9reenfnZgDd39pXrBx33zb/PP79863p/4s273h8/n0aT/K8YfumSS57Ge3Zfs3npTt33hS9jj0K3n0z4/lx1f/povTYDnV39+fz3zq+Hz5lFPz/bPPzQXnL+Y3cerAb+JJg34T37fw38QkuejHF2aVZ64y7OcAi7PEAq3Wemit9YFa61eSTEjy9wOtTpahG2+4PuM23DAbjBuXlVYand332DOXXnzRfNtcevFF2WfSfkmSXXfbPdf89KrUWvPMVVbJS7d+WZ7xjNFP2e+LXvySrLvumGVyDqxYtt1iw9w2497c/of78tic/px54S+y9w7zp2Av2LgvP7n2t0mSn0y/9Snrk2T/8S/KhVf9Kn/6f48tk3GzYljob+IlC/wmXnJR9tl34DdxwkJ+E0c/9Tfx0Ucfybe++fW8413vWSbnwdD12o1qF1mglVK2XvCVZO0kowb+XiqlFMXdUpg1a2b6xq43731f39j8cdbMBbaZlbED24waNSqrrrpaHnjggWU6TnrHc9ZdIzNmPvn9umvWA1l/3fkvT73ht3/IpJ23SpJM2mnLrL7qyll7jfmTiQN3e2nOuPDnwz9gVigL/U2c+fR/E0/51y/lTX//1jxzZQ/MoVuLS9A+t5jXZ5/GMf9xUStKKYeUUqaXUqYv7HoCYPny4S+em1dv/bxcdfqRefXWz8tdMx9If//j89aPXWe1bPG8sfnRVb/ucJQw169/dUvunHFHxu8yoeuhwGJvVPvUK36HqJRy/aJWJelbxLrUWicnmZwkjz5W69Ief0U0ZkxfZt5z97z3M2fek3XH9C2wzZjcc8/d6Rs7NnPmzMnDDz+UNddcc1kPlR7xhz8+mA36nvx+rT9mzdz1xwfn2+bu//2/HHTMN5Ikz3rm6Oy381Z58OE/z1t/wK4vzpRLb8ycQUUbDMVCfxP7nt5v4i9/+YvcfNON2XP38emf05/77rsv73jrm/K1/zh92M6DoRvKRfMrkuE6374kb06yz0Je9w7TMVdoW2y5Ve64439y14wZeeyx2Zl2/tTstPP4+bbZcefxOefsHyZJfnzhtGz78u07652z4pt+853ZdNyzs9Fz1s5Ko0bmwN1ekvMuv2m+bdZZY5V538Gj3zI+3zjn2vnWv057k6W0xZZb5Y7/WeA3cacFfhN3Gp9zpgz8Jv5oWrbdbvG/ia/7u4Pzo4svz9RpF+c/vvntbPTc5yrO6MyQniSwFM5Nsmqt9RcLriilXDpMx1yhjRo1Ksd85OM59F1vz+P9j2fS/gfkeZtullO+/KVsvsWW2Wnn8dnvNa/Nxz78oey7x25ZfY018pkTPz/v83vuNj6PPPxIHnvssVxy8UU5ZfJped7zNs0XPndizp96bv785z9l9112zP6veW3e/d7DOjxTlhf9/Y/nyBN/kHO+9M6MHFHyjXOuzS2/m5mPH7J7rrvlzpx3+c3Z4WWb5vhD90hNcsXPf5cjTjhr3uc3XG+tbNC3Zi6/7nfdnQTLrXm/ie8ewm/ingO/iScM+k3cfeG/ibSr1wKHUhvtJGpx0oJ1XnV010OAJMm9V5zY9RAgSbLK6G4qpcN/+KvO6oIv7feCZX7OQ3nUU0nyhiSb1FqPL6VsmGRsrfWaYR8dAECSEb0VoA3pGrRTkrwiycED7x9KcvKwjQgAoMcN5Rq0l9daty6l/DxJaq33l1Keenc/AAD+KoZSoD1WShmZpCZJKWXdJObEAwDLjBbnU30pyQ+SjCmlfCrJFUk+PayjAgDoYUtM0Gqt3y6l/CzJLpl7o9n9aq23DPvIAAAG9NptNoYyi3PDJI8mOWfwslrrHcM5MACAXjWUa9DOy9zrz0qSlZNsnOTXSbYYxnEBAPSsobQ4txr8vpSydZJDh21EAAALMElgCWqt1yV5+TCMBQCADO0atA8MejsiydZJ/jBsIwIAWECPzREY0jVoqw36e07mXpP2/eEZDgAAiy3QBm5Qu1qt9ahlNB4AgKcY0WMR2iKvQSuljKq19id51TIcDwBAz1tcgnZN5l5v9otSypQkZyZ55ImVtdazhnlsAAA9aSjXoK2c5N4k4/Pk/dBqEgUaALBM/MW3nVjOLa5AGzMwg/PGPFmYPaEO66gAAHrY4gq0kUlWzfyF2RMUaADAMtNjcwQWW6DdXWs9fpmNBACAJIsv0HqsVgUAWuU2G0/aZZmNAgCAeRZZoNVa71uWAwEAYK6h3GYDAKBTPdbh7LnbigAANE+CBgA0b4QEDQCALinQAAAao8UJADTPfdAAAOiUBA0AaF6PBWgSNACA1kjQAIDmuc0GAACdUqABADRGixMAaF5Jb/U4JWgAAI2RoAEAzTNJAACATknQAIDmSdAAAOiUAg0AoDFanABA80qPPYxTggYA0BgJGgDQPJMEAADolAINAKAxWpwAQPN6bI6ABA0AoDUSNACgeSN6LEKToAEANEaCBgA0z202AADolAINAKAxCjQAoHmldPda8tjKxFLKr0spt5ZSjl3MdgeUUmopZZsl7VOBBgCwlEopI5OcnGSPJJsnObiUsvlCtlstyfuT/HQo+1WgAQDNG5HS2WsJtktya631d7XW2Um+m2TSQrb7ZJJ/SfLnoZ0vAACLVEo5pJQyfdDrkEGr109y56D3MwaWDf781knG1VrPG+ox3WYDAGhel/eprbVOTjJ5aT5bShmR5PNJ3vKXfE6CBgCw9O5KMm7Q+w0Glj1htSRbJrm0lHJ7ku2TTFnSRAEFGgDA0rs2yWallI1LKaOTHJRkyhMra60P1lqfXWt9bq31uUmuTrJvrXX64naqxQkANK/VJwnUWueUUt6XZFqSkUn+vdZ6Uynl+CTTa61TFr+HhVOgAQA8DbXWqUmmLrDsuEVsu9NQ9qlAAwCaN6LLWQIdcA0aAEBjFGgAAI3R4gQAmtdjHU4JGgBAayRoAEDzTBIAAKBTEjQAoHk9FqBJ0AAAWqNAAwBojBYnANC8XkuUeu18AQCaJ0EDAJpXemyWgAQNAKAxCjQAgMZocQIAzeutBqcEDQCgORI0AKB5nsUJAECnJGgAQPN6Kz+ToAEANEeBBgDQGC1OAKB5PTZHQIIGANAaCRoA0DzP4gQAoFMSNACgeb2WKPXa+QIANE+BBgDQGC1OAKB5JgkAANApCRoA0Lzeys8kaAAAzVGgAQA0ptkW54geuxiQNt3/35/tegiQJFlr2/d1PQRIkvzp51/u5LgmCQAA0KlmEzQAgCf0WqLUa+cLANA8CRoA0DzXoAEA0CkFGgBAY7Q4AYDm9VaDU4IGANAcCRoA0LwemyMgQQMAaI0EDQBo3ogeuwpNggYA0BgFGgBAY7Q4AYDmmSQAAECnJGgAQPOKSQIAAHRJgQYA0BgtTgCgeSYJAADQKQkaANA8TxIAAKBTEjQAoHmuQQMAoFMKNACAxmhxAgDN0+IEAKBTEjQAoHmexQkAQKcUaAAAjdHiBACaN6K3OpwSNACA1kjQAIDmmSQAAECnJGgAQPPcqBYAgE4p0AAAGqPFCQA0zyQBAAA6JUEDAJrnRrUAAHRKggYANM81aAAAdEqBBgDQGC1OAKB5niQAAECnJGgAQPN6LECToAEAtEaBBgDQGC1OAKB5I3psloAEDQCgMRI0AKB5vZWfSdAAAJojQQMA2tdjEZoEDQCgMQo0AIDGaHECAM0rPdbjlKABADRGggYANK/H7lMrQQMAaI0EDQBoXo8FaBI0AIDWKNAAABqjxQkAtK/HepwSNACAxkjQAIDmuVEtAACdUqABADRGixMAaJ4nCQAA0CkJGgDQvB4L0CRoAACtkaABAO3rsQhNggYA0BgFGgBAY7Q4AYDmeZIAAACdkqABAM1zo1oAAIaslDKxlPLrUsqtpZRjF7L+A6WUm0sp15dSLiqlbLSkfSrQAACWUillZJKTk+yRZPMkB5dSNl9gs58n2abW+qIk30tywpL2q0ADAJpXOnwtwXZJbq21/q7WOjvJd5NMGrxBrfWSWuujA2+vTrLBknaqQAMAWIxSyiGllOmDXocMWr1+kjsHvZ8xsGxR3p7k/CUd0yQBAKB9HU4SqLVOTjL56e6nlFCfG2EAAAyKSURBVPLGJNsk2XFJ2yrQAACW3l1Jxg16v8HAsvmUUnZN8tEkO9Za/9+SdqpAAwCa1/CNaq9NslkpZePMLcwOSvL6wRuUUl6a5KtJJtZaZw1lp65BAwBYSrXWOUnel2RakluSnFFrvamUcnwpZd+BzU5MsmqSM0spvyilTFnSfiVoAABPQ611apKpCyw7btDfu/6l+1SgAQDN8yQBAAA6JUEDAJrXYwGaBA0AoDUSNACgfT0WoUnQAAAao0ADAGiMFicA0LyGnyQwLCRoAACNkaABAM3rtRvVKtAad+Xll+VfPvOpPN7/ePY/4MC8/Z2HzLd+9uzZ+eiHP5Rbbropa6y5Zk743ElZf/0NkiSnnfrV/OD738uIkSNyzIc/llf97auTJMd97MO57CeXZu2118lZZ587b19Hf/CI/M/vf58keeihh7LaaqvljLPOXkZnSst8D1mefeUf3pA9dtgyf7zvoWxz4Ke7Hg4MiRZnw/r7+/PpTx2fU77ytfxgynm5YOq5ue3WW+fb5gffPzOrr756zr3gR3njm9+SL3z+s0mS2269NRdMPS9nTTkvp3z1a/n0P/1j+vv7kyST9ntN/u2rX3vK8U783Bdyxlln54yzzs4uE3bL+F0nDP9J0jzfQ5Z3p59zdSa99+SuhwF/kWEr0EopLyil7FJKWXWB5ROH65grmhtvuD7jxm2UDcaNy0qjR2finnvl0ksumm+bSy6+OPtO2j9JMmG33XPN1Vel1ppLL7koE/fcK6NHj84GG4zLuHEb5cYbrk+SvGybbbP6Gmss8ri11lw47fzssdfew3dyLDd8D1neXXndbbnvwUe7HgZPU+nw1YVhKdBKKYcnOTvJYUluLKVMGrRavjxEs2bOzNj1xs57P6avLzNnzpx/m1kzM3bsekmSUaNGZdXVVssDD9yfmTNnpm/sk5/tG9uXWQt8dlGu+9n0rLPOOtloo+c+/ZNgued7CLDsDVeC9s4kL6u17pdkpyQfL6W8f2DdIovRUsohpZTppZTpp506eZiGxpKcP/XcTNxTakG3fA+B+fRYhDZckwRG1FofTpJa6+2llJ2SfK+UslEWc6q11slJJifJn+ekDtPYlhtj+vpyz933zHs/a+bM9PX1zb/NmL7cc8/d6Rs7NnPmzMnDDz2UNddcK319fZl5z5OfnXnPzIxZ4LMLM2fOnFz04x/lu2ec9dc7EZZrvocAy95wJWgzSykveeLNQLG2d5JnJ9lqmI65wtliy61yxx23Z8aMO/PY7Nm5YOp52XHn8fNts9PO4zPl7B8kSX504bRs9/LtU0rJjjuPzwVTz8vs2bMzY8adueOO27PlVi9a4jF/etV/Z+ONN5mvLUVv8z0EWlA6/F8XhitBe3OSOYMX1FrnJHlzKeWrw3TMFc6oUaPy4Y8el/cc8o48/nh/9tv/gGy66WY5+V+/mC222DI7jd8l+x/w2nz02KOz98QJWX2NNXLCZ09Kkmy66WbZbeIe2X/fPTNy5Mh85GPHZeTIkUmSY476QKZfe00eeOD+TBi/Q97z3sPymgMOTJJccP7UTNxzr87Omfb4HrK8+8Y/vyWvftlmefaaq+bWCz6ZT35lar7xw6u6HhYsVqm1zU6iFifAk9ba9n1dDwGSJH/6+Zc7iZR+dfejndUFL1hvlWV+zm5UCwA0r9eeJOBGtQAAjZGgAQDN67EATYIGANAaCRoA0L4ei9AkaAAAjVGgAQA0RosTAGheV3f074oEDQCgMRI0AKB5blQLAECnFGgAAI3R4gQAmtdjHU4JGgBAayRoAED7eixCk6ABADRGggYANM+NagEA6JQCDQCgMVqcAEDzPEkAAIBOSdAAgOb1WIAmQQMAaI0CDQCgMVqcAED7eqzHKUEDAGiMBA0AaJ4nCQAA0CkJGgDQPDeqBQCgUwo0AIDGaHECAM3rsQ6nBA0AoDUSNACgeSYJAADQKQkaALAc6K0ITYIGANAYBRoAQGO0OAGA5pkkAABApyRoAEDzeixAk6ABALRGgQYA0BgtTgCgeSYJAADQKQkaANC80mPTBCRoAACNkaABAO3rrQBNggYA0BoFGgBAY7Q4AYDm9ViHU4IGANAaCRoA0Dw3qgUAoFMSNACgeW5UCwBApxRoAACN0eIEANrXWx1OCRoAQGskaABA83osQJOgAQC0RoEGANAYLU4AoHmeJAAAQKckaABA8zxJAACATknQAIDmuQYNAIBOKdAAABqjQAMAaIwCDQCgMSYJAADNM0kAAIBOSdAAgOa5US0AAJ1SoAEANEaLEwBonkkCAAB0SoIGADSvxwI0CRoAQGsUaAAAjdHiBADa12M9TgkaAEBjJGgAQPM8SQAAgE5J0ACA5rlRLQAAnVKgAQA0RosTAGhej3U4JWgAAK2RoAEA7euxCE2CBgDQGAUaAEBjtDgBgOZ5kgAAAJ2SoAEAzfMkAQAAOlVqrV2PgWFSSjmk1jq563GA7yIt8D1keSJBW7Ed0vUAYIDvIi3wPWS5oUADAGiMAg0AoDEKtBWbay1ohe8iLfA9ZLlhkgAAQGMkaAAAjVGgAQA0RoG2giqlTCyl/LqUcmsp5diux0NvKqX8eyllVinlxq7HQu8qpYwrpVxSSrm5lHJTKeX9XY8JlsQ1aCugUsrIJL9JMiHJjCTXJjm41npzpwOj55RSdkjycJJv1lq37Ho89KZSynpJ1qu1XldKWS3Jz5Ls5zeRlknQVkzbJbm11vq7WuvsJN9NMqnjMdGDaq2XJbmv63HQ22qtd9darxv4+6EktyRZv9tRweIp0FZM6ye5c9D7GfFjBJBSynOTvDTJT7sdCSyeAg2AnlBKWTXJ95McUWv9v67HA4ujQFsx3ZVk3KD3GwwsA+hJpZSVMrc4+3at9ayuxwNLokBbMV2bZLNSysallNFJDkoypeMxAXSilFKSnJbkllrr57seDwyFAm0FVGudk+R9SaZl7sWwZ9Rab+p2VPSiUsp3klyV5G9KKTNKKW/vekz0pFcleVOS8aWUXwy89ux6ULA4brMBANAYCRoAQGMUaAAAjVGgAQA0RoEGANAYBRoAQGMUaLACKqX0D9xK4MZSypmllFWexr6+Xkp57cDfXyulbL6YbXcqpbxyKY5xeynl2UNdvsA2D/+Fx/pEKeWov3SMAMuSAg1WTH+qtb6k1rplktlJ3j14ZSll1NLstNb6jlrrzYvZZKckf3GBBsD8FGiw4rs8yaYD6dblpZQpSW4upYwspZxYSrm2lHJ9KeVdydy7rpdSvlxK+XUp5cdJxjyxo1LKpaWUbQb+nlhKua6U8stSykUDD6F+d5IjB9K7V5dS1i2lfH/gGNeWUl418Nl1SikXllJuKqV8LUlZ0kmUUn5YSvnZwGcOWWDdSQPLLyqlrDuw7HmllAsGPnN5KeUFf41/TIBlYan+KxpYPgwkZXskuWBg0dZJtqy1/n6gyHmw1rptKeUZSa4spVyY5KVJ/ibJ5kn6ktyc5N8X2O+6SU5NssPAvtautd5XSvlKkodrrZ8d2O4/k5xUa72ilLJh5j7d4oVJ/iHJFbXW40speyUZyhMG3jZwjGcmubaU8v1a671JnpVkeq31yFLKcQP7fl+SyUneXWv9bSnl5UlOSTJ+Kf4ZAZY5BRqsmJ5ZSvnFwN+XZ+5zCF+Z5Jpa6+8Hlu+W5EVPXF+WZI0kmyXZIcl3aq39Sf5QSrl4IfvfPsllT+yr1nrfIsaxa5LN5z4KMUmyeill1YFjvGbgs+eVUu4fwjkdXkrZf+DvcQNjvTfJ40n+a2D5t5KcNXCMVyY5c9CxnzGEYwA0QYEGK6Y/1VpfMnjBQKHyyOBFSQ6rtU5bYLu/5jMKRyTZvtb654WMZchKKTtlbrH3ilrro6WUS5OsvIjN68BxH1jw3wBgeeEaNOhd05K8p5SyUpKUUp5fSnlWksuS/N3ANWrrJdl5IZ+9OskOpZSNBz679sDyh5KsNmi7C5Mc9sSbUsoTBdNlSV4/sGyPJGstYaxrJLl/oDh7QeYmeE8YkeSJFPD1mds6/b8kvy+lHDhwjFJKefESjgHQDAUa9K6vZe71ZdeVUm5M8tXMTdV/kOS3A+u+meSqBT9Ya/1jkkMyt534yzzZYjwnyf5PTBJIcniSbQYmIdycJ2eT/mPmFng3ZW6r844ljPWCJKNKKbck+UzmFohPeCTJdgPnMD7J8QPL35Dk7QPjuynJpCH8mwA0odRaux4DAACDSNAAABqjQAMAaIwCDQCgMQo0AIDGKNAAABqjQAMAaIwCDQCgMf8f9V7BqwOKNlAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c2db563-bfe0-43dc-9195-f331cc1148f5"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}