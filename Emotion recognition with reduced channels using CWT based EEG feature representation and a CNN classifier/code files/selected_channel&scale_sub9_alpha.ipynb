{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub9_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "6b1bac60-d217-4eee-cb92-cf9d5bd21a22"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e3\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  #EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "75de2f82-dc5b-4603-b61b-bd853091376a"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(9,10):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.9\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (2796,) (3961,) (2563,)\n",
            "(9320,) (233,) (4893,) (4194,)\n",
            "(9320,) (3728,) (3728,) (1864,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "6014721e-90b9-4614-9416-85f72b2b8bf0"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "3c0495b2-0ac2-4c7c-d198-c515880d11f4"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "632"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "9fbd377c-1f8f-4b77-eceb-c061292b7702"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3e11ed5-868f-40ba-c781-96ec711042b7"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 20s 58ms/step - loss: 1.2062 - accuracy: 0.3828 - val_loss: 1.0875 - val_accuracy: 0.4249\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0730 - accuracy: 0.4231 - val_loss: 1.0578 - val_accuracy: 0.4276\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0686 - accuracy: 0.4331 - val_loss: 1.0504 - val_accuracy: 0.4424\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0642 - accuracy: 0.4455 - val_loss: 1.0571 - val_accuracy: 0.4223\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0622 - accuracy: 0.4499 - val_loss: 1.0432 - val_accuracy: 0.4437\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0643 - accuracy: 0.4404 - val_loss: 1.0488 - val_accuracy: 0.4209\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0587 - accuracy: 0.4421 - val_loss: 1.0337 - val_accuracy: 0.4450\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0506 - accuracy: 0.4401 - val_loss: 1.0371 - val_accuracy: 0.4504\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0470 - accuracy: 0.4499 - val_loss: 1.0243 - val_accuracy: 0.4437\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0468 - accuracy: 0.4400 - val_loss: 1.0226 - val_accuracy: 0.4544\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0411 - accuracy: 0.4456 - val_loss: 1.0188 - val_accuracy: 0.4437\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0329 - accuracy: 0.4429 - val_loss: 1.0328 - val_accuracy: 0.4383\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0353 - accuracy: 0.4570 - val_loss: 1.0402 - val_accuracy: 0.4276\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0386 - accuracy: 0.4357 - val_loss: 1.0335 - val_accuracy: 0.4383\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0295 - accuracy: 0.4633 - val_loss: 1.0172 - val_accuracy: 0.4504\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0306 - accuracy: 0.4553 - val_loss: 1.0211 - val_accuracy: 0.4517\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0382 - accuracy: 0.4538 - val_loss: 1.0154 - val_accuracy: 0.4477\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0304 - accuracy: 0.4531 - val_loss: 1.0160 - val_accuracy: 0.4638\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0335 - accuracy: 0.4594 - val_loss: 1.0166 - val_accuracy: 0.4638\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0313 - accuracy: 0.4606 - val_loss: 1.0150 - val_accuracy: 0.4611\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0278 - accuracy: 0.4575 - val_loss: 1.0166 - val_accuracy: 0.4330\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0392 - accuracy: 0.4440 - val_loss: 1.0087 - val_accuracy: 0.4732\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0165 - accuracy: 0.4665 - val_loss: 1.0087 - val_accuracy: 0.4571\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0191 - accuracy: 0.4675 - val_loss: 1.0161 - val_accuracy: 0.4517\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0186 - accuracy: 0.4639 - val_loss: 1.0160 - val_accuracy: 0.4558\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0209 - accuracy: 0.4671 - val_loss: 1.0031 - val_accuracy: 0.4611\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0104 - accuracy: 0.4607 - val_loss: 0.9945 - val_accuracy: 0.4772\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0113 - accuracy: 0.4744 - val_loss: 1.0041 - val_accuracy: 0.4678\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0129 - accuracy: 0.4801 - val_loss: 1.0017 - val_accuracy: 0.4732\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0042 - accuracy: 0.4657 - val_loss: 1.0081 - val_accuracy: 0.4732\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0043 - accuracy: 0.4781 - val_loss: 0.9874 - val_accuracy: 0.5067\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0089 - accuracy: 0.4678 - val_loss: 0.9808 - val_accuracy: 0.4839\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9961 - accuracy: 0.4817 - val_loss: 0.9667 - val_accuracy: 0.5080\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 1.0041 - accuracy: 0.4739 - val_loss: 0.9685 - val_accuracy: 0.5174\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9949 - accuracy: 0.4791 - val_loss: 0.9873 - val_accuracy: 0.4973\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9905 - accuracy: 0.4724 - val_loss: 0.9704 - val_accuracy: 0.5134\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9840 - accuracy: 0.4805 - val_loss: 0.9616 - val_accuracy: 0.4933\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9809 - accuracy: 0.4760 - val_loss: 0.9516 - val_accuracy: 0.5121\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9719 - accuracy: 0.4963 - val_loss: 0.9471 - val_accuracy: 0.5094\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9708 - accuracy: 0.4911 - val_loss: 0.9618 - val_accuracy: 0.5040\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9665 - accuracy: 0.5089 - val_loss: 0.9390 - val_accuracy: 0.5174\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9470 - accuracy: 0.5142 - val_loss: 0.9392 - val_accuracy: 0.5107\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9548 - accuracy: 0.5070 - val_loss: 0.9291 - val_accuracy: 0.5282\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9369 - accuracy: 0.5249 - val_loss: 0.9163 - val_accuracy: 0.5375\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9291 - accuracy: 0.5264 - val_loss: 0.8986 - val_accuracy: 0.5563\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9167 - accuracy: 0.5329 - val_loss: 0.9100 - val_accuracy: 0.5228\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9019 - accuracy: 0.5525 - val_loss: 0.8776 - val_accuracy: 0.5630\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8927 - accuracy: 0.5468 - val_loss: 0.8616 - val_accuracy: 0.5791\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8770 - accuracy: 0.5684 - val_loss: 0.8769 - val_accuracy: 0.5751\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8624 - accuracy: 0.5724 - val_loss: 0.8431 - val_accuracy: 0.5871\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8547 - accuracy: 0.5768 - val_loss: 0.8354 - val_accuracy: 0.5858\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8235 - accuracy: 0.5912 - val_loss: 0.8278 - val_accuracy: 0.5979\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8096 - accuracy: 0.6069 - val_loss: 0.8177 - val_accuracy: 0.6099\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7880 - accuracy: 0.6230 - val_loss: 0.7666 - val_accuracy: 0.6327\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7729 - accuracy: 0.6358 - val_loss: 0.7716 - val_accuracy: 0.6327\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7433 - accuracy: 0.6501 - val_loss: 0.7392 - val_accuracy: 0.6300\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7077 - accuracy: 0.6630 - val_loss: 0.7904 - val_accuracy: 0.6220\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6979 - accuracy: 0.6724 - val_loss: 0.7061 - val_accuracy: 0.6461\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6794 - accuracy: 0.6902 - val_loss: 0.6395 - val_accuracy: 0.7118\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.6576 - accuracy: 0.6964 - val_loss: 0.6676 - val_accuracy: 0.6890\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6460 - accuracy: 0.7033 - val_loss: 0.4407 - val_accuracy: 0.8177\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6155 - accuracy: 0.7210 - val_loss: 0.4169 - val_accuracy: 0.8311\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5828 - accuracy: 0.7416 - val_loss: 0.4434 - val_accuracy: 0.8150\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5442 - accuracy: 0.7574 - val_loss: 0.3764 - val_accuracy: 0.8378\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5366 - accuracy: 0.7608 - val_loss: 0.3820 - val_accuracy: 0.8418\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4848 - accuracy: 0.7967 - val_loss: 0.3288 - val_accuracy: 0.8660\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4863 - accuracy: 0.7921 - val_loss: 0.3210 - val_accuracy: 0.8552\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4824 - accuracy: 0.7969 - val_loss: 0.3296 - val_accuracy: 0.8660\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.4238 - accuracy: 0.8230 - val_loss: 0.2870 - val_accuracy: 0.8834\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3955 - accuracy: 0.8423 - val_loss: 0.2687 - val_accuracy: 0.8995\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3765 - accuracy: 0.8463 - val_loss: 0.3211 - val_accuracy: 0.8700\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3701 - accuracy: 0.8550 - val_loss: 0.2652 - val_accuracy: 0.8874\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3452 - accuracy: 0.8639 - val_loss: 0.2736 - val_accuracy: 0.8914\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3272 - accuracy: 0.8702 - val_loss: 0.2282 - val_accuracy: 0.9048\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2909 - accuracy: 0.8890 - val_loss: 0.2582 - val_accuracy: 0.8995\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2949 - accuracy: 0.8854 - val_loss: 0.1866 - val_accuracy: 0.9196\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2662 - accuracy: 0.8996 - val_loss: 0.2012 - val_accuracy: 0.9169\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2614 - accuracy: 0.9019 - val_loss: 0.2192 - val_accuracy: 0.9115\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2371 - accuracy: 0.9158 - val_loss: 0.1643 - val_accuracy: 0.9383\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2588 - accuracy: 0.9095 - val_loss: 0.1705 - val_accuracy: 0.9370\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2436 - accuracy: 0.9112 - val_loss: 0.1654 - val_accuracy: 0.9424\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2212 - accuracy: 0.9191 - val_loss: 0.1724 - val_accuracy: 0.9316\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2060 - accuracy: 0.9282 - val_loss: 0.1570 - val_accuracy: 0.9383\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1930 - accuracy: 0.9326 - val_loss: 0.2376 - val_accuracy: 0.9115\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2023 - accuracy: 0.9259 - val_loss: 0.1575 - val_accuracy: 0.9477\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2009 - accuracy: 0.9314 - val_loss: 0.1205 - val_accuracy: 0.9477\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1749 - accuracy: 0.9395 - val_loss: 0.1458 - val_accuracy: 0.9437\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1577 - accuracy: 0.9426 - val_loss: 0.1964 - val_accuracy: 0.9330\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1595 - accuracy: 0.9447 - val_loss: 0.1813 - val_accuracy: 0.9236\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1635 - accuracy: 0.9402 - val_loss: 0.1626 - val_accuracy: 0.9370\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1943 - accuracy: 0.9308 - val_loss: 0.0215 - val_accuracy: 0.9933\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1812 - accuracy: 0.9344 - val_loss: 0.0213 - val_accuracy: 0.9933\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1612 - accuracy: 0.9452 - val_loss: 0.0230 - val_accuracy: 0.9960\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1373 - accuracy: 0.9501 - val_loss: 0.0171 - val_accuracy: 0.9946\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1410 - accuracy: 0.9495 - val_loss: 0.0170 - val_accuracy: 0.9946\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1477 - accuracy: 0.9526 - val_loss: 0.0420 - val_accuracy: 0.9826\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1566 - accuracy: 0.9435 - val_loss: 0.0226 - val_accuracy: 0.9946\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1295 - accuracy: 0.9541 - val_loss: 0.0178 - val_accuracy: 0.9960\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1236 - accuracy: 0.9571 - val_loss: 0.0262 - val_accuracy: 0.9933\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1215 - accuracy: 0.9590 - val_loss: 0.0157 - val_accuracy: 0.9960\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1156 - accuracy: 0.9602 - val_loss: 0.0202 - val_accuracy: 0.9946\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1267 - accuracy: 0.9556 - val_loss: 0.0197 - val_accuracy: 0.9933\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1135 - accuracy: 0.9595 - val_loss: 0.0182 - val_accuracy: 0.9960\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1160 - accuracy: 0.9614 - val_loss: 0.0211 - val_accuracy: 0.9933\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1216 - accuracy: 0.9581 - val_loss: 0.0217 - val_accuracy: 0.9946\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0971 - accuracy: 0.9681 - val_loss: 0.0161 - val_accuracy: 0.9960\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0963 - accuracy: 0.9674 - val_loss: 0.0356 - val_accuracy: 0.9893\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0961 - accuracy: 0.9662 - val_loss: 0.0212 - val_accuracy: 0.9946\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1224 - accuracy: 0.9575 - val_loss: 0.0241 - val_accuracy: 0.9920\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.0990 - accuracy: 0.9683 - val_loss: 0.0298 - val_accuracy: 0.9893\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0938 - accuracy: 0.9699 - val_loss: 0.0217 - val_accuracy: 0.9920\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0911 - accuracy: 0.9696 - val_loss: 0.0212 - val_accuracy: 0.9893\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0936 - accuracy: 0.9690 - val_loss: 0.0278 - val_accuracy: 0.9893\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0929 - accuracy: 0.9668 - val_loss: 0.0154 - val_accuracy: 0.9933\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1094 - accuracy: 0.9633 - val_loss: 0.0263 - val_accuracy: 0.9906\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0837 - accuracy: 0.9723 - val_loss: 0.0175 - val_accuracy: 0.9920\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.0856 - accuracy: 0.9703 - val_loss: 0.0304 - val_accuracy: 0.9879\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0831 - accuracy: 0.9705 - val_loss: 0.0224 - val_accuracy: 0.9920\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0916 - accuracy: 0.9717 - val_loss: 0.0209 - val_accuracy: 0.9960\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0775 - accuracy: 0.9745 - val_loss: 0.0384 - val_accuracy: 0.9853\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0901 - accuracy: 0.9699 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0856 - accuracy: 0.9718 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0898 - accuracy: 0.9693 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0852 - accuracy: 0.9703 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0820 - accuracy: 0.9745 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0832 - accuracy: 0.9721 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0713 - accuracy: 0.9763 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0852 - accuracy: 0.9699 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0728 - accuracy: 0.9747 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0694 - accuracy: 0.9769 - val_loss: 0.0031 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0691 - accuracy: 0.9773 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0764 - accuracy: 0.9754 - val_loss: 0.0034 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0758 - accuracy: 0.9750 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0623 - accuracy: 0.9781 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0745 - accuracy: 0.9776 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0658 - accuracy: 0.9776 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0709 - accuracy: 0.9772 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0593 - accuracy: 0.9803 - val_loss: 0.0043 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0684 - accuracy: 0.9791 - val_loss: 0.0080 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0590 - accuracy: 0.9808 - val_loss: 0.0033 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0821 - accuracy: 0.9712 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0636 - accuracy: 0.9806 - val_loss: 6.6705e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0586 - accuracy: 0.9811 - val_loss: 7.3415e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0461 - accuracy: 0.9855 - val_loss: 6.5017e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0530 - accuracy: 0.9827 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0592 - accuracy: 0.9793 - val_loss: 7.5430e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0638 - accuracy: 0.9802 - val_loss: 0.0100 - val_accuracy: 0.9973\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0576 - accuracy: 0.9805 - val_loss: 9.9406e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0629 - accuracy: 0.9811 - val_loss: 0.0042 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0629 - accuracy: 0.9800 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0597 - accuracy: 0.9814 - val_loss: 3.0258e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0515 - accuracy: 0.9814 - val_loss: 4.0727e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0534 - accuracy: 0.9833 - val_loss: 8.0180e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0562 - accuracy: 0.9791 - val_loss: 4.4738e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0671 - accuracy: 0.9772 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0456 - accuracy: 0.9846 - val_loss: 6.6706e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0630 - accuracy: 0.9794 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0611 - accuracy: 0.9802 - val_loss: 6.1289e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0522 - accuracy: 0.9832 - val_loss: 9.3616e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0548 - accuracy: 0.9826 - val_loss: 4.4296e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0536 - accuracy: 0.9826 - val_loss: 0.0064 - val_accuracy: 0.9973\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0535 - accuracy: 0.9812 - val_loss: 0.0026 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0549 - accuracy: 0.9821 - val_loss: 4.6807e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0483 - accuracy: 0.9860 - val_loss: 3.7455e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0629 - accuracy: 0.9806 - val_loss: 9.9426e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0632 - accuracy: 0.9818 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0649 - accuracy: 0.9803 - val_loss: 5.2640e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0490 - accuracy: 0.9849 - val_loss: 0.0022 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0581 - accuracy: 0.9806 - val_loss: 6.1282e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0563 - accuracy: 0.9830 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0456 - accuracy: 0.9870 - val_loss: 6.2482e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0459 - accuracy: 0.9864 - val_loss: 6.7919e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0449 - accuracy: 0.9875 - val_loss: 0.0027 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0571 - accuracy: 0.9824 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0479 - accuracy: 0.9835 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0469 - accuracy: 0.9839 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0493 - accuracy: 0.9814 - val_loss: 0.0043 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0473 - accuracy: 0.9858 - val_loss: 7.6666e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0460 - accuracy: 0.9829 - val_loss: 6.4884e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0400 - accuracy: 0.9861 - val_loss: 3.2514e-04 - val_accuracy: 1.0000\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 48ms/step - loss: 0.0444 - accuracy: 0.9860 - val_loss: 1.4911e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0616 - accuracy: 0.9803 - val_loss: 5.1228e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0672 - accuracy: 0.9779 - val_loss: 2.6937e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0475 - accuracy: 0.9852 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0473 - accuracy: 0.9864 - val_loss: 1.4262e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0467 - accuracy: 0.9875 - val_loss: 5.8571e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0611 - accuracy: 0.9785 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0421 - accuracy: 0.9876 - val_loss: 2.1132e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0463 - accuracy: 0.9841 - val_loss: 2.3792e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0470 - accuracy: 0.9850 - val_loss: 8.7107e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0493 - accuracy: 0.9850 - val_loss: 3.1290e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0415 - accuracy: 0.9851 - val_loss: 4.8463e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0341 - accuracy: 0.9893 - val_loss: 1.5782e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0439 - accuracy: 0.9866 - val_loss: 2.4586e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0491 - accuracy: 0.9850 - val_loss: 1.4724e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0390 - accuracy: 0.9884 - val_loss: 0.0067 - val_accuracy: 0.9960\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0610 - accuracy: 0.9784 - val_loss: 6.1109e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0461 - accuracy: 0.9848 - val_loss: 4.5259e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0387 - accuracy: 0.9875 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0494 - accuracy: 0.9848 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0498 - accuracy: 0.9835 - val_loss: 8.4005e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0375 - accuracy: 0.9890 - val_loss: 5.3342e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0351 - accuracy: 0.9893 - val_loss: 5.4494e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0485 - accuracy: 0.9839 - val_loss: 9.9669e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0409 - accuracy: 0.9875 - val_loss: 1.9585e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0282 - accuracy: 0.9896 - val_loss: 3.4165e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0503 - accuracy: 0.9835 - val_loss: 0.0034 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0453 - accuracy: 0.9861 - val_loss: 1.4929e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0298 - accuracy: 0.9909 - val_loss: 7.8019e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0585 - accuracy: 0.9824 - val_loss: 4.8451e-04 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0422 - accuracy: 0.9870 - val_loss: 5.8412e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0495 - accuracy: 0.9852 - val_loss: 1.0126e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0431 - accuracy: 0.9864 - val_loss: 2.9828e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0333 - accuracy: 0.9893 - val_loss: 1.2403e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0432 - accuracy: 0.9857 - val_loss: 2.1216e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0420 - accuracy: 0.9881 - val_loss: 1.0670e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0425 - accuracy: 0.9864 - val_loss: 1.9126e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0352 - accuracy: 0.9890 - val_loss: 5.4920e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0581 - accuracy: 0.9827 - val_loss: 3.9443e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0450 - accuracy: 0.9864 - val_loss: 1.3665e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0402 - accuracy: 0.9875 - val_loss: 5.2087e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0313 - accuracy: 0.9896 - val_loss: 5.1775e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0328 - accuracy: 0.9902 - val_loss: 9.4633e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0344 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0377 - accuracy: 0.9870 - val_loss: 3.3842e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0234 - accuracy: 0.9927 - val_loss: 9.7508e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0531 - accuracy: 0.9838 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0480 - accuracy: 0.9858 - val_loss: 7.0311e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0427 - accuracy: 0.9869 - val_loss: 3.0947e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0384 - accuracy: 0.9888 - val_loss: 2.9833e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0334 - accuracy: 0.9897 - val_loss: 8.7883e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0466 - accuracy: 0.9847 - val_loss: 6.6046e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0442 - accuracy: 0.9870 - val_loss: 2.7586e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0339 - accuracy: 0.9908 - val_loss: 3.2164e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0230 - accuracy: 0.9924 - val_loss: 1.2625e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0333 - accuracy: 0.9909 - val_loss: 0.0034 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0421 - accuracy: 0.9878 - val_loss: 5.6363e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0384 - accuracy: 0.9869 - val_loss: 7.6982e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0302 - accuracy: 0.9915 - val_loss: 3.4000e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0310 - accuracy: 0.9908 - val_loss: 5.8405e-04 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0506 - accuracy: 0.9833 - val_loss: 5.3591e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0442 - accuracy: 0.9851 - val_loss: 1.2366e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0420 - accuracy: 0.9876 - val_loss: 2.8932e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0349 - accuracy: 0.9885 - val_loss: 5.7860e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0393 - accuracy: 0.9887 - val_loss: 1.1936e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0315 - accuracy: 0.9905 - val_loss: 3.9199e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0280 - accuracy: 0.9911 - val_loss: 5.8178e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0476 - accuracy: 0.9857 - val_loss: 6.1122e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0429 - accuracy: 0.9884 - val_loss: 2.0956e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0342 - accuracy: 0.9894 - val_loss: 1.2033e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0322 - accuracy: 0.9909 - val_loss: 3.0198e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0403 - accuracy: 0.9878 - val_loss: 1.4064e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0315 - accuracy: 0.9906 - val_loss: 7.0645e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0397 - accuracy: 0.9870 - val_loss: 5.7674e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0318 - accuracy: 0.9890 - val_loss: 2.6191e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0332 - accuracy: 0.9890 - val_loss: 4.4182e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0294 - accuracy: 0.9908 - val_loss: 5.5913e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0340 - accuracy: 0.9888 - val_loss: 9.4429e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0385 - accuracy: 0.9887 - val_loss: 1.0351e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0248 - accuracy: 0.9921 - val_loss: 3.3074e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0265 - accuracy: 0.9906 - val_loss: 7.5386e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 1.0465e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0336 - accuracy: 0.9888 - val_loss: 5.9073e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0317 - accuracy: 0.9891 - val_loss: 3.8357e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0416 - accuracy: 0.9878 - val_loss: 1.1739e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0346 - accuracy: 0.9894 - val_loss: 1.4484e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0287 - accuracy: 0.9906 - val_loss: 1.4603e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0376 - accuracy: 0.9893 - val_loss: 0.0033 - val_accuracy: 0.9973\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0370 - accuracy: 0.9881 - val_loss: 6.5492e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0349 - accuracy: 0.9893 - val_loss: 2.8669e-04 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0283 - accuracy: 0.9912 - val_loss: 1.6760e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0304 - accuracy: 0.9902 - val_loss: 3.5453e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0383 - accuracy: 0.9878 - val_loss: 2.0910e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0374 - accuracy: 0.9887 - val_loss: 3.8545e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0375 - accuracy: 0.9890 - val_loss: 4.4198e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0382 - accuracy: 0.9875 - val_loss: 3.9562e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0321 - accuracy: 0.9906 - val_loss: 1.2844e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0256 - accuracy: 0.9927 - val_loss: 1.5483e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0287 - accuracy: 0.9909 - val_loss: 1.4061e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0394 - accuracy: 0.9896 - val_loss: 1.4210e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0370 - accuracy: 0.9885 - val_loss: 3.9914e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0316 - accuracy: 0.9912 - val_loss: 5.6508e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0364 - accuracy: 0.9896 - val_loss: 6.6784e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0421 - accuracy: 0.9863 - val_loss: 4.0442e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0259 - accuracy: 0.9924 - val_loss: 8.4132e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0318 - accuracy: 0.9890 - val_loss: 3.2815e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0352 - accuracy: 0.9897 - val_loss: 8.2397e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0289 - accuracy: 0.9906 - val_loss: 4.2783e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0219 - accuracy: 0.9931 - val_loss: 5.9231e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0254 - accuracy: 0.9937 - val_loss: 5.6397e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0420 - accuracy: 0.9864 - val_loss: 8.2267e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0255 - accuracy: 0.9923 - val_loss: 2.4821e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0218 - accuracy: 0.9934 - val_loss: 7.6167e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0268 - accuracy: 0.9917 - val_loss: 3.0366e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0240 - accuracy: 0.9906 - val_loss: 1.1493e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0333 - accuracy: 0.9911 - val_loss: 2.1109e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0329 - accuracy: 0.9911 - val_loss: 1.0280e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0298 - accuracy: 0.9888 - val_loss: 1.6774e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0351 - accuracy: 0.9894 - val_loss: 7.6022e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0327 - accuracy: 0.9897 - val_loss: 2.1810e-04 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "CAnc2SJa3o9f",
        "outputId": "30835544-d4b6-4b89-e4a9-05924cb438d7"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 8ms/step - loss: 0.0408 - accuracy: 0.9903\n",
            "Accuracy  : 0.9903433322906494\n",
            "F1_Score  : 0.9902133057691076\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7fcxLuwZpkK",
        "outputId": "40b6a4ee-870f-4d66-f93b-140929bbebab"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "78a4b8f8-bdd5-40fb-c9dc-ffa2d14622b0"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 52ms/step - loss: 0.9252 - accuracy: 0.4766 - val_loss: 0.8317 - val_accuracy: 0.5188\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8123 - accuracy: 0.5262 - val_loss: 0.8228 - val_accuracy: 0.5188\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.8048 - accuracy: 0.5218 - val_loss: 0.8212 - val_accuracy: 0.5188\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8122 - accuracy: 0.5246 - val_loss: 0.8179 - val_accuracy: 0.5188\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.7894 - accuracy: 0.5316 - val_loss: 0.8161 - val_accuracy: 0.5188\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8119 - accuracy: 0.5122 - val_loss: 0.8227 - val_accuracy: 0.5188\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8124 - accuracy: 0.5225 - val_loss: 0.8196 - val_accuracy: 0.5188\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8082 - accuracy: 0.5105 - val_loss: 0.8157 - val_accuracy: 0.5188\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.7995 - accuracy: 0.5312 - val_loss: 0.8150 - val_accuracy: 0.5188\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7975 - accuracy: 0.5215 - val_loss: 0.8120 - val_accuracy: 0.5268\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7928 - accuracy: 0.5268 - val_loss: 0.8162 - val_accuracy: 0.5188\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7854 - accuracy: 0.5260 - val_loss: 0.8148 - val_accuracy: 0.5188\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7842 - accuracy: 0.5297 - val_loss: 0.8124 - val_accuracy: 0.5188\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7908 - accuracy: 0.5280 - val_loss: 0.8165 - val_accuracy: 0.5188\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7879 - accuracy: 0.5451 - val_loss: 0.8215 - val_accuracy: 0.5188\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7929 - accuracy: 0.5224 - val_loss: 0.8113 - val_accuracy: 0.5456\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7857 - accuracy: 0.5345 - val_loss: 0.8110 - val_accuracy: 0.5188\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7805 - accuracy: 0.5211 - val_loss: 0.8265 - val_accuracy: 0.5188\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7799 - accuracy: 0.5259 - val_loss: 0.8099 - val_accuracy: 0.5188\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7785 - accuracy: 0.5307 - val_loss: 0.8097 - val_accuracy: 0.5335\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7802 - accuracy: 0.5369 - val_loss: 0.8153 - val_accuracy: 0.5375\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7899 - accuracy: 0.5291 - val_loss: 0.8134 - val_accuracy: 0.5214\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7726 - accuracy: 0.5327 - val_loss: 0.8144 - val_accuracy: 0.5402\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7843 - accuracy: 0.5207 - val_loss: 0.8007 - val_accuracy: 0.5188\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.7807 - accuracy: 0.5196 - val_loss: 0.8114 - val_accuracy: 0.5188\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7775 - accuracy: 0.5419 - val_loss: 0.8189 - val_accuracy: 0.5188\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7601 - accuracy: 0.5390 - val_loss: 0.8037 - val_accuracy: 0.5188\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7701 - accuracy: 0.5435 - val_loss: 0.8016 - val_accuracy: 0.5389\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.7685 - accuracy: 0.5447 - val_loss: 0.8172 - val_accuracy: 0.5214\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7620 - accuracy: 0.5346 - val_loss: 0.7991 - val_accuracy: 0.5349\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7709 - accuracy: 0.5331 - val_loss: 0.7583 - val_accuracy: 0.5107\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.7697 - accuracy: 0.5383 - val_loss: 0.7544 - val_accuracy: 0.5134\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.7664 - accuracy: 0.5387 - val_loss: 0.7586 - val_accuracy: 0.5214\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7721 - accuracy: 0.5317 - val_loss: 0.7538 - val_accuracy: 0.5416\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.7659 - accuracy: 0.5455 - val_loss: 0.7544 - val_accuracy: 0.5442\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7613 - accuracy: 0.5356 - val_loss: 0.7586 - val_accuracy: 0.5469\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7605 - accuracy: 0.5426 - val_loss: 0.7556 - val_accuracy: 0.5469\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7565 - accuracy: 0.5468 - val_loss: 0.7554 - val_accuracy: 0.5228\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.7591 - accuracy: 0.5456 - val_loss: 0.7447 - val_accuracy: 0.5402\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7555 - accuracy: 0.5382 - val_loss: 0.7475 - val_accuracy: 0.5349\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7525 - accuracy: 0.5492 - val_loss: 0.7515 - val_accuracy: 0.5268\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7536 - accuracy: 0.5490 - val_loss: 0.7373 - val_accuracy: 0.5523\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7490 - accuracy: 0.5574 - val_loss: 0.7491 - val_accuracy: 0.5349\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7469 - accuracy: 0.5461 - val_loss: 0.7358 - val_accuracy: 0.5456\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7461 - accuracy: 0.5526 - val_loss: 0.7391 - val_accuracy: 0.5402\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7392 - accuracy: 0.5554 - val_loss: 0.7278 - val_accuracy: 0.5550\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7379 - accuracy: 0.5534 - val_loss: 0.7362 - val_accuracy: 0.5429\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7370 - accuracy: 0.5590 - val_loss: 0.7298 - val_accuracy: 0.5523\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7328 - accuracy: 0.5636 - val_loss: 0.7358 - val_accuracy: 0.5509\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7390 - accuracy: 0.5545 - val_loss: 0.7257 - val_accuracy: 0.5777\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7367 - accuracy: 0.5566 - val_loss: 0.7195 - val_accuracy: 0.5576\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.7209 - accuracy: 0.5642 - val_loss: 0.7231 - val_accuracy: 0.5791\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7226 - accuracy: 0.5711 - val_loss: 0.7164 - val_accuracy: 0.5777\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7183 - accuracy: 0.5715 - val_loss: 0.7316 - val_accuracy: 0.5429\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7149 - accuracy: 0.5721 - val_loss: 0.7139 - val_accuracy: 0.5737\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7197 - accuracy: 0.5721 - val_loss: 0.7001 - val_accuracy: 0.5912\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7112 - accuracy: 0.5744 - val_loss: 0.7142 - val_accuracy: 0.5818\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7081 - accuracy: 0.5781 - val_loss: 0.7060 - val_accuracy: 0.5898\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6961 - accuracy: 0.5870 - val_loss: 0.7044 - val_accuracy: 0.5858\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6905 - accuracy: 0.5912 - val_loss: 0.7116 - val_accuracy: 0.5751\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6962 - accuracy: 0.5954 - val_loss: 0.6602 - val_accuracy: 0.6233\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6909 - accuracy: 0.6043 - val_loss: 0.6588 - val_accuracy: 0.6300\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6931 - accuracy: 0.5997 - val_loss: 0.6515 - val_accuracy: 0.6381\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6808 - accuracy: 0.6007 - val_loss: 0.6328 - val_accuracy: 0.6501\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6783 - accuracy: 0.6195 - val_loss: 0.6344 - val_accuracy: 0.6622\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6657 - accuracy: 0.6282 - val_loss: 0.6215 - val_accuracy: 0.6796\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6668 - accuracy: 0.6241 - val_loss: 0.6455 - val_accuracy: 0.6421\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6545 - accuracy: 0.6417 - val_loss: 0.6272 - val_accuracy: 0.6515\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6404 - accuracy: 0.6486 - val_loss: 0.6029 - val_accuracy: 0.6836\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6387 - accuracy: 0.6537 - val_loss: 0.5929 - val_accuracy: 0.7091\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6213 - accuracy: 0.6753 - val_loss: 0.5808 - val_accuracy: 0.7265\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6209 - accuracy: 0.6745 - val_loss: 0.5899 - val_accuracy: 0.6930\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6048 - accuracy: 0.6881 - val_loss: 0.5593 - val_accuracy: 0.7252\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5843 - accuracy: 0.7077 - val_loss: 0.5439 - val_accuracy: 0.7373\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5604 - accuracy: 0.7177 - val_loss: 0.5700 - val_accuracy: 0.7225\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5634 - accuracy: 0.7206 - val_loss: 0.5300 - val_accuracy: 0.7440\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5347 - accuracy: 0.7404 - val_loss: 0.5166 - val_accuracy: 0.7520\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5215 - accuracy: 0.7478 - val_loss: 0.5085 - val_accuracy: 0.7534\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5109 - accuracy: 0.7598 - val_loss: 0.5099 - val_accuracy: 0.7413\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4915 - accuracy: 0.7751 - val_loss: 0.4829 - val_accuracy: 0.7815\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4684 - accuracy: 0.7903 - val_loss: 0.4677 - val_accuracy: 0.7842\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4549 - accuracy: 0.7949 - val_loss: 0.4741 - val_accuracy: 0.7922\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4276 - accuracy: 0.8060 - val_loss: 0.4412 - val_accuracy: 0.7989\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4143 - accuracy: 0.8161 - val_loss: 0.4067 - val_accuracy: 0.8164\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4178 - accuracy: 0.8198 - val_loss: 0.4279 - val_accuracy: 0.7855\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3842 - accuracy: 0.8328 - val_loss: 0.4750 - val_accuracy: 0.7681\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3776 - accuracy: 0.8387 - val_loss: 0.4003 - val_accuracy: 0.8298\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3356 - accuracy: 0.8577 - val_loss: 0.3570 - val_accuracy: 0.8499\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3439 - accuracy: 0.8547 - val_loss: 0.4163 - val_accuracy: 0.8083\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3078 - accuracy: 0.8700 - val_loss: 0.3618 - val_accuracy: 0.8405\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3352 - accuracy: 0.8615 - val_loss: 0.1419 - val_accuracy: 0.9598\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3255 - accuracy: 0.8711 - val_loss: 0.1264 - val_accuracy: 0.9692\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2863 - accuracy: 0.8887 - val_loss: 0.1162 - val_accuracy: 0.9692\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2723 - accuracy: 0.8961 - val_loss: 0.1088 - val_accuracy: 0.9665\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2692 - accuracy: 0.8921 - val_loss: 0.1007 - val_accuracy: 0.9651\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2557 - accuracy: 0.9025 - val_loss: 0.1041 - val_accuracy: 0.9692\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2463 - accuracy: 0.9046 - val_loss: 0.1254 - val_accuracy: 0.9611\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2410 - accuracy: 0.9076 - val_loss: 0.1287 - val_accuracy: 0.9558\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2223 - accuracy: 0.9171 - val_loss: 0.1156 - val_accuracy: 0.9558\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2195 - accuracy: 0.9133 - val_loss: 0.2220 - val_accuracy: 0.9088\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2142 - accuracy: 0.9192 - val_loss: 0.1023 - val_accuracy: 0.9611\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1909 - accuracy: 0.9279 - val_loss: 0.0905 - val_accuracy: 0.9678\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1873 - accuracy: 0.9298 - val_loss: 0.0963 - val_accuracy: 0.9625\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1727 - accuracy: 0.9338 - val_loss: 0.0753 - val_accuracy: 0.9718\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1697 - accuracy: 0.9379 - val_loss: 0.0940 - val_accuracy: 0.9705\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.1773 - accuracy: 0.9329 - val_loss: 0.1043 - val_accuracy: 0.9571\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1696 - accuracy: 0.9389 - val_loss: 0.0726 - val_accuracy: 0.9759\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1568 - accuracy: 0.9428 - val_loss: 0.0663 - val_accuracy: 0.9772\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1639 - accuracy: 0.9393 - val_loss: 0.0844 - val_accuracy: 0.9745\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1526 - accuracy: 0.9440 - val_loss: 0.0698 - val_accuracy: 0.9759\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1446 - accuracy: 0.9474 - val_loss: 0.0690 - val_accuracy: 0.9799\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1297 - accuracy: 0.9538 - val_loss: 0.0661 - val_accuracy: 0.9759\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1357 - accuracy: 0.9519 - val_loss: 0.0721 - val_accuracy: 0.9705\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1173 - accuracy: 0.9581 - val_loss: 0.0771 - val_accuracy: 0.9678\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1259 - accuracy: 0.9572 - val_loss: 0.0670 - val_accuracy: 0.9826\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1157 - accuracy: 0.9590 - val_loss: 0.0588 - val_accuracy: 0.9812\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1110 - accuracy: 0.9626 - val_loss: 0.0747 - val_accuracy: 0.9692\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1116 - accuracy: 0.9593 - val_loss: 0.0461 - val_accuracy: 0.9866\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0982 - accuracy: 0.9665 - val_loss: 0.0729 - val_accuracy: 0.9759\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.1008 - accuracy: 0.9627 - val_loss: 0.0677 - val_accuracy: 0.9732\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1355 - accuracy: 0.9508 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1291 - accuracy: 0.9554 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1229 - accuracy: 0.9548 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1101 - accuracy: 0.9608 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1049 - accuracy: 0.9635 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1038 - accuracy: 0.9653 - val_loss: 0.0207 - val_accuracy: 0.9960\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1021 - accuracy: 0.9639 - val_loss: 0.0063 - val_accuracy: 0.9973\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0817 - accuracy: 0.9715 - val_loss: 0.0145 - val_accuracy: 0.9960\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0928 - accuracy: 0.9683 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0740 - accuracy: 0.9741 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0835 - accuracy: 0.9687 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.0840 - accuracy: 0.9708 - val_loss: 0.0121 - val_accuracy: 0.9946\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0903 - accuracy: 0.9702 - val_loss: 0.0062 - val_accuracy: 0.9960\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1052 - accuracy: 0.9624 - val_loss: 0.0094 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0771 - accuracy: 0.9744 - val_loss: 0.0082 - val_accuracy: 0.9973\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0831 - accuracy: 0.9714 - val_loss: 0.0074 - val_accuracy: 0.9973\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0640 - accuracy: 0.9785 - val_loss: 0.0105 - val_accuracy: 0.9973\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0636 - accuracy: 0.9790 - val_loss: 0.0048 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0745 - accuracy: 0.9748 - val_loss: 0.0141 - val_accuracy: 0.9960\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0762 - accuracy: 0.9727 - val_loss: 0.0099 - val_accuracy: 0.9973\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0805 - accuracy: 0.9708 - val_loss: 0.0089 - val_accuracy: 0.9960\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0747 - accuracy: 0.9751 - val_loss: 0.0128 - val_accuracy: 0.9973\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0653 - accuracy: 0.9779 - val_loss: 0.0133 - val_accuracy: 0.9960\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0716 - accuracy: 0.9760 - val_loss: 0.0084 - val_accuracy: 0.9973\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0628 - accuracy: 0.9784 - val_loss: 0.0054 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0715 - accuracy: 0.9742 - val_loss: 0.0071 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0702 - accuracy: 0.9765 - val_loss: 0.0111 - val_accuracy: 0.9946\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0721 - accuracy: 0.9754 - val_loss: 0.0088 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0675 - accuracy: 0.9784 - val_loss: 0.0098 - val_accuracy: 0.9960\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0584 - accuracy: 0.9779 - val_loss: 0.0090 - val_accuracy: 0.9973\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0742 - accuracy: 0.9766 - val_loss: 8.0247e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0538 - accuracy: 0.9829 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0724 - accuracy: 0.9781 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0725 - accuracy: 0.9760 - val_loss: 0.0042 - val_accuracy: 0.9987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0666 - accuracy: 0.9760 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.0673 - accuracy: 0.9765 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0448 - accuracy: 0.9835 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0672 - accuracy: 0.9788 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0487 - accuracy: 0.9833 - val_loss: 6.9667e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0528 - accuracy: 0.9820 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0579 - accuracy: 0.9797 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0454 - accuracy: 0.9852 - val_loss: 0.0032 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0602 - accuracy: 0.9806 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0593 - accuracy: 0.9796 - val_loss: 0.0022 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0595 - accuracy: 0.9815 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0604 - accuracy: 0.9811 - val_loss: 0.0029 - val_accuracy: 0.9987\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0461 - accuracy: 0.9858 - val_loss: 0.0075 - val_accuracy: 0.9960\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0552 - accuracy: 0.9817 - val_loss: 0.0020 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0526 - accuracy: 0.9827 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0640 - accuracy: 0.9784 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0509 - accuracy: 0.9842 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0516 - accuracy: 0.9827 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0351 - accuracy: 0.9890 - val_loss: 0.0078 - val_accuracy: 0.9960\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0481 - accuracy: 0.9848 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0417 - accuracy: 0.9869 - val_loss: 0.0051 - val_accuracy: 0.9973\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0497 - accuracy: 0.9815 - val_loss: 0.0043 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0499 - accuracy: 0.9849 - val_loss: 0.0085 - val_accuracy: 0.9960\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0581 - accuracy: 0.9832 - val_loss: 0.0074 - val_accuracy: 0.9960\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0620 - accuracy: 0.9796 - val_loss: 0.0268 - val_accuracy: 0.9933\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0476 - accuracy: 0.9839 - val_loss: 0.0033 - val_accuracy: 0.9987\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0563 - accuracy: 0.9826 - val_loss: 4.7070e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0442 - accuracy: 0.9844 - val_loss: 2.7983e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0433 - accuracy: 0.9867 - val_loss: 4.7644e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0544 - accuracy: 0.9805 - val_loss: 3.1831e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0462 - accuracy: 0.9851 - val_loss: 5.4951e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0492 - accuracy: 0.9835 - val_loss: 1.2108e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0395 - accuracy: 0.9861 - val_loss: 0.0029 - val_accuracy: 0.9973\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0575 - accuracy: 0.9821 - val_loss: 3.7769e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0408 - accuracy: 0.9864 - val_loss: 1.2931e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0512 - accuracy: 0.9826 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0513 - accuracy: 0.9830 - val_loss: 0.0017 - val_accuracy: 0.9987\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0454 - accuracy: 0.9863 - val_loss: 5.7391e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0413 - accuracy: 0.9872 - val_loss: 3.4243e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0436 - accuracy: 0.9855 - val_loss: 2.0449e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.0370 - accuracy: 0.9882 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0431 - accuracy: 0.9842 - val_loss: 6.8627e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0464 - accuracy: 0.9848 - val_loss: 4.6952e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0344 - accuracy: 0.9891 - val_loss: 2.8546e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0312 - accuracy: 0.9905 - val_loss: 1.3743e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0361 - accuracy: 0.9873 - val_loss: 5.8603e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0425 - accuracy: 0.9891 - val_loss: 5.5146e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0432 - accuracy: 0.9869 - val_loss: 2.8556e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0333 - accuracy: 0.9900 - val_loss: 2.3221e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0404 - accuracy: 0.9863 - val_loss: 3.9900e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0395 - accuracy: 0.9870 - val_loss: 5.4684e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0446 - accuracy: 0.9867 - val_loss: 6.0847e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0435 - accuracy: 0.9848 - val_loss: 5.8101e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0384 - accuracy: 0.9887 - val_loss: 5.3241e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0388 - accuracy: 0.9888 - val_loss: 0.0030 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0381 - accuracy: 0.9887 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0311 - accuracy: 0.9909 - val_loss: 7.8154e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0356 - accuracy: 0.9906 - val_loss: 1.0346e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0299 - accuracy: 0.9897 - val_loss: 4.0687e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0461 - accuracy: 0.9848 - val_loss: 4.9127e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0421 - accuracy: 0.9867 - val_loss: 7.0029e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0468 - accuracy: 0.9844 - val_loss: 4.5520e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0438 - accuracy: 0.9848 - val_loss: 6.6698e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0457 - accuracy: 0.9873 - val_loss: 2.5061e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0511 - accuracy: 0.9827 - val_loss: 1.4111e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0481 - accuracy: 0.9851 - val_loss: 0.0037 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0442 - accuracy: 0.9852 - val_loss: 3.7041e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0317 - accuracy: 0.9897 - val_loss: 1.2412e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0322 - accuracy: 0.9890 - val_loss: 3.2450e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0469 - accuracy: 0.9855 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0586 - accuracy: 0.9838 - val_loss: 9.2967e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0360 - accuracy: 0.9894 - val_loss: 1.2153e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0369 - accuracy: 0.9882 - val_loss: 1.6064e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0336 - accuracy: 0.9893 - val_loss: 2.2548e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0334 - accuracy: 0.9899 - val_loss: 3.2410e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0292 - accuracy: 0.9912 - val_loss: 9.4820e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0389 - accuracy: 0.9890 - val_loss: 9.0317e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0353 - accuracy: 0.9876 - val_loss: 4.4557e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0239 - accuracy: 0.9917 - val_loss: 9.6292e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0306 - accuracy: 0.9902 - val_loss: 4.4945e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0358 - accuracy: 0.9870 - val_loss: 0.0083 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0450 - accuracy: 0.9848 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0355 - accuracy: 0.9875 - val_loss: 2.3585e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0495 - accuracy: 0.9827 - val_loss: 0.0030 - val_accuracy: 0.9973\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0328 - accuracy: 0.9894 - val_loss: 1.6345e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0235 - accuracy: 0.9920 - val_loss: 1.2710e-04 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0369 - accuracy: 0.9869 - val_loss: 3.7970e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0332 - accuracy: 0.9902 - val_loss: 4.5770e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0361 - accuracy: 0.9887 - val_loss: 1.1635e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0429 - accuracy: 0.9867 - val_loss: 5.8994e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0313 - accuracy: 0.9906 - val_loss: 2.1318e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0446 - accuracy: 0.9890 - val_loss: 8.7263e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0255 - accuracy: 0.9918 - val_loss: 4.8244e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0237 - accuracy: 0.9928 - val_loss: 3.6812e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0337 - accuracy: 0.9897 - val_loss: 2.2856e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0410 - accuracy: 0.9866 - val_loss: 0.0017 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0297 - accuracy: 0.9924 - val_loss: 1.5905e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0310 - accuracy: 0.9906 - val_loss: 0.0032 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0406 - accuracy: 0.9879 - val_loss: 2.8488e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0355 - accuracy: 0.9891 - val_loss: 1.2464e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0200 - accuracy: 0.9933 - val_loss: 5.0672e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0224 - accuracy: 0.9934 - val_loss: 0.0027 - val_accuracy: 0.9973\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0304 - accuracy: 0.9884 - val_loss: 1.3099e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0213 - accuracy: 0.9942 - val_loss: 6.9015e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0283 - accuracy: 0.9914 - val_loss: 4.2365e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0353 - accuracy: 0.9876 - val_loss: 0.0038 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0343 - accuracy: 0.9900 - val_loss: 1.1098e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0260 - accuracy: 0.9925 - val_loss: 1.7225e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0258 - accuracy: 0.9908 - val_loss: 2.1607e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0241 - accuracy: 0.9923 - val_loss: 2.6045e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0427 - accuracy: 0.9872 - val_loss: 2.0116e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0255 - accuracy: 0.9914 - val_loss: 6.4026e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0412 - accuracy: 0.9864 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0307 - accuracy: 0.9899 - val_loss: 2.0540e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0262 - accuracy: 0.9917 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0197 - accuracy: 0.9936 - val_loss: 1.7097e-04 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0309 - accuracy: 0.9908 - val_loss: 4.8320e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0221 - accuracy: 0.9924 - val_loss: 2.6288e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0308 - accuracy: 0.9900 - val_loss: 7.8031e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0350 - accuracy: 0.9890 - val_loss: 4.6656e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0431 - accuracy: 0.9845 - val_loss: 1.0047e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0281 - accuracy: 0.9920 - val_loss: 6.3734e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0289 - accuracy: 0.9911 - val_loss: 1.7953e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0268 - accuracy: 0.9921 - val_loss: 1.7744e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0339 - accuracy: 0.9897 - val_loss: 1.1607e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0345 - accuracy: 0.9893 - val_loss: 7.6273e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0311 - accuracy: 0.9905 - val_loss: 4.4230e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0269 - accuracy: 0.9915 - val_loss: 5.3751e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0252 - accuracy: 0.9924 - val_loss: 3.9477e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0206 - accuracy: 0.9928 - val_loss: 5.3387e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0310 - accuracy: 0.9906 - val_loss: 5.6436e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0271 - accuracy: 0.9920 - val_loss: 1.3935e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0252 - accuracy: 0.9911 - val_loss: 9.4994e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0255 - accuracy: 0.9924 - val_loss: 9.4290e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0297 - accuracy: 0.9912 - val_loss: 3.4282e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 3.1135e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0218 - accuracy: 0.9925 - val_loss: 9.6189e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0271 - accuracy: 0.9914 - val_loss: 4.0661e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0299 - accuracy: 0.9897 - val_loss: 2.7005e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0247 - accuracy: 0.9902 - val_loss: 1.6677e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0277 - accuracy: 0.9915 - val_loss: 0.0016 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0263 - accuracy: 0.9917 - val_loss: 8.5488e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0204 - accuracy: 0.9942 - val_loss: 3.6377e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0281 - accuracy: 0.9909 - val_loss: 2.2651e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0333 - accuracy: 0.9911 - val_loss: 8.9654e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0246 - accuracy: 0.9940 - val_loss: 9.3342e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "d027c2ab-5b3e-4c34-87d7-6c0a36634dc7"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 7ms/step - loss: 0.0883 - accuracy: 0.9775\n",
            "Accuracy  : 0.9774678349494934\n",
            "F1_Score  : 0.9706595631967728\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "11d2f834-0eb4-4b3c-8839-53ce2035e5d1"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'#dominance\\nX_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\\nprint(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "e1cba1d3-5ddb-4051-b881-fa4ac607052d"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'foldNum=0\\nmodel = get_model()\\nfor train_index, val_index in kfold.split(X_train, Y_train):\\n  foldNum = foldNum + 1\\n  print(\"Results for fold\",foldNum)\\n  x_train, x_val = X_train[train_index], X_train[val_index]\\n  y_train, y_val = Y_train[train_index], Y_train[val_index]\\n  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\\n  gc.collect() # Garbage collecter\\n  del x_train, x_val, y_train, y_val\\n  gc.collect()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "47171666-a267-4aba-bf0d-202a71c89651"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'acrc = model.evaluate(x_test, y_test)\\npred = model.predict(x_test)\\nf1scr = f1_score(y_test.argmax(1), pred.argmax(1), average=\\'macro\\')\\nc_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\\nprint(\"Accuracy  : {}\".format(acrc[1]))\\nprint(\"F1_Score  : {}\".format(f1scr))\\nc_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\\nimport seaborn as sns\\nfigure = plt.figure(figsize=(9, 9))\\nsns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\\nplt.tight_layout()\\nplt.ylabel(\\'True label\\')\\nplt.xlabel(\\'Predicted label\\')\\nplt.show()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}