{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub27_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "2fcd6488-cd72-4d54-ae40-2f30bb3f7582"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e3\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  #EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "60716f35-9ca1-4c8a-de9d-ec704a861816"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(27,28):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)\n",
        "print(valence.shape)\n",
        "print(arousal.shape)\n",
        "print(dominance.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.27\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (1165,) (3029,) (5126,)\n",
            "(9320,) (2796,) (2796,) (3728,)\n",
            "(9320,) (0,) (233,) (9087,)\n",
            "(9320, 3)\n",
            "(9320, 3)\n",
            "(9320, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "55c3880f-165b-4010-f0f5-b026324059d7"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "12bfea64-ef32-44d7-cf3a-0a104d57f06d"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "622"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "09558807-76ac-4159-dea5-7a244dda2c30"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5598dc42-cf59-451d-c842-42cbc12b2417"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 50s 65ms/step - loss: 1.0539 - accuracy: 0.4799 - val_loss: 0.9486 - val_accuracy: 0.5603\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9881 - accuracy: 0.5350 - val_loss: 0.9327 - val_accuracy: 0.5603\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9781 - accuracy: 0.5257 - val_loss: 0.9166 - val_accuracy: 0.5724\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9648 - accuracy: 0.5480 - val_loss: 0.9198 - val_accuracy: 0.5710\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9622 - accuracy: 0.5617 - val_loss: 0.9222 - val_accuracy: 0.5697\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9464 - accuracy: 0.5597 - val_loss: 0.9301 - val_accuracy: 0.5737\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9568 - accuracy: 0.5523 - val_loss: 0.9298 - val_accuracy: 0.5710\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9437 - accuracy: 0.5598 - val_loss: 0.9453 - val_accuracy: 0.5710\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9402 - accuracy: 0.5627 - val_loss: 0.9255 - val_accuracy: 0.5737\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9443 - accuracy: 0.5657 - val_loss: 0.9395 - val_accuracy: 0.5737\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9442 - accuracy: 0.5576 - val_loss: 0.9069 - val_accuracy: 0.5724\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9465 - accuracy: 0.5580 - val_loss: 0.9006 - val_accuracy: 0.5777\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9327 - accuracy: 0.5565 - val_loss: 0.9172 - val_accuracy: 0.5751\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9328 - accuracy: 0.5686 - val_loss: 0.9212 - val_accuracy: 0.5764\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9261 - accuracy: 0.5642 - val_loss: 0.8930 - val_accuracy: 0.5777\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9150 - accuracy: 0.5734 - val_loss: 0.9154 - val_accuracy: 0.5697\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9274 - accuracy: 0.5687 - val_loss: 0.8871 - val_accuracy: 0.5818\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9251 - accuracy: 0.5651 - val_loss: 0.8952 - val_accuracy: 0.5764\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9089 - accuracy: 0.5788 - val_loss: 0.8876 - val_accuracy: 0.5764\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9022 - accuracy: 0.5729 - val_loss: 0.8931 - val_accuracy: 0.5724\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9080 - accuracy: 0.5765 - val_loss: 0.8912 - val_accuracy: 0.5697\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9062 - accuracy: 0.5705 - val_loss: 0.8955 - val_accuracy: 0.5751\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9034 - accuracy: 0.5674 - val_loss: 0.9121 - val_accuracy: 0.5764\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8972 - accuracy: 0.5806 - val_loss: 0.8804 - val_accuracy: 0.5751\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8828 - accuracy: 0.5887 - val_loss: 0.8957 - val_accuracy: 0.5777\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8845 - accuracy: 0.5885 - val_loss: 0.9460 - val_accuracy: 0.5764\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8784 - accuracy: 0.5950 - val_loss: 0.8846 - val_accuracy: 0.5764\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8622 - accuracy: 0.5905 - val_loss: 0.8644 - val_accuracy: 0.5791\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8556 - accuracy: 0.6017 - val_loss: 0.8556 - val_accuracy: 0.5845\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8575 - accuracy: 0.6040 - val_loss: 0.8492 - val_accuracy: 0.5965\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8484 - accuracy: 0.6030 - val_loss: 0.9798 - val_accuracy: 0.6005\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8424 - accuracy: 0.6027 - val_loss: 0.8297 - val_accuracy: 0.6086\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8347 - accuracy: 0.6122 - val_loss: 0.8185 - val_accuracy: 0.6260\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8256 - accuracy: 0.6224 - val_loss: 0.8442 - val_accuracy: 0.6086\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8121 - accuracy: 0.6176 - val_loss: 0.7994 - val_accuracy: 0.6099\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8083 - accuracy: 0.6143 - val_loss: 0.7900 - val_accuracy: 0.6166\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7912 - accuracy: 0.6304 - val_loss: 0.8718 - val_accuracy: 0.6019\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.7899 - accuracy: 0.6367 - val_loss: 0.8532 - val_accuracy: 0.6488\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7979 - accuracy: 0.6292 - val_loss: 0.7555 - val_accuracy: 0.6622\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7525 - accuracy: 0.6520 - val_loss: 0.8197 - val_accuracy: 0.6327\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.7281 - accuracy: 0.6757 - val_loss: 0.7722 - val_accuracy: 0.6247\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7106 - accuracy: 0.6863 - val_loss: 0.7007 - val_accuracy: 0.6890\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7163 - accuracy: 0.6793 - val_loss: 0.7794 - val_accuracy: 0.6153\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6880 - accuracy: 0.6963 - val_loss: 0.6838 - val_accuracy: 0.7038\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6603 - accuracy: 0.7128 - val_loss: 0.7352 - val_accuracy: 0.6582\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.6253 - accuracy: 0.7276 - val_loss: 0.8032 - val_accuracy: 0.6327\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6033 - accuracy: 0.7489 - val_loss: 0.7620 - val_accuracy: 0.6676\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5829 - accuracy: 0.7504 - val_loss: 0.9120 - val_accuracy: 0.6461\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.5517 - accuracy: 0.7712 - val_loss: 0.7795 - val_accuracy: 0.6676\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5236 - accuracy: 0.7839 - val_loss: 0.7405 - val_accuracy: 0.6930\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4851 - accuracy: 0.8057 - val_loss: 0.9388 - val_accuracy: 0.6287\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4554 - accuracy: 0.8186 - val_loss: 0.6630 - val_accuracy: 0.6930\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4424 - accuracy: 0.8216 - val_loss: 0.5478 - val_accuracy: 0.7601\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4664 - accuracy: 0.8171 - val_loss: 0.6994 - val_accuracy: 0.6783\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5081 - accuracy: 0.8036 - val_loss: 0.8647 - val_accuracy: 0.7185\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3946 - accuracy: 0.8468 - val_loss: 0.4981 - val_accuracy: 0.8097\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3483 - accuracy: 0.8714 - val_loss: 0.6162 - val_accuracy: 0.7359\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.3500 - accuracy: 0.8650 - val_loss: 0.6949 - val_accuracy: 0.7185\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3157 - accuracy: 0.8805 - val_loss: 0.5221 - val_accuracy: 0.7748\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2999 - accuracy: 0.8884 - val_loss: 0.3355 - val_accuracy: 0.8686\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2979 - accuracy: 0.8940 - val_loss: 0.3102 - val_accuracy: 0.8592\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2727 - accuracy: 0.9003 - val_loss: 0.2544 - val_accuracy: 0.9155\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2535 - accuracy: 0.9092 - val_loss: 0.3192 - val_accuracy: 0.9115\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2632 - accuracy: 0.9061 - val_loss: 0.3024 - val_accuracy: 0.8700\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2530 - accuracy: 0.9113 - val_loss: 0.1402 - val_accuracy: 0.9437\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2256 - accuracy: 0.9197 - val_loss: 0.3246 - val_accuracy: 0.8713\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2679 - accuracy: 0.9030 - val_loss: 0.2306 - val_accuracy: 0.9075\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1914 - accuracy: 0.9337 - val_loss: 0.0960 - val_accuracy: 0.9625\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2272 - accuracy: 0.9212 - val_loss: 0.3205 - val_accuracy: 0.8794\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2209 - accuracy: 0.9224 - val_loss: 0.1660 - val_accuracy: 0.9343\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1901 - accuracy: 0.9340 - val_loss: 0.1887 - val_accuracy: 0.9209\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1562 - accuracy: 0.9449 - val_loss: 0.2334 - val_accuracy: 0.9102\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1850 - accuracy: 0.9353 - val_loss: 0.1487 - val_accuracy: 0.9491\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1748 - accuracy: 0.9386 - val_loss: 0.0668 - val_accuracy: 0.9732\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1463 - accuracy: 0.9510 - val_loss: 0.0635 - val_accuracy: 0.9799\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1276 - accuracy: 0.9566 - val_loss: 0.0923 - val_accuracy: 0.9651\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1298 - accuracy: 0.9572 - val_loss: 0.0990 - val_accuracy: 0.9598\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1073 - accuracy: 0.9621 - val_loss: 0.1333 - val_accuracy: 0.9544\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1250 - accuracy: 0.9569 - val_loss: 0.0941 - val_accuracy: 0.9651\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.1212 - accuracy: 0.9615 - val_loss: 0.1134 - val_accuracy: 0.9611\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1120 - accuracy: 0.9656 - val_loss: 0.0578 - val_accuracy: 0.9786\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1135 - accuracy: 0.9635 - val_loss: 0.0815 - val_accuracy: 0.9678\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1130 - accuracy: 0.9595 - val_loss: 0.1453 - val_accuracy: 0.9504\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1238 - accuracy: 0.9566 - val_loss: 0.2896 - val_accuracy: 0.9155\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0951 - accuracy: 0.9683 - val_loss: 0.1092 - val_accuracy: 0.9558\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1389 - accuracy: 0.9539 - val_loss: 0.0612 - val_accuracy: 0.9826\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0921 - accuracy: 0.9677 - val_loss: 0.1558 - val_accuracy: 0.9397\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0964 - accuracy: 0.9666 - val_loss: 0.2750 - val_accuracy: 0.9008\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0886 - accuracy: 0.9715 - val_loss: 0.1422 - val_accuracy: 0.9598\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0890 - accuracy: 0.9702 - val_loss: 0.0789 - val_accuracy: 0.9705\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0936 - accuracy: 0.9721 - val_loss: 0.0059 - val_accuracy: 0.9987\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0899 - accuracy: 0.9700 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0924 - accuracy: 0.9687 - val_loss: 0.0160 - val_accuracy: 0.9946\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0838 - accuracy: 0.9705 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0973 - accuracy: 0.9653 - val_loss: 0.0173 - val_accuracy: 0.9946\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1493 - accuracy: 0.9487 - val_loss: 0.2840 - val_accuracy: 0.8780\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1092 - accuracy: 0.9604 - val_loss: 0.1501 - val_accuracy: 0.9424\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0751 - accuracy: 0.9720 - val_loss: 0.0469 - val_accuracy: 0.9853\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0728 - accuracy: 0.9772 - val_loss: 0.0570 - val_accuracy: 0.9759\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0907 - accuracy: 0.9702 - val_loss: 0.0195 - val_accuracy: 0.9973\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0761 - accuracy: 0.9748 - val_loss: 0.0078 - val_accuracy: 0.9987\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0662 - accuracy: 0.9763 - val_loss: 0.1288 - val_accuracy: 0.9504\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0799 - accuracy: 0.9730 - val_loss: 0.1385 - val_accuracy: 0.9410\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1208 - accuracy: 0.9590 - val_loss: 0.0840 - val_accuracy: 0.9718\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0781 - accuracy: 0.9760 - val_loss: 0.0272 - val_accuracy: 0.9933\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0687 - accuracy: 0.9785 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0642 - accuracy: 0.9776 - val_loss: 0.0184 - val_accuracy: 0.9920\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0723 - accuracy: 0.9775 - val_loss: 0.1207 - val_accuracy: 0.9424\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0711 - accuracy: 0.9750 - val_loss: 0.0369 - val_accuracy: 0.9893\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0543 - accuracy: 0.9802 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0600 - accuracy: 0.9812 - val_loss: 0.0134 - val_accuracy: 0.9960\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0589 - accuracy: 0.9797 - val_loss: 0.0296 - val_accuracy: 0.9920\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0587 - accuracy: 0.9809 - val_loss: 0.0121 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0573 - accuracy: 0.9815 - val_loss: 0.1437 - val_accuracy: 0.9343\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0630 - accuracy: 0.9779 - val_loss: 0.0385 - val_accuracy: 0.9906\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0874 - accuracy: 0.9705 - val_loss: 0.1433 - val_accuracy: 0.9517\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0660 - accuracy: 0.9770 - val_loss: 0.0946 - val_accuracy: 0.9625\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0528 - accuracy: 0.9846 - val_loss: 0.0301 - val_accuracy: 0.9920\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0459 - accuracy: 0.9851 - val_loss: 0.0099 - val_accuracy: 0.9960\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0446 - accuracy: 0.9864 - val_loss: 0.0496 - val_accuracy: 0.9826\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0821 - accuracy: 0.9714 - val_loss: 0.0418 - val_accuracy: 0.9799\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0622 - accuracy: 0.9762 - val_loss: 0.0295 - val_accuracy: 0.9879\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0510 - accuracy: 0.9838 - val_loss: 0.0152 - val_accuracy: 0.9960\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0556 - accuracy: 0.9826 - val_loss: 0.0064 - val_accuracy: 0.9987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0514 - accuracy: 0.9811 - val_loss: 2.4863e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1422 - accuracy: 0.9592 - val_loss: 0.0218 - val_accuracy: 0.9920\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1593 - accuracy: 0.9501 - val_loss: 0.3158 - val_accuracy: 0.8887\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0533 - accuracy: 0.9839 - val_loss: 0.0542 - val_accuracy: 0.9786\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0516 - accuracy: 0.9829 - val_loss: 0.0740 - val_accuracy: 0.9732\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0486 - accuracy: 0.9852 - val_loss: 0.0699 - val_accuracy: 0.9678\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0502 - accuracy: 0.9849 - val_loss: 0.0296 - val_accuracy: 0.9839\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0399 - accuracy: 0.9882 - val_loss: 0.0075 - val_accuracy: 0.9973\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0367 - accuracy: 0.9882 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0342 - accuracy: 0.9890 - val_loss: 0.0945 - val_accuracy: 0.9718\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0967 - accuracy: 0.9715 - val_loss: 0.1045 - val_accuracy: 0.9517\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0488 - accuracy: 0.9829 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0401 - accuracy: 0.9867 - val_loss: 0.0202 - val_accuracy: 0.9906\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0448 - accuracy: 0.9846 - val_loss: 0.0488 - val_accuracy: 0.9732\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0405 - accuracy: 0.9852 - val_loss: 6.6726e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0386 - accuracy: 0.9875 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0408 - accuracy: 0.9881 - val_loss: 0.0124 - val_accuracy: 0.9973\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0423 - accuracy: 0.9860 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0318 - accuracy: 0.9917 - val_loss: 0.0100 - val_accuracy: 0.9960\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0459 - accuracy: 0.9841 - val_loss: 0.0221 - val_accuracy: 0.9906\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0459 - accuracy: 0.9864 - val_loss: 0.0719 - val_accuracy: 0.9718\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0324 - accuracy: 0.9885 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0369 - accuracy: 0.9875 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0386 - accuracy: 0.9885 - val_loss: 2.8422e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0290 - accuracy: 0.9903 - val_loss: 0.0050 - val_accuracy: 0.9960\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0615 - accuracy: 0.9802 - val_loss: 0.0551 - val_accuracy: 0.9732\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0513 - accuracy: 0.9851 - val_loss: 6.3997e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0569 - accuracy: 0.9806 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0423 - accuracy: 0.9861 - val_loss: 0.0117 - val_accuracy: 0.9946\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0411 - accuracy: 0.9867 - val_loss: 0.0032 - val_accuracy: 0.9987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0617 - accuracy: 0.9802 - val_loss: 0.0137 - val_accuracy: 0.9960\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0341 - accuracy: 0.9906 - val_loss: 0.0351 - val_accuracy: 0.9866\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1257 - accuracy: 0.9571 - val_loss: 0.0369 - val_accuracy: 0.9866\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0564 - accuracy: 0.9811 - val_loss: 0.1433 - val_accuracy: 0.9544\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0351 - accuracy: 0.9887 - val_loss: 0.0094 - val_accuracy: 0.9987\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0337 - accuracy: 0.9896 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0529 - accuracy: 0.9830 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0508 - accuracy: 0.9827 - val_loss: 0.0209 - val_accuracy: 0.9920\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0273 - accuracy: 0.9915 - val_loss: 0.0139 - val_accuracy: 0.9933\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0362 - accuracy: 0.9879 - val_loss: 0.0029 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0446 - accuracy: 0.9841 - val_loss: 0.0176 - val_accuracy: 0.9946\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0372 - accuracy: 0.9888 - val_loss: 0.0254 - val_accuracy: 0.9920\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0379 - accuracy: 0.9858 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0266 - accuracy: 0.9917 - val_loss: 0.0094 - val_accuracy: 0.9960\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0296 - accuracy: 0.9896 - val_loss: 0.0038 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0314 - accuracy: 0.9909 - val_loss: 8.5749e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0302 - accuracy: 0.9908 - val_loss: 1.7612e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0332 - accuracy: 0.9882 - val_loss: 0.0067 - val_accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0450 - accuracy: 0.9861 - val_loss: 0.0157 - val_accuracy: 0.9946\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0322 - accuracy: 0.9899 - val_loss: 0.0085 - val_accuracy: 0.9973\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0526 - accuracy: 0.9827 - val_loss: 0.0064 - val_accuracy: 0.9973\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0485 - accuracy: 0.9841 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0360 - accuracy: 0.9882 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0344 - accuracy: 0.9896 - val_loss: 9.0251e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0301 - accuracy: 0.9912 - val_loss: 5.4271e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0323 - accuracy: 0.9881 - val_loss: 3.7921e-04 - val_accuracy: 1.0000\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 50ms/step - loss: 0.0332 - accuracy: 0.9890 - val_loss: 3.6964e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0272 - accuracy: 0.9921 - val_loss: 0.0081 - val_accuracy: 0.9973\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0487 - accuracy: 0.9838 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0325 - accuracy: 0.9896 - val_loss: 1.9821e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0263 - accuracy: 0.9920 - val_loss: 4.3123e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0456 - accuracy: 0.9860 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0612 - accuracy: 0.9814 - val_loss: 0.0171 - val_accuracy: 0.9933\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0313 - accuracy: 0.9899 - val_loss: 0.0141 - val_accuracy: 0.9973\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0280 - accuracy: 0.9902 - val_loss: 9.0567e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0197 - accuracy: 0.9945 - val_loss: 7.5452e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0331 - accuracy: 0.9890 - val_loss: 2.2270e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0409 - accuracy: 0.9869 - val_loss: 4.6264e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0257 - accuracy: 0.9918 - val_loss: 0.0187 - val_accuracy: 0.9919\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0553 - accuracy: 0.9842 - val_loss: 0.0567 - val_accuracy: 0.9732\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0286 - accuracy: 0.9909 - val_loss: 0.0110 - val_accuracy: 0.9960\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0320 - accuracy: 0.9911 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0347 - accuracy: 0.9885 - val_loss: 0.0541 - val_accuracy: 0.9812\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0370 - accuracy: 0.9893 - val_loss: 0.0055 - val_accuracy: 0.9973\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0305 - accuracy: 0.9899 - val_loss: 4.9843e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0280 - accuracy: 0.9903 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0275 - accuracy: 0.9924 - val_loss: 0.0467 - val_accuracy: 0.9826\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0362 - accuracy: 0.9875 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0290 - accuracy: 0.9920 - val_loss: 0.0088 - val_accuracy: 0.9973\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0280 - accuracy: 0.9914 - val_loss: 3.5260e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0346 - accuracy: 0.9899 - val_loss: 0.0054 - val_accuracy: 0.9973\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0295 - accuracy: 0.9918 - val_loss: 5.1270e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0315 - accuracy: 0.9893 - val_loss: 0.0134 - val_accuracy: 0.9960\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0266 - accuracy: 0.9918 - val_loss: 7.0428e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0296 - accuracy: 0.9896 - val_loss: 0.0358 - val_accuracy: 0.9839\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0323 - accuracy: 0.9900 - val_loss: 2.0688e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0290 - accuracy: 0.9923 - val_loss: 5.1579e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0199 - accuracy: 0.9940 - val_loss: 3.8273e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0249 - accuracy: 0.9927 - val_loss: 1.2172e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0318 - accuracy: 0.9881 - val_loss: 1.0507e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0284 - accuracy: 0.9920 - val_loss: 0.0028 - val_accuracy: 0.9987\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0234 - accuracy: 0.9914 - val_loss: 0.0205 - val_accuracy: 0.9906\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0695 - accuracy: 0.9809 - val_loss: 0.3394 - val_accuracy: 0.9168\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0328 - accuracy: 0.9903 - val_loss: 0.0082 - val_accuracy: 0.9973\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0444 - accuracy: 0.9872 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0253 - accuracy: 0.9915 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0312 - accuracy: 0.9902 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0284 - accuracy: 0.9912 - val_loss: 2.0716e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0266 - accuracy: 0.9909 - val_loss: 7.8854e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0234 - accuracy: 0.9924 - val_loss: 5.4474e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0348 - accuracy: 0.9884 - val_loss: 6.8015e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0175 - accuracy: 0.9931 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0326 - accuracy: 0.9897 - val_loss: 1.5183e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 2.1851e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 9.9459e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0227 - accuracy: 0.9927 - val_loss: 2.1333e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0290 - accuracy: 0.9911 - val_loss: 0.0049 - val_accuracy: 0.9960\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0539 - accuracy: 0.9842 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0329 - accuracy: 0.9908 - val_loss: 1.1275e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0307 - accuracy: 0.9899 - val_loss: 2.9190e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0307 - accuracy: 0.9896 - val_loss: 9.7365e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0256 - accuracy: 0.9903 - val_loss: 1.3683e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0352 - accuracy: 0.9903 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0433 - accuracy: 0.9860 - val_loss: 0.0537 - val_accuracy: 0.9826\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0498 - accuracy: 0.9842 - val_loss: 0.1042 - val_accuracy: 0.9584\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0326 - accuracy: 0.9894 - val_loss: 4.4959e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0205 - accuracy: 0.9934 - val_loss: 2.3815e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0325 - accuracy: 0.9908 - val_loss: 1.1074e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0247 - accuracy: 0.9927 - val_loss: 0.0281 - val_accuracy: 0.9906\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 1.1737e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0194 - accuracy: 0.9939 - val_loss: 1.2155e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0173 - accuracy: 0.9951 - val_loss: 4.0679e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0395 - accuracy: 0.9867 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0273 - accuracy: 0.9911 - val_loss: 3.1303e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0253 - accuracy: 0.9930 - val_loss: 5.7042e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0217 - accuracy: 0.9928 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0155 - accuracy: 0.9945 - val_loss: 4.6594e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0345 - accuracy: 0.9887 - val_loss: 0.0029 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0354 - accuracy: 0.9887 - val_loss: 7.1495e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0170 - accuracy: 0.9945 - val_loss: 1.6458e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0205 - accuracy: 0.9943 - val_loss: 0.0210 - val_accuracy: 0.9906\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0255 - accuracy: 0.9921 - val_loss: 6.5097e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0318 - accuracy: 0.9917 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0244 - accuracy: 0.9911 - val_loss: 6.1153e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0213 - accuracy: 0.9933 - val_loss: 7.5519e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0225 - accuracy: 0.9927 - val_loss: 1.4628e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0485 - accuracy: 0.9857 - val_loss: 3.6654e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0332 - accuracy: 0.9899 - val_loss: 0.0436 - val_accuracy: 0.9866\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0719 - accuracy: 0.9768 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0199 - accuracy: 0.9945 - val_loss: 0.0043 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0286 - accuracy: 0.9918 - val_loss: 0.0075 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0237 - accuracy: 0.9933 - val_loss: 6.6081e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 3.3073e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0159 - accuracy: 0.9952 - val_loss: 2.3619e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0277 - accuracy: 0.9915 - val_loss: 4.6852e-05 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0215 - accuracy: 0.9945 - val_loss: 4.6085e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0223 - accuracy: 0.9921 - val_loss: 9.1371e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0214 - accuracy: 0.9936 - val_loss: 1.4805e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0144 - accuracy: 0.9945 - val_loss: 2.6122e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0209 - accuracy: 0.9940 - val_loss: 1.1857e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0177 - accuracy: 0.9939 - val_loss: 6.2312e-06 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 2.7785e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0305 - accuracy: 0.9914 - val_loss: 4.2416e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0446 - accuracy: 0.9870 - val_loss: 2.0301e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0293 - accuracy: 0.9912 - val_loss: 0.0044 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0368 - accuracy: 0.9881 - val_loss: 1.8020e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 1.1652e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0161 - accuracy: 0.9942 - val_loss: 8.3552e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0418 - accuracy: 0.9863 - val_loss: 6.4301e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0178 - accuracy: 0.9939 - val_loss: 1.9585e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0224 - accuracy: 0.9933 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 8.0581e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0234 - accuracy: 0.9924 - val_loss: 9.9708e-06 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0183 - accuracy: 0.9930 - val_loss: 3.6884e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0290 - accuracy: 0.9914 - val_loss: 0.0050 - val_accuracy: 0.9973\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0256 - accuracy: 0.9917 - val_loss: 1.1740e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0209 - accuracy: 0.9936 - val_loss: 1.1874e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0211 - accuracy: 0.9930 - val_loss: 4.5980e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 2.9086e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0248 - accuracy: 0.9920 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0243 - accuracy: 0.9940 - val_loss: 8.4466e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0188 - accuracy: 0.9936 - val_loss: 0.0033 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0225 - accuracy: 0.9927 - val_loss: 0.0043 - val_accuracy: 0.9973\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0205 - accuracy: 0.9937 - val_loss: 0.0177 - val_accuracy: 0.9919\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0152 - accuracy: 0.9946 - val_loss: 0.0034 - val_accuracy: 0.9987\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "CAnc2SJa3o9f",
        "outputId": "f88ddf22-f0e6-4fae-f6f2-78b39c9b861d"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 9ms/step - loss: 0.1580 - accuracy: 0.9560\n",
            "Accuracy  : 0.9560086131095886\n",
            "F1_Score  : 0.9568706846908458\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7fcxLuwZpkK",
        "outputId": "50f64c3d-9e39-465b-a715-da50a4ba2b22"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "7f5cccc7-9768-456f-d550-5e605ad17ac0"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 52ms/step - loss: 1.1508 - accuracy: 0.3611 - val_loss: 1.0848 - val_accuracy: 0.4008\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0890 - accuracy: 0.3979 - val_loss: 1.0699 - val_accuracy: 0.4169\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0772 - accuracy: 0.4096 - val_loss: 1.0697 - val_accuracy: 0.4142\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0786 - accuracy: 0.4197 - val_loss: 1.0683 - val_accuracy: 0.4169\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0755 - accuracy: 0.4072 - val_loss: 1.0723 - val_accuracy: 0.4169\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0724 - accuracy: 0.4135 - val_loss: 1.0598 - val_accuracy: 0.4196\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0645 - accuracy: 0.4312 - val_loss: 1.0665 - val_accuracy: 0.4088\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0628 - accuracy: 0.4341 - val_loss: 1.0557 - val_accuracy: 0.4370\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0645 - accuracy: 0.4395 - val_loss: 1.0530 - val_accuracy: 0.4464\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0521 - accuracy: 0.4364 - val_loss: 1.0594 - val_accuracy: 0.4276\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0561 - accuracy: 0.4333 - val_loss: 1.0415 - val_accuracy: 0.4611\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0534 - accuracy: 0.4526 - val_loss: 1.0607 - val_accuracy: 0.4249\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0562 - accuracy: 0.4455 - val_loss: 1.0455 - val_accuracy: 0.4303\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0473 - accuracy: 0.4366 - val_loss: 1.0416 - val_accuracy: 0.4330\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 1.0420 - accuracy: 0.4414 - val_loss: 1.0395 - val_accuracy: 0.4504\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0490 - accuracy: 0.4367 - val_loss: 1.0394 - val_accuracy: 0.4517\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0489 - accuracy: 0.4391 - val_loss: 1.0364 - val_accuracy: 0.4571\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0379 - accuracy: 0.4544 - val_loss: 1.0365 - val_accuracy: 0.4558\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0453 - accuracy: 0.4411 - val_loss: 1.0305 - val_accuracy: 0.4678\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0368 - accuracy: 0.4509 - val_loss: 1.0430 - val_accuracy: 0.4531\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 1.0336 - accuracy: 0.4565 - val_loss: 1.0359 - val_accuracy: 0.4383\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0286 - accuracy: 0.4649 - val_loss: 1.0228 - val_accuracy: 0.4718\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0181 - accuracy: 0.4747 - val_loss: 1.0265 - val_accuracy: 0.4558\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.0070 - accuracy: 0.4736 - val_loss: 1.0247 - val_accuracy: 0.4383\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0137 - accuracy: 0.4857 - val_loss: 1.0205 - val_accuracy: 0.4437\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 1.0098 - accuracy: 0.4815 - val_loss: 1.0143 - val_accuracy: 0.4531\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9943 - accuracy: 0.4918 - val_loss: 1.0075 - val_accuracy: 0.4745\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9841 - accuracy: 0.4995 - val_loss: 1.0069 - val_accuracy: 0.4544\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9955 - accuracy: 0.4928 - val_loss: 0.9984 - val_accuracy: 0.4826\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9747 - accuracy: 0.5135 - val_loss: 0.9952 - val_accuracy: 0.4893\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9708 - accuracy: 0.5124 - val_loss: 1.0288 - val_accuracy: 0.4705\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9742 - accuracy: 0.5134 - val_loss: 0.9532 - val_accuracy: 0.5040\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9585 - accuracy: 0.5122 - val_loss: 1.0456 - val_accuracy: 0.4651\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9520 - accuracy: 0.5215 - val_loss: 0.9437 - val_accuracy: 0.5268\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9406 - accuracy: 0.5335 - val_loss: 0.9364 - val_accuracy: 0.5322\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9340 - accuracy: 0.5364 - val_loss: 0.9756 - val_accuracy: 0.5282\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9214 - accuracy: 0.5477 - val_loss: 0.9511 - val_accuracy: 0.5362\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9089 - accuracy: 0.5516 - val_loss: 0.9365 - val_accuracy: 0.5188\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.9108 - accuracy: 0.5595 - val_loss: 0.9895 - val_accuracy: 0.5000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8751 - accuracy: 0.5663 - val_loss: 1.0061 - val_accuracy: 0.5054\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8697 - accuracy: 0.5775 - val_loss: 0.8698 - val_accuracy: 0.5764\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8480 - accuracy: 0.5958 - val_loss: 1.2044 - val_accuracy: 0.4973\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8482 - accuracy: 0.5882 - val_loss: 1.0355 - val_accuracy: 0.5174\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8262 - accuracy: 0.6083 - val_loss: 0.9149 - val_accuracy: 0.5737\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8064 - accuracy: 0.6192 - val_loss: 0.9235 - val_accuracy: 0.5818\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7704 - accuracy: 0.6370 - val_loss: 0.8721 - val_accuracy: 0.5630\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7692 - accuracy: 0.6450 - val_loss: 0.9649 - val_accuracy: 0.5590\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7519 - accuracy: 0.6569 - val_loss: 0.8626 - val_accuracy: 0.5845\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7095 - accuracy: 0.6741 - val_loss: 0.8462 - val_accuracy: 0.6153\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6963 - accuracy: 0.6790 - val_loss: 0.7895 - val_accuracy: 0.6461\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.7243 - accuracy: 0.6699 - val_loss: 1.0725 - val_accuracy: 0.5576\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6555 - accuracy: 0.7100 - val_loss: 0.8315 - val_accuracy: 0.6300\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.6608 - accuracy: 0.7027 - val_loss: 0.8676 - val_accuracy: 0.5777\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.6116 - accuracy: 0.7361 - val_loss: 0.9914 - val_accuracy: 0.6019\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5916 - accuracy: 0.7416 - val_loss: 0.8569 - val_accuracy: 0.5965\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5673 - accuracy: 0.7513 - val_loss: 0.7325 - val_accuracy: 0.6622\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5672 - accuracy: 0.7526 - val_loss: 0.9287 - val_accuracy: 0.5670\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5105 - accuracy: 0.7870 - val_loss: 0.7376 - val_accuracy: 0.6930\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.5007 - accuracy: 0.7897 - val_loss: 0.7553 - val_accuracy: 0.6461\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4776 - accuracy: 0.8009 - val_loss: 0.6911 - val_accuracy: 0.7038\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.5026 - accuracy: 0.7927 - val_loss: 0.7162 - val_accuracy: 0.6729\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.4594 - accuracy: 0.8115 - val_loss: 0.4501 - val_accuracy: 0.7560\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5015 - accuracy: 0.7963 - val_loss: 0.4505 - val_accuracy: 0.7976\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4332 - accuracy: 0.8240 - val_loss: 0.3127 - val_accuracy: 0.8713\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.3916 - accuracy: 0.8429 - val_loss: 0.7033 - val_accuracy: 0.7292\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3698 - accuracy: 0.8551 - val_loss: 0.6794 - val_accuracy: 0.7091\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3261 - accuracy: 0.8742 - val_loss: 0.6965 - val_accuracy: 0.6863\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3626 - accuracy: 0.8542 - val_loss: 1.0692 - val_accuracy: 0.6287\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3021 - accuracy: 0.8867 - val_loss: 0.1974 - val_accuracy: 0.9182\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2929 - accuracy: 0.8870 - val_loss: 0.3427 - val_accuracy: 0.8231\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2630 - accuracy: 0.9004 - val_loss: 0.2632 - val_accuracy: 0.8633\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2902 - accuracy: 0.8943 - val_loss: 0.4645 - val_accuracy: 0.8043\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2701 - accuracy: 0.9027 - val_loss: 0.4720 - val_accuracy: 0.7775\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2377 - accuracy: 0.9122 - val_loss: 0.2639 - val_accuracy: 0.8941\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2177 - accuracy: 0.9173 - val_loss: 0.1393 - val_accuracy: 0.9504\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2009 - accuracy: 0.9285 - val_loss: 0.1328 - val_accuracy: 0.9558\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.2218 - accuracy: 0.9252 - val_loss: 0.2804 - val_accuracy: 0.8874\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2118 - accuracy: 0.9243 - val_loss: 0.2965 - val_accuracy: 0.8700\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1795 - accuracy: 0.9387 - val_loss: 0.1058 - val_accuracy: 0.9611\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1615 - accuracy: 0.9408 - val_loss: 0.2866 - val_accuracy: 0.8820\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1772 - accuracy: 0.9398 - val_loss: 0.3771 - val_accuracy: 0.8619\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1804 - accuracy: 0.9367 - val_loss: 0.5325 - val_accuracy: 0.7989\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1812 - accuracy: 0.9392 - val_loss: 0.2003 - val_accuracy: 0.9236\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1542 - accuracy: 0.9463 - val_loss: 0.5004 - val_accuracy: 0.8097\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1599 - accuracy: 0.9446 - val_loss: 0.2415 - val_accuracy: 0.8981\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1285 - accuracy: 0.9560 - val_loss: 0.3978 - val_accuracy: 0.8298\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1270 - accuracy: 0.9562 - val_loss: 0.1175 - val_accuracy: 0.9517\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1342 - accuracy: 0.9556 - val_loss: 0.2244 - val_accuracy: 0.9008\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1127 - accuracy: 0.9611 - val_loss: 0.1830 - val_accuracy: 0.9249\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1147 - accuracy: 0.9607 - val_loss: 0.2246 - val_accuracy: 0.9182\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1520 - accuracy: 0.9498 - val_loss: 0.0975 - val_accuracy: 0.9558\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1163 - accuracy: 0.9596 - val_loss: 0.0213 - val_accuracy: 0.9933\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1650 - accuracy: 0.9429 - val_loss: 0.2272 - val_accuracy: 0.8834\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1414 - accuracy: 0.9548 - val_loss: 0.0203 - val_accuracy: 0.9933\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1006 - accuracy: 0.9681 - val_loss: 0.0425 - val_accuracy: 0.9853\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0954 - accuracy: 0.9666 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0862 - accuracy: 0.9705 - val_loss: 0.0248 - val_accuracy: 0.9933\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0964 - accuracy: 0.9693 - val_loss: 0.0236 - val_accuracy: 0.9933\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1034 - accuracy: 0.9642 - val_loss: 0.2126 - val_accuracy: 0.9129\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1034 - accuracy: 0.9654 - val_loss: 0.0411 - val_accuracy: 0.9866\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1003 - accuracy: 0.9665 - val_loss: 0.0725 - val_accuracy: 0.9651\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1167 - accuracy: 0.9605 - val_loss: 0.1072 - val_accuracy: 0.9611\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0982 - accuracy: 0.9662 - val_loss: 0.0292 - val_accuracy: 0.9920\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0866 - accuracy: 0.9724 - val_loss: 0.0266 - val_accuracy: 0.9933\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1069 - accuracy: 0.9633 - val_loss: 0.0589 - val_accuracy: 0.9732\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0786 - accuracy: 0.9730 - val_loss: 0.0333 - val_accuracy: 0.9853\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0898 - accuracy: 0.9706 - val_loss: 0.0093 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0952 - accuracy: 0.9684 - val_loss: 0.0148 - val_accuracy: 0.9973\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0847 - accuracy: 0.9709 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0920 - accuracy: 0.9694 - val_loss: 0.1109 - val_accuracy: 0.9584\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1211 - accuracy: 0.9623 - val_loss: 0.1054 - val_accuracy: 0.9571\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0887 - accuracy: 0.9715 - val_loss: 0.1635 - val_accuracy: 0.9223\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0638 - accuracy: 0.9782 - val_loss: 0.0660 - val_accuracy: 0.9705\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0844 - accuracy: 0.9720 - val_loss: 0.0235 - val_accuracy: 0.9920\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0819 - accuracy: 0.9717 - val_loss: 0.0234 - val_accuracy: 0.9920\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0747 - accuracy: 0.9745 - val_loss: 0.0219 - val_accuracy: 0.9946\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0651 - accuracy: 0.9794 - val_loss: 0.1709 - val_accuracy: 0.9236\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0757 - accuracy: 0.9738 - val_loss: 0.0714 - val_accuracy: 0.9678\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0983 - accuracy: 0.9668 - val_loss: 0.0559 - val_accuracy: 0.9812\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0558 - accuracy: 0.9812 - val_loss: 0.0758 - val_accuracy: 0.9732\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.1056 - accuracy: 0.9663 - val_loss: 0.0142 - val_accuracy: 0.9987\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0789 - accuracy: 0.9730 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0751 - accuracy: 0.9776 - val_loss: 0.0150 - val_accuracy: 0.9960\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.1022 - accuracy: 0.9644 - val_loss: 0.0572 - val_accuracy: 0.9786\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0750 - accuracy: 0.9785 - val_loss: 0.1346 - val_accuracy: 0.9290\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0812 - accuracy: 0.9763 - val_loss: 0.0721 - val_accuracy: 0.9732\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0645 - accuracy: 0.9797 - val_loss: 0.0440 - val_accuracy: 0.9839\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0514 - accuracy: 0.9841 - val_loss: 0.0465 - val_accuracy: 0.9839\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0568 - accuracy: 0.9823 - val_loss: 0.0337 - val_accuracy: 0.9879\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0703 - accuracy: 0.9766 - val_loss: 0.1601 - val_accuracy: 0.9303\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0611 - accuracy: 0.9784 - val_loss: 0.0882 - val_accuracy: 0.9598\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0883 - accuracy: 0.9696 - val_loss: 0.0232 - val_accuracy: 0.9906\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0621 - accuracy: 0.9787 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0517 - accuracy: 0.9839 - val_loss: 0.0238 - val_accuracy: 0.9893\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0599 - accuracy: 0.9808 - val_loss: 0.1747 - val_accuracy: 0.9330\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0406 - accuracy: 0.9867 - val_loss: 0.1352 - val_accuracy: 0.9464\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0470 - accuracy: 0.9846 - val_loss: 0.0050 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0573 - accuracy: 0.9805 - val_loss: 0.0256 - val_accuracy: 0.9933\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0609 - accuracy: 0.9808 - val_loss: 0.0173 - val_accuracy: 0.9946\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.0535 - accuracy: 0.9806 - val_loss: 0.0168 - val_accuracy: 0.9960\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 49ms/step - loss: 0.0761 - accuracy: 0.9769 - val_loss: 0.1087 - val_accuracy: 0.9517\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0683 - accuracy: 0.9794 - val_loss: 0.2158 - val_accuracy: 0.9142\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0754 - accuracy: 0.9753 - val_loss: 0.1346 - val_accuracy: 0.9477\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0531 - accuracy: 0.9835 - val_loss: 0.2295 - val_accuracy: 0.9142\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0543 - accuracy: 0.9832 - val_loss: 0.0271 - val_accuracy: 0.9906\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0516 - accuracy: 0.9846 - val_loss: 0.0593 - val_accuracy: 0.9718\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0437 - accuracy: 0.9849 - val_loss: 0.0083 - val_accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0407 - accuracy: 0.9867 - val_loss: 0.0379 - val_accuracy: 0.9853\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0534 - accuracy: 0.9839 - val_loss: 0.0132 - val_accuracy: 0.9933\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0766 - accuracy: 0.9756 - val_loss: 0.0074 - val_accuracy: 0.9973\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0569 - accuracy: 0.9812 - val_loss: 0.0034 - val_accuracy: 0.9987\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0553 - accuracy: 0.9814 - val_loss: 0.0172 - val_accuracy: 0.9933\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0529 - accuracy: 0.9849 - val_loss: 6.9358e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0538 - accuracy: 0.9823 - val_loss: 0.0058 - val_accuracy: 0.9987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0742 - accuracy: 0.9742 - val_loss: 0.0308 - val_accuracy: 0.9866\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0548 - accuracy: 0.9838 - val_loss: 0.0284 - val_accuracy: 0.9906\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0613 - accuracy: 0.9791 - val_loss: 0.0719 - val_accuracy: 0.9665\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0592 - accuracy: 0.9811 - val_loss: 0.0433 - val_accuracy: 0.9799\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0563 - accuracy: 0.9826 - val_loss: 0.0160 - val_accuracy: 0.9933\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0505 - accuracy: 0.9839 - val_loss: 0.0151 - val_accuracy: 0.9973\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0411 - accuracy: 0.9870 - val_loss: 0.0902 - val_accuracy: 0.9625\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0534 - accuracy: 0.9829 - val_loss: 0.0052 - val_accuracy: 0.9973\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0450 - accuracy: 0.9854 - val_loss: 0.0096 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0449 - accuracy: 0.9855 - val_loss: 0.0330 - val_accuracy: 0.9879\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0435 - accuracy: 0.9849 - val_loss: 0.0040 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0622 - accuracy: 0.9796 - val_loss: 0.2808 - val_accuracy: 0.9102\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0432 - accuracy: 0.9858 - val_loss: 0.1263 - val_accuracy: 0.9504\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0623 - accuracy: 0.9796 - val_loss: 0.0293 - val_accuracy: 0.9879\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0537 - accuracy: 0.9820 - val_loss: 0.0271 - val_accuracy: 0.9893\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0378 - accuracy: 0.9878 - val_loss: 0.0580 - val_accuracy: 0.9705\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0441 - accuracy: 0.9851 - val_loss: 0.0472 - val_accuracy: 0.9759\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0660 - accuracy: 0.9796 - val_loss: 0.0225 - val_accuracy: 0.9920\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0604 - accuracy: 0.9794 - val_loss: 0.1429 - val_accuracy: 0.9397\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0369 - accuracy: 0.9887 - val_loss: 0.1568 - val_accuracy: 0.9290\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0354 - accuracy: 0.9900 - val_loss: 0.0304 - val_accuracy: 0.9866\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0368 - accuracy: 0.9888 - val_loss: 0.0968 - val_accuracy: 0.9598\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0434 - accuracy: 0.9846 - val_loss: 0.0146 - val_accuracy: 0.9946\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0301 - accuracy: 0.9906 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0438 - accuracy: 0.9860 - val_loss: 0.1082 - val_accuracy: 0.9558\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0409 - accuracy: 0.9857 - val_loss: 0.0053 - val_accuracy: 0.9973\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0359 - accuracy: 0.9878 - val_loss: 0.0144 - val_accuracy: 0.9946\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0997 - accuracy: 0.9705 - val_loss: 0.1079 - val_accuracy: 0.9503\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0526 - accuracy: 0.9826 - val_loss: 0.0064 - val_accuracy: 0.9987\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0402 - accuracy: 0.9870 - val_loss: 0.0182 - val_accuracy: 0.9919\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0416 - accuracy: 0.9875 - val_loss: 0.0045 - val_accuracy: 0.9973\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0526 - accuracy: 0.9830 - val_loss: 0.0121 - val_accuracy: 0.9973\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0505 - accuracy: 0.9838 - val_loss: 6.0274e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0382 - accuracy: 0.9881 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0370 - accuracy: 0.9872 - val_loss: 0.0132 - val_accuracy: 0.9960\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0385 - accuracy: 0.9873 - val_loss: 3.8007e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0352 - accuracy: 0.9890 - val_loss: 2.1450e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0489 - accuracy: 0.9847 - val_loss: 0.0097 - val_accuracy: 0.9973\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0415 - accuracy: 0.9869 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0337 - accuracy: 0.9902 - val_loss: 0.0111 - val_accuracy: 0.9973\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0518 - accuracy: 0.9845 - val_loss: 0.0112 - val_accuracy: 0.9960\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0387 - accuracy: 0.9890 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0316 - accuracy: 0.9893 - val_loss: 6.5416e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0357 - accuracy: 0.9888 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0336 - accuracy: 0.9887 - val_loss: 0.0077 - val_accuracy: 0.9973\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0292 - accuracy: 0.9900 - val_loss: 0.0311 - val_accuracy: 0.9879\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0658 - accuracy: 0.9784 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0553 - accuracy: 0.9826 - val_loss: 1.9574e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0307 - accuracy: 0.9900 - val_loss: 0.1483 - val_accuracy: 0.9503\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0417 - accuracy: 0.9867 - val_loss: 0.0097 - val_accuracy: 0.9973\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0915 - accuracy: 0.9738 - val_loss: 0.0602 - val_accuracy: 0.9758\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0293 - accuracy: 0.9905 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0336 - accuracy: 0.9891 - val_loss: 0.0045 - val_accuracy: 0.9973\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0272 - accuracy: 0.9912 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0469 - accuracy: 0.9852 - val_loss: 0.0116 - val_accuracy: 0.9946\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0327 - accuracy: 0.9879 - val_loss: 0.0285 - val_accuracy: 0.9906\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0293 - accuracy: 0.9912 - val_loss: 0.0057 - val_accuracy: 0.9973\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0267 - accuracy: 0.9923 - val_loss: 2.2443e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0298 - accuracy: 0.9914 - val_loss: 9.0566e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0304 - accuracy: 0.9900 - val_loss: 3.9200e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0253 - accuracy: 0.9921 - val_loss: 0.1428 - val_accuracy: 0.9450\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0461 - accuracy: 0.9847 - val_loss: 0.0029 - val_accuracy: 0.9987\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0269 - accuracy: 0.9921 - val_loss: 2.0875e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0284 - accuracy: 0.9909 - val_loss: 1.2430e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0374 - accuracy: 0.9885 - val_loss: 7.9050e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0415 - accuracy: 0.9879 - val_loss: 0.0100 - val_accuracy: 0.9973\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0286 - accuracy: 0.9903 - val_loss: 6.3677e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0284 - accuracy: 0.9903 - val_loss: 4.5312e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0321 - accuracy: 0.9893 - val_loss: 0.0095 - val_accuracy: 0.9973\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0420 - accuracy: 0.9873 - val_loss: 0.0086 - val_accuracy: 0.9973\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0406 - accuracy: 0.9869 - val_loss: 4.3430e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0350 - accuracy: 0.9879 - val_loss: 8.0887e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0374 - accuracy: 0.9887 - val_loss: 0.0072 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0318 - accuracy: 0.9905 - val_loss: 4.1791e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0342 - accuracy: 0.9897 - val_loss: 0.1430 - val_accuracy: 0.9490\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0309 - accuracy: 0.9890 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0312 - accuracy: 0.9899 - val_loss: 0.0019 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0247 - accuracy: 0.9928 - val_loss: 5.2774e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0228 - accuracy: 0.9933 - val_loss: 0.0110 - val_accuracy: 0.9960\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0276 - accuracy: 0.9917 - val_loss: 0.0027 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0299 - accuracy: 0.9923 - val_loss: 5.9076e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0346 - accuracy: 0.9888 - val_loss: 0.0013 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0336 - accuracy: 0.9899 - val_loss: 5.5616e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0231 - accuracy: 0.9928 - val_loss: 8.2958e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0357 - accuracy: 0.9888 - val_loss: 0.0162 - val_accuracy: 0.9960\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0540 - accuracy: 0.9839 - val_loss: 0.0066 - val_accuracy: 0.9987\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0402 - accuracy: 0.9873 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0378 - accuracy: 0.9860 - val_loss: 2.6023e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0343 - accuracy: 0.9899 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0405 - accuracy: 0.9861 - val_loss: 0.0269 - val_accuracy: 0.9919\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0231 - accuracy: 0.9927 - val_loss: 7.6953e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0435 - accuracy: 0.9860 - val_loss: 4.9962e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0299 - accuracy: 0.9906 - val_loss: 0.0013 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0264 - accuracy: 0.9914 - val_loss: 4.5179e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0245 - accuracy: 0.9925 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0359 - accuracy: 0.9863 - val_loss: 4.4931e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0488 - accuracy: 0.9863 - val_loss: 0.0227 - val_accuracy: 0.9933\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0257 - accuracy: 0.9912 - val_loss: 3.5621e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0322 - accuracy: 0.9906 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0313 - accuracy: 0.9897 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0351 - accuracy: 0.9894 - val_loss: 0.0110 - val_accuracy: 0.9960\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0403 - accuracy: 0.9872 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0332 - accuracy: 0.9884 - val_loss: 0.0206 - val_accuracy: 0.9933\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0234 - accuracy: 0.9928 - val_loss: 0.0031 - val_accuracy: 0.9973\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0235 - accuracy: 0.9930 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0420 - accuracy: 0.9864 - val_loss: 0.0034 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0317 - accuracy: 0.9897 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0286 - accuracy: 0.9902 - val_loss: 0.0089 - val_accuracy: 0.9946\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0214 - accuracy: 0.9931 - val_loss: 2.3492e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0308 - accuracy: 0.9903 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0269 - accuracy: 0.9921 - val_loss: 0.0171 - val_accuracy: 0.9933\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0284 - accuracy: 0.9900 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0259 - accuracy: 0.9912 - val_loss: 0.0118 - val_accuracy: 0.9933\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0346 - accuracy: 0.9890 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0338 - accuracy: 0.9890 - val_loss: 1.0131e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0270 - accuracy: 0.9920 - val_loss: 0.0061 - val_accuracy: 0.9973\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0825 - accuracy: 0.9781 - val_loss: 7.9695e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0810 - accuracy: 0.9778 - val_loss: 0.0223 - val_accuracy: 0.9933\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0275 - accuracy: 0.9930 - val_loss: 0.0227 - val_accuracy: 0.9893\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 0.0278 - val_accuracy: 0.9852\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0173 - accuracy: 0.9951 - val_loss: 4.6757e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0363 - accuracy: 0.9897 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0324 - accuracy: 0.9888 - val_loss: 3.0778e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0197 - accuracy: 0.9936 - val_loss: 8.2222e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0293 - accuracy: 0.9911 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0275 - accuracy: 0.9917 - val_loss: 9.4829e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0194 - accuracy: 0.9939 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0257 - accuracy: 0.9911 - val_loss: 5.1538e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0616 - accuracy: 0.9835 - val_loss: 0.0033 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0777 - accuracy: 0.9771 - val_loss: 5.9329e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0324 - accuracy: 0.9891 - val_loss: 6.6654e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0262 - accuracy: 0.9930 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0256 - accuracy: 0.9915 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0150 - accuracy: 0.9948 - val_loss: 1.4313e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0179 - accuracy: 0.9952 - val_loss: 6.9298e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0243 - accuracy: 0.9934 - val_loss: 0.0657 - val_accuracy: 0.9785\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0203 - accuracy: 0.9940 - val_loss: 0.0325 - val_accuracy: 0.9879\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0223 - accuracy: 0.9927 - val_loss: 0.0697 - val_accuracy: 0.9785\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0266 - accuracy: 0.9915 - val_loss: 7.6093e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0314 - accuracy: 0.9899 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0355 - accuracy: 0.9893 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0245 - accuracy: 0.9930 - val_loss: 0.0025 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0176 - accuracy: 0.9952 - val_loss: 2.9378e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0183 - accuracy: 0.9939 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 0.0040 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0253 - accuracy: 0.9908 - val_loss: 0.0113 - val_accuracy: 0.9906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "14ea1326-8b1b-4c29-d1a8-264ae9a7dbb9"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1209 - accuracy: 0.9651\n",
            "Accuracy  : 0.9651287794113159\n",
            "F1_Score  : 0.9653652698578518\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "695c43c0-e60f-4f69-a398-552336a10f19"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'#dominance\\nX_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\\nprint(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "4cefaccb-4df7-48fb-bf82-20ff93aed008"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'foldNum=0\\nmodel = get_model()\\nfor train_index, val_index in kfold.split(X_train, Y_train):\\n  foldNum = foldNum + 1\\n  print(\"Results for fold\",foldNum)\\n  x_train, x_val = X_train[train_index], X_train[val_index]\\n  y_train, y_val = Y_train[train_index], Y_train[val_index]\\n  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\\n  gc.collect() # Garbage collecter\\n  del x_train, x_val, y_train, y_val\\n  gc.collect()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "ec31153d-6405-478c-e5eb-07ef299b0ef3"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'acrc = model.evaluate(x_test, y_test)\\npred = model.predict(x_test)\\nf1scr = f1_score(y_test.argmax(1), pred.argmax(1), average=\\'macro\\')\\nc_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\\nprint(\"Accuracy  : {}\".format(acrc[1]))\\nprint(\"F1_Score  : {}\".format(f1scr))\\nc_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\\nimport seaborn as sns\\nfigure = plt.figure(figsize=(9, 9))\\nsns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\\nplt.tight_layout()\\nplt.ylabel(\\'True label\\')\\nplt.xlabel(\\'Predicted label\\')\\nplt.show()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}