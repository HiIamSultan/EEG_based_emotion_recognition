{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub5_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "367ba459-45ac-4bfd-aad2-69b5d44c4b3f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e3\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  #EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "2410e84f-ad1b-4b3e-c3e8-6ec81e0ced0f"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(5,6):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.5\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (2097,) (2563,) (4660,)\n",
            "(9320,) (2097,) (3728,) (3495,)\n",
            "(9320,) (3961,) (1864,) (3495,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "d6d00dfb-3c86-4f7e-9454-c7adc36d73c9"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "14db2390-be9c-425a-8697-742c972c974b"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "34994404-f459-4880-d339-43a4c037c8f5"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2002f1d0-4c19-49e3-da9d-3a5facfb09e6"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 50s 72ms/step - loss: 1.1495 - accuracy: 0.4464 - val_loss: 1.0412 - val_accuracy: 0.5013\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0516 - accuracy: 0.5027 - val_loss: 1.0368 - val_accuracy: 0.5013\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0401 - accuracy: 0.5102 - val_loss: 1.0323 - val_accuracy: 0.5013\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0491 - accuracy: 0.4906 - val_loss: 1.0342 - val_accuracy: 0.5013\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0447 - accuracy: 0.5025 - val_loss: 1.0339 - val_accuracy: 0.5013\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0345 - accuracy: 0.5058 - val_loss: 1.0320 - val_accuracy: 0.5013\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 1.0349 - accuracy: 0.5021 - val_loss: 1.0367 - val_accuracy: 0.5013\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0389 - accuracy: 0.5055 - val_loss: 1.0295 - val_accuracy: 0.5013\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 1.0339 - accuracy: 0.5025 - val_loss: 1.0291 - val_accuracy: 0.5013\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0279 - accuracy: 0.5030 - val_loss: 1.0289 - val_accuracy: 0.5013\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0272 - accuracy: 0.5078 - val_loss: 1.0303 - val_accuracy: 0.5013\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0299 - accuracy: 0.5013 - val_loss: 1.0364 - val_accuracy: 0.5013\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0298 - accuracy: 0.4997 - val_loss: 1.0293 - val_accuracy: 0.5013\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0294 - accuracy: 0.5038 - val_loss: 1.0334 - val_accuracy: 0.5013\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 1.0276 - accuracy: 0.5061 - val_loss: 1.0289 - val_accuracy: 0.5027\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0208 - accuracy: 0.5109 - val_loss: 1.0263 - val_accuracy: 0.5027\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 1.0217 - accuracy: 0.5162 - val_loss: 1.0243 - val_accuracy: 0.5027\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0329 - accuracy: 0.4965 - val_loss: 1.0382 - val_accuracy: 0.5040\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0259 - accuracy: 0.5040 - val_loss: 1.0287 - val_accuracy: 0.5040\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0244 - accuracy: 0.5039 - val_loss: 1.0238 - val_accuracy: 0.5040\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0268 - accuracy: 0.5012 - val_loss: 1.0198 - val_accuracy: 0.5054\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0236 - accuracy: 0.4993 - val_loss: 1.0227 - val_accuracy: 0.5040\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 1.0189 - accuracy: 0.5065 - val_loss: 1.0201 - val_accuracy: 0.5040\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 1.0185 - accuracy: 0.5017 - val_loss: 1.0174 - val_accuracy: 0.5054\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0101 - accuracy: 0.5141 - val_loss: 1.0282 - val_accuracy: 0.5080\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0209 - accuracy: 0.5053 - val_loss: 1.0314 - val_accuracy: 0.5027\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0227 - accuracy: 0.4972 - val_loss: 1.0161 - val_accuracy: 0.5067\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0116 - accuracy: 0.5086 - val_loss: 1.0150 - val_accuracy: 0.5067\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0180 - accuracy: 0.5021 - val_loss: 1.0165 - val_accuracy: 0.5054\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0194 - accuracy: 0.5048 - val_loss: 1.0239 - val_accuracy: 0.5040\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 1.0176 - accuracy: 0.5054 - val_loss: 1.0121 - val_accuracy: 0.5067\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0187 - accuracy: 0.5051 - val_loss: 1.0099 - val_accuracy: 0.5067\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 1.0172 - accuracy: 0.5046 - val_loss: 1.0049 - val_accuracy: 0.5054\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0168 - accuracy: 0.5057 - val_loss: 1.0023 - val_accuracy: 0.5054\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0167 - accuracy: 0.5055 - val_loss: 1.0010 - val_accuracy: 0.5080\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0150 - accuracy: 0.5055 - val_loss: 1.0125 - val_accuracy: 0.5067\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 1.0177 - accuracy: 0.5054 - val_loss: 1.0235 - val_accuracy: 0.5067\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0178 - accuracy: 0.5049 - val_loss: 1.0015 - val_accuracy: 0.5067\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 1.0124 - accuracy: 0.5064 - val_loss: 1.0048 - val_accuracy: 0.5080\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0108 - accuracy: 0.5064 - val_loss: 1.0185 - val_accuracy: 0.5080\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0115 - accuracy: 0.5058 - val_loss: 1.0032 - val_accuracy: 0.5094\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0080 - accuracy: 0.5061 - val_loss: 0.9983 - val_accuracy: 0.5067\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0104 - accuracy: 0.5049 - val_loss: 1.0044 - val_accuracy: 0.5067\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0090 - accuracy: 0.5063 - val_loss: 1.0041 - val_accuracy: 0.5067\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0094 - accuracy: 0.5054 - val_loss: 1.0037 - val_accuracy: 0.5067\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0064 - accuracy: 0.5061 - val_loss: 0.9988 - val_accuracy: 0.5067\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0026 - accuracy: 0.5069 - val_loss: 0.9910 - val_accuracy: 0.5094\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0040 - accuracy: 0.5058 - val_loss: 1.0024 - val_accuracy: 0.5067\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0049 - accuracy: 0.5057 - val_loss: 1.0100 - val_accuracy: 0.5080\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0051 - accuracy: 0.5061 - val_loss: 0.9923 - val_accuracy: 0.5067\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9956 - accuracy: 0.5064 - val_loss: 1.0182 - val_accuracy: 0.5067\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9975 - accuracy: 0.5052 - val_loss: 1.0019 - val_accuracy: 0.5067\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9953 - accuracy: 0.5061 - val_loss: 1.0113 - val_accuracy: 0.5094\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9921 - accuracy: 0.5073 - val_loss: 1.0239 - val_accuracy: 0.5080\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9919 - accuracy: 0.5064 - val_loss: 0.9826 - val_accuracy: 0.5080\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9836 - accuracy: 0.5066 - val_loss: 1.0122 - val_accuracy: 0.5080\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.9901 - accuracy: 0.5061 - val_loss: 0.9887 - val_accuracy: 0.5094\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9830 - accuracy: 0.5069 - val_loss: 0.9905 - val_accuracy: 0.5094\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.9851 - accuracy: 0.5057 - val_loss: 0.9617 - val_accuracy: 0.5107\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9711 - accuracy: 0.5073 - val_loss: 0.9661 - val_accuracy: 0.5107\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.9733 - accuracy: 0.5072 - val_loss: 0.9694 - val_accuracy: 0.5000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.9598 - accuracy: 0.5079 - val_loss: 1.0031 - val_accuracy: 0.5000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.9591 - accuracy: 0.5083 - val_loss: 1.0208 - val_accuracy: 0.5000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9574 - accuracy: 0.5094 - val_loss: 0.9918 - val_accuracy: 0.4960\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9562 - accuracy: 0.5086 - val_loss: 0.9628 - val_accuracy: 0.5000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9431 - accuracy: 0.5094 - val_loss: 0.9910 - val_accuracy: 0.5000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.9415 - accuracy: 0.5092 - val_loss: 0.9570 - val_accuracy: 0.5000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9454 - accuracy: 0.5086 - val_loss: 1.0054 - val_accuracy: 0.5000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9350 - accuracy: 0.5092 - val_loss: 0.9296 - val_accuracy: 0.5013\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9316 - accuracy: 0.5095 - val_loss: 0.9287 - val_accuracy: 0.5000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.9230 - accuracy: 0.5110 - val_loss: 0.9533 - val_accuracy: 0.5040\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9208 - accuracy: 0.5077 - val_loss: 0.9288 - val_accuracy: 0.5000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9099 - accuracy: 0.5115 - val_loss: 0.9146 - val_accuracy: 0.5027\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.9065 - accuracy: 0.5079 - val_loss: 0.9135 - val_accuracy: 0.5000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.9056 - accuracy: 0.5098 - val_loss: 0.8961 - val_accuracy: 0.5013\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.8912 - accuracy: 0.5082 - val_loss: 0.9493 - val_accuracy: 0.5000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8801 - accuracy: 0.5079 - val_loss: 0.8935 - val_accuracy: 0.5107\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.8774 - accuracy: 0.5118 - val_loss: 0.8775 - val_accuracy: 0.5080\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8602 - accuracy: 0.5499 - val_loss: 0.8748 - val_accuracy: 0.5777\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.8626 - accuracy: 0.5645 - val_loss: 0.8891 - val_accuracy: 0.5536\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.8442 - accuracy: 0.5639 - val_loss: 0.8884 - val_accuracy: 0.5536\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8327 - accuracy: 0.5833 - val_loss: 0.8820 - val_accuracy: 0.5255\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8349 - accuracy: 0.5897 - val_loss: 0.8262 - val_accuracy: 0.6099\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8111 - accuracy: 0.6134 - val_loss: 0.7971 - val_accuracy: 0.6220\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.7972 - accuracy: 0.6156 - val_loss: 0.8046 - val_accuracy: 0.6193\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.7688 - accuracy: 0.6358 - val_loss: 0.7749 - val_accuracy: 0.6475\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.7622 - accuracy: 0.6458 - val_loss: 0.7455 - val_accuracy: 0.6890\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.7539 - accuracy: 0.6641 - val_loss: 0.7323 - val_accuracy: 0.7024\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.7250 - accuracy: 0.6683 - val_loss: 0.7306 - val_accuracy: 0.6997\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.7056 - accuracy: 0.6829 - val_loss: 0.6965 - val_accuracy: 0.7051\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.7321 - accuracy: 0.6629 - val_loss: 0.5593 - val_accuracy: 0.8137\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.6641 - accuracy: 0.7167 - val_loss: 0.5331 - val_accuracy: 0.7976\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.6499 - accuracy: 0.7216 - val_loss: 0.5091 - val_accuracy: 0.8378\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.6371 - accuracy: 0.7367 - val_loss: 0.5687 - val_accuracy: 0.7748\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.6112 - accuracy: 0.7408 - val_loss: 0.4910 - val_accuracy: 0.8123\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.6200 - accuracy: 0.7425 - val_loss: 0.4329 - val_accuracy: 0.8525\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.5746 - accuracy: 0.7689 - val_loss: 0.4136 - val_accuracy: 0.8579\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.5358 - accuracy: 0.7806 - val_loss: 0.4679 - val_accuracy: 0.8257\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.4969 - accuracy: 0.7976 - val_loss: 0.3709 - val_accuracy: 0.8660\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.4801 - accuracy: 0.8143 - val_loss: 0.3521 - val_accuracy: 0.8566\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.4901 - accuracy: 0.8066 - val_loss: 0.3243 - val_accuracy: 0.8861\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.4388 - accuracy: 0.8356 - val_loss: 0.3257 - val_accuracy: 0.8794\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.4304 - accuracy: 0.8323 - val_loss: 0.3169 - val_accuracy: 0.8834\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.3933 - accuracy: 0.8480 - val_loss: 0.2922 - val_accuracy: 0.8968\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3740 - accuracy: 0.8615 - val_loss: 0.2979 - val_accuracy: 0.8901\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3414 - accuracy: 0.8747 - val_loss: 0.2411 - val_accuracy: 0.9088\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.3242 - accuracy: 0.8814 - val_loss: 0.2609 - val_accuracy: 0.9008\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3151 - accuracy: 0.8881 - val_loss: 0.2098 - val_accuracy: 0.9236\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.3064 - accuracy: 0.8918 - val_loss: 0.2073 - val_accuracy: 0.9316\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.3022 - accuracy: 0.8928 - val_loss: 0.2325 - val_accuracy: 0.9169\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2817 - accuracy: 0.9060 - val_loss: 0.1915 - val_accuracy: 0.9357\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2578 - accuracy: 0.9077 - val_loss: 0.2163 - val_accuracy: 0.9169\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.2749 - accuracy: 0.9060 - val_loss: 0.1945 - val_accuracy: 0.9383\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.2196 - accuracy: 0.9267 - val_loss: 0.1624 - val_accuracy: 0.9477\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2211 - accuracy: 0.9297 - val_loss: 0.1853 - val_accuracy: 0.9370\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2109 - accuracy: 0.9255 - val_loss: 0.1915 - val_accuracy: 0.9357\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.2303 - accuracy: 0.9207 - val_loss: 0.1643 - val_accuracy: 0.9370\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2102 - accuracy: 0.9258 - val_loss: 0.1238 - val_accuracy: 0.9544\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1978 - accuracy: 0.9331 - val_loss: 0.1771 - val_accuracy: 0.9450\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1744 - accuracy: 0.9385 - val_loss: 0.1471 - val_accuracy: 0.9477\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2156 - accuracy: 0.9244 - val_loss: 0.0343 - val_accuracy: 0.9906\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.2020 - accuracy: 0.9285 - val_loss: 0.0396 - val_accuracy: 0.9853\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1868 - accuracy: 0.9368 - val_loss: 0.0277 - val_accuracy: 0.9946\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1778 - accuracy: 0.9404 - val_loss: 0.0338 - val_accuracy: 0.9839\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1939 - accuracy: 0.9343 - val_loss: 0.0274 - val_accuracy: 0.9933\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1630 - accuracy: 0.9440 - val_loss: 0.0211 - val_accuracy: 0.9946\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1606 - accuracy: 0.9441 - val_loss: 0.0248 - val_accuracy: 0.9933\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1537 - accuracy: 0.9504 - val_loss: 0.0285 - val_accuracy: 0.9920\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.1607 - accuracy: 0.9444 - val_loss: 0.0258 - val_accuracy: 0.9906\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1340 - accuracy: 0.9560 - val_loss: 0.0181 - val_accuracy: 0.9933\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1394 - accuracy: 0.9541 - val_loss: 0.0282 - val_accuracy: 0.9879\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1331 - accuracy: 0.9551 - val_loss: 0.0323 - val_accuracy: 0.9893\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1325 - accuracy: 0.9532 - val_loss: 0.0211 - val_accuracy: 0.9933\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1282 - accuracy: 0.9583 - val_loss: 0.0217 - val_accuracy: 0.9933\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1379 - accuracy: 0.9557 - val_loss: 0.0286 - val_accuracy: 0.9879\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1320 - accuracy: 0.9563 - val_loss: 0.0200 - val_accuracy: 0.9933\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1263 - accuracy: 0.9593 - val_loss: 0.0219 - val_accuracy: 0.9920\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1138 - accuracy: 0.9595 - val_loss: 0.0185 - val_accuracy: 0.9960\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1114 - accuracy: 0.9671 - val_loss: 0.0184 - val_accuracy: 0.9946\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1119 - accuracy: 0.9657 - val_loss: 0.0229 - val_accuracy: 0.9906\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.1004 - accuracy: 0.9648 - val_loss: 0.0181 - val_accuracy: 0.9960\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1060 - accuracy: 0.9654 - val_loss: 0.0207 - val_accuracy: 0.9933\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0957 - accuracy: 0.9686 - val_loss: 0.0145 - val_accuracy: 0.9946\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1052 - accuracy: 0.9648 - val_loss: 0.0210 - val_accuracy: 0.9946\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0964 - accuracy: 0.9702 - val_loss: 0.0195 - val_accuracy: 0.9920\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0942 - accuracy: 0.9692 - val_loss: 0.0195 - val_accuracy: 0.9946\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1013 - accuracy: 0.9660 - val_loss: 0.0168 - val_accuracy: 0.9946\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1011 - accuracy: 0.9668 - val_loss: 0.0196 - val_accuracy: 0.9933\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0912 - accuracy: 0.9668 - val_loss: 0.0196 - val_accuracy: 0.9933\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1237 - accuracy: 0.9610 - val_loss: 0.0225 - val_accuracy: 0.9920\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0888 - accuracy: 0.9705 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0933 - accuracy: 0.9689 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1104 - accuracy: 0.9644 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0809 - accuracy: 0.9763 - val_loss: 0.0028 - val_accuracy: 0.9987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0933 - accuracy: 0.9724 - val_loss: 0.0042 - val_accuracy: 0.9987\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0759 - accuracy: 0.9742 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0838 - accuracy: 0.9709 - val_loss: 0.0031 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0835 - accuracy: 0.9736 - val_loss: 0.0034 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0808 - accuracy: 0.9739 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0770 - accuracy: 0.9735 - val_loss: 0.0030 - val_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0611 - accuracy: 0.9808 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0764 - accuracy: 0.9770 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0792 - accuracy: 0.9760 - val_loss: 0.0036 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0750 - accuracy: 0.9756 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0568 - accuracy: 0.9827 - val_loss: 0.0057 - val_accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0784 - accuracy: 0.9745 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0738 - accuracy: 0.9762 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0855 - accuracy: 0.9706 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0564 - accuracy: 0.9844 - val_loss: 0.0023 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0767 - accuracy: 0.9762 - val_loss: 0.0029 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0706 - accuracy: 0.9784 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0669 - accuracy: 0.9805 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0727 - accuracy: 0.9776 - val_loss: 0.0042 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0667 - accuracy: 0.9772 - val_loss: 0.0022 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0509 - accuracy: 0.9824 - val_loss: 0.0061 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0692 - accuracy: 0.9765 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0742 - accuracy: 0.9781 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0586 - accuracy: 0.9829 - val_loss: 0.0027 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0610 - accuracy: 0.9835 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0628 - accuracy: 0.9794 - val_loss: 0.0026 - val_accuracy: 0.9987\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0615 - accuracy: 0.9794 - val_loss: 8.4617e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0734 - accuracy: 0.9771 - val_loss: 4.4514e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0771 - accuracy: 0.9771 - val_loss: 8.5846e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0644 - accuracy: 0.9784 - val_loss: 8.4492e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0523 - accuracy: 0.9829 - val_loss: 5.2443e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0725 - accuracy: 0.9768 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0544 - accuracy: 0.9836 - val_loss: 3.7789e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0626 - accuracy: 0.9821 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0609 - accuracy: 0.9793 - val_loss: 6.6544e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0610 - accuracy: 0.9827 - val_loss: 8.0654e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0720 - accuracy: 0.9779 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0615 - accuracy: 0.9793 - val_loss: 4.6574e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0619 - accuracy: 0.9826 - val_loss: 4.8408e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0489 - accuracy: 0.9850 - val_loss: 6.6408e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0512 - accuracy: 0.9827 - val_loss: 2.7392e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0631 - accuracy: 0.9800 - val_loss: 4.2476e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0574 - accuracy: 0.9829 - val_loss: 8.2137e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0530 - accuracy: 0.9833 - val_loss: 6.0277e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0545 - accuracy: 0.9844 - val_loss: 8.1835e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0499 - accuracy: 0.9847 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0416 - accuracy: 0.9863 - val_loss: 3.0397e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0511 - accuracy: 0.9841 - val_loss: 4.0219e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0652 - accuracy: 0.9818 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0575 - accuracy: 0.9826 - val_loss: 7.9813e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0451 - accuracy: 0.9864 - val_loss: 3.7716e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0422 - accuracy: 0.9869 - val_loss: 2.8119e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0392 - accuracy: 0.9872 - val_loss: 3.8151e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0487 - accuracy: 0.9852 - val_loss: 2.6053e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0504 - accuracy: 0.9833 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0446 - accuracy: 0.9857 - val_loss: 7.0653e-04 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0457 - accuracy: 0.9845 - val_loss: 7.6488e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0601 - accuracy: 0.9836 - val_loss: 9.5286e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0703 - accuracy: 0.9784 - val_loss: 1.6443e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0485 - accuracy: 0.9866 - val_loss: 6.1008e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0463 - accuracy: 0.9854 - val_loss: 1.2935e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0533 - accuracy: 0.9860 - val_loss: 2.6717e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0470 - accuracy: 0.9848 - val_loss: 4.5142e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0491 - accuracy: 0.9860 - val_loss: 7.7016e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0531 - accuracy: 0.9855 - val_loss: 1.9495e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0550 - accuracy: 0.9839 - val_loss: 1.2377e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0520 - accuracy: 0.9814 - val_loss: 5.7075e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0521 - accuracy: 0.9829 - val_loss: 1.7786e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0470 - accuracy: 0.9858 - val_loss: 1.0614e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0388 - accuracy: 0.9882 - val_loss: 5.7060e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0437 - accuracy: 0.9875 - val_loss: 7.2346e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0447 - accuracy: 0.9860 - val_loss: 1.8195e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0548 - accuracy: 0.9832 - val_loss: 1.6854e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0427 - accuracy: 0.9857 - val_loss: 1.7044e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0487 - accuracy: 0.9835 - val_loss: 2.9353e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0479 - accuracy: 0.9852 - val_loss: 5.1932e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0399 - accuracy: 0.9872 - val_loss: 5.8015e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0416 - accuracy: 0.9893 - val_loss: 1.5287e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0390 - accuracy: 0.9869 - val_loss: 1.0267e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0362 - accuracy: 0.9894 - val_loss: 8.9617e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0327 - accuracy: 0.9908 - val_loss: 1.5691e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0361 - accuracy: 0.9887 - val_loss: 6.5897e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0394 - accuracy: 0.9885 - val_loss: 1.0313e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0457 - accuracy: 0.9857 - val_loss: 5.4652e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0440 - accuracy: 0.9866 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0414 - accuracy: 0.9857 - val_loss: 3.6301e-04 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0429 - accuracy: 0.9848 - val_loss: 3.0280e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0446 - accuracy: 0.9854 - val_loss: 1.9357e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 60ms/step - loss: 0.0539 - accuracy: 0.9835 - val_loss: 1.0807e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0366 - accuracy: 0.9891 - val_loss: 8.7702e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0399 - accuracy: 0.9899 - val_loss: 2.7856e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0325 - accuracy: 0.9900 - val_loss: 1.5922e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0309 - accuracy: 0.9896 - val_loss: 4.4529e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0426 - accuracy: 0.9864 - val_loss: 3.5041e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0541 - accuracy: 0.9830 - val_loss: 5.6828e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0381 - accuracy: 0.9873 - val_loss: 2.1833e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0393 - accuracy: 0.9878 - val_loss: 1.8112e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0364 - accuracy: 0.9899 - val_loss: 3.3362e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0455 - accuracy: 0.9866 - val_loss: 8.9654e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0428 - accuracy: 0.9875 - val_loss: 4.3788e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0343 - accuracy: 0.9905 - val_loss: 6.6702e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0273 - accuracy: 0.9906 - val_loss: 4.5387e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0285 - accuracy: 0.9900 - val_loss: 3.6564e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0551 - accuracy: 0.9827 - val_loss: 1.5724e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0444 - accuracy: 0.9866 - val_loss: 2.8568e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0377 - accuracy: 0.9878 - val_loss: 4.1756e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0412 - accuracy: 0.9879 - val_loss: 3.8805e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0392 - accuracy: 0.9896 - val_loss: 1.0170e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0333 - accuracy: 0.9900 - val_loss: 7.4309e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0409 - accuracy: 0.9858 - val_loss: 1.1162e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0303 - accuracy: 0.9908 - val_loss: 3.8097e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0325 - accuracy: 0.9884 - val_loss: 5.8722e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0339 - accuracy: 0.9887 - val_loss: 2.9040e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0284 - accuracy: 0.9912 - val_loss: 1.3819e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0259 - accuracy: 0.9930 - val_loss: 1.4452e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0289 - accuracy: 0.9909 - val_loss: 1.6868e-04 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0456 - accuracy: 0.9841 - val_loss: 1.4988e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0390 - accuracy: 0.9888 - val_loss: 1.8521e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0381 - accuracy: 0.9873 - val_loss: 1.2055e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0291 - accuracy: 0.9908 - val_loss: 1.5432e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0375 - accuracy: 0.9881 - val_loss: 7.3328e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0362 - accuracy: 0.9884 - val_loss: 9.4630e-06 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0313 - accuracy: 0.9897 - val_loss: 1.8213e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0334 - accuracy: 0.9902 - val_loss: 8.2263e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0383 - accuracy: 0.9888 - val_loss: 7.8264e-06 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0327 - accuracy: 0.9879 - val_loss: 1.1081e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0353 - accuracy: 0.9890 - val_loss: 2.4300e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0337 - accuracy: 0.9909 - val_loss: 9.5761e-06 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0396 - accuracy: 0.9870 - val_loss: 0.0044 - val_accuracy: 0.9987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0464 - accuracy: 0.9839 - val_loss: 8.1738e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0416 - accuracy: 0.9866 - val_loss: 1.1023e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0292 - accuracy: 0.9903 - val_loss: 4.0673e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0399 - accuracy: 0.9858 - val_loss: 8.8988e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0378 - accuracy: 0.9881 - val_loss: 5.6826e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0395 - accuracy: 0.9881 - val_loss: 1.2766e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0242 - accuracy: 0.9924 - val_loss: 7.0469e-06 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0233 - accuracy: 0.9928 - val_loss: 1.7435e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0273 - accuracy: 0.9920 - val_loss: 7.9402e-06 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0433 - accuracy: 0.9873 - val_loss: 1.8993e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0340 - accuracy: 0.9890 - val_loss: 2.3466e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0299 - accuracy: 0.9903 - val_loss: 9.7635e-06 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0406 - accuracy: 0.9869 - val_loss: 1.7121e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0365 - accuracy: 0.9891 - val_loss: 5.0056e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0270 - accuracy: 0.9908 - val_loss: 2.3495e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0347 - accuracy: 0.9879 - val_loss: 8.4416e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0321 - accuracy: 0.9911 - val_loss: 5.7030e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAnc2SJa3o9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "3fe5d55e-1682-4126-baf2-e4022d06bb39"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 8ms/step - loss: 0.0292 - accuracy: 0.9920\n",
            "Accuracy  : 0.9919527769088745\n",
            "F1_Score  : 0.9915568721419242\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7fcxLuwZpkK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e46e7687-7a35-4abb-ed38-f6f8c0ca40ea"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "7c8eb4c3-6cde-48b1-9cab-8d9d9a5286ee"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 5s 64ms/step - loss: 1.1456 - accuracy: 0.3732 - val_loss: 1.0864 - val_accuracy: 0.4062\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0735 - accuracy: 0.4195 - val_loss: 1.0716 - val_accuracy: 0.4223\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0758 - accuracy: 0.4171 - val_loss: 1.0662 - val_accuracy: 0.4276\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0727 - accuracy: 0.4076 - val_loss: 1.0681 - val_accuracy: 0.4303\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0697 - accuracy: 0.4171 - val_loss: 1.0663 - val_accuracy: 0.4303\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0653 - accuracy: 0.4194 - val_loss: 1.0650 - val_accuracy: 0.4209\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0699 - accuracy: 0.4045 - val_loss: 1.0625 - val_accuracy: 0.4276\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0629 - accuracy: 0.4217 - val_loss: 1.0622 - val_accuracy: 0.4223\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0697 - accuracy: 0.4139 - val_loss: 1.0612 - val_accuracy: 0.4196\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0615 - accuracy: 0.4209 - val_loss: 1.0613 - val_accuracy: 0.4290\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0649 - accuracy: 0.4112 - val_loss: 1.0632 - val_accuracy: 0.4223\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0607 - accuracy: 0.4273 - val_loss: 1.0619 - val_accuracy: 0.4316\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0657 - accuracy: 0.4209 - val_loss: 1.0626 - val_accuracy: 0.4383\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0622 - accuracy: 0.4202 - val_loss: 1.0622 - val_accuracy: 0.4330\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0605 - accuracy: 0.4209 - val_loss: 1.0603 - val_accuracy: 0.4276\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0637 - accuracy: 0.4197 - val_loss: 1.0608 - val_accuracy: 0.4316\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0602 - accuracy: 0.4184 - val_loss: 1.0608 - val_accuracy: 0.4102\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0628 - accuracy: 0.4066 - val_loss: 1.0606 - val_accuracy: 0.4209\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0609 - accuracy: 0.4191 - val_loss: 1.0604 - val_accuracy: 0.4303\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0606 - accuracy: 0.4101 - val_loss: 1.0612 - val_accuracy: 0.4330\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0629 - accuracy: 0.4189 - val_loss: 1.0667 - val_accuracy: 0.3901\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0579 - accuracy: 0.4259 - val_loss: 1.0590 - val_accuracy: 0.4357\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0601 - accuracy: 0.4211 - val_loss: 1.0616 - val_accuracy: 0.4370\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0593 - accuracy: 0.4252 - val_loss: 1.0585 - val_accuracy: 0.4343\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0648 - accuracy: 0.4082 - val_loss: 1.0600 - val_accuracy: 0.4330\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0594 - accuracy: 0.4189 - val_loss: 1.0667 - val_accuracy: 0.3995\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0631 - accuracy: 0.4145 - val_loss: 1.0592 - val_accuracy: 0.4343\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0642 - accuracy: 0.4164 - val_loss: 1.0593 - val_accuracy: 0.4397\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0523 - accuracy: 0.4340 - val_loss: 1.0614 - val_accuracy: 0.4276\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0607 - accuracy: 0.4222 - val_loss: 1.0596 - val_accuracy: 0.4370\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0593 - accuracy: 0.4177 - val_loss: 1.0552 - val_accuracy: 0.4383\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0570 - accuracy: 0.4194 - val_loss: 1.0562 - val_accuracy: 0.4370\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0592 - accuracy: 0.4221 - val_loss: 1.0641 - val_accuracy: 0.4182\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0571 - accuracy: 0.4231 - val_loss: 1.0581 - val_accuracy: 0.4410\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0582 - accuracy: 0.4232 - val_loss: 1.0548 - val_accuracy: 0.4343\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0557 - accuracy: 0.4207 - val_loss: 1.0570 - val_accuracy: 0.4370\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0548 - accuracy: 0.4282 - val_loss: 1.0582 - val_accuracy: 0.4142\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0544 - accuracy: 0.4249 - val_loss: 1.0551 - val_accuracy: 0.4290\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0552 - accuracy: 0.4292 - val_loss: 1.0554 - val_accuracy: 0.4290\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0524 - accuracy: 0.4316 - val_loss: 1.0539 - val_accuracy: 0.4196\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0594 - accuracy: 0.4192 - val_loss: 1.0528 - val_accuracy: 0.4383\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0519 - accuracy: 0.4292 - val_loss: 1.0523 - val_accuracy: 0.4343\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0528 - accuracy: 0.4250 - val_loss: 1.0543 - val_accuracy: 0.4290\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0510 - accuracy: 0.4259 - val_loss: 1.0518 - val_accuracy: 0.4223\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0522 - accuracy: 0.4225 - val_loss: 1.0527 - val_accuracy: 0.4370\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0482 - accuracy: 0.4317 - val_loss: 1.0566 - val_accuracy: 0.4330\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0574 - accuracy: 0.4253 - val_loss: 1.0526 - val_accuracy: 0.4383\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0478 - accuracy: 0.4355 - val_loss: 1.0474 - val_accuracy: 0.4397\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0456 - accuracy: 0.4316 - val_loss: 1.0774 - val_accuracy: 0.4330\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0482 - accuracy: 0.4310 - val_loss: 1.0480 - val_accuracy: 0.4343\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0470 - accuracy: 0.4332 - val_loss: 1.0511 - val_accuracy: 0.4330\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0505 - accuracy: 0.4317 - val_loss: 1.0518 - val_accuracy: 0.4410\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0456 - accuracy: 0.4344 - val_loss: 1.0455 - val_accuracy: 0.4316\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0454 - accuracy: 0.4367 - val_loss: 1.0476 - val_accuracy: 0.4450\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0392 - accuracy: 0.4349 - val_loss: 1.0497 - val_accuracy: 0.4290\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0423 - accuracy: 0.4450 - val_loss: 1.1289 - val_accuracy: 0.3807\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0449 - accuracy: 0.4303 - val_loss: 1.0537 - val_accuracy: 0.4370\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0437 - accuracy: 0.4399 - val_loss: 1.0426 - val_accuracy: 0.4410\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0400 - accuracy: 0.4419 - val_loss: 1.0465 - val_accuracy: 0.4464\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 1.0382 - accuracy: 0.4504 - val_loss: 1.0431 - val_accuracy: 0.4544\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0385 - accuracy: 0.4395 - val_loss: 1.0139 - val_accuracy: 0.4879\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0327 - accuracy: 0.4510 - val_loss: 1.0215 - val_accuracy: 0.4665\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0275 - accuracy: 0.4466 - val_loss: 1.0183 - val_accuracy: 0.4678\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0215 - accuracy: 0.4568 - val_loss: 1.0137 - val_accuracy: 0.4879\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0240 - accuracy: 0.4566 - val_loss: 1.0112 - val_accuracy: 0.4799\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0163 - accuracy: 0.4697 - val_loss: 1.0067 - val_accuracy: 0.4987\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0173 - accuracy: 0.4687 - val_loss: 1.0037 - val_accuracy: 0.4906\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0121 - accuracy: 0.4684 - val_loss: 1.0071 - val_accuracy: 0.4973\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0029 - accuracy: 0.4803 - val_loss: 1.0127 - val_accuracy: 0.4973\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 1.0016 - accuracy: 0.4852 - val_loss: 0.9975 - val_accuracy: 0.4987\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9963 - accuracy: 0.4844 - val_loss: 1.0040 - val_accuracy: 0.5000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 1.0005 - accuracy: 0.4924 - val_loss: 0.9652 - val_accuracy: 0.5322\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9818 - accuracy: 0.4972 - val_loss: 0.9936 - val_accuracy: 0.4987\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9714 - accuracy: 0.5063 - val_loss: 0.9966 - val_accuracy: 0.5040\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9628 - accuracy: 0.5146 - val_loss: 0.9785 - val_accuracy: 0.5295\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.9562 - accuracy: 0.5218 - val_loss: 0.9433 - val_accuracy: 0.5469\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9393 - accuracy: 0.5297 - val_loss: 0.9591 - val_accuracy: 0.5268\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9264 - accuracy: 0.5399 - val_loss: 0.9236 - val_accuracy: 0.5710\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.9179 - accuracy: 0.5455 - val_loss: 0.9362 - val_accuracy: 0.5496\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.9007 - accuracy: 0.5620 - val_loss: 0.8845 - val_accuracy: 0.5791\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8949 - accuracy: 0.5674 - val_loss: 0.9002 - val_accuracy: 0.6005\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8657 - accuracy: 0.5879 - val_loss: 0.8798 - val_accuracy: 0.5777\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8666 - accuracy: 0.5821 - val_loss: 0.8931 - val_accuracy: 0.5764\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.8517 - accuracy: 0.5939 - val_loss: 0.8452 - val_accuracy: 0.6247\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8176 - accuracy: 0.6227 - val_loss: 0.8543 - val_accuracy: 0.5925\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.8030 - accuracy: 0.6252 - val_loss: 0.8521 - val_accuracy: 0.5871\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.7758 - accuracy: 0.6389 - val_loss: 0.8163 - val_accuracy: 0.6340\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7629 - accuracy: 0.6541 - val_loss: 0.7900 - val_accuracy: 0.6542\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.7381 - accuracy: 0.6683 - val_loss: 0.7667 - val_accuracy: 0.6421\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.7208 - accuracy: 0.6724 - val_loss: 0.7567 - val_accuracy: 0.6595\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.7229 - accuracy: 0.6711 - val_loss: 0.5074 - val_accuracy: 0.7775\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.7004 - accuracy: 0.6902 - val_loss: 0.5628 - val_accuracy: 0.7855\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.6686 - accuracy: 0.7124 - val_loss: 0.5070 - val_accuracy: 0.8123\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.6324 - accuracy: 0.7261 - val_loss: 0.4738 - val_accuracy: 0.7976\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.6117 - accuracy: 0.7337 - val_loss: 0.4665 - val_accuracy: 0.7909\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.6201 - accuracy: 0.7331 - val_loss: 0.4308 - val_accuracy: 0.8110\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.5573 - accuracy: 0.7692 - val_loss: 0.3932 - val_accuracy: 0.8231\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.5422 - accuracy: 0.7763 - val_loss: 0.3941 - val_accuracy: 0.8284\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.5389 - accuracy: 0.7742 - val_loss: 0.4529 - val_accuracy: 0.7989\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.5213 - accuracy: 0.7839 - val_loss: 0.3920 - val_accuracy: 0.8458\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.4930 - accuracy: 0.7951 - val_loss: 0.3669 - val_accuracy: 0.8351\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.4656 - accuracy: 0.8048 - val_loss: 0.3649 - val_accuracy: 0.8512\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.4558 - accuracy: 0.8162 - val_loss: 0.3447 - val_accuracy: 0.8566\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.4378 - accuracy: 0.8194 - val_loss: 0.3223 - val_accuracy: 0.8807\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.4262 - accuracy: 0.8326 - val_loss: 0.3541 - val_accuracy: 0.8512\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.4006 - accuracy: 0.8402 - val_loss: 0.3009 - val_accuracy: 0.8901\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3841 - accuracy: 0.8551 - val_loss: 0.2885 - val_accuracy: 0.8968\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.3662 - accuracy: 0.8639 - val_loss: 0.2845 - val_accuracy: 0.8874\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3415 - accuracy: 0.8700 - val_loss: 0.2358 - val_accuracy: 0.9035\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3562 - accuracy: 0.8672 - val_loss: 0.2684 - val_accuracy: 0.8954\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.3259 - accuracy: 0.8779 - val_loss: 0.2176 - val_accuracy: 0.9142\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3292 - accuracy: 0.8811 - val_loss: 0.2276 - val_accuracy: 0.9115\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.3206 - accuracy: 0.8768 - val_loss: 0.2373 - val_accuracy: 0.9129\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2779 - accuracy: 0.8996 - val_loss: 0.2051 - val_accuracy: 0.9263\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2948 - accuracy: 0.8942 - val_loss: 0.2081 - val_accuracy: 0.9303\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2808 - accuracy: 0.8942 - val_loss: 0.2081 - val_accuracy: 0.9263\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2542 - accuracy: 0.9060 - val_loss: 0.1959 - val_accuracy: 0.9276\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2478 - accuracy: 0.9125 - val_loss: 0.2036 - val_accuracy: 0.9276\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2460 - accuracy: 0.9094 - val_loss: 0.1821 - val_accuracy: 0.9316\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2488 - accuracy: 0.9085 - val_loss: 0.1771 - val_accuracy: 0.9437\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2467 - accuracy: 0.9119 - val_loss: 0.0640 - val_accuracy: 0.9812\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2481 - accuracy: 0.9115 - val_loss: 0.0690 - val_accuracy: 0.9866\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.2237 - accuracy: 0.9218 - val_loss: 0.0634 - val_accuracy: 0.9786\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.2083 - accuracy: 0.9252 - val_loss: 0.0567 - val_accuracy: 0.9906\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1981 - accuracy: 0.9301 - val_loss: 0.0487 - val_accuracy: 0.9879\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2127 - accuracy: 0.9262 - val_loss: 0.0571 - val_accuracy: 0.9866\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1951 - accuracy: 0.9310 - val_loss: 0.0498 - val_accuracy: 0.9946\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.2047 - accuracy: 0.9311 - val_loss: 0.0601 - val_accuracy: 0.9866\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.1731 - accuracy: 0.9416 - val_loss: 0.0761 - val_accuracy: 0.9718\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1678 - accuracy: 0.9426 - val_loss: 0.0461 - val_accuracy: 0.9879\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1810 - accuracy: 0.9377 - val_loss: 0.0432 - val_accuracy: 0.9906\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1579 - accuracy: 0.9472 - val_loss: 0.0474 - val_accuracy: 0.9906\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1723 - accuracy: 0.9390 - val_loss: 0.0527 - val_accuracy: 0.9853\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1624 - accuracy: 0.9392 - val_loss: 0.0453 - val_accuracy: 0.9839\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1534 - accuracy: 0.9493 - val_loss: 0.0388 - val_accuracy: 0.9920\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1410 - accuracy: 0.9516 - val_loss: 0.0414 - val_accuracy: 0.9920\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1463 - accuracy: 0.9504 - val_loss: 0.0349 - val_accuracy: 0.9920\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1326 - accuracy: 0.9560 - val_loss: 0.0373 - val_accuracy: 0.9920\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1634 - accuracy: 0.9453 - val_loss: 0.0437 - val_accuracy: 0.9866\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1475 - accuracy: 0.9539 - val_loss: 0.0701 - val_accuracy: 0.9732\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1590 - accuracy: 0.9450 - val_loss: 0.0405 - val_accuracy: 0.9906\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1336 - accuracy: 0.9539 - val_loss: 0.0388 - val_accuracy: 0.9866\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1516 - accuracy: 0.9481 - val_loss: 0.0354 - val_accuracy: 0.9906\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1320 - accuracy: 0.9563 - val_loss: 0.0270 - val_accuracy: 0.9960\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.1197 - accuracy: 0.9605 - val_loss: 0.0283 - val_accuracy: 0.9933\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1114 - accuracy: 0.9645 - val_loss: 0.0324 - val_accuracy: 0.9906\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1211 - accuracy: 0.9577 - val_loss: 0.0433 - val_accuracy: 0.9853\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1194 - accuracy: 0.9595 - val_loss: 0.0235 - val_accuracy: 0.9946\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1055 - accuracy: 0.9647 - val_loss: 0.0200 - val_accuracy: 0.9946\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1047 - accuracy: 0.9648 - val_loss: 0.0249 - val_accuracy: 0.9933\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.1116 - accuracy: 0.9633 - val_loss: 0.0044 - val_accuracy: 0.9987\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1178 - accuracy: 0.9598 - val_loss: 0.0065 - val_accuracy: 0.9987\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0928 - accuracy: 0.9702 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1268 - accuracy: 0.9618 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1020 - accuracy: 0.9666 - val_loss: 0.0054 - val_accuracy: 0.9973\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1178 - accuracy: 0.9601 - val_loss: 0.0075 - val_accuracy: 0.9973\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.1109 - accuracy: 0.9638 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0900 - accuracy: 0.9697 - val_loss: 0.0052 - val_accuracy: 0.9973\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0818 - accuracy: 0.9744 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1157 - accuracy: 0.9604 - val_loss: 0.0076 - val_accuracy: 0.9973\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1049 - accuracy: 0.9680 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0802 - accuracy: 0.9738 - val_loss: 0.0037 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0925 - accuracy: 0.9686 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.1055 - accuracy: 0.9650 - val_loss: 0.0060 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0826 - accuracy: 0.9751 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0776 - accuracy: 0.9762 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0838 - accuracy: 0.9733 - val_loss: 0.0056 - val_accuracy: 0.9973\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0928 - accuracy: 0.9723 - val_loss: 0.0076 - val_accuracy: 0.9960\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0923 - accuracy: 0.9689 - val_loss: 0.0055 - val_accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0711 - accuracy: 0.9773 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0827 - accuracy: 0.9741 - val_loss: 0.0061 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0770 - accuracy: 0.9757 - val_loss: 0.0081 - val_accuracy: 0.9973\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0854 - accuracy: 0.9712 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0793 - accuracy: 0.9751 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0716 - accuracy: 0.9796 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0663 - accuracy: 0.9776 - val_loss: 0.0048 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0770 - accuracy: 0.9751 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0835 - accuracy: 0.9744 - val_loss: 0.0093 - val_accuracy: 0.9973\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0930 - accuracy: 0.9706 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0603 - accuracy: 0.9814 - val_loss: 0.0078 - val_accuracy: 0.9987\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0866 - accuracy: 0.9715 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0724 - accuracy: 0.9776 - val_loss: 4.8296e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0760 - accuracy: 0.9735 - val_loss: 7.6284e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0767 - accuracy: 0.9751 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0584 - accuracy: 0.9803 - val_loss: 0.0024 - val_accuracy: 0.9987\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0777 - accuracy: 0.9757 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0956 - accuracy: 0.9712 - val_loss: 8.3744e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0741 - accuracy: 0.9748 - val_loss: 4.9801e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0675 - accuracy: 0.9784 - val_loss: 5.3884e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0697 - accuracy: 0.9787 - val_loss: 4.1919e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0754 - accuracy: 0.9769 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0521 - accuracy: 0.9854 - val_loss: 5.5273e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0497 - accuracy: 0.9836 - val_loss: 7.7162e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0870 - accuracy: 0.9706 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0731 - accuracy: 0.9776 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0651 - accuracy: 0.9802 - val_loss: 6.6006e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0578 - accuracy: 0.9833 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0541 - accuracy: 0.9847 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0769 - accuracy: 0.9762 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0691 - accuracy: 0.9771 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0648 - accuracy: 0.9796 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0548 - accuracy: 0.9823 - val_loss: 5.2424e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0609 - accuracy: 0.9790 - val_loss: 0.0065 - val_accuracy: 0.9960\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0581 - accuracy: 0.9829 - val_loss: 8.1394e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0651 - accuracy: 0.9779 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0583 - accuracy: 0.9820 - val_loss: 0.0031 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0623 - accuracy: 0.9796 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0649 - accuracy: 0.9806 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0594 - accuracy: 0.9808 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0550 - accuracy: 0.9830 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0745 - accuracy: 0.9760 - val_loss: 1.1999e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0673 - accuracy: 0.9784 - val_loss: 1.9703e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0630 - accuracy: 0.9790 - val_loss: 2.0939e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0552 - accuracy: 0.9827 - val_loss: 3.4957e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0504 - accuracy: 0.9823 - val_loss: 1.1980e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0473 - accuracy: 0.9857 - val_loss: 8.2724e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0585 - accuracy: 0.9818 - val_loss: 1.2083e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0520 - accuracy: 0.9847 - val_loss: 0.0019 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0536 - accuracy: 0.9835 - val_loss: 1.3905e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0581 - accuracy: 0.9814 - val_loss: 9.4460e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0520 - accuracy: 0.9850 - val_loss: 2.2739e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0501 - accuracy: 0.9842 - val_loss: 2.6851e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0547 - accuracy: 0.9821 - val_loss: 2.8448e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0568 - accuracy: 0.9824 - val_loss: 7.2654e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0619 - accuracy: 0.9800 - val_loss: 1.0122e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0431 - accuracy: 0.9870 - val_loss: 1.2245e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0615 - accuracy: 0.9818 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0545 - accuracy: 0.9833 - val_loss: 1.3336e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0726 - accuracy: 0.9766 - val_loss: 3.2837e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0521 - accuracy: 0.9848 - val_loss: 1.3917e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0521 - accuracy: 0.9836 - val_loss: 1.7724e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0486 - accuracy: 0.9851 - val_loss: 1.8374e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0499 - accuracy: 0.9855 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0553 - accuracy: 0.9830 - val_loss: 2.3727e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0404 - accuracy: 0.9875 - val_loss: 1.5916e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0461 - accuracy: 0.9858 - val_loss: 2.0724e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0472 - accuracy: 0.9847 - val_loss: 1.5003e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0444 - accuracy: 0.9855 - val_loss: 1.4056e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0459 - accuracy: 0.9866 - val_loss: 8.5115e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0485 - accuracy: 0.9851 - val_loss: 3.6626e-04 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.0601 - accuracy: 0.9820 - val_loss: 3.0757e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0532 - accuracy: 0.9845 - val_loss: 2.4047e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0466 - accuracy: 0.9839 - val_loss: 4.4871e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0469 - accuracy: 0.9872 - val_loss: 3.5575e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0372 - accuracy: 0.9893 - val_loss: 1.7534e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0416 - accuracy: 0.9876 - val_loss: 1.6762e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0505 - accuracy: 0.9844 - val_loss: 5.3797e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0557 - accuracy: 0.9838 - val_loss: 0.0013 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0412 - accuracy: 0.9878 - val_loss: 6.7381e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0401 - accuracy: 0.9852 - val_loss: 8.8121e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0357 - accuracy: 0.9876 - val_loss: 3.8905e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0340 - accuracy: 0.9908 - val_loss: 2.3956e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0530 - accuracy: 0.9815 - val_loss: 3.7356e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0452 - accuracy: 0.9867 - val_loss: 0.0016 - val_accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0297 - accuracy: 0.9912 - val_loss: 8.5729e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0404 - accuracy: 0.9875 - val_loss: 3.1724e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0432 - accuracy: 0.9878 - val_loss: 0.0012 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0397 - accuracy: 0.9884 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0443 - accuracy: 0.9857 - val_loss: 8.1433e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0475 - accuracy: 0.9878 - val_loss: 7.1131e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0494 - accuracy: 0.9858 - val_loss: 2.7561e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0417 - accuracy: 0.9882 - val_loss: 2.4583e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0376 - accuracy: 0.9887 - val_loss: 1.8307e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0393 - accuracy: 0.9894 - val_loss: 1.4551e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0383 - accuracy: 0.9900 - val_loss: 6.9445e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0396 - accuracy: 0.9888 - val_loss: 1.6170e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0353 - accuracy: 0.9878 - val_loss: 1.0738e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0475 - accuracy: 0.9847 - val_loss: 1.2402e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0397 - accuracy: 0.9867 - val_loss: 1.1143e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0448 - accuracy: 0.9872 - val_loss: 1.4867e-04 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0370 - accuracy: 0.9887 - val_loss: 3.5898e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0404 - accuracy: 0.9866 - val_loss: 3.5952e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0295 - accuracy: 0.9912 - val_loss: 2.4268e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0411 - accuracy: 0.9872 - val_loss: 3.7971e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0354 - accuracy: 0.9885 - val_loss: 2.4348e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0372 - accuracy: 0.9888 - val_loss: 2.4740e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0446 - accuracy: 0.9869 - val_loss: 3.1616e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0492 - accuracy: 0.9842 - val_loss: 5.4025e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0379 - accuracy: 0.9870 - val_loss: 2.8142e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0439 - accuracy: 0.9860 - val_loss: 4.5259e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0432 - accuracy: 0.9854 - val_loss: 4.6337e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0326 - accuracy: 0.9896 - val_loss: 2.9793e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0312 - accuracy: 0.9903 - val_loss: 2.0731e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0386 - accuracy: 0.9881 - val_loss: 2.0365e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0447 - accuracy: 0.9860 - val_loss: 8.9351e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0372 - accuracy: 0.9890 - val_loss: 9.1014e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0461 - accuracy: 0.9882 - val_loss: 4.3122e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0361 - accuracy: 0.9897 - val_loss: 9.0763e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0270 - accuracy: 0.9914 - val_loss: 5.9285e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0414 - accuracy: 0.9881 - val_loss: 3.2176e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0412 - accuracy: 0.9879 - val_loss: 0.0021 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0467 - accuracy: 0.9866 - val_loss: 3.2029e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0318 - accuracy: 0.9909 - val_loss: 1.3755e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0328 - accuracy: 0.9894 - val_loss: 7.1152e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0293 - accuracy: 0.9903 - val_loss: 3.3203e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.0261 - accuracy: 0.9923 - val_loss: 7.9063e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 3s 58ms/step - loss: 0.0405 - accuracy: 0.9869 - val_loss: 1.7947e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0384 - accuracy: 0.9882 - val_loss: 0.0012 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0504 - accuracy: 0.9833 - val_loss: 4.9996e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 3s 57ms/step - loss: 0.0325 - accuracy: 0.9906 - val_loss: 2.0598e-04 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "6113e514-3ccf-4f14-dabf-32ccafcdaf01"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 8ms/step - loss: 0.0532 - accuracy: 0.9828\n",
            "Accuracy  : 0.9828326106071472\n",
            "F1_Score  : 0.9817452690767587\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}