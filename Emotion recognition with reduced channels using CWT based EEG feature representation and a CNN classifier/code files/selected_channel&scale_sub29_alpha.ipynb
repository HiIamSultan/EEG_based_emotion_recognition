{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selected_channel&scale_sub29_alpha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "from pywt import swt, cwt\n",
        "import scipy.misc\n",
        "from scipy.signal import welch\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, AvgPool2D, Reshape, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.layers import Activation, GlobalMaxPool2D, SpatialDropout2D, GlobalAvgPool2D, SeparableConv1D\n",
        "from keras.layers import AvgPool1D, Conv1D, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D, Add, Concatenate\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler                                                      \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from scipy import signal\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "d8782286-b4fb-44b2-bf16-a41b526d385e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIY4fiC5qCkI"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9LZgo2IM9N-"
      },
      "source": [
        "from scipy.signal.lti_conversion import cont2discrete\n",
        "const = 1e5\n",
        "def cwt_EER(x):\n",
        "  coef = cwt(x,np.arange(11, 31),'morl')[0]#[7:39]\n",
        "  energy = np.square(coef)\n",
        "  energy_each_coef_sum = sum(energy.T)\n",
        "  energy_each_coef_sum_tile = np.tile(energy_each_coef_sum, (256,1)).T\n",
        "  probability = np.divide(energy,energy_each_coef_sum_tile)\n",
        "  entropy = -probability*np.log(probability)\n",
        "  EER = np.divide(energy, entropy)\n",
        "  #EER = EER/const\n",
        "  return EER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXrZrst909d"
      },
      "source": [
        "channel = np.array([1,3,7,8,21,22,25,26,27,30])\n",
        "scale = len(np.arange(11, 31))\n",
        "sampling_rate = 128\n",
        "window_size = 256\n",
        "skip = 32\n",
        "channel_len = len(channel)\n",
        "classes=3\n",
        "order = 6\n",
        "fs = 128      # sample rate, Hz\n",
        "cutoff = 60  # desired cutoff frequency of the filter, Hz\n",
        "waveletname = 'db4'\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 45/(sampling_rate/2)]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EotvnIan4d84",
        "outputId": "311229a8-182d-4394-dd67-802961851869"
      },
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "dominance = []\n",
        "signal_freq = []\n",
        "eeg_sig = []\n",
        "gc.collect()\n",
        "\n",
        "for person in range(29,30):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  # EEG files address\n",
        "  if person < 10 :\n",
        "    address = input_path+'s0'+str(person)+'.dat'\n",
        "  else :\n",
        "    address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<4] = 0\n",
        "  label[(label>=4) & (label<6)] = 1\n",
        "  label[(label>=6) & (label<=9)] = 2     \n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "  dom = label.T[2] # Dominance label\n",
        "\n",
        "  del data, label\n",
        "  \n",
        "\n",
        "  for i in range(40): # Iterating through 40 vidoes/trials\n",
        "\n",
        "    sig = eeg[i]\n",
        "    sig = sig[:32, 384:]\n",
        "    \n",
        "    dfs = []\n",
        "    for j in channel:\n",
        "      ## Dividing Alpha Band\n",
        "      num, den = signal.butter(4, bands['alpha'], 'bandpass')\n",
        "      dfs.append(signal.filtfilt(num, den, sig[j,:]))\n",
        "\n",
        "    sig = np.array(dfs)\n",
        "    sig = sig.reshape([-1,7680])\n",
        "    eeg_signal.append(sig)\n",
        "  del dfs, sig, eeg\n",
        "  eeg_signal = np.reshape(eeg_signal,[-1,len(channel),7680])\n",
        "  gc.collect()\n",
        "  for i in range(40):\n",
        "    v = val[i]\n",
        "    a = aro[i]\n",
        "    d = dom[i]\n",
        "    start = 0\n",
        "    # Segmenting into 2 seconds (256 timesteps) windows with 1.75 seconds overlap\n",
        "    while start + window_size <=eeg_signal.shape[2]:\n",
        "      for j in range(eeg_signal.shape[1]):\n",
        "        eeg_sig.append(cwt_EER(eeg_signal[i, j, start:start+window_size]))#.mean())#axis=1))\n",
        "      valence.append(v)\n",
        "      arousal.append(a)\n",
        "      dominance.append(d)\n",
        "      start += skip\n",
        "#eeg_sig = np.array(eeg_sig)\n",
        "gc.collect()\n",
        "del eeg_signal\n",
        "eeg_sig = np.reshape(eeg_sig,[-1,len(channel)*len(np.arange(11, 31)),256,1])\n",
        "data = np.asarray(eeg_sig, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_sig\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "dominance = np.asarray(dominance, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape, valence[valence==2].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape, arousal[arousal==2].shape)\n",
        "print(dominance.shape, dominance[dominance == 0].shape, dominance[dominance == 1].shape, dominance[dominance==2].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "dominance = np_utils.to_categorical(dominance)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Person No.29\n",
            "(9320, 200, 256, 1)\n",
            "(9320,) (3262,) (1398,) (4660,)\n",
            "(9320,) (2796,) (1398,) (5126,)\n",
            "(9320,) (3262,) (932,) (5126,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VMwwMiur8kW"
      },
      "source": [
        "# **Proposed Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZC2UyIPd33"
      },
      "source": [
        "def get_model() :\n",
        "    input_shape = (data.shape[1],data.shape[2],1)\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='tanh'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLb7uFzTl7H",
        "outputId": "de8fdb6f-dee8-4e34-965b-0080b3625cc0"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 128, 16)      416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 32, 32)        25120     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 8, 64)          165952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 397,123\n",
            "Trainable params: 396,899\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6fgR_XrOSw",
        "outputId": "399055d9-87a9-4e99-fc34-e4053727f98c"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "kfold = KFold(10, True, 1)\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "706"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94Q8iJ4rJsF"
      },
      "source": [
        "# **Valence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHEnzkdKqgOS",
        "outputId": "7c8772f0-08f6-40d3-c827-ae6dc8498eb6"
      },
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,valence, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdPOzU7rQRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "597ef86f-d687-46e4-cb3b-3cd9bc1de972"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 26s 59ms/step - loss: 1.1585 - accuracy: 0.4441 - val_loss: 0.9963 - val_accuracy: 0.5188\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0087 - accuracy: 0.4985 - val_loss: 0.9650 - val_accuracy: 0.5255\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 1.0013 - accuracy: 0.4976 - val_loss: 0.9577 - val_accuracy: 0.5228\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9905 - accuracy: 0.5121 - val_loss: 0.9487 - val_accuracy: 0.5322\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9912 - accuracy: 0.5133 - val_loss: 0.9497 - val_accuracy: 0.5349\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9866 - accuracy: 0.5243 - val_loss: 0.9380 - val_accuracy: 0.5536\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9828 - accuracy: 0.5209 - val_loss: 0.9407 - val_accuracy: 0.5349\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9709 - accuracy: 0.5307 - val_loss: 0.9458 - val_accuracy: 0.5724\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9646 - accuracy: 0.5330 - val_loss: 0.9515 - val_accuracy: 0.5429\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9674 - accuracy: 0.5274 - val_loss: 0.9494 - val_accuracy: 0.5523\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9576 - accuracy: 0.5469 - val_loss: 0.9366 - val_accuracy: 0.5603\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9703 - accuracy: 0.5304 - val_loss: 0.9328 - val_accuracy: 0.5697\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 39ms/step - loss: 0.9620 - accuracy: 0.5339 - val_loss: 0.9198 - val_accuracy: 0.5509\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9524 - accuracy: 0.5474 - val_loss: 0.9256 - val_accuracy: 0.5684\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9514 - accuracy: 0.5492 - val_loss: 0.9601 - val_accuracy: 0.5536\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9455 - accuracy: 0.5497 - val_loss: 0.9284 - val_accuracy: 0.5550\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9493 - accuracy: 0.5438 - val_loss: 0.9394 - val_accuracy: 0.5590\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9406 - accuracy: 0.5554 - val_loss: 0.9280 - val_accuracy: 0.5657\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 39ms/step - loss: 0.9455 - accuracy: 0.5526 - val_loss: 0.9429 - val_accuracy: 0.5442\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9413 - accuracy: 0.5545 - val_loss: 0.9245 - val_accuracy: 0.5670\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9357 - accuracy: 0.5604 - val_loss: 0.9038 - val_accuracy: 0.5576\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9362 - accuracy: 0.5510 - val_loss: 0.9088 - val_accuracy: 0.5657\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9246 - accuracy: 0.5615 - val_loss: 0.9279 - val_accuracy: 0.5617\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9300 - accuracy: 0.5561 - val_loss: 0.8956 - val_accuracy: 0.5684\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9222 - accuracy: 0.5684 - val_loss: 0.8990 - val_accuracy: 0.5737\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9140 - accuracy: 0.5668 - val_loss: 0.8933 - val_accuracy: 0.5710\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9210 - accuracy: 0.5728 - val_loss: 0.9174 - val_accuracy: 0.5697\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9189 - accuracy: 0.5718 - val_loss: 0.8882 - val_accuracy: 0.5791\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9068 - accuracy: 0.5721 - val_loss: 0.8956 - val_accuracy: 0.5764\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.9148 - accuracy: 0.5710 - val_loss: 0.8797 - val_accuracy: 0.5751\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9063 - accuracy: 0.5817 - val_loss: 0.8888 - val_accuracy: 0.5737\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8944 - accuracy: 0.5796 - val_loss: 0.8962 - val_accuracy: 0.5697\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8972 - accuracy: 0.5806 - val_loss: 0.8965 - val_accuracy: 0.5657\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8846 - accuracy: 0.5806 - val_loss: 0.9000 - val_accuracy: 0.5697\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8932 - accuracy: 0.5821 - val_loss: 0.9039 - val_accuracy: 0.5697\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8723 - accuracy: 0.5920 - val_loss: 0.8804 - val_accuracy: 0.5804\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8780 - accuracy: 0.5861 - val_loss: 0.8789 - val_accuracy: 0.5831\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8720 - accuracy: 0.5928 - val_loss: 0.8793 - val_accuracy: 0.5724\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8675 - accuracy: 0.6015 - val_loss: 0.8643 - val_accuracy: 0.5938\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.8582 - accuracy: 0.6003 - val_loss: 0.8619 - val_accuracy: 0.5925\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8636 - accuracy: 0.6015 - val_loss: 0.8841 - val_accuracy: 0.5710\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8545 - accuracy: 0.6069 - val_loss: 0.8776 - val_accuracy: 0.5912\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.8432 - accuracy: 0.6119 - val_loss: 0.8627 - val_accuracy: 0.5845\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8493 - accuracy: 0.6077 - val_loss: 0.8479 - val_accuracy: 0.5885\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8393 - accuracy: 0.6146 - val_loss: 0.8570 - val_accuracy: 0.5979\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8241 - accuracy: 0.6241 - val_loss: 0.8586 - val_accuracy: 0.5858\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.8373 - accuracy: 0.6188 - val_loss: 0.8532 - val_accuracy: 0.5777\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8146 - accuracy: 0.6331 - val_loss: 0.8361 - val_accuracy: 0.5992\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8116 - accuracy: 0.6300 - val_loss: 0.8338 - val_accuracy: 0.6072\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8054 - accuracy: 0.6317 - val_loss: 0.8493 - val_accuracy: 0.5965\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.8114 - accuracy: 0.6332 - val_loss: 0.8385 - val_accuracy: 0.6059\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7989 - accuracy: 0.6332 - val_loss: 0.8269 - val_accuracy: 0.5979\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7809 - accuracy: 0.6414 - val_loss: 0.8245 - val_accuracy: 0.6166\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7776 - accuracy: 0.6480 - val_loss: 0.8099 - val_accuracy: 0.6126\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7734 - accuracy: 0.6532 - val_loss: 0.8039 - val_accuracy: 0.6139\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7575 - accuracy: 0.6529 - val_loss: 0.8178 - val_accuracy: 0.6019\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7564 - accuracy: 0.6592 - val_loss: 0.8021 - val_accuracy: 0.6220\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7466 - accuracy: 0.6586 - val_loss: 0.8144 - val_accuracy: 0.6086\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7306 - accuracy: 0.6717 - val_loss: 0.7947 - val_accuracy: 0.6314\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7211 - accuracy: 0.6751 - val_loss: 0.7628 - val_accuracy: 0.6421\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.7255 - accuracy: 0.6766 - val_loss: 0.6345 - val_accuracy: 0.7319\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.6990 - accuracy: 0.6873 - val_loss: 0.6901 - val_accuracy: 0.6810\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7050 - accuracy: 0.6842 - val_loss: 0.6127 - val_accuracy: 0.7225\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7131 - accuracy: 0.6790 - val_loss: 0.6018 - val_accuracy: 0.7453\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6849 - accuracy: 0.6966 - val_loss: 0.6004 - val_accuracy: 0.7493\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6670 - accuracy: 0.7055 - val_loss: 0.6436 - val_accuracy: 0.7225\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.6604 - accuracy: 0.7075 - val_loss: 0.5450 - val_accuracy: 0.7534\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.6358 - accuracy: 0.7151 - val_loss: 0.5597 - val_accuracy: 0.7547\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6215 - accuracy: 0.7207 - val_loss: 0.5640 - val_accuracy: 0.7641\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.6079 - accuracy: 0.7322 - val_loss: 0.5509 - val_accuracy: 0.7480\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5974 - accuracy: 0.7441 - val_loss: 0.5499 - val_accuracy: 0.7453\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5802 - accuracy: 0.7432 - val_loss: 0.4935 - val_accuracy: 0.7775\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.5501 - accuracy: 0.7599 - val_loss: 0.4961 - val_accuracy: 0.7735\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5408 - accuracy: 0.7680 - val_loss: 0.5219 - val_accuracy: 0.7694\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.5365 - accuracy: 0.7660 - val_loss: 0.5405 - val_accuracy: 0.7507\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.5262 - accuracy: 0.7744 - val_loss: 0.4755 - val_accuracy: 0.7949\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4890 - accuracy: 0.7917 - val_loss: 0.4618 - val_accuracy: 0.8137\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4811 - accuracy: 0.7960 - val_loss: 0.5329 - val_accuracy: 0.7520\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4604 - accuracy: 0.8125 - val_loss: 0.4430 - val_accuracy: 0.8097\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4389 - accuracy: 0.8180 - val_loss: 0.4312 - val_accuracy: 0.8365\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4165 - accuracy: 0.8294 - val_loss: 0.3552 - val_accuracy: 0.8552\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4376 - accuracy: 0.8177 - val_loss: 0.3766 - val_accuracy: 0.8499\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3990 - accuracy: 0.8383 - val_loss: 0.3845 - val_accuracy: 0.8485\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3584 - accuracy: 0.8547 - val_loss: 0.3560 - val_accuracy: 0.8539\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3671 - accuracy: 0.8528 - val_loss: 0.3504 - val_accuracy: 0.8633\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3378 - accuracy: 0.8681 - val_loss: 0.3493 - val_accuracy: 0.8539\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3318 - accuracy: 0.8694 - val_loss: 0.3414 - val_accuracy: 0.8673\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3265 - accuracy: 0.8711 - val_loss: 0.3055 - val_accuracy: 0.8847\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2943 - accuracy: 0.8885 - val_loss: 0.2864 - val_accuracy: 0.8861\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2930 - accuracy: 0.8844 - val_loss: 0.2959 - val_accuracy: 0.8780\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.3072 - accuracy: 0.8820 - val_loss: 0.1218 - val_accuracy: 0.9678\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2833 - accuracy: 0.8927 - val_loss: 0.1275 - val_accuracy: 0.9584\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2582 - accuracy: 0.9028 - val_loss: 0.1046 - val_accuracy: 0.9625\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2491 - accuracy: 0.9104 - val_loss: 0.0934 - val_accuracy: 0.9718\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2509 - accuracy: 0.9034 - val_loss: 0.0785 - val_accuracy: 0.9786\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.2437 - accuracy: 0.9077 - val_loss: 0.0907 - val_accuracy: 0.9732\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2239 - accuracy: 0.9158 - val_loss: 0.0965 - val_accuracy: 0.9678\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2035 - accuracy: 0.9258 - val_loss: 0.1116 - val_accuracy: 0.9598\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2068 - accuracy: 0.9218 - val_loss: 0.0779 - val_accuracy: 0.9732\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.2148 - accuracy: 0.9204 - val_loss: 0.0733 - val_accuracy: 0.9772\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1639 - accuracy: 0.9414 - val_loss: 0.0666 - val_accuracy: 0.9786\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1828 - accuracy: 0.9364 - val_loss: 0.0737 - val_accuracy: 0.9705\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1679 - accuracy: 0.9416 - val_loss: 0.0885 - val_accuracy: 0.9638\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1574 - accuracy: 0.9443 - val_loss: 0.0742 - val_accuracy: 0.9732\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1486 - accuracy: 0.9471 - val_loss: 0.0734 - val_accuracy: 0.9772\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.1644 - accuracy: 0.9438 - val_loss: 0.0593 - val_accuracy: 0.9826\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1439 - accuracy: 0.9481 - val_loss: 0.0523 - val_accuracy: 0.9826\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1500 - accuracy: 0.9481 - val_loss: 0.0985 - val_accuracy: 0.9598\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1385 - accuracy: 0.9505 - val_loss: 0.0811 - val_accuracy: 0.9651\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1310 - accuracy: 0.9556 - val_loss: 0.0697 - val_accuracy: 0.9786\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1020 - accuracy: 0.9639 - val_loss: 0.0662 - val_accuracy: 0.9745\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1100 - accuracy: 0.9630 - val_loss: 0.0684 - val_accuracy: 0.9718\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1247 - accuracy: 0.9581 - val_loss: 0.0737 - val_accuracy: 0.9692\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1053 - accuracy: 0.9638 - val_loss: 0.0666 - val_accuracy: 0.9826\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0951 - accuracy: 0.9675 - val_loss: 0.0790 - val_accuracy: 0.9705\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1164 - accuracy: 0.9611 - val_loss: 0.1133 - val_accuracy: 0.9611\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0957 - accuracy: 0.9694 - val_loss: 0.0531 - val_accuracy: 0.9812\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0864 - accuracy: 0.9699 - val_loss: 0.0741 - val_accuracy: 0.9786\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0825 - accuracy: 0.9723 - val_loss: 0.0479 - val_accuracy: 0.9906\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1007 - accuracy: 0.9672 - val_loss: 0.0598 - val_accuracy: 0.9812\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1289 - accuracy: 0.9590 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0941 - accuracy: 0.9714 - val_loss: 0.0072 - val_accuracy: 0.9987\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0995 - accuracy: 0.9638 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0854 - accuracy: 0.9729 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1039 - accuracy: 0.9653 - val_loss: 0.0078 - val_accuracy: 0.9973\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0860 - accuracy: 0.9718 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0859 - accuracy: 0.9699 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0796 - accuracy: 0.9757 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0780 - accuracy: 0.9723 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0800 - accuracy: 0.9739 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0786 - accuracy: 0.9748 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0652 - accuracy: 0.9787 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0764 - accuracy: 0.9742 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0626 - accuracy: 0.9785 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.0716 - accuracy: 0.9781 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0837 - accuracy: 0.9697 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0799 - accuracy: 0.9748 - val_loss: 0.0093 - val_accuracy: 0.9973\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0724 - accuracy: 0.9756 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0663 - accuracy: 0.9773 - val_loss: 0.0068 - val_accuracy: 0.9973\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0665 - accuracy: 0.9776 - val_loss: 0.0078 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0540 - accuracy: 0.9827 - val_loss: 0.0083 - val_accuracy: 0.9960\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0621 - accuracy: 0.9797 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0974 - accuracy: 0.9663 - val_loss: 0.0110 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0735 - accuracy: 0.9757 - val_loss: 0.0042 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0519 - accuracy: 0.9827 - val_loss: 0.0076 - val_accuracy: 0.9960\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0617 - accuracy: 0.9800 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0545 - accuracy: 0.9838 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0479 - accuracy: 0.9845 - val_loss: 0.0030 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0578 - accuracy: 0.9836 - val_loss: 0.0063 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0481 - accuracy: 0.9835 - val_loss: 0.0110 - val_accuracy: 0.9960\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0633 - accuracy: 0.9806 - val_loss: 2.6384e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0561 - accuracy: 0.9818 - val_loss: 7.2955e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0483 - accuracy: 0.9851 - val_loss: 3.4951e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0501 - accuracy: 0.9846 - val_loss: 2.3677e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0528 - accuracy: 0.9820 - val_loss: 4.0468e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0485 - accuracy: 0.9845 - val_loss: 1.7440e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0605 - accuracy: 0.9806 - val_loss: 6.5463e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0519 - accuracy: 0.9826 - val_loss: 1.9105e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0451 - accuracy: 0.9841 - val_loss: 2.6007e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0493 - accuracy: 0.9842 - val_loss: 8.3606e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0449 - accuracy: 0.9855 - val_loss: 6.1651e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0561 - accuracy: 0.9826 - val_loss: 2.6878e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0431 - accuracy: 0.9876 - val_loss: 4.5414e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0517 - accuracy: 0.9821 - val_loss: 3.4428e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0447 - accuracy: 0.9845 - val_loss: 2.5971e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0499 - accuracy: 0.9855 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0450 - accuracy: 0.9852 - val_loss: 7.6990e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0503 - accuracy: 0.9836 - val_loss: 0.0032 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0566 - accuracy: 0.9823 - val_loss: 9.4370e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0487 - accuracy: 0.9836 - val_loss: 0.0018 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0491 - accuracy: 0.9838 - val_loss: 0.0043 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0458 - accuracy: 0.9890 - val_loss: 6.0797e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0469 - accuracy: 0.9866 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0500 - accuracy: 0.9849 - val_loss: 6.9648e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0430 - accuracy: 0.9866 - val_loss: 8.9864e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0371 - accuracy: 0.9891 - val_loss: 0.0018 - val_accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0515 - accuracy: 0.9839 - val_loss: 0.0053 - val_accuracy: 0.9973\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0500 - accuracy: 0.9844 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0373 - accuracy: 0.9885 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0319 - accuracy: 0.9899 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.0482 - accuracy: 0.9850 - val_loss: 1.4985e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0390 - accuracy: 0.9864 - val_loss: 1.1261e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0512 - accuracy: 0.9830 - val_loss: 3.6339e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0500 - accuracy: 0.9847 - val_loss: 1.2437e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0389 - accuracy: 0.9894 - val_loss: 9.6173e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0334 - accuracy: 0.9896 - val_loss: 5.8947e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0395 - accuracy: 0.9867 - val_loss: 1.0115e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0399 - accuracy: 0.9879 - val_loss: 3.8978e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0425 - accuracy: 0.9851 - val_loss: 9.8967e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0338 - accuracy: 0.9902 - val_loss: 1.7447e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0326 - accuracy: 0.9902 - val_loss: 8.3964e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0377 - accuracy: 0.9878 - val_loss: 2.6462e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0353 - accuracy: 0.9888 - val_loss: 1.4845e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0443 - accuracy: 0.9866 - val_loss: 1.0687e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0473 - accuracy: 0.9860 - val_loss: 3.7179e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0312 - accuracy: 0.9903 - val_loss: 3.5582e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0369 - accuracy: 0.9888 - val_loss: 6.4549e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0342 - accuracy: 0.9881 - val_loss: 1.3960e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0344 - accuracy: 0.9900 - val_loss: 3.9843e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0283 - accuracy: 0.9917 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0412 - accuracy: 0.9852 - val_loss: 1.8803e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0308 - accuracy: 0.9900 - val_loss: 9.3965e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0301 - accuracy: 0.9911 - val_loss: 2.4410e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0307 - accuracy: 0.9909 - val_loss: 0.0035 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0284 - accuracy: 0.9920 - val_loss: 0.0043 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0568 - accuracy: 0.9836 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0488 - accuracy: 0.9841 - val_loss: 5.5185e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0325 - accuracy: 0.9899 - val_loss: 2.9972e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0324 - accuracy: 0.9894 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0299 - accuracy: 0.9887 - val_loss: 6.7247e-05 - val_accuracy: 1.0000\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0387 - accuracy: 0.9884 - val_loss: 6.4822e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0339 - accuracy: 0.9900 - val_loss: 3.1352e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0249 - accuracy: 0.9915 - val_loss: 1.2779e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0273 - accuracy: 0.9908 - val_loss: 1.2102e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0343 - accuracy: 0.9881 - val_loss: 1.6707e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0358 - accuracy: 0.9893 - val_loss: 5.2673e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0355 - accuracy: 0.9881 - val_loss: 8.1808e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0428 - accuracy: 0.9869 - val_loss: 5.4146e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0348 - accuracy: 0.9891 - val_loss: 2.7895e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0339 - accuracy: 0.9891 - val_loss: 6.0728e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0271 - accuracy: 0.9905 - val_loss: 8.0992e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0424 - accuracy: 0.9867 - val_loss: 1.1909e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0396 - accuracy: 0.9873 - val_loss: 5.0342e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0298 - accuracy: 0.9914 - val_loss: 1.4221e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0263 - accuracy: 0.9909 - val_loss: 6.9103e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0252 - accuracy: 0.9924 - val_loss: 8.6912e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0262 - accuracy: 0.9911 - val_loss: 4.1693e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0260 - accuracy: 0.9912 - val_loss: 7.7398e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0305 - accuracy: 0.9914 - val_loss: 5.0390e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0306 - accuracy: 0.9899 - val_loss: 7.9237e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0422 - accuracy: 0.9867 - val_loss: 9.9361e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0224 - accuracy: 0.9930 - val_loss: 8.3292e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0293 - accuracy: 0.9906 - val_loss: 9.0653e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0238 - accuracy: 0.9928 - val_loss: 3.1103e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0379 - accuracy: 0.9903 - val_loss: 0.0030 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0291 - accuracy: 0.9923 - val_loss: 1.7237e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0196 - accuracy: 0.9940 - val_loss: 1.4743e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0331 - accuracy: 0.9906 - val_loss: 4.1886e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0289 - accuracy: 0.9917 - val_loss: 1.8851e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0216 - accuracy: 0.9939 - val_loss: 1.1003e-04 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0215 - accuracy: 0.9927 - val_loss: 7.3181e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0256 - accuracy: 0.9925 - val_loss: 4.0378e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0384 - accuracy: 0.9873 - val_loss: 1.1796e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0437 - accuracy: 0.9855 - val_loss: 4.2829e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0284 - accuracy: 0.9925 - val_loss: 2.1748e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0356 - accuracy: 0.9878 - val_loss: 7.7661e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0277 - accuracy: 0.9918 - val_loss: 1.8208e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0244 - accuracy: 0.9923 - val_loss: 5.4236e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0432 - accuracy: 0.9873 - val_loss: 1.5572e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0215 - accuracy: 0.9920 - val_loss: 1.2825e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0253 - accuracy: 0.9923 - val_loss: 6.0157e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0271 - accuracy: 0.9918 - val_loss: 8.2110e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0288 - accuracy: 0.9903 - val_loss: 5.4062e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0230 - accuracy: 0.9920 - val_loss: 3.5517e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 7.3843e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0380 - accuracy: 0.9881 - val_loss: 1.2131e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0407 - accuracy: 0.9878 - val_loss: 0.0021 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 7.4333e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0181 - accuracy: 0.9924 - val_loss: 1.8476e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0231 - accuracy: 0.9936 - val_loss: 1.4734e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0315 - accuracy: 0.9915 - val_loss: 1.0761e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0204 - accuracy: 0.9925 - val_loss: 2.6463e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0291 - accuracy: 0.9921 - val_loss: 2.7702e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0259 - accuracy: 0.9921 - val_loss: 5.0900e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0185 - accuracy: 0.9940 - val_loss: 1.2168e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0192 - accuracy: 0.9948 - val_loss: 6.1712e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0189 - accuracy: 0.9943 - val_loss: 7.2522e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0289 - accuracy: 0.9908 - val_loss: 9.6671e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0261 - accuracy: 0.9917 - val_loss: 8.7484e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0245 - accuracy: 0.9925 - val_loss: 0.0014 - val_accuracy: 0.9987\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0255 - accuracy: 0.9918 - val_loss: 7.0036e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0291 - accuracy: 0.9905 - val_loss: 8.0059e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0155 - accuracy: 0.9955 - val_loss: 1.7916e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0256 - accuracy: 0.9925 - val_loss: 6.6824e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0203 - accuracy: 0.9921 - val_loss: 1.2825e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0311 - accuracy: 0.9912 - val_loss: 2.4847e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0245 - accuracy: 0.9921 - val_loss: 1.3504e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0309 - accuracy: 0.9893 - val_loss: 3.1977e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0280 - accuracy: 0.9912 - val_loss: 1.2901e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0301 - accuracy: 0.9899 - val_loss: 3.4400e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0272 - accuracy: 0.9931 - val_loss: 6.2714e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0237 - accuracy: 0.9923 - val_loss: 3.1669e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0278 - accuracy: 0.9912 - val_loss: 6.2486e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0302 - accuracy: 0.9893 - val_loss: 2.8548e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0253 - accuracy: 0.9923 - val_loss: 8.6155e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0245 - accuracy: 0.9912 - val_loss: 1.2165e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 7.7927e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0204 - accuracy: 0.9946 - val_loss: 8.3466e-06 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0266 - accuracy: 0.9915 - val_loss: 1.7803e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 0.0018 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0181 - accuracy: 0.9958 - val_loss: 3.0733e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0218 - accuracy: 0.9925 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0269 - accuracy: 0.9912 - val_loss: 1.8270e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0156 - accuracy: 0.9960 - val_loss: 7.5460e-06 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0277 - accuracy: 0.9923 - val_loss: 1.5930e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0258 - accuracy: 0.9920 - val_loss: 3.4782e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0177 - accuracy: 0.9937 - val_loss: 1.3067e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0166 - accuracy: 0.9934 - val_loss: 3.8654e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0167 - accuracy: 0.9943 - val_loss: 4.7084e-06 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "CAnc2SJa3o9f",
        "outputId": "e9b33dce-9d53-4d89-93e3-67eca54fb7e7"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 1s 8ms/step - loss: 0.0683 - accuracy: 0.9855\n",
            "Accuracy  : 0.9855149984359741\n",
            "F1_Score  : 0.9840380484478283\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ypZ2NnYxes"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7fcxLuwZpkK",
        "outputId": "f0d6276d-d161-4efe-dbff-b4e9e2c1e5ad"
      },
      "source": [
        "#arousal\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7456, 200, 256, 1) (1864, 200, 256, 1) (7456, 3) (1864, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iz5mTT7Zwcp",
        "outputId": "0d37da02-94ff-4197-a7b9-56a255c93166"
      },
      "source": [
        "foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 51ms/step - loss: 1.0824 - accuracy: 0.5283 - val_loss: 0.9536 - val_accuracy: 0.5858\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9789 - accuracy: 0.5677 - val_loss: 0.9581 - val_accuracy: 0.5925\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9498 - accuracy: 0.5899 - val_loss: 0.9532 - val_accuracy: 0.5979\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9512 - accuracy: 0.5894 - val_loss: 0.9465 - val_accuracy: 0.5952\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9459 - accuracy: 0.5961 - val_loss: 0.9339 - val_accuracy: 0.5912\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9464 - accuracy: 0.5917 - val_loss: 0.9337 - val_accuracy: 0.6005\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9332 - accuracy: 0.5993 - val_loss: 0.9294 - val_accuracy: 0.5979\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9182 - accuracy: 0.6094 - val_loss: 0.9178 - val_accuracy: 0.6072\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9205 - accuracy: 0.6029 - val_loss: 0.9163 - val_accuracy: 0.6005\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9006 - accuracy: 0.6123 - val_loss: 0.9264 - val_accuracy: 0.6019\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.9054 - accuracy: 0.6123 - val_loss: 0.9203 - val_accuracy: 0.5979\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8982 - accuracy: 0.6200 - val_loss: 0.9139 - val_accuracy: 0.6086\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9013 - accuracy: 0.6115 - val_loss: 0.9080 - val_accuracy: 0.6086\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.9013 - accuracy: 0.6157 - val_loss: 0.9006 - val_accuracy: 0.6046\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8927 - accuracy: 0.6151 - val_loss: 0.9070 - val_accuracy: 0.6046\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8898 - accuracy: 0.6163 - val_loss: 0.9044 - val_accuracy: 0.6046\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8795 - accuracy: 0.6197 - val_loss: 0.8991 - val_accuracy: 0.6113\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8853 - accuracy: 0.6253 - val_loss: 0.9066 - val_accuracy: 0.6086\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8888 - accuracy: 0.6223 - val_loss: 0.8953 - val_accuracy: 0.6072\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8753 - accuracy: 0.6280 - val_loss: 0.8952 - val_accuracy: 0.6072\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8702 - accuracy: 0.6297 - val_loss: 0.8905 - val_accuracy: 0.6046\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8723 - accuracy: 0.6294 - val_loss: 0.9037 - val_accuracy: 0.6046\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.8683 - accuracy: 0.6214 - val_loss: 0.8761 - val_accuracy: 0.6180\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.8662 - accuracy: 0.6306 - val_loss: 0.8994 - val_accuracy: 0.6046\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8766 - accuracy: 0.6252 - val_loss: 0.8921 - val_accuracy: 0.6153\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8511 - accuracy: 0.6397 - val_loss: 0.8605 - val_accuracy: 0.6180\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8501 - accuracy: 0.6353 - val_loss: 0.8636 - val_accuracy: 0.6260\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.8394 - accuracy: 0.6388 - val_loss: 0.8541 - val_accuracy: 0.6247\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8471 - accuracy: 0.6398 - val_loss: 0.8510 - val_accuracy: 0.6247\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.8420 - accuracy: 0.6394 - val_loss: 0.8549 - val_accuracy: 0.6273\n",
            "Results for fold 2\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.8461 - accuracy: 0.6365 - val_loss: 0.7973 - val_accuracy: 0.6635\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.8389 - accuracy: 0.6387 - val_loss: 0.7843 - val_accuracy: 0.6676\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8352 - accuracy: 0.6401 - val_loss: 0.8144 - val_accuracy: 0.6649\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8277 - accuracy: 0.6474 - val_loss: 0.7912 - val_accuracy: 0.6716\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8286 - accuracy: 0.6438 - val_loss: 0.7798 - val_accuracy: 0.6716\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8180 - accuracy: 0.6495 - val_loss: 0.7931 - val_accuracy: 0.6488\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8097 - accuracy: 0.6507 - val_loss: 0.7812 - val_accuracy: 0.6649\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8035 - accuracy: 0.6486 - val_loss: 0.7783 - val_accuracy: 0.6662\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.8078 - accuracy: 0.6519 - val_loss: 0.7868 - val_accuracy: 0.6555\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7927 - accuracy: 0.6593 - val_loss: 0.7804 - val_accuracy: 0.6662\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7771 - accuracy: 0.6647 - val_loss: 0.7534 - val_accuracy: 0.6756\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7702 - accuracy: 0.6632 - val_loss: 0.7657 - val_accuracy: 0.6488\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7678 - accuracy: 0.6683 - val_loss: 0.7543 - val_accuracy: 0.6662\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7625 - accuracy: 0.6724 - val_loss: 0.7205 - val_accuracy: 0.6796\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7483 - accuracy: 0.6757 - val_loss: 0.7644 - val_accuracy: 0.6528\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7542 - accuracy: 0.6781 - val_loss: 0.7530 - val_accuracy: 0.6729\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7334 - accuracy: 0.6852 - val_loss: 0.7193 - val_accuracy: 0.6877\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7323 - accuracy: 0.6838 - val_loss: 0.7111 - val_accuracy: 0.6984\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.7242 - accuracy: 0.6891 - val_loss: 0.7613 - val_accuracy: 0.6836\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.7101 - accuracy: 0.6920 - val_loss: 0.7110 - val_accuracy: 0.7011\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6780 - accuracy: 0.7095 - val_loss: 0.7936 - val_accuracy: 0.6702\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6899 - accuracy: 0.7031 - val_loss: 0.7239 - val_accuracy: 0.6917\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6805 - accuracy: 0.7124 - val_loss: 0.6678 - val_accuracy: 0.7212\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6656 - accuracy: 0.7124 - val_loss: 0.6964 - val_accuracy: 0.7011\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6508 - accuracy: 0.7219 - val_loss: 0.6796 - val_accuracy: 0.7172\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.6302 - accuracy: 0.7332 - val_loss: 0.6593 - val_accuracy: 0.7359\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.6207 - accuracy: 0.7420 - val_loss: 0.6564 - val_accuracy: 0.7265\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5974 - accuracy: 0.7450 - val_loss: 0.6869 - val_accuracy: 0.7306\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5825 - accuracy: 0.7499 - val_loss: 0.6562 - val_accuracy: 0.7185\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5761 - accuracy: 0.7601 - val_loss: 0.6303 - val_accuracy: 0.7386\n",
            "Results for fold 3\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5902 - accuracy: 0.7531 - val_loss: 0.4461 - val_accuracy: 0.8244\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5655 - accuracy: 0.7720 - val_loss: 0.4086 - val_accuracy: 0.8499\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.5583 - accuracy: 0.7680 - val_loss: 0.4365 - val_accuracy: 0.8445\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5249 - accuracy: 0.7841 - val_loss: 0.3822 - val_accuracy: 0.8432\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5210 - accuracy: 0.7845 - val_loss: 0.4131 - val_accuracy: 0.8391\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.5074 - accuracy: 0.7949 - val_loss: 0.3937 - val_accuracy: 0.8472\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4707 - accuracy: 0.8125 - val_loss: 0.3862 - val_accuracy: 0.8485\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4483 - accuracy: 0.8191 - val_loss: 0.3636 - val_accuracy: 0.8606\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.4337 - accuracy: 0.8270 - val_loss: 0.3205 - val_accuracy: 0.8713\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4294 - accuracy: 0.8295 - val_loss: 0.2991 - val_accuracy: 0.8901\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.4081 - accuracy: 0.8371 - val_loss: 0.3426 - val_accuracy: 0.8713\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3888 - accuracy: 0.8483 - val_loss: 0.3126 - val_accuracy: 0.8794\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3598 - accuracy: 0.8614 - val_loss: 0.2791 - val_accuracy: 0.8901\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3537 - accuracy: 0.8595 - val_loss: 0.2509 - val_accuracy: 0.9048\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.3197 - accuracy: 0.8799 - val_loss: 0.2523 - val_accuracy: 0.9048\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.3145 - accuracy: 0.8814 - val_loss: 0.2553 - val_accuracy: 0.9062\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2887 - accuracy: 0.8872 - val_loss: 0.2258 - val_accuracy: 0.9155\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2846 - accuracy: 0.8955 - val_loss: 0.2281 - val_accuracy: 0.9142\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2694 - accuracy: 0.9007 - val_loss: 0.2256 - val_accuracy: 0.9196\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2561 - accuracy: 0.9092 - val_loss: 0.2272 - val_accuracy: 0.9102\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2449 - accuracy: 0.9095 - val_loss: 0.2908 - val_accuracy: 0.8847\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2517 - accuracy: 0.9057 - val_loss: 0.1903 - val_accuracy: 0.9303\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2309 - accuracy: 0.9142 - val_loss: 0.1624 - val_accuracy: 0.9397\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.2168 - accuracy: 0.9174 - val_loss: 0.1896 - val_accuracy: 0.9263\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.2022 - accuracy: 0.9270 - val_loss: 0.1472 - val_accuracy: 0.9383\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1949 - accuracy: 0.9298 - val_loss: 0.1543 - val_accuracy: 0.9477\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1799 - accuracy: 0.9402 - val_loss: 0.1635 - val_accuracy: 0.9437\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1874 - accuracy: 0.9338 - val_loss: 0.1672 - val_accuracy: 0.9370\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1588 - accuracy: 0.9428 - val_loss: 0.1930 - val_accuracy: 0.9424\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1481 - accuracy: 0.9480 - val_loss: 0.1620 - val_accuracy: 0.9357\n",
            "Results for fold 4\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1905 - accuracy: 0.9332 - val_loss: 0.0315 - val_accuracy: 0.9920\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1839 - accuracy: 0.9386 - val_loss: 0.0325 - val_accuracy: 0.9973\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1694 - accuracy: 0.9410 - val_loss: 0.0471 - val_accuracy: 0.9879\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1501 - accuracy: 0.9477 - val_loss: 0.0203 - val_accuracy: 0.9960\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1416 - accuracy: 0.9499 - val_loss: 0.0332 - val_accuracy: 0.9906\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1378 - accuracy: 0.9495 - val_loss: 0.0270 - val_accuracy: 0.9960\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1181 - accuracy: 0.9601 - val_loss: 0.0249 - val_accuracy: 0.9933\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1205 - accuracy: 0.9557 - val_loss: 0.0247 - val_accuracy: 0.9920\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1051 - accuracy: 0.9624 - val_loss: 0.0306 - val_accuracy: 0.9920\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0979 - accuracy: 0.9662 - val_loss: 0.0253 - val_accuracy: 0.9906\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1118 - accuracy: 0.9613 - val_loss: 0.0232 - val_accuracy: 0.9946\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0989 - accuracy: 0.9690 - val_loss: 0.0158 - val_accuracy: 0.9973\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0988 - accuracy: 0.9669 - val_loss: 0.0277 - val_accuracy: 0.9906\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1060 - accuracy: 0.9623 - val_loss: 0.0303 - val_accuracy: 0.9906\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.1017 - accuracy: 0.9675 - val_loss: 0.0181 - val_accuracy: 0.9946\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0927 - accuracy: 0.9683 - val_loss: 0.0135 - val_accuracy: 0.9946\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0873 - accuracy: 0.9708 - val_loss: 0.0225 - val_accuracy: 0.9960\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0933 - accuracy: 0.9677 - val_loss: 0.0329 - val_accuracy: 0.9933\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.1004 - accuracy: 0.9680 - val_loss: 0.0381 - val_accuracy: 0.9893\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0778 - accuracy: 0.9735 - val_loss: 0.0162 - val_accuracy: 0.9960\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0815 - accuracy: 0.9723 - val_loss: 0.0217 - val_accuracy: 0.9946\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0798 - accuracy: 0.9729 - val_loss: 0.0154 - val_accuracy: 0.9973\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0719 - accuracy: 0.9753 - val_loss: 0.0181 - val_accuracy: 0.9946\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0844 - accuracy: 0.9714 - val_loss: 0.0171 - val_accuracy: 0.9960\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0824 - accuracy: 0.9730 - val_loss: 0.0188 - val_accuracy: 0.9946\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0737 - accuracy: 0.9776 - val_loss: 0.0133 - val_accuracy: 0.9960\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0760 - accuracy: 0.9754 - val_loss: 0.0111 - val_accuracy: 0.9973\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0610 - accuracy: 0.9787 - val_loss: 0.0088 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0555 - accuracy: 0.9830 - val_loss: 0.0254 - val_accuracy: 0.9920\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0555 - accuracy: 0.9811 - val_loss: 0.0161 - val_accuracy: 0.9946\n",
            "Results for fold 5\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0843 - accuracy: 0.9736 - val_loss: 6.5484e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0978 - accuracy: 0.9686 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0697 - accuracy: 0.9753 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0625 - accuracy: 0.9779 - val_loss: 9.6599e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.0706 - accuracy: 0.9757 - val_loss: 9.5893e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0675 - accuracy: 0.9778 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0731 - accuracy: 0.9776 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0629 - accuracy: 0.9806 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0618 - accuracy: 0.9791 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0537 - accuracy: 0.9820 - val_loss: 7.2556e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0516 - accuracy: 0.9845 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0589 - accuracy: 0.9790 - val_loss: 0.0027 - val_accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0585 - accuracy: 0.9800 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0508 - accuracy: 0.9833 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0675 - accuracy: 0.9756 - val_loss: 0.0062 - val_accuracy: 0.9973\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0530 - accuracy: 0.9821 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0478 - accuracy: 0.9836 - val_loss: 0.0028 - val_accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0497 - accuracy: 0.9852 - val_loss: 0.0154 - val_accuracy: 0.9933\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0615 - accuracy: 0.9824 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0531 - accuracy: 0.9821 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0504 - accuracy: 0.9836 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0381 - accuracy: 0.9867 - val_loss: 4.6651e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0486 - accuracy: 0.9846 - val_loss: 8.2268e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0447 - accuracy: 0.9866 - val_loss: 9.5532e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0476 - accuracy: 0.9858 - val_loss: 0.0054 - val_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0410 - accuracy: 0.9846 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0348 - accuracy: 0.9884 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0376 - accuracy: 0.9890 - val_loss: 7.5102e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0305 - accuracy: 0.9885 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0351 - accuracy: 0.9858 - val_loss: 6.3868e-04 - val_accuracy: 1.0000\n",
            "Results for fold 6\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0535 - accuracy: 0.9820 - val_loss: 3.9611e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0475 - accuracy: 0.9848 - val_loss: 1.6558e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0421 - accuracy: 0.9855 - val_loss: 1.3753e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0396 - accuracy: 0.9875 - val_loss: 1.3622e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0406 - accuracy: 0.9872 - val_loss: 5.5070e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0498 - accuracy: 0.9833 - val_loss: 8.8646e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0426 - accuracy: 0.9878 - val_loss: 4.6738e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0424 - accuracy: 0.9869 - val_loss: 2.0729e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0330 - accuracy: 0.9906 - val_loss: 5.4599e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0437 - accuracy: 0.9873 - val_loss: 2.0980e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0315 - accuracy: 0.9897 - val_loss: 2.0571e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0445 - accuracy: 0.9858 - val_loss: 2.1986e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0305 - accuracy: 0.9897 - val_loss: 2.0802e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0364 - accuracy: 0.9879 - val_loss: 5.7506e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0421 - accuracy: 0.9876 - val_loss: 0.0025 - val_accuracy: 0.9973\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0345 - accuracy: 0.9887 - val_loss: 1.5761e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0425 - accuracy: 0.9872 - val_loss: 6.2994e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0508 - accuracy: 0.9835 - val_loss: 7.1502e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0330 - accuracy: 0.9887 - val_loss: 5.6916e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0376 - accuracy: 0.9876 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0390 - accuracy: 0.9866 - val_loss: 7.4928e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0301 - accuracy: 0.9908 - val_loss: 7.3854e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0251 - accuracy: 0.9909 - val_loss: 4.1157e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0331 - accuracy: 0.9891 - val_loss: 3.9409e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0340 - accuracy: 0.9909 - val_loss: 1.9870e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0297 - accuracy: 0.9906 - val_loss: 2.9120e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0339 - accuracy: 0.9908 - val_loss: 4.1747e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0332 - accuracy: 0.9887 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0280 - accuracy: 0.9903 - val_loss: 0.0059 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0430 - accuracy: 0.9861 - val_loss: 4.7743e-04 - val_accuracy: 1.0000\n",
            "Results for fold 7\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0380 - accuracy: 0.9888 - val_loss: 4.7050e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0378 - accuracy: 0.9884 - val_loss: 4.3844e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0438 - accuracy: 0.9876 - val_loss: 2.1424e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0362 - accuracy: 0.9884 - val_loss: 1.0686e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0457 - accuracy: 0.9841 - val_loss: 2.5857e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0435 - accuracy: 0.9864 - val_loss: 2.7287e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0326 - accuracy: 0.9893 - val_loss: 1.7283e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0241 - accuracy: 0.9923 - val_loss: 4.8180e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0281 - accuracy: 0.9906 - val_loss: 8.2716e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0279 - accuracy: 0.9918 - val_loss: 9.8632e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0256 - accuracy: 0.9915 - val_loss: 7.3184e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0290 - accuracy: 0.9909 - val_loss: 1.4577e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0272 - accuracy: 0.9915 - val_loss: 4.1367e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0324 - accuracy: 0.9903 - val_loss: 3.8882e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0349 - accuracy: 0.9903 - val_loss: 2.1950e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0370 - accuracy: 0.9887 - val_loss: 4.2895e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0295 - accuracy: 0.9906 - val_loss: 2.1429e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0438 - accuracy: 0.9855 - val_loss: 0.0022 - val_accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0294 - accuracy: 0.9891 - val_loss: 7.8167e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0244 - accuracy: 0.9917 - val_loss: 4.0043e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0284 - accuracy: 0.9911 - val_loss: 0.0048 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0252 - accuracy: 0.9911 - val_loss: 9.8490e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0191 - accuracy: 0.9942 - val_loss: 3.0839e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0300 - accuracy: 0.9905 - val_loss: 2.3207e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0223 - accuracy: 0.9945 - val_loss: 8.7030e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0242 - accuracy: 0.9915 - val_loss: 8.6615e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0323 - accuracy: 0.9911 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0336 - accuracy: 0.9900 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0281 - accuracy: 0.9914 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0291 - accuracy: 0.9920 - val_loss: 0.0015 - val_accuracy: 0.9987\n",
            "Results for fold 8\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0374 - accuracy: 0.9888 - val_loss: 2.1777e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0302 - accuracy: 0.9915 - val_loss: 3.4157e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 1.1208e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0217 - accuracy: 0.9934 - val_loss: 3.7806e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0288 - accuracy: 0.9909 - val_loss: 5.4708e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0280 - accuracy: 0.9917 - val_loss: 2.0358e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0243 - accuracy: 0.9934 - val_loss: 5.4559e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0220 - accuracy: 0.9923 - val_loss: 7.7221e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0372 - accuracy: 0.9873 - val_loss: 7.1519e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 40ms/step - loss: 0.0198 - accuracy: 0.9934 - val_loss: 3.9163e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0156 - accuracy: 0.9955 - val_loss: 1.2722e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0244 - accuracy: 0.9934 - val_loss: 6.4509e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0267 - accuracy: 0.9928 - val_loss: 8.2315e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0208 - accuracy: 0.9927 - val_loss: 1.5796e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0168 - accuracy: 0.9942 - val_loss: 4.5536e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0244 - accuracy: 0.9923 - val_loss: 1.2742e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0267 - accuracy: 0.9918 - val_loss: 8.8898e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0260 - accuracy: 0.9917 - val_loss: 1.4341e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0243 - accuracy: 0.9923 - val_loss: 5.7234e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0245 - accuracy: 0.9924 - val_loss: 1.5305e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0229 - accuracy: 0.9921 - val_loss: 1.9984e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0276 - accuracy: 0.9921 - val_loss: 7.1382e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0258 - accuracy: 0.9918 - val_loss: 1.0144e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0235 - accuracy: 0.9928 - val_loss: 1.4635e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0249 - accuracy: 0.9924 - val_loss: 2.2046e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0261 - accuracy: 0.9912 - val_loss: 1.9750e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0293 - accuracy: 0.9917 - val_loss: 9.8828e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0208 - accuracy: 0.9937 - val_loss: 0.0012 - val_accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0234 - accuracy: 0.9933 - val_loss: 3.1938e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0185 - accuracy: 0.9951 - val_loss: 1.4811e-04 - val_accuracy: 1.0000\n",
            "Results for fold 9\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.0238 - accuracy: 0.9918 - val_loss: 2.5394e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0239 - accuracy: 0.9927 - val_loss: 2.4143e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0374 - accuracy: 0.9887 - val_loss: 5.3092e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0207 - accuracy: 0.9931 - val_loss: 3.9017e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0265 - accuracy: 0.9912 - val_loss: 1.4153e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0313 - accuracy: 0.9908 - val_loss: 1.3566e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0166 - accuracy: 0.9963 - val_loss: 9.0884e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0311 - accuracy: 0.9909 - val_loss: 6.1114e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0194 - accuracy: 0.9934 - val_loss: 2.9565e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0161 - accuracy: 0.9948 - val_loss: 1.1018e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0189 - accuracy: 0.9940 - val_loss: 1.0137e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0121 - accuracy: 0.9952 - val_loss: 1.2420e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0204 - accuracy: 0.9934 - val_loss: 6.3312e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0231 - accuracy: 0.9931 - val_loss: 6.9856e-06 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0207 - accuracy: 0.9931 - val_loss: 3.1694e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0472 - accuracy: 0.9867 - val_loss: 1.1420e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 1.3786e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0206 - accuracy: 0.9943 - val_loss: 8.3100e-06 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0246 - accuracy: 0.9930 - val_loss: 1.2108e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0261 - accuracy: 0.9920 - val_loss: 2.3460e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0192 - accuracy: 0.9931 - val_loss: 1.5040e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 7.1942e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0231 - accuracy: 0.9920 - val_loss: 6.2540e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0213 - accuracy: 0.9952 - val_loss: 1.6778e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0181 - accuracy: 0.9943 - val_loss: 1.8302e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0146 - accuracy: 0.9960 - val_loss: 1.2495e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0188 - accuracy: 0.9930 - val_loss: 1.1994e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0222 - accuracy: 0.9940 - val_loss: 3.7444e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0215 - accuracy: 0.9942 - val_loss: 2.4133e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0174 - accuracy: 0.9948 - val_loss: 3.0787e-05 - val_accuracy: 1.0000\n",
            "Results for fold 10\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0247 - accuracy: 0.9924 - val_loss: 5.1676e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0147 - accuracy: 0.9966 - val_loss: 3.3360e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0293 - accuracy: 0.9912 - val_loss: 2.7737e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0260 - accuracy: 0.9933 - val_loss: 1.0073e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 9.3326e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 2.0704e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0179 - accuracy: 0.9946 - val_loss: 7.5644e-06 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0385 - accuracy: 0.9872 - val_loss: 4.6549e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0262 - accuracy: 0.9914 - val_loss: 3.0582e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0107 - accuracy: 0.9975 - val_loss: 3.5436e-06 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 3.5614e-06 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0152 - accuracy: 0.9958 - val_loss: 6.0262e-06 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0183 - accuracy: 0.9948 - val_loss: 2.1748e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 2.4992e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0226 - accuracy: 0.9917 - val_loss: 5.2570e-06 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0134 - accuracy: 0.9955 - val_loss: 1.8013e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0153 - accuracy: 0.9945 - val_loss: 3.4048e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0209 - accuracy: 0.9936 - val_loss: 4.9049e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0159 - accuracy: 0.9937 - val_loss: 5.3241e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0193 - accuracy: 0.9940 - val_loss: 5.0257e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 0.0250 - accuracy: 0.9931 - val_loss: 1.4767e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0197 - accuracy: 0.9934 - val_loss: 1.2185e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0187 - accuracy: 0.9942 - val_loss: 1.7928e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0190 - accuracy: 0.9946 - val_loss: 1.7925e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0261 - accuracy: 0.9924 - val_loss: 8.6242e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0163 - accuracy: 0.9940 - val_loss: 8.5143e-06 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 4.2473e-06 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 2s 41ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 1.1168e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0220 - accuracy: 0.9936 - val_loss: 1.4200e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0150 - accuracy: 0.9946 - val_loss: 1.7693e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-SH0e6flrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "e6f013c1-a009-4eb4-9f94-6d48572402c6"
      },
      "source": [
        "acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 0s 6ms/step - loss: 0.0758 - accuracy: 0.9828\n",
            "Accuracy  : 0.9828326106071472\n",
            "F1_Score  : 0.9798341350273146\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJehdYs6ZBcD"
      },
      "source": [
        "# **Dominance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwJWlxMZEe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "d4c5ed01-9eb1-46d2-bc6c-dadd96c249f3"
      },
      "source": [
        "'''#dominance\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'#dominance\\nX_train, x_test, Y_train, y_test = train_test_split(data,dominance, test_size=0.2, random_state=4)\\nprint(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljSiW-xZMC_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "63f7a5ad-1a1b-4d94-aebf-45ff0154f58d"
      },
      "source": [
        "'''foldNum=0\n",
        "model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val\n",
        "  gc.collect()'''"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'foldNum=0\\nmodel = get_model()\\nfor train_index, val_index in kfold.split(X_train, Y_train):\\n  foldNum = foldNum + 1\\n  print(\"Results for fold\",foldNum)\\n  x_train, x_val = X_train[train_index], X_train[val_index]\\n  y_train, y_val = Y_train[train_index], Y_train[val_index]\\n  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\\n  gc.collect() # Garbage collecter\\n  del x_train, x_val, y_train, y_val\\n  gc.collect()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_olzDVBZS7u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "b06b6099-b012-43a6-d51e-65e56b51130c"
      },
      "source": [
        "'''acrc = model.evaluate(x_test, y_test)\n",
        "pred = model.predict(x_test)\n",
        "f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "c_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\n",
        "print(\"Accuracy  : {}\".format(acrc[1]))\n",
        "print(\"F1_Score  : {}\".format(f1scr))\n",
        "c_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'acrc = model.evaluate(x_test, y_test)\\npred = model.predict(x_test)\\nf1scr = f1_score(y_test.argmax(1), pred.argmax(1), average=\\'macro\\')\\nc_matrix = confusion_matrix(y_test.argmax(1), pred.argmax(1))\\nprint(\"Accuracy  : {}\".format(acrc[1]))\\nprint(\"F1_Score  : {}\".format(f1scr))\\nc_matrix = c_matrix/np.sum(c_matrix, axis=1).reshape(3,1)\\nimport seaborn as sns\\nfigure = plt.figure(figsize=(9, 9))\\nsns.heatmap(c_matrix, annot=True,cmap=plt.cm.Blues)\\nplt.tight_layout()\\nplt.ylabel(\\'True label\\')\\nplt.xlabel(\\'Predicted label\\')\\nplt.show()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}