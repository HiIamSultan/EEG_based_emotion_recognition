{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mJl4myg42Jt-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import pickle as pkl\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, Input, Reshape, BatchNormalization, Bidirectional, LSTM, Multiply, Activation, Normalization, TimeDistributed, Lambda\n",
        "from keras.layers import Conv3D, Conv2D, Conv1D, MaxPool3D, MaxPool2D, MaxPool1D, AvgPool3D, AvgPool2D, AvgPool1D, GlobalMaxPool3D, Attention\n",
        "from keras.layers import GlobalMaxPool2D, GlobalMaxPool1D, SpatialDropout3D, SpatialDropout2D, SpatialDropout1D, GlobalAvgPool3D, MultiHeadAttention\n",
        "from keras.layers import GlobalAvgPool2D, GlobalAvgPool1D, SeparableConv2D, MaxPooling2D, SeparableConv1D, Add, Concatenate, LeakyReLU, ELU, Activation, PReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import gc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "636j2NDJVajh"
      },
      "source": [
        "# **Data Loading**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ns3s5JN97fU",
        "outputId": "cf350263-d59a-4049-b983-5af63e8be22d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ugvNZGZX-DO7"
      },
      "outputs": [],
      "source": [
        "input_path='/content/drive/MyDrive/data_preprocessed_python/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHPHG2H5lmju",
        "outputId": "18c14fae-e621-4bbe-9928-0b7954271f84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Person No.7\n",
            "(1200, 256, 32)\n",
            "(1200,) (360,) (840,)\n",
            "(1200,) (450,) (750,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "eeg_signal = []\n",
        "valence = []\n",
        "arousal = []\n",
        "window_size = 256\n",
        "skip = 256\n",
        "\n",
        "for person in range(7,8):\n",
        "  print('Person No.' + str(person))\n",
        "  \n",
        "  \n",
        "  address = input_path+'s'+str(person)+'.dat'\n",
        "\n",
        "  with open(address, 'rb') as file:\n",
        "    data = pkl.load(file, encoding = 'latin1')\n",
        "\n",
        "  eeg = data['data']\n",
        "  label = data['labels']\n",
        "  \n",
        "  # Assigning classes\n",
        "  label[label<5] = 0\n",
        "  label[label>=5] = 1\n",
        "\n",
        "  val = label.T[0] # Valence label\n",
        "  aro = label.T[1] # Arousal label\n",
        "\n",
        "  del data, label\n",
        "  # Iterating through 40 vidoes/trials\n",
        "  for i in range(40):\n",
        "    sig = eeg[i].T\n",
        "    sig = sig[384:, :32]\n",
        "    # Segmenting into 3 seconds (384 timesteps) windows without overlap\n",
        "    start = 0\n",
        "    while start + window_size <=sig.shape[0]:\n",
        "      eeg_signal.append(sig[start:start+window_size,:])\n",
        "      valence.append(val[i])\n",
        "      arousal.append(aro[i])\n",
        "      start += skip \n",
        "  del eeg, val, aro, sig\n",
        "#eeg_signal = np.array(eeg_signal)\n",
        "#print(eeg_signal.shape)\n",
        "eeg_signal = np.reshape(eeg_signal,[-1,256,32])\n",
        "data = np.asarray(eeg_signal, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
        "del eeg_signal\n",
        "valence = np.asarray(valence, dtype = np.int8)\n",
        "arousal = np.asarray(arousal, dtype = np.int8)\n",
        "\n",
        "print(data.shape)\n",
        "print(valence.shape, valence[valence == 0].shape, valence[valence == 1].shape)\n",
        "print(arousal.shape, arousal[arousal == 0].shape, arousal[arousal == 1].shape)\n",
        "\n",
        "valence = np_utils.to_categorical(valence)\n",
        "arousal = np_utils.to_categorical(arousal)\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lpz2A61dXyQI",
        "outputId": "72f46af1-b963-4d3d-a4b3-6b8a9b4a86e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1080, 256, 32) (120, 256, 32) (1080, 2) (120, 2)\n"
          ]
        }
      ],
      "source": [
        " X_train, x_test, Y_train, y_test = train_test_split(data, valence, test_size=0.1, random_state=4)\n",
        " print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Previous 2D Model"
      ],
      "metadata": {
        "id": "F4VAAMGvtuWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ReshapeLayer(x):\n",
        "    \n",
        "    shape = x.shape\n",
        "    \n",
        "    reshape = Reshape((shape[1],shape[2],1))(x)\n",
        "    \n",
        "    \n",
        "    return reshape\n",
        "def get_CNN_model(x):\n",
        "  x = Bidirectional(LSTM(32, return_sequences=True))(x)\n",
        "  x = Reshape((-1, x.shape[2],1), name='Reshape_1')(x)\n",
        "  x = Conv2D(filters=16, kernel_size=(5,5), strides=(2,2), padding='same', name = 'Conv_1')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = MaxPooling2D(pool_size=(2,2))(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "  x = Conv2D(filters=32, kernel_size=(7,7), strides=(2,2), padding='same', name = 'Conv_2')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = MaxPooling2D(pool_size=(2,2))(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "  x = Conv2D(filters=64, kernel_size=(9,9), strides=(2,2), padding='same', name = 'Conv_3')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = MaxPooling2D(pool_size=(1,1))(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(256,activation='tanh')(x)\n",
        "  x = Dropout(0.4)(x)\n",
        "  x = Dense(32,activation='relu')(x)\n",
        "  x = Dropout(0.4)(x)\n",
        "  x = Dense(2,activation='softmax')(x)\n",
        "  return x\n",
        "def get_model():\n",
        "  input = Input(shape = (256,32))\n",
        "  output = get_CNN_model(input)\n",
        "  model_a = Model(input,output)\n",
        "  opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "  model_a.compile(loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"], optimizer=opt)\n",
        "  return model_a\n",
        "\n",
        "model = get_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62JKbRmSRASa",
        "outputId": "c2168aba-41fe-4273-fd6f-c1d41b4c536f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 256, 32)]         0         \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 256, 64)          16640     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " Reshape_1 (Reshape)         (None, 256, 64, 1)        0         \n",
            "                                                                 \n",
            " Conv_1 (Conv2D)             (None, 128, 32, 16)       416       \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 128, 32, 16)      64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 64, 16, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 64, 16, 16)        0         \n",
            "                                                                 \n",
            " Conv_2 (Conv2D)             (None, 32, 8, 32)         25120     \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 32, 8, 32)        128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 16, 4, 32)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 16, 4, 32)         0         \n",
            "                                                                 \n",
            " Conv_3 (Conv2D)             (None, 8, 2, 64)          165952    \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 8, 2, 64)         256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 8, 2, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 8, 2, 64)          0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               262400    \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 32)                8224      \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 479,266\n",
            "Trainable params: 479,042\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "epochs = 200\n",
        "kfold = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTM6aQ6mhrxE",
        "outputId": "f016527c-c2d7-45ed-dca3-918f6e7976ee"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9856"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-KlZlvaENEF",
        "outputId": "6fe3d75e-e6c1-4cc8-947c-23f19ba5b72d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for fold 1\n",
            "(972, 256, 32)\n",
            "Epoch 1/50\n",
            "98/98 [==============================] - 15s 113ms/step - loss: 0.6855 - accuracy: 0.6646 - val_loss: 0.6070 - val_accuracy: 0.7222\n",
            "Epoch 2/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6254 - accuracy: 0.7027 - val_loss: 0.6167 - val_accuracy: 0.7222\n",
            "Epoch 3/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6260 - accuracy: 0.6996 - val_loss: 0.6031 - val_accuracy: 0.7222\n",
            "Epoch 4/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6255 - accuracy: 0.6996 - val_loss: 0.6015 - val_accuracy: 0.7222\n",
            "Epoch 5/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6308 - accuracy: 0.6986 - val_loss: 0.5996 - val_accuracy: 0.7222\n",
            "Epoch 6/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6235 - accuracy: 0.6965 - val_loss: 0.6163 - val_accuracy: 0.7222\n",
            "Epoch 7/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6194 - accuracy: 0.6996 - val_loss: 0.5918 - val_accuracy: 0.7222\n",
            "Epoch 8/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6172 - accuracy: 0.6996 - val_loss: 0.5936 - val_accuracy: 0.7222\n",
            "Epoch 9/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6209 - accuracy: 0.6996 - val_loss: 0.5979 - val_accuracy: 0.7222\n",
            "Epoch 10/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6217 - accuracy: 0.6986 - val_loss: 0.6171 - val_accuracy: 0.7222\n",
            "Epoch 11/50\n",
            "98/98 [==============================] - 9s 96ms/step - loss: 0.6249 - accuracy: 0.6996 - val_loss: 0.6052 - val_accuracy: 0.7222\n",
            "Epoch 12/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6181 - accuracy: 0.6996 - val_loss: 0.5992 - val_accuracy: 0.7222\n",
            "Epoch 13/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6180 - accuracy: 0.6996 - val_loss: 0.6052 - val_accuracy: 0.7222\n",
            "Epoch 14/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6177 - accuracy: 0.6996 - val_loss: 0.5910 - val_accuracy: 0.7222\n",
            "Epoch 15/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6177 - accuracy: 0.6996 - val_loss: 0.6015 - val_accuracy: 0.7222\n",
            "Epoch 16/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6205 - accuracy: 0.6996 - val_loss: 0.5976 - val_accuracy: 0.7222\n",
            "Epoch 17/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6197 - accuracy: 0.6996 - val_loss: 0.5950 - val_accuracy: 0.7222\n",
            "Epoch 18/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6174 - accuracy: 0.6996 - val_loss: 0.5930 - val_accuracy: 0.7222\n",
            "Epoch 19/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6132 - accuracy: 0.6996 - val_loss: 0.6041 - val_accuracy: 0.7222\n",
            "Epoch 20/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6190 - accuracy: 0.6996 - val_loss: 0.5927 - val_accuracy: 0.7222\n",
            "Epoch 21/50\n",
            "98/98 [==============================] - 9s 91ms/step - loss: 0.6141 - accuracy: 0.6996 - val_loss: 0.5970 - val_accuracy: 0.7222\n",
            "Epoch 22/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6168 - accuracy: 0.6986 - val_loss: 0.5924 - val_accuracy: 0.7222\n",
            "Epoch 23/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6135 - accuracy: 0.6986 - val_loss: 0.5918 - val_accuracy: 0.7222\n",
            "Epoch 24/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6169 - accuracy: 0.6996 - val_loss: 0.5990 - val_accuracy: 0.7222\n",
            "Epoch 25/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6123 - accuracy: 0.6996 - val_loss: 0.5922 - val_accuracy: 0.7222\n",
            "Epoch 26/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6130 - accuracy: 0.6996 - val_loss: 0.5945 - val_accuracy: 0.7222\n",
            "Epoch 27/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6126 - accuracy: 0.6996 - val_loss: 0.6006 - val_accuracy: 0.7222\n",
            "Epoch 28/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6152 - accuracy: 0.6996 - val_loss: 0.5946 - val_accuracy: 0.7222\n",
            "Epoch 29/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6115 - accuracy: 0.6996 - val_loss: 0.5925 - val_accuracy: 0.7222\n",
            "Epoch 30/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6137 - accuracy: 0.6996 - val_loss: 0.6005 - val_accuracy: 0.7222\n",
            "Epoch 31/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6162 - accuracy: 0.6986 - val_loss: 0.5971 - val_accuracy: 0.7222\n",
            "Epoch 32/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6144 - accuracy: 0.6996 - val_loss: 0.5937 - val_accuracy: 0.7222\n",
            "Epoch 33/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6140 - accuracy: 0.6986 - val_loss: 0.5952 - val_accuracy: 0.7222\n",
            "Epoch 34/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6122 - accuracy: 0.6996 - val_loss: 0.5906 - val_accuracy: 0.7222\n",
            "Epoch 35/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6098 - accuracy: 0.6996 - val_loss: 0.5812 - val_accuracy: 0.7222\n",
            "Epoch 36/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6270 - accuracy: 0.6883 - val_loss: 0.6198 - val_accuracy: 0.7222\n",
            "Epoch 37/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6026 - accuracy: 0.6975 - val_loss: 0.5480 - val_accuracy: 0.7222\n",
            "Epoch 38/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.5813 - accuracy: 0.6955 - val_loss: 0.6551 - val_accuracy: 0.7222\n",
            "Epoch 39/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.5588 - accuracy: 0.6944 - val_loss: 0.8020 - val_accuracy: 0.7222\n",
            "Epoch 40/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.5510 - accuracy: 0.6965 - val_loss: 0.5626 - val_accuracy: 0.7222\n",
            "Epoch 41/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.5192 - accuracy: 0.7150 - val_loss: 1.0473 - val_accuracy: 0.7222\n",
            "Epoch 42/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.5019 - accuracy: 0.7140 - val_loss: 0.6592 - val_accuracy: 0.7315\n",
            "Epoch 43/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.4854 - accuracy: 0.7510 - val_loss: 0.5099 - val_accuracy: 0.6759\n",
            "Epoch 44/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.4150 - accuracy: 0.7963 - val_loss: 0.7569 - val_accuracy: 0.7315\n",
            "Epoch 45/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.4140 - accuracy: 0.7767 - val_loss: 0.5809 - val_accuracy: 0.7222\n",
            "Epoch 46/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.3874 - accuracy: 0.8241 - val_loss: 0.9442 - val_accuracy: 0.7407\n",
            "Epoch 47/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.3519 - accuracy: 0.8488 - val_loss: 0.9928 - val_accuracy: 0.7407\n",
            "Epoch 48/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.3227 - accuracy: 0.8663 - val_loss: 0.6300 - val_accuracy: 0.6852\n",
            "Epoch 49/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.3033 - accuracy: 0.8765 - val_loss: 0.7240 - val_accuracy: 0.7037\n",
            "Epoch 50/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.2579 - accuracy: 0.9023 - val_loss: 0.8343 - val_accuracy: 0.7500\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.1702 - accuracy: 0.6833\n",
            "[1.1701641082763672, 0.6833333373069763]\n",
            "0.5052083333333333\n",
            "Results for fold 2\n",
            "(972, 256, 32)\n",
            "Epoch 1/50\n",
            "98/98 [==============================] - 14s 104ms/step - loss: 0.6945 - accuracy: 0.6646 - val_loss: 0.7539 - val_accuracy: 0.2778\n",
            "Epoch 2/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6386 - accuracy: 0.6986 - val_loss: 0.7234 - val_accuracy: 0.2778\n",
            "Epoch 3/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6298 - accuracy: 0.6986 - val_loss: 0.6332 - val_accuracy: 0.7222\n",
            "Epoch 4/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6296 - accuracy: 0.6996 - val_loss: 0.5997 - val_accuracy: 0.7222\n",
            "Epoch 5/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6216 - accuracy: 0.6996 - val_loss: 0.6073 - val_accuracy: 0.7222\n",
            "Epoch 6/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6145 - accuracy: 0.6986 - val_loss: 0.5905 - val_accuracy: 0.7222\n",
            "Epoch 7/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6244 - accuracy: 0.6996 - val_loss: 0.5945 - val_accuracy: 0.7222\n",
            "Epoch 8/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6224 - accuracy: 0.6996 - val_loss: 0.6030 - val_accuracy: 0.7222\n",
            "Epoch 9/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6214 - accuracy: 0.6996 - val_loss: 0.5992 - val_accuracy: 0.7222\n",
            "Epoch 10/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6230 - accuracy: 0.6996 - val_loss: 0.6086 - val_accuracy: 0.7222\n",
            "Epoch 11/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6224 - accuracy: 0.6996 - val_loss: 0.6035 - val_accuracy: 0.7222\n",
            "Epoch 12/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6190 - accuracy: 0.6996 - val_loss: 0.5949 - val_accuracy: 0.7222\n",
            "Epoch 13/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6187 - accuracy: 0.6975 - val_loss: 0.5938 - val_accuracy: 0.7222\n",
            "Epoch 14/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6206 - accuracy: 0.6996 - val_loss: 0.5969 - val_accuracy: 0.7222\n",
            "Epoch 15/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6140 - accuracy: 0.6996 - val_loss: 0.5911 - val_accuracy: 0.7222\n",
            "Epoch 16/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6085 - accuracy: 0.6934 - val_loss: 0.5919 - val_accuracy: 0.7222\n",
            "Epoch 17/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.5930 - accuracy: 0.7006 - val_loss: 0.6992 - val_accuracy: 0.7222\n",
            "Epoch 18/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.5710 - accuracy: 0.6965 - val_loss: 0.6927 - val_accuracy: 0.7222\n",
            "Epoch 19/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.5643 - accuracy: 0.7191 - val_loss: 0.7724 - val_accuracy: 0.7222\n",
            "Epoch 20/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.5252 - accuracy: 0.7099 - val_loss: 0.7544 - val_accuracy: 0.7222\n",
            "Epoch 21/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.5168 - accuracy: 0.7109 - val_loss: 1.1065 - val_accuracy: 0.7222\n",
            "Epoch 22/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.4693 - accuracy: 0.7479 - val_loss: 0.9662 - val_accuracy: 0.7222\n",
            "Epoch 23/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.4472 - accuracy: 0.7778 - val_loss: 1.0738 - val_accuracy: 0.7222\n",
            "Epoch 24/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.4186 - accuracy: 0.8056 - val_loss: 1.2123 - val_accuracy: 0.7222\n",
            "Epoch 25/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.3893 - accuracy: 0.8230 - val_loss: 0.7578 - val_accuracy: 0.6667\n",
            "Epoch 26/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.3628 - accuracy: 0.8385 - val_loss: 0.5746 - val_accuracy: 0.6759\n",
            "Epoch 27/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.3004 - accuracy: 0.8827 - val_loss: 0.8818 - val_accuracy: 0.6944\n",
            "Epoch 28/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.2964 - accuracy: 0.8868 - val_loss: 1.5780 - val_accuracy: 0.7130\n",
            "Epoch 29/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.2729 - accuracy: 0.8879 - val_loss: 1.7515 - val_accuracy: 0.7222\n",
            "Epoch 30/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.2400 - accuracy: 0.9208 - val_loss: 1.4797 - val_accuracy: 0.5000\n",
            "Epoch 31/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.2126 - accuracy: 0.9311 - val_loss: 1.1933 - val_accuracy: 0.5741\n",
            "Epoch 32/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.2078 - accuracy: 0.9239 - val_loss: 1.2951 - val_accuracy: 0.7037\n",
            "Epoch 33/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.2128 - accuracy: 0.9146 - val_loss: 1.0554 - val_accuracy: 0.6852\n",
            "Epoch 34/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.1511 - accuracy: 0.9465 - val_loss: 1.2079 - val_accuracy: 0.6574\n",
            "Epoch 35/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.1636 - accuracy: 0.9259 - val_loss: 1.0929 - val_accuracy: 0.6204\n",
            "Epoch 36/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.1318 - accuracy: 0.9527 - val_loss: 1.5283 - val_accuracy: 0.6759\n",
            "Epoch 37/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.1980 - accuracy: 0.9342 - val_loss: 1.1056 - val_accuracy: 0.6759\n",
            "Epoch 38/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.1035 - accuracy: 0.9671 - val_loss: 1.3189 - val_accuracy: 0.6759\n",
            "Epoch 39/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.1866 - accuracy: 0.9372 - val_loss: 0.8239 - val_accuracy: 0.6944\n",
            "Epoch 40/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.1472 - accuracy: 0.9434 - val_loss: 1.1187 - val_accuracy: 0.6852\n",
            "Epoch 41/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.1301 - accuracy: 0.9609 - val_loss: 1.1043 - val_accuracy: 0.6759\n",
            "Epoch 42/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.0918 - accuracy: 0.9671 - val_loss: 1.7738 - val_accuracy: 0.6296\n",
            "Epoch 43/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.0991 - accuracy: 0.9671 - val_loss: 1.4951 - val_accuracy: 0.6389\n",
            "Epoch 44/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.0991 - accuracy: 0.9630 - val_loss: 2.4547 - val_accuracy: 0.5000\n",
            "Epoch 45/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.1389 - accuracy: 0.9496 - val_loss: 0.9190 - val_accuracy: 0.6759\n",
            "Epoch 46/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.1066 - accuracy: 0.9630 - val_loss: 1.4112 - val_accuracy: 0.6759\n",
            "Epoch 47/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.0925 - accuracy: 0.9650 - val_loss: 1.4024 - val_accuracy: 0.6296\n",
            "Epoch 48/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.0904 - accuracy: 0.9650 - val_loss: 1.5194 - val_accuracy: 0.6759\n",
            "Epoch 49/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.0641 - accuracy: 0.9753 - val_loss: 2.3646 - val_accuracy: 0.6296\n",
            "Epoch 50/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.2179 - accuracy: 0.9239 - val_loss: 0.9642 - val_accuracy: 0.6019\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.7293 - accuracy: 0.6833\n",
            "[0.7293168902397156, 0.6833333373069763]\n",
            "0.6101231190150479\n",
            "Results for fold 3\n",
            "(972, 256, 32)\n",
            "Epoch 1/50\n",
            "98/98 [==============================] - 14s 103ms/step - loss: 0.7206 - accuracy: 0.6728 - val_loss: 0.6519 - val_accuracy: 0.6574\n",
            "Epoch 2/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6271 - accuracy: 0.7058 - val_loss: 0.6502 - val_accuracy: 0.6574\n",
            "Epoch 3/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6307 - accuracy: 0.7078 - val_loss: 0.6474 - val_accuracy: 0.6574\n",
            "Epoch 4/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6224 - accuracy: 0.7068 - val_loss: 0.6428 - val_accuracy: 0.6574\n",
            "Epoch 5/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6170 - accuracy: 0.7068 - val_loss: 0.6434 - val_accuracy: 0.6574\n",
            "Epoch 6/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6224 - accuracy: 0.7058 - val_loss: 0.6429 - val_accuracy: 0.6574\n",
            "Epoch 7/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6125 - accuracy: 0.7068 - val_loss: 0.6426 - val_accuracy: 0.6574\n",
            "Epoch 8/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6211 - accuracy: 0.7047 - val_loss: 0.6439 - val_accuracy: 0.6574\n",
            "Epoch 9/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6148 - accuracy: 0.7068 - val_loss: 0.6442 - val_accuracy: 0.6574\n",
            "Epoch 10/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6149 - accuracy: 0.7068 - val_loss: 0.6428 - val_accuracy: 0.6574\n",
            "Epoch 11/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6120 - accuracy: 0.7068 - val_loss: 0.6457 - val_accuracy: 0.6574\n",
            "Epoch 12/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6093 - accuracy: 0.7006 - val_loss: 0.6472 - val_accuracy: 0.6574\n",
            "Epoch 13/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6098 - accuracy: 0.7068 - val_loss: 0.6447 - val_accuracy: 0.6574\n",
            "Epoch 14/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6120 - accuracy: 0.7068 - val_loss: 0.6524 - val_accuracy: 0.6574\n",
            "Epoch 15/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6131 - accuracy: 0.7068 - val_loss: 0.6435 - val_accuracy: 0.6574\n",
            "Epoch 16/50\n",
            "98/98 [==============================] - 9s 92ms/step - loss: 0.6064 - accuracy: 0.7068 - val_loss: 0.6583 - val_accuracy: 0.6574\n",
            "Epoch 17/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6152 - accuracy: 0.7068 - val_loss: 0.6503 - val_accuracy: 0.6574\n",
            "Epoch 18/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6090 - accuracy: 0.7068 - val_loss: 0.6487 - val_accuracy: 0.6574\n",
            "Epoch 19/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6078 - accuracy: 0.7068 - val_loss: 0.6462 - val_accuracy: 0.6574\n",
            "Epoch 20/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6056 - accuracy: 0.7068 - val_loss: 0.6459 - val_accuracy: 0.6574\n",
            "Epoch 21/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6097 - accuracy: 0.7068 - val_loss: 0.6467 - val_accuracy: 0.6574\n",
            "Epoch 22/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6098 - accuracy: 0.7068 - val_loss: 0.6436 - val_accuracy: 0.6574\n",
            "Epoch 23/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6092 - accuracy: 0.7068 - val_loss: 0.6446 - val_accuracy: 0.6574\n",
            "Epoch 24/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6085 - accuracy: 0.7068 - val_loss: 0.6445 - val_accuracy: 0.6574\n",
            "Epoch 25/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6074 - accuracy: 0.7068 - val_loss: 0.6471 - val_accuracy: 0.6574\n",
            "Epoch 26/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6095 - accuracy: 0.7068 - val_loss: 0.6387 - val_accuracy: 0.6574\n",
            "Epoch 27/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6095 - accuracy: 0.7078 - val_loss: 0.6442 - val_accuracy: 0.6574\n",
            "Epoch 28/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6071 - accuracy: 0.7068 - val_loss: 0.6500 - val_accuracy: 0.6574\n",
            "Epoch 29/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.6004 - accuracy: 0.7068 - val_loss: 0.6534 - val_accuracy: 0.6574\n",
            "Epoch 30/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.6039 - accuracy: 0.7047 - val_loss: 0.6412 - val_accuracy: 0.6574\n",
            "Epoch 31/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.5874 - accuracy: 0.7130 - val_loss: 0.6960 - val_accuracy: 0.6574\n",
            "Epoch 32/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.5853 - accuracy: 0.7109 - val_loss: 0.6631 - val_accuracy: 0.6574\n",
            "Epoch 33/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.5711 - accuracy: 0.7222 - val_loss: 0.6998 - val_accuracy: 0.6574\n",
            "Epoch 34/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.5631 - accuracy: 0.7233 - val_loss: 0.7228 - val_accuracy: 0.6574\n",
            "Epoch 35/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.5354 - accuracy: 0.7233 - val_loss: 0.7065 - val_accuracy: 0.6574\n",
            "Epoch 36/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.5228 - accuracy: 0.7377 - val_loss: 0.9417 - val_accuracy: 0.6574\n",
            "Epoch 37/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.4710 - accuracy: 0.7737 - val_loss: 1.0548 - val_accuracy: 0.6574\n",
            "Epoch 38/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.4544 - accuracy: 0.7942 - val_loss: 1.0123 - val_accuracy: 0.6667\n",
            "Epoch 39/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.3930 - accuracy: 0.8302 - val_loss: 1.2410 - val_accuracy: 0.6574\n",
            "Epoch 40/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.3547 - accuracy: 0.8344 - val_loss: 0.5874 - val_accuracy: 0.7407\n",
            "Epoch 41/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.3532 - accuracy: 0.8508 - val_loss: 0.8463 - val_accuracy: 0.7130\n",
            "Epoch 42/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.2773 - accuracy: 0.8796 - val_loss: 0.6052 - val_accuracy: 0.7500\n",
            "Epoch 43/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.2459 - accuracy: 0.9053 - val_loss: 0.6905 - val_accuracy: 0.6852\n",
            "Epoch 44/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.2278 - accuracy: 0.9156 - val_loss: 0.7025 - val_accuracy: 0.7130\n",
            "Epoch 45/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.2102 - accuracy: 0.9136 - val_loss: 0.9050 - val_accuracy: 0.7130\n",
            "Epoch 46/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.2219 - accuracy: 0.9146 - val_loss: 1.3364 - val_accuracy: 0.5185\n",
            "Epoch 47/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.1716 - accuracy: 0.9362 - val_loss: 0.9649 - val_accuracy: 0.7222\n",
            "Epoch 48/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.1715 - accuracy: 0.9424 - val_loss: 0.8752 - val_accuracy: 0.7037\n",
            "Epoch 49/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.1854 - accuracy: 0.9393 - val_loss: 0.6817 - val_accuracy: 0.7407\n",
            "Epoch 50/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.1582 - accuracy: 0.9383 - val_loss: 0.7673 - val_accuracy: 0.7315\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.0543 - accuracy: 0.6583\n",
            "[1.0543476343154907, 0.6583333611488342]\n",
            "0.5674725274725274\n",
            "Results for fold 4\n",
            "(972, 256, 32)\n",
            "Epoch 1/50\n",
            "98/98 [==============================] - 15s 105ms/step - loss: 0.6987 - accuracy: 0.6553 - val_loss: 0.5655 - val_accuracy: 0.7685\n",
            "Epoch 2/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.6247 - accuracy: 0.6893 - val_loss: 0.5439 - val_accuracy: 0.7685\n",
            "Epoch 3/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6317 - accuracy: 0.6914 - val_loss: 0.5645 - val_accuracy: 0.7685\n",
            "Epoch 4/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.6314 - accuracy: 0.6934 - val_loss: 0.5644 - val_accuracy: 0.7685\n",
            "Epoch 5/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.6334 - accuracy: 0.6944 - val_loss: 0.5825 - val_accuracy: 0.7685\n",
            "Epoch 6/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6249 - accuracy: 0.6944 - val_loss: 0.5819 - val_accuracy: 0.7685\n",
            "Epoch 7/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.6303 - accuracy: 0.6944 - val_loss: 0.5550 - val_accuracy: 0.7685\n",
            "Epoch 8/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6298 - accuracy: 0.6944 - val_loss: 0.5693 - val_accuracy: 0.7685\n",
            "Epoch 9/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6243 - accuracy: 0.6944 - val_loss: 0.5573 - val_accuracy: 0.7685\n",
            "Epoch 10/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6294 - accuracy: 0.6944 - val_loss: 0.5629 - val_accuracy: 0.7685\n",
            "Epoch 11/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6240 - accuracy: 0.6944 - val_loss: 0.5672 - val_accuracy: 0.7685\n",
            "Epoch 12/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6204 - accuracy: 0.6944 - val_loss: 0.5583 - val_accuracy: 0.7685\n",
            "Epoch 13/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6191 - accuracy: 0.6944 - val_loss: 0.5516 - val_accuracy: 0.7685\n",
            "Epoch 14/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.6248 - accuracy: 0.6944 - val_loss: 0.5544 - val_accuracy: 0.7685\n",
            "Epoch 15/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6288 - accuracy: 0.6811 - val_loss: 0.5477 - val_accuracy: 0.7685\n",
            "Epoch 16/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.6108 - accuracy: 0.6944 - val_loss: 0.5429 - val_accuracy: 0.7685\n",
            "Epoch 17/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.5903 - accuracy: 0.6914 - val_loss: 0.5285 - val_accuracy: 0.7685\n",
            "Epoch 18/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.5831 - accuracy: 0.6944 - val_loss: 0.5394 - val_accuracy: 0.7685\n",
            "Epoch 19/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.5509 - accuracy: 0.7047 - val_loss: 0.5667 - val_accuracy: 0.7685\n",
            "Epoch 20/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.5521 - accuracy: 0.7047 - val_loss: 0.5218 - val_accuracy: 0.7685\n",
            "Epoch 21/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.5239 - accuracy: 0.7130 - val_loss: 0.5788 - val_accuracy: 0.7685\n",
            "Epoch 22/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.4957 - accuracy: 0.7294 - val_loss: 0.7282 - val_accuracy: 0.7685\n",
            "Epoch 23/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.4465 - accuracy: 0.7757 - val_loss: 0.7730 - val_accuracy: 0.4907\n",
            "Epoch 24/50\n",
            "98/98 [==============================] - 9s 96ms/step - loss: 0.4423 - accuracy: 0.7757 - val_loss: 0.9549 - val_accuracy: 0.7685\n",
            "Epoch 25/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.4025 - accuracy: 0.8179 - val_loss: 1.0776 - val_accuracy: 0.7685\n",
            "Epoch 26/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.4130 - accuracy: 0.8097 - val_loss: 0.7707 - val_accuracy: 0.7685\n",
            "Epoch 27/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.3582 - accuracy: 0.8498 - val_loss: 1.5811 - val_accuracy: 0.2778\n",
            "Epoch 28/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.3431 - accuracy: 0.8508 - val_loss: 0.8395 - val_accuracy: 0.5648\n",
            "Epoch 29/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.2884 - accuracy: 0.8704 - val_loss: 0.7328 - val_accuracy: 0.6574\n",
            "Epoch 30/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.2112 - accuracy: 0.9239 - val_loss: 1.1986 - val_accuracy: 0.4815\n",
            "Epoch 31/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.1893 - accuracy: 0.9342 - val_loss: 0.8540 - val_accuracy: 0.7870\n",
            "Epoch 32/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.2443 - accuracy: 0.9115 - val_loss: 0.6764 - val_accuracy: 0.7593\n",
            "Epoch 33/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.1786 - accuracy: 0.9321 - val_loss: 0.8478 - val_accuracy: 0.7778\n",
            "Epoch 34/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.1870 - accuracy: 0.9280 - val_loss: 0.8721 - val_accuracy: 0.7407\n",
            "Epoch 35/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.1208 - accuracy: 0.9599 - val_loss: 1.1333 - val_accuracy: 0.7593\n",
            "Epoch 36/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.1906 - accuracy: 0.9290 - val_loss: 0.7900 - val_accuracy: 0.7407\n",
            "Epoch 37/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.1218 - accuracy: 0.9496 - val_loss: 1.2665 - val_accuracy: 0.7778\n",
            "Epoch 38/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.1300 - accuracy: 0.9486 - val_loss: 0.8131 - val_accuracy: 0.7407\n",
            "Epoch 39/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.1632 - accuracy: 0.9393 - val_loss: 0.6836 - val_accuracy: 0.7963\n",
            "Epoch 40/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.1313 - accuracy: 0.9588 - val_loss: 0.9658 - val_accuracy: 0.7870\n",
            "Epoch 41/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.0982 - accuracy: 0.9640 - val_loss: 1.1399 - val_accuracy: 0.7037\n",
            "Epoch 42/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.1194 - accuracy: 0.9630 - val_loss: 2.1356 - val_accuracy: 0.4167\n",
            "Epoch 43/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.1116 - accuracy: 0.9599 - val_loss: 1.2191 - val_accuracy: 0.7870\n",
            "Epoch 44/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.0690 - accuracy: 0.9743 - val_loss: 2.4415 - val_accuracy: 0.5463\n",
            "Epoch 45/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.1187 - accuracy: 0.9516 - val_loss: 0.8911 - val_accuracy: 0.7963\n",
            "Epoch 46/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.0903 - accuracy: 0.9753 - val_loss: 1.0640 - val_accuracy: 0.7407\n",
            "Epoch 47/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.0685 - accuracy: 0.9753 - val_loss: 1.3616 - val_accuracy: 0.7130\n",
            "Epoch 48/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.0443 - accuracy: 0.9835 - val_loss: 1.5735 - val_accuracy: 0.7315\n",
            "Epoch 49/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.0760 - accuracy: 0.9835 - val_loss: 1.3907 - val_accuracy: 0.7685\n",
            "Epoch 50/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.1389 - accuracy: 0.9506 - val_loss: 0.8219 - val_accuracy: 0.7500\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.7969 - accuracy: 0.7583\n",
            "[0.796890914440155, 0.7583333253860474]\n",
            "0.6812894953750344\n",
            "Results for fold 5\n",
            "(972, 256, 32)\n",
            "Epoch 1/50\n",
            "98/98 [==============================] - 15s 105ms/step - loss: 0.7177 - accuracy: 0.6543 - val_loss: 0.6419 - val_accuracy: 0.6852\n",
            "Epoch 2/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.6349 - accuracy: 0.7027 - val_loss: 0.6386 - val_accuracy: 0.6852\n",
            "Epoch 3/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.6229 - accuracy: 0.7037 - val_loss: 0.6576 - val_accuracy: 0.6852\n",
            "Epoch 4/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6260 - accuracy: 0.7027 - val_loss: 0.6329 - val_accuracy: 0.6852\n",
            "Epoch 5/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.6278 - accuracy: 0.7037 - val_loss: 0.6239 - val_accuracy: 0.6852\n",
            "Epoch 6/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.6240 - accuracy: 0.7037 - val_loss: 0.6225 - val_accuracy: 0.6852\n",
            "Epoch 7/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.6131 - accuracy: 0.7037 - val_loss: 0.6239 - val_accuracy: 0.6852\n",
            "Epoch 8/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.6178 - accuracy: 0.7037 - val_loss: 0.6231 - val_accuracy: 0.6852\n",
            "Epoch 9/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.6189 - accuracy: 0.7037 - val_loss: 0.6237 - val_accuracy: 0.6852\n",
            "Epoch 10/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.6194 - accuracy: 0.7037 - val_loss: 0.6255 - val_accuracy: 0.6852\n",
            "Epoch 11/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.6157 - accuracy: 0.7037 - val_loss: 0.6229 - val_accuracy: 0.6852\n",
            "Epoch 12/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.6188 - accuracy: 0.7037 - val_loss: 0.6236 - val_accuracy: 0.6852\n",
            "Epoch 13/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.6120 - accuracy: 0.7037 - val_loss: 0.6224 - val_accuracy: 0.6852\n",
            "Epoch 14/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.6122 - accuracy: 0.7037 - val_loss: 0.6204 - val_accuracy: 0.6852\n",
            "Epoch 15/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.6120 - accuracy: 0.7037 - val_loss: 0.6210 - val_accuracy: 0.6852\n",
            "Epoch 16/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.6096 - accuracy: 0.7027 - val_loss: 0.6292 - val_accuracy: 0.6852\n",
            "Epoch 17/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.6014 - accuracy: 0.6986 - val_loss: 0.5909 - val_accuracy: 0.6852\n",
            "Epoch 18/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.5902 - accuracy: 0.7099 - val_loss: 0.5629 - val_accuracy: 0.7037\n",
            "Epoch 19/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.5913 - accuracy: 0.6986 - val_loss: 0.6242 - val_accuracy: 0.6852\n",
            "Epoch 20/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.5565 - accuracy: 0.7037 - val_loss: 0.7812 - val_accuracy: 0.6852\n",
            "Epoch 21/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.5328 - accuracy: 0.7140 - val_loss: 0.5283 - val_accuracy: 0.7130\n",
            "Epoch 22/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.4957 - accuracy: 0.7469 - val_loss: 0.6664 - val_accuracy: 0.7037\n",
            "Epoch 23/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.4602 - accuracy: 0.7654 - val_loss: 1.0734 - val_accuracy: 0.6852\n",
            "Epoch 24/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.4189 - accuracy: 0.7984 - val_loss: 1.3742 - val_accuracy: 0.6852\n",
            "Epoch 25/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.3812 - accuracy: 0.8261 - val_loss: 1.1140 - val_accuracy: 0.7130\n",
            "Epoch 26/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.3345 - accuracy: 0.8560 - val_loss: 0.8421 - val_accuracy: 0.7315\n",
            "Epoch 27/50\n",
            "98/98 [==============================] - 9s 93ms/step - loss: 0.3281 - accuracy: 0.8632 - val_loss: 1.1655 - val_accuracy: 0.6852\n",
            "Epoch 28/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.2653 - accuracy: 0.9002 - val_loss: 2.0381 - val_accuracy: 0.6852\n",
            "Epoch 29/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.2442 - accuracy: 0.8889 - val_loss: 1.0216 - val_accuracy: 0.6667\n",
            "Epoch 30/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.2518 - accuracy: 0.9177 - val_loss: 0.8369 - val_accuracy: 0.7222\n",
            "Epoch 31/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.2192 - accuracy: 0.9187 - val_loss: 1.2483 - val_accuracy: 0.7130\n",
            "Epoch 32/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.1473 - accuracy: 0.9486 - val_loss: 1.0215 - val_accuracy: 0.6852\n",
            "Epoch 33/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.1632 - accuracy: 0.9372 - val_loss: 1.0942 - val_accuracy: 0.5556\n",
            "Epoch 34/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.1733 - accuracy: 0.9362 - val_loss: 0.9377 - val_accuracy: 0.7500\n",
            "Epoch 35/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.1750 - accuracy: 0.9434 - val_loss: 1.2128 - val_accuracy: 0.7037\n",
            "Epoch 36/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.1065 - accuracy: 0.9630 - val_loss: 1.4529 - val_accuracy: 0.7315\n",
            "Epoch 37/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.1457 - accuracy: 0.9403 - val_loss: 1.2242 - val_accuracy: 0.6667\n",
            "Epoch 38/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.0725 - accuracy: 0.9743 - val_loss: 1.5425 - val_accuracy: 0.7500\n",
            "Epoch 39/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.1208 - accuracy: 0.9578 - val_loss: 0.9344 - val_accuracy: 0.7407\n",
            "Epoch 40/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.1243 - accuracy: 0.9496 - val_loss: 1.1323 - val_accuracy: 0.7407\n",
            "Epoch 41/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.0872 - accuracy: 0.9640 - val_loss: 2.1483 - val_accuracy: 0.5463\n",
            "Epoch 42/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.1248 - accuracy: 0.9609 - val_loss: 1.6812 - val_accuracy: 0.7130\n",
            "Epoch 43/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.1513 - accuracy: 0.9506 - val_loss: 1.4150 - val_accuracy: 0.5556\n",
            "Epoch 44/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.1123 - accuracy: 0.9640 - val_loss: 1.5090 - val_accuracy: 0.5741\n",
            "Epoch 45/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.0841 - accuracy: 0.9660 - val_loss: 1.6117 - val_accuracy: 0.7222\n",
            "Epoch 46/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.1064 - accuracy: 0.9681 - val_loss: 1.1913 - val_accuracy: 0.6759\n",
            "Epoch 47/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.0886 - accuracy: 0.9681 - val_loss: 1.1026 - val_accuracy: 0.7315\n",
            "Epoch 48/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.0950 - accuracy: 0.9691 - val_loss: 1.6252 - val_accuracy: 0.7222\n",
            "Epoch 49/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.0716 - accuracy: 0.9753 - val_loss: 3.0307 - val_accuracy: 0.6944\n",
            "Epoch 50/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.0814 - accuracy: 0.9733 - val_loss: 1.3500 - val_accuracy: 0.7500\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1.3018 - accuracy: 0.6750\n",
            "[1.3018200397491455, 0.675000011920929]\n",
            "0.5713893213664255\n",
            "Results for fold 6\n",
            "(972, 256, 32)\n",
            "Epoch 1/50\n",
            "98/98 [==============================] - 15s 106ms/step - loss: 0.7233 - accuracy: 0.6471 - val_loss: 0.6364 - val_accuracy: 0.6944\n",
            "Epoch 2/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.6458 - accuracy: 0.6986 - val_loss: 0.6359 - val_accuracy: 0.6944\n",
            "Epoch 3/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.6287 - accuracy: 0.7027 - val_loss: 0.6286 - val_accuracy: 0.6944\n",
            "Epoch 4/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.6245 - accuracy: 0.7027 - val_loss: 0.6155 - val_accuracy: 0.6944\n",
            "Epoch 5/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.6286 - accuracy: 0.7027 - val_loss: 0.6185 - val_accuracy: 0.6944\n",
            "Epoch 6/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.6188 - accuracy: 0.7027 - val_loss: 0.6158 - val_accuracy: 0.6944\n",
            "Epoch 7/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.6236 - accuracy: 0.7016 - val_loss: 0.6176 - val_accuracy: 0.6944\n",
            "Epoch 8/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.6216 - accuracy: 0.6996 - val_loss: 0.6165 - val_accuracy: 0.6944\n",
            "Epoch 9/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.6186 - accuracy: 0.7016 - val_loss: 0.6159 - val_accuracy: 0.6944\n",
            "Epoch 10/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.6163 - accuracy: 0.7027 - val_loss: 0.6180 - val_accuracy: 0.6944\n",
            "Epoch 11/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.6122 - accuracy: 0.7027 - val_loss: 0.6158 - val_accuracy: 0.6944\n",
            "Epoch 12/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.6169 - accuracy: 0.6903 - val_loss: 0.6161 - val_accuracy: 0.6944\n",
            "Epoch 13/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.6179 - accuracy: 0.7027 - val_loss: 0.6173 - val_accuracy: 0.6944\n",
            "Epoch 14/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.6151 - accuracy: 0.7027 - val_loss: 0.6161 - val_accuracy: 0.6944\n",
            "Epoch 15/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.6091 - accuracy: 0.7027 - val_loss: 0.6157 - val_accuracy: 0.6944\n",
            "Epoch 16/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.6147 - accuracy: 0.7027 - val_loss: 0.6156 - val_accuracy: 0.6944\n",
            "Epoch 17/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.6145 - accuracy: 0.7027 - val_loss: 0.6162 - val_accuracy: 0.6944\n",
            "Epoch 18/50\n",
            "98/98 [==============================] - 9s 96ms/step - loss: 0.6101 - accuracy: 0.7027 - val_loss: 0.6155 - val_accuracy: 0.6944\n",
            "Epoch 19/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.6080 - accuracy: 0.7027 - val_loss: 0.6161 - val_accuracy: 0.6944\n",
            "Epoch 20/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.6150 - accuracy: 0.7027 - val_loss: 0.6169 - val_accuracy: 0.6944\n",
            "Epoch 21/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.6121 - accuracy: 0.7027 - val_loss: 0.6160 - val_accuracy: 0.6944\n",
            "Epoch 22/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.6135 - accuracy: 0.7027 - val_loss: 0.6162 - val_accuracy: 0.6944\n",
            "Epoch 23/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.6049 - accuracy: 0.7027 - val_loss: 0.6154 - val_accuracy: 0.6944\n",
            "Epoch 24/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.6114 - accuracy: 0.7027 - val_loss: 0.6127 - val_accuracy: 0.6944\n",
            "Epoch 25/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.6095 - accuracy: 0.7027 - val_loss: 0.6114 - val_accuracy: 0.6944\n",
            "Epoch 26/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.5977 - accuracy: 0.7027 - val_loss: 0.6104 - val_accuracy: 0.6944\n",
            "Epoch 27/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.6039 - accuracy: 0.7006 - val_loss: 0.5943 - val_accuracy: 0.6944\n",
            "Epoch 28/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.5871 - accuracy: 0.7027 - val_loss: 0.6186 - val_accuracy: 0.6944\n",
            "Epoch 29/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.5690 - accuracy: 0.6986 - val_loss: 0.6913 - val_accuracy: 0.6944\n",
            "Epoch 30/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.5717 - accuracy: 0.7047 - val_loss: 0.8870 - val_accuracy: 0.6944\n",
            "Epoch 31/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.5256 - accuracy: 0.7037 - val_loss: 0.6228 - val_accuracy: 0.6944\n",
            "Epoch 32/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.5144 - accuracy: 0.7150 - val_loss: 0.5736 - val_accuracy: 0.7037\n",
            "Epoch 33/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.4744 - accuracy: 0.7377 - val_loss: 1.1610 - val_accuracy: 0.6944\n",
            "Epoch 34/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.4785 - accuracy: 0.7325 - val_loss: 0.6965 - val_accuracy: 0.6944\n",
            "Epoch 35/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.4147 - accuracy: 0.7675 - val_loss: 1.6279 - val_accuracy: 0.6944\n",
            "Epoch 36/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.4451 - accuracy: 0.7778 - val_loss: 0.9679 - val_accuracy: 0.6667\n",
            "Epoch 37/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.3869 - accuracy: 0.8086 - val_loss: 1.0748 - val_accuracy: 0.6574\n",
            "Epoch 38/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.3653 - accuracy: 0.8282 - val_loss: 0.6767 - val_accuracy: 0.6667\n",
            "Epoch 39/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.3253 - accuracy: 0.8549 - val_loss: 1.1278 - val_accuracy: 0.6852\n",
            "Epoch 40/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.3003 - accuracy: 0.8652 - val_loss: 0.8235 - val_accuracy: 0.6389\n",
            "Epoch 41/50\n",
            "98/98 [==============================] - 9s 94ms/step - loss: 0.2641 - accuracy: 0.8930 - val_loss: 0.8824 - val_accuracy: 0.6204\n",
            "Epoch 42/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.2691 - accuracy: 0.8724 - val_loss: 2.3081 - val_accuracy: 0.6759\n",
            "Epoch 43/50\n",
            "98/98 [==============================] - 9s 95ms/step - loss: 0.2656 - accuracy: 0.8909 - val_loss: 0.9442 - val_accuracy: 0.6296\n",
            "Epoch 44/50\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2359 - accuracy: 0.9093"
          ]
        }
      ],
      "source": [
        "val_res = {'accuracy': [], 'f1_score': [], 'confusion_matrix': []}\n",
        "foldNum=0\n",
        "#model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  model_a = get_model()\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  print(x_train.shape)\n",
        "  opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "  model_a.compile(optimizer=opt, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "  model_a.fit(x_train, y_train, epochs=50, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  acc = model_a.evaluate(x_test, y_test)\n",
        "  print(acc)\n",
        "  val_res['accuracy'].append(acc)\n",
        "  pred = model_a.predict(x_test)\n",
        "  f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "  print(f1scr)\n",
        "  val_res['f1_score'].append(f1scr)\n",
        "  val_res['confusion_matrix'].append(confusion_matrix(y_test.argmax(1), pred.argmax(1)))\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val, acc, f1scr\n",
        "  gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = []\n",
        "f1 = []\n",
        "for i in val_res['accuracy']:\n",
        "  print(round(i[1]*100, 2))# Rounding off to two decimal places\n",
        "  a.append(i[1]*100)\n",
        "a = np.array(a)\n",
        "print(np.mean(a))\n",
        "for i in val_res['confusion_matrix']:\n",
        "  print(i)\n",
        "for i in val_res['f1_score']:\n",
        "  print(i*100)\n",
        "  f1.append(i)\n",
        "f1 = np.array(f1)\n",
        "print(np.mean(f1))\n"
      ],
      "metadata": {
        "id": "rJ2u_Yejpqc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F2Pa3j4VhZr"
      },
      "source": [
        "# **Arousal**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbCNIFVD3V2L"
      },
      "outputs": [],
      "source": [
        "#valence\n",
        "X_train, x_test, Y_train, y_test = train_test_split(data,arousal, test_size=0.1, random_state=4)\n",
        "print(X_train.shape,x_test.shape,Y_train.shape,y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qN7aC6MR7T0"
      },
      "outputs": [],
      "source": [
        "val_res = {'accuracy': [], 'f1_score': [], 'confusion_matrix': []}\n",
        "foldNum=0\n",
        "#model = get_model()\n",
        "for train_index, val_index in kfold.split(X_train, Y_train):\n",
        "  foldNum = foldNum + 1\n",
        "  model = get_model()\n",
        "  print(\"Results for fold\",foldNum)\n",
        "  x_train, x_val = X_train[train_index], X_train[val_index]\n",
        "  y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
        "  print(x_train.shape)\n",
        "  model_a.compile(optimizer=opt, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "  model_a.fit(x_train, y_train, epochs=200, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val),shuffle=True)\n",
        "  acc = model_a.evaluate(x_test, y_test)\n",
        "  print(acc)\n",
        "  val_res['accuracy'].append(acc)\n",
        "  pred = model_a.predict(x_test)\n",
        "  f1scr = f1_score(y_test.argmax(1), pred.argmax(1), average='macro')\n",
        "  print(f1scr)\n",
        "  val_res['f1_score'].append(f1scr)\n",
        "  val_res['confusion_matrix'].append(confusion_matrix(y_test.argmax(1), pred.argmax(1)))\n",
        "  gc.collect() # Garbage collecter\n",
        "  del x_train, x_val, y_train, y_val, acc, f1scr\n",
        "  gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUUIuZ3PVDcp"
      },
      "outputs": [],
      "source": [
        "a = []\n",
        "f1 = []\n",
        "for i in val_res['accuracy']:\n",
        "  print(round(i[1]*100, 2))# Rounding off to two decimal places\n",
        "  a.append(i[1]*100)\n",
        "a = np.array(a)\n",
        "print(np.mean(a))\n",
        "for i in val_res['confusion_matrix']:\n",
        "  print(i)\n",
        "for i in val_res['f1_score']:\n",
        "  print(i*100)\n",
        "  f1.append(i)\n",
        "f1 = np.array(f1)\n",
        "print(np.mean(f1))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "raw_2D_non_overlap_LSTM_2D_model_raw_new.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}